{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7efba7d7-6aa1-4d85-89e1-00e1216c3591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import os\n",
    "import logging\n",
    "import pickle as pk\n",
    "from collections import defaultdict\n",
    "\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from patchify import patchify,unpatchify\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.getLogger(\"PIL\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from skimage.measure import block_reduce\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from torchvision.models.resnet import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86744095-e8c2-4d17-8853-4187a2bcd122",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computing Contrastive Loss\n",
    "\n",
    "Really helped: https://gombru.github.io/2018/05/23/cross_entropy_loss/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3c913-5b67-4adc-9023-cfe98ed93ebf",
   "metadata": {},
   "source": [
    "The loss NT-XENT loss is a categorical-crossentropy like loss whereby:\n",
    "\n",
    "$$\n",
    "\\ell(i,j) = -\\log\\frac{\\exp(sim(\\vec{z}_i, \\vec{z}_j)/\\tau)}{\\sum_{k = 1, k \\neq i}^{2N} \\exp(sim(\\vec{z}_i, \\vec{z}_k)/\\tau)}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "sim(\\vec{u}, \\vec{v}) = \\vec{u}^T\\vec{v}/\\|\\vec{u}\\|\\|\\vec{v}\\|\n",
    "$$\n",
    "Then, the total contrastive loss will be:\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{2N}\\sum_{k = 1}^N  [\\ell(2k-1, 2k) + \\ell(2k, 2k-1)]\n",
    "$$\n",
    "\n",
    "Here, $N$ represents the mini-batch size. In standard contrastive loss, for each mini-batch sample $\\vec{x}_k, k \\in [1,N]$, we sample 2 random transformations $\\mathcal{T}_1, \\mathcal{T}_2$, to derive augmented samples $\\vec{z}_{2k-1}, \\vec{z}_{2k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7c3bf-c49d-4168-9d73-2381f894e837",
   "metadata": {},
   "source": [
    "We store the augmented samples in a matrix:\n",
    "\n",
    "$$\n",
    "M = \\begin{pmatrix}\n",
    "\\vec{z}_1^T \\\\\n",
    "\\vec{z}_2^T \\\\\n",
    "\\vdots \\\\\n",
    "\\vec{z}_{2k-1}^T \\\\\n",
    "\\vec{z}_{2k}^T\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "\\vec{z}_{2N-1}^T \\\\\n",
    "\\vec{z}_{2N}^T\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "We can then normalise the samples to have unit length (define $\\vec{a}_k = \\vec{z}_k/\\|\\vec{z}_k\\|$):\n",
    "\n",
    "$$\n",
    "\\bar{M} = \\begin{pmatrix}\n",
    "\\vec{a}_1^T \\\\\n",
    "\\vec{a}_2^T \\\\\n",
    "\\vdots \\\\\n",
    "\\vec{a}_{2k-1}^T \\\\\n",
    "\\vec{a}_{2k}^T\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "\\vec{a}_{2N-1}^T \\\\\n",
    "\\vec{a}_{2N}^T\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Then, we can easily compute our similarity scores:\n",
    "$$\n",
    "M^* = \\bar{M}\\bar{M}^T \n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\vec{a}_1^T\\vec{a}_1 & \\vec{a}_1^T\\vec{a}_2 & \\ldots & \\vec{a}_1^T\\vec{a}_{2k} & \\ldots & \\vec{a}_1^T\\vec{a}_{2N} \\\\\n",
    "\\vec{a}_2^T\\vec{a}_1 & \\vec{a}_2^T\\vec{a}_2 & \\ldots & \\vec{a}_2^T\\vec{a}_{2k} & \\ldots & \\vec{a}_2^T\\vec{a}_{2N} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\vec{a}_{2N}^T\\vec{a}_1 & \\vec{a}_{2N}^T\\vec{a}_2 & \\ldots & \\vec{a}_{2N}^T\\vec{a}_{2k} & \\ldots & \\vec{a}_{2N}^T\\vec{a}_{2N} \\\\\n",
    "\\end{pmatrix} \\in \\mathbb{R}^{2N \\times 2N}\n",
    "$$\n",
    "such that:\n",
    "$$\n",
    "sim(\\vec{z}_i, \\vec{z}_j) = (M^*)_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766fc2f-f191-432e-b40f-411522d2be88",
   "metadata": {},
   "source": [
    "Now, we recall crossentropy loss for categories. Say we have a vector:\n",
    "$$\n",
    "\\vec{x}_n = \\begin{pmatrix}\n",
    "x_n^1 \\\\\n",
    "x_n^2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n^{D}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "and a total of $C$ categories (indexed $[0,C)$).\n",
    "\n",
    "We can define the cross-entropy loss of $\\vec{x}_n$ (assuming it is expected to belong to class $p \\in [0,C)$) by:\n",
    "$$\n",
    "\\ell_n = -\\log \\frac{\\exp(x_n^p)}{\\sum_{c = 1}^C \\exp(x_n^c)}\n",
    "$$\n",
    "and for **all** the training samples (say we have $N$ many) we will have:\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{n = 1}^N \\ell_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec35f33-975a-42cf-a3f0-2ff306c1f2b2",
   "metadata": {},
   "source": [
    "The above is the PyTorch formulation, whereby we need to provide:\n",
    "- a matrix of samples $M$\n",
    "- a vector of labels $L$ (such that if $\\vec{x}_n$ is in class $p$, then $L[n] = p$)\n",
    "Hence, to compute NT-XENT efficinetly, we can use PyTorch's `CrossEntropyLoss` directly, after slightly tweking our matrix $M^*$.\n",
    "\n",
    "Let do a final transformation to $M^*$, by replacing its diagonal by -1000:\n",
    "\n",
    "$$\n",
    "M' = \n",
    "\\begin{pmatrix}\n",
    "-1000 & \\vec{a}_1^T\\vec{a}_2 & \\ldots & \\vec{a}_1^T\\vec{a}_{2k} & \\ldots & \\vec{a}_1^T\\vec{a}_{2N} \\\\\n",
    "\\vec{a}_2^T\\vec{a}_1 & -1000 & \\ldots & \\vec{a}_2^T\\vec{a}_{2k} & \\ldots & \\vec{a}_2^T\\vec{a}_{2N} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\vec{a}_{2N}^T\\vec{a}_1 & \\vec{a}_{2N}^T\\vec{a}_2 & \\ldots & \\vec{a}_{2N}^T\\vec{a}_{2k} & \\ldots & -1000 \\\\\n",
    "\\end{pmatrix} \\in \\mathbb{R}^{2N \\times 2N}\n",
    "$$\n",
    "\n",
    "$\\ell(i,j)$ then corresponds to feeding $(M')_{i,-}$ to `CrossEntropyLoss` alongside the label $L[i] = j$. By replacing the diagonal with -1000, we ensure that $exp(\\vec{a}_i^T\\vec{a}_i) \\approx 0$, so it won't count towards the denominator of the cross-entropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f4d6bf-42db-4815-bac0-034aa00cc002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8., 7., 5.],\n",
      "        [3., 0., 3.],\n",
      "        [7., 7., 9.]])\n",
      "tensor([[0.6810, 0.5959, 0.4256],\n",
      "        [0.7071, 0.0000, 0.7071],\n",
      "        [0.5232, 0.5232, 0.6727]])\n",
      "tensor([[1.0000, 0.7825, 0.9544],\n",
      "        [0.7825, 1.0000, 0.8456],\n",
      "        [0.9544, 0.8456, 1.0000]])\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(0,10,(3,3)).float()\n",
    "print(a)\n",
    "#b = a / nn.functional.normalize(a, axis = 1)\n",
    "#a.T @ a\n",
    "b = nn.functional.normalize(a, dim = 1)\n",
    "print(b)\n",
    "c = b @ b.T\n",
    "print(c)\n",
    "\n",
    "for i in range(3):\n",
    "    print(torch.norm(b[i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31ef1166-a5de-487d-a327-584ddccc51aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    4.,     0.,     9.,     2., -1000.],\n",
       "        [    9.,     3.,     3.,     7., -1000.],\n",
       "        [    4.,     2.,     8.,     2., -1000.],\n",
       "        [    3.,     8.,     1.,     4., -1000.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(0,10,(4,4))\n",
    "b = -1000*torch.ones(4,1)\n",
    "torch.cat((a,b), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cde02633-5fbd-4139-9069-f87806f53c40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contrastive_loss_2(z_batch, tau):\n",
    "    N = len(z_batch)\n",
    "    \n",
    "    # normalise to have unit length rows\n",
    "    norm_z_batch = F.normalize(z_batch)\n",
    "    \n",
    "    # compute similarity & apply factor of tau\n",
    "    sim_batch = (norm_z_batch @ norm_z_batch.T)/tau\n",
    "    \n",
    "    # remove diagonal\n",
    "    sim_batch = sim_batch.flatten()[1:].view(N-1, N+1)[:,:-1].reshape(N, N-1)\n",
    "    sim_batch = torch.cat((sim_batch, -1000*torch.ones(N,1)), dim = 1)\n",
    "    print(sim_batch)\n",
    "    \n",
    "    # generate labels\n",
    "    # here we assume that z_batch[2k-1] and z_batch[2k] are a positive pair of samples\n",
    "    labels = torch.Tensor([k if k%2 == 0 else k-1 for k in range(0,N)]).long()\n",
    "    print(labels)\n",
    "    \n",
    "    # return the NT-XENT loss\n",
    "    return 1/N * F.cross_entropy(sim_batch, labels, reduction = \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de6e76f5-a48f-4415-b85e-4d89ec535d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(z_batch, tau):\n",
    "    N = len(z_batch)\n",
    "    \n",
    "    # normalise to have unit length rows\n",
    "    norm_z_batch = F.normalize(z_batch)\n",
    "    \n",
    "    # compute similarity & apply factor of tau\n",
    "    sim_batch = (norm_z_batch @ norm_z_batch.T)/tau\n",
    "    \n",
    "    # fill the diagonal with -1000, to make sure it is never considered in the cross entropy computations\n",
    "    sim_batch.fill_diagonal_(-1000)\n",
    "    \n",
    "    # generate labels\n",
    "    # here we assume that z_batch[2k-1] and z_batch[2k] are a positive pair of samples\n",
    "    labels = torch.Tensor([k+1 if k%2 == 0 else k-1 for k in range(0,N)]).long()\n",
    "    \n",
    "    # return the NT-XENT loss\n",
    "    return 1/N * F.cross_entropy(sim_batch, labels, reduction = \"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8adc81de-2ea6-404f-a715-d5160c251b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  6., -10.,   9.,   0.,   6.],\n",
      "        [ -4.,  -9.,   4.,   3.,   3.],\n",
      "        [  3.,  -1.,  -2., -10.,  -4.],\n",
      "        [ -6.,  -8.,  -7.,   3.,   1.],\n",
      "        [  2.,   0.,   5.,  -4.,   0.],\n",
      "        [  3.,  -6.,  -5.,  -7.,  -4.]])\n",
      "tensor([[ 6.5915e-01, -7.7196e-02, -6.4816e-02,  5.3421e-01,  4.8698e-02,\n",
      "         -1.0000e+03],\n",
      "        [ 6.5915e-01, -4.0613e-01,  5.5431e-01,  0.0000e+00, -8.2716e-02,\n",
      "         -1.0000e+03],\n",
      "        [-7.7196e-02, -4.0613e-01, -2.0867e-01,  4.7068e-01,  8.3789e-01,\n",
      "         -1.0000e+03],\n",
      "        [-6.4816e-02,  5.5431e-01, -2.0867e-01, -6.9750e-01,  2.7302e-01,\n",
      "         -1.0000e+03],\n",
      "        [ 5.3421e-01,  0.0000e+00,  4.7068e-01, -6.9750e-01,  1.1547e-01,\n",
      "         -1.0000e+03],\n",
      "        [ 4.8698e-02, -8.2716e-02,  8.3789e-01,  2.7302e-01,  1.1547e-01,\n",
      "         -1.0000e+03]])\n",
      "tensor([1, 0, 3, 2, 5, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(168.3250)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_batch = torch.randint(-10,10,(6,5)).float()\n",
    "print(rand_batch)\n",
    "contrastive_loss(rand_batch, tau = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6134b24-4ad7-4643-a999-85af7fd2e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000e+03,  6.5915e-01, -7.7196e-02, -6.4816e-02,  5.3421e-01,\n",
      "          4.8698e-02],\n",
      "        [ 6.5915e-01, -1.0000e+03, -4.0613e-01,  5.5431e-01,  0.0000e+00,\n",
      "         -8.2716e-02],\n",
      "        [-7.7196e-02, -4.0613e-01, -1.0000e+03, -2.0867e-01,  4.7068e-01,\n",
      "          8.3789e-01],\n",
      "        [-6.4816e-02,  5.5431e-01, -2.0867e-01, -1.0000e+03, -6.9750e-01,\n",
      "          2.7302e-01],\n",
      "        [ 5.3421e-01,  0.0000e+00,  4.7068e-01, -6.9750e-01, -1.0000e+03,\n",
      "          1.1547e-01],\n",
      "        [ 4.8698e-02, -8.2716e-02,  8.3789e-01,  2.7302e-01,  1.1547e-01,\n",
      "         -1.0000e+03]])\n",
      "tensor([1, 0, 3, 2, 5, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.6296)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_loss(rand_batch, tau = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15254d57-edd2-4dea-8020-f315dca1373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.5915e-01, -7.7196e-02, -6.4816e-02,  5.3421e-01,  4.8698e-02,\n",
      "         -1.0000e+03],\n",
      "        [ 6.5915e-01, -4.0613e-01,  5.5431e-01,  0.0000e+00, -8.2716e-02,\n",
      "         -1.0000e+03],\n",
      "        [-7.7196e-02, -4.0613e-01, -2.0867e-01,  4.7068e-01,  8.3789e-01,\n",
      "         -1.0000e+03],\n",
      "        [-6.4816e-02,  5.5431e-01, -2.0867e-01, -6.9750e-01,  2.7302e-01,\n",
      "         -1.0000e+03],\n",
      "        [ 5.3421e-01,  0.0000e+00,  4.7068e-01, -6.9750e-01,  1.1547e-01,\n",
      "         -1.0000e+03],\n",
      "        [ 4.8698e-02, -8.2716e-02,  8.3789e-01,  2.7302e-01,  1.1547e-01,\n",
      "         -1.0000e+03]])\n",
      "tensor([0, 0, 2, 2, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.6296)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_loss_2(rand_batch, tau = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "01179e31-8608-4729-94c8-a32108f0bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0177)\n",
      "tensor(2.0729)\n",
      "tensor(2.7130)\n"
     ]
    }
   ],
   "source": [
    "test_vec = torch.Tensor([\n",
    "[1.1, 1.1, 1.1],\n",
    "[1.1, 1.1, 1.1],\n",
    "[-0.3, 0.2, -0.6],\n",
    "[-0.3, 0.2, -0.6],\n",
    "[22, 23, 24],\n",
    "[22, 23, 24]\n",
    "])\n",
    "\n",
    "test_vec_2 = torch.Tensor([\n",
    "[1.1, 1.1, 1.1],\n",
    "[-0.3, 0.2, -0.6],\n",
    "[22, 23, 24],\n",
    "[1.1, 1.1, 1.1],\n",
    "[-0.3, 0.2, -0.6],\n",
    "[22, 23, 24]\n",
    "])\n",
    "\n",
    "test_vec_3 = torch.Tensor([\n",
    "[1.1, 1.1, 1.1],\n",
    "[-1.1, -1.1, -1.1],\n",
    "[-0.3, 0.2, -0.6],\n",
    "[0.3, -0.2, 0.6],\n",
    "[-22, -23, -24],\n",
    "[22, 23, 24]\n",
    "])\n",
    "\n",
    "print(contrastive_loss(test_vec, tau = 1))\n",
    "print(contrastive_loss(test_vec_2, tau = 1))\n",
    "print(contrastive_loss(test_vec_3, tau = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "02c1001a-8e4c-4cd3-a989-88423ecdc4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(67.1667)\n"
     ]
    }
   ],
   "source": [
    "projs = rand_batch\n",
    "b = projs.shape[0]//2\n",
    "n = b * 2\n",
    "\n",
    "logits = projs @ projs.t()\n",
    "\n",
    "mask = torch.eye(n).bool()\n",
    "logits = logits[~mask].reshape(n, n - 1)\n",
    "\n",
    "labels = torch.cat(((torch.arange(b) + b - 1), torch.arange(b)), dim=0)\n",
    "\n",
    "loss = nn.functional.cross_entropy(logits, labels, reduction='sum')\n",
    "print(loss/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1708c8f-9979-43d5-837e-552defb6e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4, 0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b452f35a-44d2-4d0c-9f85-2addb324aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapCLNN(nn.Module):\n",
    "    def __init__(self, positive_samples):\n",
    "        super(MapCLNN, self).__init__()\n",
    "        \n",
    "        self.MAX_PIXEL_VALUE = 255\n",
    "        self.RESNET_DIM = 224\n",
    "        \n",
    "        self.resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # dictionary containing patch alignments\n",
    "        # key is a tuple, representing the patch coordinates of the patch\n",
    "        # value is a list, containing MapPatch instances\n",
    "        # MapPatch instances with the same key can be thought of as positive samples for the algorithm\n",
    "        self.positive_samples = positive_samples\n",
    "    \n",
    "    def img_to_resnet(self, img, dim = 224):\n",
    "        \"\"\"\n",
    "        Convert image into the desired format for ResNet.\n",
    "        The image must have width and height of at least self.RESNET_DIM, with RGB values between 0 and 1.\n",
    "        Moreover, it must be normalised, by using a mean of [0.485, 0.456, 0.406] and a standard deviation of [0.229, 0.224, 0.225]\n",
    "        --------------------------------------------------------------------------------------------------------------------------------\n",
    "        :param img: a numpy nd.array, with 3 colour channels (this must be stored in the last dimensions), which has to be fed to ResNet\n",
    "        :param dim: the desired dimension of the image (if we want to resize img before feeding it to ResNet).\n",
    "                    This should be at least self.RESTNET_DIM.\n",
    "        --------------------------------------------------------------------------------------------------------------------------------\n",
    "        :return a Tensor, with the first dimension corresponding to the RGB channels, and normalised to be used by ResNet.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert dim >= self.RESNET_DIM, f\"Provided dimension {dim} is less than the required for RESNET ({self.RESNET_DIM})\"\n",
    "        \n",
    "        # put the colour channel in front\n",
    "        norm_img = np.moveaxis(img, -1, 0)\n",
    "        \n",
    "        # normalise into range [0,1]\n",
    "        norm_img = torch.from_numpy(norm_img)/255\n",
    "        \n",
    "        # resize\n",
    "        if img.shape[0] < self.RESNET_DIM or img.shape[1] < self.RESNET_DIM:\n",
    "            norm_img = T.Resize(self.RESNET_DIM)(norm_img)\n",
    "        else:\n",
    "            if dim is not None:\n",
    "                norm_img = T.Resize(dim)(norm_img)     \n",
    "        \n",
    "        # normalise mean and variance\n",
    "        mean = torch.Tensor([0.485, 0.456, 0.406])\n",
    "        std = torch.Tensor([0.229, 0.224, 0.225])\n",
    "        \n",
    "        return T.Normalize(mean = mean, std = std)(norm_img)\n",
    "    \n",
    "    def sim(self, z_i, z_j):\n",
    "        \"\"\"\n",
    "        Computes cosine similarity between 2 vectors z_i, z_j.\n",
    "        \"\"\"\n",
    "        return torch.dot(z_i,z_j)/(torch.linalg.norm(z_i) * torch.linalg.norm(z_j))\n",
    "    \n",
    "    def exp_sim(self, z_i, z_j, tau):\n",
    "        \"\"\"\n",
    "        Computes a temperature-scaled, exponential similarity between 2 vectors z_i, z_j\n",
    "        \"\"\"\n",
    "        return torch.exp(self.sim(z_i, z_j)/tau)\n",
    "    \n",
    "    def sample_contrastive_loss(self, z_i, z_j, z_batch, tau):\n",
    "        \"\"\"\n",
    "        Computes the contrastive loss for a pair of positive samples z_i, z_j i.\n",
    "        -----------------------------------------------------------------------------\n",
    "        :param z_i,z_j: 1D Tensors; these are positive samples whose loss we compute.\n",
    "        :param z_batch: a 2D Tensor, giving the batch over which we compute the loss. \n",
    "                        Contains the negative samples for z_i,z_j.\n",
    "        :param tau: a float, the \"temperature\"\n",
    "        \"\"\"\n",
    "        similarity = self.exp_sim(z_i, z_j, tau)\n",
    "        all_dissimilarities = [self.exp_sim(z_i, z_k, tau) for z_k in z_batch if not torch.equal(z_i,z_k)]\n",
    "        dissimilarity = torch.sum(torch.Tensor(all_dissimilarities))\n",
    "        \n",
    "        return -torch.log(similarity/dissimilarity)\n",
    "    \n",
    "    def contrastive_loss(self, z_batch, tau):\n",
    "        N = len(z_batch)\n",
    "        all_losses = [self.sample_contrastive_loss(z_batch[2*k], z_batch[2*k+1], z_batch, tau) +\n",
    "                      self.sample_contrastive_loss(z_batch[2*k+1], z_batch[2*k], z_batch, tau)\n",
    "                      for k in range(1,N//2)]\n",
    "        \n",
    "        return 1/N * torch.sum(torch.Tensor(all_losses))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        pass\n",
    "    \n",
    "    def compile_model(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ce0c4c6-4ba3-4c22-835f-c448eeb01ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0475)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mclnn = MapCLNN(\"a\")\n",
    "mclnn.contrastive_loss(logits, tau = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d0207-b2b7-48bc-8db2-cef6bdba9ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henv",
   "language": "python",
   "name": "henv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
