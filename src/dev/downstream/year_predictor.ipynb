{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46056b3a-1242-4c42-97c9-1b99b58a4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../py/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92b16861-d8ae-4e16-95db-4ab9c9216afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pickle as pk\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-4s %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    datefmt='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4540890-46e8-4935-8f1f-876d004ac283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearPredictorDataset(Dataset):\n",
    "    def __init__(self, patch_dataset, meta_df):\n",
    "        embeddings, labels, map_name_to_class, patch_data_idx_to_emb_idx = YearPredictorDataset.init_from_patch_dataset(patch_dataset, meta_df)\n",
    "        \n",
    "        self.patch_dataset = patch_dataset\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "        self.patch_data_idx_to_emb_idx = patch_data_idx_to_emb_idx\n",
    "        self.map_name_to_class = map_name_to_class\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(embeddings)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        if isinstance(i, slice):\n",
    "            start = i.start if i.start else 0\n",
    "            stop = i.stop if i.stop else len(self.X_1)\n",
    "            step = i.step if i.step else 1\n",
    "\n",
    "            return [(self.embeddings[j], self.labels[j]) for j in range(start, stop, step)]\n",
    "\n",
    "        return (self.embeddings[i], self.labels[i])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_map_name(patch):\n",
    "        origin_map = patch.origin_map\n",
    "        end_idx = origin_map.index(\".\")\n",
    "        start_idx = len(origin_map) - origin_map[::-1].index(\"/\")\n",
    "        \n",
    "        return patch.origin_map[start_idx : end_idx]\n",
    "    \n",
    "    @staticmethod\n",
    "    def assign_class(year):\n",
    "        if year < 1900:\n",
    "            return 0\n",
    "        elif year < 1910:\n",
    "            return 1\n",
    "        elif year < 1930:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_from_patch_dataset(patch_dataset, meta_df):\n",
    "        patch_data_idx_to_emb_idx = {}\n",
    "        embeddings = []\n",
    "        \n",
    "        emb_idx = 0\n",
    "        Xs = [patch_dataset.X_1, patch_dataset.X_2]\n",
    "        labels = []\n",
    "        map_name_to_class = {}\n",
    "        \n",
    "        for i in range(len(patch_dataset)):\n",
    "            for j in range(2):\n",
    "                patch = Xs[j][i]\n",
    "                map_name = int(YearPredictorDataset.get_map_name(patch))\n",
    "                \n",
    "                if map_name in map_name_to_class:\n",
    "                    year_class = map_name_to_class[map_name]\n",
    "                else:\n",
    "                    year = meta_df[meta_df[\"IMAGE\"] == map_name].iloc[0][\"YEAR\"]\n",
    "                    year_class = YearPredictorDataset.assign_class(year)\n",
    "                    map_name_to_class[map_name] = year_class\n",
    "                    \n",
    "                embeddings.append(patch.patch_shift)\n",
    "                labels.append(year_class)\n",
    "                patch_data_idx_to_emb_idx[emb_idx] = (i,j)\n",
    "                emb_idx += 1\n",
    "        \n",
    "        return embeddings, labels, map_name_to_class, patch_data_idx_to_emb_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f4a512-53a1-4e30-b298-d4c139fc8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../py/output/patch_train_dataset_128.pk\", \"rb\") as f:\n",
    "    train_data = pk.load(f)\n",
    "    \n",
    "with open(\"../../py/output/patch_val_dataset_128.pk\", \"rb\") as f:\n",
    "    val_data = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc3a4683-5810-4ef3-9e2f-b8063ac30cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../../../os_meta.csv\")\n",
    "meta = metadata[[\"PUB_SORT\", \"IMAGE\"]].rename(columns = {\"PUB_SORT\" : \"YEAR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf9e289a-80e2-4033-bbe5-163b17c60edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>IMAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1894</td>\n",
       "      <td>82877892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1894</td>\n",
       "      <td>82877928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1894</td>\n",
       "      <td>82877940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1894</td>\n",
       "      <td>82877949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1894</td>\n",
       "      <td>82877958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR     IMAGE\n",
       "0  1894  82877892\n",
       "1  1894  82877928\n",
       "2  1894  82877940\n",
       "3  1894  82877949\n",
       "4  1894  82877958"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d6fab88-1ca1-4d0f-829b-2221b988d593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MAP COUNT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5685</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5721</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3827</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5814</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       YEAR  MAP COUNT\n",
       "CLASS                 \n",
       "0      5685         57\n",
       "1      5721         57\n",
       "2      3827         57\n",
       "3      5814         41"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_counts = meta.groupby(\"YEAR\").count().reset_index().rename(columns = {\"IMAGE\" : \"MAP COUNT\"})\n",
    "year_counts[\"CLASS\"] = year_counts[\"YEAR\"].apply(lambda year : assign_class(year))\n",
    "year_counts.groupby(\"CLASS\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0638ce6-dee0-4554-a746-44cc3bf7b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_train = YearPredictorDataset(patch_dataset = train_data, meta_df = meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "943aa34b-2462-48f5-affb-bbfba9031a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearPredictorClassifier(nn.Module):\n",
    "    def __init__(self, first_hidden_parameters, second_hidden_parameters, output_parameters):\n",
    "        super(YearPredictorClassifier, self).__init__()\n",
    "        \n",
    "        self.hidden_mlp_1 = MLP(**first_hidden_parameterst_hidden_parameters)\n",
    "        self.hidden_mlp_2 = MLP(**second_hidden_parameters)\n",
    "        self.output_mlp = MLP(**output_parameters)\n",
    "    \n",
    "        self.classifier = nn.Sequential(self.hidden_mlp_1, self.hidden_mlp_2, self.output_mlp)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimiser = None\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.checkpoint = {\"epoch\": 0,\n",
    "                           \"batch\": 0,\n",
    "                           \"model_state_dict\": self.state_dict(),\n",
    "                           \"optimiser_state_dict\": None,\n",
    "                           \"loss\": 0,\n",
    "                           \"avg_batch_losses_20\": [],\n",
    "                           \"batch_losses\": [],\n",
    "                           \"validation_losses \": [],\n",
    "                           \"run_start\": datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "                           \"run_end\": None,\n",
    "                           \"model_kwargs\": self.kwargs}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y = self.classifier(x)\n",
    "        \n",
    "        return np.argmax(y)\n",
    "    \n",
    "    def compile_optimiser(self, **kwargs):\n",
    "        self.optimiser = optim.Adam(self.parameters(), **kwargs) \n",
    "        \n",
    "    def get_loss(self, y_true, y_pred):\n",
    "        return self.criterion(y_true, y_pred)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, evaluation_loader, validation = True):\n",
    "\n",
    "        eval_losses = []\n",
    "\n",
    "        self.eval()\n",
    "\n",
    "        for embeddings, y_true in validation_loader:\n",
    "            embeddings, y_true = embeddings.to(self.device), y_true.to(self.device)\n",
    "            y_pred = self.classifier(embeddings)\n",
    "            val_losses.append(self.get_loss(y_true = y_true, y_pred = y_pred).cpu())\n",
    "\n",
    "        if validation:\n",
    "            self.train()\n",
    "            return np.mean(val_losses)\n",
    "\n",
    "        return val_losses\n",
    "    \n",
    "    def update_checkpoint(self, checkpoint_dir, batch_losses, validation_losses, **checkpoint_data):\n",
    "\n",
    "        for k, v in checkpoint_data.items():\n",
    "            if k in self.checkpoint:\n",
    "                self.checkpoint[k] = v\n",
    "\n",
    "        if checkpoint_dir is not None:\n",
    "\n",
    "            if not os.path.isdir(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "\n",
    "            model_params_dir = os.path.join(checkpoint_dir, \"year_classifier_checkpoint.pt\")\n",
    "            torch.save(self.checkpoint, model_params_dir)\n",
    "\n",
    "            batch_loss_train_dir = os.path.join(checkpoint_dir,\n",
    "                                                f\"batch_loss_logs_t{checkpoint_data.get('epoch', 0)}.pk\")\n",
    "            with open(batch_loss_train_dir, \"wb\") as f:\n",
    "                pk.dump(batch_losses, f)\n",
    "\n",
    "            batch_loss_validation_dir = os.path.join(checkpoint_dir,\n",
    "                                                     f\"batch_loss_logs_v{checkpoint_data.get('epoch', 0)}.pk\")\n",
    "            with open(batch_loss_validation_dir, \"wb\") as f:\n",
    "                pk.dump(validation_losses, f)\n",
    "    \n",
    "    def train_model(self, train_loader, validation_loader, epochs, checkpoint_dir=None, batch_log_rate=100):\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            batch_losses = []\n",
    "            validation_losses = []\n",
    "            avg_batch_losses_20 = []\n",
    "\n",
    "            logging.info(f\"Starting Epoch: {epoch + 1}\")\n",
    "\n",
    "            for batch, (embeddings, y_true) in enumerate(train_loader):\n",
    "\n",
    "                self.optimiser.zero_grad()\n",
    "\n",
    "                embeddings, y_true = embeddings.to(self.device), y_true.to(self.device)\n",
    "                y_pred = self.classifier(embeddings)\n",
    "\n",
    "                loss = self.get_loss(y_true = y_true, y_pred = y_pred)\n",
    "\n",
    "                batch_losses.append(loss.cpu().detach())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimiser.step()\n",
    "\n",
    "                if batch % (len(train_loader) // batch_log_rate + 1) == 0 and batch != 0:\n",
    "                    with torch.no_grad():\n",
    "                        avg_loss = np.mean(batch_losses[-20:])\n",
    "                        avg_batch_losses_20.append(avg_loss)\n",
    "                        logging.info(\n",
    "                            f\"Epoch {epoch + 1}: [{batch + 1}/{len(train_loader)}] ---- CrossEntropy Training Loss = {avg_loss}\")\n",
    "\n",
    "                        if batch % (len(train_loader) // (batch_log_rate//4) + 1) == 0:\n",
    "                            validation_loss = self.get_validation_loss(validation_loader)\n",
    "                            validation_losses.append(validation_loss)\n",
    "                            logging.info(\n",
    "                                f\"Epoch {epoch + 1}: [{batch + 1}/{len(train_loader)}] ---- CrossEntropy Validation Loss = {validation_loss}\")\n",
    "\n",
    "                        self.update_checkpoint(checkpoint_dir=checkpoint_dir,\n",
    "                                               batch_losses=batch_losses,\n",
    "                                               validation_losses=validation_losses,\n",
    "                                               epoch=epoch,\n",
    "                                               batch=batch,\n",
    "                                               model_state_dict=self.state_dict(),\n",
    "                                               optimiser_state_dict=self.optimiser.state_dict,\n",
    "                                               loss=loss.cpu().detach(),\n",
    "                                               avg_batch_losses_20=avg_batch_losses_20,\n",
    "                                               run_end=datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.update_checkpoint(checkpoint_dir=checkpoint_dir,\n",
    "                                       batch_losses=batch_losses,\n",
    "                                       validation_losses=validation_losses,\n",
    "                                       epoch=epochs,\n",
    "                                       batch=len(train_loader),\n",
    "                                       model_state_dict=self.state_dict(),\n",
    "                                       optimiser_state_dict=self.optimiser.state_dict,\n",
    "                                       loss=loss.cpu().detach(),\n",
    "                                       avg_batch_losses_20=avg_batch_losses_20,\n",
    "                                       run_end=datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "\n",
    "        return self.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd36d4-eabe-4fab-844a-c74aa97f11fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henv",
   "language": "python",
   "name": "henv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
