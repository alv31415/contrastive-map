29-01-2023 22:37:48 INFO Running main & importing modules...
29-01-2023 22:38:00 INFO Parsed arguments: Namespace(batch_size=32, byol_ema_tau=0.9, debug=False, encoder='resnet18', encoder_layer_idx=-2, epochs=5, experiment_name='b-presnet18-e5-b32-t0_9-p64', input='/disk/scratch_big/s1908368/data', log_interval=1000, lr=0.001, output='/disk/scratch_big/s1908368/output', patch_size=64, pretrain_encoder=True, seed=23, simclr_tau=0.99, train_proportion=0.98, use_byol=True)
29-01-2023 22:38:00 INFO File at /disk/scratch_big/s1908368/data/patch_train_dataset_64.pk: True
29-01-2023 22:38:00 INFO File at /disk/scratch_big/s1908368/data/patch_val_dataset_64.pk: True
29-01-2023 22:38:08 INFO Generated training dataset with 350062 samples.
29-01-2023 22:38:08 INFO Generated validation dataset with 7145 samples.
29-01-2023 22:38:08 INFO Using encoder resnet18 with pretrained weights = True
29-01-2023 22:38:08 INFO Using BYOL with tau = 0.9, with encoder layer index = -2
29-01-2023 22:38:08 INFO Using device: cuda
29-01-2023 22:38:12 INFO Starting Epoch: 1
29-01-2023 22:38:30 INFO Epoch 1: [12/10940] ---- BYOL Training Loss = 2.168836832046509
29-01-2023 22:38:47 INFO Epoch 1: [23/10940] ---- BYOL Training Loss = 1.7204887866973877
29-01-2023 22:39:05 INFO Epoch 1: [34/10940] ---- BYOL Training Loss = 1.3589410781860352
29-01-2023 22:39:22 INFO Epoch 1: [45/10940] ---- BYOL Training Loss = 1.11905038356781
29-01-2023 22:40:14 INFO Epoch 1: [45/10940] ---- BYOL Validation Loss = 0.9393230080604553
29-01-2023 22:40:31 INFO Epoch 1: [56/10940] ---- BYOL Training Loss = 0.9070054888725281
29-01-2023 22:40:49 INFO Epoch 1: [67/10940] ---- BYOL Training Loss = 0.8293125033378601
29-01-2023 22:41:06 INFO Epoch 1: [78/10940] ---- BYOL Training Loss = 0.7819827198982239
29-01-2023 22:41:24 INFO Epoch 1: [89/10940] ---- BYOL Training Loss = 0.6838514804840088
29-01-2023 22:42:16 INFO Epoch 1: [89/10940] ---- BYOL Validation Loss = 0.6081151366233826
29-01-2023 22:42:33 INFO Epoch 1: [100/10940] ---- BYOL Training Loss = 0.6429718732833862
29-01-2023 22:42:51 INFO Epoch 1: [111/10940] ---- BYOL Training Loss = 0.6425257921218872
29-01-2023 22:43:08 INFO Epoch 1: [122/10940] ---- BYOL Training Loss = 0.5757283568382263
29-01-2023 22:43:26 INFO Epoch 1: [133/10940] ---- BYOL Training Loss = 0.5613656640052795
29-01-2023 22:44:18 INFO Epoch 1: [133/10940] ---- BYOL Validation Loss = 0.6000034213066101
29-01-2023 22:44:35 INFO Epoch 1: [144/10940] ---- BYOL Training Loss = 0.5600439310073853
29-01-2023 22:44:53 INFO Epoch 1: [155/10940] ---- BYOL Training Loss = 0.5497016310691833
29-01-2023 22:45:10 INFO Epoch 1: [166/10940] ---- BYOL Training Loss = 0.5299152731895447
29-01-2023 22:45:28 INFO Epoch 1: [177/10940] ---- BYOL Training Loss = 0.5875461101531982
29-01-2023 22:46:20 INFO Epoch 1: [177/10940] ---- BYOL Validation Loss = 0.4760030210018158
29-01-2023 22:46:37 INFO Epoch 1: [188/10940] ---- BYOL Training Loss = 0.573175311088562
29-01-2023 22:46:55 INFO Epoch 1: [199/10940] ---- BYOL Training Loss = 0.5548473596572876
29-01-2023 22:47:12 INFO Epoch 1: [210/10940] ---- BYOL Training Loss = 0.4731926918029785
29-01-2023 22:47:30 INFO Epoch 1: [221/10940] ---- BYOL Training Loss = 0.41561904549598694
29-01-2023 22:48:22 INFO Epoch 1: [221/10940] ---- BYOL Validation Loss = 0.43321889638900757
29-01-2023 22:48:40 INFO Epoch 1: [232/10940] ---- BYOL Training Loss = 0.5070136189460754
29-01-2023 22:48:57 INFO Epoch 1: [243/10940] ---- BYOL Training Loss = 0.46874895691871643
29-01-2023 22:49:15 INFO Epoch 1: [254/10940] ---- BYOL Training Loss = 0.44141116738319397
29-01-2023 22:49:32 INFO Epoch 1: [265/10940] ---- BYOL Training Loss = 0.4869503974914551
29-01-2023 22:50:25 INFO Epoch 1: [265/10940] ---- BYOL Validation Loss = 0.43504753708839417
29-01-2023 22:50:42 INFO Epoch 1: [276/10940] ---- BYOL Training Loss = 0.48920971155166626
29-01-2023 22:50:59 INFO Epoch 1: [287/10940] ---- BYOL Training Loss = 0.4315428137779236
29-01-2023 22:51:17 INFO Epoch 1: [298/10940] ---- BYOL Training Loss = 0.42026957869529724
29-01-2023 22:51:34 INFO Epoch 1: [309/10940] ---- BYOL Training Loss = 0.4496626853942871
29-01-2023 22:52:27 INFO Epoch 1: [309/10940] ---- BYOL Validation Loss = 0.4136756360530853
29-01-2023 22:52:44 INFO Epoch 1: [320/10940] ---- BYOL Training Loss = 0.4488673210144043
29-01-2023 22:53:02 INFO Epoch 1: [331/10940] ---- BYOL Training Loss = 0.4714016318321228
29-01-2023 22:53:19 INFO Epoch 1: [342/10940] ---- BYOL Training Loss = 0.5359693169593811
29-01-2023 22:53:37 INFO Epoch 1: [353/10940] ---- BYOL Training Loss = 0.5171245336532593
29-01-2023 22:54:29 INFO Epoch 1: [353/10940] ---- BYOL Validation Loss = 0.43604931235313416
29-01-2023 22:54:46 INFO Epoch 1: [364/10940] ---- BYOL Training Loss = 0.5220046639442444
29-01-2023 22:55:04 INFO Epoch 1: [375/10940] ---- BYOL Training Loss = 0.4835934638977051
29-01-2023 22:55:22 INFO Epoch 1: [386/10940] ---- BYOL Training Loss = 0.48248037695884705
29-01-2023 22:55:39 INFO Epoch 1: [397/10940] ---- BYOL Training Loss = 0.4696526527404785
29-01-2023 22:56:32 INFO Epoch 1: [397/10940] ---- BYOL Validation Loss = 0.40285032987594604
29-01-2023 22:56:49 INFO Epoch 1: [408/10940] ---- BYOL Training Loss = 0.4292387366294861
29-01-2023 22:57:06 INFO Epoch 1: [419/10940] ---- BYOL Training Loss = 0.4521045684814453
29-01-2023 22:57:24 INFO Epoch 1: [430/10940] ---- BYOL Training Loss = 0.4395987093448639
29-01-2023 22:57:41 INFO Epoch 1: [441/10940] ---- BYOL Training Loss = 0.3643115162849426
29-01-2023 22:58:34 INFO Epoch 1: [441/10940] ---- BYOL Validation Loss = 0.40297624468803406
29-01-2023 22:58:51 INFO Epoch 1: [452/10940] ---- BYOL Training Loss = 0.4109838604927063
29-01-2023 22:59:09 INFO Epoch 1: [463/10940] ---- BYOL Training Loss = 0.45663270354270935
29-01-2023 22:59:26 INFO Epoch 1: [474/10940] ---- BYOL Training Loss = 0.4552517533302307
29-01-2023 22:59:44 INFO Epoch 1: [485/10940] ---- BYOL Training Loss = 0.3736424744129181
29-01-2023 23:00:36 INFO Epoch 1: [485/10940] ---- BYOL Validation Loss = 0.4050128161907196
29-01-2023 23:00:53 INFO Epoch 1: [496/10940] ---- BYOL Training Loss = 0.37322232127189636
29-01-2023 23:01:11 INFO Epoch 1: [507/10940] ---- BYOL Training Loss = 0.45413509011268616
29-01-2023 23:01:28 INFO Epoch 1: [518/10940] ---- BYOL Training Loss = 0.4227500855922699
29-01-2023 23:01:46 INFO Epoch 1: [529/10940] ---- BYOL Training Loss = 0.4095185399055481
29-01-2023 23:02:38 INFO Epoch 1: [529/10940] ---- BYOL Validation Loss = 0.416981041431427
29-01-2023 23:02:55 INFO Epoch 1: [540/10940] ---- BYOL Training Loss = 0.4318154454231262
29-01-2023 23:03:13 INFO Epoch 1: [551/10940] ---- BYOL Training Loss = 0.43715015053749084
29-01-2023 23:03:31 INFO Epoch 1: [562/10940] ---- BYOL Training Loss = 0.4017893373966217
29-01-2023 23:03:48 INFO Epoch 1: [573/10940] ---- BYOL Training Loss = 0.39604800939559937
29-01-2023 23:04:41 INFO Epoch 1: [573/10940] ---- BYOL Validation Loss = 0.41807445883750916
29-01-2023 23:04:58 INFO Epoch 1: [584/10940] ---- BYOL Training Loss = 0.39514023065567017
29-01-2023 23:05:16 INFO Epoch 1: [595/10940] ---- BYOL Training Loss = 0.429359495639801
29-01-2023 23:05:33 INFO Epoch 1: [606/10940] ---- BYOL Training Loss = 0.47423774003982544
29-01-2023 23:05:51 INFO Epoch 1: [617/10940] ---- BYOL Training Loss = 0.45629414916038513
29-01-2023 23:06:43 INFO Epoch 1: [617/10940] ---- BYOL Validation Loss = 0.3940034508705139
29-01-2023 23:07:00 INFO Epoch 1: [628/10940] ---- BYOL Training Loss = 0.3999318480491638
29-01-2023 23:07:18 INFO Epoch 1: [639/10940] ---- BYOL Training Loss = 0.4592415690422058
29-01-2023 23:07:35 INFO Epoch 1: [650/10940] ---- BYOL Training Loss = 0.46283215284347534
29-01-2023 23:07:53 INFO Epoch 1: [661/10940] ---- BYOL Training Loss = 0.48341894149780273
29-01-2023 23:08:45 INFO Epoch 1: [661/10940] ---- BYOL Validation Loss = 0.4045271873474121
29-01-2023 23:09:02 INFO Epoch 1: [672/10940] ---- BYOL Training Loss = 0.502754271030426
29-01-2023 23:09:20 INFO Epoch 1: [683/10940] ---- BYOL Training Loss = 0.45648273825645447
29-01-2023 23:09:38 INFO Epoch 1: [694/10940] ---- BYOL Training Loss = 0.4337941110134125
29-01-2023 23:09:55 INFO Epoch 1: [705/10940] ---- BYOL Training Loss = 0.46913614869117737
29-01-2023 23:10:48 INFO Epoch 1: [705/10940] ---- BYOL Validation Loss = 0.3825962245464325
29-01-2023 23:11:05 INFO Epoch 1: [716/10940] ---- BYOL Training Loss = 0.42283764481544495
29-01-2023 23:11:23 INFO Epoch 1: [727/10940] ---- BYOL Training Loss = 0.4098840355873108
29-01-2023 23:11:40 INFO Epoch 1: [738/10940] ---- BYOL Training Loss = 0.47338980436325073
29-01-2023 23:11:58 INFO Epoch 1: [749/10940] ---- BYOL Training Loss = 0.4338107705116272
29-01-2023 23:12:51 INFO Epoch 1: [749/10940] ---- BYOL Validation Loss = 0.3827514350414276
29-01-2023 23:13:08 INFO Epoch 1: [760/10940] ---- BYOL Training Loss = 0.38629958033561707
29-01-2023 23:13:25 INFO Epoch 1: [771/10940] ---- BYOL Training Loss = 0.37660661339759827
29-01-2023 23:13:43 INFO Epoch 1: [782/10940] ---- BYOL Training Loss = 0.4126172959804535
29-01-2023 23:14:01 INFO Epoch 1: [793/10940] ---- BYOL Training Loss = 0.3337424695491791
29-01-2023 23:14:53 INFO Epoch 1: [793/10940] ---- BYOL Validation Loss = 0.3779672682285309
29-01-2023 23:15:10 INFO Epoch 1: [804/10940] ---- BYOL Training Loss = 0.39318013191223145
29-01-2023 23:15:28 INFO Epoch 1: [815/10940] ---- BYOL Training Loss = 0.4768189787864685
29-01-2023 23:15:46 INFO Epoch 1: [826/10940] ---- BYOL Training Loss = 0.4396776258945465
29-01-2023 23:16:03 INFO Epoch 1: [837/10940] ---- BYOL Training Loss = 0.38793453574180603
29-01-2023 23:16:56 INFO Epoch 1: [837/10940] ---- BYOL Validation Loss = 0.40016868710517883
29-01-2023 23:17:13 INFO Epoch 1: [848/10940] ---- BYOL Training Loss = 0.4536682665348053
29-01-2023 23:17:31 INFO Epoch 1: [859/10940] ---- BYOL Training Loss = 0.46607738733291626
29-01-2023 23:17:48 INFO Epoch 1: [870/10940] ---- BYOL Training Loss = 0.3929462730884552
29-01-2023 23:18:06 INFO Epoch 1: [881/10940] ---- BYOL Training Loss = 0.41564542055130005
29-01-2023 23:18:58 INFO Epoch 1: [881/10940] ---- BYOL Validation Loss = 0.39245277643203735
29-01-2023 23:19:16 INFO Epoch 1: [892/10940] ---- BYOL Training Loss = 0.45519495010375977
29-01-2023 23:19:33 INFO Epoch 1: [903/10940] ---- BYOL Training Loss = 0.3971509039402008
29-01-2023 23:19:51 INFO Epoch 1: [914/10940] ---- BYOL Training Loss = 0.38660627603530884
29-01-2023 23:20:09 INFO Epoch 1: [925/10940] ---- BYOL Training Loss = 0.41595563292503357
29-01-2023 23:21:01 INFO Epoch 1: [925/10940] ---- BYOL Validation Loss = 0.381691038608551
29-01-2023 23:21:19 INFO Epoch 1: [936/10940] ---- BYOL Training Loss = 0.4168991148471832
29-01-2023 23:21:37 INFO Epoch 1: [947/10940] ---- BYOL Training Loss = 0.3951047956943512
29-01-2023 23:21:54 INFO Epoch 1: [958/10940] ---- BYOL Training Loss = 0.4223945736885071
29-01-2023 23:22:12 INFO Epoch 1: [969/10940] ---- BYOL Training Loss = 0.42851048707962036
29-01-2023 23:23:05 INFO Epoch 1: [969/10940] ---- BYOL Validation Loss = 0.3949972689151764
29-01-2023 23:23:22 INFO Epoch 1: [980/10940] ---- BYOL Training Loss = 0.4253864288330078
29-01-2023 23:23:39 INFO Epoch 1: [991/10940] ---- BYOL Training Loss = 0.41807904839515686
29-01-2023 23:23:57 INFO Epoch 1: [1002/10940] ---- BYOL Training Loss = 0.3446149528026581
29-01-2023 23:24:15 INFO Epoch 1: [1013/10940] ---- BYOL Training Loss = 0.336267352104187
29-01-2023 23:25:07 INFO Epoch 1: [1013/10940] ---- BYOL Validation Loss = 0.38673704862594604
29-01-2023 23:25:25 INFO Epoch 1: [1024/10940] ---- BYOL Training Loss = 0.3258046805858612
29-01-2023 23:25:42 INFO Epoch 1: [1035/10940] ---- BYOL Training Loss = 0.3808864653110504
29-01-2023 23:26:00 INFO Epoch 1: [1046/10940] ---- BYOL Training Loss = 0.4034942090511322
29-01-2023 23:26:17 INFO Epoch 1: [1057/10940] ---- BYOL Training Loss = 0.39887499809265137
29-01-2023 23:27:10 INFO Epoch 1: [1057/10940] ---- BYOL Validation Loss = 0.3795548975467682
29-01-2023 23:27:27 INFO Epoch 1: [1068/10940] ---- BYOL Training Loss = 0.3884078860282898
29-01-2023 23:27:45 INFO Epoch 1: [1079/10940] ---- BYOL Training Loss = 0.36261436343193054
29-01-2023 23:28:02 INFO Epoch 1: [1090/10940] ---- BYOL Training Loss = 0.3615451753139496
29-01-2023 23:28:20 INFO Epoch 1: [1101/10940] ---- BYOL Training Loss = 0.3686864972114563
29-01-2023 23:29:13 INFO Epoch 1: [1101/10940] ---- BYOL Validation Loss = 0.3797167241573334
29-01-2023 23:29:30 INFO Epoch 1: [1112/10940] ---- BYOL Training Loss = 0.4147874712944031
29-01-2023 23:29:47 INFO Epoch 1: [1123/10940] ---- BYOL Training Loss = 0.4068606495857239
29-01-2023 23:30:05 INFO Epoch 1: [1134/10940] ---- BYOL Training Loss = 0.3736342787742615
29-01-2023 23:30:23 INFO Epoch 1: [1145/10940] ---- BYOL Training Loss = 0.3961365222930908
29-01-2023 23:31:15 INFO Epoch 1: [1145/10940] ---- BYOL Validation Loss = 0.37875106930732727
29-01-2023 23:31:32 INFO Epoch 1: [1156/10940] ---- BYOL Training Loss = 0.35943499207496643
29-01-2023 23:31:50 INFO Epoch 1: [1167/10940] ---- BYOL Training Loss = 0.4035736918449402
29-01-2023 23:32:08 INFO Epoch 1: [1178/10940] ---- BYOL Training Loss = 0.4095314145088196
29-01-2023 23:32:25 INFO Epoch 1: [1189/10940] ---- BYOL Training Loss = 0.35882967710494995
29-01-2023 23:33:18 INFO Epoch 1: [1189/10940] ---- BYOL Validation Loss = 0.368600457906723
29-01-2023 23:33:35 INFO Epoch 1: [1200/10940] ---- BYOL Training Loss = 0.3300255239009857
29-01-2023 23:33:53 INFO Epoch 1: [1211/10940] ---- BYOL Training Loss = 0.3963375687599182
29-01-2023 23:34:11 INFO Epoch 1: [1222/10940] ---- BYOL Training Loss = 0.4190898537635803
29-01-2023 23:34:29 INFO Epoch 1: [1233/10940] ---- BYOL Training Loss = 0.3783920109272003
29-01-2023 23:35:21 INFO Epoch 1: [1233/10940] ---- BYOL Validation Loss = 0.36257508397102356
29-01-2023 23:35:39 INFO Epoch 1: [1244/10940] ---- BYOL Training Loss = 0.3387826383113861
29-01-2023 23:35:56 INFO Epoch 1: [1255/10940] ---- BYOL Training Loss = 0.309769868850708
29-01-2023 23:36:14 INFO Epoch 1: [1266/10940] ---- BYOL Training Loss = 0.34012821316719055
29-01-2023 23:36:32 INFO Epoch 1: [1277/10940] ---- BYOL Training Loss = 0.3694153130054474
29-01-2023 23:37:24 INFO Epoch 1: [1277/10940] ---- BYOL Validation Loss = 0.3659973740577698
29-01-2023 23:37:41 INFO Epoch 1: [1288/10940] ---- BYOL Training Loss = 0.35327696800231934
29-01-2023 23:37:59 INFO Epoch 1: [1299/10940] ---- BYOL Training Loss = 0.3442636728286743
29-01-2023 23:38:17 INFO Epoch 1: [1310/10940] ---- BYOL Training Loss = 0.35557040572166443
29-01-2023 23:38:34 INFO Epoch 1: [1321/10940] ---- BYOL Training Loss = 0.40185657143592834
29-01-2023 23:39:27 INFO Epoch 1: [1321/10940] ---- BYOL Validation Loss = 0.3691796362400055
29-01-2023 23:39:44 INFO Epoch 1: [1332/10940] ---- BYOL Training Loss = 0.34973278641700745
29-01-2023 23:40:02 INFO Epoch 1: [1343/10940] ---- BYOL Training Loss = 0.30891862511634827
29-01-2023 23:40:19 INFO Epoch 1: [1354/10940] ---- BYOL Training Loss = 0.3610881268978119
29-01-2023 23:40:37 INFO Epoch 1: [1365/10940] ---- BYOL Training Loss = 0.36056140065193176
29-01-2023 23:41:30 INFO Epoch 1: [1365/10940] ---- BYOL Validation Loss = 0.36930274963378906
29-01-2023 23:41:47 INFO Epoch 1: [1376/10940] ---- BYOL Training Loss = 0.34946611523628235
29-01-2023 23:42:05 INFO Epoch 1: [1387/10940] ---- BYOL Training Loss = 0.3770272731781006
29-01-2023 23:42:22 INFO Epoch 1: [1398/10940] ---- BYOL Training Loss = 0.440390408039093
29-01-2023 23:42:40 INFO Epoch 1: [1409/10940] ---- BYOL Training Loss = 0.407550185918808
29-01-2023 23:43:33 INFO Epoch 1: [1409/10940] ---- BYOL Validation Loss = 0.37008827924728394
29-01-2023 23:43:50 INFO Epoch 1: [1420/10940] ---- BYOL Training Loss = 0.39696502685546875
29-01-2023 23:44:08 INFO Epoch 1: [1431/10940] ---- BYOL Training Loss = 0.37231865525245667
29-01-2023 23:44:25 INFO Epoch 1: [1442/10940] ---- BYOL Training Loss = 0.3800604045391083
29-01-2023 23:44:43 INFO Epoch 1: [1453/10940] ---- BYOL Training Loss = 0.37644025683403015
29-01-2023 23:45:36 INFO Epoch 1: [1453/10940] ---- BYOL Validation Loss = 0.36909279227256775
29-01-2023 23:45:53 INFO Epoch 1: [1464/10940] ---- BYOL Training Loss = 0.3860907256603241
29-01-2023 23:46:10 INFO Epoch 1: [1475/10940] ---- BYOL Training Loss = 0.38153696060180664
29-01-2023 23:46:28 INFO Epoch 1: [1486/10940] ---- BYOL Training Loss = 0.39465704560279846
29-01-2023 23:46:46 INFO Epoch 1: [1497/10940] ---- BYOL Training Loss = 0.4018373489379883
29-01-2023 23:47:38 INFO Epoch 1: [1497/10940] ---- BYOL Validation Loss = 0.36852794885635376
29-01-2023 23:47:56 INFO Epoch 1: [1508/10940] ---- BYOL Training Loss = 0.36607685685157776
29-01-2023 23:48:14 INFO Epoch 1: [1519/10940] ---- BYOL Training Loss = 0.4083412289619446
29-01-2023 23:48:31 INFO Epoch 1: [1530/10940] ---- BYOL Training Loss = 0.4001632630825043
29-01-2023 23:48:49 INFO Epoch 1: [1541/10940] ---- BYOL Training Loss = 0.3510138988494873
29-01-2023 23:49:42 INFO Epoch 1: [1541/10940] ---- BYOL Validation Loss = 0.36439594626426697
29-01-2023 23:49:59 INFO Epoch 1: [1552/10940] ---- BYOL Training Loss = 0.3838263154029846
29-01-2023 23:50:17 INFO Epoch 1: [1563/10940] ---- BYOL Training Loss = 0.3954336643218994
29-01-2023 23:50:34 INFO Epoch 1: [1574/10940] ---- BYOL Training Loss = 0.38002437353134155
29-01-2023 23:50:52 INFO Epoch 1: [1585/10940] ---- BYOL Training Loss = 0.3894418478012085
29-01-2023 23:51:45 INFO Epoch 1: [1585/10940] ---- BYOL Validation Loss = 0.35887497663497925
29-01-2023 23:52:02 INFO Epoch 1: [1596/10940] ---- BYOL Training Loss = 0.36786407232284546
29-01-2023 23:52:20 INFO Epoch 1: [1607/10940] ---- BYOL Training Loss = 0.38243788480758667
29-01-2023 23:52:37 INFO Epoch 1: [1618/10940] ---- BYOL Training Loss = 0.4089098870754242
29-01-2023 23:52:55 INFO Epoch 1: [1629/10940] ---- BYOL Training Loss = 0.4200197160243988
29-01-2023 23:53:47 INFO Epoch 1: [1629/10940] ---- BYOL Validation Loss = 0.36272192001342773
29-01-2023 23:54:05 INFO Epoch 1: [1640/10940] ---- BYOL Training Loss = 0.3726440370082855
29-01-2023 23:54:22 INFO Epoch 1: [1651/10940] ---- BYOL Training Loss = 0.3388828933238983
29-01-2023 23:54:40 INFO Epoch 1: [1662/10940] ---- BYOL Training Loss = 0.3082519471645355
29-01-2023 23:54:58 INFO Epoch 1: [1673/10940] ---- BYOL Training Loss = 0.3783382773399353
29-01-2023 23:55:50 INFO Epoch 1: [1673/10940] ---- BYOL Validation Loss = 0.37348318099975586
29-01-2023 23:56:08 INFO Epoch 1: [1684/10940] ---- BYOL Training Loss = 0.4234548509120941
29-01-2023 23:56:25 INFO Epoch 1: [1695/10940] ---- BYOL Training Loss = 0.3942900002002716
29-01-2023 23:56:43 INFO Epoch 1: [1706/10940] ---- BYOL Training Loss = 0.3630658984184265
29-01-2023 23:57:01 INFO Epoch 1: [1717/10940] ---- BYOL Training Loss = 0.33711183071136475
29-01-2023 23:57:53 INFO Epoch 1: [1717/10940] ---- BYOL Validation Loss = 0.35431092977523804
29-01-2023 23:58:11 INFO Epoch 1: [1728/10940] ---- BYOL Training Loss = 0.38140833377838135
29-01-2023 23:58:28 INFO Epoch 1: [1739/10940] ---- BYOL Training Loss = 0.37604573369026184
29-01-2023 23:58:46 INFO Epoch 1: [1750/10940] ---- BYOL Training Loss = 0.35383832454681396
29-01-2023 23:59:04 INFO Epoch 1: [1761/10940] ---- BYOL Training Loss = 0.33799073100090027
29-01-2023 23:59:57 INFO Epoch 1: [1761/10940] ---- BYOL Validation Loss = 0.3478233814239502
30-01-2023 00:00:14 INFO Epoch 1: [1772/10940] ---- BYOL Training Loss = 0.3395492434501648
30-01-2023 00:00:32 INFO Epoch 1: [1783/10940] ---- BYOL Training Loss = 0.32051822543144226
30-01-2023 00:00:49 INFO Epoch 1: [1794/10940] ---- BYOL Training Loss = 0.34857630729675293
30-01-2023 00:01:07 INFO Epoch 1: [1805/10940] ---- BYOL Training Loss = 0.4228116571903229
30-01-2023 00:01:59 INFO Epoch 1: [1805/10940] ---- BYOL Validation Loss = 0.3462401032447815
30-01-2023 00:02:17 INFO Epoch 1: [1816/10940] ---- BYOL Training Loss = 0.40145277976989746
30-01-2023 00:02:34 INFO Epoch 1: [1827/10940] ---- BYOL Training Loss = 0.34076160192489624
30-01-2023 00:02:52 INFO Epoch 1: [1838/10940] ---- BYOL Training Loss = 0.3745284974575043
30-01-2023 00:03:10 INFO Epoch 1: [1849/10940] ---- BYOL Training Loss = 0.3829954266548157
30-01-2023 00:04:02 INFO Epoch 1: [1849/10940] ---- BYOL Validation Loss = 0.33866479992866516
30-01-2023 00:04:20 INFO Epoch 1: [1860/10940] ---- BYOL Training Loss = 0.39024025201797485
30-01-2023 00:04:37 INFO Epoch 1: [1871/10940] ---- BYOL Training Loss = 0.47806277871131897
30-01-2023 00:04:55 INFO Epoch 1: [1882/10940] ---- BYOL Training Loss = 0.374276727437973
30-01-2023 00:05:13 INFO Epoch 1: [1893/10940] ---- BYOL Training Loss = 0.3331192135810852
30-01-2023 00:06:05 INFO Epoch 1: [1893/10940] ---- BYOL Validation Loss = 0.35429200530052185
30-01-2023 00:06:23 INFO Epoch 1: [1904/10940] ---- BYOL Training Loss = 0.3925359845161438
30-01-2023 00:06:41 INFO Epoch 1: [1915/10940] ---- BYOL Training Loss = 0.3780181109905243
30-01-2023 00:06:58 INFO Epoch 1: [1926/10940] ---- BYOL Training Loss = 0.36640846729278564
30-01-2023 00:07:16 INFO Epoch 1: [1937/10940] ---- BYOL Training Loss = 0.351876437664032
30-01-2023 00:08:09 INFO Epoch 1: [1937/10940] ---- BYOL Validation Loss = 0.3561672866344452
30-01-2023 00:08:26 INFO Epoch 1: [1948/10940] ---- BYOL Training Loss = 0.3812400698661804
30-01-2023 00:08:44 INFO Epoch 1: [1959/10940] ---- BYOL Training Loss = 0.3458520472049713
30-01-2023 00:09:01 INFO Epoch 1: [1970/10940] ---- BYOL Training Loss = 0.322924941778183
30-01-2023 00:09:19 INFO Epoch 1: [1981/10940] ---- BYOL Training Loss = 0.3393270969390869
30-01-2023 00:10:12 INFO Epoch 1: [1981/10940] ---- BYOL Validation Loss = 0.34047219157218933
30-01-2023 00:10:29 INFO Epoch 1: [1992/10940] ---- BYOL Training Loss = 0.308310329914093
30-01-2023 00:10:47 INFO Epoch 1: [2003/10940] ---- BYOL Training Loss = 0.3439522087574005
30-01-2023 00:11:04 INFO Epoch 1: [2014/10940] ---- BYOL Training Loss = 0.3199666142463684
30-01-2023 00:11:22 INFO Epoch 1: [2025/10940] ---- BYOL Training Loss = 0.32209670543670654
30-01-2023 00:12:15 INFO Epoch 1: [2025/10940] ---- BYOL Validation Loss = 0.3485495150089264
30-01-2023 00:12:32 INFO Epoch 1: [2036/10940] ---- BYOL Training Loss = 0.31769800186157227
30-01-2023 00:12:50 INFO Epoch 1: [2047/10940] ---- BYOL Training Loss = 0.30859026312828064
30-01-2023 00:13:08 INFO Epoch 1: [2058/10940] ---- BYOL Training Loss = 0.3226701617240906
30-01-2023 00:13:26 INFO Epoch 1: [2069/10940] ---- BYOL Training Loss = 0.2814106345176697
30-01-2023 00:14:18 INFO Epoch 1: [2069/10940] ---- BYOL Validation Loss = 0.3364812433719635
30-01-2023 00:14:36 INFO Epoch 1: [2080/10940] ---- BYOL Training Loss = 0.25503426790237427
30-01-2023 00:14:54 INFO Epoch 1: [2091/10940] ---- BYOL Training Loss = 0.3534620702266693
30-01-2023 00:15:11 INFO Epoch 1: [2102/10940] ---- BYOL Training Loss = 0.339796781539917
30-01-2023 00:15:29 INFO Epoch 1: [2113/10940] ---- BYOL Training Loss = 0.37760645151138306
30-01-2023 00:16:22 INFO Epoch 1: [2113/10940] ---- BYOL Validation Loss = 0.3800176680088043
30-01-2023 00:16:39 INFO Epoch 1: [2124/10940] ---- BYOL Training Loss = 0.4374087452888489
30-01-2023 00:16:57 INFO Epoch 1: [2135/10940] ---- BYOL Training Loss = 0.3792990446090698
30-01-2023 00:17:15 INFO Epoch 1: [2146/10940] ---- BYOL Training Loss = 0.40070024132728577
30-01-2023 00:17:32 INFO Epoch 1: [2157/10940] ---- BYOL Training Loss = 0.3648138642311096
30-01-2023 00:18:25 INFO Epoch 1: [2157/10940] ---- BYOL Validation Loss = 0.34058645367622375
30-01-2023 00:18:42 INFO Epoch 1: [2168/10940] ---- BYOL Training Loss = 0.3213857114315033
30-01-2023 00:19:00 INFO Epoch 1: [2179/10940] ---- BYOL Training Loss = 0.3614891469478607
30-01-2023 00:19:18 INFO Epoch 1: [2190/10940] ---- BYOL Training Loss = 0.33378782868385315
30-01-2023 00:19:36 INFO Epoch 1: [2201/10940] ---- BYOL Training Loss = 0.3176769018173218
30-01-2023 00:20:28 INFO Epoch 1: [2201/10940] ---- BYOL Validation Loss = 0.33562150597572327
30-01-2023 00:20:45 INFO Epoch 1: [2212/10940] ---- BYOL Training Loss = 0.3838043808937073
30-01-2023 00:21:04 INFO Epoch 1: [2223/10940] ---- BYOL Training Loss = 0.3787210285663605
30-01-2023 00:21:21 INFO Epoch 1: [2234/10940] ---- BYOL Training Loss = 0.3186587989330292
30-01-2023 00:21:39 INFO Epoch 1: [2245/10940] ---- BYOL Training Loss = 0.3749077320098877
30-01-2023 00:22:32 INFO Epoch 1: [2245/10940] ---- BYOL Validation Loss = 0.3482271134853363
30-01-2023 00:22:49 INFO Epoch 1: [2256/10940] ---- BYOL Training Loss = 0.3417206406593323
30-01-2023 00:23:07 INFO Epoch 1: [2267/10940] ---- BYOL Training Loss = 0.3807242810726166
30-01-2023 00:23:24 INFO Epoch 1: [2278/10940] ---- BYOL Training Loss = 0.3757212162017822
30-01-2023 00:23:42 INFO Epoch 1: [2289/10940] ---- BYOL Training Loss = 0.28645059466362
30-01-2023 00:24:35 INFO Epoch 1: [2289/10940] ---- BYOL Validation Loss = 0.33851388096809387
30-01-2023 00:24:52 INFO Epoch 1: [2300/10940] ---- BYOL Training Loss = 0.35595762729644775
30-01-2023 00:25:10 INFO Epoch 1: [2311/10940] ---- BYOL Training Loss = 0.384193480014801
30-01-2023 00:25:27 INFO Epoch 1: [2322/10940] ---- BYOL Training Loss = 0.32171905040740967
30-01-2023 00:25:45 INFO Epoch 1: [2333/10940] ---- BYOL Training Loss = 0.34187498688697815
30-01-2023 00:26:38 INFO Epoch 1: [2333/10940] ---- BYOL Validation Loss = 0.3393113315105438
30-01-2023 00:26:55 INFO Epoch 1: [2344/10940] ---- BYOL Training Loss = 0.316153347492218
30-01-2023 00:27:13 INFO Epoch 1: [2355/10940] ---- BYOL Training Loss = 0.28736135363578796
30-01-2023 00:27:31 INFO Epoch 1: [2366/10940] ---- BYOL Training Loss = 0.3057020306587219
30-01-2023 00:27:49 INFO Epoch 1: [2377/10940] ---- BYOL Training Loss = 0.348434180021286
30-01-2023 00:28:42 INFO Epoch 1: [2377/10940] ---- BYOL Validation Loss = 0.33932971954345703
30-01-2023 00:28:59 INFO Epoch 1: [2388/10940] ---- BYOL Training Loss = 0.32869166135787964
30-01-2023 00:29:17 INFO Epoch 1: [2399/10940] ---- BYOL Training Loss = 0.28547364473342896
30-01-2023 00:29:35 INFO Epoch 1: [2410/10940] ---- BYOL Training Loss = 0.28203845024108887
30-01-2023 00:29:52 INFO Epoch 1: [2421/10940] ---- BYOL Training Loss = 0.30904752016067505
30-01-2023 00:30:45 INFO Epoch 1: [2421/10940] ---- BYOL Validation Loss = 0.34439006447792053
30-01-2023 00:31:02 INFO Epoch 1: [2432/10940] ---- BYOL Training Loss = 0.33257633447647095
30-01-2023 00:31:20 INFO Epoch 1: [2443/10940] ---- BYOL Training Loss = 0.3544279634952545
30-01-2023 00:31:38 INFO Epoch 1: [2454/10940] ---- BYOL Training Loss = 0.3397729992866516
30-01-2023 00:31:56 INFO Epoch 1: [2465/10940] ---- BYOL Training Loss = 0.3969402313232422
30-01-2023 00:32:48 INFO Epoch 1: [2465/10940] ---- BYOL Validation Loss = 0.338666170835495
30-01-2023 00:33:06 INFO Epoch 1: [2476/10940] ---- BYOL Training Loss = 0.37337934970855713
30-01-2023 00:33:23 INFO Epoch 1: [2487/10940] ---- BYOL Training Loss = 0.3521311283111572
30-01-2023 00:33:41 INFO Epoch 1: [2498/10940] ---- BYOL Training Loss = 0.41457390785217285
30-01-2023 00:33:59 INFO Epoch 1: [2509/10940] ---- BYOL Training Loss = 0.39717039465904236
30-01-2023 00:34:52 INFO Epoch 1: [2509/10940] ---- BYOL Validation Loss = 0.36282452940940857
30-01-2023 00:35:09 INFO Epoch 1: [2520/10940] ---- BYOL Training Loss = 0.3252888321876526
30-01-2023 00:35:27 INFO Epoch 1: [2531/10940] ---- BYOL Training Loss = 0.38523250818252563
30-01-2023 00:35:45 INFO Epoch 1: [2542/10940] ---- BYOL Training Loss = 0.44001859426498413
30-01-2023 00:36:02 INFO Epoch 1: [2553/10940] ---- BYOL Training Loss = 0.402014821767807
30-01-2023 00:36:55 INFO Epoch 1: [2553/10940] ---- BYOL Validation Loss = 0.3557715117931366
30-01-2023 00:37:12 INFO Epoch 1: [2564/10940] ---- BYOL Training Loss = 0.3571661710739136
30-01-2023 00:37:31 INFO Epoch 1: [2575/10940] ---- BYOL Training Loss = 0.3672463297843933
30-01-2023 00:37:48 INFO Epoch 1: [2586/10940] ---- BYOL Training Loss = 0.358152836561203
30-01-2023 00:38:06 INFO Epoch 1: [2597/10940] ---- BYOL Training Loss = 0.30256494879722595
30-01-2023 00:38:59 INFO Epoch 1: [2597/10940] ---- BYOL Validation Loss = 0.3231990933418274
30-01-2023 00:39:16 INFO Epoch 1: [2608/10940] ---- BYOL Training Loss = 0.30333083868026733
30-01-2023 00:39:34 INFO Epoch 1: [2619/10940] ---- BYOL Training Loss = 0.3563167154788971
30-01-2023 00:39:52 INFO Epoch 1: [2630/10940] ---- BYOL Training Loss = 0.37043553590774536
30-01-2023 00:40:10 INFO Epoch 1: [2641/10940] ---- BYOL Training Loss = 0.3662075102329254
30-01-2023 00:41:02 INFO Epoch 1: [2641/10940] ---- BYOL Validation Loss = 0.3302364647388458
30-01-2023 00:41:19 INFO Epoch 1: [2652/10940] ---- BYOL Training Loss = 0.35483139753341675
30-01-2023 00:41:37 INFO Epoch 1: [2663/10940] ---- BYOL Training Loss = 0.36137962341308594
30-01-2023 00:41:55 INFO Epoch 1: [2674/10940] ---- BYOL Training Loss = 0.36620572209358215
30-01-2023 00:42:13 INFO Epoch 1: [2685/10940] ---- BYOL Training Loss = 0.3579745590686798
30-01-2023 00:43:06 INFO Epoch 1: [2685/10940] ---- BYOL Validation Loss = 0.33288413286209106
30-01-2023 00:43:23 INFO Epoch 1: [2696/10940] ---- BYOL Training Loss = 0.36435338854789734
30-01-2023 00:43:41 INFO Epoch 1: [2707/10940] ---- BYOL Training Loss = 0.36815062165260315
30-01-2023 00:43:59 INFO Epoch 1: [2718/10940] ---- BYOL Training Loss = 0.35996919870376587
30-01-2023 00:44:17 INFO Epoch 1: [2729/10940] ---- BYOL Training Loss = 0.3301020562648773
30-01-2023 00:45:09 INFO Epoch 1: [2729/10940] ---- BYOL Validation Loss = 0.3240824341773987
30-01-2023 00:45:27 INFO Epoch 1: [2740/10940] ---- BYOL Training Loss = 0.3056704103946686
30-01-2023 00:45:44 INFO Epoch 1: [2751/10940] ---- BYOL Training Loss = 0.2673919200897217
30-01-2023 00:46:02 INFO Epoch 1: [2762/10940] ---- BYOL Training Loss = 0.2975316643714905
30-01-2023 00:46:20 INFO Epoch 1: [2773/10940] ---- BYOL Training Loss = 0.3129235804080963
30-01-2023 00:47:13 INFO Epoch 1: [2773/10940] ---- BYOL Validation Loss = 0.3224584758281708
30-01-2023 00:47:30 INFO Epoch 1: [2784/10940] ---- BYOL Training Loss = 0.3461219072341919
30-01-2023 00:47:48 INFO Epoch 1: [2795/10940] ---- BYOL Training Loss = 0.36845237016677856
30-01-2023 00:48:06 INFO Epoch 1: [2806/10940] ---- BYOL Training Loss = 0.39739611744880676
30-01-2023 00:48:24 INFO Epoch 1: [2817/10940] ---- BYOL Training Loss = 0.35471445322036743
30-01-2023 00:49:16 INFO Epoch 1: [2817/10940] ---- BYOL Validation Loss = 0.3125002682209015
30-01-2023 00:49:34 INFO Epoch 1: [2828/10940] ---- BYOL Training Loss = 0.35265880823135376
30-01-2023 00:49:51 INFO Epoch 1: [2839/10940] ---- BYOL Training Loss = 0.3596421778202057
30-01-2023 00:50:09 INFO Epoch 1: [2850/10940] ---- BYOL Training Loss = 0.3801606595516205
30-01-2023 00:50:27 INFO Epoch 1: [2861/10940] ---- BYOL Training Loss = 0.3761644959449768
30-01-2023 00:51:20 INFO Epoch 1: [2861/10940] ---- BYOL Validation Loss = 0.3274555206298828
30-01-2023 00:51:37 INFO Epoch 1: [2872/10940] ---- BYOL Training Loss = 0.35673007369041443
30-01-2023 00:51:55 INFO Epoch 1: [2883/10940] ---- BYOL Training Loss = 0.32470688223838806
30-01-2023 00:52:13 INFO Epoch 1: [2894/10940] ---- BYOL Training Loss = 0.34538009762763977
30-01-2023 00:52:31 INFO Epoch 1: [2905/10940] ---- BYOL Training Loss = 0.3928317129611969
30-01-2023 00:53:23 INFO Epoch 1: [2905/10940] ---- BYOL Validation Loss = 0.34312087297439575
30-01-2023 00:53:41 INFO Epoch 1: [2916/10940] ---- BYOL Training Loss = 0.3773336112499237
30-01-2023 00:53:59 INFO Epoch 1: [2927/10940] ---- BYOL Training Loss = 0.34734809398651123
30-01-2023 00:54:17 INFO Epoch 1: [2938/10940] ---- BYOL Training Loss = 0.3602558672428131
30-01-2023 00:54:34 INFO Epoch 1: [2949/10940] ---- BYOL Training Loss = 0.34332042932510376
30-01-2023 00:55:27 INFO Epoch 1: [2949/10940] ---- BYOL Validation Loss = 0.32839056849479675
30-01-2023 00:55:44 INFO Epoch 1: [2960/10940] ---- BYOL Training Loss = 0.32905593514442444
30-01-2023 00:56:03 INFO Epoch 1: [2971/10940] ---- BYOL Training Loss = 0.315653920173645
30-01-2023 00:56:20 INFO Epoch 1: [2982/10940] ---- BYOL Training Loss = 0.3013131320476532
30-01-2023 00:56:38 INFO Epoch 1: [2993/10940] ---- BYOL Training Loss = 0.31786221265792847
30-01-2023 00:57:31 INFO Epoch 1: [2993/10940] ---- BYOL Validation Loss = 0.3302760124206543
30-01-2023 00:57:48 INFO Epoch 1: [3004/10940] ---- BYOL Training Loss = 0.35683804750442505
30-01-2023 00:58:06 INFO Epoch 1: [3015/10940] ---- BYOL Training Loss = 0.37899452447891235
30-01-2023 00:58:24 INFO Epoch 1: [3026/10940] ---- BYOL Training Loss = 0.35733702778816223
30-01-2023 00:58:42 INFO Epoch 1: [3037/10940] ---- BYOL Training Loss = 0.3565009832382202
30-01-2023 00:59:34 INFO Epoch 1: [3037/10940] ---- BYOL Validation Loss = 0.3222479224205017
30-01-2023 00:59:52 INFO Epoch 1: [3048/10940] ---- BYOL Training Loss = 0.38009998202323914
30-01-2023 01:00:10 INFO Epoch 1: [3059/10940] ---- BYOL Training Loss = 0.3336411416530609
30-01-2023 01:00:28 INFO Epoch 1: [3070/10940] ---- BYOL Training Loss = 0.3015673756599426
30-01-2023 01:00:46 INFO Epoch 1: [3081/10940] ---- BYOL Training Loss = 0.332881361246109
30-01-2023 01:01:39 INFO Epoch 1: [3081/10940] ---- BYOL Validation Loss = 0.32405874133110046
30-01-2023 01:01:56 INFO Epoch 1: [3092/10940] ---- BYOL Training Loss = 0.27751559019088745
30-01-2023 01:02:14 INFO Epoch 1: [3103/10940] ---- BYOL Training Loss = 0.35082748532295227
30-01-2023 01:02:31 INFO Epoch 1: [3114/10940] ---- BYOL Training Loss = 0.412194162607193
30-01-2023 01:02:49 INFO Epoch 1: [3125/10940] ---- BYOL Training Loss = 0.33419886231422424
30-01-2023 01:03:42 INFO Epoch 1: [3125/10940] ---- BYOL Validation Loss = 0.3260348439216614
30-01-2023 01:03:59 INFO Epoch 1: [3136/10940] ---- BYOL Training Loss = 0.32775142788887024
30-01-2023 01:04:17 INFO Epoch 1: [3147/10940] ---- BYOL Training Loss = 0.2733721435070038
30-01-2023 01:04:35 INFO Epoch 1: [3158/10940] ---- BYOL Training Loss = 0.3082636296749115
30-01-2023 01:04:53 INFO Epoch 1: [3169/10940] ---- BYOL Training Loss = 0.34224119782447815
30-01-2023 01:05:46 INFO Epoch 1: [3169/10940] ---- BYOL Validation Loss = 0.3321754038333893
30-01-2023 01:06:03 INFO Epoch 1: [3180/10940] ---- BYOL Training Loss = 0.3196278512477875
30-01-2023 01:06:21 INFO Epoch 1: [3191/10940] ---- BYOL Training Loss = 0.36710187792778015
30-01-2023 01:06:39 INFO Epoch 1: [3202/10940] ---- BYOL Training Loss = 0.3798998296260834
30-01-2023 01:06:57 INFO Epoch 1: [3213/10940] ---- BYOL Training Loss = 0.3590243458747864
30-01-2023 01:07:49 INFO Epoch 1: [3213/10940] ---- BYOL Validation Loss = 0.32156142592430115
30-01-2023 01:08:07 INFO Epoch 1: [3224/10940] ---- BYOL Training Loss = 0.2947129011154175
30-01-2023 01:08:25 INFO Epoch 1: [3235/10940] ---- BYOL Training Loss = 0.31499117612838745
30-01-2023 01:08:42 INFO Epoch 1: [3246/10940] ---- BYOL Training Loss = 0.4022321105003357
30-01-2023 01:09:01 INFO Epoch 1: [3257/10940] ---- BYOL Training Loss = 0.3911755084991455
30-01-2023 01:09:53 INFO Epoch 1: [3257/10940] ---- BYOL Validation Loss = 0.32421866059303284
30-01-2023 01:10:11 INFO Epoch 1: [3268/10940] ---- BYOL Training Loss = 0.325106680393219
30-01-2023 01:10:28 INFO Epoch 1: [3279/10940] ---- BYOL Training Loss = 0.3381499946117401
30-01-2023 01:10:46 INFO Epoch 1: [3290/10940] ---- BYOL Training Loss = 0.2836177945137024
30-01-2023 01:11:04 INFO Epoch 1: [3301/10940] ---- BYOL Training Loss = 0.300788551568985
30-01-2023 01:11:56 INFO Epoch 1: [3301/10940] ---- BYOL Validation Loss = 0.33183059096336365
30-01-2023 01:12:14 INFO Epoch 1: [3312/10940] ---- BYOL Training Loss = 0.31242576241493225
30-01-2023 01:12:32 INFO Epoch 1: [3323/10940] ---- BYOL Training Loss = 0.30919256806373596
30-01-2023 01:12:50 INFO Epoch 1: [3334/10940] ---- BYOL Training Loss = 0.3557054400444031
30-01-2023 01:13:08 INFO Epoch 1: [3345/10940] ---- BYOL Training Loss = 0.3350215256214142
30-01-2023 01:14:00 INFO Epoch 1: [3345/10940] ---- BYOL Validation Loss = 0.328382283449173
30-01-2023 01:14:18 INFO Epoch 1: [3356/10940] ---- BYOL Training Loss = 0.2998543679714203
30-01-2023 01:14:35 INFO Epoch 1: [3367/10940] ---- BYOL Training Loss = 0.3011612892150879
30-01-2023 01:14:53 INFO Epoch 1: [3378/10940] ---- BYOL Training Loss = 0.35277432203292847
30-01-2023 01:15:11 INFO Epoch 1: [3389/10940] ---- BYOL Training Loss = 0.3422655463218689
30-01-2023 01:16:04 INFO Epoch 1: [3389/10940] ---- BYOL Validation Loss = 0.33704042434692383
30-01-2023 01:16:21 INFO Epoch 1: [3400/10940] ---- BYOL Training Loss = 0.3680657148361206
30-01-2023 01:16:39 INFO Epoch 1: [3411/10940] ---- BYOL Training Loss = 0.3962627649307251
30-01-2023 01:16:57 INFO Epoch 1: [3422/10940] ---- BYOL Training Loss = 0.3290960192680359
30-01-2023 01:17:15 INFO Epoch 1: [3433/10940] ---- BYOL Training Loss = 0.29915690422058105
30-01-2023 01:18:07 INFO Epoch 1: [3433/10940] ---- BYOL Validation Loss = 0.3383800983428955
30-01-2023 01:18:25 INFO Epoch 1: [3444/10940] ---- BYOL Training Loss = 0.3568662405014038
30-01-2023 01:18:43 INFO Epoch 1: [3455/10940] ---- BYOL Training Loss = 0.3292559087276459
30-01-2023 01:19:01 INFO Epoch 1: [3466/10940] ---- BYOL Training Loss = 0.3790728449821472
30-01-2023 01:19:18 INFO Epoch 1: [3477/10940] ---- BYOL Training Loss = 0.38063642382621765
30-01-2023 01:20:11 INFO Epoch 1: [3477/10940] ---- BYOL Validation Loss = 0.3401853144168854
30-01-2023 01:20:29 INFO Epoch 1: [3488/10940] ---- BYOL Training Loss = 0.3463219702243805
30-01-2023 01:20:47 INFO Epoch 1: [3499/10940] ---- BYOL Training Loss = 0.32517802715301514
30-01-2023 01:21:04 INFO Epoch 1: [3510/10940] ---- BYOL Training Loss = 0.3758670687675476
30-01-2023 01:21:22 INFO Epoch 1: [3521/10940] ---- BYOL Training Loss = 0.39049196243286133
30-01-2023 01:22:15 INFO Epoch 1: [3521/10940] ---- BYOL Validation Loss = 0.32133153080940247
30-01-2023 01:22:32 INFO Epoch 1: [3532/10940] ---- BYOL Training Loss = 0.36298975348472595
30-01-2023 01:22:50 INFO Epoch 1: [3543/10940] ---- BYOL Training Loss = 0.33016929030418396
30-01-2023 01:23:08 INFO Epoch 1: [3554/10940] ---- BYOL Training Loss = 0.3356759250164032
30-01-2023 01:23:26 INFO Epoch 1: [3565/10940] ---- BYOL Training Loss = 0.3368934392929077
30-01-2023 01:24:18 INFO Epoch 1: [3565/10940] ---- BYOL Validation Loss = 0.3267858922481537
30-01-2023 01:24:36 INFO Epoch 1: [3576/10940] ---- BYOL Training Loss = 0.3134162425994873
30-01-2023 01:24:54 INFO Epoch 1: [3587/10940] ---- BYOL Training Loss = 0.3157021403312683
30-01-2023 01:25:12 INFO Epoch 1: [3598/10940] ---- BYOL Training Loss = 0.3141809105873108
30-01-2023 01:25:30 INFO Epoch 1: [3609/10940] ---- BYOL Training Loss = 0.3634489178657532
30-01-2023 01:26:22 INFO Epoch 1: [3609/10940] ---- BYOL Validation Loss = 0.32424429059028625
30-01-2023 01:26:40 INFO Epoch 1: [3620/10940] ---- BYOL Training Loss = 0.3802436292171478
30-01-2023 01:26:57 INFO Epoch 1: [3631/10940] ---- BYOL Training Loss = 0.35385942459106445
30-01-2023 01:27:16 INFO Epoch 1: [3642/10940] ---- BYOL Training Loss = 0.3588370382785797
30-01-2023 01:27:34 INFO Epoch 1: [3653/10940] ---- BYOL Training Loss = 0.3347011208534241
30-01-2023 01:28:26 INFO Epoch 1: [3653/10940] ---- BYOL Validation Loss = 0.3374563157558441
30-01-2023 01:28:44 INFO Epoch 1: [3664/10940] ---- BYOL Training Loss = 0.36895307898521423
30-01-2023 01:29:02 INFO Epoch 1: [3675/10940] ---- BYOL Training Loss = 0.3638686537742615
30-01-2023 01:29:19 INFO Epoch 1: [3686/10940] ---- BYOL Training Loss = 0.3536129295825958
30-01-2023 01:29:37 INFO Epoch 1: [3697/10940] ---- BYOL Training Loss = 0.3273787498474121
30-01-2023 01:30:30 INFO Epoch 1: [3697/10940] ---- BYOL Validation Loss = 0.3327566683292389
30-01-2023 01:30:47 INFO Epoch 1: [3708/10940] ---- BYOL Training Loss = 0.27590328454971313
30-01-2023 01:31:06 INFO Epoch 1: [3719/10940] ---- BYOL Training Loss = 0.3305078446865082
30-01-2023 01:31:24 INFO Epoch 1: [3730/10940] ---- BYOL Training Loss = 0.36157646775245667
30-01-2023 01:31:41 INFO Epoch 1: [3741/10940] ---- BYOL Training Loss = 0.3790872097015381
30-01-2023 01:32:34 INFO Epoch 1: [3741/10940] ---- BYOL Validation Loss = 0.3396743834018707
30-01-2023 01:32:52 INFO Epoch 1: [3752/10940] ---- BYOL Training Loss = 0.33437398076057434
30-01-2023 01:33:09 INFO Epoch 1: [3763/10940] ---- BYOL Training Loss = 0.3639562129974365
30-01-2023 01:33:27 INFO Epoch 1: [3774/10940] ---- BYOL Training Loss = 0.3769611716270447
30-01-2023 01:33:45 INFO Epoch 1: [3785/10940] ---- BYOL Training Loss = 0.40336066484451294
30-01-2023 01:34:38 INFO Epoch 1: [3785/10940] ---- BYOL Validation Loss = 0.3387901186943054
30-01-2023 01:34:55 INFO Epoch 1: [3796/10940] ---- BYOL Training Loss = 0.4338153004646301
30-01-2023 01:35:13 INFO Epoch 1: [3807/10940] ---- BYOL Training Loss = 0.3667570948600769
30-01-2023 01:35:31 INFO Epoch 1: [3818/10940] ---- BYOL Training Loss = 0.3208377957344055
30-01-2023 01:35:49 INFO Epoch 1: [3829/10940] ---- BYOL Training Loss = 0.2812424898147583
30-01-2023 01:36:42 INFO Epoch 1: [3829/10940] ---- BYOL Validation Loss = 0.33415868878364563
30-01-2023 01:36:59 INFO Epoch 1: [3840/10940] ---- BYOL Training Loss = 0.3259952664375305
30-01-2023 01:37:17 INFO Epoch 1: [3851/10940] ---- BYOL Training Loss = 0.3469592332839966
30-01-2023 01:37:35 INFO Epoch 1: [3862/10940] ---- BYOL Training Loss = 0.3884790241718292
30-01-2023 01:37:53 INFO Epoch 1: [3873/10940] ---- BYOL Training Loss = 0.361135333776474
30-01-2023 01:38:46 INFO Epoch 1: [3873/10940] ---- BYOL Validation Loss = 0.33667120337486267
30-01-2023 01:39:03 INFO Epoch 1: [3884/10940] ---- BYOL Training Loss = 0.3357675075531006
30-01-2023 01:39:21 INFO Epoch 1: [3895/10940] ---- BYOL Training Loss = 0.32657095789909363
30-01-2023 01:39:39 INFO Epoch 1: [3906/10940] ---- BYOL Training Loss = 0.37283721566200256
30-01-2023 01:39:57 INFO Epoch 1: [3917/10940] ---- BYOL Training Loss = 0.39037376642227173
30-01-2023 01:40:50 INFO Epoch 1: [3917/10940] ---- BYOL Validation Loss = 0.3464813828468323
30-01-2023 01:41:08 INFO Epoch 1: [3928/10940] ---- BYOL Training Loss = 0.3982779383659363
30-01-2023 01:41:26 INFO Epoch 1: [3939/10940] ---- BYOL Training Loss = 0.3939839005470276
30-01-2023 01:41:44 INFO Epoch 1: [3950/10940] ---- BYOL Training Loss = 0.3588598668575287
30-01-2023 01:42:02 INFO Epoch 1: [3961/10940] ---- BYOL Training Loss = 0.3697953522205353
30-01-2023 01:42:54 INFO Epoch 1: [3961/10940] ---- BYOL Validation Loss = 0.3501332700252533
30-01-2023 01:43:12 INFO Epoch 1: [3972/10940] ---- BYOL Training Loss = 0.34552663564682007
30-01-2023 01:43:30 INFO Epoch 1: [3983/10940] ---- BYOL Training Loss = 0.34390002489089966
30-01-2023 01:43:48 INFO Epoch 1: [3994/10940] ---- BYOL Training Loss = 0.35367125272750854
30-01-2023 01:44:06 INFO Epoch 1: [4005/10940] ---- BYOL Training Loss = 0.31812626123428345
30-01-2023 01:44:58 INFO Epoch 1: [4005/10940] ---- BYOL Validation Loss = 0.3363165855407715
30-01-2023 01:45:16 INFO Epoch 1: [4016/10940] ---- BYOL Training Loss = 0.36435288190841675
30-01-2023 01:45:34 INFO Epoch 1: [4027/10940] ---- BYOL Training Loss = 0.37473899126052856
30-01-2023 01:45:52 INFO Epoch 1: [4038/10940] ---- BYOL Training Loss = 0.35074347257614136
30-01-2023 01:46:09 INFO Epoch 1: [4049/10940] ---- BYOL Training Loss = 0.3706657588481903
30-01-2023 01:47:02 INFO Epoch 1: [4049/10940] ---- BYOL Validation Loss = 0.3254196047782898
30-01-2023 01:47:20 INFO Epoch 1: [4060/10940] ---- BYOL Training Loss = 0.3710685074329376
30-01-2023 01:47:38 INFO Epoch 1: [4071/10940] ---- BYOL Training Loss = 0.3722877502441406
30-01-2023 01:47:56 INFO Epoch 1: [4082/10940] ---- BYOL Training Loss = 0.3569951057434082
30-01-2023 01:48:14 INFO Epoch 1: [4093/10940] ---- BYOL Training Loss = 0.3497163951396942
30-01-2023 01:49:07 INFO Epoch 1: [4093/10940] ---- BYOL Validation Loss = 0.3282181918621063
30-01-2023 01:49:24 INFO Epoch 1: [4104/10940] ---- BYOL Training Loss = 0.3548949360847473
30-01-2023 01:49:42 INFO Epoch 1: [4115/10940] ---- BYOL Training Loss = 0.34974926710128784
30-01-2023 01:50:00 INFO Epoch 1: [4126/10940] ---- BYOL Training Loss = 0.36870521306991577
30-01-2023 01:50:18 INFO Epoch 1: [4137/10940] ---- BYOL Training Loss = 0.36311525106430054
30-01-2023 01:51:11 INFO Epoch 1: [4137/10940] ---- BYOL Validation Loss = 0.34312132000923157
30-01-2023 01:51:28 INFO Epoch 1: [4148/10940] ---- BYOL Training Loss = 0.3181390166282654
30-01-2023 01:51:46 INFO Epoch 1: [4159/10940] ---- BYOL Training Loss = 0.29320284724235535
30-01-2023 01:52:04 INFO Epoch 1: [4170/10940] ---- BYOL Training Loss = 0.3774113655090332
30-01-2023 01:52:22 INFO Epoch 1: [4181/10940] ---- BYOL Training Loss = 0.4029556214809418
30-01-2023 01:53:14 INFO Epoch 1: [4181/10940] ---- BYOL Validation Loss = 0.3151340186595917
30-01-2023 01:53:32 INFO Epoch 1: [4192/10940] ---- BYOL Training Loss = 0.36678728461265564
30-01-2023 01:53:50 INFO Epoch 1: [4203/10940] ---- BYOL Training Loss = 0.3340176045894623
30-01-2023 01:54:08 INFO Epoch 1: [4214/10940] ---- BYOL Training Loss = 0.33013859391212463
30-01-2023 01:54:26 INFO Epoch 1: [4225/10940] ---- BYOL Training Loss = 0.28830486536026
30-01-2023 01:55:19 INFO Epoch 1: [4225/10940] ---- BYOL Validation Loss = 0.3192767798900604
30-01-2023 01:55:36 INFO Epoch 1: [4236/10940] ---- BYOL Training Loss = 0.30637267231941223
30-01-2023 01:55:54 INFO Epoch 1: [4247/10940] ---- BYOL Training Loss = 0.36004042625427246
30-01-2023 01:56:12 INFO Epoch 1: [4258/10940] ---- BYOL Training Loss = 0.35769397020339966
30-01-2023 01:56:30 INFO Epoch 1: [4269/10940] ---- BYOL Training Loss = 0.34367719292640686
30-01-2023 01:57:23 INFO Epoch 1: [4269/10940] ---- BYOL Validation Loss = 0.33388015627861023
30-01-2023 01:57:40 INFO Epoch 1: [4280/10940] ---- BYOL Training Loss = 0.35007765889167786
30-01-2023 01:57:58 INFO Epoch 1: [4291/10940] ---- BYOL Training Loss = 0.34212300181388855
30-01-2023 01:58:16 INFO Epoch 1: [4302/10940] ---- BYOL Training Loss = 0.38204577565193176
30-01-2023 01:58:35 INFO Epoch 1: [4313/10940] ---- BYOL Training Loss = 0.35646089911460876
30-01-2023 01:59:27 INFO Epoch 1: [4313/10940] ---- BYOL Validation Loss = 0.3189637362957001
30-01-2023 01:59:45 INFO Epoch 1: [4324/10940] ---- BYOL Training Loss = 0.3046151399612427
30-01-2023 02:00:03 INFO Epoch 1: [4335/10940] ---- BYOL Training Loss = 0.32946664094924927
30-01-2023 02:00:21 INFO Epoch 1: [4346/10940] ---- BYOL Training Loss = 0.36122217774391174
30-01-2023 02:00:39 INFO Epoch 1: [4357/10940] ---- BYOL Training Loss = 0.35122331976890564
30-01-2023 02:01:31 INFO Epoch 1: [4357/10940] ---- BYOL Validation Loss = 0.33247110247612
30-01-2023 02:01:49 INFO Epoch 1: [4368/10940] ---- BYOL Training Loss = 0.3614785671234131
30-01-2023 02:02:07 INFO Epoch 1: [4379/10940] ---- BYOL Training Loss = 0.30610042810440063
30-01-2023 02:02:25 INFO Epoch 1: [4390/10940] ---- BYOL Training Loss = 0.31266477704048157
30-01-2023 02:02:43 INFO Epoch 1: [4401/10940] ---- BYOL Training Loss = 0.3542887270450592
30-01-2023 02:03:36 INFO Epoch 1: [4401/10940] ---- BYOL Validation Loss = 0.3386058211326599
30-01-2023 02:03:53 INFO Epoch 1: [4412/10940] ---- BYOL Training Loss = 0.3179672360420227
30-01-2023 02:04:11 INFO Epoch 1: [4423/10940] ---- BYOL Training Loss = 0.31394606828689575
30-01-2023 02:04:29 INFO Epoch 1: [4434/10940] ---- BYOL Training Loss = 0.31273749470710754
30-01-2023 02:04:47 INFO Epoch 1: [4445/10940] ---- BYOL Training Loss = 0.3294728696346283
30-01-2023 02:05:40 INFO Epoch 1: [4445/10940] ---- BYOL Validation Loss = 0.3192385137081146
30-01-2023 02:05:58 INFO Epoch 1: [4456/10940] ---- BYOL Training Loss = 0.3193604350090027
30-01-2023 02:06:16 INFO Epoch 1: [4467/10940] ---- BYOL Training Loss = 0.3216661214828491
30-01-2023 02:06:34 INFO Epoch 1: [4478/10940] ---- BYOL Training Loss = 0.3363889455795288
30-01-2023 02:06:52 INFO Epoch 1: [4489/10940] ---- BYOL Training Loss = 0.3459871709346771
30-01-2023 02:07:44 INFO Epoch 1: [4489/10940] ---- BYOL Validation Loss = 0.3119983673095703
30-01-2023 02:08:02 INFO Epoch 1: [4500/10940] ---- BYOL Training Loss = 0.3584783673286438
30-01-2023 02:08:20 INFO Epoch 1: [4511/10940] ---- BYOL Training Loss = 0.3253503143787384
30-01-2023 02:08:38 INFO Epoch 1: [4522/10940] ---- BYOL Training Loss = 0.313249409198761
30-01-2023 02:08:56 INFO Epoch 1: [4533/10940] ---- BYOL Training Loss = 0.38320714235305786
30-01-2023 02:09:49 INFO Epoch 1: [4533/10940] ---- BYOL Validation Loss = 0.31695792078971863
30-01-2023 02:10:06 INFO Epoch 1: [4544/10940] ---- BYOL Training Loss = 0.3518823981285095
30-01-2023 02:10:25 INFO Epoch 1: [4555/10940] ---- BYOL Training Loss = 0.30131983757019043
30-01-2023 02:10:43 INFO Epoch 1: [4566/10940] ---- BYOL Training Loss = 0.2872135043144226
30-01-2023 02:11:00 INFO Epoch 1: [4577/10940] ---- BYOL Training Loss = 0.36351993680000305
30-01-2023 02:11:53 INFO Epoch 1: [4577/10940] ---- BYOL Validation Loss = 0.31818056106567383
30-01-2023 02:12:11 INFO Epoch 1: [4588/10940] ---- BYOL Training Loss = 0.4346657395362854
30-01-2023 02:12:29 INFO Epoch 1: [4599/10940] ---- BYOL Training Loss = 0.34864717721939087
30-01-2023 02:12:47 INFO Epoch 1: [4610/10940] ---- BYOL Training Loss = 0.33960777521133423
30-01-2023 02:13:05 INFO Epoch 1: [4621/10940] ---- BYOL Training Loss = 0.31099581718444824
30-01-2023 02:13:58 INFO Epoch 1: [4621/10940] ---- BYOL Validation Loss = 0.3099123537540436
30-01-2023 02:14:15 INFO Epoch 1: [4632/10940] ---- BYOL Training Loss = 0.3025926649570465
30-01-2023 02:14:33 INFO Epoch 1: [4643/10940] ---- BYOL Training Loss = 0.31693756580352783
30-01-2023 02:14:51 INFO Epoch 1: [4654/10940] ---- BYOL Training Loss = 0.32634642720222473
30-01-2023 02:15:09 INFO Epoch 1: [4665/10940] ---- BYOL Training Loss = 0.2886999249458313
30-01-2023 02:16:02 INFO Epoch 1: [4665/10940] ---- BYOL Validation Loss = 0.3130756914615631
30-01-2023 02:16:20 INFO Epoch 1: [4676/10940] ---- BYOL Training Loss = 0.31133487820625305
30-01-2023 02:16:38 INFO Epoch 1: [4687/10940] ---- BYOL Training Loss = 0.35361191630363464
30-01-2023 02:16:56 INFO Epoch 1: [4698/10940] ---- BYOL Training Loss = 0.369900643825531
30-01-2023 02:17:14 INFO Epoch 1: [4709/10940] ---- BYOL Training Loss = 0.38525447249412537
30-01-2023 02:18:06 INFO Epoch 1: [4709/10940] ---- BYOL Validation Loss = 0.3177050054073334
30-01-2023 02:18:24 INFO Epoch 1: [4720/10940] ---- BYOL Training Loss = 0.34582656621932983
30-01-2023 02:18:42 INFO Epoch 1: [4731/10940] ---- BYOL Training Loss = 0.3416588306427002
30-01-2023 02:19:00 INFO Epoch 1: [4742/10940] ---- BYOL Training Loss = 0.3368251621723175
30-01-2023 02:19:18 INFO Epoch 1: [4753/10940] ---- BYOL Training Loss = 0.3543117642402649
30-01-2023 02:20:11 INFO Epoch 1: [4753/10940] ---- BYOL Validation Loss = 0.324290931224823
30-01-2023 02:20:29 INFO Epoch 1: [4764/10940] ---- BYOL Training Loss = 0.369490385055542
30-01-2023 02:20:47 INFO Epoch 1: [4775/10940] ---- BYOL Training Loss = 0.2755170166492462
30-01-2023 02:21:05 INFO Epoch 1: [4786/10940] ---- BYOL Training Loss = 0.34569746255874634
30-01-2023 02:21:23 INFO Epoch 1: [4797/10940] ---- BYOL Training Loss = 0.3629091680049896
30-01-2023 02:22:16 INFO Epoch 1: [4797/10940] ---- BYOL Validation Loss = 0.3146938681602478
30-01-2023 02:22:33 INFO Epoch 1: [4808/10940] ---- BYOL Training Loss = 0.32936176657676697
30-01-2023 02:22:51 INFO Epoch 1: [4819/10940] ---- BYOL Training Loss = 0.35078370571136475
30-01-2023 02:23:09 INFO Epoch 1: [4830/10940] ---- BYOL Training Loss = 0.33455514907836914
30-01-2023 02:23:28 INFO Epoch 1: [4841/10940] ---- BYOL Training Loss = 0.3341413140296936
30-01-2023 02:24:20 INFO Epoch 1: [4841/10940] ---- BYOL Validation Loss = 0.3203766345977783
30-01-2023 02:24:38 INFO Epoch 1: [4852/10940] ---- BYOL Training Loss = 0.36106598377227783
30-01-2023 02:24:56 INFO Epoch 1: [4863/10940] ---- BYOL Training Loss = 0.35037466883659363
30-01-2023 02:25:14 INFO Epoch 1: [4874/10940] ---- BYOL Training Loss = 0.3276531398296356
30-01-2023 02:25:32 INFO Epoch 1: [4885/10940] ---- BYOL Training Loss = 0.31870222091674805
30-01-2023 02:26:25 INFO Epoch 1: [4885/10940] ---- BYOL Validation Loss = 0.3205787241458893
30-01-2023 02:26:42 INFO Epoch 1: [4896/10940] ---- BYOL Training Loss = 0.34147292375564575
30-01-2023 02:27:00 INFO Epoch 1: [4907/10940] ---- BYOL Training Loss = 0.34608250856399536
30-01-2023 02:27:18 INFO Epoch 1: [4918/10940] ---- BYOL Training Loss = 0.31060612201690674
30-01-2023 02:27:36 INFO Epoch 1: [4929/10940] ---- BYOL Training Loss = 0.3188954293727875
30-01-2023 02:28:29 INFO Epoch 1: [4929/10940] ---- BYOL Validation Loss = 0.34101465344429016
30-01-2023 02:28:47 INFO Epoch 1: [4940/10940] ---- BYOL Training Loss = 0.3381258249282837
30-01-2023 02:29:05 INFO Epoch 1: [4951/10940] ---- BYOL Training Loss = 0.35484498739242554
30-01-2023 02:29:23 INFO Epoch 1: [4962/10940] ---- BYOL Training Loss = 0.38080403208732605
30-01-2023 02:29:41 INFO Epoch 1: [4973/10940] ---- BYOL Training Loss = 0.3155544102191925
30-01-2023 02:30:34 INFO Epoch 1: [4973/10940] ---- BYOL Validation Loss = 0.3205198645591736
30-01-2023 02:30:51 INFO Epoch 1: [4984/10940] ---- BYOL Training Loss = 0.2545818090438843
30-01-2023 02:31:10 INFO Epoch 1: [4995/10940] ---- BYOL Training Loss = 0.2778491973876953
30-01-2023 02:31:28 INFO Epoch 1: [5006/10940] ---- BYOL Training Loss = 0.3300747275352478
30-01-2023 02:31:46 INFO Epoch 1: [5017/10940] ---- BYOL Training Loss = 0.3384637236595154
30-01-2023 02:32:38 INFO Epoch 1: [5017/10940] ---- BYOL Validation Loss = 0.32749703526496887
30-01-2023 02:32:56 INFO Epoch 1: [5028/10940] ---- BYOL Training Loss = 0.3703441619873047
30-01-2023 02:33:14 INFO Epoch 1: [5039/10940] ---- BYOL Training Loss = 0.3783668577671051
30-01-2023 02:33:32 INFO Epoch 1: [5050/10940] ---- BYOL Training Loss = 0.3454040288925171
30-01-2023 02:33:50 INFO Epoch 1: [5061/10940] ---- BYOL Training Loss = 0.3210076689720154
30-01-2023 02:34:43 INFO Epoch 1: [5061/10940] ---- BYOL Validation Loss = 0.312591016292572
30-01-2023 02:35:00 INFO Epoch 1: [5072/10940] ---- BYOL Training Loss = 0.2887815833091736
30-01-2023 02:35:19 INFO Epoch 1: [5083/10940] ---- BYOL Training Loss = 0.28381624817848206
30-01-2023 02:35:37 INFO Epoch 1: [5094/10940] ---- BYOL Training Loss = 0.3364109396934509
30-01-2023 02:35:55 INFO Epoch 1: [5105/10940] ---- BYOL Training Loss = 0.33792978525161743
30-01-2023 02:36:48 INFO Epoch 1: [5105/10940] ---- BYOL Validation Loss = 0.3050333857536316
30-01-2023 02:37:05 INFO Epoch 1: [5116/10940] ---- BYOL Training Loss = 0.3132052719593048
30-01-2023 02:37:23 INFO Epoch 1: [5127/10940] ---- BYOL Training Loss = 0.2814588248729706
30-01-2023 02:37:41 INFO Epoch 1: [5138/10940] ---- BYOL Training Loss = 0.31492868065834045
30-01-2023 02:38:00 INFO Epoch 1: [5149/10940] ---- BYOL Training Loss = 0.30857008695602417
30-01-2023 02:38:52 INFO Epoch 1: [5149/10940] ---- BYOL Validation Loss = 0.32063981890678406
30-01-2023 02:39:10 INFO Epoch 1: [5160/10940] ---- BYOL Training Loss = 0.29142385721206665
30-01-2023 02:39:28 INFO Epoch 1: [5171/10940] ---- BYOL Training Loss = 0.34507110714912415
30-01-2023 02:39:46 INFO Epoch 1: [5182/10940] ---- BYOL Training Loss = 0.3402468264102936
30-01-2023 02:40:04 INFO Epoch 1: [5193/10940] ---- BYOL Training Loss = 0.32060274481773376
30-01-2023 02:40:57 INFO Epoch 1: [5193/10940] ---- BYOL Validation Loss = 0.3152598738670349
30-01-2023 02:41:15 INFO Epoch 1: [5204/10940] ---- BYOL Training Loss = 0.35254842042922974
30-01-2023 02:41:33 INFO Epoch 1: [5215/10940] ---- BYOL Training Loss = 0.4036600589752197
30-01-2023 02:41:51 INFO Epoch 1: [5226/10940] ---- BYOL Training Loss = 0.3709433078765869
30-01-2023 02:42:09 INFO Epoch 1: [5237/10940] ---- BYOL Training Loss = 0.33384591341018677
30-01-2023 02:43:01 INFO Epoch 1: [5237/10940] ---- BYOL Validation Loss = 0.3154822289943695
30-01-2023 02:43:19 INFO Epoch 1: [5248/10940] ---- BYOL Training Loss = 0.3642292022705078
30-01-2023 02:43:37 INFO Epoch 1: [5259/10940] ---- BYOL Training Loss = 0.32118475437164307
30-01-2023 02:43:55 INFO Epoch 1: [5270/10940] ---- BYOL Training Loss = 0.3511665463447571
30-01-2023 02:44:13 INFO Epoch 1: [5281/10940] ---- BYOL Training Loss = 0.3540742099285126
30-01-2023 02:45:06 INFO Epoch 1: [5281/10940] ---- BYOL Validation Loss = 0.3176264762878418
30-01-2023 02:45:24 INFO Epoch 1: [5292/10940] ---- BYOL Training Loss = 0.38127896189689636
30-01-2023 02:45:42 INFO Epoch 1: [5303/10940] ---- BYOL Training Loss = 0.41034436225891113
30-01-2023 02:46:00 INFO Epoch 1: [5314/10940] ---- BYOL Training Loss = 0.34742382168769836
30-01-2023 02:46:18 INFO Epoch 1: [5325/10940] ---- BYOL Training Loss = 0.34274616837501526
30-01-2023 02:47:11 INFO Epoch 1: [5325/10940] ---- BYOL Validation Loss = 0.31931713223457336
30-01-2023 02:47:28 INFO Epoch 1: [5336/10940] ---- BYOL Training Loss = 0.3364853858947754
30-01-2023 02:47:46 INFO Epoch 1: [5347/10940] ---- BYOL Training Loss = 0.3420112133026123
30-01-2023 02:48:05 INFO Epoch 1: [5358/10940] ---- BYOL Training Loss = 0.32792696356773376
30-01-2023 02:48:23 INFO Epoch 1: [5369/10940] ---- BYOL Training Loss = 0.3279973566532135
30-01-2023 02:49:15 INFO Epoch 1: [5369/10940] ---- BYOL Validation Loss = 0.3220141530036926
30-01-2023 02:49:33 INFO Epoch 1: [5380/10940] ---- BYOL Training Loss = 0.328734815120697
30-01-2023 02:49:51 INFO Epoch 1: [5391/10940] ---- BYOL Training Loss = 0.317125529050827
30-01-2023 02:50:10 INFO Epoch 1: [5402/10940] ---- BYOL Training Loss = 0.3133453130722046
30-01-2023 02:50:28 INFO Epoch 1: [5413/10940] ---- BYOL Training Loss = 0.2975311279296875
30-01-2023 02:51:20 INFO Epoch 1: [5413/10940] ---- BYOL Validation Loss = 0.32343626022338867
30-01-2023 02:51:38 INFO Epoch 1: [5424/10940] ---- BYOL Training Loss = 0.29831555485725403
30-01-2023 02:51:56 INFO Epoch 1: [5435/10940] ---- BYOL Training Loss = 0.30966717004776
30-01-2023 02:52:14 INFO Epoch 1: [5446/10940] ---- BYOL Training Loss = 0.3229874074459076
30-01-2023 02:52:32 INFO Epoch 1: [5457/10940] ---- BYOL Training Loss = 0.327555388212204
30-01-2023 02:53:25 INFO Epoch 1: [5457/10940] ---- BYOL Validation Loss = 0.31826430559158325
30-01-2023 02:53:43 INFO Epoch 1: [5468/10940] ---- BYOL Training Loss = 0.35316142439842224
30-01-2023 02:54:01 INFO Epoch 1: [5479/10940] ---- BYOL Training Loss = 0.3682294189929962
30-01-2023 02:54:19 INFO Epoch 1: [5490/10940] ---- BYOL Training Loss = 0.41212692856788635
30-01-2023 02:54:37 INFO Epoch 1: [5501/10940] ---- BYOL Training Loss = 0.32516008615493774
30-01-2023 02:55:30 INFO Epoch 1: [5501/10940] ---- BYOL Validation Loss = 0.31803634762763977
30-01-2023 02:55:48 INFO Epoch 1: [5512/10940] ---- BYOL Training Loss = 0.320624440908432
30-01-2023 02:56:06 INFO Epoch 1: [5523/10940] ---- BYOL Training Loss = 0.3757665455341339
30-01-2023 02:56:24 INFO Epoch 1: [5534/10940] ---- BYOL Training Loss = 0.34317439794540405
30-01-2023 02:56:42 INFO Epoch 1: [5545/10940] ---- BYOL Training Loss = 0.31225496530532837
30-01-2023 02:57:35 INFO Epoch 1: [5545/10940] ---- BYOL Validation Loss = 0.3132082521915436
30-01-2023 02:57:53 INFO Epoch 1: [5556/10940] ---- BYOL Training Loss = 0.3345186412334442
30-01-2023 02:58:11 INFO Epoch 1: [5567/10940] ---- BYOL Training Loss = 0.34298214316368103
30-01-2023 02:58:29 INFO Epoch 1: [5578/10940] ---- BYOL Training Loss = 0.2946736216545105
30-01-2023 02:58:47 INFO Epoch 1: [5589/10940] ---- BYOL Training Loss = 0.30045706033706665
30-01-2023 02:59:39 INFO Epoch 1: [5589/10940] ---- BYOL Validation Loss = 0.3233155608177185
30-01-2023 02:59:58 INFO Epoch 1: [5600/10940] ---- BYOL Training Loss = 0.3393191993236542
30-01-2023 03:00:16 INFO Epoch 1: [5611/10940] ---- BYOL Training Loss = 0.3110116124153137
30-01-2023 03:00:34 INFO Epoch 1: [5622/10940] ---- BYOL Training Loss = 0.3076348900794983
30-01-2023 03:00:52 INFO Epoch 1: [5633/10940] ---- BYOL Training Loss = 0.34486427903175354
30-01-2023 03:01:44 INFO Epoch 1: [5633/10940] ---- BYOL Validation Loss = 0.31765609979629517
30-01-2023 03:02:02 INFO Epoch 1: [5644/10940] ---- BYOL Training Loss = 0.3947039842605591
30-01-2023 03:02:20 INFO Epoch 1: [5655/10940] ---- BYOL Training Loss = 0.3864213526248932
30-01-2023 03:02:38 INFO Epoch 1: [5666/10940] ---- BYOL Training Loss = 0.32849183678627014
30-01-2023 03:02:57 INFO Epoch 1: [5677/10940] ---- BYOL Training Loss = 0.3339022994041443
30-01-2023 03:03:49 INFO Epoch 1: [5677/10940] ---- BYOL Validation Loss = 0.32343626022338867
30-01-2023 03:04:07 INFO Epoch 1: [5688/10940] ---- BYOL Training Loss = 0.3370417654514313
30-01-2023 03:04:25 INFO Epoch 1: [5699/10940] ---- BYOL Training Loss = 0.41558948159217834
30-01-2023 03:04:43 INFO Epoch 1: [5710/10940] ---- BYOL Training Loss = 0.42109403014183044
30-01-2023 03:05:02 INFO Epoch 1: [5721/10940] ---- BYOL Training Loss = 0.3304709196090698
30-01-2023 03:05:54 INFO Epoch 1: [5721/10940] ---- BYOL Validation Loss = 0.31045040488243103
30-01-2023 03:06:12 INFO Epoch 1: [5732/10940] ---- BYOL Training Loss = 0.27535590529441833
30-01-2023 03:06:31 INFO Epoch 1: [5743/10940] ---- BYOL Training Loss = 0.2534845173358917
30-01-2023 03:06:49 INFO Epoch 1: [5754/10940] ---- BYOL Training Loss = 0.28449657559394836
30-01-2023 03:07:07 INFO Epoch 1: [5765/10940] ---- BYOL Training Loss = 0.3261668086051941
30-01-2023 03:07:59 INFO Epoch 1: [5765/10940] ---- BYOL Validation Loss = 0.3133120536804199
30-01-2023 03:08:17 INFO Epoch 1: [5776/10940] ---- BYOL Training Loss = 0.32702311873435974
30-01-2023 03:08:35 INFO Epoch 1: [5787/10940] ---- BYOL Training Loss = 0.3201359510421753
30-01-2023 03:08:53 INFO Epoch 1: [5798/10940] ---- BYOL Training Loss = 0.3358224630355835
30-01-2023 03:09:12 INFO Epoch 1: [5809/10940] ---- BYOL Training Loss = 0.2664397060871124
30-01-2023 03:10:04 INFO Epoch 1: [5809/10940] ---- BYOL Validation Loss = 0.3014299273490906
30-01-2023 03:10:22 INFO Epoch 1: [5820/10940] ---- BYOL Training Loss = 0.2630879580974579
30-01-2023 03:10:40 INFO Epoch 1: [5831/10940] ---- BYOL Training Loss = 0.32136911153793335
30-01-2023 03:10:59 INFO Epoch 1: [5842/10940] ---- BYOL Training Loss = 0.31202828884124756
30-01-2023 03:11:17 INFO Epoch 1: [5853/10940] ---- BYOL Training Loss = 0.3017069697380066
30-01-2023 03:12:09 INFO Epoch 1: [5853/10940] ---- BYOL Validation Loss = 0.31635281443595886
30-01-2023 03:12:27 INFO Epoch 1: [5864/10940] ---- BYOL Training Loss = 0.3123432993888855
30-01-2023 03:12:45 INFO Epoch 1: [5875/10940] ---- BYOL Training Loss = 0.3511226177215576
30-01-2023 03:13:03 INFO Epoch 1: [5886/10940] ---- BYOL Training Loss = 0.32197484374046326
30-01-2023 03:13:22 INFO Epoch 1: [5897/10940] ---- BYOL Training Loss = 0.3021634817123413
30-01-2023 03:14:14 INFO Epoch 1: [5897/10940] ---- BYOL Validation Loss = 0.29939937591552734
30-01-2023 03:14:32 INFO Epoch 1: [5908/10940] ---- BYOL Training Loss = 0.31183499097824097
30-01-2023 03:14:50 INFO Epoch 1: [5919/10940] ---- BYOL Training Loss = 0.29977622628211975
30-01-2023 03:15:08 INFO Epoch 1: [5930/10940] ---- BYOL Training Loss = 0.32127857208251953
30-01-2023 03:15:26 INFO Epoch 1: [5941/10940] ---- BYOL Training Loss = 0.3378612697124481
30-01-2023 03:16:19 INFO Epoch 1: [5941/10940] ---- BYOL Validation Loss = 0.3145539164543152
30-01-2023 03:16:36 INFO Epoch 1: [5952/10940] ---- BYOL Training Loss = 0.32561057806015015
30-01-2023 03:16:55 INFO Epoch 1: [5963/10940] ---- BYOL Training Loss = 0.3077217936515808
30-01-2023 03:17:13 INFO Epoch 1: [5974/10940] ---- BYOL Training Loss = 0.34322279691696167
30-01-2023 03:17:31 INFO Epoch 1: [5985/10940] ---- BYOL Training Loss = 0.28978511691093445
30-01-2023 03:18:24 INFO Epoch 1: [5985/10940] ---- BYOL Validation Loss = 0.30626267194747925
30-01-2023 03:18:41 INFO Epoch 1: [5996/10940] ---- BYOL Training Loss = 0.2899304926395416
30-01-2023 03:19:00 INFO Epoch 1: [6007/10940] ---- BYOL Training Loss = 0.34429246187210083
30-01-2023 03:19:18 INFO Epoch 1: [6018/10940] ---- BYOL Training Loss = 0.3288176953792572
30-01-2023 03:19:36 INFO Epoch 1: [6029/10940] ---- BYOL Training Loss = 0.3038064241409302
30-01-2023 03:20:29 INFO Epoch 1: [6029/10940] ---- BYOL Validation Loss = 0.3131633400917053
30-01-2023 03:20:46 INFO Epoch 1: [6040/10940] ---- BYOL Training Loss = 0.2803838849067688
30-01-2023 03:21:05 INFO Epoch 1: [6051/10940] ---- BYOL Training Loss = 0.2877054512500763
30-01-2023 03:21:23 INFO Epoch 1: [6062/10940] ---- BYOL Training Loss = 0.3245747685432434
30-01-2023 03:21:41 INFO Epoch 1: [6073/10940] ---- BYOL Training Loss = 0.32795852422714233
30-01-2023 03:22:34 INFO Epoch 1: [6073/10940] ---- BYOL Validation Loss = 0.3161540925502777
30-01-2023 03:22:51 INFO Epoch 1: [6084/10940] ---- BYOL Training Loss = 0.32982999086380005
30-01-2023 03:23:10 INFO Epoch 1: [6095/10940] ---- BYOL Training Loss = 0.325813353061676
30-01-2023 03:23:28 INFO Epoch 1: [6106/10940] ---- BYOL Training Loss = 0.3288728594779968
30-01-2023 03:23:46 INFO Epoch 1: [6117/10940] ---- BYOL Training Loss = 0.3616197109222412
30-01-2023 03:24:39 INFO Epoch 1: [6117/10940] ---- BYOL Validation Loss = 0.31644824147224426
30-01-2023 03:24:56 INFO Epoch 1: [6128/10940] ---- BYOL Training Loss = 0.33322373032569885
30-01-2023 03:25:15 INFO Epoch 1: [6139/10940] ---- BYOL Training Loss = 0.3433302640914917
30-01-2023 03:25:33 INFO Epoch 1: [6150/10940] ---- BYOL Training Loss = 0.3678206503391266
30-01-2023 03:25:51 INFO Epoch 1: [6161/10940] ---- BYOL Training Loss = 0.3399493992328644
30-01-2023 03:26:44 INFO Epoch 1: [6161/10940] ---- BYOL Validation Loss = 0.3008682429790497
30-01-2023 03:27:02 INFO Epoch 1: [6172/10940] ---- BYOL Training Loss = 0.32118040323257446
30-01-2023 03:27:20 INFO Epoch 1: [6183/10940] ---- BYOL Training Loss = 0.2917085587978363
30-01-2023 03:27:38 INFO Epoch 1: [6194/10940] ---- BYOL Training Loss = 0.2956164479255676
30-01-2023 03:27:56 INFO Epoch 1: [6205/10940] ---- BYOL Training Loss = 0.3127809166908264
30-01-2023 03:28:49 INFO Epoch 1: [6205/10940] ---- BYOL Validation Loss = 0.30792906880378723
30-01-2023 03:29:06 INFO Epoch 1: [6216/10940] ---- BYOL Training Loss = 0.3742066025733948
30-01-2023 03:29:25 INFO Epoch 1: [6227/10940] ---- BYOL Training Loss = 0.35268935561180115
30-01-2023 03:29:43 INFO Epoch 1: [6238/10940] ---- BYOL Training Loss = 0.31442883610725403
30-01-2023 03:30:01 INFO Epoch 1: [6249/10940] ---- BYOL Training Loss = 0.32299381494522095
30-01-2023 03:30:54 INFO Epoch 1: [6249/10940] ---- BYOL Validation Loss = 0.3146939277648926
30-01-2023 03:31:11 INFO Epoch 1: [6260/10940] ---- BYOL Training Loss = 0.3294965326786041
30-01-2023 03:31:30 INFO Epoch 1: [6271/10940] ---- BYOL Training Loss = 0.32027295231819153
30-01-2023 03:31:48 INFO Epoch 1: [6282/10940] ---- BYOL Training Loss = 0.35109153389930725
30-01-2023 03:32:06 INFO Epoch 1: [6293/10940] ---- BYOL Training Loss = 0.35431915521621704
30-01-2023 03:32:59 INFO Epoch 1: [6293/10940] ---- BYOL Validation Loss = 0.304381400346756
30-01-2023 03:33:17 INFO Epoch 1: [6304/10940] ---- BYOL Training Loss = 0.3438568711280823
30-01-2023 03:33:35 INFO Epoch 1: [6315/10940] ---- BYOL Training Loss = 0.3749886453151703
30-01-2023 03:33:53 INFO Epoch 1: [6326/10940] ---- BYOL Training Loss = 0.34452491998672485
30-01-2023 03:34:11 INFO Epoch 1: [6337/10940] ---- BYOL Training Loss = 0.34717410802841187
30-01-2023 03:35:04 INFO Epoch 1: [6337/10940] ---- BYOL Validation Loss = 0.30365943908691406
30-01-2023 03:35:22 INFO Epoch 1: [6348/10940] ---- BYOL Training Loss = 0.3280520439147949
30-01-2023 03:35:40 INFO Epoch 1: [6359/10940] ---- BYOL Training Loss = 0.32572340965270996
30-01-2023 03:35:58 INFO Epoch 1: [6370/10940] ---- BYOL Training Loss = 0.3312223553657532
30-01-2023 03:36:16 INFO Epoch 1: [6381/10940] ---- BYOL Training Loss = 0.2717009484767914
30-01-2023 03:37:09 INFO Epoch 1: [6381/10940] ---- BYOL Validation Loss = 0.3026050925254822
30-01-2023 03:37:27 INFO Epoch 1: [6392/10940] ---- BYOL Training Loss = 0.3102906346321106
30-01-2023 03:37:45 INFO Epoch 1: [6403/10940] ---- BYOL Training Loss = 0.389695942401886
30-01-2023 03:38:03 INFO Epoch 1: [6414/10940] ---- BYOL Training Loss = 0.3394719958305359
30-01-2023 03:38:22 INFO Epoch 1: [6425/10940] ---- BYOL Training Loss = 0.31896841526031494
30-01-2023 03:39:14 INFO Epoch 1: [6425/10940] ---- BYOL Validation Loss = 0.30890029668807983
30-01-2023 03:39:32 INFO Epoch 1: [6436/10940] ---- BYOL Training Loss = 0.3541933000087738
30-01-2023 03:39:51 INFO Epoch 1: [6447/10940] ---- BYOL Training Loss = 0.3692670464515686
30-01-2023 03:40:09 INFO Epoch 1: [6458/10940] ---- BYOL Training Loss = 0.3152361214160919
30-01-2023 03:40:27 INFO Epoch 1: [6469/10940] ---- BYOL Training Loss = 0.26966145634651184
30-01-2023 03:41:20 INFO Epoch 1: [6469/10940] ---- BYOL Validation Loss = 0.31217989325523376
30-01-2023 03:41:38 INFO Epoch 1: [6480/10940] ---- BYOL Training Loss = 0.2645353078842163
30-01-2023 03:41:56 INFO Epoch 1: [6491/10940] ---- BYOL Training Loss = 0.28413838148117065
30-01-2023 03:42:14 INFO Epoch 1: [6502/10940] ---- BYOL Training Loss = 0.3185086250305176
30-01-2023 03:42:32 INFO Epoch 1: [6513/10940] ---- BYOL Training Loss = 0.35525569319725037
30-01-2023 03:43:24 INFO Epoch 1: [6513/10940] ---- BYOL Validation Loss = 0.3058205246925354
30-01-2023 03:43:43 INFO Epoch 1: [6524/10940] ---- BYOL Training Loss = 0.3292106091976166
30-01-2023 03:44:01 INFO Epoch 1: [6535/10940] ---- BYOL Training Loss = 0.2734474539756775
30-01-2023 03:44:19 INFO Epoch 1: [6546/10940] ---- BYOL Training Loss = 0.3166787326335907
30-01-2023 03:44:38 INFO Epoch 1: [6557/10940] ---- BYOL Training Loss = 0.31283923983573914
30-01-2023 03:45:30 INFO Epoch 1: [6557/10940] ---- BYOL Validation Loss = 0.2940852642059326
30-01-2023 03:45:48 INFO Epoch 1: [6568/10940] ---- BYOL Training Loss = 0.3055093288421631
30-01-2023 03:46:06 INFO Epoch 1: [6579/10940] ---- BYOL Training Loss = 0.3603540360927582
30-01-2023 03:46:24 INFO Epoch 1: [6590/10940] ---- BYOL Training Loss = 0.34862202405929565
30-01-2023 03:46:42 INFO Epoch 1: [6601/10940] ---- BYOL Training Loss = 0.3162357211112976
30-01-2023 03:47:35 INFO Epoch 1: [6601/10940] ---- BYOL Validation Loss = 0.29851770401000977
30-01-2023 03:47:53 INFO Epoch 1: [6612/10940] ---- BYOL Training Loss = 0.3144370913505554
30-01-2023 03:48:11 INFO Epoch 1: [6623/10940] ---- BYOL Training Loss = 0.2797170579433441
30-01-2023 03:48:29 INFO Epoch 1: [6634/10940] ---- BYOL Training Loss = 0.2858423590660095
30-01-2023 03:48:48 INFO Epoch 1: [6645/10940] ---- BYOL Training Loss = 0.3295164704322815
30-01-2023 03:49:40 INFO Epoch 1: [6645/10940] ---- BYOL Validation Loss = 0.2967233657836914
30-01-2023 03:49:58 INFO Epoch 1: [6656/10940] ---- BYOL Training Loss = 0.3702714741230011
30-01-2023 03:50:16 INFO Epoch 1: [6667/10940] ---- BYOL Training Loss = 0.38033467531204224
30-01-2023 03:50:34 INFO Epoch 1: [6678/10940] ---- BYOL Training Loss = 0.3660133481025696
30-01-2023 03:50:53 INFO Epoch 1: [6689/10940] ---- BYOL Training Loss = 0.33686429262161255
30-01-2023 03:51:45 INFO Epoch 1: [6689/10940] ---- BYOL Validation Loss = 0.3075839579105377
30-01-2023 03:52:03 INFO Epoch 1: [6700/10940] ---- BYOL Training Loss = 0.2954661250114441
30-01-2023 03:52:21 INFO Epoch 1: [6711/10940] ---- BYOL Training Loss = 0.2838088274002075
30-01-2023 03:52:40 INFO Epoch 1: [6722/10940] ---- BYOL Training Loss = 0.2794550657272339
30-01-2023 03:52:58 INFO Epoch 1: [6733/10940] ---- BYOL Training Loss = 0.3061838746070862
30-01-2023 03:53:51 INFO Epoch 1: [6733/10940] ---- BYOL Validation Loss = 0.294348806142807
30-01-2023 03:54:09 INFO Epoch 1: [6744/10940] ---- BYOL Training Loss = 0.37843814492225647
30-01-2023 03:54:27 INFO Epoch 1: [6755/10940] ---- BYOL Training Loss = 0.36760324239730835
30-01-2023 03:54:45 INFO Epoch 1: [6766/10940] ---- BYOL Training Loss = 0.2936555743217468
30-01-2023 03:55:03 INFO Epoch 1: [6777/10940] ---- BYOL Training Loss = 0.3021419048309326
30-01-2023 03:55:56 INFO Epoch 1: [6777/10940] ---- BYOL Validation Loss = 0.29370054602622986
30-01-2023 03:56:14 INFO Epoch 1: [6788/10940] ---- BYOL Training Loss = 0.28965041041374207
30-01-2023 03:56:32 INFO Epoch 1: [6799/10940] ---- BYOL Training Loss = 0.2771156430244446
30-01-2023 03:56:50 INFO Epoch 1: [6810/10940] ---- BYOL Training Loss = 0.259748637676239
30-01-2023 03:57:09 INFO Epoch 1: [6821/10940] ---- BYOL Training Loss = 0.2550109028816223
30-01-2023 03:58:01 INFO Epoch 1: [6821/10940] ---- BYOL Validation Loss = 0.28618890047073364
30-01-2023 03:58:19 INFO Epoch 1: [6832/10940] ---- BYOL Training Loss = 0.3040023148059845
30-01-2023 03:58:38 INFO Epoch 1: [6843/10940] ---- BYOL Training Loss = 0.3041780889034271
30-01-2023 03:58:56 INFO Epoch 1: [6854/10940] ---- BYOL Training Loss = 0.26783767342567444
30-01-2023 03:59:14 INFO Epoch 1: [6865/10940] ---- BYOL Training Loss = 0.2875819206237793
30-01-2023 04:00:06 INFO Epoch 1: [6865/10940] ---- BYOL Validation Loss = 0.29108765721321106
30-01-2023 04:00:24 INFO Epoch 1: [6876/10940] ---- BYOL Training Loss = 0.29117560386657715
30-01-2023 04:00:43 INFO Epoch 1: [6887/10940] ---- BYOL Training Loss = 0.2926943302154541
30-01-2023 04:01:01 INFO Epoch 1: [6898/10940] ---- BYOL Training Loss = 0.2807706296443939
30-01-2023 04:01:19 INFO Epoch 1: [6909/10940] ---- BYOL Training Loss = 0.32450440526008606
30-01-2023 04:02:12 INFO Epoch 1: [6909/10940] ---- BYOL Validation Loss = 0.2991805076599121
30-01-2023 04:02:30 INFO Epoch 1: [6920/10940] ---- BYOL Training Loss = 0.37663888931274414
30-01-2023 04:02:48 INFO Epoch 1: [6931/10940] ---- BYOL Training Loss = 0.321919322013855
30-01-2023 04:03:06 INFO Epoch 1: [6942/10940] ---- BYOL Training Loss = 0.2808746099472046
30-01-2023 04:03:24 INFO Epoch 1: [6953/10940] ---- BYOL Training Loss = 0.340009868144989
30-01-2023 04:04:17 INFO Epoch 1: [6953/10940] ---- BYOL Validation Loss = 0.3028959631919861
30-01-2023 04:04:35 INFO Epoch 1: [6964/10940] ---- BYOL Training Loss = 0.3458578288555145
30-01-2023 04:04:53 INFO Epoch 1: [6975/10940] ---- BYOL Training Loss = 0.32725000381469727
30-01-2023 04:05:11 INFO Epoch 1: [6986/10940] ---- BYOL Training Loss = 0.3116348087787628
30-01-2023 04:05:29 INFO Epoch 1: [6997/10940] ---- BYOL Training Loss = 0.2834723889827728
30-01-2023 04:06:22 INFO Epoch 1: [6997/10940] ---- BYOL Validation Loss = 0.29267460107803345
30-01-2023 04:06:40 INFO Epoch 1: [7008/10940] ---- BYOL Training Loss = 0.32021135091781616
30-01-2023 04:06:58 INFO Epoch 1: [7019/10940] ---- BYOL Training Loss = 0.3660739064216614
30-01-2023 04:07:17 INFO Epoch 1: [7030/10940] ---- BYOL Training Loss = 0.3337685465812683
30-01-2023 04:07:35 INFO Epoch 1: [7041/10940] ---- BYOL Training Loss = 0.3191220760345459
30-01-2023 04:08:27 INFO Epoch 1: [7041/10940] ---- BYOL Validation Loss = 0.2986700236797333
30-01-2023 04:08:45 INFO Epoch 1: [7052/10940] ---- BYOL Training Loss = 0.2725941240787506
30-01-2023 04:09:04 INFO Epoch 1: [7063/10940] ---- BYOL Training Loss = 0.24809618294239044
30-01-2023 04:09:22 INFO Epoch 1: [7074/10940] ---- BYOL Training Loss = 0.2893739342689514
30-01-2023 04:09:40 INFO Epoch 1: [7085/10940] ---- BYOL Training Loss = 0.33895793557167053
30-01-2023 04:10:33 INFO Epoch 1: [7085/10940] ---- BYOL Validation Loss = 0.28402191400527954
30-01-2023 04:10:51 INFO Epoch 1: [7096/10940] ---- BYOL Training Loss = 0.2783685028553009
30-01-2023 04:11:09 INFO Epoch 1: [7107/10940] ---- BYOL Training Loss = 0.262803852558136
30-01-2023 04:11:28 INFO Epoch 1: [7118/10940] ---- BYOL Training Loss = 0.28760212659835815
30-01-2023 04:11:46 INFO Epoch 1: [7129/10940] ---- BYOL Training Loss = 0.2971475422382355
30-01-2023 04:12:38 INFO Epoch 1: [7129/10940] ---- BYOL Validation Loss = 0.28958559036254883
30-01-2023 04:12:57 INFO Epoch 1: [7140/10940] ---- BYOL Training Loss = 0.33082935214042664
30-01-2023 04:13:15 INFO Epoch 1: [7151/10940] ---- BYOL Training Loss = 0.31340333819389343
30-01-2023 04:13:33 INFO Epoch 1: [7162/10940] ---- BYOL Training Loss = 0.31679782271385193
30-01-2023 04:13:52 INFO Epoch 1: [7173/10940] ---- BYOL Training Loss = 0.3367648720741272
30-01-2023 04:14:44 INFO Epoch 1: [7173/10940] ---- BYOL Validation Loss = 0.288345605134964
30-01-2023 04:15:02 INFO Epoch 1: [7184/10940] ---- BYOL Training Loss = 0.33628445863723755
30-01-2023 04:15:20 INFO Epoch 1: [7195/10940] ---- BYOL Training Loss = 0.3229983448982239
30-01-2023 04:15:38 INFO Epoch 1: [7206/10940] ---- BYOL Training Loss = 0.35288846492767334
30-01-2023 04:15:57 INFO Epoch 1: [7217/10940] ---- BYOL Training Loss = 0.3358137607574463
30-01-2023 04:16:50 INFO Epoch 1: [7217/10940] ---- BYOL Validation Loss = 0.3003252446651459
30-01-2023 04:17:07 INFO Epoch 1: [7228/10940] ---- BYOL Training Loss = 0.3610439896583557
30-01-2023 04:17:25 INFO Epoch 1: [7239/10940] ---- BYOL Training Loss = 0.35193610191345215
30-01-2023 04:17:44 INFO Epoch 1: [7250/10940] ---- BYOL Training Loss = 0.35766494274139404
30-01-2023 04:18:03 INFO Epoch 1: [7261/10940] ---- BYOL Training Loss = 0.36860376596450806
30-01-2023 04:18:55 INFO Epoch 1: [7261/10940] ---- BYOL Validation Loss = 0.2978513240814209
30-01-2023 04:19:13 INFO Epoch 1: [7272/10940] ---- BYOL Training Loss = 0.3723641335964203
30-01-2023 04:19:32 INFO Epoch 1: [7283/10940] ---- BYOL Training Loss = 0.3273434042930603
30-01-2023 04:19:50 INFO Epoch 1: [7294/10940] ---- BYOL Training Loss = 0.3130948543548584
30-01-2023 04:20:08 INFO Epoch 1: [7305/10940] ---- BYOL Training Loss = 0.30789071321487427
30-01-2023 04:21:01 INFO Epoch 1: [7305/10940] ---- BYOL Validation Loss = 0.3006095290184021
30-01-2023 04:21:19 INFO Epoch 1: [7316/10940] ---- BYOL Training Loss = 0.34728237986564636
30-01-2023 04:21:37 INFO Epoch 1: [7327/10940] ---- BYOL Training Loss = 0.32701510190963745
30-01-2023 04:21:56 INFO Epoch 1: [7338/10940] ---- BYOL Training Loss = 0.32073208689689636
30-01-2023 04:22:14 INFO Epoch 1: [7349/10940] ---- BYOL Training Loss = 0.3184243142604828
30-01-2023 04:23:06 INFO Epoch 1: [7349/10940] ---- BYOL Validation Loss = 0.3014696538448334
30-01-2023 04:23:25 INFO Epoch 1: [7360/10940] ---- BYOL Training Loss = 0.3279162645339966
30-01-2023 04:23:43 INFO Epoch 1: [7371/10940] ---- BYOL Training Loss = 0.3430500626564026
30-01-2023 04:24:01 INFO Epoch 1: [7382/10940] ---- BYOL Training Loss = 0.3399769365787506
30-01-2023 04:24:20 INFO Epoch 1: [7393/10940] ---- BYOL Training Loss = 0.31234440207481384
30-01-2023 04:25:12 INFO Epoch 1: [7393/10940] ---- BYOL Validation Loss = 0.3023501932621002
30-01-2023 04:25:30 INFO Epoch 1: [7404/10940] ---- BYOL Training Loss = 0.33535197377204895
30-01-2023 04:25:49 INFO Epoch 1: [7415/10940] ---- BYOL Training Loss = 0.29029494524002075
30-01-2023 04:26:07 INFO Epoch 1: [7426/10940] ---- BYOL Training Loss = 0.311145544052124
30-01-2023 04:26:26 INFO Epoch 1: [7437/10940] ---- BYOL Training Loss = 0.292347252368927
30-01-2023 04:27:18 INFO Epoch 1: [7437/10940] ---- BYOL Validation Loss = 0.3025236129760742
30-01-2023 04:27:36 INFO Epoch 1: [7448/10940] ---- BYOL Training Loss = 0.30282723903656006
30-01-2023 04:27:54 INFO Epoch 1: [7459/10940] ---- BYOL Training Loss = 0.34502506256103516
30-01-2023 04:28:13 INFO Epoch 1: [7470/10940] ---- BYOL Training Loss = 0.34782880544662476
30-01-2023 04:28:31 INFO Epoch 1: [7481/10940] ---- BYOL Training Loss = 0.3333264887332916
30-01-2023 04:29:24 INFO Epoch 1: [7481/10940] ---- BYOL Validation Loss = 0.2942526936531067
30-01-2023 04:29:41 INFO Epoch 1: [7492/10940] ---- BYOL Training Loss = 0.3269933760166168
30-01-2023 04:30:00 INFO Epoch 1: [7503/10940] ---- BYOL Training Loss = 0.2867925763130188
30-01-2023 04:30:18 INFO Epoch 1: [7514/10940] ---- BYOL Training Loss = 0.30439993739128113
30-01-2023 04:30:36 INFO Epoch 1: [7525/10940] ---- BYOL Training Loss = 0.3361760973930359
30-01-2023 04:31:29 INFO Epoch 1: [7525/10940] ---- BYOL Validation Loss = 0.28733059763908386
30-01-2023 04:31:47 INFO Epoch 1: [7536/10940] ---- BYOL Training Loss = 0.3258008360862732
30-01-2023 04:32:05 INFO Epoch 1: [7547/10940] ---- BYOL Training Loss = 0.3095034658908844
30-01-2023 04:32:24 INFO Epoch 1: [7558/10940] ---- BYOL Training Loss = 0.2507650554180145
30-01-2023 04:32:42 INFO Epoch 1: [7569/10940] ---- BYOL Training Loss = 0.2827037274837494
30-01-2023 04:33:35 INFO Epoch 1: [7569/10940] ---- BYOL Validation Loss = 0.2908255457878113
30-01-2023 04:33:52 INFO Epoch 1: [7580/10940] ---- BYOL Training Loss = 0.28833186626434326
30-01-2023 04:34:11 INFO Epoch 1: [7591/10940] ---- BYOL Training Loss = 0.2704121172428131
30-01-2023 04:34:29 INFO Epoch 1: [7602/10940] ---- BYOL Training Loss = 0.286840558052063
30-01-2023 04:34:47 INFO Epoch 1: [7613/10940] ---- BYOL Training Loss = 0.24515824019908905
30-01-2023 04:35:40 INFO Epoch 1: [7613/10940] ---- BYOL Validation Loss = 0.28349700570106506
30-01-2023 04:35:58 INFO Epoch 1: [7624/10940] ---- BYOL Training Loss = 0.2921348512172699
30-01-2023 04:36:16 INFO Epoch 1: [7635/10940] ---- BYOL Training Loss = 0.3243052661418915
30-01-2023 04:36:35 INFO Epoch 1: [7646/10940] ---- BYOL Training Loss = 0.28247004747390747
30-01-2023 04:36:53 INFO Epoch 1: [7657/10940] ---- BYOL Training Loss = 0.27298077940940857
30-01-2023 04:37:45 INFO Epoch 1: [7657/10940] ---- BYOL Validation Loss = 0.2950303852558136
30-01-2023 04:38:04 INFO Epoch 1: [7668/10940] ---- BYOL Training Loss = 0.30476754903793335
30-01-2023 04:38:22 INFO Epoch 1: [7679/10940] ---- BYOL Training Loss = 0.31502681970596313
30-01-2023 04:38:40 INFO Epoch 1: [7690/10940] ---- BYOL Training Loss = 0.30294427275657654
30-01-2023 04:38:59 INFO Epoch 1: [7701/10940] ---- BYOL Training Loss = 0.30850479006767273
30-01-2023 04:39:51 INFO Epoch 1: [7701/10940] ---- BYOL Validation Loss = 0.2996034026145935
30-01-2023 04:40:09 INFO Epoch 1: [7712/10940] ---- BYOL Training Loss = 0.3397615849971771
30-01-2023 04:40:27 INFO Epoch 1: [7723/10940] ---- BYOL Training Loss = 0.34779027104377747
30-01-2023 04:40:46 INFO Epoch 1: [7734/10940] ---- BYOL Training Loss = 0.2557825446128845
30-01-2023 04:41:04 INFO Epoch 1: [7745/10940] ---- BYOL Training Loss = 0.24120113253593445
30-01-2023 04:41:57 INFO Epoch 1: [7745/10940] ---- BYOL Validation Loss = 0.2891571521759033
30-01-2023 04:42:15 INFO Epoch 1: [7756/10940] ---- BYOL Training Loss = 0.2691684663295746
30-01-2023 04:42:33 INFO Epoch 1: [7767/10940] ---- BYOL Training Loss = 0.263570636510849
30-01-2023 04:42:52 INFO Epoch 1: [7778/10940] ---- BYOL Training Loss = 0.2887098789215088
30-01-2023 04:43:10 INFO Epoch 1: [7789/10940] ---- BYOL Training Loss = 0.36551108956336975
30-01-2023 04:44:02 INFO Epoch 1: [7789/10940] ---- BYOL Validation Loss = 0.295135498046875
30-01-2023 04:44:20 INFO Epoch 1: [7800/10940] ---- BYOL Training Loss = 0.32923558354377747
30-01-2023 04:44:39 INFO Epoch 1: [7811/10940] ---- BYOL Training Loss = 0.3068114221096039
30-01-2023 04:44:57 INFO Epoch 1: [7822/10940] ---- BYOL Training Loss = 0.3007794916629791
30-01-2023 04:45:15 INFO Epoch 1: [7833/10940] ---- BYOL Training Loss = 0.28695574402809143
30-01-2023 04:46:08 INFO Epoch 1: [7833/10940] ---- BYOL Validation Loss = 0.29315805435180664
30-01-2023 04:46:26 INFO Epoch 1: [7844/10940] ---- BYOL Training Loss = 0.3094586730003357
30-01-2023 04:46:44 INFO Epoch 1: [7855/10940] ---- BYOL Training Loss = 0.28443393111228943
30-01-2023 04:47:02 INFO Epoch 1: [7866/10940] ---- BYOL Training Loss = 0.29166465997695923
30-01-2023 04:47:21 INFO Epoch 1: [7877/10940] ---- BYOL Training Loss = 0.2919851839542389
30-01-2023 04:48:13 INFO Epoch 1: [7877/10940] ---- BYOL Validation Loss = 0.29580211639404297
30-01-2023 04:48:31 INFO Epoch 1: [7888/10940] ---- BYOL Training Loss = 0.2804473042488098
30-01-2023 04:48:50 INFO Epoch 1: [7899/10940] ---- BYOL Training Loss = 0.36723393201828003
30-01-2023 04:49:08 INFO Epoch 1: [7910/10940] ---- BYOL Training Loss = 0.3667398989200592
30-01-2023 04:49:27 INFO Epoch 1: [7921/10940] ---- BYOL Training Loss = 0.31391918659210205
30-01-2023 04:50:19 INFO Epoch 1: [7921/10940] ---- BYOL Validation Loss = 0.2933169901371002
30-01-2023 04:50:37 INFO Epoch 1: [7932/10940] ---- BYOL Training Loss = 0.33811917901039124
30-01-2023 04:50:56 INFO Epoch 1: [7943/10940] ---- BYOL Training Loss = 0.2916153073310852
30-01-2023 04:51:14 INFO Epoch 1: [7954/10940] ---- BYOL Training Loss = 0.28484025597572327
30-01-2023 04:51:33 INFO Epoch 1: [7965/10940] ---- BYOL Training Loss = 0.3099522888660431
30-01-2023 04:52:25 INFO Epoch 1: [7965/10940] ---- BYOL Validation Loss = 0.29607275128364563
30-01-2023 04:52:43 INFO Epoch 1: [7976/10940] ---- BYOL Training Loss = 0.30081111192703247
30-01-2023 04:53:01 INFO Epoch 1: [7987/10940] ---- BYOL Training Loss = 0.33975929021835327
30-01-2023 04:53:20 INFO Epoch 1: [7998/10940] ---- BYOL Training Loss = 0.32938092947006226
30-01-2023 04:53:38 INFO Epoch 1: [8009/10940] ---- BYOL Training Loss = 0.30977481603622437
30-01-2023 04:54:31 INFO Epoch 1: [8009/10940] ---- BYOL Validation Loss = 0.2905898690223694
30-01-2023 04:54:49 INFO Epoch 1: [8020/10940] ---- BYOL Training Loss = 0.30574488639831543
30-01-2023 04:55:08 INFO Epoch 1: [8031/10940] ---- BYOL Training Loss = 0.2882264256477356
30-01-2023 04:55:26 INFO Epoch 1: [8042/10940] ---- BYOL Training Loss = 0.2750297784805298
30-01-2023 04:55:45 INFO Epoch 1: [8053/10940] ---- BYOL Training Loss = 0.30735090374946594
30-01-2023 04:56:37 INFO Epoch 1: [8053/10940] ---- BYOL Validation Loss = 0.28530120849609375
30-01-2023 04:56:55 INFO Epoch 1: [8064/10940] ---- BYOL Training Loss = 0.2884846329689026
30-01-2023 04:57:13 INFO Epoch 1: [8075/10940] ---- BYOL Training Loss = 0.274417519569397
30-01-2023 04:57:32 INFO Epoch 1: [8086/10940] ---- BYOL Training Loss = 0.24571998417377472
30-01-2023 04:57:50 INFO Epoch 1: [8097/10940] ---- BYOL Training Loss = 0.2581297755241394
30-01-2023 04:58:43 INFO Epoch 1: [8097/10940] ---- BYOL Validation Loss = 0.2895025610923767
30-01-2023 04:59:01 INFO Epoch 1: [8108/10940] ---- BYOL Training Loss = 0.3490072786808014
30-01-2023 04:59:19 INFO Epoch 1: [8119/10940] ---- BYOL Training Loss = 0.3207593560218811
30-01-2023 04:59:38 INFO Epoch 1: [8130/10940] ---- BYOL Training Loss = 0.29895251989364624
30-01-2023 04:59:56 INFO Epoch 1: [8141/10940] ---- BYOL Training Loss = 0.31934526562690735
30-01-2023 05:00:49 INFO Epoch 1: [8141/10940] ---- BYOL Validation Loss = 0.28723081946372986
30-01-2023 05:01:07 INFO Epoch 1: [8152/10940] ---- BYOL Training Loss = 0.3213854432106018
30-01-2023 05:01:25 INFO Epoch 1: [8163/10940] ---- BYOL Training Loss = 0.3410720229148865
30-01-2023 05:01:44 INFO Epoch 1: [8174/10940] ---- BYOL Training Loss = 0.2986675798892975
30-01-2023 05:02:02 INFO Epoch 1: [8185/10940] ---- BYOL Training Loss = 0.3146544098854065
30-01-2023 05:02:55 INFO Epoch 1: [8185/10940] ---- BYOL Validation Loss = 0.2941391170024872
30-01-2023 05:03:13 INFO Epoch 1: [8196/10940] ---- BYOL Training Loss = 0.31945690512657166
30-01-2023 05:03:31 INFO Epoch 1: [8207/10940] ---- BYOL Training Loss = 0.32453685998916626
30-01-2023 05:03:50 INFO Epoch 1: [8218/10940] ---- BYOL Training Loss = 0.2887042164802551
30-01-2023 05:04:08 INFO Epoch 1: [8229/10940] ---- BYOL Training Loss = 0.266560822725296
30-01-2023 05:05:01 INFO Epoch 1: [8229/10940] ---- BYOL Validation Loss = 0.29520970582962036
30-01-2023 05:05:18 INFO Epoch 1: [8240/10940] ---- BYOL Training Loss = 0.2706945240497589
30-01-2023 05:05:37 INFO Epoch 1: [8251/10940] ---- BYOL Training Loss = 0.2623883783817291
30-01-2023 05:05:55 INFO Epoch 1: [8262/10940] ---- BYOL Training Loss = 0.3300932049751282
30-01-2023 05:06:13 INFO Epoch 1: [8273/10940] ---- BYOL Training Loss = 0.3487127423286438
30-01-2023 05:07:06 INFO Epoch 1: [8273/10940] ---- BYOL Validation Loss = 0.2848990261554718
30-01-2023 05:07:24 INFO Epoch 1: [8284/10940] ---- BYOL Training Loss = 0.313908189535141
30-01-2023 05:07:43 INFO Epoch 1: [8295/10940] ---- BYOL Training Loss = 0.26710209250450134
30-01-2023 05:08:01 INFO Epoch 1: [8306/10940] ---- BYOL Training Loss = 0.3133445382118225
30-01-2023 05:08:19 INFO Epoch 1: [8317/10940] ---- BYOL Training Loss = 0.3179440200328827
30-01-2023 05:09:12 INFO Epoch 1: [8317/10940] ---- BYOL Validation Loss = 0.2866363525390625
30-01-2023 05:09:30 INFO Epoch 1: [8328/10940] ---- BYOL Training Loss = 0.2996748089790344
30-01-2023 05:09:48 INFO Epoch 1: [8339/10940] ---- BYOL Training Loss = 0.3123137950897217
30-01-2023 05:10:07 INFO Epoch 1: [8350/10940] ---- BYOL Training Loss = 0.3686884343624115
30-01-2023 05:10:25 INFO Epoch 1: [8361/10940] ---- BYOL Training Loss = 0.2975415587425232
30-01-2023 05:11:18 INFO Epoch 1: [8361/10940] ---- BYOL Validation Loss = 0.2882322371006012
30-01-2023 05:11:36 INFO Epoch 1: [8372/10940] ---- BYOL Training Loss = 0.2762828469276428
30-01-2023 05:11:54 INFO Epoch 1: [8383/10940] ---- BYOL Training Loss = 0.31691819429397583
30-01-2023 05:12:12 INFO Epoch 1: [8394/10940] ---- BYOL Training Loss = 0.30097725987434387
30-01-2023 05:12:31 INFO Epoch 1: [8405/10940] ---- BYOL Training Loss = 0.3255458474159241
30-01-2023 05:13:24 INFO Epoch 1: [8405/10940] ---- BYOL Validation Loss = 0.28993383049964905
30-01-2023 05:13:42 INFO Epoch 1: [8416/10940] ---- BYOL Training Loss = 0.3124943971633911
30-01-2023 05:14:00 INFO Epoch 1: [8427/10940] ---- BYOL Training Loss = 0.30077168345451355
30-01-2023 05:14:18 INFO Epoch 1: [8438/10940] ---- BYOL Training Loss = 0.30227071046829224
30-01-2023 05:14:37 INFO Epoch 1: [8449/10940] ---- BYOL Training Loss = 0.32794541120529175
30-01-2023 05:15:29 INFO Epoch 1: [8449/10940] ---- BYOL Validation Loss = 0.2830337584018707
30-01-2023 05:15:47 INFO Epoch 1: [8460/10940] ---- BYOL Training Loss = 0.32893672585487366
30-01-2023 05:16:06 INFO Epoch 1: [8471/10940] ---- BYOL Training Loss = 0.3086039423942566
30-01-2023 05:16:24 INFO Epoch 1: [8482/10940] ---- BYOL Training Loss = 0.3311161696910858
30-01-2023 05:16:43 INFO Epoch 1: [8493/10940] ---- BYOL Training Loss = 0.30981412529945374
30-01-2023 05:17:35 INFO Epoch 1: [8493/10940] ---- BYOL Validation Loss = 0.2810429036617279
30-01-2023 05:17:53 INFO Epoch 1: [8504/10940] ---- BYOL Training Loss = 0.29341068863868713
30-01-2023 05:18:12 INFO Epoch 1: [8515/10940] ---- BYOL Training Loss = 0.3189697861671448
30-01-2023 05:18:30 INFO Epoch 1: [8526/10940] ---- BYOL Training Loss = 0.357876718044281
30-01-2023 05:18:49 INFO Epoch 1: [8537/10940] ---- BYOL Training Loss = 0.33030965924263
30-01-2023 05:19:42 INFO Epoch 1: [8537/10940] ---- BYOL Validation Loss = 0.2806151211261749
30-01-2023 05:20:00 INFO Epoch 1: [8548/10940] ---- BYOL Training Loss = 0.32368963956832886
30-01-2023 05:20:18 INFO Epoch 1: [8559/10940] ---- BYOL Training Loss = 0.3209967315196991
30-01-2023 05:20:37 INFO Epoch 1: [8570/10940] ---- BYOL Training Loss = 0.2825007140636444
30-01-2023 05:20:55 INFO Epoch 1: [8581/10940] ---- BYOL Training Loss = 0.2650851607322693
30-01-2023 05:21:48 INFO Epoch 1: [8581/10940] ---- BYOL Validation Loss = 0.27730488777160645
30-01-2023 05:22:06 INFO Epoch 1: [8592/10940] ---- BYOL Training Loss = 0.26148924231529236
30-01-2023 05:22:24 INFO Epoch 1: [8603/10940] ---- BYOL Training Loss = 0.2320125848054886
30-01-2023 05:22:43 INFO Epoch 1: [8614/10940] ---- BYOL Training Loss = 0.2886068820953369
30-01-2023 05:23:01 INFO Epoch 1: [8625/10940] ---- BYOL Training Loss = 0.34678012132644653
30-01-2023 05:23:53 INFO Epoch 1: [8625/10940] ---- BYOL Validation Loss = 0.43346109986305237
30-01-2023 05:24:12 INFO Epoch 1: [8636/10940] ---- BYOL Training Loss = 0.31395724415779114
30-01-2023 05:24:30 INFO Epoch 1: [8647/10940] ---- BYOL Training Loss = 0.2868962287902832
30-01-2023 05:24:49 INFO Epoch 1: [8658/10940] ---- BYOL Training Loss = 0.2955743074417114
30-01-2023 05:25:07 INFO Epoch 1: [8669/10940] ---- BYOL Training Loss = 0.34220802783966064
30-01-2023 05:26:00 INFO Epoch 1: [8669/10940] ---- BYOL Validation Loss = 0.28441283106803894
30-01-2023 05:26:18 INFO Epoch 1: [8680/10940] ---- BYOL Training Loss = 0.36519211530685425
30-01-2023 05:26:36 INFO Epoch 1: [8691/10940] ---- BYOL Training Loss = 0.3424316942691803
30-01-2023 05:26:54 INFO Epoch 1: [8702/10940] ---- BYOL Training Loss = 0.36823612451553345
30-01-2023 05:27:13 INFO Epoch 1: [8713/10940] ---- BYOL Training Loss = 0.3326508402824402
30-01-2023 05:28:05 INFO Epoch 1: [8713/10940] ---- BYOL Validation Loss = 0.2780991792678833
30-01-2023 05:28:24 INFO Epoch 1: [8724/10940] ---- BYOL Training Loss = 0.2986449599266052
30-01-2023 05:28:42 INFO Epoch 1: [8735/10940] ---- BYOL Training Loss = 0.2984430193901062
30-01-2023 05:29:01 INFO Epoch 1: [8746/10940] ---- BYOL Training Loss = 0.2514927387237549
30-01-2023 05:29:19 INFO Epoch 1: [8757/10940] ---- BYOL Training Loss = 0.2636485695838928
30-01-2023 05:30:12 INFO Epoch 1: [8757/10940] ---- BYOL Validation Loss = 0.28553450107574463
30-01-2023 05:30:30 INFO Epoch 1: [8768/10940] ---- BYOL Training Loss = 0.32603636384010315
30-01-2023 05:30:48 INFO Epoch 1: [8779/10940] ---- BYOL Training Loss = 0.3533434271812439
30-01-2023 05:31:07 INFO Epoch 1: [8790/10940] ---- BYOL Training Loss = 0.3403800129890442
30-01-2023 05:31:25 INFO Epoch 1: [8801/10940] ---- BYOL Training Loss = 0.2949386239051819
30-01-2023 05:32:18 INFO Epoch 1: [8801/10940] ---- BYOL Validation Loss = 0.2797812521457672
30-01-2023 05:32:36 INFO Epoch 1: [8812/10940] ---- BYOL Training Loss = 0.29325610399246216
30-01-2023 05:32:54 INFO Epoch 1: [8823/10940] ---- BYOL Training Loss = 0.3060605227947235
30-01-2023 05:33:12 INFO Epoch 1: [8834/10940] ---- BYOL Training Loss = 0.3463086485862732
30-01-2023 05:33:31 INFO Epoch 1: [8845/10940] ---- BYOL Training Loss = 0.325365275144577
30-01-2023 05:34:24 INFO Epoch 1: [8845/10940] ---- BYOL Validation Loss = 0.2793741524219513
30-01-2023 05:34:42 INFO Epoch 1: [8856/10940] ---- BYOL Training Loss = 0.3267093896865845
30-01-2023 05:35:00 INFO Epoch 1: [8867/10940] ---- BYOL Training Loss = 0.30144935846328735
30-01-2023 05:35:19 INFO Epoch 1: [8878/10940] ---- BYOL Training Loss = 0.3134811818599701
30-01-2023 05:35:37 INFO Epoch 1: [8889/10940] ---- BYOL Training Loss = 0.3290172219276428
30-01-2023 05:36:30 INFO Epoch 1: [8889/10940] ---- BYOL Validation Loss = 0.2830796241760254
30-01-2023 05:36:48 INFO Epoch 1: [8900/10940] ---- BYOL Training Loss = 0.3250228762626648
30-01-2023 05:37:06 INFO Epoch 1: [8911/10940] ---- BYOL Training Loss = 0.28925958275794983
30-01-2023 05:37:25 INFO Epoch 1: [8922/10940] ---- BYOL Training Loss = 0.271790087223053
30-01-2023 05:37:43 INFO Epoch 1: [8933/10940] ---- BYOL Training Loss = 0.2640978693962097
30-01-2023 05:38:36 INFO Epoch 1: [8933/10940] ---- BYOL Validation Loss = 0.2744464576244354
30-01-2023 05:38:54 INFO Epoch 1: [8944/10940] ---- BYOL Training Loss = 0.2930455505847931
30-01-2023 05:39:12 INFO Epoch 1: [8955/10940] ---- BYOL Training Loss = 0.26218241453170776
30-01-2023 05:39:31 INFO Epoch 1: [8966/10940] ---- BYOL Training Loss = 0.3023295998573303
30-01-2023 05:39:50 INFO Epoch 1: [8977/10940] ---- BYOL Training Loss = 0.3091201186180115
30-01-2023 05:40:42 INFO Epoch 1: [8977/10940] ---- BYOL Validation Loss = 0.2608734667301178
30-01-2023 05:41:00 INFO Epoch 1: [8988/10940] ---- BYOL Training Loss = 0.2821436822414398
30-01-2023 05:41:19 INFO Epoch 1: [8999/10940] ---- BYOL Training Loss = 0.23872557282447815
30-01-2023 05:41:37 INFO Epoch 1: [9010/10940] ---- BYOL Training Loss = 0.21972796320915222
30-01-2023 05:41:56 INFO Epoch 1: [9021/10940] ---- BYOL Training Loss = 0.25634875893592834
30-01-2023 05:42:48 INFO Epoch 1: [9021/10940] ---- BYOL Validation Loss = 0.2764582335948944
30-01-2023 05:43:06 INFO Epoch 1: [9032/10940] ---- BYOL Training Loss = 0.29202157258987427
30-01-2023 05:43:25 INFO Epoch 1: [9043/10940] ---- BYOL Training Loss = 0.2813569903373718
30-01-2023 05:43:43 INFO Epoch 1: [9054/10940] ---- BYOL Training Loss = 0.2538900077342987
30-01-2023 05:44:02 INFO Epoch 1: [9065/10940] ---- BYOL Training Loss = 0.238384410738945
30-01-2023 05:44:54 INFO Epoch 1: [9065/10940] ---- BYOL Validation Loss = 0.28080469369888306
30-01-2023 05:45:12 INFO Epoch 1: [9076/10940] ---- BYOL Training Loss = 0.2790444791316986
30-01-2023 05:45:31 INFO Epoch 1: [9087/10940] ---- BYOL Training Loss = 0.34850797057151794
30-01-2023 05:45:50 INFO Epoch 1: [9098/10940] ---- BYOL Training Loss = 0.3263905644416809
30-01-2023 05:46:08 INFO Epoch 1: [9109/10940] ---- BYOL Training Loss = 0.2900838851928711
30-01-2023 05:47:01 INFO Epoch 1: [9109/10940] ---- BYOL Validation Loss = 0.2770022749900818
30-01-2023 05:47:19 INFO Epoch 1: [9120/10940] ---- BYOL Training Loss = 0.2808668911457062
30-01-2023 05:47:37 INFO Epoch 1: [9131/10940] ---- BYOL Training Loss = 0.27041345834732056
30-01-2023 05:47:56 INFO Epoch 1: [9142/10940] ---- BYOL Training Loss = 0.267967164516449
30-01-2023 05:48:15 INFO Epoch 1: [9153/10940] ---- BYOL Training Loss = 0.26171934604644775
30-01-2023 05:49:07 INFO Epoch 1: [9153/10940] ---- BYOL Validation Loss = 0.2730206549167633
30-01-2023 05:49:25 INFO Epoch 1: [9164/10940] ---- BYOL Training Loss = 0.3190852105617523
30-01-2023 05:49:44 INFO Epoch 1: [9175/10940] ---- BYOL Training Loss = 0.32794830203056335
30-01-2023 05:50:03 INFO Epoch 1: [9186/10940] ---- BYOL Training Loss = 0.2973676919937134
30-01-2023 05:50:21 INFO Epoch 1: [9197/10940] ---- BYOL Training Loss = 0.3099270164966583
30-01-2023 05:51:14 INFO Epoch 1: [9197/10940] ---- BYOL Validation Loss = 0.28127846121788025
30-01-2023 05:51:32 INFO Epoch 1: [9208/10940] ---- BYOL Training Loss = 0.27680355310440063
30-01-2023 05:51:50 INFO Epoch 1: [9219/10940] ---- BYOL Training Loss = 0.2561569809913635
30-01-2023 05:52:09 INFO Epoch 1: [9230/10940] ---- BYOL Training Loss = 0.2978113293647766
30-01-2023 05:52:28 INFO Epoch 1: [9241/10940] ---- BYOL Training Loss = 0.2934245467185974
30-01-2023 05:53:20 INFO Epoch 1: [9241/10940] ---- BYOL Validation Loss = 0.27322128415107727
30-01-2023 05:53:39 INFO Epoch 1: [9252/10940] ---- BYOL Training Loss = 0.2888950705528259
30-01-2023 05:53:57 INFO Epoch 1: [9263/10940] ---- BYOL Training Loss = 0.3490399718284607
30-01-2023 05:54:15 INFO Epoch 1: [9274/10940] ---- BYOL Training Loss = 0.3103768825531006
30-01-2023 05:54:34 INFO Epoch 1: [9285/10940] ---- BYOL Training Loss = 0.3039558529853821
30-01-2023 05:55:27 INFO Epoch 1: [9285/10940] ---- BYOL Validation Loss = 0.2898782193660736
30-01-2023 05:55:45 INFO Epoch 1: [9296/10940] ---- BYOL Training Loss = 0.28852495551109314
30-01-2023 05:56:03 INFO Epoch 1: [9307/10940] ---- BYOL Training Loss = 0.2541765570640564
30-01-2023 05:56:22 INFO Epoch 1: [9318/10940] ---- BYOL Training Loss = 0.2749982178211212
30-01-2023 05:56:40 INFO Epoch 1: [9329/10940] ---- BYOL Training Loss = 0.2761411666870117
30-01-2023 05:57:32 INFO Epoch 1: [9329/10940] ---- BYOL Validation Loss = 0.28258413076400757
30-01-2023 05:57:51 INFO Epoch 1: [9340/10940] ---- BYOL Training Loss = 0.28022465109825134
30-01-2023 05:58:09 INFO Epoch 1: [9351/10940] ---- BYOL Training Loss = 0.2965603172779083
30-01-2023 05:58:27 INFO Epoch 1: [9362/10940] ---- BYOL Training Loss = 0.308464378118515
30-01-2023 05:58:46 INFO Epoch 1: [9373/10940] ---- BYOL Training Loss = 0.3035474717617035
30-01-2023 05:59:38 INFO Epoch 1: [9373/10940] ---- BYOL Validation Loss = 0.2968663275241852
30-01-2023 05:59:56 INFO Epoch 1: [9384/10940] ---- BYOL Training Loss = 0.31207147240638733
30-01-2023 06:00:15 INFO Epoch 1: [9395/10940] ---- BYOL Training Loss = 0.29069751501083374
30-01-2023 06:00:33 INFO Epoch 1: [9406/10940] ---- BYOL Training Loss = 0.26986950635910034
30-01-2023 06:00:52 INFO Epoch 1: [9417/10940] ---- BYOL Training Loss = 0.2891581654548645
30-01-2023 06:01:44 INFO Epoch 1: [9417/10940] ---- BYOL Validation Loss = 0.28561854362487793
30-01-2023 06:02:03 INFO Epoch 1: [9428/10940] ---- BYOL Training Loss = 0.316231906414032
30-01-2023 06:02:21 INFO Epoch 1: [9439/10940] ---- BYOL Training Loss = 0.3102596700191498
30-01-2023 06:02:40 INFO Epoch 1: [9450/10940] ---- BYOL Training Loss = 0.3010851740837097
30-01-2023 06:02:58 INFO Epoch 1: [9461/10940] ---- BYOL Training Loss = 0.3075021505355835
30-01-2023 06:03:51 INFO Epoch 1: [9461/10940] ---- BYOL Validation Loss = 0.2909355163574219
30-01-2023 06:04:09 INFO Epoch 1: [9472/10940] ---- BYOL Training Loss = 0.2793234884738922
30-01-2023 06:04:28 INFO Epoch 1: [9483/10940] ---- BYOL Training Loss = 0.29056820273399353
30-01-2023 06:04:46 INFO Epoch 1: [9494/10940] ---- BYOL Training Loss = 0.3039175868034363
30-01-2023 06:05:05 INFO Epoch 1: [9505/10940] ---- BYOL Training Loss = 0.31676602363586426
30-01-2023 06:05:57 INFO Epoch 1: [9505/10940] ---- BYOL Validation Loss = 0.2952750027179718
30-01-2023 06:06:15 INFO Epoch 1: [9516/10940] ---- BYOL Training Loss = 0.2813427150249481
30-01-2023 06:06:34 INFO Epoch 1: [9527/10940] ---- BYOL Training Loss = 0.2639678716659546
30-01-2023 06:06:53 INFO Epoch 1: [9538/10940] ---- BYOL Training Loss = 0.2643967568874359
30-01-2023 06:07:11 INFO Epoch 1: [9549/10940] ---- BYOL Training Loss = 0.26879891753196716
30-01-2023 06:08:04 INFO Epoch 1: [9549/10940] ---- BYOL Validation Loss = 0.29479116201400757
30-01-2023 06:08:22 INFO Epoch 1: [9560/10940] ---- BYOL Training Loss = 0.30859312415122986
30-01-2023 06:08:41 INFO Epoch 1: [9571/10940] ---- BYOL Training Loss = 0.3184712827205658
30-01-2023 06:08:59 INFO Epoch 1: [9582/10940] ---- BYOL Training Loss = 0.3244686722755432
30-01-2023 06:09:18 INFO Epoch 1: [9593/10940] ---- BYOL Training Loss = 0.3047863841056824
30-01-2023 06:10:10 INFO Epoch 1: [9593/10940] ---- BYOL Validation Loss = 0.29651790857315063
30-01-2023 06:10:28 INFO Epoch 1: [9604/10940] ---- BYOL Training Loss = 0.2888106405735016
30-01-2023 06:10:47 INFO Epoch 1: [9615/10940] ---- BYOL Training Loss = 0.2968086004257202
30-01-2023 06:11:06 INFO Epoch 1: [9626/10940] ---- BYOL Training Loss = 0.2919267416000366
30-01-2023 06:11:24 INFO Epoch 1: [9637/10940] ---- BYOL Training Loss = 0.28704389929771423
30-01-2023 06:12:17 INFO Epoch 1: [9637/10940] ---- BYOL Validation Loss = 0.31411388516426086
30-01-2023 06:12:35 INFO Epoch 1: [9648/10940] ---- BYOL Training Loss = 0.3113669753074646
30-01-2023 06:12:54 INFO Epoch 1: [9659/10940] ---- BYOL Training Loss = 0.30500009655952454
30-01-2023 06:13:12 INFO Epoch 1: [9670/10940] ---- BYOL Training Loss = 0.3124721646308899
30-01-2023 06:13:31 INFO Epoch 1: [9681/10940] ---- BYOL Training Loss = 0.32224246859550476
30-01-2023 06:14:23 INFO Epoch 1: [9681/10940] ---- BYOL Validation Loss = 0.320380836725235
30-01-2023 06:14:41 INFO Epoch 1: [9692/10940] ---- BYOL Training Loss = 0.342629611492157
30-01-2023 06:15:00 INFO Epoch 1: [9703/10940] ---- BYOL Training Loss = 0.31550028920173645
30-01-2023 06:15:18 INFO Epoch 1: [9714/10940] ---- BYOL Training Loss = 0.35884207487106323
30-01-2023 06:15:37 INFO Epoch 1: [9725/10940] ---- BYOL Training Loss = 0.3698710799217224
30-01-2023 06:16:30 INFO Epoch 1: [9725/10940] ---- BYOL Validation Loss = 0.3241159915924072
30-01-2023 06:16:48 INFO Epoch 1: [9736/10940] ---- BYOL Training Loss = 0.39429110288619995
30-01-2023 06:17:07 INFO Epoch 1: [9747/10940] ---- BYOL Training Loss = 0.3596682846546173
30-01-2023 06:17:25 INFO Epoch 1: [9758/10940] ---- BYOL Training Loss = 0.2832331657409668
30-01-2023 06:17:43 INFO Epoch 1: [9769/10940] ---- BYOL Training Loss = 0.2928834855556488
30-01-2023 06:18:36 INFO Epoch 1: [9769/10940] ---- BYOL Validation Loss = 0.3141038715839386
30-01-2023 06:18:55 INFO Epoch 1: [9780/10940] ---- BYOL Training Loss = 0.3600694239139557
30-01-2023 06:19:13 INFO Epoch 1: [9791/10940] ---- BYOL Training Loss = 0.3243800699710846
30-01-2023 06:19:32 INFO Epoch 1: [9802/10940] ---- BYOL Training Loss = 0.3586410880088806
30-01-2023 06:19:50 INFO Epoch 1: [9813/10940] ---- BYOL Training Loss = 0.33007198572158813
30-01-2023 06:20:43 INFO Epoch 1: [9813/10940] ---- BYOL Validation Loss = 0.32590216398239136
30-01-2023 06:21:01 INFO Epoch 1: [9824/10940] ---- BYOL Training Loss = 0.3172425627708435
30-01-2023 06:21:20 INFO Epoch 1: [9835/10940] ---- BYOL Training Loss = 0.35625597834587097
30-01-2023 06:21:39 INFO Epoch 1: [9846/10940] ---- BYOL Training Loss = 0.3351309299468994
30-01-2023 06:21:57 INFO Epoch 1: [9857/10940] ---- BYOL Training Loss = 0.2779942452907562
30-01-2023 06:22:50 INFO Epoch 1: [9857/10940] ---- BYOL Validation Loss = 0.3108069598674774
30-01-2023 06:23:08 INFO Epoch 1: [9868/10940] ---- BYOL Training Loss = 0.28502610325813293
30-01-2023 06:23:26 INFO Epoch 1: [9879/10940] ---- BYOL Training Loss = 0.30720213055610657
30-01-2023 06:23:45 INFO Epoch 1: [9890/10940] ---- BYOL Training Loss = 0.32369285821914673
30-01-2023 06:24:04 INFO Epoch 1: [9901/10940] ---- BYOL Training Loss = 0.3613772988319397
30-01-2023 06:24:56 INFO Epoch 1: [9901/10940] ---- BYOL Validation Loss = 0.30909496545791626
30-01-2023 06:25:15 INFO Epoch 1: [9912/10940] ---- BYOL Training Loss = 0.3474370837211609
30-01-2023 06:25:33 INFO Epoch 1: [9923/10940] ---- BYOL Training Loss = 0.31865161657333374
30-01-2023 06:25:52 INFO Epoch 1: [9934/10940] ---- BYOL Training Loss = 0.2796398401260376
30-01-2023 06:26:10 INFO Epoch 1: [9945/10940] ---- BYOL Training Loss = 0.2822995185852051
30-01-2023 06:27:03 INFO Epoch 1: [9945/10940] ---- BYOL Validation Loss = 0.3049451410770416
30-01-2023 06:27:21 INFO Epoch 1: [9956/10940] ---- BYOL Training Loss = 0.3078756630420685
30-01-2023 06:27:40 INFO Epoch 1: [9967/10940] ---- BYOL Training Loss = 0.3306402266025543
30-01-2023 06:27:58 INFO Epoch 1: [9978/10940] ---- BYOL Training Loss = 0.3346802592277527
30-01-2023 06:28:17 INFO Epoch 1: [9989/10940] ---- BYOL Training Loss = 0.3522684872150421
30-01-2023 06:29:09 INFO Epoch 1: [9989/10940] ---- BYOL Validation Loss = 0.30389541387557983
30-01-2023 06:29:28 INFO Epoch 1: [10000/10940] ---- BYOL Training Loss = 0.34110742807388306
30-01-2023 06:29:46 INFO Epoch 1: [10011/10940] ---- BYOL Training Loss = 0.29375600814819336
30-01-2023 06:30:05 INFO Epoch 1: [10022/10940] ---- BYOL Training Loss = 0.3102398216724396
30-01-2023 06:30:23 INFO Epoch 1: [10033/10940] ---- BYOL Training Loss = 0.31029826402664185
30-01-2023 06:31:16 INFO Epoch 1: [10033/10940] ---- BYOL Validation Loss = 0.30579012632369995
30-01-2023 06:31:34 INFO Epoch 1: [10044/10940] ---- BYOL Training Loss = 0.2979397773742676
30-01-2023 06:31:53 INFO Epoch 1: [10055/10940] ---- BYOL Training Loss = 0.2952575385570526
30-01-2023 06:32:11 INFO Epoch 1: [10066/10940] ---- BYOL Training Loss = 0.32927340269088745
30-01-2023 06:32:30 INFO Epoch 1: [10077/10940] ---- BYOL Training Loss = 0.33561426401138306
30-01-2023 06:33:23 INFO Epoch 1: [10077/10940] ---- BYOL Validation Loss = 0.30300068855285645
30-01-2023 06:33:41 INFO Epoch 1: [10088/10940] ---- BYOL Training Loss = 0.34475210309028625
30-01-2023 06:34:00 INFO Epoch 1: [10099/10940] ---- BYOL Training Loss = 0.39644044637680054
30-01-2023 06:34:18 INFO Epoch 1: [10110/10940] ---- BYOL Training Loss = 0.3435109555721283
30-01-2023 06:34:36 INFO Epoch 1: [10121/10940] ---- BYOL Training Loss = 0.2981620728969574
30-01-2023 06:35:29 INFO Epoch 1: [10121/10940] ---- BYOL Validation Loss = 0.30934301018714905
30-01-2023 06:35:47 INFO Epoch 1: [10132/10940] ---- BYOL Training Loss = 0.33742231130599976
30-01-2023 06:36:06 INFO Epoch 1: [10143/10940] ---- BYOL Training Loss = 0.29732024669647217
30-01-2023 06:36:25 INFO Epoch 1: [10154/10940] ---- BYOL Training Loss = 0.2561954855918884
30-01-2023 06:36:43 INFO Epoch 1: [10165/10940] ---- BYOL Training Loss = 0.28766441345214844
30-01-2023 06:37:35 INFO Epoch 1: [10165/10940] ---- BYOL Validation Loss = 0.30899184942245483
30-01-2023 06:37:54 INFO Epoch 1: [10176/10940] ---- BYOL Training Loss = 0.3309958875179291
30-01-2023 06:38:13 INFO Epoch 1: [10187/10940] ---- BYOL Training Loss = 0.27287256717681885
30-01-2023 06:38:31 INFO Epoch 1: [10198/10940] ---- BYOL Training Loss = 0.2720831334590912
30-01-2023 06:38:50 INFO Epoch 1: [10209/10940] ---- BYOL Training Loss = 0.35335734486579895
30-01-2023 06:39:43 INFO Epoch 1: [10209/10940] ---- BYOL Validation Loss = 0.3060089647769928
30-01-2023 06:40:01 INFO Epoch 1: [10220/10940] ---- BYOL Training Loss = 0.35837674140930176
30-01-2023 06:40:20 INFO Epoch 1: [10231/10940] ---- BYOL Training Loss = 0.3367477059364319
30-01-2023 06:40:38 INFO Epoch 1: [10242/10940] ---- BYOL Training Loss = 0.3285616934299469
30-01-2023 06:40:57 INFO Epoch 1: [10253/10940] ---- BYOL Training Loss = 0.3227795958518982
30-01-2023 06:41:49 INFO Epoch 1: [10253/10940] ---- BYOL Validation Loss = 0.2973892390727997
30-01-2023 06:42:07 INFO Epoch 1: [10264/10940] ---- BYOL Training Loss = 0.33693382143974304
30-01-2023 06:42:26 INFO Epoch 1: [10275/10940] ---- BYOL Training Loss = 0.3067266345024109
30-01-2023 06:42:45 INFO Epoch 1: [10286/10940] ---- BYOL Training Loss = 0.32537466287612915
30-01-2023 06:43:03 INFO Epoch 1: [10297/10940] ---- BYOL Training Loss = 0.33785197138786316
30-01-2023 06:43:56 INFO Epoch 1: [10297/10940] ---- BYOL Validation Loss = 0.3010953366756439
30-01-2023 06:44:14 INFO Epoch 1: [10308/10940] ---- BYOL Training Loss = 0.341560035943985
30-01-2023 06:44:33 INFO Epoch 1: [10319/10940] ---- BYOL Training Loss = 0.3128536641597748
30-01-2023 06:44:51 INFO Epoch 1: [10330/10940] ---- BYOL Training Loss = 0.3095734119415283
30-01-2023 06:45:10 INFO Epoch 1: [10341/10940] ---- BYOL Training Loss = 0.2812958061695099
30-01-2023 06:46:03 INFO Epoch 1: [10341/10940] ---- BYOL Validation Loss = 0.28583961725234985
30-01-2023 06:46:21 INFO Epoch 1: [10352/10940] ---- BYOL Training Loss = 0.2851521968841553
30-01-2023 06:46:40 INFO Epoch 1: [10363/10940] ---- BYOL Training Loss = 0.304788202047348
30-01-2023 06:46:58 INFO Epoch 1: [10374/10940] ---- BYOL Training Loss = 0.2825070023536682
30-01-2023 06:47:17 INFO Epoch 1: [10385/10940] ---- BYOL Training Loss = 0.2720213830471039
30-01-2023 06:48:09 INFO Epoch 1: [10385/10940] ---- BYOL Validation Loss = 0.29351621866226196
30-01-2023 06:48:28 INFO Epoch 1: [10396/10940] ---- BYOL Training Loss = 0.2596781253814697
30-01-2023 06:48:46 INFO Epoch 1: [10407/10940] ---- BYOL Training Loss = 0.28528982400894165
30-01-2023 06:49:05 INFO Epoch 1: [10418/10940] ---- BYOL Training Loss = 0.2927336096763611
30-01-2023 06:49:23 INFO Epoch 1: [10429/10940] ---- BYOL Training Loss = 0.3059949278831482
30-01-2023 06:50:16 INFO Epoch 1: [10429/10940] ---- BYOL Validation Loss = 0.2992515563964844
30-01-2023 06:50:34 INFO Epoch 1: [10440/10940] ---- BYOL Training Loss = 0.35679033398628235
30-01-2023 06:50:53 INFO Epoch 1: [10451/10940] ---- BYOL Training Loss = 0.32595065236091614
30-01-2023 06:51:12 INFO Epoch 1: [10462/10940] ---- BYOL Training Loss = 0.3358462452888489
30-01-2023 06:51:31 INFO Epoch 1: [10473/10940] ---- BYOL Training Loss = 0.35763269662857056
30-01-2023 06:52:23 INFO Epoch 1: [10473/10940] ---- BYOL Validation Loss = 0.2926342189311981
30-01-2023 06:52:42 INFO Epoch 1: [10484/10940] ---- BYOL Training Loss = 0.31558361649513245
30-01-2023 06:53:00 INFO Epoch 1: [10495/10940] ---- BYOL Training Loss = 0.3202560245990753
30-01-2023 06:53:19 INFO Epoch 1: [10506/10940] ---- BYOL Training Loss = 0.34481069445610046
30-01-2023 06:53:38 INFO Epoch 1: [10517/10940] ---- BYOL Training Loss = 0.29012399911880493
30-01-2023 06:54:30 INFO Epoch 1: [10517/10940] ---- BYOL Validation Loss = 0.28679004311561584
30-01-2023 06:54:49 INFO Epoch 1: [10528/10940] ---- BYOL Training Loss = 0.2943195700645447
30-01-2023 06:55:08 INFO Epoch 1: [10539/10940] ---- BYOL Training Loss = 0.3330744206905365
30-01-2023 06:55:26 INFO Epoch 1: [10550/10940] ---- BYOL Training Loss = 0.3556133806705475
30-01-2023 06:55:45 INFO Epoch 1: [10561/10940] ---- BYOL Training Loss = 0.29848408699035645
30-01-2023 06:56:38 INFO Epoch 1: [10561/10940] ---- BYOL Validation Loss = 0.29453712701797485
30-01-2023 06:56:56 INFO Epoch 1: [10572/10940] ---- BYOL Training Loss = 0.3113361597061157
30-01-2023 06:57:15 INFO Epoch 1: [10583/10940] ---- BYOL Training Loss = 0.3286048471927643
30-01-2023 06:57:33 INFO Epoch 1: [10594/10940] ---- BYOL Training Loss = 0.2832477390766144
30-01-2023 06:57:51 INFO Epoch 1: [10605/10940] ---- BYOL Training Loss = 0.28424572944641113
30-01-2023 06:58:44 INFO Epoch 1: [10605/10940] ---- BYOL Validation Loss = 0.2894725203514099
30-01-2023 06:59:02 INFO Epoch 1: [10616/10940] ---- BYOL Training Loss = 0.32240304350852966
30-01-2023 06:59:21 INFO Epoch 1: [10627/10940] ---- BYOL Training Loss = 0.34961411356925964
30-01-2023 06:59:40 INFO Epoch 1: [10638/10940] ---- BYOL Training Loss = 0.3576434552669525
30-01-2023 06:59:58 INFO Epoch 1: [10649/10940] ---- BYOL Training Loss = 0.34044188261032104
30-01-2023 07:00:51 INFO Epoch 1: [10649/10940] ---- BYOL Validation Loss = 0.2862248420715332
30-01-2023 07:01:09 INFO Epoch 1: [10660/10940] ---- BYOL Training Loss = 0.3358214795589447
30-01-2023 07:01:28 INFO Epoch 1: [10671/10940] ---- BYOL Training Loss = 0.3330320119857788
30-01-2023 07:01:47 INFO Epoch 1: [10682/10940] ---- BYOL Training Loss = 0.33238038420677185
30-01-2023 07:02:06 INFO Epoch 1: [10693/10940] ---- BYOL Training Loss = 0.31776490807533264
30-01-2023 07:02:58 INFO Epoch 1: [10693/10940] ---- BYOL Validation Loss = 0.2876705527305603
30-01-2023 07:03:16 INFO Epoch 1: [10704/10940] ---- BYOL Training Loss = 0.3189990520477295
30-01-2023 07:03:35 INFO Epoch 1: [10715/10940] ---- BYOL Training Loss = 0.32537132501602173
30-01-2023 07:03:54 INFO Epoch 1: [10726/10940] ---- BYOL Training Loss = 0.2964330315589905
30-01-2023 07:04:12 INFO Epoch 1: [10737/10940] ---- BYOL Training Loss = 0.29221123456954956
30-01-2023 07:05:05 INFO Epoch 1: [10737/10940] ---- BYOL Validation Loss = 0.2835997939109802
30-01-2023 07:05:23 INFO Epoch 1: [10748/10940] ---- BYOL Training Loss = 0.3244744539260864
30-01-2023 07:05:42 INFO Epoch 1: [10759/10940] ---- BYOL Training Loss = 0.2849784791469574
30-01-2023 07:06:01 INFO Epoch 1: [10770/10940] ---- BYOL Training Loss = 0.3028842508792877
30-01-2023 07:06:20 INFO Epoch 1: [10781/10940] ---- BYOL Training Loss = 0.328734427690506
30-01-2023 07:07:12 INFO Epoch 1: [10781/10940] ---- BYOL Validation Loss = 0.2948833405971527
30-01-2023 07:07:30 INFO Epoch 1: [10792/10940] ---- BYOL Training Loss = 0.3170378506183624
30-01-2023 07:07:49 INFO Epoch 1: [10803/10940] ---- BYOL Training Loss = 0.29723915457725525
30-01-2023 07:08:08 INFO Epoch 1: [10814/10940] ---- BYOL Training Loss = 0.3200892210006714
30-01-2023 07:08:27 INFO Epoch 1: [10825/10940] ---- BYOL Training Loss = 0.28529974818229675
30-01-2023 07:09:19 INFO Epoch 1: [10825/10940] ---- BYOL Validation Loss = 0.2903512418270111
30-01-2023 07:09:38 INFO Epoch 1: [10836/10940] ---- BYOL Training Loss = 0.2653285264968872
30-01-2023 07:09:56 INFO Epoch 1: [10847/10940] ---- BYOL Training Loss = 0.3071886897087097
30-01-2023 07:10:15 INFO Epoch 1: [10858/10940] ---- BYOL Training Loss = 0.3356532156467438
30-01-2023 07:10:33 INFO Epoch 1: [10869/10940] ---- BYOL Training Loss = 0.3174203336238861
30-01-2023 07:11:26 INFO Epoch 1: [10869/10940] ---- BYOL Validation Loss = 0.2991550862789154
30-01-2023 07:11:44 INFO Epoch 1: [10880/10940] ---- BYOL Training Loss = 0.31616899371147156
30-01-2023 07:12:03 INFO Epoch 1: [10891/10940] ---- BYOL Training Loss = 0.2859012484550476
30-01-2023 07:12:22 INFO Epoch 1: [10902/10940] ---- BYOL Training Loss = 0.3065212368965149
30-01-2023 07:12:41 INFO Epoch 1: [10913/10940] ---- BYOL Training Loss = 0.31616804003715515
30-01-2023 07:13:33 INFO Epoch 1: [10913/10940] ---- BYOL Validation Loss = 0.29437974095344543
30-01-2023 07:13:52 INFO Epoch 1: [10924/10940] ---- BYOL Training Loss = 0.31955379247665405
30-01-2023 07:14:11 INFO Epoch 1: [10935/10940] ---- BYOL Training Loss = 0.3242100775241852
30-01-2023 07:14:20 INFO Starting Epoch: 2
30-01-2023 07:14:38 INFO Epoch 2: [12/10940] ---- BYOL Training Loss = 0.2668905556201935
30-01-2023 07:14:56 INFO Epoch 2: [23/10940] ---- BYOL Training Loss = 0.3106648325920105
30-01-2023 07:15:13 INFO Epoch 2: [34/10940] ---- BYOL Training Loss = 0.30830615758895874
30-01-2023 07:15:31 INFO Epoch 2: [45/10940] ---- BYOL Training Loss = 0.27208951115608215
30-01-2023 07:16:23 INFO Epoch 2: [45/10940] ---- BYOL Validation Loss = 0.2847704291343689
30-01-2023 07:16:40 INFO Epoch 2: [56/10940] ---- BYOL Training Loss = 0.3108256459236145
30-01-2023 07:16:58 INFO Epoch 2: [67/10940] ---- BYOL Training Loss = 0.295391321182251
30-01-2023 07:17:15 INFO Epoch 2: [78/10940] ---- BYOL Training Loss = 0.2945597469806671
30-01-2023 07:17:33 INFO Epoch 2: [89/10940] ---- BYOL Training Loss = 0.3260108530521393
30-01-2023 07:18:25 INFO Epoch 2: [89/10940] ---- BYOL Validation Loss = 0.2924315929412842
30-01-2023 07:18:42 INFO Epoch 2: [100/10940] ---- BYOL Training Loss = 0.2750489115715027
30-01-2023 07:19:00 INFO Epoch 2: [111/10940] ---- BYOL Training Loss = 0.31326907873153687
30-01-2023 07:19:17 INFO Epoch 2: [122/10940] ---- BYOL Training Loss = 0.29789504408836365
30-01-2023 07:19:35 INFO Epoch 2: [133/10940] ---- BYOL Training Loss = 0.3083381652832031
30-01-2023 07:20:27 INFO Epoch 2: [133/10940] ---- BYOL Validation Loss = 0.2878207564353943
30-01-2023 07:20:45 INFO Epoch 2: [144/10940] ---- BYOL Training Loss = 0.27644890546798706
30-01-2023 07:21:02 INFO Epoch 2: [155/10940] ---- BYOL Training Loss = 0.24971655011177063
30-01-2023 07:21:20 INFO Epoch 2: [166/10940] ---- BYOL Training Loss = 0.252095490694046
30-01-2023 07:21:37 INFO Epoch 2: [177/10940] ---- BYOL Training Loss = 0.26977837085723877
30-01-2023 07:22:30 INFO Epoch 2: [177/10940] ---- BYOL Validation Loss = 0.28487128019332886
30-01-2023 07:22:47 INFO Epoch 2: [188/10940] ---- BYOL Training Loss = 0.28675344586372375
30-01-2023 07:23:05 INFO Epoch 2: [199/10940] ---- BYOL Training Loss = 0.28257298469543457
30-01-2023 07:23:22 INFO Epoch 2: [210/10940] ---- BYOL Training Loss = 0.3065764307975769
30-01-2023 07:23:40 INFO Epoch 2: [221/10940] ---- BYOL Training Loss = 0.3274264633655548
30-01-2023 07:24:33 INFO Epoch 2: [221/10940] ---- BYOL Validation Loss = 0.2885432243347168
30-01-2023 07:24:50 INFO Epoch 2: [232/10940] ---- BYOL Training Loss = 0.30448275804519653
30-01-2023 07:25:07 INFO Epoch 2: [243/10940] ---- BYOL Training Loss = 0.28366830945014954
30-01-2023 07:25:25 INFO Epoch 2: [254/10940] ---- BYOL Training Loss = 0.2846314311027527
30-01-2023 07:25:43 INFO Epoch 2: [265/10940] ---- BYOL Training Loss = 0.28107598423957825
30-01-2023 07:26:35 INFO Epoch 2: [265/10940] ---- BYOL Validation Loss = 0.2947450578212738
30-01-2023 07:26:52 INFO Epoch 2: [276/10940] ---- BYOL Training Loss = 0.29398444294929504
30-01-2023 07:27:10 INFO Epoch 2: [287/10940] ---- BYOL Training Loss = 0.2840011715888977
30-01-2023 07:27:28 INFO Epoch 2: [298/10940] ---- BYOL Training Loss = 0.3191727101802826
30-01-2023 07:27:45 INFO Epoch 2: [309/10940] ---- BYOL Training Loss = 0.3213912844657898
30-01-2023 07:28:38 INFO Epoch 2: [309/10940] ---- BYOL Validation Loss = 0.29536062479019165
30-01-2023 07:28:55 INFO Epoch 2: [320/10940] ---- BYOL Training Loss = 0.31179922819137573
30-01-2023 07:29:12 INFO Epoch 2: [331/10940] ---- BYOL Training Loss = 0.2831272482872009
30-01-2023 07:29:30 INFO Epoch 2: [342/10940] ---- BYOL Training Loss = 0.2938581705093384
30-01-2023 07:29:47 INFO Epoch 2: [353/10940] ---- BYOL Training Loss = 0.3458027243614197
30-01-2023 07:30:40 INFO Epoch 2: [353/10940] ---- BYOL Validation Loss = 0.29624539613723755
30-01-2023 07:30:57 INFO Epoch 2: [364/10940] ---- BYOL Training Loss = 0.3751266598701477
30-01-2023 07:31:15 INFO Epoch 2: [375/10940] ---- BYOL Training Loss = 0.297164648771286
30-01-2023 07:31:32 INFO Epoch 2: [386/10940] ---- BYOL Training Loss = 0.29656317830085754
30-01-2023 07:31:50 INFO Epoch 2: [397/10940] ---- BYOL Training Loss = 0.3058702349662781
30-01-2023 07:32:43 INFO Epoch 2: [397/10940] ---- BYOL Validation Loss = 0.2891286313533783
30-01-2023 07:33:00 INFO Epoch 2: [408/10940] ---- BYOL Training Loss = 0.3119792342185974
30-01-2023 07:33:17 INFO Epoch 2: [419/10940] ---- BYOL Training Loss = 0.3008851408958435
30-01-2023 07:33:35 INFO Epoch 2: [430/10940] ---- BYOL Training Loss = 0.29464244842529297
30-01-2023 07:33:52 INFO Epoch 2: [441/10940] ---- BYOL Training Loss = 0.28100913763046265
30-01-2023 07:34:45 INFO Epoch 2: [441/10940] ---- BYOL Validation Loss = 0.28510257601737976
30-01-2023 07:35:02 INFO Epoch 2: [452/10940] ---- BYOL Training Loss = 0.2701474726200104
30-01-2023 07:35:20 INFO Epoch 2: [463/10940] ---- BYOL Training Loss = 0.2822537124156952
30-01-2023 07:35:37 INFO Epoch 2: [474/10940] ---- BYOL Training Loss = 0.28709927201271057
30-01-2023 07:35:55 INFO Epoch 2: [485/10940] ---- BYOL Training Loss = 0.313517302274704
30-01-2023 07:36:47 INFO Epoch 2: [485/10940] ---- BYOL Validation Loss = 0.2896144688129425
30-01-2023 07:37:05 INFO Epoch 2: [496/10940] ---- BYOL Training Loss = 0.3155010938644409
30-01-2023 07:37:22 INFO Epoch 2: [507/10940] ---- BYOL Training Loss = 0.30826789140701294
30-01-2023 07:37:40 INFO Epoch 2: [518/10940] ---- BYOL Training Loss = 0.28133296966552734
30-01-2023 07:37:57 INFO Epoch 2: [529/10940] ---- BYOL Training Loss = 0.2554645836353302
30-01-2023 07:38:50 INFO Epoch 2: [529/10940] ---- BYOL Validation Loss = 0.2904023230075836
30-01-2023 07:39:07 INFO Epoch 2: [540/10940] ---- BYOL Training Loss = 0.26355236768722534
30-01-2023 07:39:25 INFO Epoch 2: [551/10940] ---- BYOL Training Loss = 0.2777661681175232
30-01-2023 07:39:42 INFO Epoch 2: [562/10940] ---- BYOL Training Loss = 0.30823761224746704
30-01-2023 07:40:00 INFO Epoch 2: [573/10940] ---- BYOL Training Loss = 0.2982429563999176
30-01-2023 07:40:52 INFO Epoch 2: [573/10940] ---- BYOL Validation Loss = 0.2944175899028778
30-01-2023 07:41:10 INFO Epoch 2: [584/10940] ---- BYOL Training Loss = 0.31373757123947144
30-01-2023 07:41:27 INFO Epoch 2: [595/10940] ---- BYOL Training Loss = 0.2963179349899292
30-01-2023 07:41:45 INFO Epoch 2: [606/10940] ---- BYOL Training Loss = 0.2906251549720764
30-01-2023 07:42:02 INFO Epoch 2: [617/10940] ---- BYOL Training Loss = 0.29564693570137024
30-01-2023 07:42:55 INFO Epoch 2: [617/10940] ---- BYOL Validation Loss = 0.29108092188835144
30-01-2023 07:43:12 INFO Epoch 2: [628/10940] ---- BYOL Training Loss = 0.2524677813053131
30-01-2023 07:43:30 INFO Epoch 2: [639/10940] ---- BYOL Training Loss = 0.27146250009536743
30-01-2023 07:43:47 INFO Epoch 2: [650/10940] ---- BYOL Training Loss = 0.3207336962223053
30-01-2023 07:44:05 INFO Epoch 2: [661/10940] ---- BYOL Training Loss = 0.3097183406352997
30-01-2023 07:44:57 INFO Epoch 2: [661/10940] ---- BYOL Validation Loss = 0.28526630997657776
30-01-2023 07:45:15 INFO Epoch 2: [672/10940] ---- BYOL Training Loss = 0.2847776412963867
30-01-2023 07:45:32 INFO Epoch 2: [683/10940] ---- BYOL Training Loss = 0.2459554672241211
30-01-2023 07:45:50 INFO Epoch 2: [694/10940] ---- BYOL Training Loss = 0.2445099651813507
30-01-2023 07:46:07 INFO Epoch 2: [705/10940] ---- BYOL Training Loss = 0.332194447517395
30-01-2023 07:47:00 INFO Epoch 2: [705/10940] ---- BYOL Validation Loss = 0.29613828659057617
30-01-2023 07:47:17 INFO Epoch 2: [716/10940] ---- BYOL Training Loss = 0.32829251885414124
30-01-2023 07:47:35 INFO Epoch 2: [727/10940] ---- BYOL Training Loss = 0.2886499762535095
30-01-2023 07:47:52 INFO Epoch 2: [738/10940] ---- BYOL Training Loss = 0.2950185239315033
30-01-2023 07:48:10 INFO Epoch 2: [749/10940] ---- BYOL Training Loss = 0.2866024672985077
30-01-2023 07:49:03 INFO Epoch 2: [749/10940] ---- BYOL Validation Loss = 0.295911967754364
30-01-2023 07:49:20 INFO Epoch 2: [760/10940] ---- BYOL Training Loss = 0.28381943702697754
30-01-2023 07:49:37 INFO Epoch 2: [771/10940] ---- BYOL Training Loss = 0.30492928624153137
30-01-2023 07:49:55 INFO Epoch 2: [782/10940] ---- BYOL Training Loss = 0.2810514271259308
30-01-2023 07:50:12 INFO Epoch 2: [793/10940] ---- BYOL Training Loss = 0.2930809259414673
30-01-2023 07:51:05 INFO Epoch 2: [793/10940] ---- BYOL Validation Loss = 0.2973507344722748
30-01-2023 07:51:22 INFO Epoch 2: [804/10940] ---- BYOL Training Loss = 0.30811452865600586
30-01-2023 07:51:40 INFO Epoch 2: [815/10940] ---- BYOL Training Loss = 0.3353865444660187
30-01-2023 07:51:57 INFO Epoch 2: [826/10940] ---- BYOL Training Loss = 0.28274303674697876
30-01-2023 07:52:15 INFO Epoch 2: [837/10940] ---- BYOL Training Loss = 0.2691120505332947
30-01-2023 07:53:08 INFO Epoch 2: [837/10940] ---- BYOL Validation Loss = 0.29232531785964966
30-01-2023 07:53:25 INFO Epoch 2: [848/10940] ---- BYOL Training Loss = 0.28332051634788513
30-01-2023 07:53:43 INFO Epoch 2: [859/10940] ---- BYOL Training Loss = 0.2692108154296875
30-01-2023 07:54:00 INFO Epoch 2: [870/10940] ---- BYOL Training Loss = 0.28916501998901367
30-01-2023 07:54:18 INFO Epoch 2: [881/10940] ---- BYOL Training Loss = 0.3138824999332428
30-01-2023 07:55:11 INFO Epoch 2: [881/10940] ---- BYOL Validation Loss = 0.2904840409755707
30-01-2023 07:55:28 INFO Epoch 2: [892/10940] ---- BYOL Training Loss = 0.30994677543640137
30-01-2023 07:55:46 INFO Epoch 2: [903/10940] ---- BYOL Training Loss = 0.2935650944709778
30-01-2023 07:56:03 INFO Epoch 2: [914/10940] ---- BYOL Training Loss = 0.32153406739234924
30-01-2023 07:56:21 INFO Epoch 2: [925/10940] ---- BYOL Training Loss = 0.33741259574890137
30-01-2023 07:57:13 INFO Epoch 2: [925/10940] ---- BYOL Validation Loss = 0.29644694924354553
30-01-2023 07:57:31 INFO Epoch 2: [936/10940] ---- BYOL Training Loss = 0.3205065131187439
30-01-2023 07:57:48 INFO Epoch 2: [947/10940] ---- BYOL Training Loss = 0.2743981182575226
30-01-2023 07:58:06 INFO Epoch 2: [958/10940] ---- BYOL Training Loss = 0.2930259108543396
30-01-2023 07:58:23 INFO Epoch 2: [969/10940] ---- BYOL Training Loss = 0.3206492066383362
30-01-2023 07:59:16 INFO Epoch 2: [969/10940] ---- BYOL Validation Loss = 0.29460853338241577
30-01-2023 07:59:33 INFO Epoch 2: [980/10940] ---- BYOL Training Loss = 0.2875531017780304
30-01-2023 07:59:51 INFO Epoch 2: [991/10940] ---- BYOL Training Loss = 0.32897546887397766
30-01-2023 08:00:08 INFO Epoch 2: [1002/10940] ---- BYOL Training Loss = 0.34688955545425415
30-01-2023 08:00:26 INFO Epoch 2: [1013/10940] ---- BYOL Training Loss = 0.3212966322898865
30-01-2023 08:01:19 INFO Epoch 2: [1013/10940] ---- BYOL Validation Loss = 0.28801658749580383
30-01-2023 08:01:36 INFO Epoch 2: [1024/10940] ---- BYOL Training Loss = 0.35583269596099854
30-01-2023 08:01:53 INFO Epoch 2: [1035/10940] ---- BYOL Training Loss = 0.3062736392021179
30-01-2023 08:02:11 INFO Epoch 2: [1046/10940] ---- BYOL Training Loss = 0.25910577178001404
30-01-2023 08:02:29 INFO Epoch 2: [1057/10940] ---- BYOL Training Loss = 0.3087899088859558
30-01-2023 08:03:21 INFO Epoch 2: [1057/10940] ---- BYOL Validation Loss = 0.2840672731399536
30-01-2023 08:03:38 INFO Epoch 2: [1068/10940] ---- BYOL Training Loss = 0.3266386389732361
30-01-2023 08:03:56 INFO Epoch 2: [1079/10940] ---- BYOL Training Loss = 0.2798539996147156
30-01-2023 08:04:14 INFO Epoch 2: [1090/10940] ---- BYOL Training Loss = 0.2630809247493744
30-01-2023 08:04:31 INFO Epoch 2: [1101/10940] ---- BYOL Training Loss = 0.2865491807460785
30-01-2023 08:05:24 INFO Epoch 2: [1101/10940] ---- BYOL Validation Loss = 0.2826825976371765
30-01-2023 08:05:41 INFO Epoch 2: [1112/10940] ---- BYOL Training Loss = 0.27303072810173035
30-01-2023 08:05:59 INFO Epoch 2: [1123/10940] ---- BYOL Training Loss = 0.28120237588882446
30-01-2023 08:06:17 INFO Epoch 2: [1134/10940] ---- BYOL Training Loss = 0.3041861057281494
30-01-2023 08:06:34 INFO Epoch 2: [1145/10940] ---- BYOL Training Loss = 0.27996861934661865
30-01-2023 08:07:27 INFO Epoch 2: [1145/10940] ---- BYOL Validation Loss = 0.2906973659992218
30-01-2023 08:07:44 INFO Epoch 2: [1156/10940] ---- BYOL Training Loss = 0.27547016739845276
30-01-2023 08:08:02 INFO Epoch 2: [1167/10940] ---- BYOL Training Loss = 0.28280821442604065
30-01-2023 08:08:20 INFO Epoch 2: [1178/10940] ---- BYOL Training Loss = 0.30377817153930664
30-01-2023 08:08:37 INFO Epoch 2: [1189/10940] ---- BYOL Training Loss = 0.3047410845756531
30-01-2023 08:09:30 INFO Epoch 2: [1189/10940] ---- BYOL Validation Loss = 0.27078375220298767
30-01-2023 08:09:47 INFO Epoch 2: [1200/10940] ---- BYOL Training Loss = 0.2710422873497009
30-01-2023 08:10:05 INFO Epoch 2: [1211/10940] ---- BYOL Training Loss = 0.29462236166000366
30-01-2023 08:10:22 INFO Epoch 2: [1222/10940] ---- BYOL Training Loss = 0.3214990794658661
30-01-2023 08:10:40 INFO Epoch 2: [1233/10940] ---- BYOL Training Loss = 0.29544797539711
30-01-2023 08:11:32 INFO Epoch 2: [1233/10940] ---- BYOL Validation Loss = 0.2871048152446747
30-01-2023 08:11:50 INFO Epoch 2: [1244/10940] ---- BYOL Training Loss = 0.3143903911113739
30-01-2023 08:12:07 INFO Epoch 2: [1255/10940] ---- BYOL Training Loss = 0.3164222240447998
30-01-2023 08:12:25 INFO Epoch 2: [1266/10940] ---- BYOL Training Loss = 0.2922251522541046
30-01-2023 08:12:42 INFO Epoch 2: [1277/10940] ---- BYOL Training Loss = 0.2709786891937256
30-01-2023 08:13:35 INFO Epoch 2: [1277/10940] ---- BYOL Validation Loss = 0.2863292694091797
30-01-2023 08:13:52 INFO Epoch 2: [1288/10940] ---- BYOL Training Loss = 0.25077980756759644
30-01-2023 08:14:10 INFO Epoch 2: [1299/10940] ---- BYOL Training Loss = 0.30454766750335693
30-01-2023 08:14:27 INFO Epoch 2: [1310/10940] ---- BYOL Training Loss = 0.3210428059101105
30-01-2023 08:14:45 INFO Epoch 2: [1321/10940] ---- BYOL Training Loss = 0.3108448386192322
30-01-2023 08:15:38 INFO Epoch 2: [1321/10940] ---- BYOL Validation Loss = 0.2873323857784271
30-01-2023 08:15:55 INFO Epoch 2: [1332/10940] ---- BYOL Training Loss = 0.3059626817703247
30-01-2023 08:16:13 INFO Epoch 2: [1343/10940] ---- BYOL Training Loss = 0.2879616618156433
30-01-2023 08:16:30 INFO Epoch 2: [1354/10940] ---- BYOL Training Loss = 0.30993959307670593
30-01-2023 08:16:48 INFO Epoch 2: [1365/10940] ---- BYOL Training Loss = 0.3332262933254242
30-01-2023 08:17:41 INFO Epoch 2: [1365/10940] ---- BYOL Validation Loss = 0.29994967579841614
30-01-2023 08:17:58 INFO Epoch 2: [1376/10940] ---- BYOL Training Loss = 0.31828320026397705
30-01-2023 08:18:16 INFO Epoch 2: [1387/10940] ---- BYOL Training Loss = 0.28963005542755127
30-01-2023 08:18:33 INFO Epoch 2: [1398/10940] ---- BYOL Training Loss = 0.2724980413913727
30-01-2023 08:18:51 INFO Epoch 2: [1409/10940] ---- BYOL Training Loss = 0.27369117736816406
30-01-2023 08:19:44 INFO Epoch 2: [1409/10940] ---- BYOL Validation Loss = 0.2977006733417511
30-01-2023 08:20:01 INFO Epoch 2: [1420/10940] ---- BYOL Training Loss = 0.3070346415042877
30-01-2023 08:20:19 INFO Epoch 2: [1431/10940] ---- BYOL Training Loss = 0.3437788486480713
30-01-2023 08:20:37 INFO Epoch 2: [1442/10940] ---- BYOL Training Loss = 0.3278770446777344
30-01-2023 08:20:54 INFO Epoch 2: [1453/10940] ---- BYOL Training Loss = 0.28167641162872314
30-01-2023 08:21:47 INFO Epoch 2: [1453/10940] ---- BYOL Validation Loss = 0.2803139388561249
30-01-2023 08:22:04 INFO Epoch 2: [1464/10940] ---- BYOL Training Loss = 0.24627888202667236
30-01-2023 08:22:22 INFO Epoch 2: [1475/10940] ---- BYOL Training Loss = 0.27978628873825073
30-01-2023 08:22:39 INFO Epoch 2: [1486/10940] ---- BYOL Training Loss = 0.30716195702552795
30-01-2023 08:22:57 INFO Epoch 2: [1497/10940] ---- BYOL Training Loss = 0.27168136835098267
30-01-2023 08:23:50 INFO Epoch 2: [1497/10940] ---- BYOL Validation Loss = 0.2910926342010498
30-01-2023 08:24:07 INFO Epoch 2: [1508/10940] ---- BYOL Training Loss = 0.2494617998600006
30-01-2023 08:24:25 INFO Epoch 2: [1519/10940] ---- BYOL Training Loss = 0.25910717248916626
30-01-2023 08:24:42 INFO Epoch 2: [1530/10940] ---- BYOL Training Loss = 0.297869473695755
30-01-2023 08:25:00 INFO Epoch 2: [1541/10940] ---- BYOL Training Loss = 0.32120051980018616
30-01-2023 08:25:52 INFO Epoch 2: [1541/10940] ---- BYOL Validation Loss = 0.2895723879337311
30-01-2023 08:26:10 INFO Epoch 2: [1552/10940] ---- BYOL Training Loss = 0.2927469313144684
30-01-2023 08:26:27 INFO Epoch 2: [1563/10940] ---- BYOL Training Loss = 0.23711057007312775
30-01-2023 08:26:45 INFO Epoch 2: [1574/10940] ---- BYOL Training Loss = 0.2521336078643799
30-01-2023 08:27:03 INFO Epoch 2: [1585/10940] ---- BYOL Training Loss = 0.2536533772945404
30-01-2023 08:27:56 INFO Epoch 2: [1585/10940] ---- BYOL Validation Loss = 0.2806416153907776
30-01-2023 08:28:13 INFO Epoch 2: [1596/10940] ---- BYOL Training Loss = 0.2697298228740692
30-01-2023 08:28:30 INFO Epoch 2: [1607/10940] ---- BYOL Training Loss = 0.3198244571685791
30-01-2023 08:28:48 INFO Epoch 2: [1618/10940] ---- BYOL Training Loss = 0.29299867153167725
30-01-2023 08:29:06 INFO Epoch 2: [1629/10940] ---- BYOL Training Loss = 0.24920761585235596
30-01-2023 08:29:58 INFO Epoch 2: [1629/10940] ---- BYOL Validation Loss = 0.2727983891963959
30-01-2023 08:30:16 INFO Epoch 2: [1640/10940] ---- BYOL Training Loss = 0.24034824967384338
30-01-2023 08:30:34 INFO Epoch 2: [1651/10940] ---- BYOL Training Loss = 0.2827165722846985
30-01-2023 08:30:51 INFO Epoch 2: [1662/10940] ---- BYOL Training Loss = 0.3357465863227844
30-01-2023 08:31:09 INFO Epoch 2: [1673/10940] ---- BYOL Training Loss = 0.30305200815200806
30-01-2023 08:32:02 INFO Epoch 2: [1673/10940] ---- BYOL Validation Loss = 0.2753518521785736
30-01-2023 08:32:19 INFO Epoch 2: [1684/10940] ---- BYOL Training Loss = 0.27527421712875366
30-01-2023 08:32:37 INFO Epoch 2: [1695/10940] ---- BYOL Training Loss = 0.2747167944908142
30-01-2023 08:32:54 INFO Epoch 2: [1706/10940] ---- BYOL Training Loss = 0.3111441731452942
30-01-2023 08:33:12 INFO Epoch 2: [1717/10940] ---- BYOL Training Loss = 0.3127623200416565
30-01-2023 08:34:05 INFO Epoch 2: [1717/10940] ---- BYOL Validation Loss = 0.2785414159297943
30-01-2023 08:34:22 INFO Epoch 2: [1728/10940] ---- BYOL Training Loss = 0.2767733335494995
30-01-2023 08:34:39 INFO Epoch 2: [1739/10940] ---- BYOL Training Loss = 0.27365779876708984
30-01-2023 08:34:57 INFO Epoch 2: [1750/10940] ---- BYOL Training Loss = 0.2861531972885132
30-01-2023 08:35:15 INFO Epoch 2: [1761/10940] ---- BYOL Training Loss = 0.2817450165748596
30-01-2023 08:36:07 INFO Epoch 2: [1761/10940] ---- BYOL Validation Loss = 0.27309513092041016
30-01-2023 08:36:25 INFO Epoch 2: [1772/10940] ---- BYOL Training Loss = 0.27897804975509644
30-01-2023 08:36:42 INFO Epoch 2: [1783/10940] ---- BYOL Training Loss = 0.3027324080467224
30-01-2023 08:37:00 INFO Epoch 2: [1794/10940] ---- BYOL Training Loss = 0.2932332754135132
30-01-2023 08:37:18 INFO Epoch 2: [1805/10940] ---- BYOL Training Loss = 0.30793246626853943
30-01-2023 08:38:10 INFO Epoch 2: [1805/10940] ---- BYOL Validation Loss = 0.2800028324127197
30-01-2023 08:38:28 INFO Epoch 2: [1816/10940] ---- BYOL Training Loss = 0.34718742966651917
30-01-2023 08:38:46 INFO Epoch 2: [1827/10940] ---- BYOL Training Loss = 0.28005164861679077
30-01-2023 08:39:03 INFO Epoch 2: [1838/10940] ---- BYOL Training Loss = 0.2813907563686371
30-01-2023 08:39:21 INFO Epoch 2: [1849/10940] ---- BYOL Training Loss = 0.29368695616722107
30-01-2023 08:40:13 INFO Epoch 2: [1849/10940] ---- BYOL Validation Loss = 0.2829168140888214
30-01-2023 08:40:31 INFO Epoch 2: [1860/10940] ---- BYOL Training Loss = 0.3184301257133484
30-01-2023 08:40:48 INFO Epoch 2: [1871/10940] ---- BYOL Training Loss = 0.2855331599712372
30-01-2023 08:41:06 INFO Epoch 2: [1882/10940] ---- BYOL Training Loss = 0.25986388325691223
30-01-2023 08:41:24 INFO Epoch 2: [1893/10940] ---- BYOL Training Loss = 0.28916841745376587
30-01-2023 08:42:16 INFO Epoch 2: [1893/10940] ---- BYOL Validation Loss = 0.2746249735355377
30-01-2023 08:42:34 INFO Epoch 2: [1904/10940] ---- BYOL Training Loss = 0.2772378921508789
30-01-2023 08:42:51 INFO Epoch 2: [1915/10940] ---- BYOL Training Loss = 0.32876142859458923
30-01-2023 08:43:09 INFO Epoch 2: [1926/10940] ---- BYOL Training Loss = 0.34722867608070374
30-01-2023 08:43:27 INFO Epoch 2: [1937/10940] ---- BYOL Training Loss = 0.31402459740638733
30-01-2023 08:44:19 INFO Epoch 2: [1937/10940] ---- BYOL Validation Loss = 0.28350022435188293
30-01-2023 08:44:37 INFO Epoch 2: [1948/10940] ---- BYOL Training Loss = 0.3416680097579956
30-01-2023 08:44:54 INFO Epoch 2: [1959/10940] ---- BYOL Training Loss = 0.3264705240726471
30-01-2023 08:45:12 INFO Epoch 2: [1970/10940] ---- BYOL Training Loss = 0.31947842240333557
30-01-2023 08:45:30 INFO Epoch 2: [1981/10940] ---- BYOL Training Loss = 0.322870135307312
30-01-2023 08:46:22 INFO Epoch 2: [1981/10940] ---- BYOL Validation Loss = 0.2836359441280365
30-01-2023 08:46:39 INFO Epoch 2: [1992/10940] ---- BYOL Training Loss = 0.3174193799495697
30-01-2023 08:46:57 INFO Epoch 2: [2003/10940] ---- BYOL Training Loss = 0.3192046284675598
30-01-2023 08:47:15 INFO Epoch 2: [2014/10940] ---- BYOL Training Loss = 0.32566484808921814
30-01-2023 08:47:33 INFO Epoch 2: [2025/10940] ---- BYOL Training Loss = 0.3472115993499756
30-01-2023 08:48:25 INFO Epoch 2: [2025/10940] ---- BYOL Validation Loss = 0.2794933021068573
30-01-2023 08:48:43 INFO Epoch 2: [2036/10940] ---- BYOL Training Loss = 0.3100222945213318
30-01-2023 08:49:00 INFO Epoch 2: [2047/10940] ---- BYOL Training Loss = 0.32358282804489136
30-01-2023 08:49:18 INFO Epoch 2: [2058/10940] ---- BYOL Training Loss = 0.3154849410057068
30-01-2023 08:49:36 INFO Epoch 2: [2069/10940] ---- BYOL Training Loss = 0.3008871376514435
30-01-2023 08:50:28 INFO Epoch 2: [2069/10940] ---- BYOL Validation Loss = 0.2903960645198822
30-01-2023 08:50:46 INFO Epoch 2: [2080/10940] ---- BYOL Training Loss = 0.29150551557540894
30-01-2023 08:51:03 INFO Epoch 2: [2091/10940] ---- BYOL Training Loss = 0.2648906111717224
30-01-2023 08:51:21 INFO Epoch 2: [2102/10940] ---- BYOL Training Loss = 0.282787561416626
30-01-2023 08:51:39 INFO Epoch 2: [2113/10940] ---- BYOL Training Loss = 0.27526170015335083
30-01-2023 08:52:31 INFO Epoch 2: [2113/10940] ---- BYOL Validation Loss = 0.2774043381214142
30-01-2023 08:52:49 INFO Epoch 2: [2124/10940] ---- BYOL Training Loss = 0.3124410808086395
30-01-2023 08:53:06 INFO Epoch 2: [2135/10940] ---- BYOL Training Loss = 0.31465452909469604
30-01-2023 08:53:24 INFO Epoch 2: [2146/10940] ---- BYOL Training Loss = 0.2828984260559082
30-01-2023 08:53:42 INFO Epoch 2: [2157/10940] ---- BYOL Training Loss = 0.3018220067024231
30-01-2023 08:54:35 INFO Epoch 2: [2157/10940] ---- BYOL Validation Loss = 0.28706035017967224
30-01-2023 08:54:52 INFO Epoch 2: [2168/10940] ---- BYOL Training Loss = 0.3094673156738281
30-01-2023 08:55:10 INFO Epoch 2: [2179/10940] ---- BYOL Training Loss = 0.29814156889915466
30-01-2023 08:55:28 INFO Epoch 2: [2190/10940] ---- BYOL Training Loss = 0.30893993377685547
30-01-2023 08:55:46 INFO Epoch 2: [2201/10940] ---- BYOL Training Loss = 0.29709604382514954
30-01-2023 08:56:38 INFO Epoch 2: [2201/10940] ---- BYOL Validation Loss = 0.28531575202941895
30-01-2023 08:56:56 INFO Epoch 2: [2212/10940] ---- BYOL Training Loss = 0.2550997734069824
30-01-2023 08:57:13 INFO Epoch 2: [2223/10940] ---- BYOL Training Loss = 0.26209166646003723
30-01-2023 08:57:31 INFO Epoch 2: [2234/10940] ---- BYOL Training Loss = 0.2981865406036377
30-01-2023 08:57:49 INFO Epoch 2: [2245/10940] ---- BYOL Training Loss = 0.2525096535682678
30-01-2023 08:58:42 INFO Epoch 2: [2245/10940] ---- BYOL Validation Loss = 0.2847083508968353
30-01-2023 08:58:59 INFO Epoch 2: [2256/10940] ---- BYOL Training Loss = 0.30155307054519653
30-01-2023 08:59:17 INFO Epoch 2: [2267/10940] ---- BYOL Training Loss = 0.3051312565803528
30-01-2023 08:59:35 INFO Epoch 2: [2278/10940] ---- BYOL Training Loss = 0.29099416732788086
30-01-2023 08:59:53 INFO Epoch 2: [2289/10940] ---- BYOL Training Loss = 0.30482709407806396
30-01-2023 09:00:45 INFO Epoch 2: [2289/10940] ---- BYOL Validation Loss = 0.2926728427410126
30-01-2023 09:01:03 INFO Epoch 2: [2300/10940] ---- BYOL Training Loss = 0.2883072793483734
30-01-2023 09:01:20 INFO Epoch 2: [2311/10940] ---- BYOL Training Loss = 0.3087829649448395
30-01-2023 09:01:38 INFO Epoch 2: [2322/10940] ---- BYOL Training Loss = 0.28976017236709595
30-01-2023 09:01:56 INFO Epoch 2: [2333/10940] ---- BYOL Training Loss = 0.2621713876724243
30-01-2023 09:02:48 INFO Epoch 2: [2333/10940] ---- BYOL Validation Loss = 0.28247198462486267
30-01-2023 09:03:06 INFO Epoch 2: [2344/10940] ---- BYOL Training Loss = 0.25999683141708374
30-01-2023 09:03:23 INFO Epoch 2: [2355/10940] ---- BYOL Training Loss = 0.25109750032424927
30-01-2023 09:03:41 INFO Epoch 2: [2366/10940] ---- BYOL Training Loss = 0.26883944869041443
30-01-2023 09:03:59 INFO Epoch 2: [2377/10940] ---- BYOL Training Loss = 0.3003471791744232
30-01-2023 09:04:51 INFO Epoch 2: [2377/10940] ---- BYOL Validation Loss = 0.2686208188533783
30-01-2023 09:05:09 INFO Epoch 2: [2388/10940] ---- BYOL Training Loss = 0.3256533443927765
30-01-2023 09:05:26 INFO Epoch 2: [2399/10940] ---- BYOL Training Loss = 0.3551669716835022
30-01-2023 09:05:44 INFO Epoch 2: [2410/10940] ---- BYOL Training Loss = 0.29917165637016296
30-01-2023 09:06:02 INFO Epoch 2: [2421/10940] ---- BYOL Training Loss = 0.25589051842689514
30-01-2023 09:06:55 INFO Epoch 2: [2421/10940] ---- BYOL Validation Loss = 0.2820435166358948
30-01-2023 09:07:12 INFO Epoch 2: [2432/10940] ---- BYOL Training Loss = 0.2829018533229828
30-01-2023 09:07:30 INFO Epoch 2: [2443/10940] ---- BYOL Training Loss = 0.30559080839157104
30-01-2023 09:07:48 INFO Epoch 2: [2454/10940] ---- BYOL Training Loss = 0.3008429706096649
30-01-2023 09:08:05 INFO Epoch 2: [2465/10940] ---- BYOL Training Loss = 0.3006792962551117
30-01-2023 09:08:58 INFO Epoch 2: [2465/10940] ---- BYOL Validation Loss = 0.27816903591156006
30-01-2023 09:09:15 INFO Epoch 2: [2476/10940] ---- BYOL Training Loss = 0.2824110686779022
30-01-2023 09:09:33 INFO Epoch 2: [2487/10940] ---- BYOL Training Loss = 0.2926899194717407
30-01-2023 09:09:51 INFO Epoch 2: [2498/10940] ---- BYOL Training Loss = 0.25494101643562317
30-01-2023 09:10:09 INFO Epoch 2: [2509/10940] ---- BYOL Training Loss = 0.3136662244796753
30-01-2023 09:11:01 INFO Epoch 2: [2509/10940] ---- BYOL Validation Loss = 0.2823111414909363
30-01-2023 09:11:19 INFO Epoch 2: [2520/10940] ---- BYOL Training Loss = 0.3449934422969818
30-01-2023 09:11:36 INFO Epoch 2: [2531/10940] ---- BYOL Training Loss = 0.24747610092163086
30-01-2023 09:11:54 INFO Epoch 2: [2542/10940] ---- BYOL Training Loss = 0.27247458696365356
30-01-2023 09:12:12 INFO Epoch 2: [2553/10940] ---- BYOL Training Loss = 0.2839474081993103
30-01-2023 09:13:05 INFO Epoch 2: [2553/10940] ---- BYOL Validation Loss = 0.2709272801876068
30-01-2023 09:13:22 INFO Epoch 2: [2564/10940] ---- BYOL Training Loss = 0.25861477851867676
30-01-2023 09:13:40 INFO Epoch 2: [2575/10940] ---- BYOL Training Loss = 0.2891921401023865
30-01-2023 09:13:57 INFO Epoch 2: [2586/10940] ---- BYOL Training Loss = 0.3185606896877289
30-01-2023 09:14:15 INFO Epoch 2: [2597/10940] ---- BYOL Training Loss = 0.29781705141067505
30-01-2023 09:15:08 INFO Epoch 2: [2597/10940] ---- BYOL Validation Loss = 0.2759765684604645
30-01-2023 09:15:25 INFO Epoch 2: [2608/10940] ---- BYOL Training Loss = 0.3031062185764313
30-01-2023 09:15:43 INFO Epoch 2: [2619/10940] ---- BYOL Training Loss = 0.31024035811424255
30-01-2023 09:16:01 INFO Epoch 2: [2630/10940] ---- BYOL Training Loss = 0.29236334562301636
30-01-2023 09:16:19 INFO Epoch 2: [2641/10940] ---- BYOL Training Loss = 0.30436134338378906
30-01-2023 09:17:11 INFO Epoch 2: [2641/10940] ---- BYOL Validation Loss = 0.2785792648792267
30-01-2023 09:17:29 INFO Epoch 2: [2652/10940] ---- BYOL Training Loss = 0.28450047969818115
30-01-2023 09:17:47 INFO Epoch 2: [2663/10940] ---- BYOL Training Loss = 0.2964492440223694
30-01-2023 09:18:04 INFO Epoch 2: [2674/10940] ---- BYOL Training Loss = 0.30976349115371704
30-01-2023 09:18:22 INFO Epoch 2: [2685/10940] ---- BYOL Training Loss = 0.32896214723587036
30-01-2023 09:19:15 INFO Epoch 2: [2685/10940] ---- BYOL Validation Loss = 0.28253206610679626
30-01-2023 09:19:32 INFO Epoch 2: [2696/10940] ---- BYOL Training Loss = 0.3153124749660492
30-01-2023 09:19:50 INFO Epoch 2: [2707/10940] ---- BYOL Training Loss = 0.300711452960968
30-01-2023 09:20:08 INFO Epoch 2: [2718/10940] ---- BYOL Training Loss = 0.29107457399368286
30-01-2023 09:20:25 INFO Epoch 2: [2729/10940] ---- BYOL Training Loss = 0.2840995490550995
30-01-2023 09:21:18 INFO Epoch 2: [2729/10940] ---- BYOL Validation Loss = 0.2766073942184448
30-01-2023 09:21:36 INFO Epoch 2: [2740/10940] ---- BYOL Training Loss = 0.30599474906921387
30-01-2023 09:21:54 INFO Epoch 2: [2751/10940] ---- BYOL Training Loss = 0.2644769549369812
30-01-2023 09:22:11 INFO Epoch 2: [2762/10940] ---- BYOL Training Loss = 0.2766709327697754
30-01-2023 09:22:29 INFO Epoch 2: [2773/10940] ---- BYOL Training Loss = 0.34104496240615845
30-01-2023 09:23:22 INFO Epoch 2: [2773/10940] ---- BYOL Validation Loss = 0.2840886116027832
30-01-2023 09:23:39 INFO Epoch 2: [2784/10940] ---- BYOL Training Loss = 0.3131590783596039
30-01-2023 09:23:57 INFO Epoch 2: [2795/10940] ---- BYOL Training Loss = 0.25544270873069763
30-01-2023 09:24:15 INFO Epoch 2: [2806/10940] ---- BYOL Training Loss = 0.25159046053886414
30-01-2023 09:24:32 INFO Epoch 2: [2817/10940] ---- BYOL Training Loss = 0.29384303092956543
30-01-2023 09:25:25 INFO Epoch 2: [2817/10940] ---- BYOL Validation Loss = 0.282327264547348
30-01-2023 09:25:42 INFO Epoch 2: [2828/10940] ---- BYOL Training Loss = 0.30393967032432556
30-01-2023 09:26:00 INFO Epoch 2: [2839/10940] ---- BYOL Training Loss = 0.3142077922821045
30-01-2023 09:26:18 INFO Epoch 2: [2850/10940] ---- BYOL Training Loss = 0.33425503969192505
30-01-2023 09:26:36 INFO Epoch 2: [2861/10940] ---- BYOL Training Loss = 0.2915443778038025
30-01-2023 09:27:29 INFO Epoch 2: [2861/10940] ---- BYOL Validation Loss = 0.2744387686252594
30-01-2023 09:27:46 INFO Epoch 2: [2872/10940] ---- BYOL Training Loss = 0.2518131136894226
30-01-2023 09:28:04 INFO Epoch 2: [2883/10940] ---- BYOL Training Loss = 0.2953489422798157
30-01-2023 09:28:21 INFO Epoch 2: [2894/10940] ---- BYOL Training Loss = 0.3254111111164093
30-01-2023 09:28:39 INFO Epoch 2: [2905/10940] ---- BYOL Training Loss = 0.2877776324748993
30-01-2023 09:29:32 INFO Epoch 2: [2905/10940] ---- BYOL Validation Loss = 0.2783193290233612
30-01-2023 09:29:49 INFO Epoch 2: [2916/10940] ---- BYOL Training Loss = 0.25808414816856384
30-01-2023 09:30:07 INFO Epoch 2: [2927/10940] ---- BYOL Training Loss = 0.27135390043258667
30-01-2023 09:30:25 INFO Epoch 2: [2938/10940] ---- BYOL Training Loss = 0.3058842122554779
30-01-2023 09:30:43 INFO Epoch 2: [2949/10940] ---- BYOL Training Loss = 0.29234829545021057
30-01-2023 09:31:36 INFO Epoch 2: [2949/10940] ---- BYOL Validation Loss = 0.2625786364078522
30-01-2023 09:31:53 INFO Epoch 2: [2960/10940] ---- BYOL Training Loss = 0.27399033308029175
30-01-2023 09:32:11 INFO Epoch 2: [2971/10940] ---- BYOL Training Loss = 0.24331696331501007
30-01-2023 09:32:28 INFO Epoch 2: [2982/10940] ---- BYOL Training Loss = 0.2912569046020508
30-01-2023 09:32:46 INFO Epoch 2: [2993/10940] ---- BYOL Training Loss = 0.32957062125205994
30-01-2023 09:33:39 INFO Epoch 2: [2993/10940] ---- BYOL Validation Loss = 0.285983145236969
30-01-2023 09:33:56 INFO Epoch 2: [3004/10940] ---- BYOL Training Loss = 0.29622453451156616
30-01-2023 09:34:14 INFO Epoch 2: [3015/10940] ---- BYOL Training Loss = 0.3258543014526367
30-01-2023 09:34:32 INFO Epoch 2: [3026/10940] ---- BYOL Training Loss = 0.33811622858047485
30-01-2023 09:34:50 INFO Epoch 2: [3037/10940] ---- BYOL Training Loss = 0.31113100051879883
30-01-2023 09:35:42 INFO Epoch 2: [3037/10940] ---- BYOL Validation Loss = 0.2868559658527374
30-01-2023 09:36:00 INFO Epoch 2: [3048/10940] ---- BYOL Training Loss = 0.33076274394989014
30-01-2023 09:36:18 INFO Epoch 2: [3059/10940] ---- BYOL Training Loss = 0.29781001806259155
30-01-2023 09:36:35 INFO Epoch 2: [3070/10940] ---- BYOL Training Loss = 0.29961997270584106
30-01-2023 09:36:53 INFO Epoch 2: [3081/10940] ---- BYOL Training Loss = 0.3229793310165405
30-01-2023 09:37:46 INFO Epoch 2: [3081/10940] ---- BYOL Validation Loss = 0.2729188799858093
30-01-2023 09:38:03 INFO Epoch 2: [3092/10940] ---- BYOL Training Loss = 0.30699703097343445
30-01-2023 09:38:21 INFO Epoch 2: [3103/10940] ---- BYOL Training Loss = 0.2451292723417282
30-01-2023 09:38:39 INFO Epoch 2: [3114/10940] ---- BYOL Training Loss = 0.2606925964355469
30-01-2023 09:38:57 INFO Epoch 2: [3125/10940] ---- BYOL Training Loss = 0.2963811159133911
30-01-2023 09:39:50 INFO Epoch 2: [3125/10940] ---- BYOL Validation Loss = 0.2771967947483063
30-01-2023 09:40:07 INFO Epoch 2: [3136/10940] ---- BYOL Training Loss = 0.29718977212905884
30-01-2023 09:40:25 INFO Epoch 2: [3147/10940] ---- BYOL Training Loss = 0.3075946867465973
30-01-2023 09:40:43 INFO Epoch 2: [3158/10940] ---- BYOL Training Loss = 0.2913890480995178
30-01-2023 09:41:00 INFO Epoch 2: [3169/10940] ---- BYOL Training Loss = 0.2721722722053528
30-01-2023 09:41:53 INFO Epoch 2: [3169/10940] ---- BYOL Validation Loss = 0.26686450839042664
30-01-2023 09:42:10 INFO Epoch 2: [3180/10940] ---- BYOL Training Loss = 0.27568575739860535
30-01-2023 09:42:28 INFO Epoch 2: [3191/10940] ---- BYOL Training Loss = 0.31276169419288635
30-01-2023 09:42:46 INFO Epoch 2: [3202/10940] ---- BYOL Training Loss = 0.27882009744644165
30-01-2023 09:43:04 INFO Epoch 2: [3213/10940] ---- BYOL Training Loss = 0.2566208243370056
30-01-2023 09:43:57 INFO Epoch 2: [3213/10940] ---- BYOL Validation Loss = 0.27173399925231934
30-01-2023 09:44:14 INFO Epoch 2: [3224/10940] ---- BYOL Training Loss = 0.2678694427013397
30-01-2023 09:44:32 INFO Epoch 2: [3235/10940] ---- BYOL Training Loss = 0.3139505684375763
30-01-2023 09:44:50 INFO Epoch 2: [3246/10940] ---- BYOL Training Loss = 0.31531935930252075
30-01-2023 09:45:08 INFO Epoch 2: [3257/10940] ---- BYOL Training Loss = 0.26606181263923645
30-01-2023 09:46:00 INFO Epoch 2: [3257/10940] ---- BYOL Validation Loss = 0.2738479971885681
30-01-2023 09:46:18 INFO Epoch 2: [3268/10940] ---- BYOL Training Loss = 0.24097004532814026
30-01-2023 09:46:35 INFO Epoch 2: [3279/10940] ---- BYOL Training Loss = 0.2631925642490387
30-01-2023 09:46:54 INFO Epoch 2: [3290/10940] ---- BYOL Training Loss = 0.26562127470970154
30-01-2023 09:47:12 INFO Epoch 2: [3301/10940] ---- BYOL Training Loss = 0.28066641092300415
30-01-2023 09:48:04 INFO Epoch 2: [3301/10940] ---- BYOL Validation Loss = 0.27119091153144836
30-01-2023 09:48:22 INFO Epoch 2: [3312/10940] ---- BYOL Training Loss = 0.27259212732315063
30-01-2023 09:48:39 INFO Epoch 2: [3323/10940] ---- BYOL Training Loss = 0.3120855689048767
30-01-2023 09:48:57 INFO Epoch 2: [3334/10940] ---- BYOL Training Loss = 0.3056219518184662
30-01-2023 09:49:15 INFO Epoch 2: [3345/10940] ---- BYOL Training Loss = 0.3058589994907379
30-01-2023 09:50:08 INFO Epoch 2: [3345/10940] ---- BYOL Validation Loss = 0.2823316752910614
30-01-2023 09:50:25 INFO Epoch 2: [3356/10940] ---- BYOL Training Loss = 0.2983330190181732
30-01-2023 09:50:43 INFO Epoch 2: [3367/10940] ---- BYOL Training Loss = 0.2516951560974121
30-01-2023 09:51:01 INFO Epoch 2: [3378/10940] ---- BYOL Training Loss = 0.2677610516548157
30-01-2023 09:51:19 INFO Epoch 2: [3389/10940] ---- BYOL Training Loss = 0.26834627985954285
30-01-2023 09:52:12 INFO Epoch 2: [3389/10940] ---- BYOL Validation Loss = 0.27475690841674805
30-01-2023 09:52:29 INFO Epoch 2: [3400/10940] ---- BYOL Training Loss = 0.26364487409591675
30-01-2023 09:52:47 INFO Epoch 2: [3411/10940] ---- BYOL Training Loss = 0.2559749484062195
30-01-2023 09:53:05 INFO Epoch 2: [3422/10940] ---- BYOL Training Loss = 0.2643381953239441
30-01-2023 09:53:23 INFO Epoch 2: [3433/10940] ---- BYOL Training Loss = 0.2665577530860901
30-01-2023 09:54:15 INFO Epoch 2: [3433/10940] ---- BYOL Validation Loss = 0.2548595070838928
30-01-2023 09:54:33 INFO Epoch 2: [3444/10940] ---- BYOL Training Loss = 0.26381757855415344
30-01-2023 09:54:51 INFO Epoch 2: [3455/10940] ---- BYOL Training Loss = 0.2820565700531006
30-01-2023 09:55:09 INFO Epoch 2: [3466/10940] ---- BYOL Training Loss = 0.27049827575683594
30-01-2023 09:55:26 INFO Epoch 2: [3477/10940] ---- BYOL Training Loss = 0.22679570317268372
30-01-2023 09:56:19 INFO Epoch 2: [3477/10940] ---- BYOL Validation Loss = 0.27556249499320984
30-01-2023 09:56:36 INFO Epoch 2: [3488/10940] ---- BYOL Training Loss = 0.25911185145378113
30-01-2023 09:56:54 INFO Epoch 2: [3499/10940] ---- BYOL Training Loss = 0.28693240880966187
30-01-2023 09:57:12 INFO Epoch 2: [3510/10940] ---- BYOL Training Loss = 0.29199278354644775
30-01-2023 09:57:30 INFO Epoch 2: [3521/10940] ---- BYOL Training Loss = 0.2881834805011749
30-01-2023 09:58:23 INFO Epoch 2: [3521/10940] ---- BYOL Validation Loss = 0.2755983769893646
30-01-2023 09:58:40 INFO Epoch 2: [3532/10940] ---- BYOL Training Loss = 0.3077768385410309
30-01-2023 09:58:58 INFO Epoch 2: [3543/10940] ---- BYOL Training Loss = 0.33372142910957336
30-01-2023 09:59:16 INFO Epoch 2: [3554/10940] ---- BYOL Training Loss = 0.2938179671764374
30-01-2023 09:59:34 INFO Epoch 2: [3565/10940] ---- BYOL Training Loss = 0.3145533502101898
30-01-2023 10:00:26 INFO Epoch 2: [3565/10940] ---- BYOL Validation Loss = 0.28359726071357727
30-01-2023 10:00:44 INFO Epoch 2: [3576/10940] ---- BYOL Training Loss = 0.29737111926078796
30-01-2023 10:01:02 INFO Epoch 2: [3587/10940] ---- BYOL Training Loss = 0.2550943195819855
30-01-2023 10:01:20 INFO Epoch 2: [3598/10940] ---- BYOL Training Loss = 0.27111107110977173
30-01-2023 10:01:38 INFO Epoch 2: [3609/10940] ---- BYOL Training Loss = 0.2725794315338135
30-01-2023 10:02:30 INFO Epoch 2: [3609/10940] ---- BYOL Validation Loss = 0.27606815099716187
30-01-2023 10:02:48 INFO Epoch 2: [3620/10940] ---- BYOL Training Loss = 0.25562402606010437
30-01-2023 10:03:06 INFO Epoch 2: [3631/10940] ---- BYOL Training Loss = 0.28431206941604614
30-01-2023 10:03:23 INFO Epoch 2: [3642/10940] ---- BYOL Training Loss = 0.33587995171546936
30-01-2023 10:03:41 INFO Epoch 2: [3653/10940] ---- BYOL Training Loss = 0.3624144494533539
30-01-2023 10:04:34 INFO Epoch 2: [3653/10940] ---- BYOL Validation Loss = 0.28114521503448486
30-01-2023 10:04:51 INFO Epoch 2: [3664/10940] ---- BYOL Training Loss = 0.2880064845085144
30-01-2023 10:05:10 INFO Epoch 2: [3675/10940] ---- BYOL Training Loss = 0.2848338782787323
30-01-2023 10:05:27 INFO Epoch 2: [3686/10940] ---- BYOL Training Loss = 0.29542627930641174
30-01-2023 10:05:45 INFO Epoch 2: [3697/10940] ---- BYOL Training Loss = 0.29170170426368713
30-01-2023 10:06:38 INFO Epoch 2: [3697/10940] ---- BYOL Validation Loss = 0.27917078137397766
30-01-2023 10:06:55 INFO Epoch 2: [3708/10940] ---- BYOL Training Loss = 0.33568912744522095
30-01-2023 10:07:13 INFO Epoch 2: [3719/10940] ---- BYOL Training Loss = 0.28400087356567383
30-01-2023 10:07:31 INFO Epoch 2: [3730/10940] ---- BYOL Training Loss = 0.26192301511764526
30-01-2023 10:07:49 INFO Epoch 2: [3741/10940] ---- BYOL Training Loss = 0.3088364899158478
30-01-2023 10:08:42 INFO Epoch 2: [3741/10940] ---- BYOL Validation Loss = 0.285991370677948
30-01-2023 10:08:59 INFO Epoch 2: [3752/10940] ---- BYOL Training Loss = 0.3263514041900635
30-01-2023 10:09:17 INFO Epoch 2: [3763/10940] ---- BYOL Training Loss = 0.2809709906578064
30-01-2023 10:09:35 INFO Epoch 2: [3774/10940] ---- BYOL Training Loss = 0.24182383716106415
30-01-2023 10:09:53 INFO Epoch 2: [3785/10940] ---- BYOL Training Loss = 0.2583526074886322
30-01-2023 10:10:45 INFO Epoch 2: [3785/10940] ---- BYOL Validation Loss = 0.27491453289985657
30-01-2023 10:11:03 INFO Epoch 2: [3796/10940] ---- BYOL Training Loss = 0.31172674894332886
30-01-2023 10:11:21 INFO Epoch 2: [3807/10940] ---- BYOL Training Loss = 0.2872016429901123
30-01-2023 10:11:39 INFO Epoch 2: [3818/10940] ---- BYOL Training Loss = 0.25702768564224243
30-01-2023 10:11:57 INFO Epoch 2: [3829/10940] ---- BYOL Training Loss = 0.33415883779525757
30-01-2023 10:12:50 INFO Epoch 2: [3829/10940] ---- BYOL Validation Loss = 0.28423506021499634
30-01-2023 10:13:07 INFO Epoch 2: [3840/10940] ---- BYOL Training Loss = 0.3138510584831238
30-01-2023 10:13:25 INFO Epoch 2: [3851/10940] ---- BYOL Training Loss = 0.25342753529548645
30-01-2023 10:13:43 INFO Epoch 2: [3862/10940] ---- BYOL Training Loss = 0.2595016360282898
30-01-2023 10:14:01 INFO Epoch 2: [3873/10940] ---- BYOL Training Loss = 0.28180450201034546
30-01-2023 10:14:53 INFO Epoch 2: [3873/10940] ---- BYOL Validation Loss = 0.27715808153152466
30-01-2023 10:15:11 INFO Epoch 2: [3884/10940] ---- BYOL Training Loss = 0.29162532091140747
30-01-2023 10:15:29 INFO Epoch 2: [3895/10940] ---- BYOL Training Loss = 0.2878950536251068
30-01-2023 10:15:47 INFO Epoch 2: [3906/10940] ---- BYOL Training Loss = 0.2809734344482422
30-01-2023 10:16:05 INFO Epoch 2: [3917/10940] ---- BYOL Training Loss = 0.26101651787757874
30-01-2023 10:16:57 INFO Epoch 2: [3917/10940] ---- BYOL Validation Loss = 0.2756234109401703
30-01-2023 10:17:15 INFO Epoch 2: [3928/10940] ---- BYOL Training Loss = 0.2709820568561554
30-01-2023 10:17:33 INFO Epoch 2: [3939/10940] ---- BYOL Training Loss = 0.2929295003414154
30-01-2023 10:17:51 INFO Epoch 2: [3950/10940] ---- BYOL Training Loss = 0.31412142515182495
30-01-2023 10:18:09 INFO Epoch 2: [3961/10940] ---- BYOL Training Loss = 0.3456662893295288
30-01-2023 10:19:02 INFO Epoch 2: [3961/10940] ---- BYOL Validation Loss = 0.28414952754974365
30-01-2023 10:19:19 INFO Epoch 2: [3972/10940] ---- BYOL Training Loss = 0.33636701107025146
30-01-2023 10:19:37 INFO Epoch 2: [3983/10940] ---- BYOL Training Loss = 0.2679349482059479
30-01-2023 10:19:55 INFO Epoch 2: [3994/10940] ---- BYOL Training Loss = 0.25205767154693604
30-01-2023 10:20:13 INFO Epoch 2: [4005/10940] ---- BYOL Training Loss = 0.2401031255722046
30-01-2023 10:21:06 INFO Epoch 2: [4005/10940] ---- BYOL Validation Loss = 0.2727048993110657
30-01-2023 10:21:23 INFO Epoch 2: [4016/10940] ---- BYOL Training Loss = 0.2628858685493469
30-01-2023 10:21:41 INFO Epoch 2: [4027/10940] ---- BYOL Training Loss = 0.2665410339832306
30-01-2023 10:21:59 INFO Epoch 2: [4038/10940] ---- BYOL Training Loss = 0.26920831203460693
30-01-2023 10:22:17 INFO Epoch 2: [4049/10940] ---- BYOL Training Loss = 0.31044140458106995
30-01-2023 10:23:10 INFO Epoch 2: [4049/10940] ---- BYOL Validation Loss = 0.2704422175884247
30-01-2023 10:23:27 INFO Epoch 2: [4060/10940] ---- BYOL Training Loss = 0.2951793670654297
30-01-2023 10:23:45 INFO Epoch 2: [4071/10940] ---- BYOL Training Loss = 0.25207337737083435
30-01-2023 10:24:04 INFO Epoch 2: [4082/10940] ---- BYOL Training Loss = 0.278980016708374
30-01-2023 10:24:21 INFO Epoch 2: [4093/10940] ---- BYOL Training Loss = 0.2689846158027649
30-01-2023 10:25:14 INFO Epoch 2: [4093/10940] ---- BYOL Validation Loss = 0.27521950006484985
30-01-2023 10:25:31 INFO Epoch 2: [4104/10940] ---- BYOL Training Loss = 0.27840304374694824
30-01-2023 10:25:49 INFO Epoch 2: [4115/10940] ---- BYOL Training Loss = 0.28713878989219666
30-01-2023 10:26:07 INFO Epoch 2: [4126/10940] ---- BYOL Training Loss = 0.25778186321258545
30-01-2023 10:26:25 INFO Epoch 2: [4137/10940] ---- BYOL Training Loss = 0.2565096914768219
30-01-2023 10:27:18 INFO Epoch 2: [4137/10940] ---- BYOL Validation Loss = 0.27163904905319214
30-01-2023 10:27:36 INFO Epoch 2: [4148/10940] ---- BYOL Training Loss = 0.26757651567459106
30-01-2023 10:27:54 INFO Epoch 2: [4159/10940] ---- BYOL Training Loss = 0.2888684868812561
30-01-2023 10:28:11 INFO Epoch 2: [4170/10940] ---- BYOL Training Loss = 0.3068575859069824
30-01-2023 10:28:29 INFO Epoch 2: [4181/10940] ---- BYOL Training Loss = 0.30497127771377563
30-01-2023 10:29:22 INFO Epoch 2: [4181/10940] ---- BYOL Validation Loss = 0.282482773065567
30-01-2023 10:29:40 INFO Epoch 2: [4192/10940] ---- BYOL Training Loss = 0.32344964146614075
30-01-2023 10:29:58 INFO Epoch 2: [4203/10940] ---- BYOL Training Loss = 0.30824190378189087
30-01-2023 10:30:16 INFO Epoch 2: [4214/10940] ---- BYOL Training Loss = 0.2822558879852295
30-01-2023 10:30:34 INFO Epoch 2: [4225/10940] ---- BYOL Training Loss = 0.2401997298002243
30-01-2023 10:31:26 INFO Epoch 2: [4225/10940] ---- BYOL Validation Loss = 0.2735716700553894
30-01-2023 10:31:44 INFO Epoch 2: [4236/10940] ---- BYOL Training Loss = 0.25301700830459595
30-01-2023 10:32:02 INFO Epoch 2: [4247/10940] ---- BYOL Training Loss = 0.2962437570095062
30-01-2023 10:32:20 INFO Epoch 2: [4258/10940] ---- BYOL Training Loss = 0.3143925070762634
30-01-2023 10:32:38 INFO Epoch 2: [4269/10940] ---- BYOL Training Loss = 0.30387479066848755
30-01-2023 10:33:31 INFO Epoch 2: [4269/10940] ---- BYOL Validation Loss = 0.2791499197483063
30-01-2023 10:33:48 INFO Epoch 2: [4280/10940] ---- BYOL Training Loss = 0.2770148813724518
30-01-2023 10:34:06 INFO Epoch 2: [4291/10940] ---- BYOL Training Loss = 0.3252861797809601
30-01-2023 10:34:24 INFO Epoch 2: [4302/10940] ---- BYOL Training Loss = 0.30638986825942993
30-01-2023 10:34:42 INFO Epoch 2: [4313/10940] ---- BYOL Training Loss = 0.3013021647930145
30-01-2023 10:35:35 INFO Epoch 2: [4313/10940] ---- BYOL Validation Loss = 0.2792268395423889
30-01-2023 10:35:52 INFO Epoch 2: [4324/10940] ---- BYOL Training Loss = 0.28874072432518005
30-01-2023 10:36:10 INFO Epoch 2: [4335/10940] ---- BYOL Training Loss = 0.3064468502998352
30-01-2023 10:36:28 INFO Epoch 2: [4346/10940] ---- BYOL Training Loss = 0.2898123264312744
30-01-2023 10:36:46 INFO Epoch 2: [4357/10940] ---- BYOL Training Loss = 0.2992669343948364
30-01-2023 10:37:39 INFO Epoch 2: [4357/10940] ---- BYOL Validation Loss = 0.28618648648262024
30-01-2023 10:37:56 INFO Epoch 2: [4368/10940] ---- BYOL Training Loss = 0.3497902750968933
30-01-2023 10:38:14 INFO Epoch 2: [4379/10940] ---- BYOL Training Loss = 0.30334219336509705
30-01-2023 10:38:33 INFO Epoch 2: [4390/10940] ---- BYOL Training Loss = 0.3336905837059021
30-01-2023 10:38:51 INFO Epoch 2: [4401/10940] ---- BYOL Training Loss = 0.2990284860134125
30-01-2023 10:39:44 INFO Epoch 2: [4401/10940] ---- BYOL Validation Loss = 0.2757149636745453
30-01-2023 10:40:01 INFO Epoch 2: [4412/10940] ---- BYOL Training Loss = 0.2856829762458801
30-01-2023 10:40:19 INFO Epoch 2: [4423/10940] ---- BYOL Training Loss = 0.332093745470047
30-01-2023 10:40:37 INFO Epoch 2: [4434/10940] ---- BYOL Training Loss = 0.361199289560318
30-01-2023 10:40:56 INFO Epoch 2: [4445/10940] ---- BYOL Training Loss = 0.33346739411354065
30-01-2023 10:41:48 INFO Epoch 2: [4445/10940] ---- BYOL Validation Loss = 0.2882005274295807
30-01-2023 10:42:06 INFO Epoch 2: [4456/10940] ---- BYOL Training Loss = 0.33937913179397583
30-01-2023 10:42:24 INFO Epoch 2: [4467/10940] ---- BYOL Training Loss = 0.38373687863349915
30-01-2023 10:42:42 INFO Epoch 2: [4478/10940] ---- BYOL Training Loss = 0.31333664059638977
30-01-2023 10:42:59 INFO Epoch 2: [4489/10940] ---- BYOL Training Loss = 0.28344371914863586
30-01-2023 10:43:52 INFO Epoch 2: [4489/10940] ---- BYOL Validation Loss = 0.28143277764320374
30-01-2023 10:44:10 INFO Epoch 2: [4500/10940] ---- BYOL Training Loss = 0.3170703947544098
30-01-2023 10:44:28 INFO Epoch 2: [4511/10940] ---- BYOL Training Loss = 0.3442504405975342
30-01-2023 10:44:46 INFO Epoch 2: [4522/10940] ---- BYOL Training Loss = 0.3193783164024353
30-01-2023 10:45:04 INFO Epoch 2: [4533/10940] ---- BYOL Training Loss = 0.272285133600235
30-01-2023 10:45:56 INFO Epoch 2: [4533/10940] ---- BYOL Validation Loss = 0.27831992506980896
30-01-2023 10:46:14 INFO Epoch 2: [4544/10940] ---- BYOL Training Loss = 0.27883416414260864
30-01-2023 10:46:32 INFO Epoch 2: [4555/10940] ---- BYOL Training Loss = 0.29933804273605347
30-01-2023 10:46:50 INFO Epoch 2: [4566/10940] ---- BYOL Training Loss = 0.3368837833404541
30-01-2023 10:47:08 INFO Epoch 2: [4577/10940] ---- BYOL Training Loss = 0.3599529266357422
30-01-2023 10:48:01 INFO Epoch 2: [4577/10940] ---- BYOL Validation Loss = 0.26774632930755615
30-01-2023 10:48:18 INFO Epoch 2: [4588/10940] ---- BYOL Training Loss = 0.2933892607688904
30-01-2023 10:48:36 INFO Epoch 2: [4599/10940] ---- BYOL Training Loss = 0.2886733412742615
30-01-2023 10:48:54 INFO Epoch 2: [4610/10940] ---- BYOL Training Loss = 0.28182172775268555
30-01-2023 10:49:13 INFO Epoch 2: [4621/10940] ---- BYOL Training Loss = 0.30691519379615784
30-01-2023 10:50:05 INFO Epoch 2: [4621/10940] ---- BYOL Validation Loss = 0.27626052498817444
30-01-2023 10:50:23 INFO Epoch 2: [4632/10940] ---- BYOL Training Loss = 0.31095144152641296
30-01-2023 10:50:41 INFO Epoch 2: [4643/10940] ---- BYOL Training Loss = 0.27087652683258057
30-01-2023 10:50:59 INFO Epoch 2: [4654/10940] ---- BYOL Training Loss = 0.28989940881729126
30-01-2023 10:51:17 INFO Epoch 2: [4665/10940] ---- BYOL Training Loss = 0.31627270579338074
30-01-2023 10:52:10 INFO Epoch 2: [4665/10940] ---- BYOL Validation Loss = 0.2823892831802368
30-01-2023 10:52:28 INFO Epoch 2: [4676/10940] ---- BYOL Training Loss = 0.26609259843826294
30-01-2023 10:52:45 INFO Epoch 2: [4687/10940] ---- BYOL Training Loss = 0.26121947169303894
30-01-2023 10:53:03 INFO Epoch 2: [4698/10940] ---- BYOL Training Loss = 0.28364211320877075
30-01-2023 10:53:21 INFO Epoch 2: [4709/10940] ---- BYOL Training Loss = 0.30062180757522583
30-01-2023 10:54:14 INFO Epoch 2: [4709/10940] ---- BYOL Validation Loss = 0.2787732183933258
30-01-2023 10:54:31 INFO Epoch 2: [4720/10940] ---- BYOL Training Loss = 0.32084912061691284
30-01-2023 10:54:50 INFO Epoch 2: [4731/10940] ---- BYOL Training Loss = 0.27775806188583374
30-01-2023 10:55:08 INFO Epoch 2: [4742/10940] ---- BYOL Training Loss = 0.24797920882701874
30-01-2023 10:55:26 INFO Epoch 2: [4753/10940] ---- BYOL Training Loss = 0.25683820247650146
30-01-2023 10:56:18 INFO Epoch 2: [4753/10940] ---- BYOL Validation Loss = 0.2768959105014801
30-01-2023 10:56:36 INFO Epoch 2: [4764/10940] ---- BYOL Training Loss = 0.2740978002548218
30-01-2023 10:56:54 INFO Epoch 2: [4775/10940] ---- BYOL Training Loss = 0.3054274320602417
30-01-2023 10:57:12 INFO Epoch 2: [4786/10940] ---- BYOL Training Loss = 0.3265777826309204
30-01-2023 10:57:30 INFO Epoch 2: [4797/10940] ---- BYOL Training Loss = 0.3567342758178711
30-01-2023 10:58:23 INFO Epoch 2: [4797/10940] ---- BYOL Validation Loss = 0.28379812836647034
30-01-2023 10:58:40 INFO Epoch 2: [4808/10940] ---- BYOL Training Loss = 0.33120644092559814
30-01-2023 10:58:58 INFO Epoch 2: [4819/10940] ---- BYOL Training Loss = 0.29120105504989624
30-01-2023 10:59:16 INFO Epoch 2: [4830/10940] ---- BYOL Training Loss = 0.296546995639801
30-01-2023 10:59:34 INFO Epoch 2: [4841/10940] ---- BYOL Training Loss = 0.25475645065307617
30-01-2023 11:00:27 INFO Epoch 2: [4841/10940] ---- BYOL Validation Loss = 0.280286580324173
30-01-2023 11:00:45 INFO Epoch 2: [4852/10940] ---- BYOL Training Loss = 0.2640877366065979
30-01-2023 11:01:03 INFO Epoch 2: [4863/10940] ---- BYOL Training Loss = 0.31181976199150085
30-01-2023 11:01:21 INFO Epoch 2: [4874/10940] ---- BYOL Training Loss = 0.2955213487148285
30-01-2023 11:01:39 INFO Epoch 2: [4885/10940] ---- BYOL Training Loss = 0.30452585220336914
30-01-2023 11:02:32 INFO Epoch 2: [4885/10940] ---- BYOL Validation Loss = 0.28504320979118347
30-01-2023 11:02:49 INFO Epoch 2: [4896/10940] ---- BYOL Training Loss = 0.325777530670166
30-01-2023 11:03:08 INFO Epoch 2: [4907/10940] ---- BYOL Training Loss = 0.27714014053344727
30-01-2023 11:03:26 INFO Epoch 2: [4918/10940] ---- BYOL Training Loss = 0.283236563205719
30-01-2023 11:03:44 INFO Epoch 2: [4929/10940] ---- BYOL Training Loss = 0.303352415561676
30-01-2023 11:04:36 INFO Epoch 2: [4929/10940] ---- BYOL Validation Loss = 0.2793896794319153
30-01-2023 11:04:54 INFO Epoch 2: [4940/10940] ---- BYOL Training Loss = 0.34266090393066406
30-01-2023 11:05:12 INFO Epoch 2: [4951/10940] ---- BYOL Training Loss = 0.3453560471534729
30-01-2023 11:05:30 INFO Epoch 2: [4962/10940] ---- BYOL Training Loss = 0.3206845223903656
30-01-2023 11:05:48 INFO Epoch 2: [4973/10940] ---- BYOL Training Loss = 0.29146698117256165
30-01-2023 11:06:41 INFO Epoch 2: [4973/10940] ---- BYOL Validation Loss = 0.2813659906387329
30-01-2023 11:06:59 INFO Epoch 2: [4984/10940] ---- BYOL Training Loss = 0.3168107569217682
30-01-2023 11:07:17 INFO Epoch 2: [4995/10940] ---- BYOL Training Loss = 0.3130842447280884
30-01-2023 11:07:35 INFO Epoch 2: [5006/10940] ---- BYOL Training Loss = 0.25358110666275024
30-01-2023 11:07:53 INFO Epoch 2: [5017/10940] ---- BYOL Training Loss = 0.2596516013145447
30-01-2023 11:08:45 INFO Epoch 2: [5017/10940] ---- BYOL Validation Loss = 0.2747134864330292
30-01-2023 11:09:03 INFO Epoch 2: [5028/10940] ---- BYOL Training Loss = 0.2701367437839508
30-01-2023 11:09:21 INFO Epoch 2: [5039/10940] ---- BYOL Training Loss = 0.29044368863105774
30-01-2023 11:09:39 INFO Epoch 2: [5050/10940] ---- BYOL Training Loss = 0.287975549697876
30-01-2023 11:09:57 INFO Epoch 2: [5061/10940] ---- BYOL Training Loss = 0.3032591640949249
30-01-2023 11:10:49 INFO Epoch 2: [5061/10940] ---- BYOL Validation Loss = 0.2767106294631958
30-01-2023 11:11:07 INFO Epoch 2: [5072/10940] ---- BYOL Training Loss = 0.3129551410675049
30-01-2023 11:11:26 INFO Epoch 2: [5083/10940] ---- BYOL Training Loss = 0.28438466787338257
30-01-2023 11:11:44 INFO Epoch 2: [5094/10940] ---- BYOL Training Loss = 0.27938413619995117
30-01-2023 11:12:02 INFO Epoch 2: [5105/10940] ---- BYOL Training Loss = 0.31967693567276
30-01-2023 11:12:54 INFO Epoch 2: [5105/10940] ---- BYOL Validation Loss = 0.2746650278568268
30-01-2023 11:13:12 INFO Epoch 2: [5116/10940] ---- BYOL Training Loss = 0.28478485345840454
30-01-2023 11:13:30 INFO Epoch 2: [5127/10940] ---- BYOL Training Loss = 0.2835387885570526
30-01-2023 11:13:49 INFO Epoch 2: [5138/10940] ---- BYOL Training Loss = 0.2853512465953827
30-01-2023 11:14:07 INFO Epoch 2: [5149/10940] ---- BYOL Training Loss = 0.2832786440849304
30-01-2023 11:14:59 INFO Epoch 2: [5149/10940] ---- BYOL Validation Loss = 0.27595290541648865
30-01-2023 11:15:17 INFO Epoch 2: [5160/10940] ---- BYOL Training Loss = 0.28835195302963257
30-01-2023 11:15:35 INFO Epoch 2: [5171/10940] ---- BYOL Training Loss = 0.2733362317085266
30-01-2023 11:15:53 INFO Epoch 2: [5182/10940] ---- BYOL Training Loss = 0.300008624792099
30-01-2023 11:16:11 INFO Epoch 2: [5193/10940] ---- BYOL Training Loss = 0.3395792841911316
30-01-2023 11:17:04 INFO Epoch 2: [5193/10940] ---- BYOL Validation Loss = 0.2840442657470703
30-01-2023 11:17:22 INFO Epoch 2: [5204/10940] ---- BYOL Training Loss = 0.2752050757408142
30-01-2023 11:17:40 INFO Epoch 2: [5215/10940] ---- BYOL Training Loss = 0.2453855574131012
30-01-2023 11:17:58 INFO Epoch 2: [5226/10940] ---- BYOL Training Loss = 0.2409842312335968
30-01-2023 11:18:16 INFO Epoch 2: [5237/10940] ---- BYOL Training Loss = 0.3171814978122711
30-01-2023 11:19:09 INFO Epoch 2: [5237/10940] ---- BYOL Validation Loss = 0.27711981534957886
30-01-2023 11:19:26 INFO Epoch 2: [5248/10940] ---- BYOL Training Loss = 0.33125489950180054
30-01-2023 11:19:44 INFO Epoch 2: [5259/10940] ---- BYOL Training Loss = 0.2817344665527344
30-01-2023 11:20:03 INFO Epoch 2: [5270/10940] ---- BYOL Training Loss = 0.29209959506988525
30-01-2023 11:20:21 INFO Epoch 2: [5281/10940] ---- BYOL Training Loss = 0.29690152406692505
30-01-2023 11:21:13 INFO Epoch 2: [5281/10940] ---- BYOL Validation Loss = 0.27109163999557495
30-01-2023 11:21:31 INFO Epoch 2: [5292/10940] ---- BYOL Training Loss = 0.2898954749107361
30-01-2023 11:21:49 INFO Epoch 2: [5303/10940] ---- BYOL Training Loss = 0.2893659174442291
30-01-2023 11:22:07 INFO Epoch 2: [5314/10940] ---- BYOL Training Loss = 0.3209109902381897
30-01-2023 11:22:25 INFO Epoch 2: [5325/10940] ---- BYOL Training Loss = 0.3279019296169281
30-01-2023 11:23:18 INFO Epoch 2: [5325/10940] ---- BYOL Validation Loss = 0.27904394268989563
30-01-2023 11:23:35 INFO Epoch 2: [5336/10940] ---- BYOL Training Loss = 0.2992953658103943
30-01-2023 11:23:53 INFO Epoch 2: [5347/10940] ---- BYOL Training Loss = 0.28251880407333374
30-01-2023 11:24:11 INFO Epoch 2: [5358/10940] ---- BYOL Training Loss = 0.27542945742607117
30-01-2023 11:24:30 INFO Epoch 2: [5369/10940] ---- BYOL Training Loss = 0.2809025049209595
30-01-2023 11:25:22 INFO Epoch 2: [5369/10940] ---- BYOL Validation Loss = 0.2755587697029114
30-01-2023 11:25:40 INFO Epoch 2: [5380/10940] ---- BYOL Training Loss = 0.28800082206726074
30-01-2023 11:25:58 INFO Epoch 2: [5391/10940] ---- BYOL Training Loss = 0.26377642154693604
30-01-2023 11:26:16 INFO Epoch 2: [5402/10940] ---- BYOL Training Loss = 0.2920113801956177
30-01-2023 11:26:34 INFO Epoch 2: [5413/10940] ---- BYOL Training Loss = 0.3301483988761902
30-01-2023 11:27:27 INFO Epoch 2: [5413/10940] ---- BYOL Validation Loss = 0.2768501341342926
30-01-2023 11:27:45 INFO Epoch 2: [5424/10940] ---- BYOL Training Loss = 0.3396417498588562
30-01-2023 11:28:03 INFO Epoch 2: [5435/10940] ---- BYOL Training Loss = 0.309778094291687
30-01-2023 11:28:21 INFO Epoch 2: [5446/10940] ---- BYOL Training Loss = 0.258242666721344
30-01-2023 11:28:39 INFO Epoch 2: [5457/10940] ---- BYOL Training Loss = 0.27322736382484436
30-01-2023 11:29:31 INFO Epoch 2: [5457/10940] ---- BYOL Validation Loss = 0.2728046476840973
30-01-2023 11:29:50 INFO Epoch 2: [5468/10940] ---- BYOL Training Loss = 0.28166672587394714
30-01-2023 11:30:08 INFO Epoch 2: [5479/10940] ---- BYOL Training Loss = 0.27130812406539917
30-01-2023 11:30:26 INFO Epoch 2: [5490/10940] ---- BYOL Training Loss = 0.2642584443092346
30-01-2023 11:30:44 INFO Epoch 2: [5501/10940] ---- BYOL Training Loss = 0.2699092924594879
30-01-2023 11:31:36 INFO Epoch 2: [5501/10940] ---- BYOL Validation Loss = 0.26924532651901245
30-01-2023 11:31:54 INFO Epoch 2: [5512/10940] ---- BYOL Training Loss = 0.2795965075492859
30-01-2023 11:32:12 INFO Epoch 2: [5523/10940] ---- BYOL Training Loss = 0.25961437821388245
30-01-2023 11:32:30 INFO Epoch 2: [5534/10940] ---- BYOL Training Loss = 0.276517778635025
30-01-2023 11:32:48 INFO Epoch 2: [5545/10940] ---- BYOL Training Loss = 0.30300217866897583
30-01-2023 11:33:41 INFO Epoch 2: [5545/10940] ---- BYOL Validation Loss = 0.27237653732299805
30-01-2023 11:33:59 INFO Epoch 2: [5556/10940] ---- BYOL Training Loss = 0.2594664394855499
30-01-2023 11:34:17 INFO Epoch 2: [5567/10940] ---- BYOL Training Loss = 0.2558746933937073
30-01-2023 11:34:35 INFO Epoch 2: [5578/10940] ---- BYOL Training Loss = 0.24333567917346954
30-01-2023 11:34:53 INFO Epoch 2: [5589/10940] ---- BYOL Training Loss = 0.2530331313610077
30-01-2023 11:35:45 INFO Epoch 2: [5589/10940] ---- BYOL Validation Loss = 0.271163672208786
30-01-2023 11:36:03 INFO Epoch 2: [5600/10940] ---- BYOL Training Loss = 0.3160936236381531
30-01-2023 11:36:21 INFO Epoch 2: [5611/10940] ---- BYOL Training Loss = 0.34554770588874817
30-01-2023 11:36:40 INFO Epoch 2: [5622/10940] ---- BYOL Training Loss = 0.2889191210269928
30-01-2023 11:36:58 INFO Epoch 2: [5633/10940] ---- BYOL Training Loss = 0.274172306060791
30-01-2023 11:37:50 INFO Epoch 2: [5633/10940] ---- BYOL Validation Loss = 0.29029610753059387
30-01-2023 11:38:08 INFO Epoch 2: [5644/10940] ---- BYOL Training Loss = 0.26764070987701416
30-01-2023 11:38:26 INFO Epoch 2: [5655/10940] ---- BYOL Training Loss = 0.3195780813694
30-01-2023 11:38:44 INFO Epoch 2: [5666/10940] ---- BYOL Training Loss = 0.32476964592933655
30-01-2023 11:39:02 INFO Epoch 2: [5677/10940] ---- BYOL Training Loss = 0.24356964230537415
30-01-2023 11:39:55 INFO Epoch 2: [5677/10940] ---- BYOL Validation Loss = 0.2854614555835724
30-01-2023 11:40:13 INFO Epoch 2: [5688/10940] ---- BYOL Training Loss = 0.25637495517730713
30-01-2023 11:40:31 INFO Epoch 2: [5699/10940] ---- BYOL Training Loss = 0.27808061242103577
30-01-2023 11:40:49 INFO Epoch 2: [5710/10940] ---- BYOL Training Loss = 0.28226038813591003
30-01-2023 11:41:07 INFO Epoch 2: [5721/10940] ---- BYOL Training Loss = 0.30136069655418396
30-01-2023 11:42:00 INFO Epoch 2: [5721/10940] ---- BYOL Validation Loss = 0.276571124792099
30-01-2023 11:42:17 INFO Epoch 2: [5732/10940] ---- BYOL Training Loss = 0.318970263004303
30-01-2023 11:42:36 INFO Epoch 2: [5743/10940] ---- BYOL Training Loss = 0.3244559168815613
30-01-2023 11:42:54 INFO Epoch 2: [5754/10940] ---- BYOL Training Loss = 0.3092370331287384
30-01-2023 11:43:12 INFO Epoch 2: [5765/10940] ---- BYOL Training Loss = 0.29417043924331665
30-01-2023 11:44:04 INFO Epoch 2: [5765/10940] ---- BYOL Validation Loss = 0.27269378304481506
30-01-2023 11:44:22 INFO Epoch 2: [5776/10940] ---- BYOL Training Loss = 0.27522116899490356
30-01-2023 11:44:41 INFO Epoch 2: [5787/10940] ---- BYOL Training Loss = 0.27116507291793823
30-01-2023 11:44:59 INFO Epoch 2: [5798/10940] ---- BYOL Training Loss = 0.2911871671676636
30-01-2023 11:45:17 INFO Epoch 2: [5809/10940] ---- BYOL Training Loss = 0.3347781300544739
30-01-2023 11:46:09 INFO Epoch 2: [5809/10940] ---- BYOL Validation Loss = 0.29276376962661743
30-01-2023 11:46:27 INFO Epoch 2: [5820/10940] ---- BYOL Training Loss = 0.3205626606941223
30-01-2023 11:46:45 INFO Epoch 2: [5831/10940] ---- BYOL Training Loss = 0.30098411440849304
30-01-2023 11:47:03 INFO Epoch 2: [5842/10940] ---- BYOL Training Loss = 0.29233235120773315
30-01-2023 11:47:21 INFO Epoch 2: [5853/10940] ---- BYOL Training Loss = 0.3015190064907074
30-01-2023 11:48:14 INFO Epoch 2: [5853/10940] ---- BYOL Validation Loss = 0.28008535504341125
30-01-2023 11:48:32 INFO Epoch 2: [5864/10940] ---- BYOL Training Loss = 0.28519222140312195
30-01-2023 11:48:50 INFO Epoch 2: [5875/10940] ---- BYOL Training Loss = 0.3236733376979828
30-01-2023 11:49:08 INFO Epoch 2: [5886/10940] ---- BYOL Training Loss = 0.3781820237636566
30-01-2023 11:49:26 INFO Epoch 2: [5897/10940] ---- BYOL Training Loss = 0.3516560196876526
30-01-2023 11:50:19 INFO Epoch 2: [5897/10940] ---- BYOL Validation Loss = 0.3089165985584259
30-01-2023 11:50:37 INFO Epoch 2: [5908/10940] ---- BYOL Training Loss = 0.3239198327064514
30-01-2023 11:50:55 INFO Epoch 2: [5919/10940] ---- BYOL Training Loss = 0.3352110981941223
30-01-2023 11:51:13 INFO Epoch 2: [5930/10940] ---- BYOL Training Loss = 0.33376747369766235
30-01-2023 11:51:31 INFO Epoch 2: [5941/10940] ---- BYOL Training Loss = 0.31142210960388184
30-01-2023 11:52:24 INFO Epoch 2: [5941/10940] ---- BYOL Validation Loss = 0.31813016533851624
30-01-2023 11:52:42 INFO Epoch 2: [5952/10940] ---- BYOL Training Loss = 0.28949326276779175
30-01-2023 11:53:00 INFO Epoch 2: [5963/10940] ---- BYOL Training Loss = 0.3636450171470642
30-01-2023 11:53:18 INFO Epoch 2: [5974/10940] ---- BYOL Training Loss = 0.3481956422328949
30-01-2023 11:53:36 INFO Epoch 2: [5985/10940] ---- BYOL Training Loss = 0.3709690272808075
30-01-2023 11:54:29 INFO Epoch 2: [5985/10940] ---- BYOL Validation Loss = 0.3261529505252838
30-01-2023 11:54:46 INFO Epoch 2: [5996/10940] ---- BYOL Training Loss = 0.38447171449661255
30-01-2023 11:55:05 INFO Epoch 2: [6007/10940] ---- BYOL Training Loss = 0.3416465222835541
30-01-2023 11:55:23 INFO Epoch 2: [6018/10940] ---- BYOL Training Loss = 0.31539633870124817
30-01-2023 11:55:41 INFO Epoch 2: [6029/10940] ---- BYOL Training Loss = 0.33753710985183716
30-01-2023 11:56:33 INFO Epoch 2: [6029/10940] ---- BYOL Validation Loss = 0.33381417393684387
30-01-2023 11:56:51 INFO Epoch 2: [6040/10940] ---- BYOL Training Loss = 0.37670475244522095
30-01-2023 11:57:10 INFO Epoch 2: [6051/10940] ---- BYOL Training Loss = 0.37249308824539185
30-01-2023 11:57:28 INFO Epoch 2: [6062/10940] ---- BYOL Training Loss = 0.35948270559310913
30-01-2023 11:57:46 INFO Epoch 2: [6073/10940] ---- BYOL Training Loss = 0.3492944836616516
30-01-2023 11:58:38 INFO Epoch 2: [6073/10940] ---- BYOL Validation Loss = 0.3233671188354492
30-01-2023 11:58:56 INFO Epoch 2: [6084/10940] ---- BYOL Training Loss = 0.32541683316230774
30-01-2023 11:59:14 INFO Epoch 2: [6095/10940] ---- BYOL Training Loss = 0.319747656583786
30-01-2023 11:59:33 INFO Epoch 2: [6106/10940] ---- BYOL Training Loss = 0.3497011065483093
30-01-2023 11:59:51 INFO Epoch 2: [6117/10940] ---- BYOL Training Loss = 0.40891480445861816
30-01-2023 12:00:44 INFO Epoch 2: [6117/10940] ---- BYOL Validation Loss = 0.3147854506969452
30-01-2023 12:01:01 INFO Epoch 2: [6128/10940] ---- BYOL Training Loss = 0.38570699095726013
30-01-2023 12:01:19 INFO Epoch 2: [6139/10940] ---- BYOL Training Loss = 0.3599054515361786
30-01-2023 12:01:38 INFO Epoch 2: [6150/10940] ---- BYOL Training Loss = 0.3514919579029083
30-01-2023 12:01:56 INFO Epoch 2: [6161/10940] ---- BYOL Training Loss = 0.3862989842891693
30-01-2023 12:02:49 INFO Epoch 2: [6161/10940] ---- BYOL Validation Loss = 0.30640146136283875
30-01-2023 12:03:06 INFO Epoch 2: [6172/10940] ---- BYOL Training Loss = 0.3398844301700592
30-01-2023 12:03:25 INFO Epoch 2: [6183/10940] ---- BYOL Training Loss = 0.27956730127334595
30-01-2023 12:03:43 INFO Epoch 2: [6194/10940] ---- BYOL Training Loss = 0.27490270137786865
30-01-2023 12:04:01 INFO Epoch 2: [6205/10940] ---- BYOL Training Loss = 0.28978022933006287
30-01-2023 12:04:54 INFO Epoch 2: [6205/10940] ---- BYOL Validation Loss = 0.3069811463356018
30-01-2023 12:05:11 INFO Epoch 2: [6216/10940] ---- BYOL Training Loss = 0.28186091780662537
30-01-2023 12:05:30 INFO Epoch 2: [6227/10940] ---- BYOL Training Loss = 0.3368326425552368
30-01-2023 12:05:48 INFO Epoch 2: [6238/10940] ---- BYOL Training Loss = 0.3578910231590271
30-01-2023 12:06:06 INFO Epoch 2: [6249/10940] ---- BYOL Training Loss = 0.3326335549354553
30-01-2023 12:06:58 INFO Epoch 2: [6249/10940] ---- BYOL Validation Loss = 0.3005729615688324
30-01-2023 12:07:16 INFO Epoch 2: [6260/10940] ---- BYOL Training Loss = 0.35735613107681274
30-01-2023 12:07:34 INFO Epoch 2: [6271/10940] ---- BYOL Training Loss = 0.3115650415420532
30-01-2023 12:07:53 INFO Epoch 2: [6282/10940] ---- BYOL Training Loss = 0.29810357093811035
30-01-2023 12:08:11 INFO Epoch 2: [6293/10940] ---- BYOL Training Loss = 0.312126100063324
30-01-2023 12:09:03 INFO Epoch 2: [6293/10940] ---- BYOL Validation Loss = 0.2983839511871338
30-01-2023 12:09:21 INFO Epoch 2: [6304/10940] ---- BYOL Training Loss = 0.3231021463871002
30-01-2023 12:09:40 INFO Epoch 2: [6315/10940] ---- BYOL Training Loss = 0.3584806025028229
30-01-2023 12:09:58 INFO Epoch 2: [6326/10940] ---- BYOL Training Loss = 0.3413732349872589
30-01-2023 12:10:16 INFO Epoch 2: [6337/10940] ---- BYOL Training Loss = 0.347674161195755
30-01-2023 12:11:08 INFO Epoch 2: [6337/10940] ---- BYOL Validation Loss = 0.2941564619541168
30-01-2023 12:11:26 INFO Epoch 2: [6348/10940] ---- BYOL Training Loss = 0.342162549495697
30-01-2023 12:11:44 INFO Epoch 2: [6359/10940] ---- BYOL Training Loss = 0.30535948276519775
30-01-2023 12:12:02 INFO Epoch 2: [6370/10940] ---- BYOL Training Loss = 0.29406246542930603
30-01-2023 12:12:20 INFO Epoch 2: [6381/10940] ---- BYOL Training Loss = 0.2887192964553833
30-01-2023 12:13:13 INFO Epoch 2: [6381/10940] ---- BYOL Validation Loss = 0.2980465292930603
30-01-2023 12:13:31 INFO Epoch 2: [6392/10940] ---- BYOL Training Loss = 0.2633707523345947
30-01-2023 12:13:49 INFO Epoch 2: [6403/10940] ---- BYOL Training Loss = 0.24849775433540344
30-01-2023 12:14:07 INFO Epoch 2: [6414/10940] ---- BYOL Training Loss = 0.25263190269470215
30-01-2023 12:14:25 INFO Epoch 2: [6425/10940] ---- BYOL Training Loss = 0.32726603746414185
30-01-2023 12:15:18 INFO Epoch 2: [6425/10940] ---- BYOL Validation Loss = 0.29453185200691223
30-01-2023 12:15:36 INFO Epoch 2: [6436/10940] ---- BYOL Training Loss = 0.3189167082309723
30-01-2023 12:15:54 INFO Epoch 2: [6447/10940] ---- BYOL Training Loss = 0.28001007437705994
30-01-2023 12:16:12 INFO Epoch 2: [6458/10940] ---- BYOL Training Loss = 0.28883853554725647
30-01-2023 12:16:30 INFO Epoch 2: [6469/10940] ---- BYOL Training Loss = 0.3122154176235199
30-01-2023 12:17:23 INFO Epoch 2: [6469/10940] ---- BYOL Validation Loss = 0.2837376296520233
30-01-2023 12:17:41 INFO Epoch 2: [6480/10940] ---- BYOL Training Loss = 0.3442748188972473
30-01-2023 12:17:59 INFO Epoch 2: [6491/10940] ---- BYOL Training Loss = 0.3415853977203369
30-01-2023 12:18:17 INFO Epoch 2: [6502/10940] ---- BYOL Training Loss = 0.29866185784339905
30-01-2023 12:18:36 INFO Epoch 2: [6513/10940] ---- BYOL Training Loss = 0.298477441072464
30-01-2023 12:19:28 INFO Epoch 2: [6513/10940] ---- BYOL Validation Loss = 0.28539174795150757
30-01-2023 12:19:46 INFO Epoch 2: [6524/10940] ---- BYOL Training Loss = 0.32753464579582214
30-01-2023 12:20:04 INFO Epoch 2: [6535/10940] ---- BYOL Training Loss = 0.3480428159236908
30-01-2023 12:20:22 INFO Epoch 2: [6546/10940] ---- BYOL Training Loss = 0.3300066590309143
30-01-2023 12:20:41 INFO Epoch 2: [6557/10940] ---- BYOL Training Loss = 0.26899319887161255
30-01-2023 12:21:33 INFO Epoch 2: [6557/10940] ---- BYOL Validation Loss = 0.2891027331352234
30-01-2023 12:21:51 INFO Epoch 2: [6568/10940] ---- BYOL Training Loss = 0.28810614347457886
30-01-2023 12:22:09 INFO Epoch 2: [6579/10940] ---- BYOL Training Loss = 0.31042954325675964
30-01-2023 12:22:28 INFO Epoch 2: [6590/10940] ---- BYOL Training Loss = 0.3066611886024475
30-01-2023 12:22:46 INFO Epoch 2: [6601/10940] ---- BYOL Training Loss = 0.29144740104675293
30-01-2023 12:23:38 INFO Epoch 2: [6601/10940] ---- BYOL Validation Loss = 0.2840687334537506
30-01-2023 12:23:56 INFO Epoch 2: [6612/10940] ---- BYOL Training Loss = 0.3336781859397888
30-01-2023 12:24:14 INFO Epoch 2: [6623/10940] ---- BYOL Training Loss = 0.3494230806827545
30-01-2023 12:24:33 INFO Epoch 2: [6634/10940] ---- BYOL Training Loss = 0.31124478578567505
30-01-2023 12:24:51 INFO Epoch 2: [6645/10940] ---- BYOL Training Loss = 0.29021674394607544
30-01-2023 12:25:43 INFO Epoch 2: [6645/10940] ---- BYOL Validation Loss = 0.2807921767234802
30-01-2023 12:26:01 INFO Epoch 2: [6656/10940] ---- BYOL Training Loss = 0.29497888684272766
30-01-2023 12:26:19 INFO Epoch 2: [6667/10940] ---- BYOL Training Loss = 0.26926979422569275
30-01-2023 12:26:38 INFO Epoch 2: [6678/10940] ---- BYOL Training Loss = 0.31335559487342834
30-01-2023 12:26:56 INFO Epoch 2: [6689/10940] ---- BYOL Training Loss = 0.3548114597797394
30-01-2023 12:27:48 INFO Epoch 2: [6689/10940] ---- BYOL Validation Loss = 0.2879312336444855
30-01-2023 12:28:06 INFO Epoch 2: [6700/10940] ---- BYOL Training Loss = 0.32458731532096863
30-01-2023 12:28:25 INFO Epoch 2: [6711/10940] ---- BYOL Training Loss = 0.31491750478744507
30-01-2023 12:28:43 INFO Epoch 2: [6722/10940] ---- BYOL Training Loss = 0.32400578260421753
30-01-2023 12:29:01 INFO Epoch 2: [6733/10940] ---- BYOL Training Loss = 0.3086373805999756
30-01-2023 12:29:54 INFO Epoch 2: [6733/10940] ---- BYOL Validation Loss = 0.28446075320243835
30-01-2023 12:30:12 INFO Epoch 2: [6744/10940] ---- BYOL Training Loss = 0.3011687397956848
30-01-2023 12:30:30 INFO Epoch 2: [6755/10940] ---- BYOL Training Loss = 0.25704675912857056
30-01-2023 12:30:48 INFO Epoch 2: [6766/10940] ---- BYOL Training Loss = 0.2343277931213379
30-01-2023 12:31:07 INFO Epoch 2: [6777/10940] ---- BYOL Training Loss = 0.27817097306251526
30-01-2023 12:31:59 INFO Epoch 2: [6777/10940] ---- BYOL Validation Loss = 0.2752320468425751
30-01-2023 12:32:17 INFO Epoch 2: [6788/10940] ---- BYOL Training Loss = 0.25275033712387085
30-01-2023 12:32:36 INFO Epoch 2: [6799/10940] ---- BYOL Training Loss = 0.2676123380661011
30-01-2023 12:32:54 INFO Epoch 2: [6810/10940] ---- BYOL Training Loss = 0.31406477093696594
30-01-2023 12:33:12 INFO Epoch 2: [6821/10940] ---- BYOL Training Loss = 0.3224288821220398
30-01-2023 12:34:05 INFO Epoch 2: [6821/10940] ---- BYOL Validation Loss = 0.2772362232208252
30-01-2023 12:34:23 INFO Epoch 2: [6832/10940] ---- BYOL Training Loss = 0.2919631004333496
30-01-2023 12:34:41 INFO Epoch 2: [6843/10940] ---- BYOL Training Loss = 0.3146309554576874
30-01-2023 12:34:59 INFO Epoch 2: [6854/10940] ---- BYOL Training Loss = 0.30973535776138306
30-01-2023 12:35:17 INFO Epoch 2: [6865/10940] ---- BYOL Training Loss = 0.2605207860469818
30-01-2023 12:36:10 INFO Epoch 2: [6865/10940] ---- BYOL Validation Loss = 0.2799353003501892
30-01-2023 12:36:28 INFO Epoch 2: [6876/10940] ---- BYOL Training Loss = 0.2802148461341858
30-01-2023 12:36:46 INFO Epoch 2: [6887/10940] ---- BYOL Training Loss = 0.2997269034385681
30-01-2023 12:37:04 INFO Epoch 2: [6898/10940] ---- BYOL Training Loss = 0.2808919847011566
30-01-2023 12:37:23 INFO Epoch 2: [6909/10940] ---- BYOL Training Loss = 0.28303831815719604
30-01-2023 12:38:15 INFO Epoch 2: [6909/10940] ---- BYOL Validation Loss = 0.27599313855171204
30-01-2023 12:38:33 INFO Epoch 2: [6920/10940] ---- BYOL Training Loss = 0.3176259994506836
30-01-2023 12:38:52 INFO Epoch 2: [6931/10940] ---- BYOL Training Loss = 0.2685687839984894
30-01-2023 12:39:10 INFO Epoch 2: [6942/10940] ---- BYOL Training Loss = 0.27419114112854004
30-01-2023 12:39:28 INFO Epoch 2: [6953/10940] ---- BYOL Training Loss = 0.29908883571624756
30-01-2023 12:40:21 INFO Epoch 2: [6953/10940] ---- BYOL Validation Loss = 0.2721671462059021
30-01-2023 12:40:39 INFO Epoch 2: [6964/10940] ---- BYOL Training Loss = 0.32349857687950134
30-01-2023 12:40:57 INFO Epoch 2: [6975/10940] ---- BYOL Training Loss = 0.315398633480072
30-01-2023 12:41:16 INFO Epoch 2: [6986/10940] ---- BYOL Training Loss = 0.3155512511730194
30-01-2023 12:41:34 INFO Epoch 2: [6997/10940] ---- BYOL Training Loss = 0.3076782822608948
30-01-2023 12:42:26 INFO Epoch 2: [6997/10940] ---- BYOL Validation Loss = 0.2715190351009369
30-01-2023 12:42:44 INFO Epoch 2: [7008/10940] ---- BYOL Training Loss = 0.27243104577064514
30-01-2023 12:43:03 INFO Epoch 2: [7019/10940] ---- BYOL Training Loss = 0.2548242509365082
30-01-2023 12:43:21 INFO Epoch 2: [7030/10940] ---- BYOL Training Loss = 0.30049943923950195
30-01-2023 12:43:39 INFO Epoch 2: [7041/10940] ---- BYOL Training Loss = 0.27002573013305664
30-01-2023 12:44:32 INFO Epoch 2: [7041/10940] ---- BYOL Validation Loss = 0.2719261944293976
30-01-2023 12:44:50 INFO Epoch 2: [7052/10940] ---- BYOL Training Loss = 0.3220824599266052
30-01-2023 12:45:08 INFO Epoch 2: [7063/10940] ---- BYOL Training Loss = 0.3245391845703125
30-01-2023 12:45:26 INFO Epoch 2: [7074/10940] ---- BYOL Training Loss = 0.27066558599472046
30-01-2023 12:45:45 INFO Epoch 2: [7085/10940] ---- BYOL Training Loss = 0.24330559372901917
30-01-2023 12:46:37 INFO Epoch 2: [7085/10940] ---- BYOL Validation Loss = 0.26159900426864624
30-01-2023 12:46:55 INFO Epoch 2: [7096/10940] ---- BYOL Training Loss = 0.2922461926937103
30-01-2023 12:47:14 INFO Epoch 2: [7107/10940] ---- BYOL Training Loss = 0.28809860348701477
30-01-2023 12:47:32 INFO Epoch 2: [7118/10940] ---- BYOL Training Loss = 0.2958492934703827
30-01-2023 12:47:50 INFO Epoch 2: [7129/10940] ---- BYOL Training Loss = 0.30045488476753235
30-01-2023 12:48:43 INFO Epoch 2: [7129/10940] ---- BYOL Validation Loss = 0.26700687408447266
30-01-2023 12:49:01 INFO Epoch 2: [7140/10940] ---- BYOL Training Loss = 0.2739388048648834
30-01-2023 12:49:19 INFO Epoch 2: [7151/10940] ---- BYOL Training Loss = 0.27892065048217773
30-01-2023 12:49:38 INFO Epoch 2: [7162/10940] ---- BYOL Training Loss = 0.26222091913223267
30-01-2023 12:49:56 INFO Epoch 2: [7173/10940] ---- BYOL Training Loss = 0.2622535824775696
30-01-2023 12:50:48 INFO Epoch 2: [7173/10940] ---- BYOL Validation Loss = 0.26053449511528015
30-01-2023 12:51:06 INFO Epoch 2: [7184/10940] ---- BYOL Training Loss = 0.25677257776260376
30-01-2023 12:51:25 INFO Epoch 2: [7195/10940] ---- BYOL Training Loss = 0.25014790892601013
30-01-2023 12:51:43 INFO Epoch 2: [7206/10940] ---- BYOL Training Loss = 0.28862667083740234
30-01-2023 12:52:01 INFO Epoch 2: [7217/10940] ---- BYOL Training Loss = 0.2969732880592346
30-01-2023 12:52:53 INFO Epoch 2: [7217/10940] ---- BYOL Validation Loss = 0.27257925271987915
30-01-2023 12:53:12 INFO Epoch 2: [7228/10940] ---- BYOL Training Loss = 0.3104498088359833
30-01-2023 12:53:30 INFO Epoch 2: [7239/10940] ---- BYOL Training Loss = 0.3304963707923889
30-01-2023 12:53:48 INFO Epoch 2: [7250/10940] ---- BYOL Training Loss = 0.31744736433029175
30-01-2023 12:54:07 INFO Epoch 2: [7261/10940] ---- BYOL Training Loss = 0.28632277250289917
30-01-2023 12:54:59 INFO Epoch 2: [7261/10940] ---- BYOL Validation Loss = 0.2719699442386627
30-01-2023 12:55:17 INFO Epoch 2: [7272/10940] ---- BYOL Training Loss = 0.25515100359916687
30-01-2023 12:55:35 INFO Epoch 2: [7283/10940] ---- BYOL Training Loss = 0.282869815826416
30-01-2023 12:55:53 INFO Epoch 2: [7294/10940] ---- BYOL Training Loss = 0.2675040662288666
30-01-2023 12:56:12 INFO Epoch 2: [7305/10940] ---- BYOL Training Loss = 0.2345932424068451
30-01-2023 12:57:04 INFO Epoch 2: [7305/10940] ---- BYOL Validation Loss = 0.2637951970100403
30-01-2023 12:57:22 INFO Epoch 2: [7316/10940] ---- BYOL Training Loss = 0.2801966071128845
30-01-2023 12:57:40 INFO Epoch 2: [7327/10940] ---- BYOL Training Loss = 0.3385932445526123
30-01-2023 12:57:59 INFO Epoch 2: [7338/10940] ---- BYOL Training Loss = 0.30265289545059204
30-01-2023 12:58:17 INFO Epoch 2: [7349/10940] ---- BYOL Training Loss = 0.28485822677612305
30-01-2023 12:59:10 INFO Epoch 2: [7349/10940] ---- BYOL Validation Loss = 0.2807203233242035
30-01-2023 12:59:28 INFO Epoch 2: [7360/10940] ---- BYOL Training Loss = 0.3070245385169983
30-01-2023 12:59:46 INFO Epoch 2: [7371/10940] ---- BYOL Training Loss = 0.2987288236618042
30-01-2023 13:00:04 INFO Epoch 2: [7382/10940] ---- BYOL Training Loss = 0.26990607380867004
30-01-2023 13:00:23 INFO Epoch 2: [7393/10940] ---- BYOL Training Loss = 0.2621265649795532
30-01-2023 13:01:15 INFO Epoch 2: [7393/10940] ---- BYOL Validation Loss = 0.25761961936950684
30-01-2023 13:01:34 INFO Epoch 2: [7404/10940] ---- BYOL Training Loss = 0.23685741424560547
30-01-2023 13:01:52 INFO Epoch 2: [7415/10940] ---- BYOL Training Loss = 0.2684951424598694
30-01-2023 13:02:10 INFO Epoch 2: [7426/10940] ---- BYOL Training Loss = 0.29181236028671265
30-01-2023 13:02:29 INFO Epoch 2: [7437/10940] ---- BYOL Training Loss = 0.2596234977245331
30-01-2023 13:03:21 INFO Epoch 2: [7437/10940] ---- BYOL Validation Loss = 0.2595069706439972
30-01-2023 13:03:39 INFO Epoch 2: [7448/10940] ---- BYOL Training Loss = 0.274160236120224
30-01-2023 13:03:57 INFO Epoch 2: [7459/10940] ---- BYOL Training Loss = 0.2755299210548401
30-01-2023 13:04:15 INFO Epoch 2: [7470/10940] ---- BYOL Training Loss = 0.2356576919555664
30-01-2023 13:04:34 INFO Epoch 2: [7481/10940] ---- BYOL Training Loss = 0.28307342529296875
30-01-2023 13:05:26 INFO Epoch 2: [7481/10940] ---- BYOL Validation Loss = 0.2726573348045349
30-01-2023 13:05:44 INFO Epoch 2: [7492/10940] ---- BYOL Training Loss = 0.31597381830215454
30-01-2023 13:06:02 INFO Epoch 2: [7503/10940] ---- BYOL Training Loss = 0.30382534861564636
30-01-2023 13:06:21 INFO Epoch 2: [7514/10940] ---- BYOL Training Loss = 0.2796691954135895
30-01-2023 13:06:39 INFO Epoch 2: [7525/10940] ---- BYOL Training Loss = 0.2657363712787628
30-01-2023 13:07:32 INFO Epoch 2: [7525/10940] ---- BYOL Validation Loss = 0.2621161937713623
30-01-2023 13:07:49 INFO Epoch 2: [7536/10940] ---- BYOL Training Loss = 0.2906767725944519
30-01-2023 13:08:08 INFO Epoch 2: [7547/10940] ---- BYOL Training Loss = 0.26152822375297546
30-01-2023 13:08:26 INFO Epoch 2: [7558/10940] ---- BYOL Training Loss = 0.2665671408176422
30-01-2023 13:08:44 INFO Epoch 2: [7569/10940] ---- BYOL Training Loss = 0.2856660783290863
30-01-2023 13:09:37 INFO Epoch 2: [7569/10940] ---- BYOL Validation Loss = 0.25616052746772766
30-01-2023 13:09:55 INFO Epoch 2: [7580/10940] ---- BYOL Training Loss = 0.28556638956069946
30-01-2023 13:10:14 INFO Epoch 2: [7591/10940] ---- BYOL Training Loss = 0.27887606620788574
30-01-2023 13:10:32 INFO Epoch 2: [7602/10940] ---- BYOL Training Loss = 0.271179735660553
30-01-2023 13:10:50 INFO Epoch 2: [7613/10940] ---- BYOL Training Loss = 0.28392890095710754
30-01-2023 13:11:42 INFO Epoch 2: [7613/10940] ---- BYOL Validation Loss = 0.25740066170692444
30-01-2023 13:12:01 INFO Epoch 2: [7624/10940] ---- BYOL Training Loss = 0.27916744351387024
30-01-2023 13:12:19 INFO Epoch 2: [7635/10940] ---- BYOL Training Loss = 0.2678740918636322
30-01-2023 13:12:37 INFO Epoch 2: [7646/10940] ---- BYOL Training Loss = 0.28158578276634216
30-01-2023 13:12:56 INFO Epoch 2: [7657/10940] ---- BYOL Training Loss = 0.2857688069343567
30-01-2023 13:13:49 INFO Epoch 2: [7657/10940] ---- BYOL Validation Loss = 0.2608436644077301
30-01-2023 13:14:06 INFO Epoch 2: [7668/10940] ---- BYOL Training Loss = 0.3283480703830719
30-01-2023 13:14:25 INFO Epoch 2: [7679/10940] ---- BYOL Training Loss = 0.38634592294692993
30-01-2023 13:14:43 INFO Epoch 2: [7690/10940] ---- BYOL Training Loss = 0.27623558044433594
30-01-2023 13:15:02 INFO Epoch 2: [7701/10940] ---- BYOL Training Loss = 0.24049174785614014
30-01-2023 13:15:54 INFO Epoch 2: [7701/10940] ---- BYOL Validation Loss = 0.2591685652732849
30-01-2023 13:16:12 INFO Epoch 2: [7712/10940] ---- BYOL Training Loss = 0.29251009225845337
30-01-2023 13:16:31 INFO Epoch 2: [7723/10940] ---- BYOL Training Loss = 0.31682902574539185
30-01-2023 13:16:49 INFO Epoch 2: [7734/10940] ---- BYOL Training Loss = 0.29636910557746887
30-01-2023 13:17:07 INFO Epoch 2: [7745/10940] ---- BYOL Training Loss = 0.25722864270210266
30-01-2023 13:18:00 INFO Epoch 2: [7745/10940] ---- BYOL Validation Loss = 0.26106923818588257
30-01-2023 13:18:18 INFO Epoch 2: [7756/10940] ---- BYOL Training Loss = 0.24372312426567078
30-01-2023 13:18:36 INFO Epoch 2: [7767/10940] ---- BYOL Training Loss = 0.24571654200553894
30-01-2023 13:18:55 INFO Epoch 2: [7778/10940] ---- BYOL Training Loss = 0.29691261053085327
30-01-2023 13:19:13 INFO Epoch 2: [7789/10940] ---- BYOL Training Loss = 0.31216615438461304
30-01-2023 13:20:06 INFO Epoch 2: [7789/10940] ---- BYOL Validation Loss = 0.2536419928073883
30-01-2023 13:20:24 INFO Epoch 2: [7800/10940] ---- BYOL Training Loss = 0.24906523525714874
30-01-2023 13:20:42 INFO Epoch 2: [7811/10940] ---- BYOL Training Loss = 0.2834877371788025
30-01-2023 13:21:00 INFO Epoch 2: [7822/10940] ---- BYOL Training Loss = 0.31697601079940796
30-01-2023 13:21:19 INFO Epoch 2: [7833/10940] ---- BYOL Training Loss = 0.31235969066619873
30-01-2023 13:22:11 INFO Epoch 2: [7833/10940] ---- BYOL Validation Loss = 0.2696424126625061
30-01-2023 13:22:29 INFO Epoch 2: [7844/10940] ---- BYOL Training Loss = 0.33188188076019287
30-01-2023 13:22:48 INFO Epoch 2: [7855/10940] ---- BYOL Training Loss = 0.2637857496738434
30-01-2023 13:23:06 INFO Epoch 2: [7866/10940] ---- BYOL Training Loss = 0.2485274374485016
30-01-2023 13:23:24 INFO Epoch 2: [7877/10940] ---- BYOL Training Loss = 0.279995858669281
30-01-2023 13:24:17 INFO Epoch 2: [7877/10940] ---- BYOL Validation Loss = 0.2511303424835205
30-01-2023 13:24:35 INFO Epoch 2: [7888/10940] ---- BYOL Training Loss = 0.2714918851852417
30-01-2023 13:24:54 INFO Epoch 2: [7899/10940] ---- BYOL Training Loss = 0.2777555584907532
30-01-2023 13:25:12 INFO Epoch 2: [7910/10940] ---- BYOL Training Loss = 0.24936822056770325
30-01-2023 13:25:31 INFO Epoch 2: [7921/10940] ---- BYOL Training Loss = 0.2671402096748352
30-01-2023 13:26:23 INFO Epoch 2: [7921/10940] ---- BYOL Validation Loss = 0.2526746392250061
30-01-2023 13:26:41 INFO Epoch 2: [7932/10940] ---- BYOL Training Loss = 0.26210129261016846
30-01-2023 13:26:59 INFO Epoch 2: [7943/10940] ---- BYOL Training Loss = 0.25702983140945435
30-01-2023 13:27:18 INFO Epoch 2: [7954/10940] ---- BYOL Training Loss = 0.25998854637145996
30-01-2023 13:27:36 INFO Epoch 2: [7965/10940] ---- BYOL Training Loss = 0.26716238260269165
30-01-2023 13:28:29 INFO Epoch 2: [7965/10940] ---- BYOL Validation Loss = 0.24903056025505066
30-01-2023 13:28:47 INFO Epoch 2: [7976/10940] ---- BYOL Training Loss = 0.30328983068466187
30-01-2023 13:29:05 INFO Epoch 2: [7987/10940] ---- BYOL Training Loss = 0.2807113528251648
30-01-2023 13:29:23 INFO Epoch 2: [7998/10940] ---- BYOL Training Loss = 0.24911029636859894
30-01-2023 13:29:42 INFO Epoch 2: [8009/10940] ---- BYOL Training Loss = 0.24735164642333984
30-01-2023 13:30:34 INFO Epoch 2: [8009/10940] ---- BYOL Validation Loss = 0.24992355704307556
30-01-2023 13:30:52 INFO Epoch 2: [8020/10940] ---- BYOL Training Loss = 0.25844451785087585
30-01-2023 13:31:10 INFO Epoch 2: [8031/10940] ---- BYOL Training Loss = 0.24956543743610382
30-01-2023 13:31:29 INFO Epoch 2: [8042/10940] ---- BYOL Training Loss = 0.22762469947338104
30-01-2023 13:31:47 INFO Epoch 2: [8053/10940] ---- BYOL Training Loss = 0.2528589367866516
30-01-2023 13:32:40 INFO Epoch 2: [8053/10940] ---- BYOL Validation Loss = 0.25739362835884094
30-01-2023 13:32:58 INFO Epoch 2: [8064/10940] ---- BYOL Training Loss = 0.2577478289604187
30-01-2023 13:33:16 INFO Epoch 2: [8075/10940] ---- BYOL Training Loss = 0.22791370749473572
30-01-2023 13:33:35 INFO Epoch 2: [8086/10940] ---- BYOL Training Loss = 0.23639865219593048
30-01-2023 13:33:53 INFO Epoch 2: [8097/10940] ---- BYOL Training Loss = 0.24670147895812988
30-01-2023 13:34:46 INFO Epoch 2: [8097/10940] ---- BYOL Validation Loss = 0.24599303305149078
30-01-2023 13:35:04 INFO Epoch 2: [8108/10940] ---- BYOL Training Loss = 0.26136982440948486
30-01-2023 13:35:22 INFO Epoch 2: [8119/10940] ---- BYOL Training Loss = 0.24975839257240295
30-01-2023 13:35:40 INFO Epoch 2: [8130/10940] ---- BYOL Training Loss = 0.25135689973831177
30-01-2023 13:35:59 INFO Epoch 2: [8141/10940] ---- BYOL Training Loss = 0.26048544049263
30-01-2023 13:36:51 INFO Epoch 2: [8141/10940] ---- BYOL Validation Loss = 0.2623911201953888
30-01-2023 13:37:10 INFO Epoch 2: [8152/10940] ---- BYOL Training Loss = 0.27577731013298035
30-01-2023 13:37:28 INFO Epoch 2: [8163/10940] ---- BYOL Training Loss = 0.26816225051879883
30-01-2023 13:37:46 INFO Epoch 2: [8174/10940] ---- BYOL Training Loss = 0.2886640429496765
30-01-2023 13:38:05 INFO Epoch 2: [8185/10940] ---- BYOL Training Loss = 0.2730627655982971
30-01-2023 13:38:58 INFO Epoch 2: [8185/10940] ---- BYOL Validation Loss = 0.2545620799064636
30-01-2023 13:39:16 INFO Epoch 2: [8196/10940] ---- BYOL Training Loss = 0.27195829153060913
30-01-2023 13:39:34 INFO Epoch 2: [8207/10940] ---- BYOL Training Loss = 0.24736276268959045
30-01-2023 13:39:53 INFO Epoch 2: [8218/10940] ---- BYOL Training Loss = 0.2562337815761566
30-01-2023 13:40:11 INFO Epoch 2: [8229/10940] ---- BYOL Training Loss = 0.2969569265842438
30-01-2023 13:41:04 INFO Epoch 2: [8229/10940] ---- BYOL Validation Loss = 0.24685299396514893
30-01-2023 13:41:21 INFO Epoch 2: [8240/10940] ---- BYOL Training Loss = 0.2915375828742981
30-01-2023 13:41:40 INFO Epoch 2: [8251/10940] ---- BYOL Training Loss = 0.28810951113700867
30-01-2023 13:41:58 INFO Epoch 2: [8262/10940] ---- BYOL Training Loss = 0.2804142236709595
30-01-2023 13:42:17 INFO Epoch 2: [8273/10940] ---- BYOL Training Loss = 0.2665227949619293
30-01-2023 13:43:09 INFO Epoch 2: [8273/10940] ---- BYOL Validation Loss = 0.25795695185661316
30-01-2023 13:43:28 INFO Epoch 2: [8284/10940] ---- BYOL Training Loss = 0.250253826379776
30-01-2023 13:43:46 INFO Epoch 2: [8295/10940] ---- BYOL Training Loss = 0.2664197087287903
30-01-2023 13:44:05 INFO Epoch 2: [8306/10940] ---- BYOL Training Loss = 0.2751949429512024
30-01-2023 13:44:23 INFO Epoch 2: [8317/10940] ---- BYOL Training Loss = 0.262302041053772
30-01-2023 13:45:16 INFO Epoch 2: [8317/10940] ---- BYOL Validation Loss = 0.25105971097946167
30-01-2023 13:45:34 INFO Epoch 2: [8328/10940] ---- BYOL Training Loss = 0.2704269289970398
30-01-2023 13:45:52 INFO Epoch 2: [8339/10940] ---- BYOL Training Loss = 0.2925630807876587
30-01-2023 13:46:11 INFO Epoch 2: [8350/10940] ---- BYOL Training Loss = 0.27814429998397827
30-01-2023 13:46:29 INFO Epoch 2: [8361/10940] ---- BYOL Training Loss = 0.2809787094593048
30-01-2023 13:47:21 INFO Epoch 2: [8361/10940] ---- BYOL Validation Loss = 0.22926433384418488
30-01-2023 13:47:40 INFO Epoch 2: [8372/10940] ---- BYOL Training Loss = 0.2700343132019043
30-01-2023 13:47:58 INFO Epoch 2: [8383/10940] ---- BYOL Training Loss = 0.302778422832489
30-01-2023 13:48:16 INFO Epoch 2: [8394/10940] ---- BYOL Training Loss = 0.2906666398048401
30-01-2023 13:48:35 INFO Epoch 2: [8405/10940] ---- BYOL Training Loss = 0.2960132658481598
30-01-2023 13:49:28 INFO Epoch 2: [8405/10940] ---- BYOL Validation Loss = 0.2556588351726532
30-01-2023 13:49:46 INFO Epoch 2: [8416/10940] ---- BYOL Training Loss = 0.3083350360393524
30-01-2023 13:50:04 INFO Epoch 2: [8427/10940] ---- BYOL Training Loss = 0.3476797938346863
30-01-2023 13:50:23 INFO Epoch 2: [8438/10940] ---- BYOL Training Loss = 0.3165123760700226
30-01-2023 13:50:41 INFO Epoch 2: [8449/10940] ---- BYOL Training Loss = 0.29118120670318604
30-01-2023 13:51:33 INFO Epoch 2: [8449/10940] ---- BYOL Validation Loss = 0.2411775141954422
30-01-2023 13:51:51 INFO Epoch 2: [8460/10940] ---- BYOL Training Loss = 0.2509647607803345
30-01-2023 13:52:10 INFO Epoch 2: [8471/10940] ---- BYOL Training Loss = 0.25594964623451233
30-01-2023 13:52:29 INFO Epoch 2: [8482/10940] ---- BYOL Training Loss = 0.25679200887680054
30-01-2023 13:52:47 INFO Epoch 2: [8493/10940] ---- BYOL Training Loss = 0.322806179523468
30-01-2023 13:53:39 INFO Epoch 2: [8493/10940] ---- BYOL Validation Loss = 0.24726292490959167
30-01-2023 13:53:58 INFO Epoch 2: [8504/10940] ---- BYOL Training Loss = 0.35507339239120483
30-01-2023 13:54:16 INFO Epoch 2: [8515/10940] ---- BYOL Training Loss = 0.3064979910850525
30-01-2023 13:54:34 INFO Epoch 2: [8526/10940] ---- BYOL Training Loss = 0.2938879430294037
30-01-2023 13:54:53 INFO Epoch 2: [8537/10940] ---- BYOL Training Loss = 0.27846667170524597
30-01-2023 13:55:45 INFO Epoch 2: [8537/10940] ---- BYOL Validation Loss = 0.2360886037349701
30-01-2023 13:56:03 INFO Epoch 2: [8548/10940] ---- BYOL Training Loss = 0.27857232093811035
30-01-2023 13:56:21 INFO Epoch 2: [8559/10940] ---- BYOL Training Loss = 0.27980807423591614
30-01-2023 13:56:40 INFO Epoch 2: [8570/10940] ---- BYOL Training Loss = 0.2882050573825836
30-01-2023 13:56:59 INFO Epoch 2: [8581/10940] ---- BYOL Training Loss = 0.2946420907974243
30-01-2023 13:57:51 INFO Epoch 2: [8581/10940] ---- BYOL Validation Loss = 0.2545889914035797
30-01-2023 13:58:10 INFO Epoch 2: [8592/10940] ---- BYOL Training Loss = 0.2715803384780884
30-01-2023 13:58:28 INFO Epoch 2: [8603/10940] ---- BYOL Training Loss = 0.27592408657073975
30-01-2023 13:58:46 INFO Epoch 2: [8614/10940] ---- BYOL Training Loss = 0.28853899240493774
30-01-2023 13:59:05 INFO Epoch 2: [8625/10940] ---- BYOL Training Loss = 0.2712131440639496
30-01-2023 13:59:58 INFO Epoch 2: [8625/10940] ---- BYOL Validation Loss = 0.25032898783683777
30-01-2023 14:00:16 INFO Epoch 2: [8636/10940] ---- BYOL Training Loss = 0.2762259542942047
30-01-2023 14:00:34 INFO Epoch 2: [8647/10940] ---- BYOL Training Loss = 0.2542322874069214
30-01-2023 14:00:53 INFO Epoch 2: [8658/10940] ---- BYOL Training Loss = 0.2438388168811798
30-01-2023 14:01:11 INFO Epoch 2: [8669/10940] ---- BYOL Training Loss = 0.2554009258747101
30-01-2023 14:02:04 INFO Epoch 2: [8669/10940] ---- BYOL Validation Loss = 0.2635963559150696
30-01-2023 14:02:22 INFO Epoch 2: [8680/10940] ---- BYOL Training Loss = 0.25892630219459534
30-01-2023 14:02:40 INFO Epoch 2: [8691/10940] ---- BYOL Training Loss = 0.2708435356616974
30-01-2023 14:02:59 INFO Epoch 2: [8702/10940] ---- BYOL Training Loss = 0.24821850657463074
30-01-2023 14:03:17 INFO Epoch 2: [8713/10940] ---- BYOL Training Loss = 0.25914865732192993
30-01-2023 14:04:10 INFO Epoch 2: [8713/10940] ---- BYOL Validation Loss = 0.25667205452919006
30-01-2023 14:04:28 INFO Epoch 2: [8724/10940] ---- BYOL Training Loss = 0.2782220244407654
30-01-2023 14:04:46 INFO Epoch 2: [8735/10940] ---- BYOL Training Loss = 0.26980653405189514
30-01-2023 14:05:05 INFO Epoch 2: [8746/10940] ---- BYOL Training Loss = 0.2694111466407776
30-01-2023 14:05:23 INFO Epoch 2: [8757/10940] ---- BYOL Training Loss = 0.29953691363334656
30-01-2023 14:06:16 INFO Epoch 2: [8757/10940] ---- BYOL Validation Loss = 0.25102490186691284
30-01-2023 14:06:34 INFO Epoch 2: [8768/10940] ---- BYOL Training Loss = 0.27336740493774414
30-01-2023 14:06:52 INFO Epoch 2: [8779/10940] ---- BYOL Training Loss = 0.2873501181602478
30-01-2023 14:07:11 INFO Epoch 2: [8790/10940] ---- BYOL Training Loss = 0.28635546565055847
30-01-2023 14:07:29 INFO Epoch 2: [8801/10940] ---- BYOL Training Loss = 0.27870962023735046
30-01-2023 14:08:22 INFO Epoch 2: [8801/10940] ---- BYOL Validation Loss = 0.24621626734733582
30-01-2023 14:08:40 INFO Epoch 2: [8812/10940] ---- BYOL Training Loss = 0.29967936873435974
30-01-2023 14:08:59 INFO Epoch 2: [8823/10940] ---- BYOL Training Loss = 0.27885645627975464
30-01-2023 14:09:17 INFO Epoch 2: [8834/10940] ---- BYOL Training Loss = 0.22492098808288574
30-01-2023 14:09:36 INFO Epoch 2: [8845/10940] ---- BYOL Training Loss = 0.23591235280036926
30-01-2023 14:10:28 INFO Epoch 2: [8845/10940] ---- BYOL Validation Loss = 0.244321808218956
30-01-2023 14:10:46 INFO Epoch 2: [8856/10940] ---- BYOL Training Loss = 0.30711835622787476
30-01-2023 14:11:05 INFO Epoch 2: [8867/10940] ---- BYOL Training Loss = 0.284297376871109
30-01-2023 14:11:24 INFO Epoch 2: [8878/10940] ---- BYOL Training Loss = 0.2593787610530853
30-01-2023 14:11:42 INFO Epoch 2: [8889/10940] ---- BYOL Training Loss = 0.24543921649456024
30-01-2023 14:12:35 INFO Epoch 2: [8889/10940] ---- BYOL Validation Loss = 0.2505953311920166
30-01-2023 14:12:53 INFO Epoch 2: [8900/10940] ---- BYOL Training Loss = 0.29432976245880127
30-01-2023 14:13:12 INFO Epoch 2: [8911/10940] ---- BYOL Training Loss = 0.2720101475715637
30-01-2023 14:13:31 INFO Epoch 2: [8922/10940] ---- BYOL Training Loss = 0.23402433097362518
30-01-2023 14:13:49 INFO Epoch 2: [8933/10940] ---- BYOL Training Loss = 0.22873930633068085
30-01-2023 14:14:42 INFO Epoch 2: [8933/10940] ---- BYOL Validation Loss = 0.25321948528289795
30-01-2023 14:15:00 INFO Epoch 2: [8944/10940] ---- BYOL Training Loss = 0.2730657160282135
30-01-2023 14:15:19 INFO Epoch 2: [8955/10940] ---- BYOL Training Loss = 0.2833210229873657
30-01-2023 14:15:37 INFO Epoch 2: [8966/10940] ---- BYOL Training Loss = 0.3092062473297119
30-01-2023 14:15:56 INFO Epoch 2: [8977/10940] ---- BYOL Training Loss = 0.3194118142127991
30-01-2023 14:16:48 INFO Epoch 2: [8977/10940] ---- BYOL Validation Loss = 0.24395547807216644
30-01-2023 14:17:06 INFO Epoch 2: [8988/10940] ---- BYOL Training Loss = 0.3047592341899872
30-01-2023 14:17:25 INFO Epoch 2: [8999/10940] ---- BYOL Training Loss = 0.2617985010147095
30-01-2023 14:17:43 INFO Epoch 2: [9010/10940] ---- BYOL Training Loss = 0.24194495379924774
30-01-2023 14:18:02 INFO Epoch 2: [9021/10940] ---- BYOL Training Loss = 0.22262218594551086
30-01-2023 14:18:54 INFO Epoch 2: [9021/10940] ---- BYOL Validation Loss = 0.24134588241577148
30-01-2023 14:19:12 INFO Epoch 2: [9032/10940] ---- BYOL Training Loss = 0.2464093416929245
30-01-2023 14:19:31 INFO Epoch 2: [9043/10940] ---- BYOL Training Loss = 0.26532217860221863
30-01-2023 14:19:50 INFO Epoch 2: [9054/10940] ---- BYOL Training Loss = 0.23321035504341125
30-01-2023 14:20:08 INFO Epoch 2: [9065/10940] ---- BYOL Training Loss = 0.24607887864112854
30-01-2023 14:21:01 INFO Epoch 2: [9065/10940] ---- BYOL Validation Loss = 0.2542223334312439
30-01-2023 14:21:19 INFO Epoch 2: [9076/10940] ---- BYOL Training Loss = 0.25848308205604553
30-01-2023 14:21:37 INFO Epoch 2: [9087/10940] ---- BYOL Training Loss = 0.26455923914909363
30-01-2023 14:21:56 INFO Epoch 2: [9098/10940] ---- BYOL Training Loss = 0.2418825328350067
30-01-2023 14:22:15 INFO Epoch 2: [9109/10940] ---- BYOL Training Loss = 0.23551137745380402
30-01-2023 14:23:07 INFO Epoch 2: [9109/10940] ---- BYOL Validation Loss = 0.25018438696861267
30-01-2023 14:23:25 INFO Epoch 2: [9120/10940] ---- BYOL Training Loss = 0.290835440158844
30-01-2023 14:23:44 INFO Epoch 2: [9131/10940] ---- BYOL Training Loss = 0.290140300989151
30-01-2023 14:24:02 INFO Epoch 2: [9142/10940] ---- BYOL Training Loss = 0.2974705994129181
30-01-2023 14:24:21 INFO Epoch 2: [9153/10940] ---- BYOL Training Loss = 0.2774129807949066
30-01-2023 14:25:13 INFO Epoch 2: [9153/10940] ---- BYOL Validation Loss = 0.23767109215259552
30-01-2023 14:25:31 INFO Epoch 2: [9164/10940] ---- BYOL Training Loss = 0.28907567262649536
30-01-2023 14:25:49 INFO Epoch 2: [9175/10940] ---- BYOL Training Loss = 0.2775452733039856
30-01-2023 14:26:08 INFO Epoch 2: [9186/10940] ---- BYOL Training Loss = 0.23032522201538086
30-01-2023 14:26:27 INFO Epoch 2: [9197/10940] ---- BYOL Training Loss = 0.23687843978405
30-01-2023 14:27:19 INFO Epoch 2: [9197/10940] ---- BYOL Validation Loss = 0.2372562140226364
30-01-2023 14:27:38 INFO Epoch 2: [9208/10940] ---- BYOL Training Loss = 0.24465636909008026
30-01-2023 14:27:56 INFO Epoch 2: [9219/10940] ---- BYOL Training Loss = 0.26085615158081055
30-01-2023 14:28:14 INFO Epoch 2: [9230/10940] ---- BYOL Training Loss = 0.29031509160995483
30-01-2023 14:28:33 INFO Epoch 2: [9241/10940] ---- BYOL Training Loss = 0.2936674952507019
30-01-2023 14:29:26 INFO Epoch 2: [9241/10940] ---- BYOL Validation Loss = 0.2522485554218292
30-01-2023 14:29:44 INFO Epoch 2: [9252/10940] ---- BYOL Training Loss = 0.2555386424064636
30-01-2023 14:30:02 INFO Epoch 2: [9263/10940] ---- BYOL Training Loss = 0.2518886923789978
30-01-2023 14:30:21 INFO Epoch 2: [9274/10940] ---- BYOL Training Loss = 0.2821853756904602
30-01-2023 14:30:39 INFO Epoch 2: [9285/10940] ---- BYOL Training Loss = 0.26574692130088806
30-01-2023 14:31:32 INFO Epoch 2: [9285/10940] ---- BYOL Validation Loss = 0.24985480308532715
30-01-2023 14:31:50 INFO Epoch 2: [9296/10940] ---- BYOL Training Loss = 0.25285398960113525
30-01-2023 14:32:09 INFO Epoch 2: [9307/10940] ---- BYOL Training Loss = 0.2489376813173294
30-01-2023 14:32:27 INFO Epoch 2: [9318/10940] ---- BYOL Training Loss = 0.2641434669494629
30-01-2023 14:32:46 INFO Epoch 2: [9329/10940] ---- BYOL Training Loss = 0.262633740901947
30-01-2023 14:33:38 INFO Epoch 2: [9329/10940] ---- BYOL Validation Loss = 0.2459699660539627
30-01-2023 14:33:56 INFO Epoch 2: [9340/10940] ---- BYOL Training Loss = 0.24428942799568176
30-01-2023 14:34:15 INFO Epoch 2: [9351/10940] ---- BYOL Training Loss = 0.2889645993709564
30-01-2023 14:34:34 INFO Epoch 2: [9362/10940] ---- BYOL Training Loss = 0.2945469617843628
30-01-2023 14:34:52 INFO Epoch 2: [9373/10940] ---- BYOL Training Loss = 0.2625235617160797
30-01-2023 14:35:45 INFO Epoch 2: [9373/10940] ---- BYOL Validation Loss = 0.2541230618953705
30-01-2023 14:36:03 INFO Epoch 2: [9384/10940] ---- BYOL Training Loss = 0.2672656774520874
30-01-2023 14:36:21 INFO Epoch 2: [9395/10940] ---- BYOL Training Loss = 0.29399988055229187
30-01-2023 14:36:40 INFO Epoch 2: [9406/10940] ---- BYOL Training Loss = 0.27432915568351746
30-01-2023 14:36:59 INFO Epoch 2: [9417/10940] ---- BYOL Training Loss = 0.2744254469871521
30-01-2023 14:37:51 INFO Epoch 2: [9417/10940] ---- BYOL Validation Loss = 0.2480589896440506
30-01-2023 14:38:09 INFO Epoch 2: [9428/10940] ---- BYOL Training Loss = 0.3061855435371399
30-01-2023 14:38:28 INFO Epoch 2: [9439/10940] ---- BYOL Training Loss = 0.2927323281764984
30-01-2023 14:38:46 INFO Epoch 2: [9450/10940] ---- BYOL Training Loss = 0.2433386594057083
30-01-2023 14:39:05 INFO Epoch 2: [9461/10940] ---- BYOL Training Loss = 0.22634661197662354
30-01-2023 14:39:58 INFO Epoch 2: [9461/10940] ---- BYOL Validation Loss = 0.24897244572639465
30-01-2023 14:40:16 INFO Epoch 2: [9472/10940] ---- BYOL Training Loss = 0.2701568305492401
30-01-2023 14:40:34 INFO Epoch 2: [9483/10940] ---- BYOL Training Loss = 0.29491692781448364
30-01-2023 14:40:53 INFO Epoch 2: [9494/10940] ---- BYOL Training Loss = 0.28838855028152466
30-01-2023 14:41:11 INFO Epoch 2: [9505/10940] ---- BYOL Training Loss = 0.2827032506465912
30-01-2023 14:42:04 INFO Epoch 2: [9505/10940] ---- BYOL Validation Loss = 0.23907460272312164
30-01-2023 14:42:22 INFO Epoch 2: [9516/10940] ---- BYOL Training Loss = 0.23999741673469543
30-01-2023 14:42:41 INFO Epoch 2: [9527/10940] ---- BYOL Training Loss = 0.23980793356895447
30-01-2023 14:42:59 INFO Epoch 2: [9538/10940] ---- BYOL Training Loss = 0.29379886388778687
30-01-2023 14:43:18 INFO Epoch 2: [9549/10940] ---- BYOL Training Loss = 0.2791007161140442
30-01-2023 14:44:10 INFO Epoch 2: [9549/10940] ---- BYOL Validation Loss = 0.25069424510002136
30-01-2023 14:44:28 INFO Epoch 2: [9560/10940] ---- BYOL Training Loss = 0.26873016357421875
30-01-2023 14:44:47 INFO Epoch 2: [9571/10940] ---- BYOL Training Loss = 0.308663547039032
30-01-2023 14:45:06 INFO Epoch 2: [9582/10940] ---- BYOL Training Loss = 0.29412704706192017
30-01-2023 14:45:24 INFO Epoch 2: [9593/10940] ---- BYOL Training Loss = 0.27076151967048645
30-01-2023 14:46:17 INFO Epoch 2: [9593/10940] ---- BYOL Validation Loss = 0.24247565865516663
30-01-2023 14:46:35 INFO Epoch 2: [9604/10940] ---- BYOL Training Loss = 0.3010477125644684
30-01-2023 14:46:54 INFO Epoch 2: [9615/10940] ---- BYOL Training Loss = 0.2739989161491394
30-01-2023 14:47:12 INFO Epoch 2: [9626/10940] ---- BYOL Training Loss = 0.2760317921638489
30-01-2023 14:47:31 INFO Epoch 2: [9637/10940] ---- BYOL Training Loss = 0.27074891328811646
30-01-2023 14:48:24 INFO Epoch 2: [9637/10940] ---- BYOL Validation Loss = 0.23791150748729706
30-01-2023 14:48:42 INFO Epoch 2: [9648/10940] ---- BYOL Training Loss = 0.2603488564491272
30-01-2023 14:49:00 INFO Epoch 2: [9659/10940] ---- BYOL Training Loss = 0.2525060474872589
30-01-2023 14:49:19 INFO Epoch 2: [9670/10940] ---- BYOL Training Loss = 0.27052488923072815
30-01-2023 14:49:37 INFO Epoch 2: [9681/10940] ---- BYOL Training Loss = 0.2796058654785156
30-01-2023 14:50:30 INFO Epoch 2: [9681/10940] ---- BYOL Validation Loss = 0.24991509318351746
30-01-2023 14:50:48 INFO Epoch 2: [9692/10940] ---- BYOL Training Loss = 0.2932698130607605
30-01-2023 14:51:07 INFO Epoch 2: [9703/10940] ---- BYOL Training Loss = 0.328663170337677
30-01-2023 14:51:26 INFO Epoch 2: [9714/10940] ---- BYOL Training Loss = 0.31515780091285706
30-01-2023 14:51:44 INFO Epoch 2: [9725/10940] ---- BYOL Training Loss = 0.2866266667842865
30-01-2023 14:52:36 INFO Epoch 2: [9725/10940] ---- BYOL Validation Loss = 0.24420319497585297
30-01-2023 14:52:54 INFO Epoch 2: [9736/10940] ---- BYOL Training Loss = 0.2492539882659912
30-01-2023 14:53:13 INFO Epoch 2: [9747/10940] ---- BYOL Training Loss = 0.2577100992202759
30-01-2023 14:53:31 INFO Epoch 2: [9758/10940] ---- BYOL Training Loss = 0.28369826078414917
30-01-2023 14:53:50 INFO Epoch 2: [9769/10940] ---- BYOL Training Loss = 0.28778237104415894
30-01-2023 14:54:43 INFO Epoch 2: [9769/10940] ---- BYOL Validation Loss = 0.2545466125011444
30-01-2023 14:55:01 INFO Epoch 2: [9780/10940] ---- BYOL Training Loss = 0.25939542055130005
30-01-2023 14:55:19 INFO Epoch 2: [9791/10940] ---- BYOL Training Loss = 0.25450557470321655
30-01-2023 14:55:38 INFO Epoch 2: [9802/10940] ---- BYOL Training Loss = 0.24745480716228485
30-01-2023 14:55:56 INFO Epoch 2: [9813/10940] ---- BYOL Training Loss = 0.23454396426677704
30-01-2023 14:56:49 INFO Epoch 2: [9813/10940] ---- BYOL Validation Loss = 0.24981768429279327
30-01-2023 14:57:08 INFO Epoch 2: [9824/10940] ---- BYOL Training Loss = 0.2911483645439148
30-01-2023 14:57:26 INFO Epoch 2: [9835/10940] ---- BYOL Training Loss = 0.3026455044746399
30-01-2023 14:57:45 INFO Epoch 2: [9846/10940] ---- BYOL Training Loss = 0.28955546021461487
30-01-2023 14:58:04 INFO Epoch 2: [9857/10940] ---- BYOL Training Loss = 0.2728133797645569
30-01-2023 14:58:56 INFO Epoch 2: [9857/10940] ---- BYOL Validation Loss = 0.24649013578891754
30-01-2023 14:59:14 INFO Epoch 2: [9868/10940] ---- BYOL Training Loss = 0.24880413711071014
30-01-2023 14:59:33 INFO Epoch 2: [9879/10940] ---- BYOL Training Loss = 0.24992701411247253
30-01-2023 14:59:51 INFO Epoch 2: [9890/10940] ---- BYOL Training Loss = 0.26775890588760376
30-01-2023 15:00:10 INFO Epoch 2: [9901/10940] ---- BYOL Training Loss = 0.265296995639801
30-01-2023 15:01:03 INFO Epoch 2: [9901/10940] ---- BYOL Validation Loss = 0.23829016089439392
30-01-2023 15:01:21 INFO Epoch 2: [9912/10940] ---- BYOL Training Loss = 0.3036673665046692
30-01-2023 15:01:39 INFO Epoch 2: [9923/10940] ---- BYOL Training Loss = 0.24358248710632324
30-01-2023 15:01:58 INFO Epoch 2: [9934/10940] ---- BYOL Training Loss = 0.21620556712150574
30-01-2023 15:02:16 INFO Epoch 2: [9945/10940] ---- BYOL Training Loss = 0.22060425579547882
30-01-2023 15:03:09 INFO Epoch 2: [9945/10940] ---- BYOL Validation Loss = 0.2343020737171173
30-01-2023 15:03:28 INFO Epoch 2: [9956/10940] ---- BYOL Training Loss = 0.1998579055070877
30-01-2023 15:03:46 INFO Epoch 2: [9967/10940] ---- BYOL Training Loss = 0.233956977725029
30-01-2023 15:04:05 INFO Epoch 2: [9978/10940] ---- BYOL Training Loss = 0.24572667479515076
30-01-2023 15:04:23 INFO Epoch 2: [9989/10940] ---- BYOL Training Loss = 0.2512040436267853
30-01-2023 15:05:16 INFO Epoch 2: [9989/10940] ---- BYOL Validation Loss = 0.24306021630764008
30-01-2023 15:05:34 INFO Epoch 2: [10000/10940] ---- BYOL Training Loss = 0.2715400755405426
30-01-2023 15:05:53 INFO Epoch 2: [10011/10940] ---- BYOL Training Loss = 0.25781407952308655
30-01-2023 15:06:11 INFO Epoch 2: [10022/10940] ---- BYOL Training Loss = 0.2409634292125702
30-01-2023 15:06:30 INFO Epoch 2: [10033/10940] ---- BYOL Training Loss = 0.3080293834209442
30-01-2023 15:07:23 INFO Epoch 2: [10033/10940] ---- BYOL Validation Loss = 0.2429060935974121
30-01-2023 15:07:41 INFO Epoch 2: [10044/10940] ---- BYOL Training Loss = 0.3856236934661865
30-01-2023 15:07:59 INFO Epoch 2: [10055/10940] ---- BYOL Training Loss = 0.3132115304470062
30-01-2023 15:08:18 INFO Epoch 2: [10066/10940] ---- BYOL Training Loss = 0.26982760429382324
30-01-2023 15:08:36 INFO Epoch 2: [10077/10940] ---- BYOL Training Loss = 0.2603336274623871
30-01-2023 15:09:29 INFO Epoch 2: [10077/10940] ---- BYOL Validation Loss = 0.24129344522953033
30-01-2023 15:09:47 INFO Epoch 2: [10088/10940] ---- BYOL Training Loss = 0.25551676750183105
30-01-2023 15:10:06 INFO Epoch 2: [10099/10940] ---- BYOL Training Loss = 0.2541063725948334
30-01-2023 15:10:24 INFO Epoch 2: [10110/10940] ---- BYOL Training Loss = 0.2639601230621338
30-01-2023 15:10:43 INFO Epoch 2: [10121/10940] ---- BYOL Training Loss = 0.23647792637348175
30-01-2023 15:11:36 INFO Epoch 2: [10121/10940] ---- BYOL Validation Loss = 0.23578734695911407
30-01-2023 15:11:54 INFO Epoch 2: [10132/10940] ---- BYOL Training Loss = 0.2532663345336914
30-01-2023 15:12:12 INFO Epoch 2: [10143/10940] ---- BYOL Training Loss = 0.2471970021724701
30-01-2023 15:12:31 INFO Epoch 2: [10154/10940] ---- BYOL Training Loss = 0.2748725414276123
30-01-2023 15:12:50 INFO Epoch 2: [10165/10940] ---- BYOL Training Loss = 0.3299635350704193
30-01-2023 15:13:42 INFO Epoch 2: [10165/10940] ---- BYOL Validation Loss = 0.24704892933368683
30-01-2023 15:14:00 INFO Epoch 2: [10176/10940] ---- BYOL Training Loss = 0.30142560601234436
30-01-2023 15:14:19 INFO Epoch 2: [10187/10940] ---- BYOL Training Loss = 0.26483914256095886
30-01-2023 15:14:38 INFO Epoch 2: [10198/10940] ---- BYOL Training Loss = 0.26111501455307007
30-01-2023 15:14:56 INFO Epoch 2: [10209/10940] ---- BYOL Training Loss = 0.2106051743030548
30-01-2023 15:15:49 INFO Epoch 2: [10209/10940] ---- BYOL Validation Loss = 0.2313930243253708
30-01-2023 15:16:07 INFO Epoch 2: [10220/10940] ---- BYOL Training Loss = 0.2435877025127411
30-01-2023 15:16:26 INFO Epoch 2: [10231/10940] ---- BYOL Training Loss = 0.2865551710128784
30-01-2023 15:16:44 INFO Epoch 2: [10242/10940] ---- BYOL Training Loss = 0.26132529973983765
30-01-2023 15:17:03 INFO Epoch 2: [10253/10940] ---- BYOL Training Loss = 0.2736186385154724
30-01-2023 15:17:56 INFO Epoch 2: [10253/10940] ---- BYOL Validation Loss = 0.25409314036369324
30-01-2023 15:18:14 INFO Epoch 2: [10264/10940] ---- BYOL Training Loss = 0.28293371200561523
30-01-2023 15:18:32 INFO Epoch 2: [10275/10940] ---- BYOL Training Loss = 0.2481215000152588
30-01-2023 15:18:51 INFO Epoch 2: [10286/10940] ---- BYOL Training Loss = 0.29591235518455505
30-01-2023 15:19:10 INFO Epoch 2: [10297/10940] ---- BYOL Training Loss = 0.28364691138267517
30-01-2023 15:20:02 INFO Epoch 2: [10297/10940] ---- BYOL Validation Loss = 0.24723254144191742
30-01-2023 15:20:20 INFO Epoch 2: [10308/10940] ---- BYOL Training Loss = 0.24843323230743408
30-01-2023 15:20:39 INFO Epoch 2: [10319/10940] ---- BYOL Training Loss = 0.2605757713317871
30-01-2023 15:20:57 INFO Epoch 2: [10330/10940] ---- BYOL Training Loss = 0.2595677673816681
30-01-2023 15:21:16 INFO Epoch 2: [10341/10940] ---- BYOL Training Loss = 0.28381404280662537
30-01-2023 15:22:08 INFO Epoch 2: [10341/10940] ---- BYOL Validation Loss = 0.2654946744441986
30-01-2023 15:22:27 INFO Epoch 2: [10352/10940] ---- BYOL Training Loss = 0.26798146963119507
30-01-2023 15:22:46 INFO Epoch 2: [10363/10940] ---- BYOL Training Loss = 0.2631951570510864
30-01-2023 15:23:05 INFO Epoch 2: [10374/10940] ---- BYOL Training Loss = 0.2656387686729431
30-01-2023 15:23:23 INFO Epoch 2: [10385/10940] ---- BYOL Training Loss = 0.2637246549129486
30-01-2023 15:24:15 INFO Epoch 2: [10385/10940] ---- BYOL Validation Loss = 0.25592121481895447
30-01-2023 15:24:33 INFO Epoch 2: [10396/10940] ---- BYOL Training Loss = 0.2894457280635834
30-01-2023 15:24:52 INFO Epoch 2: [10407/10940] ---- BYOL Training Loss = 0.2874128818511963
30-01-2023 15:25:11 INFO Epoch 2: [10418/10940] ---- BYOL Training Loss = 0.2548478841781616
30-01-2023 15:25:30 INFO Epoch 2: [10429/10940] ---- BYOL Training Loss = 0.24526366591453552
30-01-2023 15:26:22 INFO Epoch 2: [10429/10940] ---- BYOL Validation Loss = 0.24056604504585266
30-01-2023 15:26:40 INFO Epoch 2: [10440/10940] ---- BYOL Training Loss = 0.22818267345428467
30-01-2023 15:26:59 INFO Epoch 2: [10451/10940] ---- BYOL Training Loss = 0.23535671830177307
30-01-2023 15:27:18 INFO Epoch 2: [10462/10940] ---- BYOL Training Loss = 0.2957559823989868
30-01-2023 15:27:37 INFO Epoch 2: [10473/10940] ---- BYOL Training Loss = 0.2735207974910736
30-01-2023 15:28:29 INFO Epoch 2: [10473/10940] ---- BYOL Validation Loss = 0.253715842962265
30-01-2023 15:28:47 INFO Epoch 2: [10484/10940] ---- BYOL Training Loss = 0.2386503964662552
30-01-2023 15:29:06 INFO Epoch 2: [10495/10940] ---- BYOL Training Loss = 0.31173425912857056
30-01-2023 15:29:25 INFO Epoch 2: [10506/10940] ---- BYOL Training Loss = 0.3445690870285034
30-01-2023 15:29:43 INFO Epoch 2: [10517/10940] ---- BYOL Training Loss = 0.28413331508636475
30-01-2023 15:30:36 INFO Epoch 2: [10517/10940] ---- BYOL Validation Loss = 0.24952013790607452
30-01-2023 15:30:55 INFO Epoch 2: [10528/10940] ---- BYOL Training Loss = 0.3332189619541168
30-01-2023 15:31:13 INFO Epoch 2: [10539/10940] ---- BYOL Training Loss = 0.29700881242752075
30-01-2023 15:31:32 INFO Epoch 2: [10550/10940] ---- BYOL Training Loss = 0.29914411902427673
30-01-2023 15:31:51 INFO Epoch 2: [10561/10940] ---- BYOL Training Loss = 0.3089490532875061
30-01-2023 15:32:43 INFO Epoch 2: [10561/10940] ---- BYOL Validation Loss = 0.26045942306518555
30-01-2023 15:33:02 INFO Epoch 2: [10572/10940] ---- BYOL Training Loss = 0.292676717042923
30-01-2023 15:33:20 INFO Epoch 2: [10583/10940] ---- BYOL Training Loss = 0.2510051727294922
30-01-2023 15:33:39 INFO Epoch 2: [10594/10940] ---- BYOL Training Loss = 0.25805407762527466
30-01-2023 15:33:58 INFO Epoch 2: [10605/10940] ---- BYOL Training Loss = 0.268329918384552
30-01-2023 15:34:50 INFO Epoch 2: [10605/10940] ---- BYOL Validation Loss = 0.2654021382331848
30-01-2023 15:35:08 INFO Epoch 2: [10616/10940] ---- BYOL Training Loss = 0.31724390387535095
30-01-2023 15:35:27 INFO Epoch 2: [10627/10940] ---- BYOL Training Loss = 0.32606154680252075
30-01-2023 15:35:46 INFO Epoch 2: [10638/10940] ---- BYOL Training Loss = 0.294067919254303
30-01-2023 15:36:04 INFO Epoch 2: [10649/10940] ---- BYOL Training Loss = 0.3068949580192566
30-01-2023 15:36:57 INFO Epoch 2: [10649/10940] ---- BYOL Validation Loss = 0.2505625784397125
30-01-2023 15:37:15 INFO Epoch 2: [10660/10940] ---- BYOL Training Loss = 0.27625003457069397
30-01-2023 15:37:34 INFO Epoch 2: [10671/10940] ---- BYOL Training Loss = 0.2568665146827698
30-01-2023 15:37:52 INFO Epoch 2: [10682/10940] ---- BYOL Training Loss = 0.28076499700546265
30-01-2023 15:38:11 INFO Epoch 2: [10693/10940] ---- BYOL Training Loss = 0.2803383767604828
30-01-2023 15:39:04 INFO Epoch 2: [10693/10940] ---- BYOL Validation Loss = 0.25466296076774597
30-01-2023 15:39:22 INFO Epoch 2: [10704/10940] ---- BYOL Training Loss = 0.28417402505874634
30-01-2023 15:39:41 INFO Epoch 2: [10715/10940] ---- BYOL Training Loss = 0.2265719175338745
30-01-2023 15:40:00 INFO Epoch 2: [10726/10940] ---- BYOL Training Loss = 0.2718617618083954
30-01-2023 15:40:18 INFO Epoch 2: [10737/10940] ---- BYOL Training Loss = 0.2976694703102112
30-01-2023 15:41:11 INFO Epoch 2: [10737/10940] ---- BYOL Validation Loss = 0.25241726636886597
30-01-2023 15:41:30 INFO Epoch 2: [10748/10940] ---- BYOL Training Loss = 0.3107856512069702
30-01-2023 15:41:48 INFO Epoch 2: [10759/10940] ---- BYOL Training Loss = 0.2989233136177063
30-01-2023 15:42:07 INFO Epoch 2: [10770/10940] ---- BYOL Training Loss = 0.2486094981431961
30-01-2023 15:42:26 INFO Epoch 2: [10781/10940] ---- BYOL Training Loss = 0.2955166697502136
30-01-2023 15:43:19 INFO Epoch 2: [10781/10940] ---- BYOL Validation Loss = 0.24778570234775543
30-01-2023 15:43:37 INFO Epoch 2: [10792/10940] ---- BYOL Training Loss = 0.27390462160110474
30-01-2023 15:43:56 INFO Epoch 2: [10803/10940] ---- BYOL Training Loss = 0.25689277052879333
30-01-2023 15:44:14 INFO Epoch 2: [10814/10940] ---- BYOL Training Loss = 0.24606366455554962
30-01-2023 15:44:33 INFO Epoch 2: [10825/10940] ---- BYOL Training Loss = 0.2500876188278198
30-01-2023 15:45:26 INFO Epoch 2: [10825/10940] ---- BYOL Validation Loss = 0.25743913650512695
30-01-2023 15:45:44 INFO Epoch 2: [10836/10940] ---- BYOL Training Loss = 0.29251423478126526
30-01-2023 15:46:03 INFO Epoch 2: [10847/10940] ---- BYOL Training Loss = 0.278198778629303
30-01-2023 15:46:22 INFO Epoch 2: [10858/10940] ---- BYOL Training Loss = 0.2808564305305481
30-01-2023 15:46:41 INFO Epoch 2: [10869/10940] ---- BYOL Training Loss = 0.26757627725601196
30-01-2023 15:47:33 INFO Epoch 2: [10869/10940] ---- BYOL Validation Loss = 0.25250765681266785
30-01-2023 15:47:51 INFO Epoch 2: [10880/10940] ---- BYOL Training Loss = 0.2741543650627136
30-01-2023 15:48:10 INFO Epoch 2: [10891/10940] ---- BYOL Training Loss = 0.29232296347618103
30-01-2023 15:48:28 INFO Epoch 2: [10902/10940] ---- BYOL Training Loss = 0.30986061692237854
30-01-2023 15:48:47 INFO Epoch 2: [10913/10940] ---- BYOL Training Loss = 0.30973872542381287
30-01-2023 15:49:40 INFO Epoch 2: [10913/10940] ---- BYOL Validation Loss = 0.2461365908384323
30-01-2023 15:49:58 INFO Epoch 2: [10924/10940] ---- BYOL Training Loss = 0.2863911986351013
30-01-2023 15:50:17 INFO Epoch 2: [10935/10940] ---- BYOL Training Loss = 0.25309187173843384
30-01-2023 15:50:26 INFO Starting Epoch: 3
30-01-2023 15:50:45 INFO Epoch 3: [12/10940] ---- BYOL Training Loss = 0.3497319519519806
30-01-2023 15:51:02 INFO Epoch 3: [23/10940] ---- BYOL Training Loss = 0.3384135365486145
30-01-2023 15:51:20 INFO Epoch 3: [34/10940] ---- BYOL Training Loss = 0.27266302704811096
30-01-2023 15:51:37 INFO Epoch 3: [45/10940] ---- BYOL Training Loss = 0.2957431972026825
30-01-2023 15:52:30 INFO Epoch 3: [45/10940] ---- BYOL Validation Loss = 0.255999892950058
30-01-2023 15:52:47 INFO Epoch 3: [56/10940] ---- BYOL Training Loss = 0.2868238687515259
30-01-2023 15:53:04 INFO Epoch 3: [67/10940] ---- BYOL Training Loss = 0.20036527514457703
30-01-2023 15:53:22 INFO Epoch 3: [78/10940] ---- BYOL Training Loss = 0.23007377982139587
30-01-2023 15:53:40 INFO Epoch 3: [89/10940] ---- BYOL Training Loss = 0.2505077123641968
30-01-2023 15:54:32 INFO Epoch 3: [89/10940] ---- BYOL Validation Loss = 0.240235835313797
30-01-2023 15:54:49 INFO Epoch 3: [100/10940] ---- BYOL Training Loss = 0.23540642857551575
30-01-2023 15:55:07 INFO Epoch 3: [111/10940] ---- BYOL Training Loss = 0.25741061568260193
30-01-2023 15:55:24 INFO Epoch 3: [122/10940] ---- BYOL Training Loss = 0.2824575901031494
30-01-2023 15:55:42 INFO Epoch 3: [133/10940] ---- BYOL Training Loss = 0.28972309827804565
30-01-2023 15:56:35 INFO Epoch 3: [133/10940] ---- BYOL Validation Loss = 0.23877587914466858
30-01-2023 15:56:52 INFO Epoch 3: [144/10940] ---- BYOL Training Loss = 0.23032763600349426
30-01-2023 15:57:09 INFO Epoch 3: [155/10940] ---- BYOL Training Loss = 0.2244594842195511
30-01-2023 15:57:27 INFO Epoch 3: [166/10940] ---- BYOL Training Loss = 0.2654247581958771
30-01-2023 15:57:44 INFO Epoch 3: [177/10940] ---- BYOL Training Loss = 0.3099793791770935
30-01-2023 15:58:37 INFO Epoch 3: [177/10940] ---- BYOL Validation Loss = 0.22828790545463562
30-01-2023 15:58:54 INFO Epoch 3: [188/10940] ---- BYOL Training Loss = 0.3062199056148529
30-01-2023 15:59:11 INFO Epoch 3: [199/10940] ---- BYOL Training Loss = 0.23426476120948792
30-01-2023 15:59:29 INFO Epoch 3: [210/10940] ---- BYOL Training Loss = 0.24604709446430206
30-01-2023 15:59:46 INFO Epoch 3: [221/10940] ---- BYOL Training Loss = 0.22490188479423523
30-01-2023 16:00:39 INFO Epoch 3: [221/10940] ---- BYOL Validation Loss = 0.2395249605178833
30-01-2023 16:00:56 INFO Epoch 3: [232/10940] ---- BYOL Training Loss = 0.23616819083690643
30-01-2023 16:01:14 INFO Epoch 3: [243/10940] ---- BYOL Training Loss = 0.2631858289241791
30-01-2023 16:01:31 INFO Epoch 3: [254/10940] ---- BYOL Training Loss = 0.26463598012924194
30-01-2023 16:01:49 INFO Epoch 3: [265/10940] ---- BYOL Training Loss = 0.2502482831478119
30-01-2023 16:02:41 INFO Epoch 3: [265/10940] ---- BYOL Validation Loss = 0.24662820994853973
30-01-2023 16:02:59 INFO Epoch 3: [276/10940] ---- BYOL Training Loss = 0.1923038512468338
30-01-2023 16:03:16 INFO Epoch 3: [287/10940] ---- BYOL Training Loss = 0.20900902152061462
30-01-2023 16:03:34 INFO Epoch 3: [298/10940] ---- BYOL Training Loss = 0.28606516122817993
30-01-2023 16:03:51 INFO Epoch 3: [309/10940] ---- BYOL Training Loss = 0.2577376961708069
30-01-2023 16:04:44 INFO Epoch 3: [309/10940] ---- BYOL Validation Loss = 0.2570419907569885
30-01-2023 16:05:01 INFO Epoch 3: [320/10940] ---- BYOL Training Loss = 0.2193032205104828
30-01-2023 16:05:19 INFO Epoch 3: [331/10940] ---- BYOL Training Loss = 0.25659891963005066
30-01-2023 16:05:36 INFO Epoch 3: [342/10940] ---- BYOL Training Loss = 0.2703392505645752
30-01-2023 16:05:54 INFO Epoch 3: [353/10940] ---- BYOL Training Loss = 0.2507086396217346
30-01-2023 16:06:46 INFO Epoch 3: [353/10940] ---- BYOL Validation Loss = 0.2529415488243103
30-01-2023 16:07:04 INFO Epoch 3: [364/10940] ---- BYOL Training Loss = 0.2195403128862381
30-01-2023 16:07:21 INFO Epoch 3: [375/10940] ---- BYOL Training Loss = 0.2743600904941559
30-01-2023 16:07:39 INFO Epoch 3: [386/10940] ---- BYOL Training Loss = 0.2726448178291321
30-01-2023 16:07:56 INFO Epoch 3: [397/10940] ---- BYOL Training Loss = 0.2498261034488678
30-01-2023 16:08:49 INFO Epoch 3: [397/10940] ---- BYOL Validation Loss = 0.24209824204444885
30-01-2023 16:09:06 INFO Epoch 3: [408/10940] ---- BYOL Training Loss = 0.24477963149547577
30-01-2023 16:09:23 INFO Epoch 3: [419/10940] ---- BYOL Training Loss = 0.22823932766914368
30-01-2023 16:09:41 INFO Epoch 3: [430/10940] ---- BYOL Training Loss = 0.2208520621061325
30-01-2023 16:09:59 INFO Epoch 3: [441/10940] ---- BYOL Training Loss = 0.2315528839826584
30-01-2023 16:10:51 INFO Epoch 3: [441/10940] ---- BYOL Validation Loss = 0.24010911583900452
30-01-2023 16:11:08 INFO Epoch 3: [452/10940] ---- BYOL Training Loss = 0.2646106779575348
30-01-2023 16:11:26 INFO Epoch 3: [463/10940] ---- BYOL Training Loss = 0.25591227412223816
30-01-2023 16:11:43 INFO Epoch 3: [474/10940] ---- BYOL Training Loss = 0.3030479848384857
30-01-2023 16:12:01 INFO Epoch 3: [485/10940] ---- BYOL Training Loss = 0.2927238643169403
30-01-2023 16:12:53 INFO Epoch 3: [485/10940] ---- BYOL Validation Loss = 0.23656882345676422
30-01-2023 16:13:11 INFO Epoch 3: [496/10940] ---- BYOL Training Loss = 0.24915950000286102
30-01-2023 16:13:28 INFO Epoch 3: [507/10940] ---- BYOL Training Loss = 0.26531165838241577
30-01-2023 16:13:46 INFO Epoch 3: [518/10940] ---- BYOL Training Loss = 0.2564713954925537
30-01-2023 16:14:04 INFO Epoch 3: [529/10940] ---- BYOL Training Loss = 0.2793850302696228
30-01-2023 16:14:56 INFO Epoch 3: [529/10940] ---- BYOL Validation Loss = 0.23668932914733887
30-01-2023 16:15:13 INFO Epoch 3: [540/10940] ---- BYOL Training Loss = 0.30459439754486084
30-01-2023 16:15:31 INFO Epoch 3: [551/10940] ---- BYOL Training Loss = 0.2675480246543884
30-01-2023 16:15:48 INFO Epoch 3: [562/10940] ---- BYOL Training Loss = 0.2244279831647873
30-01-2023 16:16:06 INFO Epoch 3: [573/10940] ---- BYOL Training Loss = 0.24212613701820374
30-01-2023 16:16:59 INFO Epoch 3: [573/10940] ---- BYOL Validation Loss = 0.24549131095409393
30-01-2023 16:17:16 INFO Epoch 3: [584/10940] ---- BYOL Training Loss = 0.25438469648361206
30-01-2023 16:17:33 INFO Epoch 3: [595/10940] ---- BYOL Training Loss = 0.21734404563903809
30-01-2023 16:17:51 INFO Epoch 3: [606/10940] ---- BYOL Training Loss = 0.24307949841022491
30-01-2023 16:18:09 INFO Epoch 3: [617/10940] ---- BYOL Training Loss = 0.24781718850135803
30-01-2023 16:19:01 INFO Epoch 3: [617/10940] ---- BYOL Validation Loss = 0.230733260512352
30-01-2023 16:19:18 INFO Epoch 3: [628/10940] ---- BYOL Training Loss = 0.2713766098022461
30-01-2023 16:19:36 INFO Epoch 3: [639/10940] ---- BYOL Training Loss = 0.2537176012992859
30-01-2023 16:19:53 INFO Epoch 3: [650/10940] ---- BYOL Training Loss = 0.20694315433502197
30-01-2023 16:20:11 INFO Epoch 3: [661/10940] ---- BYOL Training Loss = 0.2326035499572754
30-01-2023 16:21:04 INFO Epoch 3: [661/10940] ---- BYOL Validation Loss = 0.22316302359104156
30-01-2023 16:21:21 INFO Epoch 3: [672/10940] ---- BYOL Training Loss = 0.2540188431739807
30-01-2023 16:21:39 INFO Epoch 3: [683/10940] ---- BYOL Training Loss = 0.28068381547927856
30-01-2023 16:21:56 INFO Epoch 3: [694/10940] ---- BYOL Training Loss = 0.27961021661758423
30-01-2023 16:22:14 INFO Epoch 3: [705/10940] ---- BYOL Training Loss = 0.2932259440422058
30-01-2023 16:23:06 INFO Epoch 3: [705/10940] ---- BYOL Validation Loss = 0.25238123536109924
30-01-2023 16:23:24 INFO Epoch 3: [716/10940] ---- BYOL Training Loss = 0.3098587989807129
30-01-2023 16:23:41 INFO Epoch 3: [727/10940] ---- BYOL Training Loss = 0.2912057042121887
30-01-2023 16:23:59 INFO Epoch 3: [738/10940] ---- BYOL Training Loss = 0.28166067600250244
30-01-2023 16:24:16 INFO Epoch 3: [749/10940] ---- BYOL Training Loss = 0.2314714938402176
30-01-2023 16:25:09 INFO Epoch 3: [749/10940] ---- BYOL Validation Loss = 0.2417798936367035
30-01-2023 16:25:26 INFO Epoch 3: [760/10940] ---- BYOL Training Loss = 0.2124008685350418
30-01-2023 16:25:44 INFO Epoch 3: [771/10940] ---- BYOL Training Loss = 0.20673604309558868
30-01-2023 16:26:01 INFO Epoch 3: [782/10940] ---- BYOL Training Loss = 0.21471306681632996
30-01-2023 16:26:19 INFO Epoch 3: [793/10940] ---- BYOL Training Loss = 0.29858407378196716
30-01-2023 16:27:12 INFO Epoch 3: [793/10940] ---- BYOL Validation Loss = 0.232619971036911
30-01-2023 16:27:29 INFO Epoch 3: [804/10940] ---- BYOL Training Loss = 0.3303166627883911
30-01-2023 16:27:46 INFO Epoch 3: [815/10940] ---- BYOL Training Loss = 0.31558477878570557
30-01-2023 16:28:04 INFO Epoch 3: [826/10940] ---- BYOL Training Loss = 0.263827383518219
30-01-2023 16:28:22 INFO Epoch 3: [837/10940] ---- BYOL Training Loss = 0.2546919286251068
30-01-2023 16:29:14 INFO Epoch 3: [837/10940] ---- BYOL Validation Loss = 0.22480638325214386
30-01-2023 16:29:31 INFO Epoch 3: [848/10940] ---- BYOL Training Loss = 0.23411794006824493
30-01-2023 16:29:49 INFO Epoch 3: [859/10940] ---- BYOL Training Loss = 0.2490764558315277
30-01-2023 16:30:07 INFO Epoch 3: [870/10940] ---- BYOL Training Loss = 0.24147649109363556
30-01-2023 16:30:24 INFO Epoch 3: [881/10940] ---- BYOL Training Loss = 0.22197651863098145
30-01-2023 16:31:17 INFO Epoch 3: [881/10940] ---- BYOL Validation Loss = 0.23986360430717468
30-01-2023 16:31:34 INFO Epoch 3: [892/10940] ---- BYOL Training Loss = 0.26957613229751587
30-01-2023 16:31:52 INFO Epoch 3: [903/10940] ---- BYOL Training Loss = 0.2886028587818146
30-01-2023 16:32:09 INFO Epoch 3: [914/10940] ---- BYOL Training Loss = 0.25693780183792114
30-01-2023 16:32:27 INFO Epoch 3: [925/10940] ---- BYOL Training Loss = 0.2922954261302948
30-01-2023 16:33:20 INFO Epoch 3: [925/10940] ---- BYOL Validation Loss = 0.24148747324943542
30-01-2023 16:33:37 INFO Epoch 3: [936/10940] ---- BYOL Training Loss = 0.27808648347854614
30-01-2023 16:33:55 INFO Epoch 3: [947/10940] ---- BYOL Training Loss = 0.2399427890777588
30-01-2023 16:34:12 INFO Epoch 3: [958/10940] ---- BYOL Training Loss = 0.2617453932762146
30-01-2023 16:34:30 INFO Epoch 3: [969/10940] ---- BYOL Training Loss = 0.23901212215423584
30-01-2023 16:35:22 INFO Epoch 3: [969/10940] ---- BYOL Validation Loss = 0.21967141330242157
30-01-2023 16:35:40 INFO Epoch 3: [980/10940] ---- BYOL Training Loss = 0.2347838431596756
30-01-2023 16:35:57 INFO Epoch 3: [991/10940] ---- BYOL Training Loss = 0.27005651593208313
30-01-2023 16:36:15 INFO Epoch 3: [1002/10940] ---- BYOL Training Loss = 0.282432496547699
30-01-2023 16:36:33 INFO Epoch 3: [1013/10940] ---- BYOL Training Loss = 0.2501485049724579
30-01-2023 16:37:25 INFO Epoch 3: [1013/10940] ---- BYOL Validation Loss = 0.23525606095790863
30-01-2023 16:37:42 INFO Epoch 3: [1024/10940] ---- BYOL Training Loss = 0.27343305945396423
30-01-2023 16:38:00 INFO Epoch 3: [1035/10940] ---- BYOL Training Loss = 0.28541988134384155
30-01-2023 16:38:18 INFO Epoch 3: [1046/10940] ---- BYOL Training Loss = 0.28997141122817993
30-01-2023 16:38:35 INFO Epoch 3: [1057/10940] ---- BYOL Training Loss = 0.3057085871696472
30-01-2023 16:39:28 INFO Epoch 3: [1057/10940] ---- BYOL Validation Loss = 0.22753919661045074
30-01-2023 16:39:46 INFO Epoch 3: [1068/10940] ---- BYOL Training Loss = 0.27435916662216187
30-01-2023 16:40:03 INFO Epoch 3: [1079/10940] ---- BYOL Training Loss = 0.25955790281295776
30-01-2023 16:40:21 INFO Epoch 3: [1090/10940] ---- BYOL Training Loss = 0.21884968876838684
30-01-2023 16:40:39 INFO Epoch 3: [1101/10940] ---- BYOL Training Loss = 0.20901498198509216
30-01-2023 16:41:31 INFO Epoch 3: [1101/10940] ---- BYOL Validation Loss = 0.2253122478723526
30-01-2023 16:41:48 INFO Epoch 3: [1112/10940] ---- BYOL Training Loss = 0.2344987839460373
30-01-2023 16:42:06 INFO Epoch 3: [1123/10940] ---- BYOL Training Loss = 0.22798092663288116
30-01-2023 16:42:24 INFO Epoch 3: [1134/10940] ---- BYOL Training Loss = 0.21797016263008118
30-01-2023 16:42:41 INFO Epoch 3: [1145/10940] ---- BYOL Training Loss = 0.2269667387008667
30-01-2023 16:43:34 INFO Epoch 3: [1145/10940] ---- BYOL Validation Loss = 0.22844374179840088
30-01-2023 16:43:51 INFO Epoch 3: [1156/10940] ---- BYOL Training Loss = 0.1979760378599167
30-01-2023 16:44:08 INFO Epoch 3: [1167/10940] ---- BYOL Training Loss = 0.2342233955860138
30-01-2023 16:44:26 INFO Epoch 3: [1178/10940] ---- BYOL Training Loss = 0.27528896927833557
30-01-2023 16:44:44 INFO Epoch 3: [1189/10940] ---- BYOL Training Loss = 0.29038482904434204
30-01-2023 16:45:36 INFO Epoch 3: [1189/10940] ---- BYOL Validation Loss = 0.2540430724620819
30-01-2023 16:45:53 INFO Epoch 3: [1200/10940] ---- BYOL Training Loss = 0.29405462741851807
30-01-2023 16:46:11 INFO Epoch 3: [1211/10940] ---- BYOL Training Loss = 0.30398330092430115
30-01-2023 16:46:29 INFO Epoch 3: [1222/10940] ---- BYOL Training Loss = 0.32512909173965454
30-01-2023 16:46:46 INFO Epoch 3: [1233/10940] ---- BYOL Training Loss = 0.34850698709487915
30-01-2023 16:47:39 INFO Epoch 3: [1233/10940] ---- BYOL Validation Loss = 0.2650040090084076
30-01-2023 16:47:56 INFO Epoch 3: [1244/10940] ---- BYOL Training Loss = 0.3057432472705841
30-01-2023 16:48:14 INFO Epoch 3: [1255/10940] ---- BYOL Training Loss = 0.2992808222770691
30-01-2023 16:48:31 INFO Epoch 3: [1266/10940] ---- BYOL Training Loss = 0.28954875469207764
30-01-2023 16:48:49 INFO Epoch 3: [1277/10940] ---- BYOL Training Loss = 0.26100844144821167
30-01-2023 16:49:42 INFO Epoch 3: [1277/10940] ---- BYOL Validation Loss = 0.26308080554008484
30-01-2023 16:49:59 INFO Epoch 3: [1288/10940] ---- BYOL Training Loss = 0.25143417716026306
30-01-2023 16:50:16 INFO Epoch 3: [1299/10940] ---- BYOL Training Loss = 0.22222957015037537
30-01-2023 16:50:34 INFO Epoch 3: [1310/10940] ---- BYOL Training Loss = 0.24443113803863525
30-01-2023 16:50:52 INFO Epoch 3: [1321/10940] ---- BYOL Training Loss = 0.26747027039527893
30-01-2023 16:51:44 INFO Epoch 3: [1321/10940] ---- BYOL Validation Loss = 0.25027647614479065
30-01-2023 16:52:02 INFO Epoch 3: [1332/10940] ---- BYOL Training Loss = 0.259452760219574
30-01-2023 16:52:19 INFO Epoch 3: [1343/10940] ---- BYOL Training Loss = 0.24203717708587646
30-01-2023 16:52:37 INFO Epoch 3: [1354/10940] ---- BYOL Training Loss = 0.2878653109073639
30-01-2023 16:52:55 INFO Epoch 3: [1365/10940] ---- BYOL Training Loss = 0.2938326299190521
30-01-2023 16:53:47 INFO Epoch 3: [1365/10940] ---- BYOL Validation Loss = 0.254233181476593
30-01-2023 16:54:04 INFO Epoch 3: [1376/10940] ---- BYOL Training Loss = 0.30512696504592896
30-01-2023 16:54:22 INFO Epoch 3: [1387/10940] ---- BYOL Training Loss = 0.30933159589767456
30-01-2023 16:54:40 INFO Epoch 3: [1398/10940] ---- BYOL Training Loss = 0.2516241669654846
30-01-2023 16:54:58 INFO Epoch 3: [1409/10940] ---- BYOL Training Loss = 0.252554714679718
30-01-2023 16:55:50 INFO Epoch 3: [1409/10940] ---- BYOL Validation Loss = 0.24415329098701477
30-01-2023 16:56:08 INFO Epoch 3: [1420/10940] ---- BYOL Training Loss = 0.25188520550727844
30-01-2023 16:56:25 INFO Epoch 3: [1431/10940] ---- BYOL Training Loss = 0.23495280742645264
30-01-2023 16:56:43 INFO Epoch 3: [1442/10940] ---- BYOL Training Loss = 0.26115378737449646
30-01-2023 16:57:01 INFO Epoch 3: [1453/10940] ---- BYOL Training Loss = 0.2751404643058777
30-01-2023 16:57:54 INFO Epoch 3: [1453/10940] ---- BYOL Validation Loss = 0.2532596290111542
30-01-2023 16:58:11 INFO Epoch 3: [1464/10940] ---- BYOL Training Loss = 0.2197587788105011
30-01-2023 16:58:28 INFO Epoch 3: [1475/10940] ---- BYOL Training Loss = 0.22265839576721191
30-01-2023 16:58:46 INFO Epoch 3: [1486/10940] ---- BYOL Training Loss = 0.21927504241466522
30-01-2023 16:59:04 INFO Epoch 3: [1497/10940] ---- BYOL Training Loss = 0.2433118373155594
30-01-2023 16:59:56 INFO Epoch 3: [1497/10940] ---- BYOL Validation Loss = 0.260027140378952
30-01-2023 17:00:14 INFO Epoch 3: [1508/10940] ---- BYOL Training Loss = 0.25918281078338623
30-01-2023 17:00:31 INFO Epoch 3: [1519/10940] ---- BYOL Training Loss = 0.26344969868659973
30-01-2023 17:00:49 INFO Epoch 3: [1530/10940] ---- BYOL Training Loss = 0.3102113902568817
30-01-2023 17:01:07 INFO Epoch 3: [1541/10940] ---- BYOL Training Loss = 0.2630540728569031
30-01-2023 17:01:59 INFO Epoch 3: [1541/10940] ---- BYOL Validation Loss = 0.25214406847953796
30-01-2023 17:02:17 INFO Epoch 3: [1552/10940] ---- BYOL Training Loss = 0.2596007287502289
30-01-2023 17:02:34 INFO Epoch 3: [1563/10940] ---- BYOL Training Loss = 0.2922992408275604
30-01-2023 17:02:52 INFO Epoch 3: [1574/10940] ---- BYOL Training Loss = 0.2650640606880188
30-01-2023 17:03:10 INFO Epoch 3: [1585/10940] ---- BYOL Training Loss = 0.28666073083877563
30-01-2023 17:04:02 INFO Epoch 3: [1585/10940] ---- BYOL Validation Loss = 0.2751535475254059
30-01-2023 17:04:20 INFO Epoch 3: [1596/10940] ---- BYOL Training Loss = 0.2772761881351471
30-01-2023 17:04:37 INFO Epoch 3: [1607/10940] ---- BYOL Training Loss = 0.25802522897720337
30-01-2023 17:04:55 INFO Epoch 3: [1618/10940] ---- BYOL Training Loss = 0.24166841804981232
30-01-2023 17:05:13 INFO Epoch 3: [1629/10940] ---- BYOL Training Loss = 0.3098609149456024
30-01-2023 17:06:05 INFO Epoch 3: [1629/10940] ---- BYOL Validation Loss = 0.2649448812007904
30-01-2023 17:06:23 INFO Epoch 3: [1640/10940] ---- BYOL Training Loss = 0.29650330543518066
30-01-2023 17:06:41 INFO Epoch 3: [1651/10940] ---- BYOL Training Loss = 0.26106005907058716
30-01-2023 17:06:58 INFO Epoch 3: [1662/10940] ---- BYOL Training Loss = 0.28298047184944153
30-01-2023 17:07:16 INFO Epoch 3: [1673/10940] ---- BYOL Training Loss = 0.24887582659721375
30-01-2023 17:08:09 INFO Epoch 3: [1673/10940] ---- BYOL Validation Loss = 0.2594631016254425
30-01-2023 17:08:26 INFO Epoch 3: [1684/10940] ---- BYOL Training Loss = 0.2784329652786255
30-01-2023 17:08:44 INFO Epoch 3: [1695/10940] ---- BYOL Training Loss = 0.299287885427475
30-01-2023 17:09:01 INFO Epoch 3: [1706/10940] ---- BYOL Training Loss = 0.2524365782737732
30-01-2023 17:09:19 INFO Epoch 3: [1717/10940] ---- BYOL Training Loss = 0.23785746097564697
30-01-2023 17:10:12 INFO Epoch 3: [1717/10940] ---- BYOL Validation Loss = 0.2705667316913605
30-01-2023 17:10:29 INFO Epoch 3: [1728/10940] ---- BYOL Training Loss = 0.2637210488319397
30-01-2023 17:10:47 INFO Epoch 3: [1739/10940] ---- BYOL Training Loss = 0.25180482864379883
30-01-2023 17:11:05 INFO Epoch 3: [1750/10940] ---- BYOL Training Loss = 0.25798144936561584
30-01-2023 17:11:22 INFO Epoch 3: [1761/10940] ---- BYOL Training Loss = 0.26255908608436584
30-01-2023 17:12:15 INFO Epoch 3: [1761/10940] ---- BYOL Validation Loss = 0.24844898283481598
30-01-2023 17:12:32 INFO Epoch 3: [1772/10940] ---- BYOL Training Loss = 0.22605092823505402
30-01-2023 17:12:50 INFO Epoch 3: [1783/10940] ---- BYOL Training Loss = 0.20500501990318298
30-01-2023 17:13:08 INFO Epoch 3: [1794/10940] ---- BYOL Training Loss = 0.27855706214904785
30-01-2023 17:13:25 INFO Epoch 3: [1805/10940] ---- BYOL Training Loss = 0.2870776653289795
30-01-2023 17:14:18 INFO Epoch 3: [1805/10940] ---- BYOL Validation Loss = 0.26052817702293396
30-01-2023 17:14:35 INFO Epoch 3: [1816/10940] ---- BYOL Training Loss = 0.26754921674728394
30-01-2023 17:14:53 INFO Epoch 3: [1827/10940] ---- BYOL Training Loss = 0.31463226675987244
30-01-2023 17:15:11 INFO Epoch 3: [1838/10940] ---- BYOL Training Loss = 0.3212992250919342
30-01-2023 17:15:28 INFO Epoch 3: [1849/10940] ---- BYOL Training Loss = 0.3057391047477722
30-01-2023 17:16:21 INFO Epoch 3: [1849/10940] ---- BYOL Validation Loss = 0.26020392775535583
30-01-2023 17:16:38 INFO Epoch 3: [1860/10940] ---- BYOL Training Loss = 0.2721034586429596
30-01-2023 17:16:56 INFO Epoch 3: [1871/10940] ---- BYOL Training Loss = 0.27981796860694885
30-01-2023 17:17:14 INFO Epoch 3: [1882/10940] ---- BYOL Training Loss = 0.34225228428840637
30-01-2023 17:17:31 INFO Epoch 3: [1893/10940] ---- BYOL Training Loss = 0.2990546226501465
30-01-2023 17:18:24 INFO Epoch 3: [1893/10940] ---- BYOL Validation Loss = 0.25547537207603455
30-01-2023 17:18:41 INFO Epoch 3: [1904/10940] ---- BYOL Training Loss = 0.3090363144874573
30-01-2023 17:18:59 INFO Epoch 3: [1915/10940] ---- BYOL Training Loss = 0.28371816873550415
30-01-2023 17:19:17 INFO Epoch 3: [1926/10940] ---- BYOL Training Loss = 0.2622373402118683
30-01-2023 17:19:35 INFO Epoch 3: [1937/10940] ---- BYOL Training Loss = 0.2471768856048584
30-01-2023 17:20:27 INFO Epoch 3: [1937/10940] ---- BYOL Validation Loss = 0.23771932721138
30-01-2023 17:20:45 INFO Epoch 3: [1948/10940] ---- BYOL Training Loss = 0.29545533657073975
30-01-2023 17:21:02 INFO Epoch 3: [1959/10940] ---- BYOL Training Loss = 0.31654390692710876
30-01-2023 17:21:20 INFO Epoch 3: [1970/10940] ---- BYOL Training Loss = 0.26283568143844604
30-01-2023 17:21:38 INFO Epoch 3: [1981/10940] ---- BYOL Training Loss = 0.3210381269454956
30-01-2023 17:22:30 INFO Epoch 3: [1981/10940] ---- BYOL Validation Loss = 0.237636998295784
30-01-2023 17:22:48 INFO Epoch 3: [1992/10940] ---- BYOL Training Loss = 0.344929575920105
30-01-2023 17:23:06 INFO Epoch 3: [2003/10940] ---- BYOL Training Loss = 0.29180318117141724
30-01-2023 17:23:24 INFO Epoch 3: [2014/10940] ---- BYOL Training Loss = 0.3071814179420471
30-01-2023 17:23:41 INFO Epoch 3: [2025/10940] ---- BYOL Training Loss = 0.32479581236839294
30-01-2023 17:24:34 INFO Epoch 3: [2025/10940] ---- BYOL Validation Loss = 0.2556019425392151
30-01-2023 17:24:51 INFO Epoch 3: [2036/10940] ---- BYOL Training Loss = 0.2783997654914856
30-01-2023 17:25:09 INFO Epoch 3: [2047/10940] ---- BYOL Training Loss = 0.3050229549407959
30-01-2023 17:25:27 INFO Epoch 3: [2058/10940] ---- BYOL Training Loss = 0.3331466317176819
30-01-2023 17:25:44 INFO Epoch 3: [2069/10940] ---- BYOL Training Loss = 0.2740461230278015
30-01-2023 17:26:37 INFO Epoch 3: [2069/10940] ---- BYOL Validation Loss = 0.2544800341129303
30-01-2023 17:26:54 INFO Epoch 3: [2080/10940] ---- BYOL Training Loss = 0.25632745027542114
30-01-2023 17:27:12 INFO Epoch 3: [2091/10940] ---- BYOL Training Loss = 0.27860569953918457
30-01-2023 17:27:29 INFO Epoch 3: [2102/10940] ---- BYOL Training Loss = 0.30293747782707214
30-01-2023 17:27:47 INFO Epoch 3: [2113/10940] ---- BYOL Training Loss = 0.2959170937538147
30-01-2023 17:28:40 INFO Epoch 3: [2113/10940] ---- BYOL Validation Loss = 0.2566637694835663
30-01-2023 17:28:57 INFO Epoch 3: [2124/10940] ---- BYOL Training Loss = 0.2825624942779541
30-01-2023 17:29:15 INFO Epoch 3: [2135/10940] ---- BYOL Training Loss = 0.28837066888809204
30-01-2023 17:29:33 INFO Epoch 3: [2146/10940] ---- BYOL Training Loss = 0.2538655698299408
30-01-2023 17:29:50 INFO Epoch 3: [2157/10940] ---- BYOL Training Loss = 0.2131480723619461
30-01-2023 17:30:43 INFO Epoch 3: [2157/10940] ---- BYOL Validation Loss = 0.25416940450668335
30-01-2023 17:31:01 INFO Epoch 3: [2168/10940] ---- BYOL Training Loss = 0.2554675042629242
30-01-2023 17:31:18 INFO Epoch 3: [2179/10940] ---- BYOL Training Loss = 0.26200613379478455
30-01-2023 17:31:36 INFO Epoch 3: [2190/10940] ---- BYOL Training Loss = 0.2878100275993347
30-01-2023 17:31:54 INFO Epoch 3: [2201/10940] ---- BYOL Training Loss = 0.270866721868515
30-01-2023 17:32:46 INFO Epoch 3: [2201/10940] ---- BYOL Validation Loss = 0.25545960664749146
30-01-2023 17:33:04 INFO Epoch 3: [2212/10940] ---- BYOL Training Loss = 0.23352360725402832
30-01-2023 17:33:21 INFO Epoch 3: [2223/10940] ---- BYOL Training Loss = 0.21365921199321747
30-01-2023 17:33:39 INFO Epoch 3: [2234/10940] ---- BYOL Training Loss = 0.25210365653038025
30-01-2023 17:33:57 INFO Epoch 3: [2245/10940] ---- BYOL Training Loss = 0.27872735261917114
30-01-2023 17:34:49 INFO Epoch 3: [2245/10940] ---- BYOL Validation Loss = 0.24112117290496826
30-01-2023 17:35:07 INFO Epoch 3: [2256/10940] ---- BYOL Training Loss = 0.30165600776672363
30-01-2023 17:35:24 INFO Epoch 3: [2267/10940] ---- BYOL Training Loss = 0.3039637804031372
30-01-2023 17:35:42 INFO Epoch 3: [2278/10940] ---- BYOL Training Loss = 0.34083759784698486
30-01-2023 17:36:00 INFO Epoch 3: [2289/10940] ---- BYOL Training Loss = 0.3309430480003357
30-01-2023 17:36:52 INFO Epoch 3: [2289/10940] ---- BYOL Validation Loss = 0.26337820291519165
30-01-2023 17:37:10 INFO Epoch 3: [2300/10940] ---- BYOL Training Loss = 0.29201680421829224
30-01-2023 17:37:28 INFO Epoch 3: [2311/10940] ---- BYOL Training Loss = 0.27282530069351196
30-01-2023 17:37:46 INFO Epoch 3: [2322/10940] ---- BYOL Training Loss = 0.2993696331977844
30-01-2023 17:38:04 INFO Epoch 3: [2333/10940] ---- BYOL Training Loss = 0.31550994515419006
30-01-2023 17:38:56 INFO Epoch 3: [2333/10940] ---- BYOL Validation Loss = 0.2549784481525421
30-01-2023 17:39:14 INFO Epoch 3: [2344/10940] ---- BYOL Training Loss = 0.2952260375022888
30-01-2023 17:39:31 INFO Epoch 3: [2355/10940] ---- BYOL Training Loss = 0.22118934988975525
30-01-2023 17:39:49 INFO Epoch 3: [2366/10940] ---- BYOL Training Loss = 0.23549194633960724
30-01-2023 17:40:07 INFO Epoch 3: [2377/10940] ---- BYOL Training Loss = 0.2947898507118225
30-01-2023 17:41:00 INFO Epoch 3: [2377/10940] ---- BYOL Validation Loss = 0.24277222156524658
30-01-2023 17:41:17 INFO Epoch 3: [2388/10940] ---- BYOL Training Loss = 0.2965230941772461
30-01-2023 17:41:35 INFO Epoch 3: [2399/10940] ---- BYOL Training Loss = 0.23578377068042755
30-01-2023 17:41:53 INFO Epoch 3: [2410/10940] ---- BYOL Training Loss = 0.22054898738861084
30-01-2023 17:42:10 INFO Epoch 3: [2421/10940] ---- BYOL Training Loss = 0.23278915882110596
30-01-2023 17:43:03 INFO Epoch 3: [2421/10940] ---- BYOL Validation Loss = 0.2251851111650467
30-01-2023 17:43:20 INFO Epoch 3: [2432/10940] ---- BYOL Training Loss = 0.2734350562095642
30-01-2023 17:43:39 INFO Epoch 3: [2443/10940] ---- BYOL Training Loss = 0.3056495487689972
30-01-2023 17:43:56 INFO Epoch 3: [2454/10940] ---- BYOL Training Loss = 0.22724536061286926
30-01-2023 17:44:14 INFO Epoch 3: [2465/10940] ---- BYOL Training Loss = 0.2504733204841614
30-01-2023 17:45:07 INFO Epoch 3: [2465/10940] ---- BYOL Validation Loss = 0.2244553565979004
30-01-2023 17:45:24 INFO Epoch 3: [2476/10940] ---- BYOL Training Loss = 0.36331209540367126
30-01-2023 17:45:42 INFO Epoch 3: [2487/10940] ---- BYOL Training Loss = 0.3262423574924469
30-01-2023 17:45:59 INFO Epoch 3: [2498/10940] ---- BYOL Training Loss = 0.30089277029037476
30-01-2023 17:46:17 INFO Epoch 3: [2509/10940] ---- BYOL Training Loss = 0.29107651114463806
30-01-2023 17:47:10 INFO Epoch 3: [2509/10940] ---- BYOL Validation Loss = 0.22878532111644745
30-01-2023 17:47:27 INFO Epoch 3: [2520/10940] ---- BYOL Training Loss = 0.24367959797382355
30-01-2023 17:47:45 INFO Epoch 3: [2531/10940] ---- BYOL Training Loss = 0.2887803018093109
30-01-2023 17:48:03 INFO Epoch 3: [2542/10940] ---- BYOL Training Loss = 0.3310192823410034
30-01-2023 17:48:21 INFO Epoch 3: [2553/10940] ---- BYOL Training Loss = 0.27654626965522766
30-01-2023 17:49:14 INFO Epoch 3: [2553/10940] ---- BYOL Validation Loss = 0.23073133826255798
30-01-2023 17:49:31 INFO Epoch 3: [2564/10940] ---- BYOL Training Loss = 0.24161815643310547
30-01-2023 17:49:49 INFO Epoch 3: [2575/10940] ---- BYOL Training Loss = 0.244771808385849
30-01-2023 17:50:07 INFO Epoch 3: [2586/10940] ---- BYOL Training Loss = 0.2758525013923645
30-01-2023 17:50:24 INFO Epoch 3: [2597/10940] ---- BYOL Training Loss = 0.2838582992553711
30-01-2023 17:51:17 INFO Epoch 3: [2597/10940] ---- BYOL Validation Loss = 0.24695660173892975
30-01-2023 17:51:34 INFO Epoch 3: [2608/10940] ---- BYOL Training Loss = 0.23927350342273712
30-01-2023 17:51:52 INFO Epoch 3: [2619/10940] ---- BYOL Training Loss = 0.2344129979610443
30-01-2023 17:52:10 INFO Epoch 3: [2630/10940] ---- BYOL Training Loss = 0.28529343008995056
30-01-2023 17:52:28 INFO Epoch 3: [2641/10940] ---- BYOL Training Loss = 0.26206260919570923
30-01-2023 17:53:20 INFO Epoch 3: [2641/10940] ---- BYOL Validation Loss = 0.26405754685401917
30-01-2023 17:53:38 INFO Epoch 3: [2652/10940] ---- BYOL Training Loss = 0.31804177165031433
30-01-2023 17:53:56 INFO Epoch 3: [2663/10940] ---- BYOL Training Loss = 0.3033314049243927
30-01-2023 17:54:14 INFO Epoch 3: [2674/10940] ---- BYOL Training Loss = 0.24891063570976257
30-01-2023 17:54:31 INFO Epoch 3: [2685/10940] ---- BYOL Training Loss = 0.263569176197052
30-01-2023 17:55:24 INFO Epoch 3: [2685/10940] ---- BYOL Validation Loss = 0.21969987452030182
30-01-2023 17:55:41 INFO Epoch 3: [2696/10940] ---- BYOL Training Loss = 0.2694206237792969
30-01-2023 17:55:59 INFO Epoch 3: [2707/10940] ---- BYOL Training Loss = 0.25694039463996887
30-01-2023 17:56:17 INFO Epoch 3: [2718/10940] ---- BYOL Training Loss = 0.21573717892169952
30-01-2023 17:56:35 INFO Epoch 3: [2729/10940] ---- BYOL Training Loss = 0.2143309861421585
30-01-2023 17:57:27 INFO Epoch 3: [2729/10940] ---- BYOL Validation Loss = 0.20831404626369476
30-01-2023 17:57:45 INFO Epoch 3: [2740/10940] ---- BYOL Training Loss = 0.2053072452545166
30-01-2023 17:58:03 INFO Epoch 3: [2751/10940] ---- BYOL Training Loss = 0.2601040005683899
30-01-2023 17:58:21 INFO Epoch 3: [2762/10940] ---- BYOL Training Loss = 0.2982688546180725
30-01-2023 17:58:39 INFO Epoch 3: [2773/10940] ---- BYOL Training Loss = 0.2658105492591858
30-01-2023 17:59:31 INFO Epoch 3: [2773/10940] ---- BYOL Validation Loss = 0.238861545920372
30-01-2023 17:59:49 INFO Epoch 3: [2784/10940] ---- BYOL Training Loss = 0.2630925178527832
30-01-2023 18:00:06 INFO Epoch 3: [2795/10940] ---- BYOL Training Loss = 0.25099626183509827
30-01-2023 18:00:24 INFO Epoch 3: [2806/10940] ---- BYOL Training Loss = 0.253030002117157
30-01-2023 18:00:42 INFO Epoch 3: [2817/10940] ---- BYOL Training Loss = 0.22258174419403076
30-01-2023 18:01:35 INFO Epoch 3: [2817/10940] ---- BYOL Validation Loss = 0.24213598668575287
30-01-2023 18:01:52 INFO Epoch 3: [2828/10940] ---- BYOL Training Loss = 0.23150916397571564
30-01-2023 18:02:10 INFO Epoch 3: [2839/10940] ---- BYOL Training Loss = 0.26839402318000793
30-01-2023 18:02:28 INFO Epoch 3: [2850/10940] ---- BYOL Training Loss = 0.305450975894928
30-01-2023 18:02:46 INFO Epoch 3: [2861/10940] ---- BYOL Training Loss = 0.25179484486579895
30-01-2023 18:03:38 INFO Epoch 3: [2861/10940] ---- BYOL Validation Loss = 0.24251532554626465
30-01-2023 18:03:56 INFO Epoch 3: [2872/10940] ---- BYOL Training Loss = 0.2422543317079544
30-01-2023 18:04:13 INFO Epoch 3: [2883/10940] ---- BYOL Training Loss = 0.24415965378284454
30-01-2023 18:04:31 INFO Epoch 3: [2894/10940] ---- BYOL Training Loss = 0.3101363182067871
30-01-2023 18:04:49 INFO Epoch 3: [2905/10940] ---- BYOL Training Loss = 0.3255150318145752
30-01-2023 18:05:42 INFO Epoch 3: [2905/10940] ---- BYOL Validation Loss = 0.22252511978149414
30-01-2023 18:05:59 INFO Epoch 3: [2916/10940] ---- BYOL Training Loss = 0.33381375670433044
30-01-2023 18:06:17 INFO Epoch 3: [2927/10940] ---- BYOL Training Loss = 0.3000796437263489
30-01-2023 18:06:35 INFO Epoch 3: [2938/10940] ---- BYOL Training Loss = 0.2510852813720703
30-01-2023 18:06:53 INFO Epoch 3: [2949/10940] ---- BYOL Training Loss = 0.3021068572998047
30-01-2023 18:07:46 INFO Epoch 3: [2949/10940] ---- BYOL Validation Loss = 0.2384222000837326
30-01-2023 18:08:03 INFO Epoch 3: [2960/10940] ---- BYOL Training Loss = 0.3174884617328644
30-01-2023 18:08:21 INFO Epoch 3: [2971/10940] ---- BYOL Training Loss = 0.3323383331298828
30-01-2023 18:08:39 INFO Epoch 3: [2982/10940] ---- BYOL Training Loss = 0.3063681721687317
30-01-2023 18:08:57 INFO Epoch 3: [2993/10940] ---- BYOL Training Loss = 0.2696745991706848
30-01-2023 18:09:50 INFO Epoch 3: [2993/10940] ---- BYOL Validation Loss = 0.22511111199855804
30-01-2023 18:10:07 INFO Epoch 3: [3004/10940] ---- BYOL Training Loss = 0.20273573696613312
30-01-2023 18:10:25 INFO Epoch 3: [3015/10940] ---- BYOL Training Loss = 0.23113012313842773
30-01-2023 18:10:42 INFO Epoch 3: [3026/10940] ---- BYOL Training Loss = 0.2576087415218353
30-01-2023 18:11:00 INFO Epoch 3: [3037/10940] ---- BYOL Training Loss = 0.2597705125808716
30-01-2023 18:11:53 INFO Epoch 3: [3037/10940] ---- BYOL Validation Loss = 0.23191262781620026
30-01-2023 18:12:11 INFO Epoch 3: [3048/10940] ---- BYOL Training Loss = 0.3012723922729492
30-01-2023 18:12:28 INFO Epoch 3: [3059/10940] ---- BYOL Training Loss = 0.3003228008747101
30-01-2023 18:12:46 INFO Epoch 3: [3070/10940] ---- BYOL Training Loss = 0.24722440540790558
30-01-2023 18:13:04 INFO Epoch 3: [3081/10940] ---- BYOL Training Loss = 0.27476006746292114
30-01-2023 18:13:57 INFO Epoch 3: [3081/10940] ---- BYOL Validation Loss = 0.23459164798259735
30-01-2023 18:14:14 INFO Epoch 3: [3092/10940] ---- BYOL Training Loss = 0.295414000749588
30-01-2023 18:14:32 INFO Epoch 3: [3103/10940] ---- BYOL Training Loss = 0.309073805809021
30-01-2023 18:14:50 INFO Epoch 3: [3114/10940] ---- BYOL Training Loss = 0.3224889039993286
30-01-2023 18:15:08 INFO Epoch 3: [3125/10940] ---- BYOL Training Loss = 0.304056853055954
30-01-2023 18:16:01 INFO Epoch 3: [3125/10940] ---- BYOL Validation Loss = 0.25315818190574646
30-01-2023 18:16:18 INFO Epoch 3: [3136/10940] ---- BYOL Training Loss = 0.26646536588668823
30-01-2023 18:16:36 INFO Epoch 3: [3147/10940] ---- BYOL Training Loss = 0.24818304181098938
30-01-2023 18:16:54 INFO Epoch 3: [3158/10940] ---- BYOL Training Loss = 0.2658153772354126
30-01-2023 18:17:11 INFO Epoch 3: [3169/10940] ---- BYOL Training Loss = 0.26309701800346375
30-01-2023 18:18:04 INFO Epoch 3: [3169/10940] ---- BYOL Validation Loss = 0.2355094999074936
30-01-2023 18:18:21 INFO Epoch 3: [3180/10940] ---- BYOL Training Loss = 0.2953623831272125
30-01-2023 18:18:39 INFO Epoch 3: [3191/10940] ---- BYOL Training Loss = 0.30749863386154175
30-01-2023 18:18:57 INFO Epoch 3: [3202/10940] ---- BYOL Training Loss = 0.27689117193222046
30-01-2023 18:19:15 INFO Epoch 3: [3213/10940] ---- BYOL Training Loss = 0.23166577517986298
30-01-2023 18:20:08 INFO Epoch 3: [3213/10940] ---- BYOL Validation Loss = 0.22637949883937836
30-01-2023 18:20:25 INFO Epoch 3: [3224/10940] ---- BYOL Training Loss = 0.21710658073425293
30-01-2023 18:20:43 INFO Epoch 3: [3235/10940] ---- BYOL Training Loss = 0.2588176131248474
30-01-2023 18:21:01 INFO Epoch 3: [3246/10940] ---- BYOL Training Loss = 0.287771075963974
30-01-2023 18:21:19 INFO Epoch 3: [3257/10940] ---- BYOL Training Loss = 0.295856237411499
30-01-2023 18:22:11 INFO Epoch 3: [3257/10940] ---- BYOL Validation Loss = 0.2362278550863266
30-01-2023 18:22:29 INFO Epoch 3: [3268/10940] ---- BYOL Training Loss = 0.25947198271751404
30-01-2023 18:22:47 INFO Epoch 3: [3279/10940] ---- BYOL Training Loss = 0.3207876980304718
30-01-2023 18:23:05 INFO Epoch 3: [3290/10940] ---- BYOL Training Loss = 0.32829636335372925
30-01-2023 18:23:23 INFO Epoch 3: [3301/10940] ---- BYOL Training Loss = 0.29566654562950134
30-01-2023 18:24:16 INFO Epoch 3: [3301/10940] ---- BYOL Validation Loss = 0.21970678865909576
30-01-2023 18:24:33 INFO Epoch 3: [3312/10940] ---- BYOL Training Loss = 0.2339351624250412
30-01-2023 18:24:51 INFO Epoch 3: [3323/10940] ---- BYOL Training Loss = 0.23486247658729553
30-01-2023 18:25:09 INFO Epoch 3: [3334/10940] ---- BYOL Training Loss = 0.2648696005344391
30-01-2023 18:25:27 INFO Epoch 3: [3345/10940] ---- BYOL Training Loss = 0.25134262442588806
30-01-2023 18:26:19 INFO Epoch 3: [3345/10940] ---- BYOL Validation Loss = 0.20825256407260895
30-01-2023 18:26:37 INFO Epoch 3: [3356/10940] ---- BYOL Training Loss = 0.22958317399024963
30-01-2023 18:26:55 INFO Epoch 3: [3367/10940] ---- BYOL Training Loss = 0.25876298546791077
30-01-2023 18:27:13 INFO Epoch 3: [3378/10940] ---- BYOL Training Loss = 0.2501964569091797
30-01-2023 18:27:30 INFO Epoch 3: [3389/10940] ---- BYOL Training Loss = 0.2078300267457962
30-01-2023 18:28:23 INFO Epoch 3: [3389/10940] ---- BYOL Validation Loss = 0.20295597612857819
30-01-2023 18:28:40 INFO Epoch 3: [3400/10940] ---- BYOL Training Loss = 0.2386082112789154
30-01-2023 18:28:58 INFO Epoch 3: [3411/10940] ---- BYOL Training Loss = 0.21854999661445618
30-01-2023 18:29:16 INFO Epoch 3: [3422/10940] ---- BYOL Training Loss = 0.27698129415512085
30-01-2023 18:29:34 INFO Epoch 3: [3433/10940] ---- BYOL Training Loss = 0.2848210036754608
30-01-2023 18:30:27 INFO Epoch 3: [3433/10940] ---- BYOL Validation Loss = 0.22709514200687408
30-01-2023 18:30:45 INFO Epoch 3: [3444/10940] ---- BYOL Training Loss = 0.26967886090278625
30-01-2023 18:31:02 INFO Epoch 3: [3455/10940] ---- BYOL Training Loss = 0.2935849726200104
30-01-2023 18:31:20 INFO Epoch 3: [3466/10940] ---- BYOL Training Loss = 0.28140872716903687
30-01-2023 18:31:38 INFO Epoch 3: [3477/10940] ---- BYOL Training Loss = 0.23225048184394836
30-01-2023 18:32:31 INFO Epoch 3: [3477/10940] ---- BYOL Validation Loss = 0.2088577300310135
30-01-2023 18:32:48 INFO Epoch 3: [3488/10940] ---- BYOL Training Loss = 0.2567683458328247
30-01-2023 18:33:06 INFO Epoch 3: [3499/10940] ---- BYOL Training Loss = 0.2374461591243744
30-01-2023 18:33:24 INFO Epoch 3: [3510/10940] ---- BYOL Training Loss = 0.2135176956653595
30-01-2023 18:33:42 INFO Epoch 3: [3521/10940] ---- BYOL Training Loss = 0.22728340327739716
30-01-2023 18:34:35 INFO Epoch 3: [3521/10940] ---- BYOL Validation Loss = 0.21739578247070312
30-01-2023 18:34:52 INFO Epoch 3: [3532/10940] ---- BYOL Training Loss = 0.26662319898605347
30-01-2023 18:35:10 INFO Epoch 3: [3543/10940] ---- BYOL Training Loss = 0.22794394195079803
30-01-2023 18:35:28 INFO Epoch 3: [3554/10940] ---- BYOL Training Loss = 0.21700075268745422
30-01-2023 18:35:45 INFO Epoch 3: [3565/10940] ---- BYOL Training Loss = 0.23699751496315002
30-01-2023 18:36:38 INFO Epoch 3: [3565/10940] ---- BYOL Validation Loss = 0.18994219601154327
30-01-2023 18:36:56 INFO Epoch 3: [3576/10940] ---- BYOL Training Loss = 0.26019087433815
30-01-2023 18:37:13 INFO Epoch 3: [3587/10940] ---- BYOL Training Loss = 0.26629215478897095
30-01-2023 18:37:32 INFO Epoch 3: [3598/10940] ---- BYOL Training Loss = 0.2417539805173874
30-01-2023 18:37:49 INFO Epoch 3: [3609/10940] ---- BYOL Training Loss = 0.21034464240074158
30-01-2023 18:38:42 INFO Epoch 3: [3609/10940] ---- BYOL Validation Loss = 0.19958822429180145
30-01-2023 18:38:59 INFO Epoch 3: [3620/10940] ---- BYOL Training Loss = 0.2578662037849426
30-01-2023 18:39:17 INFO Epoch 3: [3631/10940] ---- BYOL Training Loss = 0.2654063403606415
30-01-2023 18:39:35 INFO Epoch 3: [3642/10940] ---- BYOL Training Loss = 0.3008326590061188
30-01-2023 18:39:53 INFO Epoch 3: [3653/10940] ---- BYOL Training Loss = 0.2653176188468933
30-01-2023 18:40:46 INFO Epoch 3: [3653/10940] ---- BYOL Validation Loss = 0.2177221029996872
30-01-2023 18:41:03 INFO Epoch 3: [3664/10940] ---- BYOL Training Loss = 0.24293069541454315
30-01-2023 18:41:21 INFO Epoch 3: [3675/10940] ---- BYOL Training Loss = 0.240265890955925
30-01-2023 18:41:39 INFO Epoch 3: [3686/10940] ---- BYOL Training Loss = 0.22068271040916443
30-01-2023 18:41:57 INFO Epoch 3: [3697/10940] ---- BYOL Training Loss = 0.2487742155790329
30-01-2023 18:42:50 INFO Epoch 3: [3697/10940] ---- BYOL Validation Loss = 0.23439863324165344
30-01-2023 18:43:07 INFO Epoch 3: [3708/10940] ---- BYOL Training Loss = 0.28686121106147766
30-01-2023 18:43:25 INFO Epoch 3: [3719/10940] ---- BYOL Training Loss = 0.2674767076969147
30-01-2023 18:43:43 INFO Epoch 3: [3730/10940] ---- BYOL Training Loss = 0.2499617636203766
30-01-2023 18:44:01 INFO Epoch 3: [3741/10940] ---- BYOL Training Loss = 0.2699463963508606
30-01-2023 18:44:54 INFO Epoch 3: [3741/10940] ---- BYOL Validation Loss = 0.22638344764709473
30-01-2023 18:45:11 INFO Epoch 3: [3752/10940] ---- BYOL Training Loss = 0.25269609689712524
30-01-2023 18:45:29 INFO Epoch 3: [3763/10940] ---- BYOL Training Loss = 0.2781136631965637
30-01-2023 18:45:47 INFO Epoch 3: [3774/10940] ---- BYOL Training Loss = 0.27928438782691956
30-01-2023 18:46:05 INFO Epoch 3: [3785/10940] ---- BYOL Training Loss = 0.31585556268692017
30-01-2023 18:46:58 INFO Epoch 3: [3785/10940] ---- BYOL Validation Loss = 0.1948089301586151
30-01-2023 18:47:15 INFO Epoch 3: [3796/10940] ---- BYOL Training Loss = 0.31426459550857544
30-01-2023 18:47:33 INFO Epoch 3: [3807/10940] ---- BYOL Training Loss = 0.2874893546104431
30-01-2023 18:47:51 INFO Epoch 3: [3818/10940] ---- BYOL Training Loss = 0.27524664998054504
30-01-2023 18:48:09 INFO Epoch 3: [3829/10940] ---- BYOL Training Loss = 0.25365203619003296
30-01-2023 18:49:02 INFO Epoch 3: [3829/10940] ---- BYOL Validation Loss = 0.22998975217342377
30-01-2023 18:49:19 INFO Epoch 3: [3840/10940] ---- BYOL Training Loss = 0.25439590215682983
30-01-2023 18:49:37 INFO Epoch 3: [3851/10940] ---- BYOL Training Loss = 0.2550477981567383
30-01-2023 18:49:55 INFO Epoch 3: [3862/10940] ---- BYOL Training Loss = 0.2639313340187073
30-01-2023 18:50:13 INFO Epoch 3: [3873/10940] ---- BYOL Training Loss = 0.28359609842300415
30-01-2023 18:51:05 INFO Epoch 3: [3873/10940] ---- BYOL Validation Loss = 0.21203792095184326
30-01-2023 18:51:23 INFO Epoch 3: [3884/10940] ---- BYOL Training Loss = 0.2699924409389496
30-01-2023 18:51:41 INFO Epoch 3: [3895/10940] ---- BYOL Training Loss = 0.24304863810539246
30-01-2023 18:51:59 INFO Epoch 3: [3906/10940] ---- BYOL Training Loss = 0.23279953002929688
30-01-2023 18:52:17 INFO Epoch 3: [3917/10940] ---- BYOL Training Loss = 0.25418758392333984
30-01-2023 18:53:09 INFO Epoch 3: [3917/10940] ---- BYOL Validation Loss = 0.19938278198242188
30-01-2023 18:53:27 INFO Epoch 3: [3928/10940] ---- BYOL Training Loss = 0.27504605054855347
30-01-2023 18:53:45 INFO Epoch 3: [3939/10940] ---- BYOL Training Loss = 0.28007251024246216
30-01-2023 18:54:03 INFO Epoch 3: [3950/10940] ---- BYOL Training Loss = 0.2823076844215393
30-01-2023 18:54:21 INFO Epoch 3: [3961/10940] ---- BYOL Training Loss = 0.23800793290138245
30-01-2023 18:55:13 INFO Epoch 3: [3961/10940] ---- BYOL Validation Loss = 0.21548867225646973
30-01-2023 18:55:31 INFO Epoch 3: [3972/10940] ---- BYOL Training Loss = 0.2789982259273529
30-01-2023 18:55:49 INFO Epoch 3: [3983/10940] ---- BYOL Training Loss = 0.30532294511795044
30-01-2023 18:56:07 INFO Epoch 3: [3994/10940] ---- BYOL Training Loss = 0.2637799084186554
30-01-2023 18:56:24 INFO Epoch 3: [4005/10940] ---- BYOL Training Loss = 0.25702109932899475
30-01-2023 18:57:17 INFO Epoch 3: [4005/10940] ---- BYOL Validation Loss = 0.20847536623477936
30-01-2023 18:57:35 INFO Epoch 3: [4016/10940] ---- BYOL Training Loss = 0.21623149514198303
30-01-2023 18:57:53 INFO Epoch 3: [4027/10940] ---- BYOL Training Loss = 0.2027522772550583
30-01-2023 18:58:11 INFO Epoch 3: [4038/10940] ---- BYOL Training Loss = 0.22877967357635498
30-01-2023 18:58:29 INFO Epoch 3: [4049/10940] ---- BYOL Training Loss = 0.2523750960826874
30-01-2023 18:59:21 INFO Epoch 3: [4049/10940] ---- BYOL Validation Loss = 0.2071143537759781
30-01-2023 18:59:39 INFO Epoch 3: [4060/10940] ---- BYOL Training Loss = 0.25388938188552856
30-01-2023 18:59:57 INFO Epoch 3: [4071/10940] ---- BYOL Training Loss = 0.2223881036043167
30-01-2023 19:00:15 INFO Epoch 3: [4082/10940] ---- BYOL Training Loss = 0.17625442147254944
30-01-2023 19:00:33 INFO Epoch 3: [4093/10940] ---- BYOL Training Loss = 0.23860368132591248
30-01-2023 19:01:26 INFO Epoch 3: [4093/10940] ---- BYOL Validation Loss = 0.201300248503685
30-01-2023 19:01:43 INFO Epoch 3: [4104/10940] ---- BYOL Training Loss = 0.2741597592830658
30-01-2023 19:02:01 INFO Epoch 3: [4115/10940] ---- BYOL Training Loss = 0.26985394954681396
30-01-2023 19:02:19 INFO Epoch 3: [4126/10940] ---- BYOL Training Loss = 0.2725042700767517
30-01-2023 19:02:37 INFO Epoch 3: [4137/10940] ---- BYOL Training Loss = 0.21554262936115265
30-01-2023 19:03:30 INFO Epoch 3: [4137/10940] ---- BYOL Validation Loss = 0.2145010083913803
30-01-2023 19:03:47 INFO Epoch 3: [4148/10940] ---- BYOL Training Loss = 0.3155703842639923
30-01-2023 19:04:06 INFO Epoch 3: [4159/10940] ---- BYOL Training Loss = 0.3289068341255188
30-01-2023 19:04:24 INFO Epoch 3: [4170/10940] ---- BYOL Training Loss = 0.25393083691596985
30-01-2023 19:04:42 INFO Epoch 3: [4181/10940] ---- BYOL Training Loss = 0.29238247871398926
30-01-2023 19:05:34 INFO Epoch 3: [4181/10940] ---- BYOL Validation Loss = 0.23346278071403503
30-01-2023 19:05:52 INFO Epoch 3: [4192/10940] ---- BYOL Training Loss = 0.2691038250923157
30-01-2023 19:06:10 INFO Epoch 3: [4203/10940] ---- BYOL Training Loss = 0.23547029495239258
30-01-2023 19:06:28 INFO Epoch 3: [4214/10940] ---- BYOL Training Loss = 0.2790602743625641
30-01-2023 19:06:46 INFO Epoch 3: [4225/10940] ---- BYOL Training Loss = 0.2766820788383484
30-01-2023 19:07:38 INFO Epoch 3: [4225/10940] ---- BYOL Validation Loss = 0.19598861038684845
30-01-2023 19:07:56 INFO Epoch 3: [4236/10940] ---- BYOL Training Loss = 0.289509117603302
30-01-2023 19:08:14 INFO Epoch 3: [4247/10940] ---- BYOL Training Loss = 0.23955583572387695
30-01-2023 19:08:32 INFO Epoch 3: [4258/10940] ---- BYOL Training Loss = 0.2355378121137619
30-01-2023 19:08:49 INFO Epoch 3: [4269/10940] ---- BYOL Training Loss = 0.2599636912345886
30-01-2023 19:09:42 INFO Epoch 3: [4269/10940] ---- BYOL Validation Loss = 0.19931040704250336
30-01-2023 19:10:00 INFO Epoch 3: [4280/10940] ---- BYOL Training Loss = 0.24740633368492126
30-01-2023 19:10:18 INFO Epoch 3: [4291/10940] ---- BYOL Training Loss = 0.22542119026184082
30-01-2023 19:10:36 INFO Epoch 3: [4302/10940] ---- BYOL Training Loss = 0.22892066836357117
30-01-2023 19:10:54 INFO Epoch 3: [4313/10940] ---- BYOL Training Loss = 0.24493324756622314
30-01-2023 19:11:46 INFO Epoch 3: [4313/10940] ---- BYOL Validation Loss = 0.21244385838508606
30-01-2023 19:12:04 INFO Epoch 3: [4324/10940] ---- BYOL Training Loss = 0.2267388552427292
30-01-2023 19:12:22 INFO Epoch 3: [4335/10940] ---- BYOL Training Loss = 0.22665958106517792
30-01-2023 19:12:40 INFO Epoch 3: [4346/10940] ---- BYOL Training Loss = 0.24766233563423157
30-01-2023 19:12:58 INFO Epoch 3: [4357/10940] ---- BYOL Training Loss = 0.3268115222454071
30-01-2023 19:13:51 INFO Epoch 3: [4357/10940] ---- BYOL Validation Loss = 0.19446274638175964
30-01-2023 19:14:08 INFO Epoch 3: [4368/10940] ---- BYOL Training Loss = 0.27398061752319336
30-01-2023 19:14:26 INFO Epoch 3: [4379/10940] ---- BYOL Training Loss = 0.21719792485237122
30-01-2023 19:14:44 INFO Epoch 3: [4390/10940] ---- BYOL Training Loss = 0.22849509119987488
30-01-2023 19:15:03 INFO Epoch 3: [4401/10940] ---- BYOL Training Loss = 0.2332983911037445
30-01-2023 19:15:55 INFO Epoch 3: [4401/10940] ---- BYOL Validation Loss = 0.22346341609954834
30-01-2023 19:16:13 INFO Epoch 3: [4412/10940] ---- BYOL Training Loss = 0.27027541399002075
30-01-2023 19:16:31 INFO Epoch 3: [4423/10940] ---- BYOL Training Loss = 0.28348881006240845
30-01-2023 19:16:49 INFO Epoch 3: [4434/10940] ---- BYOL Training Loss = 0.22084924578666687
30-01-2023 19:17:07 INFO Epoch 3: [4445/10940] ---- BYOL Training Loss = 0.22405791282653809
30-01-2023 19:17:59 INFO Epoch 3: [4445/10940] ---- BYOL Validation Loss = 0.2046242505311966
30-01-2023 19:18:17 INFO Epoch 3: [4456/10940] ---- BYOL Training Loss = 0.25489774346351624
30-01-2023 19:18:35 INFO Epoch 3: [4467/10940] ---- BYOL Training Loss = 0.24831469357013702
30-01-2023 19:18:53 INFO Epoch 3: [4478/10940] ---- BYOL Training Loss = 0.25011083483695984
30-01-2023 19:19:11 INFO Epoch 3: [4489/10940] ---- BYOL Training Loss = 0.25311583280563354
30-01-2023 19:20:04 INFO Epoch 3: [4489/10940] ---- BYOL Validation Loss = 0.19422413408756256
30-01-2023 19:20:21 INFO Epoch 3: [4500/10940] ---- BYOL Training Loss = 0.23937788605690002
30-01-2023 19:20:39 INFO Epoch 3: [4511/10940] ---- BYOL Training Loss = 0.2543500065803528
30-01-2023 19:20:58 INFO Epoch 3: [4522/10940] ---- BYOL Training Loss = 0.294096976518631
30-01-2023 19:21:16 INFO Epoch 3: [4533/10940] ---- BYOL Training Loss = 0.30373165011405945
30-01-2023 19:22:08 INFO Epoch 3: [4533/10940] ---- BYOL Validation Loss = 0.22914041578769684
30-01-2023 19:22:26 INFO Epoch 3: [4544/10940] ---- BYOL Training Loss = 0.3148358464241028
30-01-2023 19:22:44 INFO Epoch 3: [4555/10940] ---- BYOL Training Loss = 0.29614824056625366
30-01-2023 19:23:02 INFO Epoch 3: [4566/10940] ---- BYOL Training Loss = 0.24109062552452087
30-01-2023 19:23:20 INFO Epoch 3: [4577/10940] ---- BYOL Training Loss = 0.2683676779270172
30-01-2023 19:24:13 INFO Epoch 3: [4577/10940] ---- BYOL Validation Loss = 0.19110701978206635
30-01-2023 19:24:30 INFO Epoch 3: [4588/10940] ---- BYOL Training Loss = 0.21621175110340118
30-01-2023 19:24:48 INFO Epoch 3: [4599/10940] ---- BYOL Training Loss = 0.21227669715881348
30-01-2023 19:25:06 INFO Epoch 3: [4610/10940] ---- BYOL Training Loss = 0.28106361627578735
30-01-2023 19:25:24 INFO Epoch 3: [4621/10940] ---- BYOL Training Loss = 0.2839806377887726
30-01-2023 19:26:17 INFO Epoch 3: [4621/10940] ---- BYOL Validation Loss = 0.2029702514410019
30-01-2023 19:26:35 INFO Epoch 3: [4632/10940] ---- BYOL Training Loss = 0.2568935751914978
30-01-2023 19:26:53 INFO Epoch 3: [4643/10940] ---- BYOL Training Loss = 0.30221083760261536
30-01-2023 19:27:11 INFO Epoch 3: [4654/10940] ---- BYOL Training Loss = 0.2611318528652191
30-01-2023 19:27:29 INFO Epoch 3: [4665/10940] ---- BYOL Training Loss = 0.20992009341716766
30-01-2023 19:28:21 INFO Epoch 3: [4665/10940] ---- BYOL Validation Loss = 0.22888319194316864
30-01-2023 19:28:39 INFO Epoch 3: [4676/10940] ---- BYOL Training Loss = 0.1998884230852127
30-01-2023 19:28:57 INFO Epoch 3: [4687/10940] ---- BYOL Training Loss = 0.21555538475513458
30-01-2023 19:29:15 INFO Epoch 3: [4698/10940] ---- BYOL Training Loss = 0.27127450704574585
30-01-2023 19:29:33 INFO Epoch 3: [4709/10940] ---- BYOL Training Loss = 0.24138741195201874
30-01-2023 19:30:26 INFO Epoch 3: [4709/10940] ---- BYOL Validation Loss = 0.18686076998710632
30-01-2023 19:30:44 INFO Epoch 3: [4720/10940] ---- BYOL Training Loss = 0.28783923387527466
30-01-2023 19:31:02 INFO Epoch 3: [4731/10940] ---- BYOL Training Loss = 0.29889675974845886
30-01-2023 19:31:20 INFO Epoch 3: [4742/10940] ---- BYOL Training Loss = 0.21445953845977783
30-01-2023 19:31:38 INFO Epoch 3: [4753/10940] ---- BYOL Training Loss = 0.18893347680568695
30-01-2023 19:32:31 INFO Epoch 3: [4753/10940] ---- BYOL Validation Loss = 0.19986966252326965
30-01-2023 19:32:49 INFO Epoch 3: [4764/10940] ---- BYOL Training Loss = 0.2732388377189636
30-01-2023 19:33:07 INFO Epoch 3: [4775/10940] ---- BYOL Training Loss = 0.301925390958786
30-01-2023 19:33:25 INFO Epoch 3: [4786/10940] ---- BYOL Training Loss = 0.2217894047498703
30-01-2023 19:33:43 INFO Epoch 3: [4797/10940] ---- BYOL Training Loss = 0.28560835123062134
30-01-2023 19:34:35 INFO Epoch 3: [4797/10940] ---- BYOL Validation Loss = 0.1859758198261261
30-01-2023 19:34:53 INFO Epoch 3: [4808/10940] ---- BYOL Training Loss = 0.3717432916164398
30-01-2023 19:35:11 INFO Epoch 3: [4819/10940] ---- BYOL Training Loss = 0.31861358880996704
30-01-2023 19:35:29 INFO Epoch 3: [4830/10940] ---- BYOL Training Loss = 0.28238385915756226
30-01-2023 19:35:47 INFO Epoch 3: [4841/10940] ---- BYOL Training Loss = 0.21046623587608337
30-01-2023 19:36:40 INFO Epoch 3: [4841/10940] ---- BYOL Validation Loss = 0.22087402641773224
30-01-2023 19:36:58 INFO Epoch 3: [4852/10940] ---- BYOL Training Loss = 0.19654950499534607
30-01-2023 19:37:16 INFO Epoch 3: [4863/10940] ---- BYOL Training Loss = 0.22748339176177979
30-01-2023 19:37:34 INFO Epoch 3: [4874/10940] ---- BYOL Training Loss = 0.21586930751800537
30-01-2023 19:37:52 INFO Epoch 3: [4885/10940] ---- BYOL Training Loss = 0.286111444234848
30-01-2023 19:38:45 INFO Epoch 3: [4885/10940] ---- BYOL Validation Loss = 0.1766071617603302
30-01-2023 19:39:03 INFO Epoch 3: [4896/10940] ---- BYOL Training Loss = 0.308864027261734
30-01-2023 19:39:21 INFO Epoch 3: [4907/10940] ---- BYOL Training Loss = 0.2525494694709778
30-01-2023 19:39:39 INFO Epoch 3: [4918/10940] ---- BYOL Training Loss = 0.21015565097332
30-01-2023 19:39:57 INFO Epoch 3: [4929/10940] ---- BYOL Training Loss = 0.23587465286254883
30-01-2023 19:40:50 INFO Epoch 3: [4929/10940] ---- BYOL Validation Loss = 0.19508029520511627
30-01-2023 19:41:07 INFO Epoch 3: [4940/10940] ---- BYOL Training Loss = 0.29074305295944214
30-01-2023 19:41:25 INFO Epoch 3: [4951/10940] ---- BYOL Training Loss = 0.34096524119377136
30-01-2023 19:41:44 INFO Epoch 3: [4962/10940] ---- BYOL Training Loss = 0.2998882234096527
30-01-2023 19:42:02 INFO Epoch 3: [4973/10940] ---- BYOL Training Loss = 0.2016039341688156
30-01-2023 19:42:55 INFO Epoch 3: [4973/10940] ---- BYOL Validation Loss = 0.17226918041706085
30-01-2023 19:43:12 INFO Epoch 3: [4984/10940] ---- BYOL Training Loss = 0.25817400217056274
30-01-2023 19:43:30 INFO Epoch 3: [4995/10940] ---- BYOL Training Loss = 0.24622531235218048
30-01-2023 19:43:49 INFO Epoch 3: [5006/10940] ---- BYOL Training Loss = 0.30189618468284607
30-01-2023 19:44:07 INFO Epoch 3: [5017/10940] ---- BYOL Training Loss = 0.39363572001457214
30-01-2023 19:45:00 INFO Epoch 3: [5017/10940] ---- BYOL Validation Loss = 0.22129447758197784
30-01-2023 19:45:18 INFO Epoch 3: [5028/10940] ---- BYOL Training Loss = 0.247646763920784
30-01-2023 19:45:35 INFO Epoch 3: [5039/10940] ---- BYOL Training Loss = 0.36694589257240295
30-01-2023 19:45:53 INFO Epoch 3: [5050/10940] ---- BYOL Training Loss = 0.3881945013999939
30-01-2023 19:46:12 INFO Epoch 3: [5061/10940] ---- BYOL Training Loss = 0.2647988498210907
30-01-2023 19:47:04 INFO Epoch 3: [5061/10940] ---- BYOL Validation Loss = 0.21660062670707703
30-01-2023 19:47:22 INFO Epoch 3: [5072/10940] ---- BYOL Training Loss = 0.25376659631729126
30-01-2023 19:47:40 INFO Epoch 3: [5083/10940] ---- BYOL Training Loss = 0.2915613353252411
30-01-2023 19:47:58 INFO Epoch 3: [5094/10940] ---- BYOL Training Loss = 0.2931540012359619
30-01-2023 19:48:16 INFO Epoch 3: [5105/10940] ---- BYOL Training Loss = 0.2781584858894348
30-01-2023 19:49:09 INFO Epoch 3: [5105/10940] ---- BYOL Validation Loss = 0.2251894325017929
30-01-2023 19:49:27 INFO Epoch 3: [5116/10940] ---- BYOL Training Loss = 0.30065664649009705
30-01-2023 19:49:45 INFO Epoch 3: [5127/10940] ---- BYOL Training Loss = 0.26635056734085083
30-01-2023 19:50:03 INFO Epoch 3: [5138/10940] ---- BYOL Training Loss = 0.2414918839931488
30-01-2023 19:50:21 INFO Epoch 3: [5149/10940] ---- BYOL Training Loss = 0.2255294770002365
30-01-2023 19:51:14 INFO Epoch 3: [5149/10940] ---- BYOL Validation Loss = 0.20504483580589294
30-01-2023 19:51:32 INFO Epoch 3: [5160/10940] ---- BYOL Training Loss = 0.2461164891719818
30-01-2023 19:51:50 INFO Epoch 3: [5171/10940] ---- BYOL Training Loss = 0.2245633602142334
30-01-2023 19:52:08 INFO Epoch 3: [5182/10940] ---- BYOL Training Loss = 0.20815357565879822
30-01-2023 19:52:26 INFO Epoch 3: [5193/10940] ---- BYOL Training Loss = 0.2620048224925995
30-01-2023 19:53:19 INFO Epoch 3: [5193/10940] ---- BYOL Validation Loss = 0.2239333540201187
30-01-2023 19:53:37 INFO Epoch 3: [5204/10940] ---- BYOL Training Loss = 0.2464304268360138
30-01-2023 19:53:55 INFO Epoch 3: [5215/10940] ---- BYOL Training Loss = 0.21024370193481445
30-01-2023 19:54:13 INFO Epoch 3: [5226/10940] ---- BYOL Training Loss = 0.24865896999835968
30-01-2023 19:54:31 INFO Epoch 3: [5237/10940] ---- BYOL Training Loss = 0.2888718247413635
30-01-2023 19:55:24 INFO Epoch 3: [5237/10940] ---- BYOL Validation Loss = 0.21832166612148285
30-01-2023 19:55:42 INFO Epoch 3: [5248/10940] ---- BYOL Training Loss = 0.2687212824821472
30-01-2023 19:56:00 INFO Epoch 3: [5259/10940] ---- BYOL Training Loss = 0.25991755723953247
30-01-2023 19:56:18 INFO Epoch 3: [5270/10940] ---- BYOL Training Loss = 0.26955947279930115
30-01-2023 19:56:36 INFO Epoch 3: [5281/10940] ---- BYOL Training Loss = 0.21861426532268524
30-01-2023 19:57:29 INFO Epoch 3: [5281/10940] ---- BYOL Validation Loss = 0.208094984292984
30-01-2023 19:57:47 INFO Epoch 3: [5292/10940] ---- BYOL Training Loss = 0.2334805428981781
30-01-2023 19:58:05 INFO Epoch 3: [5303/10940] ---- BYOL Training Loss = 0.23873372375965118
30-01-2023 19:58:23 INFO Epoch 3: [5314/10940] ---- BYOL Training Loss = 0.21793782711029053
30-01-2023 19:58:42 INFO Epoch 3: [5325/10940] ---- BYOL Training Loss = 0.26573628187179565
30-01-2023 19:59:34 INFO Epoch 3: [5325/10940] ---- BYOL Validation Loss = 0.20103466510772705
30-01-2023 19:59:52 INFO Epoch 3: [5336/10940] ---- BYOL Training Loss = 0.23169156908988953
30-01-2023 20:00:10 INFO Epoch 3: [5347/10940] ---- BYOL Training Loss = 0.19621995091438293
30-01-2023 20:00:28 INFO Epoch 3: [5358/10940] ---- BYOL Training Loss = 0.23327192664146423
30-01-2023 20:00:47 INFO Epoch 3: [5369/10940] ---- BYOL Training Loss = 0.26882675290107727
30-01-2023 20:01:40 INFO Epoch 3: [5369/10940] ---- BYOL Validation Loss = 0.2062196582555771
30-01-2023 20:01:57 INFO Epoch 3: [5380/10940] ---- BYOL Training Loss = 0.3137210011482239
30-01-2023 20:02:15 INFO Epoch 3: [5391/10940] ---- BYOL Training Loss = 0.32191988825798035
30-01-2023 20:02:33 INFO Epoch 3: [5402/10940] ---- BYOL Training Loss = 0.25108760595321655
30-01-2023 20:02:52 INFO Epoch 3: [5413/10940] ---- BYOL Training Loss = 0.27606001496315
30-01-2023 20:03:45 INFO Epoch 3: [5413/10940] ---- BYOL Validation Loss = 0.22757063806056976
30-01-2023 20:04:02 INFO Epoch 3: [5424/10940] ---- BYOL Training Loss = 0.29329174757003784
30-01-2023 20:04:20 INFO Epoch 3: [5435/10940] ---- BYOL Training Loss = 0.2794448137283325
30-01-2023 20:04:38 INFO Epoch 3: [5446/10940] ---- BYOL Training Loss = 0.2917502820491791
30-01-2023 20:04:56 INFO Epoch 3: [5457/10940] ---- BYOL Training Loss = 0.2709236443042755
30-01-2023 20:05:49 INFO Epoch 3: [5457/10940] ---- BYOL Validation Loss = 0.22405005991458893
30-01-2023 20:06:07 INFO Epoch 3: [5468/10940] ---- BYOL Training Loss = 0.22312621772289276
30-01-2023 20:06:25 INFO Epoch 3: [5479/10940] ---- BYOL Training Loss = 0.2299652099609375
30-01-2023 20:06:43 INFO Epoch 3: [5490/10940] ---- BYOL Training Loss = 0.19797804951667786
30-01-2023 20:07:01 INFO Epoch 3: [5501/10940] ---- BYOL Training Loss = 0.19617946445941925
30-01-2023 20:07:54 INFO Epoch 3: [5501/10940] ---- BYOL Validation Loss = 0.1926318258047104
30-01-2023 20:08:12 INFO Epoch 3: [5512/10940] ---- BYOL Training Loss = 0.2519725561141968
30-01-2023 20:08:30 INFO Epoch 3: [5523/10940] ---- BYOL Training Loss = 0.2549543082714081
30-01-2023 20:08:48 INFO Epoch 3: [5534/10940] ---- BYOL Training Loss = 0.26612478494644165
30-01-2023 20:09:06 INFO Epoch 3: [5545/10940] ---- BYOL Training Loss = 0.2378006875514984
30-01-2023 20:09:59 INFO Epoch 3: [5545/10940] ---- BYOL Validation Loss = 0.15532027184963226
30-01-2023 20:10:17 INFO Epoch 3: [5556/10940] ---- BYOL Training Loss = 0.23942196369171143
30-01-2023 20:10:35 INFO Epoch 3: [5567/10940] ---- BYOL Training Loss = 0.254129022359848
30-01-2023 20:10:53 INFO Epoch 3: [5578/10940] ---- BYOL Training Loss = 0.21885207295417786
30-01-2023 20:11:11 INFO Epoch 3: [5589/10940] ---- BYOL Training Loss = 0.26698121428489685
30-01-2023 20:12:04 INFO Epoch 3: [5589/10940] ---- BYOL Validation Loss = 0.1805477887392044
30-01-2023 20:12:22 INFO Epoch 3: [5600/10940] ---- BYOL Training Loss = 0.265507310628891
30-01-2023 20:12:40 INFO Epoch 3: [5611/10940] ---- BYOL Training Loss = 0.2355419397354126
30-01-2023 20:12:58 INFO Epoch 3: [5622/10940] ---- BYOL Training Loss = 0.23142468929290771
30-01-2023 20:13:16 INFO Epoch 3: [5633/10940] ---- BYOL Training Loss = 0.25329890847206116
30-01-2023 20:14:09 INFO Epoch 3: [5633/10940] ---- BYOL Validation Loss = 0.20209844410419464
30-01-2023 20:14:27 INFO Epoch 3: [5644/10940] ---- BYOL Training Loss = 0.1992645412683487
30-01-2023 20:14:45 INFO Epoch 3: [5655/10940] ---- BYOL Training Loss = 0.2114877700805664
30-01-2023 20:15:03 INFO Epoch 3: [5666/10940] ---- BYOL Training Loss = 0.21788816154003143
30-01-2023 20:15:21 INFO Epoch 3: [5677/10940] ---- BYOL Training Loss = 0.21053262054920197
30-01-2023 20:16:14 INFO Epoch 3: [5677/10940] ---- BYOL Validation Loss = 0.19640019536018372
30-01-2023 20:16:32 INFO Epoch 3: [5688/10940] ---- BYOL Training Loss = 0.28169238567352295
30-01-2023 20:16:50 INFO Epoch 3: [5699/10940] ---- BYOL Training Loss = 0.3000752329826355
30-01-2023 20:17:08 INFO Epoch 3: [5710/10940] ---- BYOL Training Loss = 0.2292262315750122
30-01-2023 20:17:26 INFO Epoch 3: [5721/10940] ---- BYOL Training Loss = 0.19783617556095123
30-01-2023 20:18:19 INFO Epoch 3: [5721/10940] ---- BYOL Validation Loss = 0.16450472176074982
30-01-2023 20:18:37 INFO Epoch 3: [5732/10940] ---- BYOL Training Loss = 0.3168434202671051
30-01-2023 20:18:55 INFO Epoch 3: [5743/10940] ---- BYOL Training Loss = 0.35425353050231934
30-01-2023 20:19:14 INFO Epoch 3: [5754/10940] ---- BYOL Training Loss = 0.2604930102825165
30-01-2023 20:19:32 INFO Epoch 3: [5765/10940] ---- BYOL Training Loss = 0.23161201179027557
30-01-2023 20:20:24 INFO Epoch 3: [5765/10940] ---- BYOL Validation Loss = 0.20337502658367157
30-01-2023 20:20:42 INFO Epoch 3: [5776/10940] ---- BYOL Training Loss = 0.2139699012041092
30-01-2023 20:21:00 INFO Epoch 3: [5787/10940] ---- BYOL Training Loss = 0.24495062232017517
30-01-2023 20:21:19 INFO Epoch 3: [5798/10940] ---- BYOL Training Loss = 0.22957894206047058
30-01-2023 20:21:37 INFO Epoch 3: [5809/10940] ---- BYOL Training Loss = 0.2143268585205078
30-01-2023 20:22:30 INFO Epoch 3: [5809/10940] ---- BYOL Validation Loss = 0.18185041844844818
30-01-2023 20:22:48 INFO Epoch 3: [5820/10940] ---- BYOL Training Loss = 0.22624127566814423
30-01-2023 20:23:06 INFO Epoch 3: [5831/10940] ---- BYOL Training Loss = 0.2022370547056198
30-01-2023 20:23:24 INFO Epoch 3: [5842/10940] ---- BYOL Training Loss = 0.22493323683738708
30-01-2023 20:23:42 INFO Epoch 3: [5853/10940] ---- BYOL Training Loss = 0.26714274287223816
30-01-2023 20:24:35 INFO Epoch 3: [5853/10940] ---- BYOL Validation Loss = 0.2094837874174118
30-01-2023 20:24:53 INFO Epoch 3: [5864/10940] ---- BYOL Training Loss = 0.2215408831834793
30-01-2023 20:25:11 INFO Epoch 3: [5875/10940] ---- BYOL Training Loss = 0.1918497532606125
30-01-2023 20:25:30 INFO Epoch 3: [5886/10940] ---- BYOL Training Loss = 0.2324734926223755
30-01-2023 20:25:48 INFO Epoch 3: [5897/10940] ---- BYOL Training Loss = 0.2198687344789505
30-01-2023 20:26:41 INFO Epoch 3: [5897/10940] ---- BYOL Validation Loss = 0.19713695347309113
30-01-2023 20:26:58 INFO Epoch 3: [5908/10940] ---- BYOL Training Loss = 0.2560344338417053
30-01-2023 20:27:16 INFO Epoch 3: [5919/10940] ---- BYOL Training Loss = 0.29313749074935913
30-01-2023 20:27:35 INFO Epoch 3: [5930/10940] ---- BYOL Training Loss = 0.2658475935459137
30-01-2023 20:27:53 INFO Epoch 3: [5941/10940] ---- BYOL Training Loss = 0.21794554591178894
30-01-2023 20:28:45 INFO Epoch 3: [5941/10940] ---- BYOL Validation Loss = 0.16998076438903809
30-01-2023 20:29:03 INFO Epoch 3: [5952/10940] ---- BYOL Training Loss = 0.22270572185516357
30-01-2023 20:29:22 INFO Epoch 3: [5963/10940] ---- BYOL Training Loss = 0.22490660846233368
30-01-2023 20:29:40 INFO Epoch 3: [5974/10940] ---- BYOL Training Loss = 0.3033173084259033
30-01-2023 20:29:58 INFO Epoch 3: [5985/10940] ---- BYOL Training Loss = 0.35701999068260193
30-01-2023 20:30:51 INFO Epoch 3: [5985/10940] ---- BYOL Validation Loss = 0.1907547414302826
30-01-2023 20:31:08 INFO Epoch 3: [5996/10940] ---- BYOL Training Loss = 0.24586069583892822
30-01-2023 20:31:26 INFO Epoch 3: [6007/10940] ---- BYOL Training Loss = 0.2617398202419281
30-01-2023 20:31:45 INFO Epoch 3: [6018/10940] ---- BYOL Training Loss = 0.2542721927165985
30-01-2023 20:32:03 INFO Epoch 3: [6029/10940] ---- BYOL Training Loss = 0.2377682477235794
30-01-2023 20:32:56 INFO Epoch 3: [6029/10940] ---- BYOL Validation Loss = 0.1913963258266449
30-01-2023 20:33:13 INFO Epoch 3: [6040/10940] ---- BYOL Training Loss = 0.21169932186603546
30-01-2023 20:33:32 INFO Epoch 3: [6051/10940] ---- BYOL Training Loss = 0.188152015209198
30-01-2023 20:33:50 INFO Epoch 3: [6062/10940] ---- BYOL Training Loss = 0.20772047340869904
30-01-2023 20:34:08 INFO Epoch 3: [6073/10940] ---- BYOL Training Loss = 0.30138352513313293
30-01-2023 20:35:01 INFO Epoch 3: [6073/10940] ---- BYOL Validation Loss = 0.1777779906988144
30-01-2023 20:35:19 INFO Epoch 3: [6084/10940] ---- BYOL Training Loss = 0.2770776152610779
30-01-2023 20:35:37 INFO Epoch 3: [6095/10940] ---- BYOL Training Loss = 0.21245166659355164
30-01-2023 20:35:55 INFO Epoch 3: [6106/10940] ---- BYOL Training Loss = 0.2376326024532318
30-01-2023 20:36:14 INFO Epoch 3: [6117/10940] ---- BYOL Training Loss = 0.23468175530433655
30-01-2023 20:37:06 INFO Epoch 3: [6117/10940] ---- BYOL Validation Loss = 0.20394372940063477
30-01-2023 20:37:24 INFO Epoch 3: [6128/10940] ---- BYOL Training Loss = 0.19059118628501892
30-01-2023 20:37:43 INFO Epoch 3: [6139/10940] ---- BYOL Training Loss = 0.24318483471870422
30-01-2023 20:38:01 INFO Epoch 3: [6150/10940] ---- BYOL Training Loss = 0.30514097213745117
30-01-2023 20:38:19 INFO Epoch 3: [6161/10940] ---- BYOL Training Loss = 0.2536064386367798
30-01-2023 20:39:12 INFO Epoch 3: [6161/10940] ---- BYOL Validation Loss = 0.20236735045909882
30-01-2023 20:39:30 INFO Epoch 3: [6172/10940] ---- BYOL Training Loss = 0.2546486258506775
30-01-2023 20:39:48 INFO Epoch 3: [6183/10940] ---- BYOL Training Loss = 0.2069908082485199
30-01-2023 20:40:06 INFO Epoch 3: [6194/10940] ---- BYOL Training Loss = 0.24368903040885925
30-01-2023 20:40:25 INFO Epoch 3: [6205/10940] ---- BYOL Training Loss = 0.29696470499038696
30-01-2023 20:41:17 INFO Epoch 3: [6205/10940] ---- BYOL Validation Loss = 0.19870230555534363
30-01-2023 20:41:35 INFO Epoch 3: [6216/10940] ---- BYOL Training Loss = 0.24080471694469452
30-01-2023 20:41:54 INFO Epoch 3: [6227/10940] ---- BYOL Training Loss = 0.21520181000232697
30-01-2023 20:42:12 INFO Epoch 3: [6238/10940] ---- BYOL Training Loss = 0.22799360752105713
30-01-2023 20:42:30 INFO Epoch 3: [6249/10940] ---- BYOL Training Loss = 0.23655405640602112
30-01-2023 20:43:23 INFO Epoch 3: [6249/10940] ---- BYOL Validation Loss = 0.18619808554649353
30-01-2023 20:43:41 INFO Epoch 3: [6260/10940] ---- BYOL Training Loss = 0.25008898973464966
30-01-2023 20:43:59 INFO Epoch 3: [6271/10940] ---- BYOL Training Loss = 0.2080705612897873
30-01-2023 20:44:18 INFO Epoch 3: [6282/10940] ---- BYOL Training Loss = 0.1931600272655487
30-01-2023 20:44:36 INFO Epoch 3: [6293/10940] ---- BYOL Training Loss = 0.18736210465431213
30-01-2023 20:45:29 INFO Epoch 3: [6293/10940] ---- BYOL Validation Loss = 0.1768319308757782
30-01-2023 20:45:46 INFO Epoch 3: [6304/10940] ---- BYOL Training Loss = 0.20316287875175476
30-01-2023 20:46:05 INFO Epoch 3: [6315/10940] ---- BYOL Training Loss = 0.22789505124092102
30-01-2023 20:46:23 INFO Epoch 3: [6326/10940] ---- BYOL Training Loss = 0.21928071975708008
30-01-2023 20:46:41 INFO Epoch 3: [6337/10940] ---- BYOL Training Loss = 0.221584290266037
30-01-2023 20:47:34 INFO Epoch 3: [6337/10940] ---- BYOL Validation Loss = 0.1624293029308319
30-01-2023 20:47:52 INFO Epoch 3: [6348/10940] ---- BYOL Training Loss = 0.22610636055469513
30-01-2023 20:48:10 INFO Epoch 3: [6359/10940] ---- BYOL Training Loss = 0.26875269412994385
30-01-2023 20:48:28 INFO Epoch 3: [6370/10940] ---- BYOL Training Loss = 0.2240089625120163
30-01-2023 20:48:46 INFO Epoch 3: [6381/10940] ---- BYOL Training Loss = 0.27825334668159485
30-01-2023 20:49:39 INFO Epoch 3: [6381/10940] ---- BYOL Validation Loss = 0.12932749092578888
30-01-2023 20:49:57 INFO Epoch 3: [6392/10940] ---- BYOL Training Loss = 0.24919739365577698
30-01-2023 20:50:16 INFO Epoch 3: [6403/10940] ---- BYOL Training Loss = 0.20494413375854492
30-01-2023 20:50:34 INFO Epoch 3: [6414/10940] ---- BYOL Training Loss = 0.22092023491859436
30-01-2023 20:50:52 INFO Epoch 3: [6425/10940] ---- BYOL Training Loss = 0.22456276416778564
30-01-2023 20:51:45 INFO Epoch 3: [6425/10940] ---- BYOL Validation Loss = 0.1817934513092041
30-01-2023 20:52:03 INFO Epoch 3: [6436/10940] ---- BYOL Training Loss = 0.22403483092784882
30-01-2023 20:52:21 INFO Epoch 3: [6447/10940] ---- BYOL Training Loss = 0.20705285668373108
30-01-2023 20:52:39 INFO Epoch 3: [6458/10940] ---- BYOL Training Loss = 0.21089179813861847
30-01-2023 20:52:58 INFO Epoch 3: [6469/10940] ---- BYOL Training Loss = 0.18026430904865265
30-01-2023 20:53:51 INFO Epoch 3: [6469/10940] ---- BYOL Validation Loss = 0.14757998287677765
30-01-2023 20:54:08 INFO Epoch 3: [6480/10940] ---- BYOL Training Loss = 0.18528446555137634
30-01-2023 20:54:27 INFO Epoch 3: [6491/10940] ---- BYOL Training Loss = 0.2037406861782074
30-01-2023 20:54:45 INFO Epoch 3: [6502/10940] ---- BYOL Training Loss = 0.2262643575668335
30-01-2023 20:55:03 INFO Epoch 3: [6513/10940] ---- BYOL Training Loss = 0.2516271471977234
30-01-2023 20:55:56 INFO Epoch 3: [6513/10940] ---- BYOL Validation Loss = 0.1673811972141266
30-01-2023 20:56:14 INFO Epoch 3: [6524/10940] ---- BYOL Training Loss = 0.24201372265815735
30-01-2023 20:56:32 INFO Epoch 3: [6535/10940] ---- BYOL Training Loss = 0.23994629085063934
30-01-2023 20:56:51 INFO Epoch 3: [6546/10940] ---- BYOL Training Loss = 0.24951021373271942
30-01-2023 20:57:09 INFO Epoch 3: [6557/10940] ---- BYOL Training Loss = 0.25253206491470337
30-01-2023 20:58:02 INFO Epoch 3: [6557/10940] ---- BYOL Validation Loss = 0.19468212127685547
30-01-2023 20:58:20 INFO Epoch 3: [6568/10940] ---- BYOL Training Loss = 0.23242969810962677
30-01-2023 20:58:38 INFO Epoch 3: [6579/10940] ---- BYOL Training Loss = 0.16614475846290588
30-01-2023 20:58:57 INFO Epoch 3: [6590/10940] ---- BYOL Training Loss = 0.16091379523277283
30-01-2023 20:59:15 INFO Epoch 3: [6601/10940] ---- BYOL Training Loss = 0.1960819512605667
30-01-2023 21:00:08 INFO Epoch 3: [6601/10940] ---- BYOL Validation Loss = 0.20662382245063782
30-01-2023 21:00:26 INFO Epoch 3: [6612/10940] ---- BYOL Training Loss = 0.2655557096004486
30-01-2023 21:00:44 INFO Epoch 3: [6623/10940] ---- BYOL Training Loss = 0.24688026309013367
30-01-2023 21:01:02 INFO Epoch 3: [6634/10940] ---- BYOL Training Loss = 0.18167930841445923
30-01-2023 21:01:20 INFO Epoch 3: [6645/10940] ---- BYOL Training Loss = 0.24303898215293884
30-01-2023 21:02:13 INFO Epoch 3: [6645/10940] ---- BYOL Validation Loss = 0.17412607371807098
30-01-2023 21:02:31 INFO Epoch 3: [6656/10940] ---- BYOL Training Loss = 0.21552565693855286
30-01-2023 21:02:50 INFO Epoch 3: [6667/10940] ---- BYOL Training Loss = 0.20465457439422607
30-01-2023 21:03:08 INFO Epoch 3: [6678/10940] ---- BYOL Training Loss = 0.21898145973682404
30-01-2023 21:03:26 INFO Epoch 3: [6689/10940] ---- BYOL Training Loss = 0.22543735802173615
30-01-2023 21:04:19 INFO Epoch 3: [6689/10940] ---- BYOL Validation Loss = 0.16198982298374176
30-01-2023 21:04:37 INFO Epoch 3: [6700/10940] ---- BYOL Training Loss = 0.21128782629966736
30-01-2023 21:04:55 INFO Epoch 3: [6711/10940] ---- BYOL Training Loss = 0.22397549450397491
30-01-2023 21:05:14 INFO Epoch 3: [6722/10940] ---- BYOL Training Loss = 0.23297517001628876
30-01-2023 21:05:32 INFO Epoch 3: [6733/10940] ---- BYOL Training Loss = 0.22478802502155304
30-01-2023 21:06:25 INFO Epoch 3: [6733/10940] ---- BYOL Validation Loss = 0.17835061252117157
30-01-2023 21:06:43 INFO Epoch 3: [6744/10940] ---- BYOL Training Loss = 0.1840302050113678
30-01-2023 21:07:01 INFO Epoch 3: [6755/10940] ---- BYOL Training Loss = 0.23278549313545227
30-01-2023 21:07:19 INFO Epoch 3: [6766/10940] ---- BYOL Training Loss = 0.26454958319664
30-01-2023 21:07:37 INFO Epoch 3: [6777/10940] ---- BYOL Training Loss = 0.2511291205883026
30-01-2023 21:08:30 INFO Epoch 3: [6777/10940] ---- BYOL Validation Loss = 0.18616943061351776
30-01-2023 21:08:49 INFO Epoch 3: [6788/10940] ---- BYOL Training Loss = 0.25352004170417786
30-01-2023 21:09:07 INFO Epoch 3: [6799/10940] ---- BYOL Training Loss = 0.22298309206962585
30-01-2023 21:09:25 INFO Epoch 3: [6810/10940] ---- BYOL Training Loss = 0.22386237978935242
30-01-2023 21:09:43 INFO Epoch 3: [6821/10940] ---- BYOL Training Loss = 0.20460200309753418
30-01-2023 21:10:36 INFO Epoch 3: [6821/10940] ---- BYOL Validation Loss = 0.20407120883464813
30-01-2023 21:10:54 INFO Epoch 3: [6832/10940] ---- BYOL Training Loss = 0.1890985667705536
30-01-2023 21:11:12 INFO Epoch 3: [6843/10940] ---- BYOL Training Loss = 0.19071577489376068
30-01-2023 21:11:30 INFO Epoch 3: [6854/10940] ---- BYOL Training Loss = 0.18577630817890167
30-01-2023 21:11:49 INFO Epoch 3: [6865/10940] ---- BYOL Training Loss = 0.21581272780895233
30-01-2023 21:12:42 INFO Epoch 3: [6865/10940] ---- BYOL Validation Loss = 0.18878325819969177
30-01-2023 21:13:00 INFO Epoch 3: [6876/10940] ---- BYOL Training Loss = 0.24670755863189697
30-01-2023 21:13:18 INFO Epoch 3: [6887/10940] ---- BYOL Training Loss = 0.26346641778945923
30-01-2023 21:13:36 INFO Epoch 3: [6898/10940] ---- BYOL Training Loss = 0.2735806107521057
30-01-2023 21:13:54 INFO Epoch 3: [6909/10940] ---- BYOL Training Loss = 0.22561559081077576
30-01-2023 21:14:47 INFO Epoch 3: [6909/10940] ---- BYOL Validation Loss = 0.19051043689250946
30-01-2023 21:15:05 INFO Epoch 3: [6920/10940] ---- BYOL Training Loss = 0.20420929789543152
30-01-2023 21:15:23 INFO Epoch 3: [6931/10940] ---- BYOL Training Loss = 0.20992925763130188
30-01-2023 21:15:42 INFO Epoch 3: [6942/10940] ---- BYOL Training Loss = 0.212009996175766
30-01-2023 21:16:00 INFO Epoch 3: [6953/10940] ---- BYOL Training Loss = 0.2363283336162567
30-01-2023 21:16:53 INFO Epoch 3: [6953/10940] ---- BYOL Validation Loss = 0.16833634674549103
30-01-2023 21:17:11 INFO Epoch 3: [6964/10940] ---- BYOL Training Loss = 0.23516595363616943
30-01-2023 21:17:29 INFO Epoch 3: [6975/10940] ---- BYOL Training Loss = 0.21353976428508759
30-01-2023 21:17:47 INFO Epoch 3: [6986/10940] ---- BYOL Training Loss = 0.1850271224975586
30-01-2023 21:18:05 INFO Epoch 3: [6997/10940] ---- BYOL Training Loss = 0.2174336463212967
30-01-2023 21:18:58 INFO Epoch 3: [6997/10940] ---- BYOL Validation Loss = 0.1818798929452896
30-01-2023 21:19:16 INFO Epoch 3: [7008/10940] ---- BYOL Training Loss = 0.1807611882686615
30-01-2023 21:19:35 INFO Epoch 3: [7019/10940] ---- BYOL Training Loss = 0.2640003263950348
30-01-2023 21:19:53 INFO Epoch 3: [7030/10940] ---- BYOL Training Loss = 0.24843385815620422
30-01-2023 21:20:11 INFO Epoch 3: [7041/10940] ---- BYOL Training Loss = 0.24598607420921326
30-01-2023 21:21:04 INFO Epoch 3: [7041/10940] ---- BYOL Validation Loss = 0.20815162360668182
30-01-2023 21:21:22 INFO Epoch 3: [7052/10940] ---- BYOL Training Loss = 0.2806256115436554
30-01-2023 21:21:40 INFO Epoch 3: [7063/10940] ---- BYOL Training Loss = 0.24599695205688477
30-01-2023 21:21:58 INFO Epoch 3: [7074/10940] ---- BYOL Training Loss = 0.25727787613868713
30-01-2023 21:22:17 INFO Epoch 3: [7085/10940] ---- BYOL Training Loss = 0.23406720161437988
30-01-2023 21:23:10 INFO Epoch 3: [7085/10940] ---- BYOL Validation Loss = 0.18352781236171722
30-01-2023 21:23:28 INFO Epoch 3: [7096/10940] ---- BYOL Training Loss = 0.26140883564949036
30-01-2023 21:23:46 INFO Epoch 3: [7107/10940] ---- BYOL Training Loss = 0.25021567940711975
30-01-2023 21:24:04 INFO Epoch 3: [7118/10940] ---- BYOL Training Loss = 0.2236432582139969
30-01-2023 21:24:23 INFO Epoch 3: [7129/10940] ---- BYOL Training Loss = 0.2340134084224701
30-01-2023 21:25:15 INFO Epoch 3: [7129/10940] ---- BYOL Validation Loss = 0.20041564106941223
30-01-2023 21:25:33 INFO Epoch 3: [7140/10940] ---- BYOL Training Loss = 0.2138800323009491
30-01-2023 21:25:51 INFO Epoch 3: [7151/10940] ---- BYOL Training Loss = 0.1970062553882599
30-01-2023 21:26:10 INFO Epoch 3: [7162/10940] ---- BYOL Training Loss = 0.1941879689693451
30-01-2023 21:26:28 INFO Epoch 3: [7173/10940] ---- BYOL Training Loss = 0.24817252159118652
30-01-2023 21:27:21 INFO Epoch 3: [7173/10940] ---- BYOL Validation Loss = 0.1999436467885971
30-01-2023 21:27:39 INFO Epoch 3: [7184/10940] ---- BYOL Training Loss = 0.27099525928497314
30-01-2023 21:27:57 INFO Epoch 3: [7195/10940] ---- BYOL Training Loss = 0.22290904819965363
30-01-2023 21:28:15 INFO Epoch 3: [7206/10940] ---- BYOL Training Loss = 0.2166277915239334
30-01-2023 21:28:34 INFO Epoch 3: [7217/10940] ---- BYOL Training Loss = 0.25299087166786194
30-01-2023 21:29:26 INFO Epoch 3: [7217/10940] ---- BYOL Validation Loss = 0.1750779151916504
30-01-2023 21:29:44 INFO Epoch 3: [7228/10940] ---- BYOL Training Loss = 0.21045604348182678
30-01-2023 21:30:03 INFO Epoch 3: [7239/10940] ---- BYOL Training Loss = 0.20268750190734863
30-01-2023 21:30:21 INFO Epoch 3: [7250/10940] ---- BYOL Training Loss = 0.22271719574928284
30-01-2023 21:30:39 INFO Epoch 3: [7261/10940] ---- BYOL Training Loss = 0.1842881441116333
30-01-2023 21:31:32 INFO Epoch 3: [7261/10940] ---- BYOL Validation Loss = 0.15854361653327942
30-01-2023 21:31:50 INFO Epoch 3: [7272/10940] ---- BYOL Training Loss = 0.15156209468841553
30-01-2023 21:32:08 INFO Epoch 3: [7283/10940] ---- BYOL Training Loss = 0.1960379183292389
30-01-2023 21:32:27 INFO Epoch 3: [7294/10940] ---- BYOL Training Loss = 0.23850886523723602
30-01-2023 21:32:45 INFO Epoch 3: [7305/10940] ---- BYOL Training Loss = 0.2169792205095291
30-01-2023 21:33:38 INFO Epoch 3: [7305/10940] ---- BYOL Validation Loss = 0.17919544875621796
30-01-2023 21:33:56 INFO Epoch 3: [7316/10940] ---- BYOL Training Loss = 0.25791555643081665
30-01-2023 21:34:14 INFO Epoch 3: [7327/10940] ---- BYOL Training Loss = 0.20554237067699432
30-01-2023 21:34:32 INFO Epoch 3: [7338/10940] ---- BYOL Training Loss = 0.1868792027235031
30-01-2023 21:34:51 INFO Epoch 3: [7349/10940] ---- BYOL Training Loss = 0.22691746056079865
30-01-2023 21:35:44 INFO Epoch 3: [7349/10940] ---- BYOL Validation Loss = 0.18025295436382294
30-01-2023 21:36:01 INFO Epoch 3: [7360/10940] ---- BYOL Training Loss = 0.2528894245624542
30-01-2023 21:36:20 INFO Epoch 3: [7371/10940] ---- BYOL Training Loss = 0.2222858965396881
30-01-2023 21:36:38 INFO Epoch 3: [7382/10940] ---- BYOL Training Loss = 0.2416336089372635
30-01-2023 21:36:56 INFO Epoch 3: [7393/10940] ---- BYOL Training Loss = 0.32102251052856445
30-01-2023 21:37:49 INFO Epoch 3: [7393/10940] ---- BYOL Validation Loss = 0.1959182173013687
30-01-2023 21:38:07 INFO Epoch 3: [7404/10940] ---- BYOL Training Loss = 0.21162088215351105
30-01-2023 21:38:26 INFO Epoch 3: [7415/10940] ---- BYOL Training Loss = 0.1798103004693985
30-01-2023 21:38:44 INFO Epoch 3: [7426/10940] ---- BYOL Training Loss = 0.20598821341991425
30-01-2023 21:39:02 INFO Epoch 3: [7437/10940] ---- BYOL Training Loss = 0.24116897583007812
30-01-2023 21:39:55 INFO Epoch 3: [7437/10940] ---- BYOL Validation Loss = 0.17980000376701355
30-01-2023 21:40:13 INFO Epoch 3: [7448/10940] ---- BYOL Training Loss = 0.21225062012672424
30-01-2023 21:40:31 INFO Epoch 3: [7459/10940] ---- BYOL Training Loss = 0.19114868342876434
30-01-2023 21:40:49 INFO Epoch 3: [7470/10940] ---- BYOL Training Loss = 0.24597029387950897
30-01-2023 21:41:08 INFO Epoch 3: [7481/10940] ---- BYOL Training Loss = 0.25684013962745667
30-01-2023 21:42:01 INFO Epoch 3: [7481/10940] ---- BYOL Validation Loss = 0.19382967054843903
30-01-2023 21:42:18 INFO Epoch 3: [7492/10940] ---- BYOL Training Loss = 0.22248423099517822
30-01-2023 21:42:37 INFO Epoch 3: [7503/10940] ---- BYOL Training Loss = 0.18542934954166412
30-01-2023 21:42:55 INFO Epoch 3: [7514/10940] ---- BYOL Training Loss = 0.21820826828479767
30-01-2023 21:43:14 INFO Epoch 3: [7525/10940] ---- BYOL Training Loss = 0.22094276547431946
30-01-2023 21:44:06 INFO Epoch 3: [7525/10940] ---- BYOL Validation Loss = 0.18409323692321777
30-01-2023 21:44:24 INFO Epoch 3: [7536/10940] ---- BYOL Training Loss = 0.24493460357189178
30-01-2023 21:44:43 INFO Epoch 3: [7547/10940] ---- BYOL Training Loss = 0.31080716848373413
30-01-2023 21:45:01 INFO Epoch 3: [7558/10940] ---- BYOL Training Loss = 0.2510066032409668
30-01-2023 21:45:19 INFO Epoch 3: [7569/10940] ---- BYOL Training Loss = 0.19764231145381927
30-01-2023 21:46:12 INFO Epoch 3: [7569/10940] ---- BYOL Validation Loss = 0.14461588859558105
30-01-2023 21:46:30 INFO Epoch 3: [7580/10940] ---- BYOL Training Loss = 0.21296417713165283
30-01-2023 21:46:49 INFO Epoch 3: [7591/10940] ---- BYOL Training Loss = 0.22616958618164062
30-01-2023 21:47:07 INFO Epoch 3: [7602/10940] ---- BYOL Training Loss = 0.228200763463974
30-01-2023 21:47:25 INFO Epoch 3: [7613/10940] ---- BYOL Training Loss = 0.24879372119903564
30-01-2023 21:48:18 INFO Epoch 3: [7613/10940] ---- BYOL Validation Loss = 0.16651365160942078
30-01-2023 21:48:36 INFO Epoch 3: [7624/10940] ---- BYOL Training Loss = 0.2583707273006439
30-01-2023 21:48:55 INFO Epoch 3: [7635/10940] ---- BYOL Training Loss = 0.2698178291320801
30-01-2023 21:49:13 INFO Epoch 3: [7646/10940] ---- BYOL Training Loss = 0.24845175445079803
30-01-2023 21:49:31 INFO Epoch 3: [7657/10940] ---- BYOL Training Loss = 0.26625940203666687
30-01-2023 21:50:24 INFO Epoch 3: [7657/10940] ---- BYOL Validation Loss = 0.1971927136182785
30-01-2023 21:50:42 INFO Epoch 3: [7668/10940] ---- BYOL Training Loss = 0.2315104454755783
30-01-2023 21:51:00 INFO Epoch 3: [7679/10940] ---- BYOL Training Loss = 0.16755983233451843
30-01-2023 21:51:18 INFO Epoch 3: [7690/10940] ---- BYOL Training Loss = 0.1719934195280075
30-01-2023 21:51:37 INFO Epoch 3: [7701/10940] ---- BYOL Training Loss = 0.20589590072631836
30-01-2023 21:52:29 INFO Epoch 3: [7701/10940] ---- BYOL Validation Loss = 0.19761840999126434
30-01-2023 21:52:47 INFO Epoch 3: [7712/10940] ---- BYOL Training Loss = 0.19772043824195862
30-01-2023 21:53:05 INFO Epoch 3: [7723/10940] ---- BYOL Training Loss = 0.18810273706912994
30-01-2023 21:53:24 INFO Epoch 3: [7734/10940] ---- BYOL Training Loss = 0.2068241387605667
30-01-2023 21:53:42 INFO Epoch 3: [7745/10940] ---- BYOL Training Loss = 0.19748911261558533
30-01-2023 21:54:35 INFO Epoch 3: [7745/10940] ---- BYOL Validation Loss = 0.1793358325958252
30-01-2023 21:54:53 INFO Epoch 3: [7756/10940] ---- BYOL Training Loss = 0.215653657913208
30-01-2023 21:55:11 INFO Epoch 3: [7767/10940] ---- BYOL Training Loss = 0.23058733344078064
30-01-2023 21:55:30 INFO Epoch 3: [7778/10940] ---- BYOL Training Loss = 0.18719010055065155
30-01-2023 21:55:48 INFO Epoch 3: [7789/10940] ---- BYOL Training Loss = 0.18027135729789734
30-01-2023 21:56:41 INFO Epoch 3: [7789/10940] ---- BYOL Validation Loss = 0.1798073947429657
30-01-2023 21:56:59 INFO Epoch 3: [7800/10940] ---- BYOL Training Loss = 0.23023977875709534
30-01-2023 21:57:17 INFO Epoch 3: [7811/10940] ---- BYOL Training Loss = 0.28390252590179443
30-01-2023 21:57:35 INFO Epoch 3: [7822/10940] ---- BYOL Training Loss = 0.200723797082901
30-01-2023 21:57:54 INFO Epoch 3: [7833/10940] ---- BYOL Training Loss = 0.22270360589027405
30-01-2023 21:58:47 INFO Epoch 3: [7833/10940] ---- BYOL Validation Loss = 0.19280755519866943
30-01-2023 21:59:04 INFO Epoch 3: [7844/10940] ---- BYOL Training Loss = 0.2554706633090973
30-01-2023 21:59:23 INFO Epoch 3: [7855/10940] ---- BYOL Training Loss = 0.25436195731163025
30-01-2023 21:59:41 INFO Epoch 3: [7866/10940] ---- BYOL Training Loss = 0.22662679851055145
30-01-2023 21:59:59 INFO Epoch 3: [7877/10940] ---- BYOL Training Loss = 0.20497897267341614
30-01-2023 22:00:52 INFO Epoch 3: [7877/10940] ---- BYOL Validation Loss = 0.18124409019947052
30-01-2023 22:01:10 INFO Epoch 3: [7888/10940] ---- BYOL Training Loss = 0.21896639466285706
30-01-2023 22:01:28 INFO Epoch 3: [7899/10940] ---- BYOL Training Loss = 0.21526837348937988
30-01-2023 22:01:47 INFO Epoch 3: [7910/10940] ---- BYOL Training Loss = 0.17372748255729675
30-01-2023 22:02:05 INFO Epoch 3: [7921/10940] ---- BYOL Training Loss = 0.17607268691062927
30-01-2023 22:02:57 INFO Epoch 3: [7921/10940] ---- BYOL Validation Loss = 0.1795007437467575
30-01-2023 22:03:16 INFO Epoch 3: [7932/10940] ---- BYOL Training Loss = 0.19943037629127502
30-01-2023 22:03:34 INFO Epoch 3: [7943/10940] ---- BYOL Training Loss = 0.2048530876636505
30-01-2023 22:03:53 INFO Epoch 3: [7954/10940] ---- BYOL Training Loss = 0.2534727454185486
30-01-2023 22:04:11 INFO Epoch 3: [7965/10940] ---- BYOL Training Loss = 0.2682003378868103
30-01-2023 22:05:04 INFO Epoch 3: [7965/10940] ---- BYOL Validation Loss = 0.1852453500032425
30-01-2023 22:05:22 INFO Epoch 3: [7976/10940] ---- BYOL Training Loss = 0.2716658115386963
30-01-2023 22:05:40 INFO Epoch 3: [7987/10940] ---- BYOL Training Loss = 0.2755248248577118
30-01-2023 22:05:59 INFO Epoch 3: [7998/10940] ---- BYOL Training Loss = 0.24811860918998718
30-01-2023 22:06:17 INFO Epoch 3: [8009/10940] ---- BYOL Training Loss = 0.20888134837150574
30-01-2023 22:07:10 INFO Epoch 3: [8009/10940] ---- BYOL Validation Loss = 0.17670737206935883
30-01-2023 22:07:28 INFO Epoch 3: [8020/10940] ---- BYOL Training Loss = 0.1895860731601715
30-01-2023 22:07:47 INFO Epoch 3: [8031/10940] ---- BYOL Training Loss = 0.2066289633512497
30-01-2023 22:08:05 INFO Epoch 3: [8042/10940] ---- BYOL Training Loss = 0.21141958236694336
30-01-2023 22:08:23 INFO Epoch 3: [8053/10940] ---- BYOL Training Loss = 0.2195371389389038
30-01-2023 22:09:16 INFO Epoch 3: [8053/10940] ---- BYOL Validation Loss = 0.1889551728963852
30-01-2023 22:09:34 INFO Epoch 3: [8064/10940] ---- BYOL Training Loss = 0.23993845283985138
30-01-2023 22:09:53 INFO Epoch 3: [8075/10940] ---- BYOL Training Loss = 0.250545859336853
30-01-2023 22:10:11 INFO Epoch 3: [8086/10940] ---- BYOL Training Loss = 0.22320003807544708
30-01-2023 22:10:30 INFO Epoch 3: [8097/10940] ---- BYOL Training Loss = 0.23082351684570312
30-01-2023 22:11:23 INFO Epoch 3: [8097/10940] ---- BYOL Validation Loss = 0.15366169810295105
30-01-2023 22:11:41 INFO Epoch 3: [8108/10940] ---- BYOL Training Loss = 0.20766393840312958
30-01-2023 22:11:59 INFO Epoch 3: [8119/10940] ---- BYOL Training Loss = 0.22515790164470673
30-01-2023 22:12:18 INFO Epoch 3: [8130/10940] ---- BYOL Training Loss = 0.2848290801048279
30-01-2023 22:12:36 INFO Epoch 3: [8141/10940] ---- BYOL Training Loss = 0.30180028080940247
30-01-2023 22:13:29 INFO Epoch 3: [8141/10940] ---- BYOL Validation Loss = 0.2115340530872345
30-01-2023 22:13:47 INFO Epoch 3: [8152/10940] ---- BYOL Training Loss = 0.2454606592655182
30-01-2023 22:14:06 INFO Epoch 3: [8163/10940] ---- BYOL Training Loss = 0.22758527100086212
30-01-2023 22:14:24 INFO Epoch 3: [8174/10940] ---- BYOL Training Loss = 0.21496164798736572
30-01-2023 22:14:43 INFO Epoch 3: [8185/10940] ---- BYOL Training Loss = 0.1914156824350357
30-01-2023 22:15:35 INFO Epoch 3: [8185/10940] ---- BYOL Validation Loss = 0.19345736503601074
30-01-2023 22:15:53 INFO Epoch 3: [8196/10940] ---- BYOL Training Loss = 0.19729213416576385
30-01-2023 22:16:12 INFO Epoch 3: [8207/10940] ---- BYOL Training Loss = 0.21793238818645477
30-01-2023 22:16:30 INFO Epoch 3: [8218/10940] ---- BYOL Training Loss = 0.2383616864681244
30-01-2023 22:16:49 INFO Epoch 3: [8229/10940] ---- BYOL Training Loss = 0.23806428909301758
30-01-2023 22:17:42 INFO Epoch 3: [8229/10940] ---- BYOL Validation Loss = 0.18970131874084473
30-01-2023 22:18:00 INFO Epoch 3: [8240/10940] ---- BYOL Training Loss = 0.2094673365354538
30-01-2023 22:18:18 INFO Epoch 3: [8251/10940] ---- BYOL Training Loss = 0.189519003033638
30-01-2023 22:18:36 INFO Epoch 3: [8262/10940] ---- BYOL Training Loss = 0.22071845829486847
30-01-2023 22:18:55 INFO Epoch 3: [8273/10940] ---- BYOL Training Loss = 0.24166688323020935
30-01-2023 22:19:47 INFO Epoch 3: [8273/10940] ---- BYOL Validation Loss = 0.20159803330898285
30-01-2023 22:20:06 INFO Epoch 3: [8284/10940] ---- BYOL Training Loss = 0.23181673884391785
30-01-2023 22:20:24 INFO Epoch 3: [8295/10940] ---- BYOL Training Loss = 0.21745440363883972
30-01-2023 22:20:42 INFO Epoch 3: [8306/10940] ---- BYOL Training Loss = 0.17298924922943115
30-01-2023 22:21:01 INFO Epoch 3: [8317/10940] ---- BYOL Training Loss = 0.20850113034248352
30-01-2023 22:21:53 INFO Epoch 3: [8317/10940] ---- BYOL Validation Loss = 0.18331609666347504
30-01-2023 22:22:11 INFO Epoch 3: [8328/10940] ---- BYOL Training Loss = 0.23252180218696594
30-01-2023 22:22:30 INFO Epoch 3: [8339/10940] ---- BYOL Training Loss = 0.24098742008209229
30-01-2023 22:22:48 INFO Epoch 3: [8350/10940] ---- BYOL Training Loss = 0.23657310009002686
30-01-2023 22:23:07 INFO Epoch 3: [8361/10940] ---- BYOL Training Loss = 0.2367589920759201
30-01-2023 22:23:59 INFO Epoch 3: [8361/10940] ---- BYOL Validation Loss = 0.20063696801662445
30-01-2023 22:24:17 INFO Epoch 3: [8372/10940] ---- BYOL Training Loss = 0.2415170669555664
30-01-2023 22:24:36 INFO Epoch 3: [8383/10940] ---- BYOL Training Loss = 0.23328843712806702
30-01-2023 22:24:54 INFO Epoch 3: [8394/10940] ---- BYOL Training Loss = 0.2143992930650711
30-01-2023 22:25:13 INFO Epoch 3: [8405/10940] ---- BYOL Training Loss = 0.25028905272483826
30-01-2023 22:26:05 INFO Epoch 3: [8405/10940] ---- BYOL Validation Loss = 0.17745055258274078
30-01-2023 22:26:24 INFO Epoch 3: [8416/10940] ---- BYOL Training Loss = 0.21615362167358398
30-01-2023 22:26:42 INFO Epoch 3: [8427/10940] ---- BYOL Training Loss = 0.19263499975204468
30-01-2023 22:27:01 INFO Epoch 3: [8438/10940] ---- BYOL Training Loss = 0.22398710250854492
30-01-2023 22:27:19 INFO Epoch 3: [8449/10940] ---- BYOL Training Loss = 0.21246390044689178
30-01-2023 22:28:12 INFO Epoch 3: [8449/10940] ---- BYOL Validation Loss = 0.1799503117799759
30-01-2023 22:28:29 INFO Epoch 3: [8460/10940] ---- BYOL Training Loss = 0.22540922462940216
30-01-2023 22:28:48 INFO Epoch 3: [8471/10940] ---- BYOL Training Loss = 0.24362337589263916
30-01-2023 22:29:06 INFO Epoch 3: [8482/10940] ---- BYOL Training Loss = 0.21663551032543182
30-01-2023 22:29:25 INFO Epoch 3: [8493/10940] ---- BYOL Training Loss = 0.22042255103588104
30-01-2023 22:30:17 INFO Epoch 3: [8493/10940] ---- BYOL Validation Loss = 0.18626467883586884
30-01-2023 22:30:36 INFO Epoch 3: [8504/10940] ---- BYOL Training Loss = 0.21131069958209991
30-01-2023 22:30:54 INFO Epoch 3: [8515/10940] ---- BYOL Training Loss = 0.15917839109897614
30-01-2023 22:31:12 INFO Epoch 3: [8526/10940] ---- BYOL Training Loss = 0.1536419540643692
30-01-2023 22:31:31 INFO Epoch 3: [8537/10940] ---- BYOL Training Loss = 0.1579028069972992
30-01-2023 22:32:23 INFO Epoch 3: [8537/10940] ---- BYOL Validation Loss = 0.12759779393672943
30-01-2023 22:32:41 INFO Epoch 3: [8548/10940] ---- BYOL Training Loss = 0.1961716264486313
30-01-2023 22:33:00 INFO Epoch 3: [8559/10940] ---- BYOL Training Loss = 0.2559480667114258
30-01-2023 22:33:18 INFO Epoch 3: [8570/10940] ---- BYOL Training Loss = 0.2575366795063019
30-01-2023 22:33:37 INFO Epoch 3: [8581/10940] ---- BYOL Training Loss = 0.24751713871955872
30-01-2023 22:34:30 INFO Epoch 3: [8581/10940] ---- BYOL Validation Loss = 0.19379231333732605
30-01-2023 22:34:48 INFO Epoch 3: [8592/10940] ---- BYOL Training Loss = 0.2563827633857727
30-01-2023 22:35:07 INFO Epoch 3: [8603/10940] ---- BYOL Training Loss = 0.22272709012031555
30-01-2023 22:35:25 INFO Epoch 3: [8614/10940] ---- BYOL Training Loss = 0.21759912371635437
30-01-2023 22:35:44 INFO Epoch 3: [8625/10940] ---- BYOL Training Loss = 0.18442001938819885
30-01-2023 22:36:36 INFO Epoch 3: [8625/10940] ---- BYOL Validation Loss = 0.1849605292081833
30-01-2023 22:36:54 INFO Epoch 3: [8636/10940] ---- BYOL Training Loss = 0.16312451660633087
30-01-2023 22:37:13 INFO Epoch 3: [8647/10940] ---- BYOL Training Loss = 0.2314087599515915
30-01-2023 22:37:31 INFO Epoch 3: [8658/10940] ---- BYOL Training Loss = 0.2544485926628113
30-01-2023 22:37:50 INFO Epoch 3: [8669/10940] ---- BYOL Training Loss = 0.24780651926994324
30-01-2023 22:38:42 INFO Epoch 3: [8669/10940] ---- BYOL Validation Loss = 0.20099769532680511
30-01-2023 22:39:00 INFO Epoch 3: [8680/10940] ---- BYOL Training Loss = 0.2523893117904663
30-01-2023 22:39:19 INFO Epoch 3: [8691/10940] ---- BYOL Training Loss = 0.19153879582881927
30-01-2023 22:39:37 INFO Epoch 3: [8702/10940] ---- BYOL Training Loss = 0.16840586066246033
30-01-2023 22:39:56 INFO Epoch 3: [8713/10940] ---- BYOL Training Loss = 0.1743161380290985
30-01-2023 22:40:48 INFO Epoch 3: [8713/10940] ---- BYOL Validation Loss = 0.1779525727033615
30-01-2023 22:41:07 INFO Epoch 3: [8724/10940] ---- BYOL Training Loss = 0.1823277473449707
30-01-2023 22:41:25 INFO Epoch 3: [8735/10940] ---- BYOL Training Loss = 0.2172846794128418
30-01-2023 22:41:44 INFO Epoch 3: [8746/10940] ---- BYOL Training Loss = 0.2710271179676056
30-01-2023 22:42:02 INFO Epoch 3: [8757/10940] ---- BYOL Training Loss = 0.20006677508354187
30-01-2023 22:42:55 INFO Epoch 3: [8757/10940] ---- BYOL Validation Loss = 0.11842720955610275
30-01-2023 22:43:13 INFO Epoch 3: [8768/10940] ---- BYOL Training Loss = 0.18243250250816345
30-01-2023 22:43:31 INFO Epoch 3: [8779/10940] ---- BYOL Training Loss = 0.24162152409553528
30-01-2023 22:43:50 INFO Epoch 3: [8790/10940] ---- BYOL Training Loss = 0.19751501083374023
30-01-2023 22:44:08 INFO Epoch 3: [8801/10940] ---- BYOL Training Loss = 0.2146565467119217
30-01-2023 22:45:01 INFO Epoch 3: [8801/10940] ---- BYOL Validation Loss = 0.1716224104166031
30-01-2023 22:45:19 INFO Epoch 3: [8812/10940] ---- BYOL Training Loss = 0.20588377118110657
30-01-2023 22:45:37 INFO Epoch 3: [8823/10940] ---- BYOL Training Loss = 0.17286130785942078
30-01-2023 22:45:56 INFO Epoch 3: [8834/10940] ---- BYOL Training Loss = 0.20360496640205383
30-01-2023 22:46:14 INFO Epoch 3: [8845/10940] ---- BYOL Training Loss = 0.29508498311042786
30-01-2023 22:47:07 INFO Epoch 3: [8845/10940] ---- BYOL Validation Loss = 0.16839547455310822
30-01-2023 22:47:25 INFO Epoch 3: [8856/10940] ---- BYOL Training Loss = 0.32341882586479187
30-01-2023 22:47:44 INFO Epoch 3: [8867/10940] ---- BYOL Training Loss = 0.285383939743042
30-01-2023 22:48:02 INFO Epoch 3: [8878/10940] ---- BYOL Training Loss = 0.2643865644931793
30-01-2023 22:48:21 INFO Epoch 3: [8889/10940] ---- BYOL Training Loss = 0.2550841271877289
30-01-2023 22:49:13 INFO Epoch 3: [8889/10940] ---- BYOL Validation Loss = 0.18254712224006653
30-01-2023 22:49:32 INFO Epoch 3: [8900/10940] ---- BYOL Training Loss = 0.24377205967903137
30-01-2023 22:49:50 INFO Epoch 3: [8911/10940] ---- BYOL Training Loss = 0.2054649144411087
30-01-2023 22:50:08 INFO Epoch 3: [8922/10940] ---- BYOL Training Loss = 0.22515735030174255
30-01-2023 22:50:27 INFO Epoch 3: [8933/10940] ---- BYOL Training Loss = 0.2707785964012146
30-01-2023 22:51:20 INFO Epoch 3: [8933/10940] ---- BYOL Validation Loss = 0.17191433906555176
30-01-2023 22:51:38 INFO Epoch 3: [8944/10940] ---- BYOL Training Loss = 0.2270713597536087
30-01-2023 22:51:57 INFO Epoch 3: [8955/10940] ---- BYOL Training Loss = 0.2028966248035431
30-01-2023 22:52:15 INFO Epoch 3: [8966/10940] ---- BYOL Training Loss = 0.2511884868144989
30-01-2023 22:52:33 INFO Epoch 3: [8977/10940] ---- BYOL Training Loss = 0.24189600348472595
30-01-2023 22:53:26 INFO Epoch 3: [8977/10940] ---- BYOL Validation Loss = 0.1787421852350235
30-01-2023 22:53:45 INFO Epoch 3: [8988/10940] ---- BYOL Training Loss = 0.2520950734615326
30-01-2023 22:54:03 INFO Epoch 3: [8999/10940] ---- BYOL Training Loss = 0.22652871906757355
30-01-2023 22:54:22 INFO Epoch 3: [9010/10940] ---- BYOL Training Loss = 0.19488036632537842
30-01-2023 22:54:40 INFO Epoch 3: [9021/10940] ---- BYOL Training Loss = 0.23672914505004883
30-01-2023 22:55:33 INFO Epoch 3: [9021/10940] ---- BYOL Validation Loss = 0.16715212166309357
30-01-2023 22:55:51 INFO Epoch 3: [9032/10940] ---- BYOL Training Loss = 0.22857670485973358
30-01-2023 22:56:10 INFO Epoch 3: [9043/10940] ---- BYOL Training Loss = 0.1856568455696106
30-01-2023 22:56:28 INFO Epoch 3: [9054/10940] ---- BYOL Training Loss = 0.15786749124526978
30-01-2023 22:56:47 INFO Epoch 3: [9065/10940] ---- BYOL Training Loss = 0.19110791385173798
30-01-2023 22:57:39 INFO Epoch 3: [9065/10940] ---- BYOL Validation Loss = 0.20095059275627136
30-01-2023 22:57:58 INFO Epoch 3: [9076/10940] ---- BYOL Training Loss = 0.2650846838951111
30-01-2023 22:58:16 INFO Epoch 3: [9087/10940] ---- BYOL Training Loss = 0.22473832964897156
30-01-2023 22:58:35 INFO Epoch 3: [9098/10940] ---- BYOL Training Loss = 0.22060644626617432
30-01-2023 22:58:53 INFO Epoch 3: [9109/10940] ---- BYOL Training Loss = 0.16517896950244904
30-01-2023 22:59:46 INFO Epoch 3: [9109/10940] ---- BYOL Validation Loss = 0.12515227496623993
30-01-2023 23:00:04 INFO Epoch 3: [9120/10940] ---- BYOL Training Loss = 0.17112110555171967
30-01-2023 23:00:23 INFO Epoch 3: [9131/10940] ---- BYOL Training Loss = 0.2255706489086151
30-01-2023 23:00:41 INFO Epoch 3: [9142/10940] ---- BYOL Training Loss = 0.2095547914505005
30-01-2023 23:01:00 INFO Epoch 3: [9153/10940] ---- BYOL Training Loss = 0.19427134096622467
30-01-2023 23:01:52 INFO Epoch 3: [9153/10940] ---- BYOL Validation Loss = 0.13906726241111755
30-01-2023 23:02:11 INFO Epoch 3: [9164/10940] ---- BYOL Training Loss = 0.20826861262321472
30-01-2023 23:02:29 INFO Epoch 3: [9175/10940] ---- BYOL Training Loss = 0.20243842899799347
30-01-2023 23:02:48 INFO Epoch 3: [9186/10940] ---- BYOL Training Loss = 0.25790172815322876
30-01-2023 23:03:06 INFO Epoch 3: [9197/10940] ---- BYOL Training Loss = 0.29028481245040894
30-01-2023 23:03:59 INFO Epoch 3: [9197/10940] ---- BYOL Validation Loss = 0.17219117283821106
30-01-2023 23:04:17 INFO Epoch 3: [9208/10940] ---- BYOL Training Loss = 0.20289337635040283
30-01-2023 23:04:36 INFO Epoch 3: [9219/10940] ---- BYOL Training Loss = 0.22915160655975342
30-01-2023 23:04:54 INFO Epoch 3: [9230/10940] ---- BYOL Training Loss = 0.19956813752651215
30-01-2023 23:05:13 INFO Epoch 3: [9241/10940] ---- BYOL Training Loss = 0.22481659054756165
30-01-2023 23:06:06 INFO Epoch 3: [9241/10940] ---- BYOL Validation Loss = 0.14862574636936188
30-01-2023 23:06:24 INFO Epoch 3: [9252/10940] ---- BYOL Training Loss = 0.213114932179451
30-01-2023 23:06:42 INFO Epoch 3: [9263/10940] ---- BYOL Training Loss = 0.23339545726776123
30-01-2023 23:07:01 INFO Epoch 3: [9274/10940] ---- BYOL Training Loss = 0.21153636276721954
30-01-2023 23:07:20 INFO Epoch 3: [9285/10940] ---- BYOL Training Loss = 0.16724705696105957
30-01-2023 23:08:12 INFO Epoch 3: [9285/10940] ---- BYOL Validation Loss = 0.1356382519006729
30-01-2023 23:08:30 INFO Epoch 3: [9296/10940] ---- BYOL Training Loss = 0.15630261600017548
30-01-2023 23:08:49 INFO Epoch 3: [9307/10940] ---- BYOL Training Loss = 0.22191078960895538
30-01-2023 23:09:08 INFO Epoch 3: [9318/10940] ---- BYOL Training Loss = 0.24054677784442902
30-01-2023 23:09:27 INFO Epoch 3: [9329/10940] ---- BYOL Training Loss = 0.19992944598197937
30-01-2023 23:10:19 INFO Epoch 3: [9329/10940] ---- BYOL Validation Loss = 0.17635345458984375
30-01-2023 23:10:37 INFO Epoch 3: [9340/10940] ---- BYOL Training Loss = 0.1855238527059555
30-01-2023 23:10:56 INFO Epoch 3: [9351/10940] ---- BYOL Training Loss = 0.29311642050743103
30-01-2023 23:11:15 INFO Epoch 3: [9362/10940] ---- BYOL Training Loss = 0.3184458613395691
30-01-2023 23:11:33 INFO Epoch 3: [9373/10940] ---- BYOL Training Loss = 0.2304392158985138
30-01-2023 23:12:25 INFO Epoch 3: [9373/10940] ---- BYOL Validation Loss = 0.1898757964372635
30-01-2023 23:12:44 INFO Epoch 3: [9384/10940] ---- BYOL Training Loss = 0.18237118422985077
30-01-2023 23:13:02 INFO Epoch 3: [9395/10940] ---- BYOL Training Loss = 0.2803918421268463
30-01-2023 23:13:21 INFO Epoch 3: [9406/10940] ---- BYOL Training Loss = 0.26192617416381836
30-01-2023 23:13:39 INFO Epoch 3: [9417/10940] ---- BYOL Training Loss = 0.19250988960266113
30-01-2023 23:14:32 INFO Epoch 3: [9417/10940] ---- BYOL Validation Loss = 0.17897239327430725
30-01-2023 23:14:50 INFO Epoch 3: [9428/10940] ---- BYOL Training Loss = 0.2072996199131012
30-01-2023 23:15:08 INFO Epoch 3: [9439/10940] ---- BYOL Training Loss = 0.21882684528827667
30-01-2023 23:15:27 INFO Epoch 3: [9450/10940] ---- BYOL Training Loss = 0.2524285912513733
30-01-2023 23:15:46 INFO Epoch 3: [9461/10940] ---- BYOL Training Loss = 0.2753579020500183
30-01-2023 23:16:38 INFO Epoch 3: [9461/10940] ---- BYOL Validation Loss = 0.14575643837451935
30-01-2023 23:16:57 INFO Epoch 3: [9472/10940] ---- BYOL Training Loss = 0.25033214688301086
30-01-2023 23:17:15 INFO Epoch 3: [9483/10940] ---- BYOL Training Loss = 0.2430982142686844
30-01-2023 23:17:34 INFO Epoch 3: [9494/10940] ---- BYOL Training Loss = 0.22171969711780548
30-01-2023 23:17:52 INFO Epoch 3: [9505/10940] ---- BYOL Training Loss = 0.21424026787281036
30-01-2023 23:18:45 INFO Epoch 3: [9505/10940] ---- BYOL Validation Loss = 0.1683894246816635
30-01-2023 23:19:03 INFO Epoch 3: [9516/10940] ---- BYOL Training Loss = 0.1982562094926834
30-01-2023 23:19:22 INFO Epoch 3: [9527/10940] ---- BYOL Training Loss = 0.21399548649787903
30-01-2023 23:19:40 INFO Epoch 3: [9538/10940] ---- BYOL Training Loss = 0.26222413778305054
30-01-2023 23:19:59 INFO Epoch 3: [9549/10940] ---- BYOL Training Loss = 0.2710556387901306
30-01-2023 23:20:51 INFO Epoch 3: [9549/10940] ---- BYOL Validation Loss = 0.19906392693519592
30-01-2023 23:21:10 INFO Epoch 3: [9560/10940] ---- BYOL Training Loss = 0.2573246955871582
30-01-2023 23:21:28 INFO Epoch 3: [9571/10940] ---- BYOL Training Loss = 0.23671670258045197
30-01-2023 23:21:47 INFO Epoch 3: [9582/10940] ---- BYOL Training Loss = 0.22740530967712402
30-01-2023 23:22:05 INFO Epoch 3: [9593/10940] ---- BYOL Training Loss = 0.22846508026123047
30-01-2023 23:22:58 INFO Epoch 3: [9593/10940] ---- BYOL Validation Loss = 0.14274144172668457
30-01-2023 23:23:17 INFO Epoch 3: [9604/10940] ---- BYOL Training Loss = 0.19214962422847748
30-01-2023 23:23:35 INFO Epoch 3: [9615/10940] ---- BYOL Training Loss = 0.18193712830543518
30-01-2023 23:23:54 INFO Epoch 3: [9626/10940] ---- BYOL Training Loss = 0.18151333928108215
30-01-2023 23:24:13 INFO Epoch 3: [9637/10940] ---- BYOL Training Loss = 0.16372594237327576
30-01-2023 23:25:05 INFO Epoch 3: [9637/10940] ---- BYOL Validation Loss = 0.17301766574382782
30-01-2023 23:25:23 INFO Epoch 3: [9648/10940] ---- BYOL Training Loss = 0.16873785853385925
30-01-2023 23:25:42 INFO Epoch 3: [9659/10940] ---- BYOL Training Loss = 0.18113364279270172
30-01-2023 23:26:01 INFO Epoch 3: [9670/10940] ---- BYOL Training Loss = 0.2361404001712799
30-01-2023 23:26:19 INFO Epoch 3: [9681/10940] ---- BYOL Training Loss = 0.2869076132774353
30-01-2023 23:27:12 INFO Epoch 3: [9681/10940] ---- BYOL Validation Loss = 0.13200397789478302
30-01-2023 23:27:30 INFO Epoch 3: [9692/10940] ---- BYOL Training Loss = 0.22886934876441956
30-01-2023 23:27:49 INFO Epoch 3: [9703/10940] ---- BYOL Training Loss = 0.2253914177417755
30-01-2023 23:28:07 INFO Epoch 3: [9714/10940] ---- BYOL Training Loss = 0.24162104725837708
30-01-2023 23:28:26 INFO Epoch 3: [9725/10940] ---- BYOL Training Loss = 0.2733430564403534
30-01-2023 23:29:18 INFO Epoch 3: [9725/10940] ---- BYOL Validation Loss = 0.16029612720012665
30-01-2023 23:29:36 INFO Epoch 3: [9736/10940] ---- BYOL Training Loss = 0.2670834958553314
30-01-2023 23:29:55 INFO Epoch 3: [9747/10940] ---- BYOL Training Loss = 0.22555367648601532
30-01-2023 23:30:14 INFO Epoch 3: [9758/10940] ---- BYOL Training Loss = 0.26353341341018677
30-01-2023 23:30:32 INFO Epoch 3: [9769/10940] ---- BYOL Training Loss = 0.2993938624858856
30-01-2023 23:31:25 INFO Epoch 3: [9769/10940] ---- BYOL Validation Loss = 0.16344566643238068
30-01-2023 23:31:43 INFO Epoch 3: [9780/10940] ---- BYOL Training Loss = 0.24881450831890106
30-01-2023 23:32:02 INFO Epoch 3: [9791/10940] ---- BYOL Training Loss = 0.22814972698688507
30-01-2023 23:32:20 INFO Epoch 3: [9802/10940] ---- BYOL Training Loss = 0.233050137758255
30-01-2023 23:32:39 INFO Epoch 3: [9813/10940] ---- BYOL Training Loss = 0.2272402048110962
30-01-2023 23:33:31 INFO Epoch 3: [9813/10940] ---- BYOL Validation Loss = 0.13938675820827484
30-01-2023 23:33:50 INFO Epoch 3: [9824/10940] ---- BYOL Training Loss = 0.21311140060424805
30-01-2023 23:34:08 INFO Epoch 3: [9835/10940] ---- BYOL Training Loss = 0.2717168629169464
30-01-2023 23:34:27 INFO Epoch 3: [9846/10940] ---- BYOL Training Loss = 0.2385111153125763
30-01-2023 23:34:45 INFO Epoch 3: [9857/10940] ---- BYOL Training Loss = 0.22067220509052277
30-01-2023 23:35:38 INFO Epoch 3: [9857/10940] ---- BYOL Validation Loss = 0.1378535032272339
30-01-2023 23:35:56 INFO Epoch 3: [9868/10940] ---- BYOL Training Loss = 0.2266463041305542
30-01-2023 23:36:15 INFO Epoch 3: [9879/10940] ---- BYOL Training Loss = 0.22855913639068604
30-01-2023 23:36:33 INFO Epoch 3: [9890/10940] ---- BYOL Training Loss = 0.1829240471124649
30-01-2023 23:36:52 INFO Epoch 3: [9901/10940] ---- BYOL Training Loss = 0.19561198353767395
30-01-2023 23:37:45 INFO Epoch 3: [9901/10940] ---- BYOL Validation Loss = 0.14002282917499542
30-01-2023 23:38:03 INFO Epoch 3: [9912/10940] ---- BYOL Training Loss = 0.21620742976665497
30-01-2023 23:38:21 INFO Epoch 3: [9923/10940] ---- BYOL Training Loss = 0.18784621357917786
30-01-2023 23:38:40 INFO Epoch 3: [9934/10940] ---- BYOL Training Loss = 0.18816907703876495
30-01-2023 23:38:58 INFO Epoch 3: [9945/10940] ---- BYOL Training Loss = 0.1894424855709076
30-01-2023 23:39:51 INFO Epoch 3: [9945/10940] ---- BYOL Validation Loss = 0.14837850630283356
30-01-2023 23:40:10 INFO Epoch 3: [9956/10940] ---- BYOL Training Loss = 0.20967388153076172
30-01-2023 23:40:28 INFO Epoch 3: [9967/10940] ---- BYOL Training Loss = 0.19569261372089386
30-01-2023 23:40:47 INFO Epoch 3: [9978/10940] ---- BYOL Training Loss = 0.29979151487350464
30-01-2023 23:41:05 INFO Epoch 3: [9989/10940] ---- BYOL Training Loss = 0.3059740662574768
30-01-2023 23:41:58 INFO Epoch 3: [9989/10940] ---- BYOL Validation Loss = 0.15349243581295013
30-01-2023 23:42:16 INFO Epoch 3: [10000/10940] ---- BYOL Training Loss = 0.2496030628681183
30-01-2023 23:42:35 INFO Epoch 3: [10011/10940] ---- BYOL Training Loss = 0.2574741840362549
30-01-2023 23:42:53 INFO Epoch 3: [10022/10940] ---- BYOL Training Loss = 0.3427451550960541
30-01-2023 23:43:12 INFO Epoch 3: [10033/10940] ---- BYOL Training Loss = 0.33366942405700684
30-01-2023 23:44:05 INFO Epoch 3: [10033/10940] ---- BYOL Validation Loss = 0.11965321004390717
30-01-2023 23:44:23 INFO Epoch 3: [10044/10940] ---- BYOL Training Loss = 0.23155279457569122
30-01-2023 23:44:42 INFO Epoch 3: [10055/10940] ---- BYOL Training Loss = 0.3098750114440918
30-01-2023 23:45:00 INFO Epoch 3: [10066/10940] ---- BYOL Training Loss = 0.34230202436447144
30-01-2023 23:45:19 INFO Epoch 3: [10077/10940] ---- BYOL Training Loss = 0.3079145550727844
30-01-2023 23:46:11 INFO Epoch 3: [10077/10940] ---- BYOL Validation Loss = 0.1480945497751236
30-01-2023 23:46:29 INFO Epoch 3: [10088/10940] ---- BYOL Training Loss = 0.24059076607227325
30-01-2023 23:46:48 INFO Epoch 3: [10099/10940] ---- BYOL Training Loss = 0.20929107069969177
30-01-2023 23:47:07 INFO Epoch 3: [10110/10940] ---- BYOL Training Loss = 0.20379790663719177
30-01-2023 23:47:25 INFO Epoch 3: [10121/10940] ---- BYOL Training Loss = 0.2886616587638855
30-01-2023 23:48:18 INFO Epoch 3: [10121/10940] ---- BYOL Validation Loss = 0.15439997613430023
30-01-2023 23:48:36 INFO Epoch 3: [10132/10940] ---- BYOL Training Loss = 0.3660239279270172
30-01-2023 23:48:55 INFO Epoch 3: [10143/10940] ---- BYOL Training Loss = 0.26765623688697815
30-01-2023 23:49:14 INFO Epoch 3: [10154/10940] ---- BYOL Training Loss = 0.21638719737529755
30-01-2023 23:49:33 INFO Epoch 3: [10165/10940] ---- BYOL Training Loss = 0.22317039966583252
30-01-2023 23:50:25 INFO Epoch 3: [10165/10940] ---- BYOL Validation Loss = 0.1380288302898407
30-01-2023 23:50:43 INFO Epoch 3: [10176/10940] ---- BYOL Training Loss = 0.24773958325386047
30-01-2023 23:51:02 INFO Epoch 3: [10187/10940] ---- BYOL Training Loss = 0.25083547830581665
30-01-2023 23:51:21 INFO Epoch 3: [10198/10940] ---- BYOL Training Loss = 0.25058332085609436
30-01-2023 23:51:39 INFO Epoch 3: [10209/10940] ---- BYOL Training Loss = 0.2207287847995758
30-01-2023 23:52:32 INFO Epoch 3: [10209/10940] ---- BYOL Validation Loss = 0.14499728381633759
30-01-2023 23:52:50 INFO Epoch 3: [10220/10940] ---- BYOL Training Loss = 0.19237332046031952
30-01-2023 23:53:08 INFO Epoch 3: [10231/10940] ---- BYOL Training Loss = 0.19247040152549744
30-01-2023 23:53:27 INFO Epoch 3: [10242/10940] ---- BYOL Training Loss = 0.1768120378255844
30-01-2023 23:53:46 INFO Epoch 3: [10253/10940] ---- BYOL Training Loss = 0.21891584992408752
30-01-2023 23:54:38 INFO Epoch 3: [10253/10940] ---- BYOL Validation Loss = 0.14103582501411438
30-01-2023 23:54:57 INFO Epoch 3: [10264/10940] ---- BYOL Training Loss = 0.22161853313446045
30-01-2023 23:55:15 INFO Epoch 3: [10275/10940] ---- BYOL Training Loss = 0.17850111424922943
30-01-2023 23:55:33 INFO Epoch 3: [10286/10940] ---- BYOL Training Loss = 0.22180144488811493
30-01-2023 23:55:52 INFO Epoch 3: [10297/10940] ---- BYOL Training Loss = 0.2584037780761719
30-01-2023 23:56:45 INFO Epoch 3: [10297/10940] ---- BYOL Validation Loss = 0.1377808302640915
30-01-2023 23:57:03 INFO Epoch 3: [10308/10940] ---- BYOL Training Loss = 0.2724836468696594
30-01-2023 23:57:22 INFO Epoch 3: [10319/10940] ---- BYOL Training Loss = 0.21473856270313263
30-01-2023 23:57:41 INFO Epoch 3: [10330/10940] ---- BYOL Training Loss = 0.1603887975215912
30-01-2023 23:58:00 INFO Epoch 3: [10341/10940] ---- BYOL Training Loss = 0.19826513528823853
30-01-2023 23:58:52 INFO Epoch 3: [10341/10940] ---- BYOL Validation Loss = 0.1250738650560379
30-01-2023 23:59:10 INFO Epoch 3: [10352/10940] ---- BYOL Training Loss = 0.2721179127693176
30-01-2023 23:59:29 INFO Epoch 3: [10363/10940] ---- BYOL Training Loss = 0.23764567077159882
30-01-2023 23:59:48 INFO Epoch 3: [10374/10940] ---- BYOL Training Loss = 0.2109462022781372
31-01-2023 00:00:06 INFO Epoch 3: [10385/10940] ---- BYOL Training Loss = 0.21317553520202637
slurmstepd-landonia23: error: _get_joules_task: received 0 sensors, 3 expected
31-01-2023 00:00:59 INFO Epoch 3: [10385/10940] ---- BYOL Validation Loss = 0.12654824554920197
31-01-2023 00:01:17 INFO Epoch 3: [10396/10940] ---- BYOL Training Loss = 0.19842414557933807
31-01-2023 00:01:36 INFO Epoch 3: [10407/10940] ---- BYOL Training Loss = 0.23243281245231628
31-01-2023 00:01:55 INFO Epoch 3: [10418/10940] ---- BYOL Training Loss = 0.2505945563316345
31-01-2023 00:02:13 INFO Epoch 3: [10429/10940] ---- BYOL Training Loss = 0.21409101784229279
31-01-2023 00:03:06 INFO Epoch 3: [10429/10940] ---- BYOL Validation Loss = 0.12183240801095963
31-01-2023 00:03:24 INFO Epoch 3: [10440/10940] ---- BYOL Training Loss = 0.2070656716823578
31-01-2023 00:03:43 INFO Epoch 3: [10451/10940] ---- BYOL Training Loss = 0.2119775116443634
31-01-2023 00:04:01 INFO Epoch 3: [10462/10940] ---- BYOL Training Loss = 0.20946410298347473
31-01-2023 00:04:20 INFO Epoch 3: [10473/10940] ---- BYOL Training Loss = 0.2295650690793991
31-01-2023 00:05:13 INFO Epoch 3: [10473/10940] ---- BYOL Validation Loss = 0.11107517778873444
31-01-2023 00:05:31 INFO Epoch 3: [10484/10940] ---- BYOL Training Loss = 0.22077539563179016
31-01-2023 00:05:50 INFO Epoch 3: [10495/10940] ---- BYOL Training Loss = 0.27782750129699707
31-01-2023 00:06:08 INFO Epoch 3: [10506/10940] ---- BYOL Training Loss = 0.25433823466300964
31-01-2023 00:06:27 INFO Epoch 3: [10517/10940] ---- BYOL Training Loss = 0.2603451609611511
31-01-2023 00:07:20 INFO Epoch 3: [10517/10940] ---- BYOL Validation Loss = 0.09243900328874588
31-01-2023 00:07:38 INFO Epoch 3: [10528/10940] ---- BYOL Training Loss = 0.23228082060813904
31-01-2023 00:07:56 INFO Epoch 3: [10539/10940] ---- BYOL Training Loss = 0.20570878684520721
31-01-2023 00:08:15 INFO Epoch 3: [10550/10940] ---- BYOL Training Loss = 0.21558353304862976
31-01-2023 00:08:34 INFO Epoch 3: [10561/10940] ---- BYOL Training Loss = 0.20882824063301086
31-01-2023 00:09:26 INFO Epoch 3: [10561/10940] ---- BYOL Validation Loss = 0.10251142084598541
31-01-2023 00:09:45 INFO Epoch 3: [10572/10940] ---- BYOL Training Loss = 0.27132871747016907
31-01-2023 00:10:03 INFO Epoch 3: [10583/10940] ---- BYOL Training Loss = 0.2672826647758484
31-01-2023 00:10:22 INFO Epoch 3: [10594/10940] ---- BYOL Training Loss = 0.19399550557136536
31-01-2023 00:10:41 INFO Epoch 3: [10605/10940] ---- BYOL Training Loss = 0.17706453800201416
31-01-2023 00:11:34 INFO Epoch 3: [10605/10940] ---- BYOL Validation Loss = 0.09223419427871704
31-01-2023 00:11:52 INFO Epoch 3: [10616/10940] ---- BYOL Training Loss = 0.2182123214006424
31-01-2023 00:12:11 INFO Epoch 3: [10627/10940] ---- BYOL Training Loss = 0.1929687112569809
31-01-2023 00:12:30 INFO Epoch 3: [10638/10940] ---- BYOL Training Loss = 0.1628626435995102
31-01-2023 00:12:48 INFO Epoch 3: [10649/10940] ---- BYOL Training Loss = 0.2692018747329712
31-01-2023 00:13:41 INFO Epoch 3: [10649/10940] ---- BYOL Validation Loss = 0.13738217949867249
31-01-2023 00:13:59 INFO Epoch 3: [10660/10940] ---- BYOL Training Loss = 0.2844523787498474
31-01-2023 00:14:18 INFO Epoch 3: [10671/10940] ---- BYOL Training Loss = 0.23943603038787842
31-01-2023 00:14:36 INFO Epoch 3: [10682/10940] ---- BYOL Training Loss = 0.31665894389152527
31-01-2023 00:14:55 INFO Epoch 3: [10693/10940] ---- BYOL Training Loss = 0.22304272651672363
31-01-2023 00:15:48 INFO Epoch 3: [10693/10940] ---- BYOL Validation Loss = 0.0795692577958107
31-01-2023 00:16:06 INFO Epoch 3: [10704/10940] ---- BYOL Training Loss = 0.27932262420654297
31-01-2023 00:16:25 INFO Epoch 3: [10715/10940] ---- BYOL Training Loss = 0.33160123229026794
31-01-2023 00:16:44 INFO Epoch 3: [10726/10940] ---- BYOL Training Loss = 0.37450820207595825
31-01-2023 00:17:02 INFO Epoch 3: [10737/10940] ---- BYOL Training Loss = 0.32065799832344055
31-01-2023 00:17:55 INFO Epoch 3: [10737/10940] ---- BYOL Validation Loss = 0.19239534437656403
31-01-2023 00:18:13 INFO Epoch 3: [10748/10940] ---- BYOL Training Loss = 0.24362924695014954
31-01-2023 00:18:32 INFO Epoch 3: [10759/10940] ---- BYOL Training Loss = 0.24735967814922333
31-01-2023 00:18:51 INFO Epoch 3: [10770/10940] ---- BYOL Training Loss = 0.2453422099351883
31-01-2023 00:19:09 INFO Epoch 3: [10781/10940] ---- BYOL Training Loss = 0.202992245554924
31-01-2023 00:20:02 INFO Epoch 3: [10781/10940] ---- BYOL Validation Loss = 0.16305793821811676
31-01-2023 00:20:20 INFO Epoch 3: [10792/10940] ---- BYOL Training Loss = 0.1479407697916031
31-01-2023 00:20:39 INFO Epoch 3: [10803/10940] ---- BYOL Training Loss = 0.15569671988487244
31-01-2023 00:20:58 INFO Epoch 3: [10814/10940] ---- BYOL Training Loss = 0.2189321219921112
31-01-2023 00:21:16 INFO Epoch 3: [10825/10940] ---- BYOL Training Loss = 0.1710491180419922
31-01-2023 00:22:09 INFO Epoch 3: [10825/10940] ---- BYOL Validation Loss = 0.14615477621555328
31-01-2023 00:22:28 INFO Epoch 3: [10836/10940] ---- BYOL Training Loss = 0.17315922677516937
31-01-2023 00:22:46 INFO Epoch 3: [10847/10940] ---- BYOL Training Loss = 0.20491662621498108
31-01-2023 00:23:05 INFO Epoch 3: [10858/10940] ---- BYOL Training Loss = 0.20652517676353455
31-01-2023 00:23:24 INFO Epoch 3: [10869/10940] ---- BYOL Training Loss = 0.15471519529819489
31-01-2023 00:24:16 INFO Epoch 3: [10869/10940] ---- BYOL Validation Loss = 0.1287596970796585
31-01-2023 00:24:34 INFO Epoch 3: [10880/10940] ---- BYOL Training Loss = 0.21576862037181854
31-01-2023 00:24:53 INFO Epoch 3: [10891/10940] ---- BYOL Training Loss = 0.2212517261505127
31-01-2023 00:25:12 INFO Epoch 3: [10902/10940] ---- BYOL Training Loss = 0.1940513700246811
31-01-2023 00:25:31 INFO Epoch 3: [10913/10940] ---- BYOL Training Loss = 0.1637917459011078
31-01-2023 00:26:23 INFO Epoch 3: [10913/10940] ---- BYOL Validation Loss = 0.1356419026851654
31-01-2023 00:26:42 INFO Epoch 3: [10924/10940] ---- BYOL Training Loss = 0.17216335237026215
31-01-2023 00:27:01 INFO Epoch 3: [10935/10940] ---- BYOL Training Loss = 0.18514594435691833
31-01-2023 00:27:10 INFO Starting Epoch: 4
31-01-2023 00:27:28 INFO Epoch 4: [12/10940] ---- BYOL Training Loss = 0.14029711484909058
31-01-2023 00:27:45 INFO Epoch 4: [23/10940] ---- BYOL Training Loss = 0.14454878866672516
31-01-2023 00:28:03 INFO Epoch 4: [34/10940] ---- BYOL Training Loss = 0.17519225180149078
31-01-2023 00:28:21 INFO Epoch 4: [45/10940] ---- BYOL Training Loss = 0.22206135094165802
31-01-2023 00:29:13 INFO Epoch 4: [45/10940] ---- BYOL Validation Loss = 0.13016246259212494
31-01-2023 00:29:30 INFO Epoch 4: [56/10940] ---- BYOL Training Loss = 0.20406091213226318
31-01-2023 00:29:48 INFO Epoch 4: [67/10940] ---- BYOL Training Loss = 0.16842828691005707
31-01-2023 00:30:05 INFO Epoch 4: [78/10940] ---- BYOL Training Loss = 0.17206628620624542
31-01-2023 00:30:23 INFO Epoch 4: [89/10940] ---- BYOL Training Loss = 0.2296619713306427
31-01-2023 00:31:16 INFO Epoch 4: [89/10940] ---- BYOL Validation Loss = 0.15078552067279816
31-01-2023 00:31:33 INFO Epoch 4: [100/10940] ---- BYOL Training Loss = 0.25558727979660034
31-01-2023 00:31:51 INFO Epoch 4: [111/10940] ---- BYOL Training Loss = 0.2105562388896942
31-01-2023 00:32:08 INFO Epoch 4: [122/10940] ---- BYOL Training Loss = 0.19842009246349335
31-01-2023 00:32:26 INFO Epoch 4: [133/10940] ---- BYOL Training Loss = 0.22073249518871307
31-01-2023 00:33:18 INFO Epoch 4: [133/10940] ---- BYOL Validation Loss = 0.1781204789876938
31-01-2023 00:33:35 INFO Epoch 4: [144/10940] ---- BYOL Training Loss = 0.2508348226547241
31-01-2023 00:33:53 INFO Epoch 4: [155/10940] ---- BYOL Training Loss = 0.20510521531105042
31-01-2023 00:34:11 INFO Epoch 4: [166/10940] ---- BYOL Training Loss = 0.17582425475120544
31-01-2023 00:34:28 INFO Epoch 4: [177/10940] ---- BYOL Training Loss = 0.17593127489089966
31-01-2023 00:35:21 INFO Epoch 4: [177/10940] ---- BYOL Validation Loss = 0.14445659518241882
31-01-2023 00:35:38 INFO Epoch 4: [188/10940] ---- BYOL Training Loss = 0.18808728456497192
31-01-2023 00:35:56 INFO Epoch 4: [199/10940] ---- BYOL Training Loss = 0.19482240080833435
31-01-2023 00:36:13 INFO Epoch 4: [210/10940] ---- BYOL Training Loss = 0.18318085372447968
31-01-2023 00:36:31 INFO Epoch 4: [221/10940] ---- BYOL Training Loss = 0.1787523329257965
31-01-2023 00:37:24 INFO Epoch 4: [221/10940] ---- BYOL Validation Loss = 0.18186815083026886
31-01-2023 00:37:41 INFO Epoch 4: [232/10940] ---- BYOL Training Loss = 0.24410629272460938
31-01-2023 00:37:58 INFO Epoch 4: [243/10940] ---- BYOL Training Loss = 0.21321530640125275
31-01-2023 00:38:16 INFO Epoch 4: [254/10940] ---- BYOL Training Loss = 0.17406539618968964
31-01-2023 00:38:34 INFO Epoch 4: [265/10940] ---- BYOL Training Loss = 0.17452868819236755
31-01-2023 00:39:26 INFO Epoch 4: [265/10940] ---- BYOL Validation Loss = 0.14290332794189453
31-01-2023 00:39:43 INFO Epoch 4: [276/10940] ---- BYOL Training Loss = 0.1652703434228897
31-01-2023 00:40:01 INFO Epoch 4: [287/10940] ---- BYOL Training Loss = 0.18183951079845428
31-01-2023 00:40:18 INFO Epoch 4: [298/10940] ---- BYOL Training Loss = 0.1731065958738327
31-01-2023 00:40:36 INFO Epoch 4: [309/10940] ---- BYOL Training Loss = 0.20209035277366638
31-01-2023 00:41:29 INFO Epoch 4: [309/10940] ---- BYOL Validation Loss = 0.15998683869838715
31-01-2023 00:41:46 INFO Epoch 4: [320/10940] ---- BYOL Training Loss = 0.24780873954296112
31-01-2023 00:42:04 INFO Epoch 4: [331/10940] ---- BYOL Training Loss = 0.22497233748435974
31-01-2023 00:42:21 INFO Epoch 4: [342/10940] ---- BYOL Training Loss = 0.23141595721244812
31-01-2023 00:42:39 INFO Epoch 4: [353/10940] ---- BYOL Training Loss = 0.20692701637744904
31-01-2023 00:43:31 INFO Epoch 4: [353/10940] ---- BYOL Validation Loss = 0.1525665819644928
31-01-2023 00:43:49 INFO Epoch 4: [364/10940] ---- BYOL Training Loss = 0.20598776638507843
31-01-2023 00:44:06 INFO Epoch 4: [375/10940] ---- BYOL Training Loss = 0.18957968056201935
31-01-2023 00:44:24 INFO Epoch 4: [386/10940] ---- BYOL Training Loss = 0.1880318820476532
31-01-2023 00:44:41 INFO Epoch 4: [397/10940] ---- BYOL Training Loss = 0.24383148550987244
31-01-2023 00:45:34 INFO Epoch 4: [397/10940] ---- BYOL Validation Loss = 0.1513374298810959
31-01-2023 00:45:51 INFO Epoch 4: [408/10940] ---- BYOL Training Loss = 0.20632031559944153
31-01-2023 00:46:09 INFO Epoch 4: [419/10940] ---- BYOL Training Loss = 0.2086549550294876
31-01-2023 00:46:26 INFO Epoch 4: [430/10940] ---- BYOL Training Loss = 0.19736257195472717
31-01-2023 00:46:44 INFO Epoch 4: [441/10940] ---- BYOL Training Loss = 0.17112502455711365
31-01-2023 00:47:36 INFO Epoch 4: [441/10940] ---- BYOL Validation Loss = 0.10290247201919556
31-01-2023 00:47:54 INFO Epoch 4: [452/10940] ---- BYOL Training Loss = 0.17299513518810272
31-01-2023 00:48:11 INFO Epoch 4: [463/10940] ---- BYOL Training Loss = 0.18014299869537354
31-01-2023 00:48:29 INFO Epoch 4: [474/10940] ---- BYOL Training Loss = 0.15945762395858765
31-01-2023 00:48:46 INFO Epoch 4: [485/10940] ---- BYOL Training Loss = 0.18689042329788208
31-01-2023 00:49:39 INFO Epoch 4: [485/10940] ---- BYOL Validation Loss = 0.15082727372646332
31-01-2023 00:49:56 INFO Epoch 4: [496/10940] ---- BYOL Training Loss = 0.18191751837730408
31-01-2023 00:50:13 INFO Epoch 4: [507/10940] ---- BYOL Training Loss = 0.14319570362567902
31-01-2023 00:50:31 INFO Epoch 4: [518/10940] ---- BYOL Training Loss = 0.23584973812103271
31-01-2023 00:50:48 INFO Epoch 4: [529/10940] ---- BYOL Training Loss = 0.19658945500850677
31-01-2023 00:51:41 INFO Epoch 4: [529/10940] ---- BYOL Validation Loss = 0.11586793512105942
31-01-2023 00:51:58 INFO Epoch 4: [540/10940] ---- BYOL Training Loss = 0.22077524662017822
31-01-2023 00:52:16 INFO Epoch 4: [551/10940] ---- BYOL Training Loss = 0.23623120784759521
31-01-2023 00:52:33 INFO Epoch 4: [562/10940] ---- BYOL Training Loss = 0.16980597376823425
31-01-2023 00:52:51 INFO Epoch 4: [573/10940] ---- BYOL Training Loss = 0.17507709562778473
31-01-2023 00:53:44 INFO Epoch 4: [573/10940] ---- BYOL Validation Loss = 0.1653801053762436
31-01-2023 00:54:01 INFO Epoch 4: [584/10940] ---- BYOL Training Loss = 0.19908174872398376
31-01-2023 00:54:18 INFO Epoch 4: [595/10940] ---- BYOL Training Loss = 0.22279158234596252
31-01-2023 00:54:36 INFO Epoch 4: [606/10940] ---- BYOL Training Loss = 0.24460813403129578
31-01-2023 00:54:54 INFO Epoch 4: [617/10940] ---- BYOL Training Loss = 0.22023756802082062
31-01-2023 00:55:46 INFO Epoch 4: [617/10940] ---- BYOL Validation Loss = 0.15620017051696777
31-01-2023 00:56:03 INFO Epoch 4: [628/10940] ---- BYOL Training Loss = 0.21151337027549744
31-01-2023 00:56:21 INFO Epoch 4: [639/10940] ---- BYOL Training Loss = 0.19208256900310516
31-01-2023 00:56:39 INFO Epoch 4: [650/10940] ---- BYOL Training Loss = 0.14129814505577087
31-01-2023 00:56:56 INFO Epoch 4: [661/10940] ---- BYOL Training Loss = 0.16744425892829895
31-01-2023 00:57:49 INFO Epoch 4: [661/10940] ---- BYOL Validation Loss = 0.15108411014080048
31-01-2023 00:58:06 INFO Epoch 4: [672/10940] ---- BYOL Training Loss = 0.2247321903705597
31-01-2023 00:58:24 INFO Epoch 4: [683/10940] ---- BYOL Training Loss = 0.22247949242591858
31-01-2023 00:58:41 INFO Epoch 4: [694/10940] ---- BYOL Training Loss = 0.19599944353103638
31-01-2023 00:58:59 INFO Epoch 4: [705/10940] ---- BYOL Training Loss = 0.20759248733520508
31-01-2023 00:59:52 INFO Epoch 4: [705/10940] ---- BYOL Validation Loss = 0.18184849619865417
31-01-2023 01:00:09 INFO Epoch 4: [716/10940] ---- BYOL Training Loss = 0.20514576137065887
31-01-2023 01:00:26 INFO Epoch 4: [727/10940] ---- BYOL Training Loss = 0.19639834761619568
31-01-2023 01:00:44 INFO Epoch 4: [738/10940] ---- BYOL Training Loss = 0.184167742729187
31-01-2023 01:01:02 INFO Epoch 4: [749/10940] ---- BYOL Training Loss = 0.15342745184898376
31-01-2023 01:01:54 INFO Epoch 4: [749/10940] ---- BYOL Validation Loss = 0.16142423450946808
31-01-2023 01:02:12 INFO Epoch 4: [760/10940] ---- BYOL Training Loss = 0.16177159547805786
31-01-2023 01:02:29 INFO Epoch 4: [771/10940] ---- BYOL Training Loss = 0.21708926558494568
31-01-2023 01:02:47 INFO Epoch 4: [782/10940] ---- BYOL Training Loss = 0.22055086493492126
31-01-2023 01:03:04 INFO Epoch 4: [793/10940] ---- BYOL Training Loss = 0.21090158820152283
31-01-2023 01:03:57 INFO Epoch 4: [793/10940] ---- BYOL Validation Loss = 0.16688476502895355
31-01-2023 01:04:14 INFO Epoch 4: [804/10940] ---- BYOL Training Loss = 0.166892409324646
31-01-2023 01:04:32 INFO Epoch 4: [815/10940] ---- BYOL Training Loss = 0.1946074515581131
31-01-2023 01:04:49 INFO Epoch 4: [826/10940] ---- BYOL Training Loss = 0.19890858232975006
31-01-2023 01:05:07 INFO Epoch 4: [837/10940] ---- BYOL Training Loss = 0.19703656435012817
31-01-2023 01:06:00 INFO Epoch 4: [837/10940] ---- BYOL Validation Loss = 0.18255257606506348
31-01-2023 01:06:17 INFO Epoch 4: [848/10940] ---- BYOL Training Loss = 0.19232547283172607
31-01-2023 01:06:35 INFO Epoch 4: [859/10940] ---- BYOL Training Loss = 0.19126610457897186
31-01-2023 01:06:52 INFO Epoch 4: [870/10940] ---- BYOL Training Loss = 0.23514270782470703
31-01-2023 01:07:10 INFO Epoch 4: [881/10940] ---- BYOL Training Loss = 0.18772311508655548
31-01-2023 01:08:03 INFO Epoch 4: [881/10940] ---- BYOL Validation Loss = 0.1694003790616989
31-01-2023 01:08:20 INFO Epoch 4: [892/10940] ---- BYOL Training Loss = 0.20448879897594452
31-01-2023 01:08:37 INFO Epoch 4: [903/10940] ---- BYOL Training Loss = 0.18941140174865723
31-01-2023 01:08:55 INFO Epoch 4: [914/10940] ---- BYOL Training Loss = 0.165062814950943
31-01-2023 01:09:13 INFO Epoch 4: [925/10940] ---- BYOL Training Loss = 0.1574084311723709
31-01-2023 01:10:06 INFO Epoch 4: [925/10940] ---- BYOL Validation Loss = 0.17410072684288025
31-01-2023 01:10:23 INFO Epoch 4: [936/10940] ---- BYOL Training Loss = 0.18512187898159027
31-01-2023 01:10:41 INFO Epoch 4: [947/10940] ---- BYOL Training Loss = 0.19366417825222015
31-01-2023 01:10:58 INFO Epoch 4: [958/10940] ---- BYOL Training Loss = 0.18079854547977448
31-01-2023 01:11:16 INFO Epoch 4: [969/10940] ---- BYOL Training Loss = 0.18550129234790802
31-01-2023 01:12:08 INFO Epoch 4: [969/10940] ---- BYOL Validation Loss = 0.16296222805976868
31-01-2023 01:12:26 INFO Epoch 4: [980/10940] ---- BYOL Training Loss = 0.168747216463089
31-01-2023 01:12:43 INFO Epoch 4: [991/10940] ---- BYOL Training Loss = 0.16950877010822296
31-01-2023 01:13:01 INFO Epoch 4: [1002/10940] ---- BYOL Training Loss = 0.17232796549797058
31-01-2023 01:13:18 INFO Epoch 4: [1013/10940] ---- BYOL Training Loss = 0.1595231592655182
31-01-2023 01:14:11 INFO Epoch 4: [1013/10940] ---- BYOL Validation Loss = 0.13979285955429077
31-01-2023 01:14:28 INFO Epoch 4: [1024/10940] ---- BYOL Training Loss = 0.1424790322780609
31-01-2023 01:14:46 INFO Epoch 4: [1035/10940] ---- BYOL Training Loss = 0.1704198271036148
31-01-2023 01:15:04 INFO Epoch 4: [1046/10940] ---- BYOL Training Loss = 0.16193051636219025
31-01-2023 01:15:21 INFO Epoch 4: [1057/10940] ---- BYOL Training Loss = 0.14736886322498322
31-01-2023 01:16:14 INFO Epoch 4: [1057/10940] ---- BYOL Validation Loss = 0.11388908326625824
31-01-2023 01:16:31 INFO Epoch 4: [1068/10940] ---- BYOL Training Loss = 0.1597266048192978
31-01-2023 01:16:49 INFO Epoch 4: [1079/10940] ---- BYOL Training Loss = 0.16347424685955048
31-01-2023 01:17:06 INFO Epoch 4: [1090/10940] ---- BYOL Training Loss = 0.16865037381649017
31-01-2023 01:17:24 INFO Epoch 4: [1101/10940] ---- BYOL Training Loss = 0.24547438323497772
31-01-2023 01:18:16 INFO Epoch 4: [1101/10940] ---- BYOL Validation Loss = 0.13347242772579193
31-01-2023 01:18:34 INFO Epoch 4: [1112/10940] ---- BYOL Training Loss = 0.2514311969280243
31-01-2023 01:18:51 INFO Epoch 4: [1123/10940] ---- BYOL Training Loss = 0.16901899874210358
31-01-2023 01:19:09 INFO Epoch 4: [1134/10940] ---- BYOL Training Loss = 0.14584478735923767
31-01-2023 01:19:27 INFO Epoch 4: [1145/10940] ---- BYOL Training Loss = 0.2545217275619507
31-01-2023 01:20:19 INFO Epoch 4: [1145/10940] ---- BYOL Validation Loss = 0.13798664510250092
31-01-2023 01:20:37 INFO Epoch 4: [1156/10940] ---- BYOL Training Loss = 0.2832799553871155
31-01-2023 01:20:54 INFO Epoch 4: [1167/10940] ---- BYOL Training Loss = 0.18213418126106262
31-01-2023 01:21:12 INFO Epoch 4: [1178/10940] ---- BYOL Training Loss = 0.21821407973766327
31-01-2023 01:21:30 INFO Epoch 4: [1189/10940] ---- BYOL Training Loss = 0.21908660233020782
31-01-2023 01:22:23 INFO Epoch 4: [1189/10940] ---- BYOL Validation Loss = 0.17103390395641327
31-01-2023 01:22:40 INFO Epoch 4: [1200/10940] ---- BYOL Training Loss = 0.20590758323669434
31-01-2023 01:22:57 INFO Epoch 4: [1211/10940] ---- BYOL Training Loss = 0.21599309146404266
31-01-2023 01:23:15 INFO Epoch 4: [1222/10940] ---- BYOL Training Loss = 0.1914026439189911
31-01-2023 01:23:33 INFO Epoch 4: [1233/10940] ---- BYOL Training Loss = 0.1753768026828766
31-01-2023 01:24:26 INFO Epoch 4: [1233/10940] ---- BYOL Validation Loss = 0.15679071843624115
31-01-2023 01:24:43 INFO Epoch 4: [1244/10940] ---- BYOL Training Loss = 0.1501971185207367
31-01-2023 01:25:01 INFO Epoch 4: [1255/10940] ---- BYOL Training Loss = 0.14446595311164856
31-01-2023 01:25:18 INFO Epoch 4: [1266/10940] ---- BYOL Training Loss = 0.14018739759922028
31-01-2023 01:25:36 INFO Epoch 4: [1277/10940] ---- BYOL Training Loss = 0.2136763632297516
31-01-2023 01:26:29 INFO Epoch 4: [1277/10940] ---- BYOL Validation Loss = 0.1674194037914276
31-01-2023 01:26:46 INFO Epoch 4: [1288/10940] ---- BYOL Training Loss = 0.2551003396511078
31-01-2023 01:27:04 INFO Epoch 4: [1299/10940] ---- BYOL Training Loss = 0.2053491771221161
31-01-2023 01:27:21 INFO Epoch 4: [1310/10940] ---- BYOL Training Loss = 0.17927762866020203
31-01-2023 01:27:39 INFO Epoch 4: [1321/10940] ---- BYOL Training Loss = 0.17766383290290833
31-01-2023 01:28:32 INFO Epoch 4: [1321/10940] ---- BYOL Validation Loss = 0.1659518927335739
31-01-2023 01:28:49 INFO Epoch 4: [1332/10940] ---- BYOL Training Loss = 0.1863885223865509
31-01-2023 01:29:06 INFO Epoch 4: [1343/10940] ---- BYOL Training Loss = 0.19503149390220642
31-01-2023 01:29:24 INFO Epoch 4: [1354/10940] ---- BYOL Training Loss = 0.17514294385910034
31-01-2023 01:29:42 INFO Epoch 4: [1365/10940] ---- BYOL Training Loss = 0.20375819504261017
31-01-2023 01:30:34 INFO Epoch 4: [1365/10940] ---- BYOL Validation Loss = 0.176128551363945
31-01-2023 01:30:52 INFO Epoch 4: [1376/10940] ---- BYOL Training Loss = 0.20306876301765442
31-01-2023 01:31:09 INFO Epoch 4: [1387/10940] ---- BYOL Training Loss = 0.14219997823238373
31-01-2023 01:31:27 INFO Epoch 4: [1398/10940] ---- BYOL Training Loss = 0.14403526484966278
31-01-2023 01:31:45 INFO Epoch 4: [1409/10940] ---- BYOL Training Loss = 0.21513080596923828
31-01-2023 01:32:37 INFO Epoch 4: [1409/10940] ---- BYOL Validation Loss = 0.17808835208415985
31-01-2023 01:32:55 INFO Epoch 4: [1420/10940] ---- BYOL Training Loss = 0.1792818009853363
31-01-2023 01:33:12 INFO Epoch 4: [1431/10940] ---- BYOL Training Loss = 0.14736786484718323
31-01-2023 01:33:30 INFO Epoch 4: [1442/10940] ---- BYOL Training Loss = 0.16480383276939392
31-01-2023 01:33:48 INFO Epoch 4: [1453/10940] ---- BYOL Training Loss = 0.20140282809734344
31-01-2023 01:34:41 INFO Epoch 4: [1453/10940] ---- BYOL Validation Loss = 0.14073272049427032
31-01-2023 01:34:58 INFO Epoch 4: [1464/10940] ---- BYOL Training Loss = 0.14788159728050232
31-01-2023 01:35:16 INFO Epoch 4: [1475/10940] ---- BYOL Training Loss = 0.18130014836788177
31-01-2023 01:35:33 INFO Epoch 4: [1486/10940] ---- BYOL Training Loss = 0.17222672700881958
31-01-2023 01:35:51 INFO Epoch 4: [1497/10940] ---- BYOL Training Loss = 0.17089127004146576
31-01-2023 01:36:44 INFO Epoch 4: [1497/10940] ---- BYOL Validation Loss = 0.14560018479824066
31-01-2023 01:37:01 INFO Epoch 4: [1508/10940] ---- BYOL Training Loss = 0.1935543715953827
31-01-2023 01:37:19 INFO Epoch 4: [1519/10940] ---- BYOL Training Loss = 0.1901886910200119
31-01-2023 01:37:36 INFO Epoch 4: [1530/10940] ---- BYOL Training Loss = 0.21334287524223328
31-01-2023 01:37:54 INFO Epoch 4: [1541/10940] ---- BYOL Training Loss = 0.20587143301963806
31-01-2023 01:38:47 INFO Epoch 4: [1541/10940] ---- BYOL Validation Loss = 0.17023110389709473
31-01-2023 01:39:04 INFO Epoch 4: [1552/10940] ---- BYOL Training Loss = 0.19211414456367493
31-01-2023 01:39:22 INFO Epoch 4: [1563/10940] ---- BYOL Training Loss = 0.18552930653095245
31-01-2023 01:39:40 INFO Epoch 4: [1574/10940] ---- BYOL Training Loss = 0.19942155480384827
31-01-2023 01:39:57 INFO Epoch 4: [1585/10940] ---- BYOL Training Loss = 0.22420522570610046
31-01-2023 01:40:50 INFO Epoch 4: [1585/10940] ---- BYOL Validation Loss = 0.15862417221069336
31-01-2023 01:41:07 INFO Epoch 4: [1596/10940] ---- BYOL Training Loss = 0.17996805906295776
31-01-2023 01:41:25 INFO Epoch 4: [1607/10940] ---- BYOL Training Loss = 0.19251276552677155
31-01-2023 01:41:43 INFO Epoch 4: [1618/10940] ---- BYOL Training Loss = 0.17557619512081146
31-01-2023 01:42:00 INFO Epoch 4: [1629/10940] ---- BYOL Training Loss = 0.15370576083660126
31-01-2023 01:42:53 INFO Epoch 4: [1629/10940] ---- BYOL Validation Loss = 0.14169040322303772
31-01-2023 01:43:10 INFO Epoch 4: [1640/10940] ---- BYOL Training Loss = 0.1928170919418335
31-01-2023 01:43:28 INFO Epoch 4: [1651/10940] ---- BYOL Training Loss = 0.1688409149646759
31-01-2023 01:43:46 INFO Epoch 4: [1662/10940] ---- BYOL Training Loss = 0.1515425145626068
31-01-2023 01:44:04 INFO Epoch 4: [1673/10940] ---- BYOL Training Loss = 0.14691288769245148
31-01-2023 01:44:56 INFO Epoch 4: [1673/10940] ---- BYOL Validation Loss = 0.12961198389530182
31-01-2023 01:45:14 INFO Epoch 4: [1684/10940] ---- BYOL Training Loss = 0.18298181891441345
31-01-2023 01:45:32 INFO Epoch 4: [1695/10940] ---- BYOL Training Loss = 0.2812803387641907
31-01-2023 01:45:50 INFO Epoch 4: [1706/10940] ---- BYOL Training Loss = 0.20535197854042053
31-01-2023 01:46:07 INFO Epoch 4: [1717/10940] ---- BYOL Training Loss = 0.18036118149757385
31-01-2023 01:47:00 INFO Epoch 4: [1717/10940] ---- BYOL Validation Loss = 0.1396232396364212
31-01-2023 01:47:17 INFO Epoch 4: [1728/10940] ---- BYOL Training Loss = 0.204924076795578
31-01-2023 01:47:35 INFO Epoch 4: [1739/10940] ---- BYOL Training Loss = 0.1700097620487213
31-01-2023 01:47:53 INFO Epoch 4: [1750/10940] ---- BYOL Training Loss = 0.2017664909362793
31-01-2023 01:48:10 INFO Epoch 4: [1761/10940] ---- BYOL Training Loss = 0.1897403746843338
31-01-2023 01:49:03 INFO Epoch 4: [1761/10940] ---- BYOL Validation Loss = 0.16732457280158997
31-01-2023 01:49:20 INFO Epoch 4: [1772/10940] ---- BYOL Training Loss = 0.18393322825431824
31-01-2023 01:49:38 INFO Epoch 4: [1783/10940] ---- BYOL Training Loss = 0.22633954882621765
31-01-2023 01:49:56 INFO Epoch 4: [1794/10940] ---- BYOL Training Loss = 0.21714229881763458
31-01-2023 01:50:13 INFO Epoch 4: [1805/10940] ---- BYOL Training Loss = 0.20954211056232452
31-01-2023 01:51:06 INFO Epoch 4: [1805/10940] ---- BYOL Validation Loss = 0.17056412994861603
31-01-2023 01:51:23 INFO Epoch 4: [1816/10940] ---- BYOL Training Loss = 0.19335903227329254
31-01-2023 01:51:41 INFO Epoch 4: [1827/10940] ---- BYOL Training Loss = 0.1582455188035965
31-01-2023 01:51:59 INFO Epoch 4: [1838/10940] ---- BYOL Training Loss = 0.1699681580066681
31-01-2023 01:52:17 INFO Epoch 4: [1849/10940] ---- BYOL Training Loss = 0.17580437660217285
31-01-2023 01:53:09 INFO Epoch 4: [1849/10940] ---- BYOL Validation Loss = 0.12313096225261688
31-01-2023 01:53:27 INFO Epoch 4: [1860/10940] ---- BYOL Training Loss = 0.15854905545711517
31-01-2023 01:53:45 INFO Epoch 4: [1871/10940] ---- BYOL Training Loss = 0.17292603850364685
31-01-2023 01:54:02 INFO Epoch 4: [1882/10940] ---- BYOL Training Loss = 0.22825007140636444
31-01-2023 01:54:20 INFO Epoch 4: [1893/10940] ---- BYOL Training Loss = 0.2717161476612091
31-01-2023 01:55:13 INFO Epoch 4: [1893/10940] ---- BYOL Validation Loss = 0.1428307145833969
31-01-2023 01:55:30 INFO Epoch 4: [1904/10940] ---- BYOL Training Loss = 0.2247442752122879
31-01-2023 01:55:48 INFO Epoch 4: [1915/10940] ---- BYOL Training Loss = 0.1754261553287506
31-01-2023 01:56:05 INFO Epoch 4: [1926/10940] ---- BYOL Training Loss = 0.1514480710029602
31-01-2023 01:56:23 INFO Epoch 4: [1937/10940] ---- BYOL Training Loss = 0.1569204479455948
31-01-2023 01:57:16 INFO Epoch 4: [1937/10940] ---- BYOL Validation Loss = 0.11214879900217056
31-01-2023 01:57:33 INFO Epoch 4: [1948/10940] ---- BYOL Training Loss = 0.1774817705154419
31-01-2023 01:57:51 INFO Epoch 4: [1959/10940] ---- BYOL Training Loss = 0.2084844410419464
31-01-2023 01:58:08 INFO Epoch 4: [1970/10940] ---- BYOL Training Loss = 0.1803847849369049
31-01-2023 01:58:26 INFO Epoch 4: [1981/10940] ---- BYOL Training Loss = 0.15177707374095917
31-01-2023 01:59:19 INFO Epoch 4: [1981/10940] ---- BYOL Validation Loss = 0.15575239062309265
31-01-2023 01:59:36 INFO Epoch 4: [1992/10940] ---- BYOL Training Loss = 0.15262018144130707
31-01-2023 01:59:54 INFO Epoch 4: [2003/10940] ---- BYOL Training Loss = 0.14992418885231018
31-01-2023 02:00:12 INFO Epoch 4: [2014/10940] ---- BYOL Training Loss = 0.14847326278686523
31-01-2023 02:00:30 INFO Epoch 4: [2025/10940] ---- BYOL Training Loss = 0.13671794533729553
31-01-2023 02:01:22 INFO Epoch 4: [2025/10940] ---- BYOL Validation Loss = 0.07015681266784668
31-01-2023 02:01:40 INFO Epoch 4: [2036/10940] ---- BYOL Training Loss = 0.1577604115009308
31-01-2023 02:01:57 INFO Epoch 4: [2047/10940] ---- BYOL Training Loss = 0.17078325152397156
31-01-2023 02:02:15 INFO Epoch 4: [2058/10940] ---- BYOL Training Loss = 0.1299111694097519
31-01-2023 02:02:33 INFO Epoch 4: [2069/10940] ---- BYOL Training Loss = 0.14902769029140472
31-01-2023 02:03:25 INFO Epoch 4: [2069/10940] ---- BYOL Validation Loss = 0.08596904575824738
31-01-2023 02:03:43 INFO Epoch 4: [2080/10940] ---- BYOL Training Loss = 0.15448027849197388
31-01-2023 02:04:01 INFO Epoch 4: [2091/10940] ---- BYOL Training Loss = 0.14935162663459778
31-01-2023 02:04:18 INFO Epoch 4: [2102/10940] ---- BYOL Training Loss = 0.1678571105003357
31-01-2023 02:04:36 INFO Epoch 4: [2113/10940] ---- BYOL Training Loss = 0.18355749547481537
31-01-2023 02:05:29 INFO Epoch 4: [2113/10940] ---- BYOL Validation Loss = 0.07801003009080887
31-01-2023 02:05:46 INFO Epoch 4: [2124/10940] ---- BYOL Training Loss = 0.18395596742630005
31-01-2023 02:06:04 INFO Epoch 4: [2135/10940] ---- BYOL Training Loss = 0.1839347779750824
31-01-2023 02:06:22 INFO Epoch 4: [2146/10940] ---- BYOL Training Loss = 0.17024634778499603
31-01-2023 02:06:39 INFO Epoch 4: [2157/10940] ---- BYOL Training Loss = 0.1653445065021515
31-01-2023 02:07:32 INFO Epoch 4: [2157/10940] ---- BYOL Validation Loss = 0.1197543814778328
31-01-2023 02:07:49 INFO Epoch 4: [2168/10940] ---- BYOL Training Loss = 0.21520033478736877
31-01-2023 02:08:07 INFO Epoch 4: [2179/10940] ---- BYOL Training Loss = 0.289217472076416
31-01-2023 02:08:25 INFO Epoch 4: [2190/10940] ---- BYOL Training Loss = 0.27169519662857056
31-01-2023 02:08:43 INFO Epoch 4: [2201/10940] ---- BYOL Training Loss = 0.1678997278213501
31-01-2023 02:09:36 INFO Epoch 4: [2201/10940] ---- BYOL Validation Loss = 0.10627734661102295
31-01-2023 02:09:53 INFO Epoch 4: [2212/10940] ---- BYOL Training Loss = 0.17415477335453033
31-01-2023 02:10:11 INFO Epoch 4: [2223/10940] ---- BYOL Training Loss = 0.1603517085313797
31-01-2023 02:10:29 INFO Epoch 4: [2234/10940] ---- BYOL Training Loss = 0.1850741058588028
31-01-2023 02:10:46 INFO Epoch 4: [2245/10940] ---- BYOL Training Loss = 0.2990773022174835
31-01-2023 02:11:39 INFO Epoch 4: [2245/10940] ---- BYOL Validation Loss = 0.12177272886037827
31-01-2023 02:11:56 INFO Epoch 4: [2256/10940] ---- BYOL Training Loss = 0.25125816464424133
31-01-2023 02:12:14 INFO Epoch 4: [2267/10940] ---- BYOL Training Loss = 0.21964845061302185
31-01-2023 02:12:32 INFO Epoch 4: [2278/10940] ---- BYOL Training Loss = 0.2213289737701416
31-01-2023 02:12:49 INFO Epoch 4: [2289/10940] ---- BYOL Training Loss = 0.1838003545999527
31-01-2023 02:13:42 INFO Epoch 4: [2289/10940] ---- BYOL Validation Loss = 0.14549268782138824
31-01-2023 02:14:00 INFO Epoch 4: [2300/10940] ---- BYOL Training Loss = 0.21870222687721252
31-01-2023 02:14:18 INFO Epoch 4: [2311/10940] ---- BYOL Training Loss = 0.18363070487976074
31-01-2023 02:14:35 INFO Epoch 4: [2322/10940] ---- BYOL Training Loss = 0.3546106517314911
31-01-2023 02:14:53 INFO Epoch 4: [2333/10940] ---- BYOL Training Loss = 0.46752962470054626
31-01-2023 02:15:45 INFO Epoch 4: [2333/10940] ---- BYOL Validation Loss = 0.2513430416584015
31-01-2023 02:16:03 INFO Epoch 4: [2344/10940] ---- BYOL Training Loss = 0.29445746541023254
31-01-2023 02:16:21 INFO Epoch 4: [2355/10940] ---- BYOL Training Loss = 0.23571833968162537
31-01-2023 02:16:38 INFO Epoch 4: [2366/10940] ---- BYOL Training Loss = 0.23168058693408966
31-01-2023 02:16:56 INFO Epoch 4: [2377/10940] ---- BYOL Training Loss = 0.21568791568279266
31-01-2023 02:17:49 INFO Epoch 4: [2377/10940] ---- BYOL Validation Loss = 0.2020425796508789
31-01-2023 02:18:06 INFO Epoch 4: [2388/10940] ---- BYOL Training Loss = 0.19958749413490295
31-01-2023 02:18:24 INFO Epoch 4: [2399/10940] ---- BYOL Training Loss = 0.18141615390777588
31-01-2023 02:18:42 INFO Epoch 4: [2410/10940] ---- BYOL Training Loss = 0.17612488567829132
31-01-2023 02:18:59 INFO Epoch 4: [2421/10940] ---- BYOL Training Loss = 0.18830335140228271
31-01-2023 02:19:52 INFO Epoch 4: [2421/10940] ---- BYOL Validation Loss = 0.17430302500724792
31-01-2023 02:20:10 INFO Epoch 4: [2432/10940] ---- BYOL Training Loss = 0.19377484917640686
31-01-2023 02:20:28 INFO Epoch 4: [2443/10940] ---- BYOL Training Loss = 0.16710622608661652
31-01-2023 02:20:45 INFO Epoch 4: [2454/10940] ---- BYOL Training Loss = 0.1517227441072464
31-01-2023 02:21:03 INFO Epoch 4: [2465/10940] ---- BYOL Training Loss = 0.207143634557724
31-01-2023 02:21:56 INFO Epoch 4: [2465/10940] ---- BYOL Validation Loss = 0.16876520216464996
31-01-2023 02:22:13 INFO Epoch 4: [2476/10940] ---- BYOL Training Loss = 0.2066665142774582
31-01-2023 02:22:31 INFO Epoch 4: [2487/10940] ---- BYOL Training Loss = 0.21942031383514404
31-01-2023 02:22:49 INFO Epoch 4: [2498/10940] ---- BYOL Training Loss = 0.19082598388195038
31-01-2023 02:23:06 INFO Epoch 4: [2509/10940] ---- BYOL Training Loss = 0.17728695273399353
31-01-2023 02:23:59 INFO Epoch 4: [2509/10940] ---- BYOL Validation Loss = 0.1628350466489792
31-01-2023 02:24:16 INFO Epoch 4: [2520/10940] ---- BYOL Training Loss = 0.21859221160411835
31-01-2023 02:24:34 INFO Epoch 4: [2531/10940] ---- BYOL Training Loss = 0.25642597675323486
31-01-2023 02:24:52 INFO Epoch 4: [2542/10940] ---- BYOL Training Loss = 0.2187315672636032
31-01-2023 02:25:10 INFO Epoch 4: [2553/10940] ---- BYOL Training Loss = 0.22972187399864197
31-01-2023 02:26:03 INFO Epoch 4: [2553/10940] ---- BYOL Validation Loss = 0.13648919761180878
31-01-2023 02:26:20 INFO Epoch 4: [2564/10940] ---- BYOL Training Loss = 0.23082122206687927
31-01-2023 02:26:38 INFO Epoch 4: [2575/10940] ---- BYOL Training Loss = 0.20266719162464142
31-01-2023 02:26:56 INFO Epoch 4: [2586/10940] ---- BYOL Training Loss = 0.16086283326148987
31-01-2023 02:27:13 INFO Epoch 4: [2597/10940] ---- BYOL Training Loss = 0.16978196799755096
31-01-2023 02:28:06 INFO Epoch 4: [2597/10940] ---- BYOL Validation Loss = 0.17815276980400085
31-01-2023 02:28:24 INFO Epoch 4: [2608/10940] ---- BYOL Training Loss = 0.18019816279411316
31-01-2023 02:28:41 INFO Epoch 4: [2619/10940] ---- BYOL Training Loss = 0.16909803450107574
31-01-2023 02:28:59 INFO Epoch 4: [2630/10940] ---- BYOL Training Loss = 0.1594158262014389
31-01-2023 02:29:17 INFO Epoch 4: [2641/10940] ---- BYOL Training Loss = 0.1998855173587799
31-01-2023 02:30:10 INFO Epoch 4: [2641/10940] ---- BYOL Validation Loss = 0.16073477268218994
31-01-2023 02:30:27 INFO Epoch 4: [2652/10940] ---- BYOL Training Loss = 0.20151308178901672
31-01-2023 02:30:45 INFO Epoch 4: [2663/10940] ---- BYOL Training Loss = 0.14543417096138
31-01-2023 02:31:03 INFO Epoch 4: [2674/10940] ---- BYOL Training Loss = 0.17044654488563538
31-01-2023 02:31:21 INFO Epoch 4: [2685/10940] ---- BYOL Training Loss = 0.20913922786712646
31-01-2023 02:32:13 INFO Epoch 4: [2685/10940] ---- BYOL Validation Loss = 0.161436527967453
31-01-2023 02:32:31 INFO Epoch 4: [2696/10940] ---- BYOL Training Loss = 0.20818790793418884
31-01-2023 02:32:49 INFO Epoch 4: [2707/10940] ---- BYOL Training Loss = 0.16370446979999542
31-01-2023 02:33:06 INFO Epoch 4: [2718/10940] ---- BYOL Training Loss = 0.16819718480110168
31-01-2023 02:33:24 INFO Epoch 4: [2729/10940] ---- BYOL Training Loss = 0.15989923477172852
31-01-2023 02:34:17 INFO Epoch 4: [2729/10940] ---- BYOL Validation Loss = 0.17618504166603088
31-01-2023 02:34:34 INFO Epoch 4: [2740/10940] ---- BYOL Training Loss = 0.1791975498199463
31-01-2023 02:34:52 INFO Epoch 4: [2751/10940] ---- BYOL Training Loss = 0.18038396537303925
31-01-2023 02:35:10 INFO Epoch 4: [2762/10940] ---- BYOL Training Loss = 0.1683039516210556
31-01-2023 02:35:28 INFO Epoch 4: [2773/10940] ---- BYOL Training Loss = 0.16309009492397308
31-01-2023 02:36:21 INFO Epoch 4: [2773/10940] ---- BYOL Validation Loss = 0.1354304403066635
31-01-2023 02:36:38 INFO Epoch 4: [2784/10940] ---- BYOL Training Loss = 0.19710904359817505
31-01-2023 02:36:56 INFO Epoch 4: [2795/10940] ---- BYOL Training Loss = 0.223008394241333
31-01-2023 02:37:14 INFO Epoch 4: [2806/10940] ---- BYOL Training Loss = 0.18831534683704376
31-01-2023 02:37:32 INFO Epoch 4: [2817/10940] ---- BYOL Training Loss = 0.18575987219810486
31-01-2023 02:38:24 INFO Epoch 4: [2817/10940] ---- BYOL Validation Loss = 0.13237126171588898
31-01-2023 02:38:42 INFO Epoch 4: [2828/10940] ---- BYOL Training Loss = 0.17568571865558624
31-01-2023 02:39:00 INFO Epoch 4: [2839/10940] ---- BYOL Training Loss = 0.16303527355194092
31-01-2023 02:39:18 INFO Epoch 4: [2850/10940] ---- BYOL Training Loss = 0.15798179805278778
31-01-2023 02:39:36 INFO Epoch 4: [2861/10940] ---- BYOL Training Loss = 0.15768927335739136
31-01-2023 02:40:28 INFO Epoch 4: [2861/10940] ---- BYOL Validation Loss = 0.13913807272911072
31-01-2023 02:40:46 INFO Epoch 4: [2872/10940] ---- BYOL Training Loss = 0.16336384415626526
31-01-2023 02:41:04 INFO Epoch 4: [2883/10940] ---- BYOL Training Loss = 0.16585516929626465
31-01-2023 02:41:21 INFO Epoch 4: [2894/10940] ---- BYOL Training Loss = 0.15205387771129608
31-01-2023 02:41:39 INFO Epoch 4: [2905/10940] ---- BYOL Training Loss = 0.14620962738990784
31-01-2023 02:42:32 INFO Epoch 4: [2905/10940] ---- BYOL Validation Loss = 0.13184528052806854
31-01-2023 02:42:49 INFO Epoch 4: [2916/10940] ---- BYOL Training Loss = 0.1858520209789276
31-01-2023 02:43:07 INFO Epoch 4: [2927/10940] ---- BYOL Training Loss = 0.1732916533946991
31-01-2023 02:43:25 INFO Epoch 4: [2938/10940] ---- BYOL Training Loss = 0.1879882514476776
31-01-2023 02:43:43 INFO Epoch 4: [2949/10940] ---- BYOL Training Loss = 0.25527048110961914
31-01-2023 02:44:36 INFO Epoch 4: [2949/10940] ---- BYOL Validation Loss = 0.14786891639232635
31-01-2023 02:44:53 INFO Epoch 4: [2960/10940] ---- BYOL Training Loss = 0.23201970756053925
31-01-2023 02:45:11 INFO Epoch 4: [2971/10940] ---- BYOL Training Loss = 0.20596297085285187
31-01-2023 02:45:29 INFO Epoch 4: [2982/10940] ---- BYOL Training Loss = 0.16435185074806213
31-01-2023 02:45:47 INFO Epoch 4: [2993/10940] ---- BYOL Training Loss = 0.18710175156593323
31-01-2023 02:46:39 INFO Epoch 4: [2993/10940] ---- BYOL Validation Loss = 0.16027972102165222
31-01-2023 02:46:57 INFO Epoch 4: [3004/10940] ---- BYOL Training Loss = 0.17685821652412415
31-01-2023 02:47:15 INFO Epoch 4: [3015/10940] ---- BYOL Training Loss = 0.21573761105537415
31-01-2023 02:47:32 INFO Epoch 4: [3026/10940] ---- BYOL Training Loss = 0.25781944394111633
31-01-2023 02:47:51 INFO Epoch 4: [3037/10940] ---- BYOL Training Loss = 0.22172124683856964
31-01-2023 02:48:43 INFO Epoch 4: [3037/10940] ---- BYOL Validation Loss = 0.17311222851276398
31-01-2023 02:49:01 INFO Epoch 4: [3048/10940] ---- BYOL Training Loss = 0.15466506779193878
31-01-2023 02:49:19 INFO Epoch 4: [3059/10940] ---- BYOL Training Loss = 0.1694139540195465
31-01-2023 02:49:36 INFO Epoch 4: [3070/10940] ---- BYOL Training Loss = 0.14799757301807404
31-01-2023 02:49:54 INFO Epoch 4: [3081/10940] ---- BYOL Training Loss = 0.17613090574741364
31-01-2023 02:50:47 INFO Epoch 4: [3081/10940] ---- BYOL Validation Loss = 0.14853334426879883
31-01-2023 02:51:04 INFO Epoch 4: [3092/10940] ---- BYOL Training Loss = 0.2027248591184616
31-01-2023 02:51:22 INFO Epoch 4: [3103/10940] ---- BYOL Training Loss = 0.21146544814109802
31-01-2023 02:51:40 INFO Epoch 4: [3114/10940] ---- BYOL Training Loss = 0.2063203752040863
31-01-2023 02:51:58 INFO Epoch 4: [3125/10940] ---- BYOL Training Loss = 0.14429110288619995
31-01-2023 02:52:50 INFO Epoch 4: [3125/10940] ---- BYOL Validation Loss = 0.1087392047047615
31-01-2023 02:53:08 INFO Epoch 4: [3136/10940] ---- BYOL Training Loss = 0.15641304850578308
31-01-2023 02:53:26 INFO Epoch 4: [3147/10940] ---- BYOL Training Loss = 0.2126907855272293
31-01-2023 02:53:44 INFO Epoch 4: [3158/10940] ---- BYOL Training Loss = 0.2152538001537323
31-01-2023 02:54:01 INFO Epoch 4: [3169/10940] ---- BYOL Training Loss = 0.1963558793067932
31-01-2023 02:54:54 INFO Epoch 4: [3169/10940] ---- BYOL Validation Loss = 0.15725718438625336
31-01-2023 02:55:11 INFO Epoch 4: [3180/10940] ---- BYOL Training Loss = 0.2035738229751587
31-01-2023 02:55:30 INFO Epoch 4: [3191/10940] ---- BYOL Training Loss = 0.20247021317481995
31-01-2023 02:55:47 INFO Epoch 4: [3202/10940] ---- BYOL Training Loss = 0.16909456253051758
31-01-2023 02:56:05 INFO Epoch 4: [3213/10940] ---- BYOL Training Loss = 0.15701766312122345
31-01-2023 02:56:58 INFO Epoch 4: [3213/10940] ---- BYOL Validation Loss = 0.11723967641592026
31-01-2023 02:57:15 INFO Epoch 4: [3224/10940] ---- BYOL Training Loss = 0.1762097179889679
31-01-2023 02:57:33 INFO Epoch 4: [3235/10940] ---- BYOL Training Loss = 0.16481849551200867
31-01-2023 02:57:51 INFO Epoch 4: [3246/10940] ---- BYOL Training Loss = 0.28586772084236145
31-01-2023 02:58:09 INFO Epoch 4: [3257/10940] ---- BYOL Training Loss = 0.2956010699272156
31-01-2023 02:59:02 INFO Epoch 4: [3257/10940] ---- BYOL Validation Loss = 0.12083639204502106
31-01-2023 02:59:20 INFO Epoch 4: [3268/10940] ---- BYOL Training Loss = 0.22566621005535126
31-01-2023 02:59:37 INFO Epoch 4: [3279/10940] ---- BYOL Training Loss = 0.23513905704021454
31-01-2023 02:59:55 INFO Epoch 4: [3290/10940] ---- BYOL Training Loss = 0.15768589079380035
31-01-2023 03:00:13 INFO Epoch 4: [3301/10940] ---- BYOL Training Loss = 0.14435222744941711
31-01-2023 03:01:06 INFO Epoch 4: [3301/10940] ---- BYOL Validation Loss = 0.14554445445537567
31-01-2023 03:01:23 INFO Epoch 4: [3312/10940] ---- BYOL Training Loss = 0.18109583854675293
31-01-2023 03:01:41 INFO Epoch 4: [3323/10940] ---- BYOL Training Loss = 0.18707242608070374
31-01-2023 03:01:59 INFO Epoch 4: [3334/10940] ---- BYOL Training Loss = 0.17624536156654358
31-01-2023 03:02:17 INFO Epoch 4: [3345/10940] ---- BYOL Training Loss = 0.19919781386852264
31-01-2023 03:03:09 INFO Epoch 4: [3345/10940] ---- BYOL Validation Loss = 0.12794284522533417
31-01-2023 03:03:27 INFO Epoch 4: [3356/10940] ---- BYOL Training Loss = 0.218867689371109
31-01-2023 03:03:45 INFO Epoch 4: [3367/10940] ---- BYOL Training Loss = 0.1836272031068802
31-01-2023 03:04:03 INFO Epoch 4: [3378/10940] ---- BYOL Training Loss = 0.16539302468299866
31-01-2023 03:04:21 INFO Epoch 4: [3389/10940] ---- BYOL Training Loss = 0.1890610158443451
31-01-2023 03:05:13 INFO Epoch 4: [3389/10940] ---- BYOL Validation Loss = 0.1197228878736496
31-01-2023 03:05:31 INFO Epoch 4: [3400/10940] ---- BYOL Training Loss = 0.1852300465106964
31-01-2023 03:05:49 INFO Epoch 4: [3411/10940] ---- BYOL Training Loss = 0.23307065665721893
31-01-2023 03:06:07 INFO Epoch 4: [3422/10940] ---- BYOL Training Loss = 0.25878721475601196
31-01-2023 03:06:25 INFO Epoch 4: [3433/10940] ---- BYOL Training Loss = 0.2595636248588562
31-01-2023 03:07:17 INFO Epoch 4: [3433/10940] ---- BYOL Validation Loss = 0.19408106803894043
31-01-2023 03:07:35 INFO Epoch 4: [3444/10940] ---- BYOL Training Loss = 0.2494368851184845
31-01-2023 03:07:53 INFO Epoch 4: [3455/10940] ---- BYOL Training Loss = 0.19570793211460114
31-01-2023 03:08:11 INFO Epoch 4: [3466/10940] ---- BYOL Training Loss = 0.21949219703674316
31-01-2023 03:08:29 INFO Epoch 4: [3477/10940] ---- BYOL Training Loss = 0.21527063846588135
31-01-2023 03:09:22 INFO Epoch 4: [3477/10940] ---- BYOL Validation Loss = 0.17127706110477448
31-01-2023 03:09:39 INFO Epoch 4: [3488/10940] ---- BYOL Training Loss = 0.19716434180736542
31-01-2023 03:09:57 INFO Epoch 4: [3499/10940] ---- BYOL Training Loss = 0.18833252787590027
31-01-2023 03:10:15 INFO Epoch 4: [3510/10940] ---- BYOL Training Loss = 0.19722367823123932
31-01-2023 03:10:33 INFO Epoch 4: [3521/10940] ---- BYOL Training Loss = 0.2000771313905716
31-01-2023 03:11:26 INFO Epoch 4: [3521/10940] ---- BYOL Validation Loss = 0.15618811547756195
31-01-2023 03:11:43 INFO Epoch 4: [3532/10940] ---- BYOL Training Loss = 0.179385244846344
31-01-2023 03:12:01 INFO Epoch 4: [3543/10940] ---- BYOL Training Loss = 0.17776235938072205
31-01-2023 03:12:19 INFO Epoch 4: [3554/10940] ---- BYOL Training Loss = 0.1878005564212799
31-01-2023 03:12:37 INFO Epoch 4: [3565/10940] ---- BYOL Training Loss = 0.18560293316841125
31-01-2023 03:13:29 INFO Epoch 4: [3565/10940] ---- BYOL Validation Loss = 0.17209281027317047
31-01-2023 03:13:47 INFO Epoch 4: [3576/10940] ---- BYOL Training Loss = 0.17591334879398346
31-01-2023 03:14:05 INFO Epoch 4: [3587/10940] ---- BYOL Training Loss = 0.18639998137950897
31-01-2023 03:14:23 INFO Epoch 4: [3598/10940] ---- BYOL Training Loss = 0.2213856726884842
31-01-2023 03:14:41 INFO Epoch 4: [3609/10940] ---- BYOL Training Loss = 0.1954745352268219
31-01-2023 03:15:34 INFO Epoch 4: [3609/10940] ---- BYOL Validation Loss = 0.16453896462917328
31-01-2023 03:15:51 INFO Epoch 4: [3620/10940] ---- BYOL Training Loss = 0.18172593414783478
31-01-2023 03:16:09 INFO Epoch 4: [3631/10940] ---- BYOL Training Loss = 0.1726032793521881
31-01-2023 03:16:27 INFO Epoch 4: [3642/10940] ---- BYOL Training Loss = 0.17828232049942017
31-01-2023 03:16:45 INFO Epoch 4: [3653/10940] ---- BYOL Training Loss = 0.17542573809623718
31-01-2023 03:17:37 INFO Epoch 4: [3653/10940] ---- BYOL Validation Loss = 0.13641105592250824
31-01-2023 03:17:55 INFO Epoch 4: [3664/10940] ---- BYOL Training Loss = 0.19101564586162567
31-01-2023 03:18:13 INFO Epoch 4: [3675/10940] ---- BYOL Training Loss = 0.22136929631233215
31-01-2023 03:18:31 INFO Epoch 4: [3686/10940] ---- BYOL Training Loss = 0.22130413353443146
31-01-2023 03:18:49 INFO Epoch 4: [3697/10940] ---- BYOL Training Loss = 0.1891893893480301
31-01-2023 03:19:42 INFO Epoch 4: [3697/10940] ---- BYOL Validation Loss = 0.19081462919712067
31-01-2023 03:19:59 INFO Epoch 4: [3708/10940] ---- BYOL Training Loss = 0.19305679202079773
31-01-2023 03:20:17 INFO Epoch 4: [3719/10940] ---- BYOL Training Loss = 0.22331976890563965
31-01-2023 03:20:35 INFO Epoch 4: [3730/10940] ---- BYOL Training Loss = 0.2105395793914795
31-01-2023 03:20:53 INFO Epoch 4: [3741/10940] ---- BYOL Training Loss = 0.1867586225271225
31-01-2023 03:21:45 INFO Epoch 4: [3741/10940] ---- BYOL Validation Loss = 0.1979077011346817
31-01-2023 03:22:03 INFO Epoch 4: [3752/10940] ---- BYOL Training Loss = 0.21834620833396912
31-01-2023 03:22:21 INFO Epoch 4: [3763/10940] ---- BYOL Training Loss = 0.21282486617565155
31-01-2023 03:22:39 INFO Epoch 4: [3774/10940] ---- BYOL Training Loss = 0.20882713794708252
31-01-2023 03:22:57 INFO Epoch 4: [3785/10940] ---- BYOL Training Loss = 0.2512328028678894
31-01-2023 03:23:50 INFO Epoch 4: [3785/10940] ---- BYOL Validation Loss = 0.20711848139762878
31-01-2023 03:24:07 INFO Epoch 4: [3796/10940] ---- BYOL Training Loss = 0.22902274131774902
31-01-2023 03:24:25 INFO Epoch 4: [3807/10940] ---- BYOL Training Loss = 0.18104836344718933
31-01-2023 03:24:43 INFO Epoch 4: [3818/10940] ---- BYOL Training Loss = 0.16024334728717804
31-01-2023 03:25:01 INFO Epoch 4: [3829/10940] ---- BYOL Training Loss = 0.1995392143726349
31-01-2023 03:25:54 INFO Epoch 4: [3829/10940] ---- BYOL Validation Loss = 0.19198592007160187
31-01-2023 03:26:11 INFO Epoch 4: [3840/10940] ---- BYOL Training Loss = 0.19882722198963165
31-01-2023 03:26:29 INFO Epoch 4: [3851/10940] ---- BYOL Training Loss = 0.19314254820346832
31-01-2023 03:26:47 INFO Epoch 4: [3862/10940] ---- BYOL Training Loss = 0.19712737202644348
31-01-2023 03:27:05 INFO Epoch 4: [3873/10940] ---- BYOL Training Loss = 0.21553583443164825
31-01-2023 03:27:58 INFO Epoch 4: [3873/10940] ---- BYOL Validation Loss = 0.18648505210876465
31-01-2023 03:28:15 INFO Epoch 4: [3884/10940] ---- BYOL Training Loss = 0.19728800654411316
31-01-2023 03:28:33 INFO Epoch 4: [3895/10940] ---- BYOL Training Loss = 0.17681315541267395
31-01-2023 03:28:51 INFO Epoch 4: [3906/10940] ---- BYOL Training Loss = 0.1790471374988556
31-01-2023 03:29:09 INFO Epoch 4: [3917/10940] ---- BYOL Training Loss = 0.1623360812664032
31-01-2023 03:30:02 INFO Epoch 4: [3917/10940] ---- BYOL Validation Loss = 0.18671448528766632
31-01-2023 03:30:19 INFO Epoch 4: [3928/10940] ---- BYOL Training Loss = 0.14908313751220703
31-01-2023 03:30:37 INFO Epoch 4: [3939/10940] ---- BYOL Training Loss = 0.14053651690483093
31-01-2023 03:30:55 INFO Epoch 4: [3950/10940] ---- BYOL Training Loss = 0.17179062962532043
31-01-2023 03:31:14 INFO Epoch 4: [3961/10940] ---- BYOL Training Loss = 0.19124490022659302
31-01-2023 03:32:06 INFO Epoch 4: [3961/10940] ---- BYOL Validation Loss = 0.1765507608652115
31-01-2023 03:32:24 INFO Epoch 4: [3972/10940] ---- BYOL Training Loss = 0.20180778205394745
31-01-2023 03:32:42 INFO Epoch 4: [3983/10940] ---- BYOL Training Loss = 0.19239720702171326
31-01-2023 03:33:00 INFO Epoch 4: [3994/10940] ---- BYOL Training Loss = 0.20730097591876984
31-01-2023 03:33:18 INFO Epoch 4: [4005/10940] ---- BYOL Training Loss = 0.241007998585701
31-01-2023 03:34:10 INFO Epoch 4: [4005/10940] ---- BYOL Validation Loss = 0.19274814426898956
31-01-2023 03:34:28 INFO Epoch 4: [4016/10940] ---- BYOL Training Loss = 0.2306571751832962
31-01-2023 03:34:46 INFO Epoch 4: [4027/10940] ---- BYOL Training Loss = 0.22309155762195587
31-01-2023 03:35:04 INFO Epoch 4: [4038/10940] ---- BYOL Training Loss = 0.18233372271060944
31-01-2023 03:35:22 INFO Epoch 4: [4049/10940] ---- BYOL Training Loss = 0.14218589663505554
31-01-2023 03:36:15 INFO Epoch 4: [4049/10940] ---- BYOL Validation Loss = 0.1674688309431076
31-01-2023 03:36:33 INFO Epoch 4: [4060/10940] ---- BYOL Training Loss = 0.13540127873420715
31-01-2023 03:36:51 INFO Epoch 4: [4071/10940] ---- BYOL Training Loss = 0.1722269356250763
31-01-2023 03:37:08 INFO Epoch 4: [4082/10940] ---- BYOL Training Loss = 0.21046558022499084
31-01-2023 03:37:27 INFO Epoch 4: [4093/10940] ---- BYOL Training Loss = 0.20964093506336212
31-01-2023 03:38:19 INFO Epoch 4: [4093/10940] ---- BYOL Validation Loss = 0.1664629429578781
31-01-2023 03:38:37 INFO Epoch 4: [4104/10940] ---- BYOL Training Loss = 0.17419962584972382
31-01-2023 03:38:55 INFO Epoch 4: [4115/10940] ---- BYOL Training Loss = 0.18168339133262634
31-01-2023 03:39:13 INFO Epoch 4: [4126/10940] ---- BYOL Training Loss = 0.21757622063159943
31-01-2023 03:39:30 INFO Epoch 4: [4137/10940] ---- BYOL Training Loss = 0.19441865384578705
31-01-2023 03:40:23 INFO Epoch 4: [4137/10940] ---- BYOL Validation Loss = 0.17787207663059235
31-01-2023 03:40:41 INFO Epoch 4: [4148/10940] ---- BYOL Training Loss = 0.16163544356822968
31-01-2023 03:40:59 INFO Epoch 4: [4159/10940] ---- BYOL Training Loss = 0.15623053908348083
31-01-2023 03:41:17 INFO Epoch 4: [4170/10940] ---- BYOL Training Loss = 0.17140330374240875
31-01-2023 03:41:35 INFO Epoch 4: [4181/10940] ---- BYOL Training Loss = 0.18369033932685852
31-01-2023 03:42:27 INFO Epoch 4: [4181/10940] ---- BYOL Validation Loss = 0.17130634188652039
31-01-2023 03:42:45 INFO Epoch 4: [4192/10940] ---- BYOL Training Loss = 0.1577683389186859
31-01-2023 03:43:03 INFO Epoch 4: [4203/10940] ---- BYOL Training Loss = 0.17408117651939392
31-01-2023 03:43:21 INFO Epoch 4: [4214/10940] ---- BYOL Training Loss = 0.1656205803155899
31-01-2023 03:43:39 INFO Epoch 4: [4225/10940] ---- BYOL Training Loss = 0.1645379513502121
31-01-2023 03:44:32 INFO Epoch 4: [4225/10940] ---- BYOL Validation Loss = 0.16550612449645996
31-01-2023 03:44:49 INFO Epoch 4: [4236/10940] ---- BYOL Training Loss = 0.18994072079658508
31-01-2023 03:45:07 INFO Epoch 4: [4247/10940] ---- BYOL Training Loss = 0.17154331505298615
31-01-2023 03:45:25 INFO Epoch 4: [4258/10940] ---- BYOL Training Loss = 0.15670979022979736
31-01-2023 03:45:43 INFO Epoch 4: [4269/10940] ---- BYOL Training Loss = 0.15346094965934753
31-01-2023 03:46:36 INFO Epoch 4: [4269/10940] ---- BYOL Validation Loss = 0.14182183146476746
31-01-2023 03:46:54 INFO Epoch 4: [4280/10940] ---- BYOL Training Loss = 0.1414659172296524
31-01-2023 03:47:12 INFO Epoch 4: [4291/10940] ---- BYOL Training Loss = 0.16448484361171722
31-01-2023 03:47:30 INFO Epoch 4: [4302/10940] ---- BYOL Training Loss = 0.1744386851787567
31-01-2023 03:47:48 INFO Epoch 4: [4313/10940] ---- BYOL Training Loss = 0.2025652378797531
31-01-2023 03:48:40 INFO Epoch 4: [4313/10940] ---- BYOL Validation Loss = 0.16962860524654388
31-01-2023 03:48:58 INFO Epoch 4: [4324/10940] ---- BYOL Training Loss = 0.23192930221557617
31-01-2023 03:49:16 INFO Epoch 4: [4335/10940] ---- BYOL Training Loss = 0.22285735607147217
31-01-2023 03:49:34 INFO Epoch 4: [4346/10940] ---- BYOL Training Loss = 0.1699863076210022
31-01-2023 03:49:52 INFO Epoch 4: [4357/10940] ---- BYOL Training Loss = 0.173955038189888
31-01-2023 03:50:45 INFO Epoch 4: [4357/10940] ---- BYOL Validation Loss = 0.15610170364379883
31-01-2023 03:51:02 INFO Epoch 4: [4368/10940] ---- BYOL Training Loss = 0.14882278442382812
31-01-2023 03:51:20 INFO Epoch 4: [4379/10940] ---- BYOL Training Loss = 0.1428215205669403
31-01-2023 03:51:38 INFO Epoch 4: [4390/10940] ---- BYOL Training Loss = 0.17084655165672302
31-01-2023 03:51:57 INFO Epoch 4: [4401/10940] ---- BYOL Training Loss = 0.1769838035106659
31-01-2023 03:52:50 INFO Epoch 4: [4401/10940] ---- BYOL Validation Loss = 0.12997967004776
31-01-2023 03:53:07 INFO Epoch 4: [4412/10940] ---- BYOL Training Loss = 0.14746098220348358
31-01-2023 03:53:25 INFO Epoch 4: [4423/10940] ---- BYOL Training Loss = 0.16335147619247437
31-01-2023 03:53:43 INFO Epoch 4: [4434/10940] ---- BYOL Training Loss = 0.16802604496479034
31-01-2023 03:54:01 INFO Epoch 4: [4445/10940] ---- BYOL Training Loss = 0.19187180697917938
31-01-2023 03:54:54 INFO Epoch 4: [4445/10940] ---- BYOL Validation Loss = 0.13090088963508606
31-01-2023 03:55:12 INFO Epoch 4: [4456/10940] ---- BYOL Training Loss = 0.1738964468240738
31-01-2023 03:55:30 INFO Epoch 4: [4467/10940] ---- BYOL Training Loss = 0.1718291938304901
31-01-2023 03:55:48 INFO Epoch 4: [4478/10940] ---- BYOL Training Loss = 0.1702336072921753
31-01-2023 03:56:06 INFO Epoch 4: [4489/10940] ---- BYOL Training Loss = 0.15722736716270447
31-01-2023 03:56:59 INFO Epoch 4: [4489/10940] ---- BYOL Validation Loss = 0.1480598747730255
31-01-2023 03:57:16 INFO Epoch 4: [4500/10940] ---- BYOL Training Loss = 0.16604332625865936
31-01-2023 03:57:35 INFO Epoch 4: [4511/10940] ---- BYOL Training Loss = 0.1839810311794281
31-01-2023 03:57:53 INFO Epoch 4: [4522/10940] ---- BYOL Training Loss = 0.15309756994247437
31-01-2023 03:58:11 INFO Epoch 4: [4533/10940] ---- BYOL Training Loss = 0.13971607387065887
31-01-2023 03:59:03 INFO Epoch 4: [4533/10940] ---- BYOL Validation Loss = 0.1456691175699234
31-01-2023 03:59:21 INFO Epoch 4: [4544/10940] ---- BYOL Training Loss = 0.1171184629201889
31-01-2023 03:59:39 INFO Epoch 4: [4555/10940] ---- BYOL Training Loss = 0.2846158742904663
31-01-2023 03:59:57 INFO Epoch 4: [4566/10940] ---- BYOL Training Loss = 0.3411286473274231
31-01-2023 04:00:15 INFO Epoch 4: [4577/10940] ---- BYOL Training Loss = 0.2200937271118164
31-01-2023 04:01:08 INFO Epoch 4: [4577/10940] ---- BYOL Validation Loss = 0.12303944677114487
31-01-2023 04:01:26 INFO Epoch 4: [4588/10940] ---- BYOL Training Loss = 0.19476082921028137
31-01-2023 04:01:44 INFO Epoch 4: [4599/10940] ---- BYOL Training Loss = 0.15706738829612732
31-01-2023 04:02:01 INFO Epoch 4: [4610/10940] ---- BYOL Training Loss = 0.14508099853992462
31-01-2023 04:02:19 INFO Epoch 4: [4621/10940] ---- BYOL Training Loss = 0.13304725289344788
31-01-2023 04:03:12 INFO Epoch 4: [4621/10940] ---- BYOL Validation Loss = 0.15029677748680115
31-01-2023 04:03:30 INFO Epoch 4: [4632/10940] ---- BYOL Training Loss = 0.16787374019622803
31-01-2023 04:03:48 INFO Epoch 4: [4643/10940] ---- BYOL Training Loss = 0.18877284228801727
31-01-2023 04:04:06 INFO Epoch 4: [4654/10940] ---- BYOL Training Loss = 0.1946088969707489
31-01-2023 04:04:24 INFO Epoch 4: [4665/10940] ---- BYOL Training Loss = 0.1878080666065216
31-01-2023 04:05:17 INFO Epoch 4: [4665/10940] ---- BYOL Validation Loss = 0.1406041383743286
31-01-2023 04:05:34 INFO Epoch 4: [4676/10940] ---- BYOL Training Loss = 0.20331938564777374
31-01-2023 04:05:53 INFO Epoch 4: [4687/10940] ---- BYOL Training Loss = 0.17184658348560333
31-01-2023 04:06:11 INFO Epoch 4: [4698/10940] ---- BYOL Training Loss = 0.17594948410987854
31-01-2023 04:06:29 INFO Epoch 4: [4709/10940] ---- BYOL Training Loss = 0.16155269742012024
31-01-2023 04:07:21 INFO Epoch 4: [4709/10940] ---- BYOL Validation Loss = 0.15777452290058136
31-01-2023 04:07:39 INFO Epoch 4: [4720/10940] ---- BYOL Training Loss = 0.15376341342926025
31-01-2023 04:07:57 INFO Epoch 4: [4731/10940] ---- BYOL Training Loss = 0.22264719009399414
31-01-2023 04:08:15 INFO Epoch 4: [4742/10940] ---- BYOL Training Loss = 0.22876672446727753
31-01-2023 04:08:33 INFO Epoch 4: [4753/10940] ---- BYOL Training Loss = 0.14759446680545807
31-01-2023 04:09:26 INFO Epoch 4: [4753/10940] ---- BYOL Validation Loss = 0.09289969503879547
31-01-2023 04:09:44 INFO Epoch 4: [4764/10940] ---- BYOL Training Loss = 0.15824058651924133
31-01-2023 04:10:02 INFO Epoch 4: [4775/10940] ---- BYOL Training Loss = 0.18918710947036743
31-01-2023 04:10:20 INFO Epoch 4: [4786/10940] ---- BYOL Training Loss = 0.22257962822914124
31-01-2023 04:10:38 INFO Epoch 4: [4797/10940] ---- BYOL Training Loss = 0.19963811337947845
31-01-2023 04:11:30 INFO Epoch 4: [4797/10940] ---- BYOL Validation Loss = 0.11471421271562576
31-01-2023 04:11:48 INFO Epoch 4: [4808/10940] ---- BYOL Training Loss = 0.13847097754478455
31-01-2023 04:12:06 INFO Epoch 4: [4819/10940] ---- BYOL Training Loss = 0.21863213181495667
31-01-2023 04:12:24 INFO Epoch 4: [4830/10940] ---- BYOL Training Loss = 0.1721312254667282
31-01-2023 04:12:42 INFO Epoch 4: [4841/10940] ---- BYOL Training Loss = 0.1601661890745163
31-01-2023 04:13:35 INFO Epoch 4: [4841/10940] ---- BYOL Validation Loss = 0.14016525447368622
31-01-2023 04:13:53 INFO Epoch 4: [4852/10940] ---- BYOL Training Loss = 0.27042266726493835
31-01-2023 04:14:11 INFO Epoch 4: [4863/10940] ---- BYOL Training Loss = 0.28173989057540894
31-01-2023 04:14:29 INFO Epoch 4: [4874/10940] ---- BYOL Training Loss = 0.1434786170721054
31-01-2023 04:14:47 INFO Epoch 4: [4885/10940] ---- BYOL Training Loss = 0.153263121843338
31-01-2023 04:15:39 INFO Epoch 4: [4885/10940] ---- BYOL Validation Loss = 0.12839899957180023
31-01-2023 04:15:57 INFO Epoch 4: [4896/10940] ---- BYOL Training Loss = 0.15785646438598633
31-01-2023 04:16:15 INFO Epoch 4: [4907/10940] ---- BYOL Training Loss = 0.28808656334877014
31-01-2023 04:16:33 INFO Epoch 4: [4918/10940] ---- BYOL Training Loss = 0.2606811225414276
31-01-2023 04:16:52 INFO Epoch 4: [4929/10940] ---- BYOL Training Loss = 0.17009957134723663
31-01-2023 04:17:44 INFO Epoch 4: [4929/10940] ---- BYOL Validation Loss = 0.11932166665792465
31-01-2023 04:18:02 INFO Epoch 4: [4940/10940] ---- BYOL Training Loss = 0.13932015001773834
31-01-2023 04:18:20 INFO Epoch 4: [4951/10940] ---- BYOL Training Loss = 0.16955189406871796
31-01-2023 04:18:38 INFO Epoch 4: [4962/10940] ---- BYOL Training Loss = 0.20797614753246307
31-01-2023 04:18:56 INFO Epoch 4: [4973/10940] ---- BYOL Training Loss = 0.29800736904144287
31-01-2023 04:19:49 INFO Epoch 4: [4973/10940] ---- BYOL Validation Loss = 0.11529151350259781
31-01-2023 04:20:07 INFO Epoch 4: [4984/10940] ---- BYOL Training Loss = 0.3169153928756714
31-01-2023 04:20:25 INFO Epoch 4: [4995/10940] ---- BYOL Training Loss = 0.22953276336193085
31-01-2023 04:20:42 INFO Epoch 4: [5006/10940] ---- BYOL Training Loss = 0.23495562374591827
31-01-2023 04:21:01 INFO Epoch 4: [5017/10940] ---- BYOL Training Loss = 0.26427847146987915
31-01-2023 04:21:54 INFO Epoch 4: [5017/10940] ---- BYOL Validation Loss = 0.1124153658747673
31-01-2023 04:22:11 INFO Epoch 4: [5028/10940] ---- BYOL Training Loss = 0.26458674669265747
31-01-2023 04:22:29 INFO Epoch 4: [5039/10940] ---- BYOL Training Loss = 0.18853934109210968
31-01-2023 04:22:47 INFO Epoch 4: [5050/10940] ---- BYOL Training Loss = 0.17074255645275116
31-01-2023 04:23:05 INFO Epoch 4: [5061/10940] ---- BYOL Training Loss = 0.17887619137763977
31-01-2023 04:23:58 INFO Epoch 4: [5061/10940] ---- BYOL Validation Loss = 0.11490283906459808
31-01-2023 04:24:16 INFO Epoch 4: [5072/10940] ---- BYOL Training Loss = 0.14060527086257935
31-01-2023 04:24:34 INFO Epoch 4: [5083/10940] ---- BYOL Training Loss = 0.16988824307918549
31-01-2023 04:24:52 INFO Epoch 4: [5094/10940] ---- BYOL Training Loss = 0.16557994484901428
31-01-2023 04:25:10 INFO Epoch 4: [5105/10940] ---- BYOL Training Loss = 0.14325910806655884
31-01-2023 04:26:03 INFO Epoch 4: [5105/10940] ---- BYOL Validation Loss = 0.11742474138736725
31-01-2023 04:26:21 INFO Epoch 4: [5116/10940] ---- BYOL Training Loss = 0.21907345950603485
31-01-2023 04:26:39 INFO Epoch 4: [5127/10940] ---- BYOL Training Loss = 0.3076609969139099
31-01-2023 04:26:57 INFO Epoch 4: [5138/10940] ---- BYOL Training Loss = 0.2023572027683258
31-01-2023 04:27:15 INFO Epoch 4: [5149/10940] ---- BYOL Training Loss = 0.18752074241638184
31-01-2023 04:28:08 INFO Epoch 4: [5149/10940] ---- BYOL Validation Loss = 0.14895932376384735
31-01-2023 04:28:26 INFO Epoch 4: [5160/10940] ---- BYOL Training Loss = 0.22260455787181854
31-01-2023 04:28:44 INFO Epoch 4: [5171/10940] ---- BYOL Training Loss = 0.24791459739208221
31-01-2023 04:29:02 INFO Epoch 4: [5182/10940] ---- BYOL Training Loss = 0.2885226607322693
31-01-2023 04:29:20 INFO Epoch 4: [5193/10940] ---- BYOL Training Loss = 0.2274065911769867
31-01-2023 04:30:13 INFO Epoch 4: [5193/10940] ---- BYOL Validation Loss = 0.1474013477563858
31-01-2023 04:30:31 INFO Epoch 4: [5204/10940] ---- BYOL Training Loss = 0.20846721529960632
31-01-2023 04:30:49 INFO Epoch 4: [5215/10940] ---- BYOL Training Loss = 0.17904692888259888
31-01-2023 04:31:07 INFO Epoch 4: [5226/10940] ---- BYOL Training Loss = 0.17741723358631134
31-01-2023 04:31:25 INFO Epoch 4: [5237/10940] ---- BYOL Training Loss = 0.1988646388053894
31-01-2023 04:32:18 INFO Epoch 4: [5237/10940] ---- BYOL Validation Loss = 0.15768353641033173
31-01-2023 04:32:35 INFO Epoch 4: [5248/10940] ---- BYOL Training Loss = 0.1973453164100647
31-01-2023 04:32:53 INFO Epoch 4: [5259/10940] ---- BYOL Training Loss = 0.17322339117527008
31-01-2023 04:33:12 INFO Epoch 4: [5270/10940] ---- BYOL Training Loss = 0.16238953173160553
31-01-2023 04:33:30 INFO Epoch 4: [5281/10940] ---- BYOL Training Loss = 0.18393641710281372
31-01-2023 04:34:22 INFO Epoch 4: [5281/10940] ---- BYOL Validation Loss = 0.1527680605649948
31-01-2023 04:34:40 INFO Epoch 4: [5292/10940] ---- BYOL Training Loss = 0.1725807636976242
31-01-2023 04:34:58 INFO Epoch 4: [5303/10940] ---- BYOL Training Loss = 0.16243615746498108
31-01-2023 04:35:16 INFO Epoch 4: [5314/10940] ---- BYOL Training Loss = 0.20412936806678772
31-01-2023 04:35:35 INFO Epoch 4: [5325/10940] ---- BYOL Training Loss = 0.18678972125053406
31-01-2023 04:36:27 INFO Epoch 4: [5325/10940] ---- BYOL Validation Loss = 0.15898005664348602
31-01-2023 04:36:45 INFO Epoch 4: [5336/10940] ---- BYOL Training Loss = 0.14171788096427917
31-01-2023 04:37:03 INFO Epoch 4: [5347/10940] ---- BYOL Training Loss = 0.1779020130634308
31-01-2023 04:37:21 INFO Epoch 4: [5358/10940] ---- BYOL Training Loss = 0.2416309118270874
31-01-2023 04:37:40 INFO Epoch 4: [5369/10940] ---- BYOL Training Loss = 0.20408101379871368
31-01-2023 04:38:32 INFO Epoch 4: [5369/10940] ---- BYOL Validation Loss = 0.1601533442735672
31-01-2023 04:38:50 INFO Epoch 4: [5380/10940] ---- BYOL Training Loss = 0.1664460152387619
31-01-2023 04:39:08 INFO Epoch 4: [5391/10940] ---- BYOL Training Loss = 0.15839478373527527
31-01-2023 04:39:26 INFO Epoch 4: [5402/10940] ---- BYOL Training Loss = 0.18798640370368958
31-01-2023 04:39:44 INFO Epoch 4: [5413/10940] ---- BYOL Training Loss = 0.19265872240066528
31-01-2023 04:40:37 INFO Epoch 4: [5413/10940] ---- BYOL Validation Loss = 0.14506983757019043
31-01-2023 04:40:55 INFO Epoch 4: [5424/10940] ---- BYOL Training Loss = 0.18599078059196472
31-01-2023 04:41:13 INFO Epoch 4: [5435/10940] ---- BYOL Training Loss = 0.16748295724391937
31-01-2023 04:41:31 INFO Epoch 4: [5446/10940] ---- BYOL Training Loss = 0.14860883355140686
31-01-2023 04:41:49 INFO Epoch 4: [5457/10940] ---- BYOL Training Loss = 0.11886535584926605
31-01-2023 04:42:42 INFO Epoch 4: [5457/10940] ---- BYOL Validation Loss = 0.10493332147598267
31-01-2023 04:43:00 INFO Epoch 4: [5468/10940] ---- BYOL Training Loss = 0.15083268284797668
31-01-2023 04:43:18 INFO Epoch 4: [5479/10940] ---- BYOL Training Loss = 0.19512097537517548
31-01-2023 04:43:36 INFO Epoch 4: [5490/10940] ---- BYOL Training Loss = 0.1632983535528183
31-01-2023 04:43:54 INFO Epoch 4: [5501/10940] ---- BYOL Training Loss = 0.14376896619796753
31-01-2023 04:44:47 INFO Epoch 4: [5501/10940] ---- BYOL Validation Loss = 0.13449683785438538
31-01-2023 04:45:05 INFO Epoch 4: [5512/10940] ---- BYOL Training Loss = 0.21134093403816223
31-01-2023 04:45:23 INFO Epoch 4: [5523/10940] ---- BYOL Training Loss = 0.2172713279724121
31-01-2023 04:45:41 INFO Epoch 4: [5534/10940] ---- BYOL Training Loss = 0.18773427605628967
31-01-2023 04:45:59 INFO Epoch 4: [5545/10940] ---- BYOL Training Loss = 0.18154427409172058
31-01-2023 04:46:52 INFO Epoch 4: [5545/10940] ---- BYOL Validation Loss = 0.091966912150383
31-01-2023 04:47:10 INFO Epoch 4: [5556/10940] ---- BYOL Training Loss = 0.1568925976753235
31-01-2023 04:47:28 INFO Epoch 4: [5567/10940] ---- BYOL Training Loss = 0.13731063902378082
31-01-2023 04:47:46 INFO Epoch 4: [5578/10940] ---- BYOL Training Loss = 0.1421186327934265
31-01-2023 04:48:04 INFO Epoch 4: [5589/10940] ---- BYOL Training Loss = 0.13099698722362518
31-01-2023 04:48:57 INFO Epoch 4: [5589/10940] ---- BYOL Validation Loss = 0.0707383081316948
31-01-2023 04:49:14 INFO Epoch 4: [5600/10940] ---- BYOL Training Loss = 0.13579905033111572
31-01-2023 04:49:33 INFO Epoch 4: [5611/10940] ---- BYOL Training Loss = 0.19928869605064392
31-01-2023 04:49:51 INFO Epoch 4: [5622/10940] ---- BYOL Training Loss = 0.2222295105457306
31-01-2023 04:50:09 INFO Epoch 4: [5633/10940] ---- BYOL Training Loss = 0.16135194897651672
31-01-2023 04:51:02 INFO Epoch 4: [5633/10940] ---- BYOL Validation Loss = 0.12107609212398529
31-01-2023 04:51:19 INFO Epoch 4: [5644/10940] ---- BYOL Training Loss = 0.1777290552854538
31-01-2023 04:51:38 INFO Epoch 4: [5655/10940] ---- BYOL Training Loss = 0.18523555994033813
31-01-2023 04:51:56 INFO Epoch 4: [5666/10940] ---- BYOL Training Loss = 0.15122075378894806
31-01-2023 04:52:14 INFO Epoch 4: [5677/10940] ---- BYOL Training Loss = 0.17458543181419373
31-01-2023 04:53:07 INFO Epoch 4: [5677/10940] ---- BYOL Validation Loss = 0.12779764831066132
31-01-2023 04:53:24 INFO Epoch 4: [5688/10940] ---- BYOL Training Loss = 0.2709011435508728
31-01-2023 04:53:43 INFO Epoch 4: [5699/10940] ---- BYOL Training Loss = 0.24874277412891388
31-01-2023 04:54:01 INFO Epoch 4: [5710/10940] ---- BYOL Training Loss = 0.18472883105278015
31-01-2023 04:54:19 INFO Epoch 4: [5721/10940] ---- BYOL Training Loss = 0.21150481700897217
31-01-2023 04:55:11 INFO Epoch 4: [5721/10940] ---- BYOL Validation Loss = 0.13476133346557617
31-01-2023 04:55:29 INFO Epoch 4: [5732/10940] ---- BYOL Training Loss = 0.22148743271827698
31-01-2023 04:55:48 INFO Epoch 4: [5743/10940] ---- BYOL Training Loss = 0.19554434716701508
31-01-2023 04:56:06 INFO Epoch 4: [5754/10940] ---- BYOL Training Loss = 0.1377420723438263
31-01-2023 04:56:24 INFO Epoch 4: [5765/10940] ---- BYOL Training Loss = 0.15904682874679565
31-01-2023 04:57:16 INFO Epoch 4: [5765/10940] ---- BYOL Validation Loss = 0.143715038895607
31-01-2023 04:57:34 INFO Epoch 4: [5776/10940] ---- BYOL Training Loss = 0.1590769737958908
31-01-2023 04:57:52 INFO Epoch 4: [5787/10940] ---- BYOL Training Loss = 0.147750124335289
31-01-2023 04:58:10 INFO Epoch 4: [5798/10940] ---- BYOL Training Loss = 0.16752463579177856
31-01-2023 04:58:28 INFO Epoch 4: [5809/10940] ---- BYOL Training Loss = 0.18357446789741516
31-01-2023 04:59:21 INFO Epoch 4: [5809/10940] ---- BYOL Validation Loss = 0.10073832422494888
31-01-2023 04:59:39 INFO Epoch 4: [5820/10940] ---- BYOL Training Loss = 0.15900437533855438
31-01-2023 04:59:57 INFO Epoch 4: [5831/10940] ---- BYOL Training Loss = 0.125102236866951
31-01-2023 05:00:15 INFO Epoch 4: [5842/10940] ---- BYOL Training Loss = 0.2252555787563324
31-01-2023 05:00:33 INFO Epoch 4: [5853/10940] ---- BYOL Training Loss = 0.20853562653064728
31-01-2023 05:01:26 INFO Epoch 4: [5853/10940] ---- BYOL Validation Loss = 0.08782648295164108
31-01-2023 05:01:44 INFO Epoch 4: [5864/10940] ---- BYOL Training Loss = 0.14439743757247925
31-01-2023 05:02:02 INFO Epoch 4: [5875/10940] ---- BYOL Training Loss = 0.14789970219135284
31-01-2023 05:02:20 INFO Epoch 4: [5886/10940] ---- BYOL Training Loss = 0.2947361171245575
31-01-2023 05:02:38 INFO Epoch 4: [5897/10940] ---- BYOL Training Loss = 0.2521944046020508
31-01-2023 05:03:31 INFO Epoch 4: [5897/10940] ---- BYOL Validation Loss = 0.12587741017341614
31-01-2023 05:03:48 INFO Epoch 4: [5908/10940] ---- BYOL Training Loss = 0.17649085819721222
31-01-2023 05:04:07 INFO Epoch 4: [5919/10940] ---- BYOL Training Loss = 0.21427381038665771
31-01-2023 05:04:25 INFO Epoch 4: [5930/10940] ---- BYOL Training Loss = 0.1759706437587738
31-01-2023 05:04:43 INFO Epoch 4: [5941/10940] ---- BYOL Training Loss = 0.18333518505096436
31-01-2023 05:05:36 INFO Epoch 4: [5941/10940] ---- BYOL Validation Loss = 0.10772854089736938
31-01-2023 05:05:53 INFO Epoch 4: [5952/10940] ---- BYOL Training Loss = 0.20726390182971954
31-01-2023 05:06:11 INFO Epoch 4: [5963/10940] ---- BYOL Training Loss = 0.13726866245269775
31-01-2023 05:06:30 INFO Epoch 4: [5974/10940] ---- BYOL Training Loss = 0.13637998700141907
31-01-2023 05:06:48 INFO Epoch 4: [5985/10940] ---- BYOL Training Loss = 0.13618330657482147
31-01-2023 05:07:41 INFO Epoch 4: [5985/10940] ---- BYOL Validation Loss = 0.09557066857814789
31-01-2023 05:07:58 INFO Epoch 4: [5996/10940] ---- BYOL Training Loss = 0.13425244390964508
31-01-2023 05:08:16 INFO Epoch 4: [6007/10940] ---- BYOL Training Loss = 0.132120281457901
31-01-2023 05:08:35 INFO Epoch 4: [6018/10940] ---- BYOL Training Loss = 0.19366519153118134
31-01-2023 05:08:53 INFO Epoch 4: [6029/10940] ---- BYOL Training Loss = 0.25324171781539917
31-01-2023 05:09:46 INFO Epoch 4: [6029/10940] ---- BYOL Validation Loss = 0.11251933127641678
31-01-2023 05:10:03 INFO Epoch 4: [6040/10940] ---- BYOL Training Loss = 0.2174346148967743
31-01-2023 05:10:21 INFO Epoch 4: [6051/10940] ---- BYOL Training Loss = 0.17965376377105713
31-01-2023 05:10:40 INFO Epoch 4: [6062/10940] ---- BYOL Training Loss = 0.15570196509361267
31-01-2023 05:10:58 INFO Epoch 4: [6073/10940] ---- BYOL Training Loss = 0.16374048590660095
31-01-2023 05:11:50 INFO Epoch 4: [6073/10940] ---- BYOL Validation Loss = 0.10839533060789108
31-01-2023 05:12:08 INFO Epoch 4: [6084/10940] ---- BYOL Training Loss = 0.20110981166362762
31-01-2023 05:12:27 INFO Epoch 4: [6095/10940] ---- BYOL Training Loss = 0.20117442309856415
31-01-2023 05:12:45 INFO Epoch 4: [6106/10940] ---- BYOL Training Loss = 0.1783784031867981
31-01-2023 05:13:03 INFO Epoch 4: [6117/10940] ---- BYOL Training Loss = 0.22771696746349335
31-01-2023 05:13:55 INFO Epoch 4: [6117/10940] ---- BYOL Validation Loss = 0.12787429988384247
31-01-2023 05:14:13 INFO Epoch 4: [6128/10940] ---- BYOL Training Loss = 0.20931503176689148
31-01-2023 05:14:32 INFO Epoch 4: [6139/10940] ---- BYOL Training Loss = 0.18511125445365906
31-01-2023 05:14:50 INFO Epoch 4: [6150/10940] ---- BYOL Training Loss = 0.17029841244220734
31-01-2023 05:15:08 INFO Epoch 4: [6161/10940] ---- BYOL Training Loss = 0.18804879486560822
31-01-2023 05:16:00 INFO Epoch 4: [6161/10940] ---- BYOL Validation Loss = 0.1315387338399887
31-01-2023 05:16:18 INFO Epoch 4: [6172/10940] ---- BYOL Training Loss = 0.1859641671180725
31-01-2023 05:16:37 INFO Epoch 4: [6183/10940] ---- BYOL Training Loss = 0.17264105379581451
31-01-2023 05:16:55 INFO Epoch 4: [6194/10940] ---- BYOL Training Loss = 0.18398132920265198
31-01-2023 05:17:13 INFO Epoch 4: [6205/10940] ---- BYOL Training Loss = 0.1709688901901245
31-01-2023 05:18:06 INFO Epoch 4: [6205/10940] ---- BYOL Validation Loss = 0.11762852221727371
31-01-2023 05:18:24 INFO Epoch 4: [6216/10940] ---- BYOL Training Loss = 0.1557846963405609
31-01-2023 05:18:42 INFO Epoch 4: [6227/10940] ---- BYOL Training Loss = 0.19785915315151215
31-01-2023 05:19:01 INFO Epoch 4: [6238/10940] ---- BYOL Training Loss = 0.18702398240566254
31-01-2023 05:19:19 INFO Epoch 4: [6249/10940] ---- BYOL Training Loss = 0.12715022265911102
31-01-2023 05:20:11 INFO Epoch 4: [6249/10940] ---- BYOL Validation Loss = 0.0799863189458847
31-01-2023 05:20:29 INFO Epoch 4: [6260/10940] ---- BYOL Training Loss = 0.1609906554222107
31-01-2023 05:20:48 INFO Epoch 4: [6271/10940] ---- BYOL Training Loss = 0.24271313846111298
31-01-2023 05:21:06 INFO Epoch 4: [6282/10940] ---- BYOL Training Loss = 0.21069884300231934
31-01-2023 05:21:24 INFO Epoch 4: [6293/10940] ---- BYOL Training Loss = 0.18273955583572388
31-01-2023 05:22:17 INFO Epoch 4: [6293/10940] ---- BYOL Validation Loss = 0.14736969769001007
31-01-2023 05:22:34 INFO Epoch 4: [6304/10940] ---- BYOL Training Loss = 0.21840214729309082
31-01-2023 05:22:53 INFO Epoch 4: [6315/10940] ---- BYOL Training Loss = 0.2390572726726532
31-01-2023 05:23:11 INFO Epoch 4: [6326/10940] ---- BYOL Training Loss = 0.1730298101902008
31-01-2023 05:23:29 INFO Epoch 4: [6337/10940] ---- BYOL Training Loss = 0.13071981072425842
31-01-2023 05:24:22 INFO Epoch 4: [6337/10940] ---- BYOL Validation Loss = 0.1434500515460968
31-01-2023 05:24:40 INFO Epoch 4: [6348/10940] ---- BYOL Training Loss = 0.17790839076042175
31-01-2023 05:24:58 INFO Epoch 4: [6359/10940] ---- BYOL Training Loss = 0.20535652339458466
31-01-2023 05:25:16 INFO Epoch 4: [6370/10940] ---- BYOL Training Loss = 0.1580606997013092
31-01-2023 05:25:35 INFO Epoch 4: [6381/10940] ---- BYOL Training Loss = 0.15861305594444275
31-01-2023 05:26:27 INFO Epoch 4: [6381/10940] ---- BYOL Validation Loss = 0.15386764705181122
31-01-2023 05:26:45 INFO Epoch 4: [6392/10940] ---- BYOL Training Loss = 0.20139209926128387
31-01-2023 05:27:04 INFO Epoch 4: [6403/10940] ---- BYOL Training Loss = 0.18630088865756989
31-01-2023 05:27:22 INFO Epoch 4: [6414/10940] ---- BYOL Training Loss = 0.1835702806711197
31-01-2023 05:27:40 INFO Epoch 4: [6425/10940] ---- BYOL Training Loss = 0.19380435347557068
31-01-2023 05:28:33 INFO Epoch 4: [6425/10940] ---- BYOL Validation Loss = 0.14033247530460358
31-01-2023 05:28:51 INFO Epoch 4: [6436/10940] ---- BYOL Training Loss = 0.13864216208457947
31-01-2023 05:29:09 INFO Epoch 4: [6447/10940] ---- BYOL Training Loss = 0.1340462863445282
31-01-2023 05:29:27 INFO Epoch 4: [6458/10940] ---- BYOL Training Loss = 0.15956071019172668
31-01-2023 05:29:45 INFO Epoch 4: [6469/10940] ---- BYOL Training Loss = 0.1412358582019806
31-01-2023 05:30:38 INFO Epoch 4: [6469/10940] ---- BYOL Validation Loss = 0.07336509227752686
31-01-2023 05:30:56 INFO Epoch 4: [6480/10940] ---- BYOL Training Loss = 0.14479316771030426
31-01-2023 05:31:14 INFO Epoch 4: [6491/10940] ---- BYOL Training Loss = 0.15507271885871887
31-01-2023 05:31:33 INFO Epoch 4: [6502/10940] ---- BYOL Training Loss = 0.20644743740558624
31-01-2023 05:31:51 INFO Epoch 4: [6513/10940] ---- BYOL Training Loss = 0.2001872956752777
31-01-2023 05:32:43 INFO Epoch 4: [6513/10940] ---- BYOL Validation Loss = 0.09299622476100922
31-01-2023 05:33:02 INFO Epoch 4: [6524/10940] ---- BYOL Training Loss = 0.16481050848960876
31-01-2023 05:33:20 INFO Epoch 4: [6535/10940] ---- BYOL Training Loss = 0.2547827959060669
31-01-2023 05:33:38 INFO Epoch 4: [6546/10940] ---- BYOL Training Loss = 0.29809969663619995
31-01-2023 05:33:57 INFO Epoch 4: [6557/10940] ---- BYOL Training Loss = 0.17117902636528015
31-01-2023 05:34:49 INFO Epoch 4: [6557/10940] ---- BYOL Validation Loss = 0.09952659904956818
31-01-2023 05:35:07 INFO Epoch 4: [6568/10940] ---- BYOL Training Loss = 0.1227615475654602
31-01-2023 05:35:25 INFO Epoch 4: [6579/10940] ---- BYOL Training Loss = 0.11421217769384384
31-01-2023 05:35:43 INFO Epoch 4: [6590/10940] ---- BYOL Training Loss = 0.1970360428094864
31-01-2023 05:36:02 INFO Epoch 4: [6601/10940] ---- BYOL Training Loss = 0.21849282085895538
31-01-2023 05:36:55 INFO Epoch 4: [6601/10940] ---- BYOL Validation Loss = 0.1036529392004013
31-01-2023 05:37:12 INFO Epoch 4: [6612/10940] ---- BYOL Training Loss = 0.2376527041196823
31-01-2023 05:37:31 INFO Epoch 4: [6623/10940] ---- BYOL Training Loss = 0.19846393167972565
31-01-2023 05:37:49 INFO Epoch 4: [6634/10940] ---- BYOL Training Loss = 0.16228166222572327
31-01-2023 05:38:07 INFO Epoch 4: [6645/10940] ---- BYOL Training Loss = 0.1627846360206604
31-01-2023 05:39:00 INFO Epoch 4: [6645/10940] ---- BYOL Validation Loss = 0.11409156769514084
31-01-2023 05:39:18 INFO Epoch 4: [6656/10940] ---- BYOL Training Loss = 0.14575907588005066
31-01-2023 05:39:36 INFO Epoch 4: [6667/10940] ---- BYOL Training Loss = 0.13642732799053192
31-01-2023 05:39:54 INFO Epoch 4: [6678/10940] ---- BYOL Training Loss = 0.15118825435638428
31-01-2023 05:40:13 INFO Epoch 4: [6689/10940] ---- BYOL Training Loss = 0.1982116401195526
31-01-2023 05:41:05 INFO Epoch 4: [6689/10940] ---- BYOL Validation Loss = 0.1175982803106308
31-01-2023 05:41:23 INFO Epoch 4: [6700/10940] ---- BYOL Training Loss = 0.19729836285114288
31-01-2023 05:41:42 INFO Epoch 4: [6711/10940] ---- BYOL Training Loss = 0.20849378407001495
31-01-2023 05:42:00 INFO Epoch 4: [6722/10940] ---- BYOL Training Loss = 0.18070977926254272
31-01-2023 05:42:18 INFO Epoch 4: [6733/10940] ---- BYOL Training Loss = 0.18559755384922028
31-01-2023 05:43:11 INFO Epoch 4: [6733/10940] ---- BYOL Validation Loss = 0.11495328694581985
31-01-2023 05:43:28 INFO Epoch 4: [6744/10940] ---- BYOL Training Loss = 0.21087250113487244
31-01-2023 05:43:47 INFO Epoch 4: [6755/10940] ---- BYOL Training Loss = 0.1753428727388382
31-01-2023 05:44:05 INFO Epoch 4: [6766/10940] ---- BYOL Training Loss = 0.15131840109825134
31-01-2023 05:44:23 INFO Epoch 4: [6777/10940] ---- BYOL Training Loss = 0.18141166865825653
31-01-2023 05:45:16 INFO Epoch 4: [6777/10940] ---- BYOL Validation Loss = 0.12658558785915375
31-01-2023 05:45:34 INFO Epoch 4: [6788/10940] ---- BYOL Training Loss = 0.19273917376995087
31-01-2023 05:45:52 INFO Epoch 4: [6799/10940] ---- BYOL Training Loss = 0.2139682024717331
31-01-2023 05:46:10 INFO Epoch 4: [6810/10940] ---- BYOL Training Loss = 0.23576977849006653
31-01-2023 05:46:29 INFO Epoch 4: [6821/10940] ---- BYOL Training Loss = 0.18170778453350067
31-01-2023 05:47:22 INFO Epoch 4: [6821/10940] ---- BYOL Validation Loss = 0.12947502732276917
31-01-2023 05:47:40 INFO Epoch 4: [6832/10940] ---- BYOL Training Loss = 0.14855390787124634
31-01-2023 05:47:58 INFO Epoch 4: [6843/10940] ---- BYOL Training Loss = 0.15793779492378235
31-01-2023 05:48:16 INFO Epoch 4: [6854/10940] ---- BYOL Training Loss = 0.14794807136058807
31-01-2023 05:48:35 INFO Epoch 4: [6865/10940] ---- BYOL Training Loss = 0.1944442093372345
31-01-2023 05:49:27 INFO Epoch 4: [6865/10940] ---- BYOL Validation Loss = 0.1346544325351715
31-01-2023 05:49:45 INFO Epoch 4: [6876/10940] ---- BYOL Training Loss = 0.20358839631080627
31-01-2023 05:50:03 INFO Epoch 4: [6887/10940] ---- BYOL Training Loss = 0.17648592591285706
31-01-2023 05:50:21 INFO Epoch 4: [6898/10940] ---- BYOL Training Loss = 0.1464691460132599
31-01-2023 05:50:40 INFO Epoch 4: [6909/10940] ---- BYOL Training Loss = 0.14449572563171387
31-01-2023 05:51:32 INFO Epoch 4: [6909/10940] ---- BYOL Validation Loss = 0.1172875314950943
31-01-2023 05:51:50 INFO Epoch 4: [6920/10940] ---- BYOL Training Loss = 0.18008816242218018
31-01-2023 05:52:08 INFO Epoch 4: [6931/10940] ---- BYOL Training Loss = 0.2127973735332489
31-01-2023 05:52:27 INFO Epoch 4: [6942/10940] ---- BYOL Training Loss = 0.17329128086566925
31-01-2023 05:52:45 INFO Epoch 4: [6953/10940] ---- BYOL Training Loss = 0.19020512700080872
31-01-2023 05:53:38 INFO Epoch 4: [6953/10940] ---- BYOL Validation Loss = 0.1278231143951416
31-01-2023 05:53:55 INFO Epoch 4: [6964/10940] ---- BYOL Training Loss = 0.20471322536468506
31-01-2023 05:54:14 INFO Epoch 4: [6975/10940] ---- BYOL Training Loss = 0.1661837249994278
31-01-2023 05:54:32 INFO Epoch 4: [6986/10940] ---- BYOL Training Loss = 0.18598207831382751
31-01-2023 05:54:50 INFO Epoch 4: [6997/10940] ---- BYOL Training Loss = 0.16730694472789764
31-01-2023 05:55:43 INFO Epoch 4: [6997/10940] ---- BYOL Validation Loss = 0.15890777111053467
31-01-2023 05:56:01 INFO Epoch 4: [7008/10940] ---- BYOL Training Loss = 0.16870269179344177
31-01-2023 05:56:19 INFO Epoch 4: [7019/10940] ---- BYOL Training Loss = 0.1566634327173233
31-01-2023 05:56:37 INFO Epoch 4: [7030/10940] ---- BYOL Training Loss = 0.13643357157707214
31-01-2023 05:56:56 INFO Epoch 4: [7041/10940] ---- BYOL Training Loss = 0.1431022733449936
31-01-2023 05:57:48 INFO Epoch 4: [7041/10940] ---- BYOL Validation Loss = 0.13196894526481628
31-01-2023 05:58:06 INFO Epoch 4: [7052/10940] ---- BYOL Training Loss = 0.18324509263038635
31-01-2023 05:58:25 INFO Epoch 4: [7063/10940] ---- BYOL Training Loss = 0.2044122964143753
31-01-2023 05:58:43 INFO Epoch 4: [7074/10940] ---- BYOL Training Loss = 0.14284971356391907
31-01-2023 05:59:01 INFO Epoch 4: [7085/10940] ---- BYOL Training Loss = 0.15902724862098694
31-01-2023 05:59:54 INFO Epoch 4: [7085/10940] ---- BYOL Validation Loss = 0.12351645529270172
31-01-2023 06:00:12 INFO Epoch 4: [7096/10940] ---- BYOL Training Loss = 0.16974927484989166
31-01-2023 06:00:30 INFO Epoch 4: [7107/10940] ---- BYOL Training Loss = 0.1930985152721405
31-01-2023 06:00:48 INFO Epoch 4: [7118/10940] ---- BYOL Training Loss = 0.18363913893699646
31-01-2023 06:01:07 INFO Epoch 4: [7129/10940] ---- BYOL Training Loss = 0.1760791838169098
31-01-2023 06:02:00 INFO Epoch 4: [7129/10940] ---- BYOL Validation Loss = 0.15302036702632904
31-01-2023 06:02:17 INFO Epoch 4: [7140/10940] ---- BYOL Training Loss = 0.15190459787845612
31-01-2023 06:02:36 INFO Epoch 4: [7151/10940] ---- BYOL Training Loss = 0.14376309514045715
31-01-2023 06:02:54 INFO Epoch 4: [7162/10940] ---- BYOL Training Loss = 0.2041594535112381
31-01-2023 06:03:12 INFO Epoch 4: [7173/10940] ---- BYOL Training Loss = 0.21450753509998322
31-01-2023 06:04:05 INFO Epoch 4: [7173/10940] ---- BYOL Validation Loss = 0.09003689140081406
31-01-2023 06:04:23 INFO Epoch 4: [7184/10940] ---- BYOL Training Loss = 0.19255688786506653
31-01-2023 06:04:41 INFO Epoch 4: [7195/10940] ---- BYOL Training Loss = 0.2450934201478958
31-01-2023 06:04:59 INFO Epoch 4: [7206/10940] ---- BYOL Training Loss = 0.2636358141899109
31-01-2023 06:05:18 INFO Epoch 4: [7217/10940] ---- BYOL Training Loss = 0.14956960082054138
31-01-2023 06:06:10 INFO Epoch 4: [7217/10940] ---- BYOL Validation Loss = 0.13191916048526764
31-01-2023 06:06:28 INFO Epoch 4: [7228/10940] ---- BYOL Training Loss = 0.14088018238544464
31-01-2023 06:06:47 INFO Epoch 4: [7239/10940] ---- BYOL Training Loss = 0.12898552417755127
31-01-2023 06:07:05 INFO Epoch 4: [7250/10940] ---- BYOL Training Loss = 0.1270497441291809
31-01-2023 06:07:23 INFO Epoch 4: [7261/10940] ---- BYOL Training Loss = 0.13061368465423584
31-01-2023 06:08:16 INFO Epoch 4: [7261/10940] ---- BYOL Validation Loss = 0.11065398156642914
31-01-2023 06:08:34 INFO Epoch 4: [7272/10940] ---- BYOL Training Loss = 0.17996986210346222
31-01-2023 06:08:52 INFO Epoch 4: [7283/10940] ---- BYOL Training Loss = 0.20768217742443085
31-01-2023 06:09:10 INFO Epoch 4: [7294/10940] ---- BYOL Training Loss = 0.18214017152786255
31-01-2023 06:09:29 INFO Epoch 4: [7305/10940] ---- BYOL Training Loss = 0.1269015073776245
31-01-2023 06:10:22 INFO Epoch 4: [7305/10940] ---- BYOL Validation Loss = 0.11782616376876831
31-01-2023 06:10:40 INFO Epoch 4: [7316/10940] ---- BYOL Training Loss = 0.1561724841594696
31-01-2023 06:10:58 INFO Epoch 4: [7327/10940] ---- BYOL Training Loss = 0.19998973608016968
31-01-2023 06:11:16 INFO Epoch 4: [7338/10940] ---- BYOL Training Loss = 0.14841090142726898
31-01-2023 06:11:34 INFO Epoch 4: [7349/10940] ---- BYOL Training Loss = 0.15185950696468353
31-01-2023 06:12:27 INFO Epoch 4: [7349/10940] ---- BYOL Validation Loss = 0.08010508865118027
31-01-2023 06:12:45 INFO Epoch 4: [7360/10940] ---- BYOL Training Loss = 0.14734889566898346
31-01-2023 06:13:03 INFO Epoch 4: [7371/10940] ---- BYOL Training Loss = 0.17516227066516876
31-01-2023 06:13:22 INFO Epoch 4: [7382/10940] ---- BYOL Training Loss = 0.14655570685863495
31-01-2023 06:13:40 INFO Epoch 4: [7393/10940] ---- BYOL Training Loss = 0.20776918530464172
31-01-2023 06:14:33 INFO Epoch 4: [7393/10940] ---- BYOL Validation Loss = 0.11438757926225662
31-01-2023 06:14:50 INFO Epoch 4: [7404/10940] ---- BYOL Training Loss = 0.27564167976379395
31-01-2023 06:15:09 INFO Epoch 4: [7415/10940] ---- BYOL Training Loss = 0.22723321616649628
31-01-2023 06:15:27 INFO Epoch 4: [7426/10940] ---- BYOL Training Loss = 0.20147261023521423
31-01-2023 06:15:46 INFO Epoch 4: [7437/10940] ---- BYOL Training Loss = 0.20786774158477783
31-01-2023 06:16:38 INFO Epoch 4: [7437/10940] ---- BYOL Validation Loss = 0.14920783042907715
31-01-2023 06:16:56 INFO Epoch 4: [7448/10940] ---- BYOL Training Loss = 0.16241328418254852
31-01-2023 06:17:15 INFO Epoch 4: [7459/10940] ---- BYOL Training Loss = 0.16299572587013245
31-01-2023 06:17:33 INFO Epoch 4: [7470/10940] ---- BYOL Training Loss = 0.22447237372398376
31-01-2023 06:17:51 INFO Epoch 4: [7481/10940] ---- BYOL Training Loss = 0.25044959783554077
31-01-2023 06:18:44 INFO Epoch 4: [7481/10940] ---- BYOL Validation Loss = 0.1815720647573471
31-01-2023 06:19:02 INFO Epoch 4: [7492/10940] ---- BYOL Training Loss = 0.206243634223938
31-01-2023 06:19:20 INFO Epoch 4: [7503/10940] ---- BYOL Training Loss = 0.18294201791286469
31-01-2023 06:19:39 INFO Epoch 4: [7514/10940] ---- BYOL Training Loss = 0.17147645354270935
31-01-2023 06:19:57 INFO Epoch 4: [7525/10940] ---- BYOL Training Loss = 0.16261088848114014
31-01-2023 06:20:50 INFO Epoch 4: [7525/10940] ---- BYOL Validation Loss = 0.18451592326164246
31-01-2023 06:21:08 INFO Epoch 4: [7536/10940] ---- BYOL Training Loss = 0.1625462770462036
31-01-2023 06:21:26 INFO Epoch 4: [7547/10940] ---- BYOL Training Loss = 0.1828216016292572
31-01-2023 06:21:45 INFO Epoch 4: [7558/10940] ---- BYOL Training Loss = 0.2075725495815277
31-01-2023 06:22:03 INFO Epoch 4: [7569/10940] ---- BYOL Training Loss = 0.20340797305107117
31-01-2023 06:22:55 INFO Epoch 4: [7569/10940] ---- BYOL Validation Loss = 0.17950239777565002
31-01-2023 06:23:13 INFO Epoch 4: [7580/10940] ---- BYOL Training Loss = 0.18647156655788422
31-01-2023 06:23:32 INFO Epoch 4: [7591/10940] ---- BYOL Training Loss = 0.2008868157863617
31-01-2023 06:23:50 INFO Epoch 4: [7602/10940] ---- BYOL Training Loss = 0.2024497538805008
31-01-2023 06:24:09 INFO Epoch 4: [7613/10940] ---- BYOL Training Loss = 0.18842385709285736
31-01-2023 06:25:01 INFO Epoch 4: [7613/10940] ---- BYOL Validation Loss = 0.1752956211566925
31-01-2023 06:25:19 INFO Epoch 4: [7624/10940] ---- BYOL Training Loss = 0.13763055205345154
31-01-2023 06:25:37 INFO Epoch 4: [7635/10940] ---- BYOL Training Loss = 0.1629367172718048
31-01-2023 06:25:56 INFO Epoch 4: [7646/10940] ---- BYOL Training Loss = 0.16925077140331268
31-01-2023 06:26:14 INFO Epoch 4: [7657/10940] ---- BYOL Training Loss = 0.17469659447669983
31-01-2023 06:27:07 INFO Epoch 4: [7657/10940] ---- BYOL Validation Loss = 0.13567300140857697
31-01-2023 06:27:25 INFO Epoch 4: [7668/10940] ---- BYOL Training Loss = 0.24010758101940155
31-01-2023 06:27:43 INFO Epoch 4: [7679/10940] ---- BYOL Training Loss = 0.25947290658950806
31-01-2023 06:28:01 INFO Epoch 4: [7690/10940] ---- BYOL Training Loss = 0.1641414314508438
31-01-2023 06:28:19 INFO Epoch 4: [7701/10940] ---- BYOL Training Loss = 0.21572265028953552
31-01-2023 06:29:12 INFO Epoch 4: [7701/10940] ---- BYOL Validation Loss = 0.18819859623908997
31-01-2023 06:29:30 INFO Epoch 4: [7712/10940] ---- BYOL Training Loss = 0.24287119507789612
31-01-2023 06:29:49 INFO Epoch 4: [7723/10940] ---- BYOL Training Loss = 0.2109145224094391
31-01-2023 06:30:07 INFO Epoch 4: [7734/10940] ---- BYOL Training Loss = 0.20550119876861572
31-01-2023 06:30:25 INFO Epoch 4: [7745/10940] ---- BYOL Training Loss = 0.24824419617652893
31-01-2023 06:31:18 INFO Epoch 4: [7745/10940] ---- BYOL Validation Loss = 0.12666168808937073
31-01-2023 06:31:36 INFO Epoch 4: [7756/10940] ---- BYOL Training Loss = 0.27527740597724915
31-01-2023 06:31:54 INFO Epoch 4: [7767/10940] ---- BYOL Training Loss = 0.29598313570022583
31-01-2023 06:32:13 INFO Epoch 4: [7778/10940] ---- BYOL Training Loss = 0.24653366208076477
31-01-2023 06:32:31 INFO Epoch 4: [7789/10940] ---- BYOL Training Loss = 0.26253974437713623
31-01-2023 06:33:24 INFO Epoch 4: [7789/10940] ---- BYOL Validation Loss = 0.24310050904750824
31-01-2023 06:33:42 INFO Epoch 4: [7800/10940] ---- BYOL Training Loss = 0.25343817472457886
31-01-2023 06:34:00 INFO Epoch 4: [7811/10940] ---- BYOL Training Loss = 0.24397239089012146
31-01-2023 06:34:19 INFO Epoch 4: [7822/10940] ---- BYOL Training Loss = 0.24378249049186707
31-01-2023 06:34:37 INFO Epoch 4: [7833/10940] ---- BYOL Training Loss = 0.22866205871105194
31-01-2023 06:35:30 INFO Epoch 4: [7833/10940] ---- BYOL Validation Loss = 0.17910169064998627
31-01-2023 06:35:47 INFO Epoch 4: [7844/10940] ---- BYOL Training Loss = 0.23576907813549042
31-01-2023 06:36:06 INFO Epoch 4: [7855/10940] ---- BYOL Training Loss = 0.24151650071144104
31-01-2023 06:36:24 INFO Epoch 4: [7866/10940] ---- BYOL Training Loss = 0.21230193972587585
31-01-2023 06:36:43 INFO Epoch 4: [7877/10940] ---- BYOL Training Loss = 0.25795257091522217
31-01-2023 06:37:35 INFO Epoch 4: [7877/10940] ---- BYOL Validation Loss = 0.20027555525302887
slurmstepd-landonia23: error: *** JOB 1508004 ON landonia23 CANCELLED AT 2023-01-31T06:37:44 DUE TO TIME LIMIT ***
