29-01-2023 21:19:07 INFO Running main & importing modules...
29-01-2023 21:19:20 INFO Parsed arguments: Namespace(batch_size=32, byol_ema_tau=0.99, debug=False, encoder='resnet34', encoder_layer_idx=-2, epochs=5, experiment_name='b-resnet34-e5-b32-t0_99-p64', input='/disk/scratch_big/s1908368/data', log_interval=1000, lr=0.001, output='/disk/scratch_big/s1908368/output', patch_size=64, pretrain_encoder=False, seed=23, simclr_tau=0.99, train_proportion=0.98, use_byol=True)
29-01-2023 21:19:20 INFO File at /disk/scratch_big/s1908368/data/patch_train_dataset_64.pk: True
29-01-2023 21:19:20 INFO File at /disk/scratch_big/s1908368/data/patch_val_dataset_64.pk: True
29-01-2023 21:19:28 INFO Generated training dataset with 350062 samples.
29-01-2023 21:19:28 INFO Generated validation dataset with 7145 samples.
29-01-2023 21:19:28 INFO Using encoder resnet34 with pretrained weights = False
29-01-2023 21:19:29 INFO Using BYOL with tau = 0.99, with encoder layer index = -2
29-01-2023 21:19:29 INFO Using device: cuda
29-01-2023 21:19:32 INFO Starting Epoch: 1
29-01-2023 21:20:00 INFO Epoch 1: [12/10940] ---- BYOL Training Loss = 1.8780388832092285
29-01-2023 21:20:27 INFO Epoch 1: [23/10940] ---- BYOL Training Loss = 1.5896122455596924
29-01-2023 21:20:54 INFO Epoch 1: [34/10940] ---- BYOL Training Loss = 1.4806898832321167
29-01-2023 21:21:21 INFO Epoch 1: [45/10940] ---- BYOL Training Loss = 1.2331478595733643
29-01-2023 21:22:49 INFO Epoch 1: [45/10940] ---- BYOL Validation Loss = 1.3071057796478271
29-01-2023 21:23:17 INFO Epoch 1: [56/10940] ---- BYOL Training Loss = 1.0657894611358643
29-01-2023 21:23:44 INFO Epoch 1: [67/10940] ---- BYOL Training Loss = 0.9434151649475098
29-01-2023 21:24:11 INFO Epoch 1: [78/10940] ---- BYOL Training Loss = 0.8064258694648743
29-01-2023 21:24:39 INFO Epoch 1: [89/10940] ---- BYOL Training Loss = 0.7346828579902649
29-01-2023 21:26:07 INFO Epoch 1: [89/10940] ---- BYOL Validation Loss = 0.9651602506637573
29-01-2023 21:26:34 INFO Epoch 1: [100/10940] ---- BYOL Training Loss = 0.8078077435493469
29-01-2023 21:27:01 INFO Epoch 1: [111/10940] ---- BYOL Training Loss = 0.7075283527374268
29-01-2023 21:27:28 INFO Epoch 1: [122/10940] ---- BYOL Training Loss = 0.6725322008132935
29-01-2023 21:27:56 INFO Epoch 1: [133/10940] ---- BYOL Training Loss = 0.6992784738540649
29-01-2023 21:29:24 INFO Epoch 1: [133/10940] ---- BYOL Validation Loss = 1.0646474361419678
29-01-2023 21:29:52 INFO Epoch 1: [144/10940] ---- BYOL Training Loss = 0.626512348651886
29-01-2023 21:30:20 INFO Epoch 1: [155/10940] ---- BYOL Training Loss = 0.6123949289321899
29-01-2023 21:30:47 INFO Epoch 1: [166/10940] ---- BYOL Training Loss = 0.5546131730079651
29-01-2023 21:31:14 INFO Epoch 1: [177/10940] ---- BYOL Training Loss = 0.565934956073761
29-01-2023 21:32:42 INFO Epoch 1: [177/10940] ---- BYOL Validation Loss = 2.1932578086853027
29-01-2023 21:33:10 INFO Epoch 1: [188/10940] ---- BYOL Training Loss = 0.6488320827484131
29-01-2023 21:33:37 INFO Epoch 1: [199/10940] ---- BYOL Training Loss = 0.5376276969909668
29-01-2023 21:34:04 INFO Epoch 1: [210/10940] ---- BYOL Training Loss = 0.5136977434158325
29-01-2023 21:34:31 INFO Epoch 1: [221/10940] ---- BYOL Training Loss = 0.587242841720581
29-01-2023 21:36:00 INFO Epoch 1: [221/10940] ---- BYOL Validation Loss = 0.6025736927986145
29-01-2023 21:36:27 INFO Epoch 1: [232/10940] ---- BYOL Training Loss = 0.6649280786514282
29-01-2023 21:36:54 INFO Epoch 1: [243/10940] ---- BYOL Training Loss = 0.7129726409912109
29-01-2023 21:37:21 INFO Epoch 1: [254/10940] ---- BYOL Training Loss = 0.6649624109268188
29-01-2023 21:37:48 INFO Epoch 1: [265/10940] ---- BYOL Training Loss = 0.5159843564033508
29-01-2023 21:39:17 INFO Epoch 1: [265/10940] ---- BYOL Validation Loss = 0.5777631998062134
29-01-2023 21:39:44 INFO Epoch 1: [276/10940] ---- BYOL Training Loss = 0.47589173913002014
29-01-2023 21:40:12 INFO Epoch 1: [287/10940] ---- BYOL Training Loss = 0.5508494973182678
29-01-2023 21:40:39 INFO Epoch 1: [298/10940] ---- BYOL Training Loss = 0.4733388423919678
29-01-2023 21:41:06 INFO Epoch 1: [309/10940] ---- BYOL Training Loss = 0.4654757082462311
29-01-2023 21:42:34 INFO Epoch 1: [309/10940] ---- BYOL Validation Loss = 0.5428619384765625
29-01-2023 21:43:02 INFO Epoch 1: [320/10940] ---- BYOL Training Loss = 0.5187479853630066
29-01-2023 21:43:29 INFO Epoch 1: [331/10940] ---- BYOL Training Loss = 0.5207945108413696
29-01-2023 21:43:56 INFO Epoch 1: [342/10940] ---- BYOL Training Loss = 0.5549692511558533
29-01-2023 21:44:24 INFO Epoch 1: [353/10940] ---- BYOL Training Loss = 0.5821453928947449
29-01-2023 21:45:52 INFO Epoch 1: [353/10940] ---- BYOL Validation Loss = 0.5896204113960266
29-01-2023 21:46:19 INFO Epoch 1: [364/10940] ---- BYOL Training Loss = 0.5115866661071777
29-01-2023 21:46:46 INFO Epoch 1: [375/10940] ---- BYOL Training Loss = 0.45417332649230957
29-01-2023 21:47:14 INFO Epoch 1: [386/10940] ---- BYOL Training Loss = 0.5664684176445007
29-01-2023 21:47:41 INFO Epoch 1: [397/10940] ---- BYOL Training Loss = 0.5543514490127563
29-01-2023 21:49:09 INFO Epoch 1: [397/10940] ---- BYOL Validation Loss = 2.3728344440460205
29-01-2023 21:49:37 INFO Epoch 1: [408/10940] ---- BYOL Training Loss = 0.4768524169921875
29-01-2023 21:50:04 INFO Epoch 1: [419/10940] ---- BYOL Training Loss = 0.5150805711746216
29-01-2023 21:50:31 INFO Epoch 1: [430/10940] ---- BYOL Training Loss = 0.5617361664772034
29-01-2023 21:50:59 INFO Epoch 1: [441/10940] ---- BYOL Training Loss = 0.5136460065841675
29-01-2023 21:52:27 INFO Epoch 1: [441/10940] ---- BYOL Validation Loss = 1.5921329259872437
29-01-2023 21:52:54 INFO Epoch 1: [452/10940] ---- BYOL Training Loss = 0.5040600299835205
29-01-2023 21:53:22 INFO Epoch 1: [463/10940] ---- BYOL Training Loss = 0.4963580071926117
29-01-2023 21:53:49 INFO Epoch 1: [474/10940] ---- BYOL Training Loss = 0.5098737478256226
29-01-2023 21:54:16 INFO Epoch 1: [485/10940] ---- BYOL Training Loss = 0.5665655732154846
29-01-2023 21:55:45 INFO Epoch 1: [485/10940] ---- BYOL Validation Loss = 2.461350679397583
29-01-2023 21:56:12 INFO Epoch 1: [496/10940] ---- BYOL Training Loss = 0.4837079644203186
29-01-2023 21:56:39 INFO Epoch 1: [507/10940] ---- BYOL Training Loss = 0.532014012336731
29-01-2023 21:57:07 INFO Epoch 1: [518/10940] ---- BYOL Training Loss = 0.5495638847351074
29-01-2023 21:57:34 INFO Epoch 1: [529/10940] ---- BYOL Training Loss = 0.6439183950424194
29-01-2023 21:59:02 INFO Epoch 1: [529/10940] ---- BYOL Validation Loss = 0.7349650263786316
29-01-2023 21:59:30 INFO Epoch 1: [540/10940] ---- BYOL Training Loss = 0.5725506544113159
29-01-2023 21:59:57 INFO Epoch 1: [551/10940] ---- BYOL Training Loss = 0.4668644070625305
29-01-2023 22:00:24 INFO Epoch 1: [562/10940] ---- BYOL Training Loss = 0.4519681930541992
29-01-2023 22:00:52 INFO Epoch 1: [573/10940] ---- BYOL Training Loss = 0.5442811846733093
29-01-2023 22:02:20 INFO Epoch 1: [573/10940] ---- BYOL Validation Loss = 2.484584331512451
29-01-2023 22:02:47 INFO Epoch 1: [584/10940] ---- BYOL Training Loss = 0.5438963174819946
29-01-2023 22:03:15 INFO Epoch 1: [595/10940] ---- BYOL Training Loss = 0.5011107921600342
29-01-2023 22:03:42 INFO Epoch 1: [606/10940] ---- BYOL Training Loss = 0.5143052339553833
29-01-2023 22:04:09 INFO Epoch 1: [617/10940] ---- BYOL Training Loss = 0.5249481201171875
29-01-2023 22:05:37 INFO Epoch 1: [617/10940] ---- BYOL Validation Loss = 0.5147935748100281
29-01-2023 22:06:05 INFO Epoch 1: [628/10940] ---- BYOL Training Loss = 0.4896225333213806
29-01-2023 22:06:32 INFO Epoch 1: [639/10940] ---- BYOL Training Loss = 0.5071499943733215
29-01-2023 22:06:59 INFO Epoch 1: [650/10940] ---- BYOL Training Loss = 0.5066751837730408
29-01-2023 22:07:27 INFO Epoch 1: [661/10940] ---- BYOL Training Loss = 0.48745593428611755
29-01-2023 22:08:55 INFO Epoch 1: [661/10940] ---- BYOL Validation Loss = 2.6643784046173096
29-01-2023 22:09:22 INFO Epoch 1: [672/10940] ---- BYOL Training Loss = 0.46167534589767456
29-01-2023 22:09:50 INFO Epoch 1: [683/10940] ---- BYOL Training Loss = 0.46528783440589905
29-01-2023 22:10:17 INFO Epoch 1: [694/10940] ---- BYOL Training Loss = 0.45839935541152954
29-01-2023 22:10:44 INFO Epoch 1: [705/10940] ---- BYOL Training Loss = 0.4556017518043518
29-01-2023 22:12:12 INFO Epoch 1: [705/10940] ---- BYOL Validation Loss = 0.4716649055480957
29-01-2023 22:12:40 INFO Epoch 1: [716/10940] ---- BYOL Training Loss = 0.4594389498233795
29-01-2023 22:13:07 INFO Epoch 1: [727/10940] ---- BYOL Training Loss = 0.49932098388671875
29-01-2023 22:13:34 INFO Epoch 1: [738/10940] ---- BYOL Training Loss = 0.5315137505531311
29-01-2023 22:14:02 INFO Epoch 1: [749/10940] ---- BYOL Training Loss = 0.4443499445915222
29-01-2023 22:15:30 INFO Epoch 1: [749/10940] ---- BYOL Validation Loss = 0.47055456042289734
29-01-2023 22:15:58 INFO Epoch 1: [760/10940] ---- BYOL Training Loss = 0.5053146481513977
29-01-2023 22:16:25 INFO Epoch 1: [771/10940] ---- BYOL Training Loss = 0.4220053255558014
29-01-2023 22:16:52 INFO Epoch 1: [782/10940] ---- BYOL Training Loss = 0.44648227095603943
29-01-2023 22:17:19 INFO Epoch 1: [793/10940] ---- BYOL Training Loss = 0.4288822114467621
29-01-2023 22:18:48 INFO Epoch 1: [793/10940] ---- BYOL Validation Loss = 0.4553559124469757
29-01-2023 22:19:15 INFO Epoch 1: [804/10940] ---- BYOL Training Loss = 0.4283766746520996
29-01-2023 22:19:42 INFO Epoch 1: [815/10940] ---- BYOL Training Loss = 0.5190486311912537
29-01-2023 22:20:10 INFO Epoch 1: [826/10940] ---- BYOL Training Loss = 0.43115025758743286
29-01-2023 22:20:37 INFO Epoch 1: [837/10940] ---- BYOL Training Loss = 0.36425113677978516
29-01-2023 22:22:06 INFO Epoch 1: [837/10940] ---- BYOL Validation Loss = 0.45462509989738464
29-01-2023 22:22:33 INFO Epoch 1: [848/10940] ---- BYOL Training Loss = 0.4139229655265808
29-01-2023 22:23:01 INFO Epoch 1: [859/10940] ---- BYOL Training Loss = 0.4179824888706207
29-01-2023 22:23:28 INFO Epoch 1: [870/10940] ---- BYOL Training Loss = 0.4575190544128418
29-01-2023 22:23:55 INFO Epoch 1: [881/10940] ---- BYOL Training Loss = 0.4722460210323334
29-01-2023 22:25:23 INFO Epoch 1: [881/10940] ---- BYOL Validation Loss = 2.4540557861328125
29-01-2023 22:25:51 INFO Epoch 1: [892/10940] ---- BYOL Training Loss = 0.4586823582649231
29-01-2023 22:26:18 INFO Epoch 1: [903/10940] ---- BYOL Training Loss = 0.4477249085903168
29-01-2023 22:26:45 INFO Epoch 1: [914/10940] ---- BYOL Training Loss = 0.3640539050102234
29-01-2023 22:27:13 INFO Epoch 1: [925/10940] ---- BYOL Training Loss = 0.40136319398880005
29-01-2023 22:28:41 INFO Epoch 1: [925/10940] ---- BYOL Validation Loss = 0.5013567805290222
29-01-2023 22:29:09 INFO Epoch 1: [936/10940] ---- BYOL Training Loss = 0.4587048590183258
29-01-2023 22:29:36 INFO Epoch 1: [947/10940] ---- BYOL Training Loss = 0.4786205291748047
29-01-2023 22:30:03 INFO Epoch 1: [958/10940] ---- BYOL Training Loss = 0.4981296956539154
29-01-2023 22:30:31 INFO Epoch 1: [969/10940] ---- BYOL Training Loss = 0.4464680552482605
29-01-2023 22:31:59 INFO Epoch 1: [969/10940] ---- BYOL Validation Loss = 2.191507339477539
29-01-2023 22:32:26 INFO Epoch 1: [980/10940] ---- BYOL Training Loss = 0.3495315611362457
29-01-2023 22:32:54 INFO Epoch 1: [991/10940] ---- BYOL Training Loss = 0.4011046886444092
29-01-2023 22:33:21 INFO Epoch 1: [1002/10940] ---- BYOL Training Loss = 0.45451340079307556
29-01-2023 22:33:49 INFO Epoch 1: [1013/10940] ---- BYOL Training Loss = 0.40826573967933655
29-01-2023 22:35:17 INFO Epoch 1: [1013/10940] ---- BYOL Validation Loss = 2.249990224838257
29-01-2023 22:35:45 INFO Epoch 1: [1024/10940] ---- BYOL Training Loss = 0.4227254390716553
29-01-2023 22:36:12 INFO Epoch 1: [1035/10940] ---- BYOL Training Loss = 0.48462456464767456
29-01-2023 22:36:39 INFO Epoch 1: [1046/10940] ---- BYOL Training Loss = 0.5213941931724548
29-01-2023 22:37:07 INFO Epoch 1: [1057/10940] ---- BYOL Training Loss = 0.45874518156051636
29-01-2023 22:38:35 INFO Epoch 1: [1057/10940] ---- BYOL Validation Loss = 0.5622991919517517
29-01-2023 22:39:02 INFO Epoch 1: [1068/10940] ---- BYOL Training Loss = 0.4815356135368347
29-01-2023 22:39:30 INFO Epoch 1: [1079/10940] ---- BYOL Training Loss = 0.4578600525856018
29-01-2023 22:39:57 INFO Epoch 1: [1090/10940] ---- BYOL Training Loss = 0.39081066846847534
29-01-2023 22:40:25 INFO Epoch 1: [1101/10940] ---- BYOL Training Loss = 0.4493487477302551
29-01-2023 22:41:53 INFO Epoch 1: [1101/10940] ---- BYOL Validation Loss = 0.43740299344062805
29-01-2023 22:42:21 INFO Epoch 1: [1112/10940] ---- BYOL Training Loss = 0.515214204788208
29-01-2023 22:42:48 INFO Epoch 1: [1123/10940] ---- BYOL Training Loss = 0.4703826308250427
29-01-2023 22:43:15 INFO Epoch 1: [1134/10940] ---- BYOL Training Loss = 0.4333345293998718
29-01-2023 22:43:42 INFO Epoch 1: [1145/10940] ---- BYOL Training Loss = 0.4597012996673584
29-01-2023 22:45:11 INFO Epoch 1: [1145/10940] ---- BYOL Validation Loss = 0.606536865234375
29-01-2023 22:45:38 INFO Epoch 1: [1156/10940] ---- BYOL Training Loss = 0.47277170419692993
29-01-2023 22:46:06 INFO Epoch 1: [1167/10940] ---- BYOL Training Loss = 0.4560021460056305
29-01-2023 22:46:33 INFO Epoch 1: [1178/10940] ---- BYOL Training Loss = 0.45021432638168335
29-01-2023 22:47:00 INFO Epoch 1: [1189/10940] ---- BYOL Training Loss = 0.47314128279685974
29-01-2023 22:48:29 INFO Epoch 1: [1189/10940] ---- BYOL Validation Loss = 0.4571853280067444
29-01-2023 22:48:56 INFO Epoch 1: [1200/10940] ---- BYOL Training Loss = 0.4976978898048401
29-01-2023 22:49:23 INFO Epoch 1: [1211/10940] ---- BYOL Training Loss = 0.4589499831199646
29-01-2023 22:49:51 INFO Epoch 1: [1222/10940] ---- BYOL Training Loss = 0.42899641394615173
29-01-2023 22:50:18 INFO Epoch 1: [1233/10940] ---- BYOL Training Loss = 0.4993111491203308
29-01-2023 22:51:46 INFO Epoch 1: [1233/10940] ---- BYOL Validation Loss = 0.5351664423942566
29-01-2023 22:52:14 INFO Epoch 1: [1244/10940] ---- BYOL Training Loss = 0.5573705434799194
29-01-2023 22:52:41 INFO Epoch 1: [1255/10940] ---- BYOL Training Loss = 0.5031782388687134
29-01-2023 22:53:09 INFO Epoch 1: [1266/10940] ---- BYOL Training Loss = 0.5095726251602173
29-01-2023 22:53:36 INFO Epoch 1: [1277/10940] ---- BYOL Training Loss = 0.4994955062866211
29-01-2023 22:55:05 INFO Epoch 1: [1277/10940] ---- BYOL Validation Loss = 0.6099316477775574
29-01-2023 22:55:32 INFO Epoch 1: [1288/10940] ---- BYOL Training Loss = 0.4589550495147705
29-01-2023 22:56:00 INFO Epoch 1: [1299/10940] ---- BYOL Training Loss = 0.37944191694259644
29-01-2023 22:56:27 INFO Epoch 1: [1310/10940] ---- BYOL Training Loss = 0.4021492898464203
29-01-2023 22:56:54 INFO Epoch 1: [1321/10940] ---- BYOL Training Loss = 0.4268585741519928
29-01-2023 22:58:23 INFO Epoch 1: [1321/10940] ---- BYOL Validation Loss = 0.43371984362602234
29-01-2023 22:58:50 INFO Epoch 1: [1332/10940] ---- BYOL Training Loss = 0.43282970786094666
29-01-2023 22:59:17 INFO Epoch 1: [1343/10940] ---- BYOL Training Loss = 0.43015503883361816
29-01-2023 22:59:45 INFO Epoch 1: [1354/10940] ---- BYOL Training Loss = 0.4359118342399597
29-01-2023 23:00:12 INFO Epoch 1: [1365/10940] ---- BYOL Training Loss = 0.4950389862060547
29-01-2023 23:01:41 INFO Epoch 1: [1365/10940] ---- BYOL Validation Loss = 0.4271261990070343
29-01-2023 23:02:08 INFO Epoch 1: [1376/10940] ---- BYOL Training Loss = 0.41675853729248047
29-01-2023 23:02:35 INFO Epoch 1: [1387/10940] ---- BYOL Training Loss = 0.3802916407585144
29-01-2023 23:03:03 INFO Epoch 1: [1398/10940] ---- BYOL Training Loss = 0.43748611211776733
29-01-2023 23:03:31 INFO Epoch 1: [1409/10940] ---- BYOL Training Loss = 0.4424515664577484
29-01-2023 23:04:59 INFO Epoch 1: [1409/10940] ---- BYOL Validation Loss = 0.5095075964927673
29-01-2023 23:05:27 INFO Epoch 1: [1420/10940] ---- BYOL Training Loss = 0.44548875093460083
29-01-2023 23:05:54 INFO Epoch 1: [1431/10940] ---- BYOL Training Loss = 0.46049991250038147
29-01-2023 23:06:21 INFO Epoch 1: [1442/10940] ---- BYOL Training Loss = 0.44729694724082947
29-01-2023 23:06:49 INFO Epoch 1: [1453/10940] ---- BYOL Training Loss = 0.4330473840236664
29-01-2023 23:08:18 INFO Epoch 1: [1453/10940] ---- BYOL Validation Loss = 1.8054701089859009
29-01-2023 23:08:45 INFO Epoch 1: [1464/10940] ---- BYOL Training Loss = 0.37267425656318665
29-01-2023 23:09:12 INFO Epoch 1: [1475/10940] ---- BYOL Training Loss = 0.4091493487358093
29-01-2023 23:09:40 INFO Epoch 1: [1486/10940] ---- BYOL Training Loss = 0.4085935652256012
29-01-2023 23:10:08 INFO Epoch 1: [1497/10940] ---- BYOL Training Loss = 0.39897042512893677
29-01-2023 23:11:36 INFO Epoch 1: [1497/10940] ---- BYOL Validation Loss = 0.49204471707344055
29-01-2023 23:12:04 INFO Epoch 1: [1508/10940] ---- BYOL Training Loss = 0.39986202120780945
29-01-2023 23:12:31 INFO Epoch 1: [1519/10940] ---- BYOL Training Loss = 0.3732992112636566
29-01-2023 23:12:59 INFO Epoch 1: [1530/10940] ---- BYOL Training Loss = 0.391242653131485
29-01-2023 23:13:26 INFO Epoch 1: [1541/10940] ---- BYOL Training Loss = 0.4380403161048889
29-01-2023 23:14:55 INFO Epoch 1: [1541/10940] ---- BYOL Validation Loss = 1.6939642429351807
29-01-2023 23:15:22 INFO Epoch 1: [1552/10940] ---- BYOL Training Loss = 0.4822019636631012
29-01-2023 23:15:50 INFO Epoch 1: [1563/10940] ---- BYOL Training Loss = 0.5446291565895081
29-01-2023 23:16:17 INFO Epoch 1: [1574/10940] ---- BYOL Training Loss = 0.49579477310180664
29-01-2023 23:16:45 INFO Epoch 1: [1585/10940] ---- BYOL Training Loss = 0.4714224934577942
29-01-2023 23:18:13 INFO Epoch 1: [1585/10940] ---- BYOL Validation Loss = 0.45538440346717834
29-01-2023 23:18:40 INFO Epoch 1: [1596/10940] ---- BYOL Training Loss = 0.4388093054294586
29-01-2023 23:19:08 INFO Epoch 1: [1607/10940] ---- BYOL Training Loss = 0.39857855439186096
29-01-2023 23:19:36 INFO Epoch 1: [1618/10940] ---- BYOL Training Loss = 0.42942309379577637
29-01-2023 23:20:03 INFO Epoch 1: [1629/10940] ---- BYOL Training Loss = 0.49845370650291443
29-01-2023 23:21:31 INFO Epoch 1: [1629/10940] ---- BYOL Validation Loss = 0.4611452519893646
29-01-2023 23:21:59 INFO Epoch 1: [1640/10940] ---- BYOL Training Loss = 0.5040135383605957
29-01-2023 23:22:26 INFO Epoch 1: [1651/10940] ---- BYOL Training Loss = 0.4379066824913025
29-01-2023 23:22:54 INFO Epoch 1: [1662/10940] ---- BYOL Training Loss = 0.41514554619789124
29-01-2023 23:23:21 INFO Epoch 1: [1673/10940] ---- BYOL Training Loss = 0.42141833901405334
29-01-2023 23:24:49 INFO Epoch 1: [1673/10940] ---- BYOL Validation Loss = 0.5407214760780334
29-01-2023 23:25:17 INFO Epoch 1: [1684/10940] ---- BYOL Training Loss = 0.4455502927303314
29-01-2023 23:25:44 INFO Epoch 1: [1695/10940] ---- BYOL Training Loss = 0.43633681535720825
29-01-2023 23:26:12 INFO Epoch 1: [1706/10940] ---- BYOL Training Loss = 0.4465467035770416
29-01-2023 23:26:39 INFO Epoch 1: [1717/10940] ---- BYOL Training Loss = 0.4582887589931488
29-01-2023 23:28:08 INFO Epoch 1: [1717/10940] ---- BYOL Validation Loss = 0.48507991433143616
29-01-2023 23:28:35 INFO Epoch 1: [1728/10940] ---- BYOL Training Loss = 0.48422956466674805
29-01-2023 23:29:02 INFO Epoch 1: [1739/10940] ---- BYOL Training Loss = 0.49077552556991577
29-01-2023 23:29:30 INFO Epoch 1: [1750/10940] ---- BYOL Training Loss = 0.5137282013893127
29-01-2023 23:29:57 INFO Epoch 1: [1761/10940] ---- BYOL Training Loss = 0.5289159417152405
29-01-2023 23:31:25 INFO Epoch 1: [1761/10940] ---- BYOL Validation Loss = 0.4594406485557556
29-01-2023 23:31:53 INFO Epoch 1: [1772/10940] ---- BYOL Training Loss = 0.48457327485084534
29-01-2023 23:32:21 INFO Epoch 1: [1783/10940] ---- BYOL Training Loss = 0.415432870388031
29-01-2023 23:32:48 INFO Epoch 1: [1794/10940] ---- BYOL Training Loss = 0.4710744321346283
29-01-2023 23:33:15 INFO Epoch 1: [1805/10940] ---- BYOL Training Loss = 0.39440205693244934
29-01-2023 23:34:44 INFO Epoch 1: [1805/10940] ---- BYOL Validation Loss = 0.4312320649623871
29-01-2023 23:35:11 INFO Epoch 1: [1816/10940] ---- BYOL Training Loss = 0.3519132137298584
29-01-2023 23:35:39 INFO Epoch 1: [1827/10940] ---- BYOL Training Loss = 0.44177111983299255
29-01-2023 23:36:06 INFO Epoch 1: [1838/10940] ---- BYOL Training Loss = 0.5099753737449646
29-01-2023 23:36:34 INFO Epoch 1: [1849/10940] ---- BYOL Training Loss = 0.4235294759273529
29-01-2023 23:38:02 INFO Epoch 1: [1849/10940] ---- BYOL Validation Loss = 0.4756498336791992
29-01-2023 23:38:30 INFO Epoch 1: [1860/10940] ---- BYOL Training Loss = 0.43957939743995667
29-01-2023 23:38:57 INFO Epoch 1: [1871/10940] ---- BYOL Training Loss = 0.4898558259010315
29-01-2023 23:39:24 INFO Epoch 1: [1882/10940] ---- BYOL Training Loss = 0.4429108202457428
29-01-2023 23:39:52 INFO Epoch 1: [1893/10940] ---- BYOL Training Loss = 0.4101688265800476
29-01-2023 23:41:20 INFO Epoch 1: [1893/10940] ---- BYOL Validation Loss = 0.579839289188385
29-01-2023 23:41:48 INFO Epoch 1: [1904/10940] ---- BYOL Training Loss = 0.36589914560317993
29-01-2023 23:42:15 INFO Epoch 1: [1915/10940] ---- BYOL Training Loss = 0.3545798361301422
29-01-2023 23:42:43 INFO Epoch 1: [1926/10940] ---- BYOL Training Loss = 0.41192859411239624
29-01-2023 23:43:11 INFO Epoch 1: [1937/10940] ---- BYOL Training Loss = 0.418320894241333
29-01-2023 23:44:39 INFO Epoch 1: [1937/10940] ---- BYOL Validation Loss = 0.4900238513946533
29-01-2023 23:45:06 INFO Epoch 1: [1948/10940] ---- BYOL Training Loss = 0.3777921199798584
29-01-2023 23:45:34 INFO Epoch 1: [1959/10940] ---- BYOL Training Loss = 0.432370126247406
29-01-2023 23:46:01 INFO Epoch 1: [1970/10940] ---- BYOL Training Loss = 0.43288499116897583
29-01-2023 23:46:28 INFO Epoch 1: [1981/10940] ---- BYOL Training Loss = 0.4226352274417877
29-01-2023 23:47:57 INFO Epoch 1: [1981/10940] ---- BYOL Validation Loss = 0.45432084798812866
29-01-2023 23:48:24 INFO Epoch 1: [1992/10940] ---- BYOL Training Loss = 0.40213704109191895
29-01-2023 23:48:51 INFO Epoch 1: [2003/10940] ---- BYOL Training Loss = 0.5428453683853149
29-01-2023 23:49:19 INFO Epoch 1: [2014/10940] ---- BYOL Training Loss = 0.5118529200553894
29-01-2023 23:49:46 INFO Epoch 1: [2025/10940] ---- BYOL Training Loss = 0.4602600932121277
29-01-2023 23:51:15 INFO Epoch 1: [2025/10940] ---- BYOL Validation Loss = 0.45729854702949524
29-01-2023 23:51:42 INFO Epoch 1: [2036/10940] ---- BYOL Training Loss = 0.4368162751197815
29-01-2023 23:52:10 INFO Epoch 1: [2047/10940] ---- BYOL Training Loss = 0.408660352230072
29-01-2023 23:52:37 INFO Epoch 1: [2058/10940] ---- BYOL Training Loss = 0.4718472957611084
29-01-2023 23:53:05 INFO Epoch 1: [2069/10940] ---- BYOL Training Loss = 0.4211193919181824
29-01-2023 23:54:33 INFO Epoch 1: [2069/10940] ---- BYOL Validation Loss = 0.4909818470478058
29-01-2023 23:55:00 INFO Epoch 1: [2080/10940] ---- BYOL Training Loss = 0.40164685249328613
29-01-2023 23:55:28 INFO Epoch 1: [2091/10940] ---- BYOL Training Loss = 0.419058620929718
29-01-2023 23:55:56 INFO Epoch 1: [2102/10940] ---- BYOL Training Loss = 0.41756439208984375
29-01-2023 23:56:23 INFO Epoch 1: [2113/10940] ---- BYOL Training Loss = 0.45264777541160583
29-01-2023 23:57:51 INFO Epoch 1: [2113/10940] ---- BYOL Validation Loss = 0.5220790505409241
29-01-2023 23:58:19 INFO Epoch 1: [2124/10940] ---- BYOL Training Loss = 0.44712209701538086
29-01-2023 23:58:46 INFO Epoch 1: [2135/10940] ---- BYOL Training Loss = 0.4809628427028656
29-01-2023 23:59:13 INFO Epoch 1: [2146/10940] ---- BYOL Training Loss = 0.48272624611854553
29-01-2023 23:59:41 INFO Epoch 1: [2157/10940] ---- BYOL Training Loss = 0.448123037815094
30-01-2023 00:01:09 INFO Epoch 1: [2157/10940] ---- BYOL Validation Loss = 0.498978853225708
30-01-2023 00:01:37 INFO Epoch 1: [2168/10940] ---- BYOL Training Loss = 0.4591345191001892
30-01-2023 00:02:04 INFO Epoch 1: [2179/10940] ---- BYOL Training Loss = 0.38502734899520874
30-01-2023 00:02:32 INFO Epoch 1: [2190/10940] ---- BYOL Training Loss = 0.4431590437889099
30-01-2023 00:02:59 INFO Epoch 1: [2201/10940] ---- BYOL Training Loss = 0.4710496962070465
30-01-2023 00:04:28 INFO Epoch 1: [2201/10940] ---- BYOL Validation Loss = 0.5428317785263062
30-01-2023 00:04:55 INFO Epoch 1: [2212/10940] ---- BYOL Training Loss = 0.48627132177352905
30-01-2023 00:05:23 INFO Epoch 1: [2223/10940] ---- BYOL Training Loss = 0.46667957305908203
30-01-2023 00:05:50 INFO Epoch 1: [2234/10940] ---- BYOL Training Loss = 0.41060319542884827
30-01-2023 00:06:18 INFO Epoch 1: [2245/10940] ---- BYOL Training Loss = 0.3924882411956787
30-01-2023 00:07:46 INFO Epoch 1: [2245/10940] ---- BYOL Validation Loss = 0.5409746766090393
30-01-2023 00:08:13 INFO Epoch 1: [2256/10940] ---- BYOL Training Loss = 0.422206312417984
30-01-2023 00:08:41 INFO Epoch 1: [2267/10940] ---- BYOL Training Loss = 0.4979557991027832
30-01-2023 00:09:09 INFO Epoch 1: [2278/10940] ---- BYOL Training Loss = 0.47854939103126526
30-01-2023 00:09:36 INFO Epoch 1: [2289/10940] ---- BYOL Training Loss = 0.46595197916030884
30-01-2023 00:11:04 INFO Epoch 1: [2289/10940] ---- BYOL Validation Loss = 0.47577863931655884
30-01-2023 00:11:32 INFO Epoch 1: [2300/10940] ---- BYOL Training Loss = 0.428875595331192
30-01-2023 00:12:00 INFO Epoch 1: [2311/10940] ---- BYOL Training Loss = 0.38529929518699646
30-01-2023 00:12:27 INFO Epoch 1: [2322/10940] ---- BYOL Training Loss = 0.3954787850379944
30-01-2023 00:12:55 INFO Epoch 1: [2333/10940] ---- BYOL Training Loss = 0.4665355682373047
30-01-2023 00:14:23 INFO Epoch 1: [2333/10940] ---- BYOL Validation Loss = 3.273500680923462
30-01-2023 00:14:50 INFO Epoch 1: [2344/10940] ---- BYOL Training Loss = 0.4178938865661621
30-01-2023 00:15:18 INFO Epoch 1: [2355/10940] ---- BYOL Training Loss = 0.41560307145118713
30-01-2023 00:15:46 INFO Epoch 1: [2366/10940] ---- BYOL Training Loss = 0.46296849846839905
30-01-2023 00:16:13 INFO Epoch 1: [2377/10940] ---- BYOL Training Loss = 0.44399604201316833
30-01-2023 00:17:41 INFO Epoch 1: [2377/10940] ---- BYOL Validation Loss = 0.47736573219299316
30-01-2023 00:18:08 INFO Epoch 1: [2388/10940] ---- BYOL Training Loss = 0.38789600133895874
30-01-2023 00:18:36 INFO Epoch 1: [2399/10940] ---- BYOL Training Loss = 0.38640889525413513
30-01-2023 00:19:04 INFO Epoch 1: [2410/10940] ---- BYOL Training Loss = 0.40833187103271484
30-01-2023 00:19:31 INFO Epoch 1: [2421/10940] ---- BYOL Training Loss = 0.3581095337867737
30-01-2023 00:21:00 INFO Epoch 1: [2421/10940] ---- BYOL Validation Loss = 0.4385075867176056
30-01-2023 00:21:27 INFO Epoch 1: [2432/10940] ---- BYOL Training Loss = 0.5058385133743286
30-01-2023 00:21:55 INFO Epoch 1: [2443/10940] ---- BYOL Training Loss = 0.49644795060157776
30-01-2023 00:22:22 INFO Epoch 1: [2454/10940] ---- BYOL Training Loss = 0.42797762155532837
30-01-2023 00:22:50 INFO Epoch 1: [2465/10940] ---- BYOL Training Loss = 0.47590702772140503
30-01-2023 00:24:18 INFO Epoch 1: [2465/10940] ---- BYOL Validation Loss = 0.4513991177082062
30-01-2023 00:24:45 INFO Epoch 1: [2476/10940] ---- BYOL Training Loss = 0.5347687005996704
30-01-2023 00:25:13 INFO Epoch 1: [2487/10940] ---- BYOL Training Loss = 0.5495868921279907
30-01-2023 00:25:40 INFO Epoch 1: [2498/10940] ---- BYOL Training Loss = 0.40145760774612427
30-01-2023 00:26:08 INFO Epoch 1: [2509/10940] ---- BYOL Training Loss = 0.3988664448261261
30-01-2023 00:27:36 INFO Epoch 1: [2509/10940] ---- BYOL Validation Loss = 0.4510672688484192
30-01-2023 00:28:04 INFO Epoch 1: [2520/10940] ---- BYOL Training Loss = 0.4347938895225525
30-01-2023 00:28:31 INFO Epoch 1: [2531/10940] ---- BYOL Training Loss = 0.40815144777297974
30-01-2023 00:28:59 INFO Epoch 1: [2542/10940] ---- BYOL Training Loss = 0.46757403016090393
30-01-2023 00:29:26 INFO Epoch 1: [2553/10940] ---- BYOL Training Loss = 0.47303056716918945
30-01-2023 00:30:54 INFO Epoch 1: [2553/10940] ---- BYOL Validation Loss = 0.44445544481277466
30-01-2023 00:31:22 INFO Epoch 1: [2564/10940] ---- BYOL Training Loss = 0.38391804695129395
30-01-2023 00:31:49 INFO Epoch 1: [2575/10940] ---- BYOL Training Loss = 0.3646935224533081
30-01-2023 00:32:17 INFO Epoch 1: [2586/10940] ---- BYOL Training Loss = 0.4612123370170593
30-01-2023 00:32:44 INFO Epoch 1: [2597/10940] ---- BYOL Training Loss = 0.4912247061729431
30-01-2023 00:34:12 INFO Epoch 1: [2597/10940] ---- BYOL Validation Loss = 0.461103618144989
30-01-2023 00:34:40 INFO Epoch 1: [2608/10940] ---- BYOL Training Loss = 0.4489150643348694
30-01-2023 00:35:08 INFO Epoch 1: [2619/10940] ---- BYOL Training Loss = 0.42712873220443726
30-01-2023 00:35:36 INFO Epoch 1: [2630/10940] ---- BYOL Training Loss = 0.4289155602455139
30-01-2023 00:36:03 INFO Epoch 1: [2641/10940] ---- BYOL Training Loss = 0.42325764894485474
30-01-2023 00:37:31 INFO Epoch 1: [2641/10940] ---- BYOL Validation Loss = 0.43604153394699097
30-01-2023 00:37:59 INFO Epoch 1: [2652/10940] ---- BYOL Training Loss = 0.4240444302558899
30-01-2023 00:38:27 INFO Epoch 1: [2663/10940] ---- BYOL Training Loss = 0.406374990940094
30-01-2023 00:38:54 INFO Epoch 1: [2674/10940] ---- BYOL Training Loss = 0.4208442270755768
30-01-2023 00:39:22 INFO Epoch 1: [2685/10940] ---- BYOL Training Loss = 0.4556160867214203
30-01-2023 00:40:50 INFO Epoch 1: [2685/10940] ---- BYOL Validation Loss = 0.4915294051170349
30-01-2023 00:41:18 INFO Epoch 1: [2696/10940] ---- BYOL Training Loss = 0.41368746757507324
30-01-2023 00:41:45 INFO Epoch 1: [2707/10940] ---- BYOL Training Loss = 0.43625736236572266
30-01-2023 00:42:13 INFO Epoch 1: [2718/10940] ---- BYOL Training Loss = 0.47011882066726685
30-01-2023 00:42:41 INFO Epoch 1: [2729/10940] ---- BYOL Training Loss = 0.40724629163742065
30-01-2023 00:44:09 INFO Epoch 1: [2729/10940] ---- BYOL Validation Loss = 0.4673536717891693
30-01-2023 00:44:36 INFO Epoch 1: [2740/10940] ---- BYOL Training Loss = 0.4618649482727051
30-01-2023 00:45:04 INFO Epoch 1: [2751/10940] ---- BYOL Training Loss = 0.4602274000644684
30-01-2023 00:45:32 INFO Epoch 1: [2762/10940] ---- BYOL Training Loss = 0.3915089964866638
30-01-2023 00:46:00 INFO Epoch 1: [2773/10940] ---- BYOL Training Loss = 0.443398654460907
30-01-2023 00:47:28 INFO Epoch 1: [2773/10940] ---- BYOL Validation Loss = 0.4848613142967224
30-01-2023 00:47:56 INFO Epoch 1: [2784/10940] ---- BYOL Training Loss = 0.45468711853027344
30-01-2023 00:48:23 INFO Epoch 1: [2795/10940] ---- BYOL Training Loss = 0.40043678879737854
30-01-2023 00:48:51 INFO Epoch 1: [2806/10940] ---- BYOL Training Loss = 0.43542370200157166
30-01-2023 00:49:18 INFO Epoch 1: [2817/10940] ---- BYOL Training Loss = 0.5426333546638489
30-01-2023 00:50:47 INFO Epoch 1: [2817/10940] ---- BYOL Validation Loss = 0.578734278678894
30-01-2023 00:51:14 INFO Epoch 1: [2828/10940] ---- BYOL Training Loss = 0.5066585540771484
30-01-2023 00:51:42 INFO Epoch 1: [2839/10940] ---- BYOL Training Loss = 0.466421902179718
30-01-2023 00:52:09 INFO Epoch 1: [2850/10940] ---- BYOL Training Loss = 0.48565468192100525
30-01-2023 00:52:37 INFO Epoch 1: [2861/10940] ---- BYOL Training Loss = 0.41651973128318787
30-01-2023 00:54:06 INFO Epoch 1: [2861/10940] ---- BYOL Validation Loss = 0.5181851387023926
30-01-2023 00:54:33 INFO Epoch 1: [2872/10940] ---- BYOL Training Loss = 0.43599408864974976
30-01-2023 00:55:01 INFO Epoch 1: [2883/10940] ---- BYOL Training Loss = 0.4762152135372162
30-01-2023 00:55:29 INFO Epoch 1: [2894/10940] ---- BYOL Training Loss = 0.5283240675926208
30-01-2023 00:55:56 INFO Epoch 1: [2905/10940] ---- BYOL Training Loss = 0.574131190776825
30-01-2023 00:57:24 INFO Epoch 1: [2905/10940] ---- BYOL Validation Loss = 0.451278954744339
30-01-2023 00:57:52 INFO Epoch 1: [2916/10940] ---- BYOL Training Loss = 0.44136372208595276
30-01-2023 00:58:20 INFO Epoch 1: [2927/10940] ---- BYOL Training Loss = 0.3208061456680298
30-01-2023 00:58:48 INFO Epoch 1: [2938/10940] ---- BYOL Training Loss = 0.35749202966690063
30-01-2023 00:59:15 INFO Epoch 1: [2949/10940] ---- BYOL Training Loss = 0.3510879874229431
30-01-2023 01:00:43 INFO Epoch 1: [2949/10940] ---- BYOL Validation Loss = 3.3799147605895996
30-01-2023 01:01:11 INFO Epoch 1: [2960/10940] ---- BYOL Training Loss = 0.3510703444480896
30-01-2023 01:01:39 INFO Epoch 1: [2971/10940] ---- BYOL Training Loss = 0.4290854334831238
30-01-2023 01:02:06 INFO Epoch 1: [2982/10940] ---- BYOL Training Loss = 0.44046634435653687
30-01-2023 01:02:34 INFO Epoch 1: [2993/10940] ---- BYOL Training Loss = 0.45685333013534546
30-01-2023 01:04:02 INFO Epoch 1: [2993/10940] ---- BYOL Validation Loss = 0.41861680150032043
30-01-2023 01:04:30 INFO Epoch 1: [3004/10940] ---- BYOL Training Loss = 0.47602492570877075
30-01-2023 01:04:58 INFO Epoch 1: [3015/10940] ---- BYOL Training Loss = 0.4079124331474304
30-01-2023 01:05:25 INFO Epoch 1: [3026/10940] ---- BYOL Training Loss = 0.47098690271377563
30-01-2023 01:05:53 INFO Epoch 1: [3037/10940] ---- BYOL Training Loss = 0.47176775336265564
30-01-2023 01:07:21 INFO Epoch 1: [3037/10940] ---- BYOL Validation Loss = 0.4248383939266205
30-01-2023 01:07:49 INFO Epoch 1: [3048/10940] ---- BYOL Training Loss = 0.42892616987228394
30-01-2023 01:08:16 INFO Epoch 1: [3059/10940] ---- BYOL Training Loss = 0.42349773645401
30-01-2023 01:08:44 INFO Epoch 1: [3070/10940] ---- BYOL Training Loss = 0.4361910820007324
30-01-2023 01:09:12 INFO Epoch 1: [3081/10940] ---- BYOL Training Loss = 0.3985651135444641
30-01-2023 01:10:40 INFO Epoch 1: [3081/10940] ---- BYOL Validation Loss = 0.43224361538887024
30-01-2023 01:11:08 INFO Epoch 1: [3092/10940] ---- BYOL Training Loss = 0.4056658148765564
30-01-2023 01:11:35 INFO Epoch 1: [3103/10940] ---- BYOL Training Loss = 0.4418583810329437
30-01-2023 01:12:03 INFO Epoch 1: [3114/10940] ---- BYOL Training Loss = 0.42811399698257446
30-01-2023 01:12:31 INFO Epoch 1: [3125/10940] ---- BYOL Training Loss = 0.47036275267601013
30-01-2023 01:13:59 INFO Epoch 1: [3125/10940] ---- BYOL Validation Loss = 0.46401476860046387
30-01-2023 01:14:27 INFO Epoch 1: [3136/10940] ---- BYOL Training Loss = 0.4782436490058899
30-01-2023 01:14:54 INFO Epoch 1: [3147/10940] ---- BYOL Training Loss = 0.42522183060646057
30-01-2023 01:15:22 INFO Epoch 1: [3158/10940] ---- BYOL Training Loss = 0.3558383584022522
30-01-2023 01:15:50 INFO Epoch 1: [3169/10940] ---- BYOL Training Loss = 0.3780483603477478
30-01-2023 01:17:18 INFO Epoch 1: [3169/10940] ---- BYOL Validation Loss = 0.43291231989860535
30-01-2023 01:17:46 INFO Epoch 1: [3180/10940] ---- BYOL Training Loss = 0.4048650860786438
30-01-2023 01:18:13 INFO Epoch 1: [3191/10940] ---- BYOL Training Loss = 0.47230809926986694
30-01-2023 01:18:41 INFO Epoch 1: [3202/10940] ---- BYOL Training Loss = 0.48481908440589905
30-01-2023 01:19:09 INFO Epoch 1: [3213/10940] ---- BYOL Training Loss = 0.42436084151268005
30-01-2023 01:20:37 INFO Epoch 1: [3213/10940] ---- BYOL Validation Loss = 0.4537825882434845
30-01-2023 01:21:05 INFO Epoch 1: [3224/10940] ---- BYOL Training Loss = 0.4777259826660156
30-01-2023 01:21:32 INFO Epoch 1: [3235/10940] ---- BYOL Training Loss = 0.47653645277023315
30-01-2023 01:22:00 INFO Epoch 1: [3246/10940] ---- BYOL Training Loss = 0.4429871141910553
30-01-2023 01:22:28 INFO Epoch 1: [3257/10940] ---- BYOL Training Loss = 0.4529213309288025
30-01-2023 01:23:56 INFO Epoch 1: [3257/10940] ---- BYOL Validation Loss = 0.4675077795982361
30-01-2023 01:24:24 INFO Epoch 1: [3268/10940] ---- BYOL Training Loss = 0.4384540915489197
30-01-2023 01:24:51 INFO Epoch 1: [3279/10940] ---- BYOL Training Loss = 0.42921513319015503
30-01-2023 01:25:19 INFO Epoch 1: [3290/10940] ---- BYOL Training Loss = 0.4291917383670807
30-01-2023 01:25:47 INFO Epoch 1: [3301/10940] ---- BYOL Training Loss = 0.41774359345436096
30-01-2023 01:27:15 INFO Epoch 1: [3301/10940] ---- BYOL Validation Loss = 0.4284012019634247
30-01-2023 01:27:43 INFO Epoch 1: [3312/10940] ---- BYOL Training Loss = 0.4639226496219635
30-01-2023 01:28:11 INFO Epoch 1: [3323/10940] ---- BYOL Training Loss = 0.47182410955429077
30-01-2023 01:28:39 INFO Epoch 1: [3334/10940] ---- BYOL Training Loss = 0.4640577733516693
30-01-2023 01:29:06 INFO Epoch 1: [3345/10940] ---- BYOL Training Loss = 0.4606189727783203
30-01-2023 01:30:34 INFO Epoch 1: [3345/10940] ---- BYOL Validation Loss = 0.48785051703453064
30-01-2023 01:31:02 INFO Epoch 1: [3356/10940] ---- BYOL Training Loss = 0.43348726630210876
30-01-2023 01:31:30 INFO Epoch 1: [3367/10940] ---- BYOL Training Loss = 0.38397854566574097
30-01-2023 01:31:57 INFO Epoch 1: [3378/10940] ---- BYOL Training Loss = 0.43896132707595825
30-01-2023 01:32:25 INFO Epoch 1: [3389/10940] ---- BYOL Training Loss = 0.4158012270927429
30-01-2023 01:33:53 INFO Epoch 1: [3389/10940] ---- BYOL Validation Loss = 0.45506635308265686
30-01-2023 01:34:21 INFO Epoch 1: [3400/10940] ---- BYOL Training Loss = 0.4672713875770569
30-01-2023 01:34:48 INFO Epoch 1: [3411/10940] ---- BYOL Training Loss = 0.5021302103996277
30-01-2023 01:35:16 INFO Epoch 1: [3422/10940] ---- BYOL Training Loss = 0.516804575920105
30-01-2023 01:35:44 INFO Epoch 1: [3433/10940] ---- BYOL Training Loss = 0.4108796715736389
30-01-2023 01:37:12 INFO Epoch 1: [3433/10940] ---- BYOL Validation Loss = 0.4373629689216614
30-01-2023 01:37:39 INFO Epoch 1: [3444/10940] ---- BYOL Training Loss = 0.38877588510513306
30-01-2023 01:38:07 INFO Epoch 1: [3455/10940] ---- BYOL Training Loss = 0.43758997321128845
30-01-2023 01:38:35 INFO Epoch 1: [3466/10940] ---- BYOL Training Loss = 0.41867655515670776
30-01-2023 01:39:03 INFO Epoch 1: [3477/10940] ---- BYOL Training Loss = 0.390020489692688
30-01-2023 01:40:31 INFO Epoch 1: [3477/10940] ---- BYOL Validation Loss = 0.4605860710144043
30-01-2023 01:40:59 INFO Epoch 1: [3488/10940] ---- BYOL Training Loss = 0.4697336256504059
30-01-2023 01:41:26 INFO Epoch 1: [3499/10940] ---- BYOL Training Loss = 0.47738370299339294
30-01-2023 01:41:54 INFO Epoch 1: [3510/10940] ---- BYOL Training Loss = 0.3646372854709625
30-01-2023 01:42:22 INFO Epoch 1: [3521/10940] ---- BYOL Training Loss = 0.3787459433078766
30-01-2023 01:43:50 INFO Epoch 1: [3521/10940] ---- BYOL Validation Loss = 0.433148056268692
30-01-2023 01:44:18 INFO Epoch 1: [3532/10940] ---- BYOL Training Loss = 0.37503862380981445
30-01-2023 01:44:46 INFO Epoch 1: [3543/10940] ---- BYOL Training Loss = 0.45890212059020996
30-01-2023 01:45:13 INFO Epoch 1: [3554/10940] ---- BYOL Training Loss = 0.5164257287979126
30-01-2023 01:45:41 INFO Epoch 1: [3565/10940] ---- BYOL Training Loss = 0.48508256673812866
30-01-2023 01:47:09 INFO Epoch 1: [3565/10940] ---- BYOL Validation Loss = 0.5352262854576111
30-01-2023 01:47:37 INFO Epoch 1: [3576/10940] ---- BYOL Training Loss = 0.45132455229759216
30-01-2023 01:48:04 INFO Epoch 1: [3587/10940] ---- BYOL Training Loss = 0.4494062066078186
30-01-2023 01:48:32 INFO Epoch 1: [3598/10940] ---- BYOL Training Loss = 0.4497414529323578
30-01-2023 01:49:00 INFO Epoch 1: [3609/10940] ---- BYOL Training Loss = 0.4379867911338806
30-01-2023 01:50:28 INFO Epoch 1: [3609/10940] ---- BYOL Validation Loss = 0.4517728388309479
30-01-2023 01:50:56 INFO Epoch 1: [3620/10940] ---- BYOL Training Loss = 0.3509458899497986
30-01-2023 01:51:23 INFO Epoch 1: [3631/10940] ---- BYOL Training Loss = 0.4025348126888275
30-01-2023 01:51:51 INFO Epoch 1: [3642/10940] ---- BYOL Training Loss = 0.4527405798435211
30-01-2023 01:52:19 INFO Epoch 1: [3653/10940] ---- BYOL Training Loss = 0.4656755030155182
30-01-2023 01:53:47 INFO Epoch 1: [3653/10940] ---- BYOL Validation Loss = 0.4608103930950165
30-01-2023 01:54:15 INFO Epoch 1: [3664/10940] ---- BYOL Training Loss = 0.4634777903556824
30-01-2023 01:54:42 INFO Epoch 1: [3675/10940] ---- BYOL Training Loss = 0.416888952255249
30-01-2023 01:55:10 INFO Epoch 1: [3686/10940] ---- BYOL Training Loss = 0.4440861642360687
30-01-2023 01:55:38 INFO Epoch 1: [3697/10940] ---- BYOL Training Loss = 0.4576970636844635
30-01-2023 01:57:06 INFO Epoch 1: [3697/10940] ---- BYOL Validation Loss = 0.48159903287887573
30-01-2023 01:57:34 INFO Epoch 1: [3708/10940] ---- BYOL Training Loss = 0.4667244553565979
30-01-2023 01:58:01 INFO Epoch 1: [3719/10940] ---- BYOL Training Loss = 0.4160431921482086
30-01-2023 01:58:29 INFO Epoch 1: [3730/10940] ---- BYOL Training Loss = 0.4717347025871277
30-01-2023 01:58:57 INFO Epoch 1: [3741/10940] ---- BYOL Training Loss = 0.49577006697654724
30-01-2023 02:00:25 INFO Epoch 1: [3741/10940] ---- BYOL Validation Loss = 0.5011184215545654
30-01-2023 02:00:53 INFO Epoch 1: [3752/10940] ---- BYOL Training Loss = 0.4436776638031006
30-01-2023 02:01:21 INFO Epoch 1: [3763/10940] ---- BYOL Training Loss = 0.4739139676094055
30-01-2023 02:01:48 INFO Epoch 1: [3774/10940] ---- BYOL Training Loss = 0.4798479974269867
30-01-2023 02:02:16 INFO Epoch 1: [3785/10940] ---- BYOL Training Loss = 0.49833789467811584
30-01-2023 02:03:44 INFO Epoch 1: [3785/10940] ---- BYOL Validation Loss = 0.6399596333503723
30-01-2023 02:04:12 INFO Epoch 1: [3796/10940] ---- BYOL Training Loss = 0.48865795135498047
30-01-2023 02:04:40 INFO Epoch 1: [3807/10940] ---- BYOL Training Loss = 0.4189547002315521
30-01-2023 02:05:08 INFO Epoch 1: [3818/10940] ---- BYOL Training Loss = 0.39358940720558167
30-01-2023 02:05:36 INFO Epoch 1: [3829/10940] ---- BYOL Training Loss = 0.4293079376220703
30-01-2023 02:07:04 INFO Epoch 1: [3829/10940] ---- BYOL Validation Loss = 0.4667254090309143
30-01-2023 02:07:32 INFO Epoch 1: [3840/10940] ---- BYOL Training Loss = 0.5009022951126099
30-01-2023 02:07:59 INFO Epoch 1: [3851/10940] ---- BYOL Training Loss = 0.5160194635391235
30-01-2023 02:08:27 INFO Epoch 1: [3862/10940] ---- BYOL Training Loss = 0.48939433693885803
30-01-2023 02:08:55 INFO Epoch 1: [3873/10940] ---- BYOL Training Loss = 0.475764662027359
30-01-2023 02:10:23 INFO Epoch 1: [3873/10940] ---- BYOL Validation Loss = 0.5099719166755676
30-01-2023 02:10:51 INFO Epoch 1: [3884/10940] ---- BYOL Training Loss = 0.4633216857910156
30-01-2023 02:11:18 INFO Epoch 1: [3895/10940] ---- BYOL Training Loss = 0.4863244593143463
30-01-2023 02:11:46 INFO Epoch 1: [3906/10940] ---- BYOL Training Loss = 0.4629444479942322
30-01-2023 02:12:13 INFO Epoch 1: [3917/10940] ---- BYOL Training Loss = 0.4036344885826111
30-01-2023 02:13:42 INFO Epoch 1: [3917/10940] ---- BYOL Validation Loss = 0.45761898159980774
30-01-2023 02:14:10 INFO Epoch 1: [3928/10940] ---- BYOL Training Loss = 0.38213303685188293
30-01-2023 02:14:37 INFO Epoch 1: [3939/10940] ---- BYOL Training Loss = 0.5212882161140442
30-01-2023 02:15:05 INFO Epoch 1: [3950/10940] ---- BYOL Training Loss = 0.5558586716651917
30-01-2023 02:15:33 INFO Epoch 1: [3961/10940] ---- BYOL Training Loss = 0.43131834268569946
30-01-2023 02:17:01 INFO Epoch 1: [3961/10940] ---- BYOL Validation Loss = 0.4946223795413971
30-01-2023 02:17:29 INFO Epoch 1: [3972/10940] ---- BYOL Training Loss = 0.4544246196746826
30-01-2023 02:17:57 INFO Epoch 1: [3983/10940] ---- BYOL Training Loss = 0.420643150806427
30-01-2023 02:18:25 INFO Epoch 1: [3994/10940] ---- BYOL Training Loss = 0.40569791197776794
30-01-2023 02:18:52 INFO Epoch 1: [4005/10940] ---- BYOL Training Loss = 0.4543456435203552
30-01-2023 02:20:21 INFO Epoch 1: [4005/10940] ---- BYOL Validation Loss = 0.4619921147823334
30-01-2023 02:20:48 INFO Epoch 1: [4016/10940] ---- BYOL Training Loss = 0.49075832962989807
30-01-2023 02:21:16 INFO Epoch 1: [4027/10940] ---- BYOL Training Loss = 0.45236530900001526
30-01-2023 02:21:44 INFO Epoch 1: [4038/10940] ---- BYOL Training Loss = 0.44427356123924255
30-01-2023 02:22:12 INFO Epoch 1: [4049/10940] ---- BYOL Training Loss = 0.4745562672615051
30-01-2023 02:23:40 INFO Epoch 1: [4049/10940] ---- BYOL Validation Loss = 0.4655514657497406
30-01-2023 02:24:08 INFO Epoch 1: [4060/10940] ---- BYOL Training Loss = 0.4793368875980377
30-01-2023 02:24:35 INFO Epoch 1: [4071/10940] ---- BYOL Training Loss = 0.4850645959377289
30-01-2023 02:25:03 INFO Epoch 1: [4082/10940] ---- BYOL Training Loss = 0.4817793369293213
30-01-2023 02:25:31 INFO Epoch 1: [4093/10940] ---- BYOL Training Loss = 0.4427170753479004
30-01-2023 02:26:59 INFO Epoch 1: [4093/10940] ---- BYOL Validation Loss = 0.4395422339439392
30-01-2023 02:27:27 INFO Epoch 1: [4104/10940] ---- BYOL Training Loss = 0.4394131302833557
30-01-2023 02:27:55 INFO Epoch 1: [4115/10940] ---- BYOL Training Loss = 0.4561381936073303
30-01-2023 02:28:23 INFO Epoch 1: [4126/10940] ---- BYOL Training Loss = 0.44992727041244507
30-01-2023 02:28:50 INFO Epoch 1: [4137/10940] ---- BYOL Training Loss = 0.41287389397621155
30-01-2023 02:30:19 INFO Epoch 1: [4137/10940] ---- BYOL Validation Loss = 0.43500301241874695
30-01-2023 02:30:46 INFO Epoch 1: [4148/10940] ---- BYOL Training Loss = 0.3649340867996216
30-01-2023 02:31:14 INFO Epoch 1: [4159/10940] ---- BYOL Training Loss = 0.44429367780685425
30-01-2023 02:31:42 INFO Epoch 1: [4170/10940] ---- BYOL Training Loss = 0.44858473539352417
30-01-2023 02:32:10 INFO Epoch 1: [4181/10940] ---- BYOL Training Loss = 0.38524383306503296
30-01-2023 02:33:38 INFO Epoch 1: [4181/10940] ---- BYOL Validation Loss = 0.7406628727912903
30-01-2023 02:34:06 INFO Epoch 1: [4192/10940] ---- BYOL Training Loss = 0.4724046587944031
30-01-2023 02:34:34 INFO Epoch 1: [4203/10940] ---- BYOL Training Loss = 0.5032123327255249
30-01-2023 02:35:01 INFO Epoch 1: [4214/10940] ---- BYOL Training Loss = 0.48934417963027954
30-01-2023 02:35:29 INFO Epoch 1: [4225/10940] ---- BYOL Training Loss = 0.4698576033115387
30-01-2023 02:36:58 INFO Epoch 1: [4225/10940] ---- BYOL Validation Loss = 0.6612507700920105
30-01-2023 02:37:25 INFO Epoch 1: [4236/10940] ---- BYOL Training Loss = 0.38130104541778564
30-01-2023 02:37:53 INFO Epoch 1: [4247/10940] ---- BYOL Training Loss = 0.3779546618461609
30-01-2023 02:38:21 INFO Epoch 1: [4258/10940] ---- BYOL Training Loss = 0.43369054794311523
30-01-2023 02:38:48 INFO Epoch 1: [4269/10940] ---- BYOL Training Loss = 0.46516337990760803
30-01-2023 02:40:17 INFO Epoch 1: [4269/10940] ---- BYOL Validation Loss = 0.5020707249641418
30-01-2023 02:40:45 INFO Epoch 1: [4280/10940] ---- BYOL Training Loss = 0.43662160634994507
30-01-2023 02:41:12 INFO Epoch 1: [4291/10940] ---- BYOL Training Loss = 0.40847739577293396
30-01-2023 02:41:40 INFO Epoch 1: [4302/10940] ---- BYOL Training Loss = 0.39613577723503113
30-01-2023 02:42:08 INFO Epoch 1: [4313/10940] ---- BYOL Training Loss = 0.39873045682907104
30-01-2023 02:43:36 INFO Epoch 1: [4313/10940] ---- BYOL Validation Loss = 0.4741310477256775
30-01-2023 02:44:04 INFO Epoch 1: [4324/10940] ---- BYOL Training Loss = 0.5103128552436829
30-01-2023 02:44:32 INFO Epoch 1: [4335/10940] ---- BYOL Training Loss = 0.5334675908088684
30-01-2023 02:44:59 INFO Epoch 1: [4346/10940] ---- BYOL Training Loss = 0.49811992049217224
30-01-2023 02:45:27 INFO Epoch 1: [4357/10940] ---- BYOL Training Loss = 0.4781018793582916
30-01-2023 02:46:55 INFO Epoch 1: [4357/10940] ---- BYOL Validation Loss = 0.43358489871025085
30-01-2023 02:47:23 INFO Epoch 1: [4368/10940] ---- BYOL Training Loss = 0.4464150369167328
30-01-2023 02:47:51 INFO Epoch 1: [4379/10940] ---- BYOL Training Loss = 0.4128756523132324
30-01-2023 02:48:19 INFO Epoch 1: [4390/10940] ---- BYOL Training Loss = 0.43831557035446167
30-01-2023 02:48:47 INFO Epoch 1: [4401/10940] ---- BYOL Training Loss = 0.40954023599624634
30-01-2023 02:50:15 INFO Epoch 1: [4401/10940] ---- BYOL Validation Loss = 0.4290793836116791
30-01-2023 02:50:43 INFO Epoch 1: [4412/10940] ---- BYOL Training Loss = 0.40964198112487793
30-01-2023 02:51:10 INFO Epoch 1: [4423/10940] ---- BYOL Training Loss = 0.42615383863449097
30-01-2023 02:51:38 INFO Epoch 1: [4434/10940] ---- BYOL Training Loss = 0.48308172821998596
30-01-2023 02:52:06 INFO Epoch 1: [4445/10940] ---- BYOL Training Loss = 0.5373989343643188
30-01-2023 02:53:34 INFO Epoch 1: [4445/10940] ---- BYOL Validation Loss = 0.4469766616821289
30-01-2023 02:54:02 INFO Epoch 1: [4456/10940] ---- BYOL Training Loss = 0.4646579325199127
30-01-2023 02:54:30 INFO Epoch 1: [4467/10940] ---- BYOL Training Loss = 0.41702836751937866
30-01-2023 02:54:58 INFO Epoch 1: [4478/10940] ---- BYOL Training Loss = 0.4791902005672455
30-01-2023 02:55:26 INFO Epoch 1: [4489/10940] ---- BYOL Training Loss = 0.4559960961341858
30-01-2023 02:56:54 INFO Epoch 1: [4489/10940] ---- BYOL Validation Loss = 0.46592018008232117
30-01-2023 02:57:22 INFO Epoch 1: [4500/10940] ---- BYOL Training Loss = 0.4604133069515228
30-01-2023 02:57:50 INFO Epoch 1: [4511/10940] ---- BYOL Training Loss = 0.4897581934928894
30-01-2023 02:58:17 INFO Epoch 1: [4522/10940] ---- BYOL Training Loss = 0.4780219495296478
30-01-2023 02:58:45 INFO Epoch 1: [4533/10940] ---- BYOL Training Loss = 0.4632492661476135
30-01-2023 03:00:13 INFO Epoch 1: [4533/10940] ---- BYOL Validation Loss = 0.4541017711162567
30-01-2023 03:00:41 INFO Epoch 1: [4544/10940] ---- BYOL Training Loss = 0.41836079955101013
30-01-2023 03:01:09 INFO Epoch 1: [4555/10940] ---- BYOL Training Loss = 0.4528546929359436
30-01-2023 03:01:37 INFO Epoch 1: [4566/10940] ---- BYOL Training Loss = 0.4355011582374573
30-01-2023 03:02:05 INFO Epoch 1: [4577/10940] ---- BYOL Training Loss = 0.4296792149543762
30-01-2023 03:03:33 INFO Epoch 1: [4577/10940] ---- BYOL Validation Loss = 0.4440172016620636
30-01-2023 03:04:01 INFO Epoch 1: [4588/10940] ---- BYOL Training Loss = 0.3577592968940735
30-01-2023 03:04:29 INFO Epoch 1: [4599/10940] ---- BYOL Training Loss = 0.3452503979206085
30-01-2023 03:04:57 INFO Epoch 1: [4610/10940] ---- BYOL Training Loss = 0.3845992684364319
30-01-2023 03:05:25 INFO Epoch 1: [4621/10940] ---- BYOL Training Loss = 0.39168933033943176
30-01-2023 03:06:53 INFO Epoch 1: [4621/10940] ---- BYOL Validation Loss = 0.4702966511249542
30-01-2023 03:07:20 INFO Epoch 1: [4632/10940] ---- BYOL Training Loss = 0.4189108908176422
30-01-2023 03:07:49 INFO Epoch 1: [4643/10940] ---- BYOL Training Loss = 0.47049206495285034
30-01-2023 03:08:16 INFO Epoch 1: [4654/10940] ---- BYOL Training Loss = 0.4710511565208435
30-01-2023 03:08:44 INFO Epoch 1: [4665/10940] ---- BYOL Training Loss = 0.39738208055496216
30-01-2023 03:10:12 INFO Epoch 1: [4665/10940] ---- BYOL Validation Loss = 0.4501104950904846
30-01-2023 03:10:40 INFO Epoch 1: [4676/10940] ---- BYOL Training Loss = 0.43442869186401367
30-01-2023 03:11:08 INFO Epoch 1: [4687/10940] ---- BYOL Training Loss = 0.4860827922821045
30-01-2023 03:11:36 INFO Epoch 1: [4698/10940] ---- BYOL Training Loss = 0.5551732778549194
30-01-2023 03:12:04 INFO Epoch 1: [4709/10940] ---- BYOL Training Loss = 0.5332779884338379
30-01-2023 03:13:32 INFO Epoch 1: [4709/10940] ---- BYOL Validation Loss = 0.4406263828277588
30-01-2023 03:14:00 INFO Epoch 1: [4720/10940] ---- BYOL Training Loss = 0.42311781644821167
30-01-2023 03:14:27 INFO Epoch 1: [4731/10940] ---- BYOL Training Loss = 0.44549232721328735
30-01-2023 03:14:55 INFO Epoch 1: [4742/10940] ---- BYOL Training Loss = 0.46734562516212463
30-01-2023 03:15:23 INFO Epoch 1: [4753/10940] ---- BYOL Training Loss = 0.43510064482688904
30-01-2023 03:16:51 INFO Epoch 1: [4753/10940] ---- BYOL Validation Loss = 0.4482603669166565
30-01-2023 03:17:19 INFO Epoch 1: [4764/10940] ---- BYOL Training Loss = 0.43902578949928284
30-01-2023 03:17:47 INFO Epoch 1: [4775/10940] ---- BYOL Training Loss = 0.39272910356521606
30-01-2023 03:18:15 INFO Epoch 1: [4786/10940] ---- BYOL Training Loss = 0.3411406874656677
30-01-2023 03:18:43 INFO Epoch 1: [4797/10940] ---- BYOL Training Loss = 0.3574531674385071
30-01-2023 03:20:11 INFO Epoch 1: [4797/10940] ---- BYOL Validation Loss = 0.4690324664115906
30-01-2023 03:20:39 INFO Epoch 1: [4808/10940] ---- BYOL Training Loss = 0.4022681713104248
30-01-2023 03:21:07 INFO Epoch 1: [4819/10940] ---- BYOL Training Loss = 0.4136367738246918
30-01-2023 03:21:34 INFO Epoch 1: [4830/10940] ---- BYOL Training Loss = 0.39711835980415344
30-01-2023 03:22:02 INFO Epoch 1: [4841/10940] ---- BYOL Training Loss = 0.4783632755279541
30-01-2023 03:23:30 INFO Epoch 1: [4841/10940] ---- BYOL Validation Loss = 0.5212198495864868
30-01-2023 03:23:59 INFO Epoch 1: [4852/10940] ---- BYOL Training Loss = 0.4396507740020752
30-01-2023 03:24:26 INFO Epoch 1: [4863/10940] ---- BYOL Training Loss = 0.36972102522850037
30-01-2023 03:24:54 INFO Epoch 1: [4874/10940] ---- BYOL Training Loss = 0.40466150641441345
30-01-2023 03:25:22 INFO Epoch 1: [4885/10940] ---- BYOL Training Loss = 0.5103431940078735
30-01-2023 03:26:50 INFO Epoch 1: [4885/10940] ---- BYOL Validation Loss = 0.46930548548698425
30-01-2023 03:27:18 INFO Epoch 1: [4896/10940] ---- BYOL Training Loss = 0.5301837921142578
30-01-2023 03:27:46 INFO Epoch 1: [4907/10940] ---- BYOL Training Loss = 0.44873517751693726
30-01-2023 03:28:15 INFO Epoch 1: [4918/10940] ---- BYOL Training Loss = 0.4824727177619934
30-01-2023 03:28:42 INFO Epoch 1: [4929/10940] ---- BYOL Training Loss = 0.44845089316368103
30-01-2023 03:30:11 INFO Epoch 1: [4929/10940] ---- BYOL Validation Loss = 0.4203810691833496
30-01-2023 03:30:38 INFO Epoch 1: [4940/10940] ---- BYOL Training Loss = 0.3631555140018463
30-01-2023 03:31:06 INFO Epoch 1: [4951/10940] ---- BYOL Training Loss = 0.3693750500679016
30-01-2023 03:31:34 INFO Epoch 1: [4962/10940] ---- BYOL Training Loss = 0.39809784293174744
30-01-2023 03:32:02 INFO Epoch 1: [4973/10940] ---- BYOL Training Loss = 0.4214588701725006
30-01-2023 03:33:30 INFO Epoch 1: [4973/10940] ---- BYOL Validation Loss = 0.4271768033504486
30-01-2023 03:33:58 INFO Epoch 1: [4984/10940] ---- BYOL Training Loss = 0.44187861680984497
30-01-2023 03:34:26 INFO Epoch 1: [4995/10940] ---- BYOL Training Loss = 0.4329906105995178
30-01-2023 03:34:54 INFO Epoch 1: [5006/10940] ---- BYOL Training Loss = 0.45883193612098694
30-01-2023 03:35:22 INFO Epoch 1: [5017/10940] ---- BYOL Training Loss = 0.4293639659881592
30-01-2023 03:36:50 INFO Epoch 1: [5017/10940] ---- BYOL Validation Loss = 0.42615100741386414
30-01-2023 03:37:18 INFO Epoch 1: [5028/10940] ---- BYOL Training Loss = 0.38590753078460693
30-01-2023 03:37:46 INFO Epoch 1: [5039/10940] ---- BYOL Training Loss = 0.35503438115119934
30-01-2023 03:38:14 INFO Epoch 1: [5050/10940] ---- BYOL Training Loss = 0.39501047134399414
30-01-2023 03:38:41 INFO Epoch 1: [5061/10940] ---- BYOL Training Loss = 0.4152302145957947
30-01-2023 03:40:10 INFO Epoch 1: [5061/10940] ---- BYOL Validation Loss = 0.43398550152778625
30-01-2023 03:40:38 INFO Epoch 1: [5072/10940] ---- BYOL Training Loss = 0.4042597711086273
30-01-2023 03:41:05 INFO Epoch 1: [5083/10940] ---- BYOL Training Loss = 0.537590742111206
30-01-2023 03:41:33 INFO Epoch 1: [5094/10940] ---- BYOL Training Loss = 0.5120123028755188
30-01-2023 03:42:01 INFO Epoch 1: [5105/10940] ---- BYOL Training Loss = 0.3801136314868927
30-01-2023 03:43:30 INFO Epoch 1: [5105/10940] ---- BYOL Validation Loss = 0.43057745695114136
30-01-2023 03:43:57 INFO Epoch 1: [5116/10940] ---- BYOL Training Loss = 0.32114043831825256
30-01-2023 03:44:25 INFO Epoch 1: [5127/10940] ---- BYOL Training Loss = 0.31986138224601746
30-01-2023 03:44:53 INFO Epoch 1: [5138/10940] ---- BYOL Training Loss = 0.4179525375366211
30-01-2023 03:45:22 INFO Epoch 1: [5149/10940] ---- BYOL Training Loss = 0.4202747344970703
30-01-2023 03:46:50 INFO Epoch 1: [5149/10940] ---- BYOL Validation Loss = 0.4144270122051239
30-01-2023 03:47:18 INFO Epoch 1: [5160/10940] ---- BYOL Training Loss = 0.4260381758213043
30-01-2023 03:47:46 INFO Epoch 1: [5171/10940] ---- BYOL Training Loss = 0.4472392499446869
30-01-2023 03:48:14 INFO Epoch 1: [5182/10940] ---- BYOL Training Loss = 0.4479095935821533
30-01-2023 03:48:42 INFO Epoch 1: [5193/10940] ---- BYOL Training Loss = 0.40816134214401245
30-01-2023 03:50:10 INFO Epoch 1: [5193/10940] ---- BYOL Validation Loss = 0.4334668219089508
30-01-2023 03:50:38 INFO Epoch 1: [5204/10940] ---- BYOL Training Loss = 0.4049723744392395
30-01-2023 03:51:06 INFO Epoch 1: [5215/10940] ---- BYOL Training Loss = 0.39127016067504883
30-01-2023 03:51:34 INFO Epoch 1: [5226/10940] ---- BYOL Training Loss = 0.4253457486629486
30-01-2023 03:52:02 INFO Epoch 1: [5237/10940] ---- BYOL Training Loss = 0.3992684781551361
30-01-2023 03:53:30 INFO Epoch 1: [5237/10940] ---- BYOL Validation Loss = 0.42436790466308594
30-01-2023 03:53:58 INFO Epoch 1: [5248/10940] ---- BYOL Training Loss = 0.370977520942688
30-01-2023 03:54:26 INFO Epoch 1: [5259/10940] ---- BYOL Training Loss = 0.39360806345939636
30-01-2023 03:54:53 INFO Epoch 1: [5270/10940] ---- BYOL Training Loss = 0.43011531233787537
30-01-2023 03:55:21 INFO Epoch 1: [5281/10940] ---- BYOL Training Loss = 0.39320507645606995
30-01-2023 03:56:50 INFO Epoch 1: [5281/10940] ---- BYOL Validation Loss = 0.4245705008506775
30-01-2023 03:57:17 INFO Epoch 1: [5292/10940] ---- BYOL Training Loss = 0.380201131105423
30-01-2023 03:57:45 INFO Epoch 1: [5303/10940] ---- BYOL Training Loss = 0.37359553575515747
30-01-2023 03:58:13 INFO Epoch 1: [5314/10940] ---- BYOL Training Loss = 0.4630744457244873
30-01-2023 03:58:41 INFO Epoch 1: [5325/10940] ---- BYOL Training Loss = 0.45101451873779297
30-01-2023 04:00:10 INFO Epoch 1: [5325/10940] ---- BYOL Validation Loss = 0.4219786822795868
30-01-2023 04:00:37 INFO Epoch 1: [5336/10940] ---- BYOL Training Loss = 0.42477506399154663
30-01-2023 04:01:05 INFO Epoch 1: [5347/10940] ---- BYOL Training Loss = 0.3668137490749359
30-01-2023 04:01:33 INFO Epoch 1: [5358/10940] ---- BYOL Training Loss = 0.3612793982028961
30-01-2023 04:02:01 INFO Epoch 1: [5369/10940] ---- BYOL Training Loss = 0.44295424222946167
30-01-2023 04:03:29 INFO Epoch 1: [5369/10940] ---- BYOL Validation Loss = 0.43012747168540955
30-01-2023 04:03:57 INFO Epoch 1: [5380/10940] ---- BYOL Training Loss = 0.3734435439109802
30-01-2023 04:04:25 INFO Epoch 1: [5391/10940] ---- BYOL Training Loss = 0.37125706672668457
30-01-2023 04:04:53 INFO Epoch 1: [5402/10940] ---- BYOL Training Loss = 0.4009172022342682
30-01-2023 04:05:21 INFO Epoch 1: [5413/10940] ---- BYOL Training Loss = 0.412651389837265
30-01-2023 04:06:49 INFO Epoch 1: [5413/10940] ---- BYOL Validation Loss = 0.4514760375022888
30-01-2023 04:07:17 INFO Epoch 1: [5424/10940] ---- BYOL Training Loss = 0.4145492911338806
30-01-2023 04:07:45 INFO Epoch 1: [5435/10940] ---- BYOL Training Loss = 0.3583677113056183
30-01-2023 04:08:13 INFO Epoch 1: [5446/10940] ---- BYOL Training Loss = 0.31609874963760376
30-01-2023 04:08:41 INFO Epoch 1: [5457/10940] ---- BYOL Training Loss = 0.41173607110977173
30-01-2023 04:10:09 INFO Epoch 1: [5457/10940] ---- BYOL Validation Loss = 0.4341718256473541
30-01-2023 04:10:37 INFO Epoch 1: [5468/10940] ---- BYOL Training Loss = 0.41188326478004456
30-01-2023 04:11:05 INFO Epoch 1: [5479/10940] ---- BYOL Training Loss = 0.437880277633667
30-01-2023 04:11:33 INFO Epoch 1: [5490/10940] ---- BYOL Training Loss = 0.5092532634735107
30-01-2023 04:12:01 INFO Epoch 1: [5501/10940] ---- BYOL Training Loss = 0.49315595626831055
30-01-2023 04:13:29 INFO Epoch 1: [5501/10940] ---- BYOL Validation Loss = 0.4129393398761749
30-01-2023 04:13:57 INFO Epoch 1: [5512/10940] ---- BYOL Training Loss = 0.4274420738220215
30-01-2023 04:14:25 INFO Epoch 1: [5523/10940] ---- BYOL Training Loss = 0.4367383122444153
30-01-2023 04:14:52 INFO Epoch 1: [5534/10940] ---- BYOL Training Loss = 0.4718928933143616
30-01-2023 04:15:20 INFO Epoch 1: [5545/10940] ---- BYOL Training Loss = 0.3514949679374695
30-01-2023 04:16:49 INFO Epoch 1: [5545/10940] ---- BYOL Validation Loss = 0.4004233181476593
30-01-2023 04:17:17 INFO Epoch 1: [5556/10940] ---- BYOL Training Loss = 0.35945993661880493
30-01-2023 04:17:44 INFO Epoch 1: [5567/10940] ---- BYOL Training Loss = 0.37286847829818726
30-01-2023 04:18:13 INFO Epoch 1: [5578/10940] ---- BYOL Training Loss = 0.39851316809654236
30-01-2023 04:18:41 INFO Epoch 1: [5589/10940] ---- BYOL Training Loss = 0.46433180570602417
30-01-2023 04:20:09 INFO Epoch 1: [5589/10940] ---- BYOL Validation Loss = 0.41358551383018494
30-01-2023 04:20:37 INFO Epoch 1: [5600/10940] ---- BYOL Training Loss = 0.42334452271461487
30-01-2023 04:21:05 INFO Epoch 1: [5611/10940] ---- BYOL Training Loss = 0.36745303869247437
30-01-2023 04:21:32 INFO Epoch 1: [5622/10940] ---- BYOL Training Loss = 0.4362436830997467
30-01-2023 04:22:01 INFO Epoch 1: [5633/10940] ---- BYOL Training Loss = 0.4571017324924469
30-01-2023 04:23:29 INFO Epoch 1: [5633/10940] ---- BYOL Validation Loss = 0.4080195724964142
30-01-2023 04:23:57 INFO Epoch 1: [5644/10940] ---- BYOL Training Loss = 0.46758073568344116
30-01-2023 04:24:25 INFO Epoch 1: [5655/10940] ---- BYOL Training Loss = 0.45191723108291626
30-01-2023 04:24:53 INFO Epoch 1: [5666/10940] ---- BYOL Training Loss = 0.39076024293899536
30-01-2023 04:25:21 INFO Epoch 1: [5677/10940] ---- BYOL Training Loss = 0.41404539346694946
30-01-2023 04:26:49 INFO Epoch 1: [5677/10940] ---- BYOL Validation Loss = 1.3638545274734497
30-01-2023 04:27:17 INFO Epoch 1: [5688/10940] ---- BYOL Training Loss = 0.41357478499412537
30-01-2023 04:27:45 INFO Epoch 1: [5699/10940] ---- BYOL Training Loss = 0.3257174491882324
30-01-2023 04:28:12 INFO Epoch 1: [5710/10940] ---- BYOL Training Loss = 0.38961172103881836
30-01-2023 04:28:41 INFO Epoch 1: [5721/10940] ---- BYOL Training Loss = 0.4368502199649811
30-01-2023 04:30:09 INFO Epoch 1: [5721/10940] ---- BYOL Validation Loss = 0.42050257325172424
30-01-2023 04:30:37 INFO Epoch 1: [5732/10940] ---- BYOL Training Loss = 0.42823633551597595
30-01-2023 04:31:05 INFO Epoch 1: [5743/10940] ---- BYOL Training Loss = 0.40763863921165466
30-01-2023 04:31:32 INFO Epoch 1: [5754/10940] ---- BYOL Training Loss = 0.366732656955719
30-01-2023 04:32:01 INFO Epoch 1: [5765/10940] ---- BYOL Training Loss = 0.35184377431869507
30-01-2023 04:33:29 INFO Epoch 1: [5765/10940] ---- BYOL Validation Loss = 0.3919439911842346
30-01-2023 04:33:57 INFO Epoch 1: [5776/10940] ---- BYOL Training Loss = 0.3946157395839691
30-01-2023 04:34:24 INFO Epoch 1: [5787/10940] ---- BYOL Training Loss = 0.39156824350357056
30-01-2023 04:34:53 INFO Epoch 1: [5798/10940] ---- BYOL Training Loss = 0.4081745147705078
30-01-2023 04:35:20 INFO Epoch 1: [5809/10940] ---- BYOL Training Loss = 0.3347526490688324
30-01-2023 04:36:48 INFO Epoch 1: [5809/10940] ---- BYOL Validation Loss = 0.3798682987689972
30-01-2023 04:37:16 INFO Epoch 1: [5820/10940] ---- BYOL Training Loss = 0.34129565954208374
30-01-2023 04:37:44 INFO Epoch 1: [5831/10940] ---- BYOL Training Loss = 0.41868162155151367
30-01-2023 04:38:12 INFO Epoch 1: [5842/10940] ---- BYOL Training Loss = 0.39380621910095215
30-01-2023 04:38:40 INFO Epoch 1: [5853/10940] ---- BYOL Training Loss = 0.3754385709762573
30-01-2023 04:40:08 INFO Epoch 1: [5853/10940] ---- BYOL Validation Loss = 0.3833964169025421
30-01-2023 04:40:36 INFO Epoch 1: [5864/10940] ---- BYOL Training Loss = 0.34711796045303345
30-01-2023 04:41:04 INFO Epoch 1: [5875/10940] ---- BYOL Training Loss = 0.3760806918144226
30-01-2023 04:41:32 INFO Epoch 1: [5886/10940] ---- BYOL Training Loss = 0.3990868628025055
30-01-2023 04:42:00 INFO Epoch 1: [5897/10940] ---- BYOL Training Loss = 0.3327317535877228
30-01-2023 04:43:28 INFO Epoch 1: [5897/10940] ---- BYOL Validation Loss = 0.4044043719768524
30-01-2023 04:43:56 INFO Epoch 1: [5908/10940] ---- BYOL Training Loss = 0.3633614480495453
30-01-2023 04:44:24 INFO Epoch 1: [5919/10940] ---- BYOL Training Loss = 0.3503505289554596
30-01-2023 04:44:52 INFO Epoch 1: [5930/10940] ---- BYOL Training Loss = 0.33354803919792175
30-01-2023 04:45:20 INFO Epoch 1: [5941/10940] ---- BYOL Training Loss = 0.3776295781135559
30-01-2023 04:46:48 INFO Epoch 1: [5941/10940] ---- BYOL Validation Loss = 0.3955645263195038
30-01-2023 04:47:16 INFO Epoch 1: [5952/10940] ---- BYOL Training Loss = 0.35117441415786743
30-01-2023 04:47:44 INFO Epoch 1: [5963/10940] ---- BYOL Training Loss = 0.3329617381095886
30-01-2023 04:48:12 INFO Epoch 1: [5974/10940] ---- BYOL Training Loss = 0.4569801688194275
30-01-2023 04:48:40 INFO Epoch 1: [5985/10940] ---- BYOL Training Loss = 0.4638758599758148
30-01-2023 04:50:08 INFO Epoch 1: [5985/10940] ---- BYOL Validation Loss = 0.3998161256313324
30-01-2023 04:50:36 INFO Epoch 1: [5996/10940] ---- BYOL Training Loss = 0.397203654050827
30-01-2023 04:51:04 INFO Epoch 1: [6007/10940] ---- BYOL Training Loss = 0.4099978804588318
30-01-2023 04:51:32 INFO Epoch 1: [6018/10940] ---- BYOL Training Loss = 0.4605347514152527
30-01-2023 04:52:00 INFO Epoch 1: [6029/10940] ---- BYOL Training Loss = 0.3705596327781677
30-01-2023 04:53:28 INFO Epoch 1: [6029/10940] ---- BYOL Validation Loss = 0.38171568512916565
30-01-2023 04:53:56 INFO Epoch 1: [6040/10940] ---- BYOL Training Loss = 0.28677597641944885
30-01-2023 04:54:24 INFO Epoch 1: [6051/10940] ---- BYOL Training Loss = 0.36079543828964233
30-01-2023 04:54:52 INFO Epoch 1: [6062/10940] ---- BYOL Training Loss = 0.41262227296829224
30-01-2023 04:55:21 INFO Epoch 1: [6073/10940] ---- BYOL Training Loss = 0.39902979135513306
30-01-2023 04:56:49 INFO Epoch 1: [6073/10940] ---- BYOL Validation Loss = 0.36915186047554016
30-01-2023 04:57:17 INFO Epoch 1: [6084/10940] ---- BYOL Training Loss = 0.42343807220458984
30-01-2023 04:57:45 INFO Epoch 1: [6095/10940] ---- BYOL Training Loss = 0.37132272124290466
30-01-2023 04:58:13 INFO Epoch 1: [6106/10940] ---- BYOL Training Loss = 0.38763323426246643
30-01-2023 04:58:41 INFO Epoch 1: [6117/10940] ---- BYOL Training Loss = 0.4222472310066223
30-01-2023 05:00:09 INFO Epoch 1: [6117/10940] ---- BYOL Validation Loss = 0.38577595353126526
30-01-2023 05:00:37 INFO Epoch 1: [6128/10940] ---- BYOL Training Loss = 0.3677115738391876
30-01-2023 05:01:05 INFO Epoch 1: [6139/10940] ---- BYOL Training Loss = 0.3901323676109314
30-01-2023 05:01:33 INFO Epoch 1: [6150/10940] ---- BYOL Training Loss = 0.41961365938186646
30-01-2023 05:02:01 INFO Epoch 1: [6161/10940] ---- BYOL Training Loss = 0.3779035210609436
30-01-2023 05:03:29 INFO Epoch 1: [6161/10940] ---- BYOL Validation Loss = 0.3887364864349365
30-01-2023 05:03:57 INFO Epoch 1: [6172/10940] ---- BYOL Training Loss = 0.34384414553642273
30-01-2023 05:04:25 INFO Epoch 1: [6183/10940] ---- BYOL Training Loss = 0.3287349343299866
30-01-2023 05:04:53 INFO Epoch 1: [6194/10940] ---- BYOL Training Loss = 0.2945632338523865
30-01-2023 05:05:21 INFO Epoch 1: [6205/10940] ---- BYOL Training Loss = 0.32339122891426086
30-01-2023 05:06:49 INFO Epoch 1: [6205/10940] ---- BYOL Validation Loss = 0.38117435574531555
30-01-2023 05:07:17 INFO Epoch 1: [6216/10940] ---- BYOL Training Loss = 0.34214118123054504
30-01-2023 05:07:45 INFO Epoch 1: [6227/10940] ---- BYOL Training Loss = 0.3275931775569916
30-01-2023 05:08:13 INFO Epoch 1: [6238/10940] ---- BYOL Training Loss = 0.3615865111351013
30-01-2023 05:08:41 INFO Epoch 1: [6249/10940] ---- BYOL Training Loss = 0.37754571437835693
30-01-2023 05:10:09 INFO Epoch 1: [6249/10940] ---- BYOL Validation Loss = 0.38619402050971985
30-01-2023 05:10:38 INFO Epoch 1: [6260/10940] ---- BYOL Training Loss = 0.3516623377799988
30-01-2023 05:11:05 INFO Epoch 1: [6271/10940] ---- BYOL Training Loss = 0.3773919939994812
30-01-2023 05:11:33 INFO Epoch 1: [6282/10940] ---- BYOL Training Loss = 0.40324991941452026
30-01-2023 05:12:02 INFO Epoch 1: [6293/10940] ---- BYOL Training Loss = 0.3884180784225464
30-01-2023 05:13:30 INFO Epoch 1: [6293/10940] ---- BYOL Validation Loss = 0.4094598889350891
30-01-2023 05:13:58 INFO Epoch 1: [6304/10940] ---- BYOL Training Loss = 0.3973998427391052
30-01-2023 05:14:26 INFO Epoch 1: [6315/10940] ---- BYOL Training Loss = 0.3523772358894348
30-01-2023 05:14:54 INFO Epoch 1: [6326/10940] ---- BYOL Training Loss = 0.3639289438724518
30-01-2023 05:15:22 INFO Epoch 1: [6337/10940] ---- BYOL Training Loss = 0.3836660385131836
30-01-2023 05:16:50 INFO Epoch 1: [6337/10940] ---- BYOL Validation Loss = 0.3704361319541931
30-01-2023 05:17:18 INFO Epoch 1: [6348/10940] ---- BYOL Training Loss = 0.3189021050930023
30-01-2023 05:17:46 INFO Epoch 1: [6359/10940] ---- BYOL Training Loss = 0.3389112055301666
30-01-2023 05:18:14 INFO Epoch 1: [6370/10940] ---- BYOL Training Loss = 0.31823453307151794
30-01-2023 05:18:42 INFO Epoch 1: [6381/10940] ---- BYOL Training Loss = 0.286261647939682
30-01-2023 05:20:10 INFO Epoch 1: [6381/10940] ---- BYOL Validation Loss = 0.36548280715942383
30-01-2023 05:20:38 INFO Epoch 1: [6392/10940] ---- BYOL Training Loss = 0.3492279648780823
30-01-2023 05:21:06 INFO Epoch 1: [6403/10940] ---- BYOL Training Loss = 0.34965240955352783
30-01-2023 05:21:35 INFO Epoch 1: [6414/10940] ---- BYOL Training Loss = 0.3646373152732849
30-01-2023 05:22:02 INFO Epoch 1: [6425/10940] ---- BYOL Training Loss = 0.4276138246059418
30-01-2023 05:23:30 INFO Epoch 1: [6425/10940] ---- BYOL Validation Loss = 0.36423876881599426
30-01-2023 05:23:58 INFO Epoch 1: [6436/10940] ---- BYOL Training Loss = 0.395842581987381
30-01-2023 05:24:27 INFO Epoch 1: [6447/10940] ---- BYOL Training Loss = 0.3528739809989929
30-01-2023 05:24:55 INFO Epoch 1: [6458/10940] ---- BYOL Training Loss = 0.3505796790122986
30-01-2023 05:25:23 INFO Epoch 1: [6469/10940] ---- BYOL Training Loss = 0.33964797854423523
30-01-2023 05:26:51 INFO Epoch 1: [6469/10940] ---- BYOL Validation Loss = 0.38100141286849976
30-01-2023 05:27:19 INFO Epoch 1: [6480/10940] ---- BYOL Training Loss = 0.3833152651786804
30-01-2023 05:27:47 INFO Epoch 1: [6491/10940] ---- BYOL Training Loss = 0.3646787405014038
30-01-2023 05:28:15 INFO Epoch 1: [6502/10940] ---- BYOL Training Loss = 0.41724783182144165
30-01-2023 05:28:43 INFO Epoch 1: [6513/10940] ---- BYOL Training Loss = 0.3665260672569275
30-01-2023 05:30:11 INFO Epoch 1: [6513/10940] ---- BYOL Validation Loss = 0.3698684275150299
30-01-2023 05:30:40 INFO Epoch 1: [6524/10940] ---- BYOL Training Loss = 0.3357391953468323
30-01-2023 05:31:08 INFO Epoch 1: [6535/10940] ---- BYOL Training Loss = 0.3630889356136322
30-01-2023 05:31:36 INFO Epoch 1: [6546/10940] ---- BYOL Training Loss = 0.3824801743030548
30-01-2023 05:32:03 INFO Epoch 1: [6557/10940] ---- BYOL Training Loss = 0.3296651840209961
30-01-2023 05:33:32 INFO Epoch 1: [6557/10940] ---- BYOL Validation Loss = 0.36649656295776367
30-01-2023 05:34:00 INFO Epoch 1: [6568/10940] ---- BYOL Training Loss = 0.319275438785553
30-01-2023 05:34:28 INFO Epoch 1: [6579/10940] ---- BYOL Training Loss = 0.3778330981731415
30-01-2023 05:34:56 INFO Epoch 1: [6590/10940] ---- BYOL Training Loss = 0.46011948585510254
30-01-2023 05:35:24 INFO Epoch 1: [6601/10940] ---- BYOL Training Loss = 0.4287286400794983
30-01-2023 05:36:53 INFO Epoch 1: [6601/10940] ---- BYOL Validation Loss = 0.36182543635368347
30-01-2023 05:37:20 INFO Epoch 1: [6612/10940] ---- BYOL Training Loss = 0.3611535429954529
30-01-2023 05:37:48 INFO Epoch 1: [6623/10940] ---- BYOL Training Loss = 0.35191893577575684
30-01-2023 05:38:17 INFO Epoch 1: [6634/10940] ---- BYOL Training Loss = 0.3523692786693573
30-01-2023 05:38:45 INFO Epoch 1: [6645/10940] ---- BYOL Training Loss = 0.39869266748428345
30-01-2023 05:40:13 INFO Epoch 1: [6645/10940] ---- BYOL Validation Loss = 1.7779762744903564
30-01-2023 05:40:41 INFO Epoch 1: [6656/10940] ---- BYOL Training Loss = 0.3707731366157532
30-01-2023 05:41:09 INFO Epoch 1: [6667/10940] ---- BYOL Training Loss = 0.3639153838157654
30-01-2023 05:41:37 INFO Epoch 1: [6678/10940] ---- BYOL Training Loss = 0.35403138399124146
30-01-2023 05:42:05 INFO Epoch 1: [6689/10940] ---- BYOL Training Loss = 0.34478968381881714
30-01-2023 05:43:33 INFO Epoch 1: [6689/10940] ---- BYOL Validation Loss = 0.36112359166145325
30-01-2023 05:44:01 INFO Epoch 1: [6700/10940] ---- BYOL Training Loss = 0.36151957511901855
30-01-2023 05:44:30 INFO Epoch 1: [6711/10940] ---- BYOL Training Loss = 0.32747066020965576
30-01-2023 05:44:57 INFO Epoch 1: [6722/10940] ---- BYOL Training Loss = 0.3261062204837799
30-01-2023 05:45:25 INFO Epoch 1: [6733/10940] ---- BYOL Training Loss = 0.4053688943386078
30-01-2023 05:46:53 INFO Epoch 1: [6733/10940] ---- BYOL Validation Loss = 0.3785445988178253
30-01-2023 05:47:22 INFO Epoch 1: [6744/10940] ---- BYOL Training Loss = 0.4648568630218506
30-01-2023 05:47:50 INFO Epoch 1: [6755/10940] ---- BYOL Training Loss = 0.4090842604637146
30-01-2023 05:48:18 INFO Epoch 1: [6766/10940] ---- BYOL Training Loss = 0.36865147948265076
30-01-2023 05:48:46 INFO Epoch 1: [6777/10940] ---- BYOL Training Loss = 0.3411133885383606
30-01-2023 05:50:14 INFO Epoch 1: [6777/10940] ---- BYOL Validation Loss = 0.37563952803611755
30-01-2023 05:50:42 INFO Epoch 1: [6788/10940] ---- BYOL Training Loss = 0.36801677942276
30-01-2023 05:51:10 INFO Epoch 1: [6799/10940] ---- BYOL Training Loss = 0.35763221979141235
30-01-2023 05:51:39 INFO Epoch 1: [6810/10940] ---- BYOL Training Loss = 0.338348388671875
30-01-2023 05:52:07 INFO Epoch 1: [6821/10940] ---- BYOL Training Loss = 0.3624086380004883
30-01-2023 05:53:35 INFO Epoch 1: [6821/10940] ---- BYOL Validation Loss = 0.36189350485801697
30-01-2023 05:54:03 INFO Epoch 1: [6832/10940] ---- BYOL Training Loss = 0.3463578224182129
30-01-2023 05:54:31 INFO Epoch 1: [6843/10940] ---- BYOL Training Loss = 0.30912286043167114
30-01-2023 05:54:59 INFO Epoch 1: [6854/10940] ---- BYOL Training Loss = 0.3383898138999939
30-01-2023 05:55:27 INFO Epoch 1: [6865/10940] ---- BYOL Training Loss = 0.3748503029346466
30-01-2023 05:56:55 INFO Epoch 1: [6865/10940] ---- BYOL Validation Loss = 0.349118709564209
30-01-2023 05:57:23 INFO Epoch 1: [6876/10940] ---- BYOL Training Loss = 0.3948296904563904
30-01-2023 05:57:51 INFO Epoch 1: [6887/10940] ---- BYOL Training Loss = 0.428866446018219
30-01-2023 05:58:19 INFO Epoch 1: [6898/10940] ---- BYOL Training Loss = 0.420090913772583
30-01-2023 05:58:47 INFO Epoch 1: [6909/10940] ---- BYOL Training Loss = 0.40016037225723267
30-01-2023 06:00:15 INFO Epoch 1: [6909/10940] ---- BYOL Validation Loss = 0.3817419111728668
30-01-2023 06:00:44 INFO Epoch 1: [6920/10940] ---- BYOL Training Loss = 0.38832396268844604
30-01-2023 06:01:12 INFO Epoch 1: [6931/10940] ---- BYOL Training Loss = 0.35873088240623474
30-01-2023 06:01:39 INFO Epoch 1: [6942/10940] ---- BYOL Training Loss = 0.3466918170452118
30-01-2023 06:02:08 INFO Epoch 1: [6953/10940] ---- BYOL Training Loss = 0.38993513584136963
30-01-2023 06:03:36 INFO Epoch 1: [6953/10940] ---- BYOL Validation Loss = 0.4101901054382324
30-01-2023 06:04:04 INFO Epoch 1: [6964/10940] ---- BYOL Training Loss = 0.4010496735572815
30-01-2023 06:04:32 INFO Epoch 1: [6975/10940] ---- BYOL Training Loss = 0.37600308656692505
30-01-2023 06:05:00 INFO Epoch 1: [6986/10940] ---- BYOL Training Loss = 0.3264094293117523
30-01-2023 06:05:28 INFO Epoch 1: [6997/10940] ---- BYOL Training Loss = 0.38242200016975403
30-01-2023 06:06:56 INFO Epoch 1: [6997/10940] ---- BYOL Validation Loss = 0.3693971037864685
30-01-2023 06:07:24 INFO Epoch 1: [7008/10940] ---- BYOL Training Loss = 0.41075438261032104
30-01-2023 06:07:52 INFO Epoch 1: [7019/10940] ---- BYOL Training Loss = 0.4113587737083435
30-01-2023 06:08:20 INFO Epoch 1: [7030/10940] ---- BYOL Training Loss = 0.40259426832199097
30-01-2023 06:08:48 INFO Epoch 1: [7041/10940] ---- BYOL Training Loss = 0.35986125469207764
30-01-2023 06:10:16 INFO Epoch 1: [7041/10940] ---- BYOL Validation Loss = 0.3524356484413147
30-01-2023 06:10:45 INFO Epoch 1: [7052/10940] ---- BYOL Training Loss = 0.33932119607925415
30-01-2023 06:11:13 INFO Epoch 1: [7063/10940] ---- BYOL Training Loss = 0.3816852867603302
30-01-2023 06:11:41 INFO Epoch 1: [7074/10940] ---- BYOL Training Loss = 0.34713810682296753
30-01-2023 06:12:09 INFO Epoch 1: [7085/10940] ---- BYOL Training Loss = 0.3095513582229614
30-01-2023 06:13:37 INFO Epoch 1: [7085/10940] ---- BYOL Validation Loss = 0.35574719309806824
30-01-2023 06:14:05 INFO Epoch 1: [7096/10940] ---- BYOL Training Loss = 0.3313336968421936
30-01-2023 06:14:33 INFO Epoch 1: [7107/10940] ---- BYOL Training Loss = 0.3590014576911926
30-01-2023 06:15:01 INFO Epoch 1: [7118/10940] ---- BYOL Training Loss = 0.3868250250816345
30-01-2023 06:15:30 INFO Epoch 1: [7129/10940] ---- BYOL Training Loss = 0.341063529253006
30-01-2023 06:16:58 INFO Epoch 1: [7129/10940] ---- BYOL Validation Loss = 0.37797531485557556
30-01-2023 06:17:26 INFO Epoch 1: [7140/10940] ---- BYOL Training Loss = 0.34353476762771606
30-01-2023 06:17:54 INFO Epoch 1: [7151/10940] ---- BYOL Training Loss = 0.3238309621810913
30-01-2023 06:18:23 INFO Epoch 1: [7162/10940] ---- BYOL Training Loss = 0.37792110443115234
30-01-2023 06:18:51 INFO Epoch 1: [7173/10940] ---- BYOL Training Loss = 0.43506336212158203
30-01-2023 06:20:19 INFO Epoch 1: [7173/10940] ---- BYOL Validation Loss = 0.35898151993751526
30-01-2023 06:20:47 INFO Epoch 1: [7184/10940] ---- BYOL Training Loss = 0.42936626076698303
30-01-2023 06:21:16 INFO Epoch 1: [7195/10940] ---- BYOL Training Loss = 0.4099104404449463
30-01-2023 06:21:43 INFO Epoch 1: [7206/10940] ---- BYOL Training Loss = 0.4176718294620514
30-01-2023 06:22:11 INFO Epoch 1: [7217/10940] ---- BYOL Training Loss = 0.39955195784568787
30-01-2023 06:23:40 INFO Epoch 1: [7217/10940] ---- BYOL Validation Loss = 0.36385872960090637
30-01-2023 06:24:08 INFO Epoch 1: [7228/10940] ---- BYOL Training Loss = 0.3327479362487793
30-01-2023 06:24:36 INFO Epoch 1: [7239/10940] ---- BYOL Training Loss = 0.33701303601264954
30-01-2023 06:25:04 INFO Epoch 1: [7250/10940] ---- BYOL Training Loss = 0.4355933666229248
30-01-2023 06:25:32 INFO Epoch 1: [7261/10940] ---- BYOL Training Loss = 0.40998023748397827
30-01-2023 06:27:01 INFO Epoch 1: [7261/10940] ---- BYOL Validation Loss = 0.3905671536922455
30-01-2023 06:27:29 INFO Epoch 1: [7272/10940] ---- BYOL Training Loss = 0.369687020778656
30-01-2023 06:27:57 INFO Epoch 1: [7283/10940] ---- BYOL Training Loss = 0.3406434655189514
30-01-2023 06:28:25 INFO Epoch 1: [7294/10940] ---- BYOL Training Loss = 0.3455051779747009
30-01-2023 06:28:53 INFO Epoch 1: [7305/10940] ---- BYOL Training Loss = 0.42392563819885254
30-01-2023 06:30:22 INFO Epoch 1: [7305/10940] ---- BYOL Validation Loss = 0.3650267422199249
30-01-2023 06:30:50 INFO Epoch 1: [7316/10940] ---- BYOL Training Loss = 0.3625291883945465
30-01-2023 06:31:18 INFO Epoch 1: [7327/10940] ---- BYOL Training Loss = 0.35767149925231934
30-01-2023 06:31:46 INFO Epoch 1: [7338/10940] ---- BYOL Training Loss = 0.3918737769126892
30-01-2023 06:32:14 INFO Epoch 1: [7349/10940] ---- BYOL Training Loss = 0.3654864728450775
30-01-2023 06:33:43 INFO Epoch 1: [7349/10940] ---- BYOL Validation Loss = 0.3420357406139374
30-01-2023 06:34:11 INFO Epoch 1: [7360/10940] ---- BYOL Training Loss = 0.3500078320503235
30-01-2023 06:34:39 INFO Epoch 1: [7371/10940] ---- BYOL Training Loss = 0.32747307419776917
30-01-2023 06:35:07 INFO Epoch 1: [7382/10940] ---- BYOL Training Loss = 0.3566567301750183
30-01-2023 06:35:36 INFO Epoch 1: [7393/10940] ---- BYOL Training Loss = 0.3518236577510834
30-01-2023 06:37:04 INFO Epoch 1: [7393/10940] ---- BYOL Validation Loss = 0.34774938225746155
30-01-2023 06:37:32 INFO Epoch 1: [7404/10940] ---- BYOL Training Loss = 0.357648104429245
30-01-2023 06:38:00 INFO Epoch 1: [7415/10940] ---- BYOL Training Loss = 0.3203050196170807
30-01-2023 06:38:29 INFO Epoch 1: [7426/10940] ---- BYOL Training Loss = 0.2780303359031677
30-01-2023 06:38:57 INFO Epoch 1: [7437/10940] ---- BYOL Training Loss = 0.29996949434280396
30-01-2023 06:40:25 INFO Epoch 1: [7437/10940] ---- BYOL Validation Loss = 0.3529214560985565
30-01-2023 06:40:53 INFO Epoch 1: [7448/10940] ---- BYOL Training Loss = 0.34741002321243286
30-01-2023 06:41:21 INFO Epoch 1: [7459/10940] ---- BYOL Training Loss = 0.3598312735557556
30-01-2023 06:41:50 INFO Epoch 1: [7470/10940] ---- BYOL Training Loss = 0.35660475492477417
30-01-2023 06:42:18 INFO Epoch 1: [7481/10940] ---- BYOL Training Loss = 0.35100257396698
30-01-2023 06:43:46 INFO Epoch 1: [7481/10940] ---- BYOL Validation Loss = 0.33454403281211853
30-01-2023 06:44:14 INFO Epoch 1: [7492/10940] ---- BYOL Training Loss = 0.34375283122062683
30-01-2023 06:44:42 INFO Epoch 1: [7503/10940] ---- BYOL Training Loss = 0.34632408618927
30-01-2023 06:45:10 INFO Epoch 1: [7514/10940] ---- BYOL Training Loss = 0.3359985947608948
30-01-2023 06:45:39 INFO Epoch 1: [7525/10940] ---- BYOL Training Loss = 0.3829163610935211
30-01-2023 06:47:07 INFO Epoch 1: [7525/10940] ---- BYOL Validation Loss = 0.368947297334671
30-01-2023 06:47:35 INFO Epoch 1: [7536/10940] ---- BYOL Training Loss = 0.3893449902534485
30-01-2023 06:48:03 INFO Epoch 1: [7547/10940] ---- BYOL Training Loss = 0.42695754766464233
30-01-2023 06:48:32 INFO Epoch 1: [7558/10940] ---- BYOL Training Loss = 0.3924097418785095
30-01-2023 06:49:00 INFO Epoch 1: [7569/10940] ---- BYOL Training Loss = 0.3098820447921753
30-01-2023 06:50:28 INFO Epoch 1: [7569/10940] ---- BYOL Validation Loss = 0.3560302257537842
30-01-2023 06:50:56 INFO Epoch 1: [7580/10940] ---- BYOL Training Loss = 0.31804317235946655
30-01-2023 06:51:24 INFO Epoch 1: [7591/10940] ---- BYOL Training Loss = 0.3094225525856018
30-01-2023 06:51:53 INFO Epoch 1: [7602/10940] ---- BYOL Training Loss = 0.3295683264732361
30-01-2023 06:52:21 INFO Epoch 1: [7613/10940] ---- BYOL Training Loss = 0.3477628827095032
30-01-2023 06:53:49 INFO Epoch 1: [7613/10940] ---- BYOL Validation Loss = 0.34221163392066956
30-01-2023 06:54:17 INFO Epoch 1: [7624/10940] ---- BYOL Training Loss = 0.3475916087627411
30-01-2023 06:54:45 INFO Epoch 1: [7635/10940] ---- BYOL Training Loss = 0.266853004693985
30-01-2023 06:55:14 INFO Epoch 1: [7646/10940] ---- BYOL Training Loss = 0.2984718978404999
30-01-2023 06:55:42 INFO Epoch 1: [7657/10940] ---- BYOL Training Loss = 0.3145909905433655
30-01-2023 06:57:10 INFO Epoch 1: [7657/10940] ---- BYOL Validation Loss = 0.3623257279396057
30-01-2023 06:57:38 INFO Epoch 1: [7668/10940] ---- BYOL Training Loss = 0.3083720803260803
30-01-2023 06:58:07 INFO Epoch 1: [7679/10940] ---- BYOL Training Loss = 0.3633357882499695
30-01-2023 06:58:35 INFO Epoch 1: [7690/10940] ---- BYOL Training Loss = 0.4247732162475586
30-01-2023 06:59:03 INFO Epoch 1: [7701/10940] ---- BYOL Training Loss = 0.34765535593032837
30-01-2023 07:00:31 INFO Epoch 1: [7701/10940] ---- BYOL Validation Loss = 0.357706755399704
30-01-2023 07:00:59 INFO Epoch 1: [7712/10940] ---- BYOL Training Loss = 0.2805035710334778
30-01-2023 07:01:28 INFO Epoch 1: [7723/10940] ---- BYOL Training Loss = 0.34312862157821655
30-01-2023 07:01:56 INFO Epoch 1: [7734/10940] ---- BYOL Training Loss = 0.3619346022605896
30-01-2023 07:02:24 INFO Epoch 1: [7745/10940] ---- BYOL Training Loss = 0.28863996267318726
30-01-2023 07:03:52 INFO Epoch 1: [7745/10940] ---- BYOL Validation Loss = 0.3590969443321228
30-01-2023 07:04:21 INFO Epoch 1: [7756/10940] ---- BYOL Training Loss = 0.2668018043041229
30-01-2023 07:04:48 INFO Epoch 1: [7767/10940] ---- BYOL Training Loss = 0.30091050267219543
30-01-2023 07:05:17 INFO Epoch 1: [7778/10940] ---- BYOL Training Loss = 0.39446350932121277
30-01-2023 07:05:45 INFO Epoch 1: [7789/10940] ---- BYOL Training Loss = 0.4033285081386566
30-01-2023 07:07:13 INFO Epoch 1: [7789/10940] ---- BYOL Validation Loss = 0.37000754475593567
30-01-2023 07:07:41 INFO Epoch 1: [7800/10940] ---- BYOL Training Loss = 0.37361079454421997
30-01-2023 07:08:09 INFO Epoch 1: [7811/10940] ---- BYOL Training Loss = 0.3730243146419525
30-01-2023 07:08:38 INFO Epoch 1: [7822/10940] ---- BYOL Training Loss = 0.3030449151992798
30-01-2023 07:09:06 INFO Epoch 1: [7833/10940] ---- BYOL Training Loss = 0.34765446186065674
30-01-2023 07:10:34 INFO Epoch 1: [7833/10940] ---- BYOL Validation Loss = 0.3619399666786194
30-01-2023 07:11:02 INFO Epoch 1: [7844/10940] ---- BYOL Training Loss = 0.30425313115119934
30-01-2023 07:11:31 INFO Epoch 1: [7855/10940] ---- BYOL Training Loss = 0.28822019696235657
30-01-2023 07:11:59 INFO Epoch 1: [7866/10940] ---- BYOL Training Loss = 0.33272427320480347
30-01-2023 07:12:27 INFO Epoch 1: [7877/10940] ---- BYOL Training Loss = 0.3558858633041382
30-01-2023 07:13:55 INFO Epoch 1: [7877/10940] ---- BYOL Validation Loss = 0.3636457324028015
30-01-2023 07:14:24 INFO Epoch 1: [7888/10940] ---- BYOL Training Loss = 0.39609965682029724
30-01-2023 07:14:52 INFO Epoch 1: [7899/10940] ---- BYOL Training Loss = 0.41288718581199646
30-01-2023 07:15:20 INFO Epoch 1: [7910/10940] ---- BYOL Training Loss = 0.3402349054813385
30-01-2023 07:15:48 INFO Epoch 1: [7921/10940] ---- BYOL Training Loss = 0.3555510640144348
30-01-2023 07:17:16 INFO Epoch 1: [7921/10940] ---- BYOL Validation Loss = 0.36015138030052185
30-01-2023 07:17:44 INFO Epoch 1: [7932/10940] ---- BYOL Training Loss = 0.3654610812664032
30-01-2023 07:18:12 INFO Epoch 1: [7943/10940] ---- BYOL Training Loss = 0.3851381540298462
30-01-2023 07:18:41 INFO Epoch 1: [7954/10940] ---- BYOL Training Loss = 0.34547799825668335
30-01-2023 07:19:09 INFO Epoch 1: [7965/10940] ---- BYOL Training Loss = 0.33677807450294495
30-01-2023 07:20:37 INFO Epoch 1: [7965/10940] ---- BYOL Validation Loss = 0.37156805396080017
30-01-2023 07:21:05 INFO Epoch 1: [7976/10940] ---- BYOL Training Loss = 0.3438873291015625
30-01-2023 07:21:33 INFO Epoch 1: [7987/10940] ---- BYOL Training Loss = 0.33315715193748474
30-01-2023 07:22:01 INFO Epoch 1: [7998/10940] ---- BYOL Training Loss = 0.3262629508972168
30-01-2023 07:22:30 INFO Epoch 1: [8009/10940] ---- BYOL Training Loss = 0.3778400421142578
30-01-2023 07:23:58 INFO Epoch 1: [8009/10940] ---- BYOL Validation Loss = 0.3517210781574249
30-01-2023 07:24:26 INFO Epoch 1: [8020/10940] ---- BYOL Training Loss = 0.3471851348876953
30-01-2023 07:24:54 INFO Epoch 1: [8031/10940] ---- BYOL Training Loss = 0.30417555570602417
30-01-2023 07:25:23 INFO Epoch 1: [8042/10940] ---- BYOL Training Loss = 0.3092242479324341
30-01-2023 07:25:50 INFO Epoch 1: [8053/10940] ---- BYOL Training Loss = 0.2959228456020355
30-01-2023 07:27:19 INFO Epoch 1: [8053/10940] ---- BYOL Validation Loss = 0.3538517951965332
30-01-2023 07:27:47 INFO Epoch 1: [8064/10940] ---- BYOL Training Loss = 0.3475283980369568
30-01-2023 07:28:15 INFO Epoch 1: [8075/10940] ---- BYOL Training Loss = 0.3561914563179016
30-01-2023 07:28:43 INFO Epoch 1: [8086/10940] ---- BYOL Training Loss = 0.3748268783092499
30-01-2023 07:29:12 INFO Epoch 1: [8097/10940] ---- BYOL Training Loss = 0.3781813085079193
30-01-2023 07:30:40 INFO Epoch 1: [8097/10940] ---- BYOL Validation Loss = 0.36996349692344666
30-01-2023 07:31:08 INFO Epoch 1: [8108/10940] ---- BYOL Training Loss = 0.31933754682540894
30-01-2023 07:31:36 INFO Epoch 1: [8119/10940] ---- BYOL Training Loss = 0.306006520986557
30-01-2023 07:32:05 INFO Epoch 1: [8130/10940] ---- BYOL Training Loss = 0.3778640329837799
30-01-2023 07:32:33 INFO Epoch 1: [8141/10940] ---- BYOL Training Loss = 0.40743669867515564
30-01-2023 07:34:01 INFO Epoch 1: [8141/10940] ---- BYOL Validation Loss = 0.3575567901134491
30-01-2023 07:34:29 INFO Epoch 1: [8152/10940] ---- BYOL Training Loss = 0.3626566529273987
30-01-2023 07:34:57 INFO Epoch 1: [8163/10940] ---- BYOL Training Loss = 0.39929062128067017
30-01-2023 07:35:25 INFO Epoch 1: [8174/10940] ---- BYOL Training Loss = 0.37364310026168823
30-01-2023 07:35:53 INFO Epoch 1: [8185/10940] ---- BYOL Training Loss = 0.37055858969688416
30-01-2023 07:37:21 INFO Epoch 1: [8185/10940] ---- BYOL Validation Loss = 0.35484883189201355
30-01-2023 07:37:50 INFO Epoch 1: [8196/10940] ---- BYOL Training Loss = 0.29627200961112976
30-01-2023 07:38:18 INFO Epoch 1: [8207/10940] ---- BYOL Training Loss = 0.34869277477264404
30-01-2023 07:38:46 INFO Epoch 1: [8218/10940] ---- BYOL Training Loss = 0.3464207053184509
30-01-2023 07:39:14 INFO Epoch 1: [8229/10940] ---- BYOL Training Loss = 0.36483925580978394
30-01-2023 07:40:42 INFO Epoch 1: [8229/10940] ---- BYOL Validation Loss = 0.34885072708129883
30-01-2023 07:41:11 INFO Epoch 1: [8240/10940] ---- BYOL Training Loss = 0.40369826555252075
30-01-2023 07:41:39 INFO Epoch 1: [8251/10940] ---- BYOL Training Loss = 0.33517274260520935
30-01-2023 07:42:07 INFO Epoch 1: [8262/10940] ---- BYOL Training Loss = 0.32484132051467896
30-01-2023 07:42:35 INFO Epoch 1: [8273/10940] ---- BYOL Training Loss = 0.3734704554080963
30-01-2023 07:44:03 INFO Epoch 1: [8273/10940] ---- BYOL Validation Loss = 0.3690578043460846
30-01-2023 07:44:32 INFO Epoch 1: [8284/10940] ---- BYOL Training Loss = 0.3519870936870575
30-01-2023 07:45:00 INFO Epoch 1: [8295/10940] ---- BYOL Training Loss = 0.3510867953300476
30-01-2023 07:45:28 INFO Epoch 1: [8306/10940] ---- BYOL Training Loss = 0.3753899931907654
30-01-2023 07:45:56 INFO Epoch 1: [8317/10940] ---- BYOL Training Loss = 0.32031741738319397
30-01-2023 07:47:24 INFO Epoch 1: [8317/10940] ---- BYOL Validation Loss = 0.3528461456298828
30-01-2023 07:47:53 INFO Epoch 1: [8328/10940] ---- BYOL Training Loss = 0.3435923159122467
30-01-2023 07:48:21 INFO Epoch 1: [8339/10940] ---- BYOL Training Loss = 0.3385447859764099
30-01-2023 07:48:49 INFO Epoch 1: [8350/10940] ---- BYOL Training Loss = 0.31635481119155884
30-01-2023 07:49:17 INFO Epoch 1: [8361/10940] ---- BYOL Training Loss = 0.39035019278526306
30-01-2023 07:50:45 INFO Epoch 1: [8361/10940] ---- BYOL Validation Loss = 0.38112756609916687
30-01-2023 07:51:14 INFO Epoch 1: [8372/10940] ---- BYOL Training Loss = 0.4072415232658386
30-01-2023 07:51:42 INFO Epoch 1: [8383/10940] ---- BYOL Training Loss = 0.364615797996521
30-01-2023 07:52:10 INFO Epoch 1: [8394/10940] ---- BYOL Training Loss = 0.32031697034835815
30-01-2023 07:52:38 INFO Epoch 1: [8405/10940] ---- BYOL Training Loss = 0.38754913210868835
30-01-2023 07:54:07 INFO Epoch 1: [8405/10940] ---- BYOL Validation Loss = 0.36406728625297546
30-01-2023 07:54:35 INFO Epoch 1: [8416/10940] ---- BYOL Training Loss = 0.4451445937156677
30-01-2023 07:55:03 INFO Epoch 1: [8427/10940] ---- BYOL Training Loss = 0.39157676696777344
30-01-2023 07:55:31 INFO Epoch 1: [8438/10940] ---- BYOL Training Loss = 0.3156277537345886
30-01-2023 07:55:59 INFO Epoch 1: [8449/10940] ---- BYOL Training Loss = 0.361081600189209
30-01-2023 07:57:27 INFO Epoch 1: [8449/10940] ---- BYOL Validation Loss = 0.3612237572669983
30-01-2023 07:57:56 INFO Epoch 1: [8460/10940] ---- BYOL Training Loss = 0.33936530351638794
30-01-2023 07:58:24 INFO Epoch 1: [8471/10940] ---- BYOL Training Loss = 0.30219167470932007
30-01-2023 07:58:52 INFO Epoch 1: [8482/10940] ---- BYOL Training Loss = 0.3283403813838959
30-01-2023 07:59:21 INFO Epoch 1: [8493/10940] ---- BYOL Training Loss = 0.3175681233406067
30-01-2023 08:00:49 INFO Epoch 1: [8493/10940] ---- BYOL Validation Loss = 0.35801559686660767
30-01-2023 08:01:17 INFO Epoch 1: [8504/10940] ---- BYOL Training Loss = 0.29714077711105347
30-01-2023 08:01:45 INFO Epoch 1: [8515/10940] ---- BYOL Training Loss = 0.27683311700820923
30-01-2023 08:02:14 INFO Epoch 1: [8526/10940] ---- BYOL Training Loss = 0.28297412395477295
30-01-2023 08:02:42 INFO Epoch 1: [8537/10940] ---- BYOL Training Loss = 0.38073229789733887
30-01-2023 08:04:10 INFO Epoch 1: [8537/10940] ---- BYOL Validation Loss = 0.3941440284252167
30-01-2023 08:04:38 INFO Epoch 1: [8548/10940] ---- BYOL Training Loss = 0.3771643042564392
30-01-2023 08:05:06 INFO Epoch 1: [8559/10940] ---- BYOL Training Loss = 0.372101366519928
30-01-2023 08:05:34 INFO Epoch 1: [8570/10940] ---- BYOL Training Loss = 0.32638680934906006
30-01-2023 08:06:03 INFO Epoch 1: [8581/10940] ---- BYOL Training Loss = 0.31980186700820923
30-01-2023 08:07:31 INFO Epoch 1: [8581/10940] ---- BYOL Validation Loss = 0.3572517931461334
30-01-2023 08:07:59 INFO Epoch 1: [8592/10940] ---- BYOL Training Loss = 0.37230435013771057
30-01-2023 08:08:27 INFO Epoch 1: [8603/10940] ---- BYOL Training Loss = 0.36839669942855835
30-01-2023 08:08:56 INFO Epoch 1: [8614/10940] ---- BYOL Training Loss = 0.3606467843055725
30-01-2023 08:09:24 INFO Epoch 1: [8625/10940] ---- BYOL Training Loss = 0.307942658662796
30-01-2023 08:10:52 INFO Epoch 1: [8625/10940] ---- BYOL Validation Loss = 0.34959524869918823
30-01-2023 08:11:20 INFO Epoch 1: [8636/10940] ---- BYOL Training Loss = 0.37352219223976135
30-01-2023 08:11:49 INFO Epoch 1: [8647/10940] ---- BYOL Training Loss = 0.3920532464981079
30-01-2023 08:12:17 INFO Epoch 1: [8658/10940] ---- BYOL Training Loss = 0.47628650069236755
30-01-2023 08:12:45 INFO Epoch 1: [8669/10940] ---- BYOL Training Loss = 0.47867172956466675
30-01-2023 08:14:13 INFO Epoch 1: [8669/10940] ---- BYOL Validation Loss = 0.36090540885925293
30-01-2023 08:14:42 INFO Epoch 1: [8680/10940] ---- BYOL Training Loss = 0.3854425847530365
30-01-2023 08:15:10 INFO Epoch 1: [8691/10940] ---- BYOL Training Loss = 0.363571435213089
30-01-2023 08:15:38 INFO Epoch 1: [8702/10940] ---- BYOL Training Loss = 0.34700360894203186
30-01-2023 08:16:06 INFO Epoch 1: [8713/10940] ---- BYOL Training Loss = 0.327362984418869
30-01-2023 08:17:34 INFO Epoch 1: [8713/10940] ---- BYOL Validation Loss = 0.3591693937778473
30-01-2023 08:18:02 INFO Epoch 1: [8724/10940] ---- BYOL Training Loss = 0.28932812809944153
30-01-2023 08:18:31 INFO Epoch 1: [8735/10940] ---- BYOL Training Loss = 0.2851051390171051
30-01-2023 08:18:59 INFO Epoch 1: [8746/10940] ---- BYOL Training Loss = 0.30083754658699036
30-01-2023 08:19:28 INFO Epoch 1: [8757/10940] ---- BYOL Training Loss = 0.2914919853210449
30-01-2023 08:20:56 INFO Epoch 1: [8757/10940] ---- BYOL Validation Loss = 0.3395855128765106
30-01-2023 08:21:24 INFO Epoch 1: [8768/10940] ---- BYOL Training Loss = 0.30989527702331543
30-01-2023 08:21:52 INFO Epoch 1: [8779/10940] ---- BYOL Training Loss = 0.3337835669517517
30-01-2023 08:22:20 INFO Epoch 1: [8790/10940] ---- BYOL Training Loss = 0.3144795894622803
30-01-2023 08:22:49 INFO Epoch 1: [8801/10940] ---- BYOL Training Loss = 0.3266686499118805
30-01-2023 08:24:17 INFO Epoch 1: [8801/10940] ---- BYOL Validation Loss = 0.3624175488948822
30-01-2023 08:24:45 INFO Epoch 1: [8812/10940] ---- BYOL Training Loss = 0.3324870765209198
30-01-2023 08:25:13 INFO Epoch 1: [8823/10940] ---- BYOL Training Loss = 0.3434675633907318
30-01-2023 08:25:41 INFO Epoch 1: [8834/10940] ---- BYOL Training Loss = 0.396441787481308
30-01-2023 08:26:10 INFO Epoch 1: [8845/10940] ---- BYOL Training Loss = 0.3794228136539459
30-01-2023 08:27:38 INFO Epoch 1: [8845/10940] ---- BYOL Validation Loss = 1.0286811590194702
30-01-2023 08:28:06 INFO Epoch 1: [8856/10940] ---- BYOL Training Loss = 0.36289453506469727
30-01-2023 08:28:34 INFO Epoch 1: [8867/10940] ---- BYOL Training Loss = 0.3317362368106842
30-01-2023 08:29:03 INFO Epoch 1: [8878/10940] ---- BYOL Training Loss = 0.3914983868598938
30-01-2023 08:29:31 INFO Epoch 1: [8889/10940] ---- BYOL Training Loss = 0.42251092195510864
30-01-2023 08:30:59 INFO Epoch 1: [8889/10940] ---- BYOL Validation Loss = 0.34799936413764954
30-01-2023 08:31:28 INFO Epoch 1: [8900/10940] ---- BYOL Training Loss = 0.4277670383453369
30-01-2023 08:31:56 INFO Epoch 1: [8911/10940] ---- BYOL Training Loss = 0.42728495597839355
30-01-2023 08:32:24 INFO Epoch 1: [8922/10940] ---- BYOL Training Loss = 0.4433714747428894
30-01-2023 08:32:52 INFO Epoch 1: [8933/10940] ---- BYOL Training Loss = 0.4089142680168152
30-01-2023 08:34:20 INFO Epoch 1: [8933/10940] ---- BYOL Validation Loss = 0.3486361503601074
30-01-2023 08:34:49 INFO Epoch 1: [8944/10940] ---- BYOL Training Loss = 0.35689741373062134
30-01-2023 08:35:17 INFO Epoch 1: [8955/10940] ---- BYOL Training Loss = 0.30997806787490845
30-01-2023 08:35:45 INFO Epoch 1: [8966/10940] ---- BYOL Training Loss = 0.3161192536354065
30-01-2023 08:36:13 INFO Epoch 1: [8977/10940] ---- BYOL Training Loss = 0.34570443630218506
30-01-2023 08:37:42 INFO Epoch 1: [8977/10940] ---- BYOL Validation Loss = 0.3528171181678772
30-01-2023 08:38:10 INFO Epoch 1: [8988/10940] ---- BYOL Training Loss = 0.36632099747657776
30-01-2023 08:38:39 INFO Epoch 1: [8999/10940] ---- BYOL Training Loss = 0.3641999363899231
30-01-2023 08:39:07 INFO Epoch 1: [9010/10940] ---- BYOL Training Loss = 0.34235894680023193
30-01-2023 08:39:35 INFO Epoch 1: [9021/10940] ---- BYOL Training Loss = 0.32780566811561584
30-01-2023 08:41:03 INFO Epoch 1: [9021/10940] ---- BYOL Validation Loss = 0.34726935625076294
30-01-2023 08:41:32 INFO Epoch 1: [9032/10940] ---- BYOL Training Loss = 0.3434794247150421
30-01-2023 08:42:00 INFO Epoch 1: [9043/10940] ---- BYOL Training Loss = 0.34678107500076294
30-01-2023 08:42:28 INFO Epoch 1: [9054/10940] ---- BYOL Training Loss = 0.28445228934288025
30-01-2023 08:42:56 INFO Epoch 1: [9065/10940] ---- BYOL Training Loss = 0.2841491103172302
30-01-2023 08:44:25 INFO Epoch 1: [9065/10940] ---- BYOL Validation Loss = 0.33192792534828186
30-01-2023 08:44:53 INFO Epoch 1: [9076/10940] ---- BYOL Training Loss = 0.32915931940078735
30-01-2023 08:45:21 INFO Epoch 1: [9087/10940] ---- BYOL Training Loss = 0.32599741220474243
30-01-2023 08:45:50 INFO Epoch 1: [9098/10940] ---- BYOL Training Loss = 0.31423836946487427
30-01-2023 08:46:18 INFO Epoch 1: [9109/10940] ---- BYOL Training Loss = 0.32882970571517944
30-01-2023 08:47:46 INFO Epoch 1: [9109/10940] ---- BYOL Validation Loss = 0.3540727198123932
30-01-2023 08:48:14 INFO Epoch 1: [9120/10940] ---- BYOL Training Loss = 0.35137972235679626
30-01-2023 08:48:43 INFO Epoch 1: [9131/10940] ---- BYOL Training Loss = 0.3747432231903076
30-01-2023 08:49:11 INFO Epoch 1: [9142/10940] ---- BYOL Training Loss = 0.38069581985473633
30-01-2023 08:49:39 INFO Epoch 1: [9153/10940] ---- BYOL Training Loss = 0.3604555130004883
30-01-2023 08:51:08 INFO Epoch 1: [9153/10940] ---- BYOL Validation Loss = 0.3393271863460541
30-01-2023 08:51:36 INFO Epoch 1: [9164/10940] ---- BYOL Training Loss = 0.34598949551582336
30-01-2023 08:52:04 INFO Epoch 1: [9175/10940] ---- BYOL Training Loss = 0.3745766282081604
30-01-2023 08:52:32 INFO Epoch 1: [9186/10940] ---- BYOL Training Loss = 0.3094378113746643
30-01-2023 08:53:01 INFO Epoch 1: [9197/10940] ---- BYOL Training Loss = 0.3475199341773987
30-01-2023 08:54:29 INFO Epoch 1: [9197/10940] ---- BYOL Validation Loss = 0.3472311496734619
30-01-2023 08:54:57 INFO Epoch 1: [9208/10940] ---- BYOL Training Loss = 0.3975748121738434
30-01-2023 08:55:26 INFO Epoch 1: [9219/10940] ---- BYOL Training Loss = 0.27454420924186707
30-01-2023 08:55:54 INFO Epoch 1: [9230/10940] ---- BYOL Training Loss = 0.32134413719177246
30-01-2023 08:56:23 INFO Epoch 1: [9241/10940] ---- BYOL Training Loss = 0.3233596682548523
30-01-2023 08:57:51 INFO Epoch 1: [9241/10940] ---- BYOL Validation Loss = 0.35387369990348816
30-01-2023 08:58:19 INFO Epoch 1: [9252/10940] ---- BYOL Training Loss = 0.2798604965209961
30-01-2023 08:58:47 INFO Epoch 1: [9263/10940] ---- BYOL Training Loss = 0.3598611652851105
30-01-2023 08:59:16 INFO Epoch 1: [9274/10940] ---- BYOL Training Loss = 0.39709538221359253
30-01-2023 08:59:44 INFO Epoch 1: [9285/10940] ---- BYOL Training Loss = 0.3121037185192108
30-01-2023 09:01:12 INFO Epoch 1: [9285/10940] ---- BYOL Validation Loss = 0.33770179748535156
30-01-2023 09:01:41 INFO Epoch 1: [9296/10940] ---- BYOL Training Loss = 0.3341202139854431
30-01-2023 09:02:09 INFO Epoch 1: [9307/10940] ---- BYOL Training Loss = 0.39701536297798157
30-01-2023 09:02:37 INFO Epoch 1: [9318/10940] ---- BYOL Training Loss = 0.4105442464351654
30-01-2023 09:03:06 INFO Epoch 1: [9329/10940] ---- BYOL Training Loss = 0.3574492335319519
30-01-2023 09:04:34 INFO Epoch 1: [9329/10940] ---- BYOL Validation Loss = 0.3335101306438446
30-01-2023 09:05:02 INFO Epoch 1: [9340/10940] ---- BYOL Training Loss = 0.36459091305732727
30-01-2023 09:05:31 INFO Epoch 1: [9351/10940] ---- BYOL Training Loss = 0.33168965578079224
30-01-2023 09:05:59 INFO Epoch 1: [9362/10940] ---- BYOL Training Loss = 0.31799089908599854
30-01-2023 09:06:27 INFO Epoch 1: [9373/10940] ---- BYOL Training Loss = 0.32363495230674744
30-01-2023 09:07:56 INFO Epoch 1: [9373/10940] ---- BYOL Validation Loss = 0.32979655265808105
30-01-2023 09:08:24 INFO Epoch 1: [9384/10940] ---- BYOL Training Loss = 0.3369746804237366
30-01-2023 09:08:52 INFO Epoch 1: [9395/10940] ---- BYOL Training Loss = 0.3624856770038605
30-01-2023 09:09:20 INFO Epoch 1: [9406/10940] ---- BYOL Training Loss = 0.38474076986312866
30-01-2023 09:09:49 INFO Epoch 1: [9417/10940] ---- BYOL Training Loss = 0.36960476636886597
30-01-2023 09:11:17 INFO Epoch 1: [9417/10940] ---- BYOL Validation Loss = 0.3539707660675049
30-01-2023 09:11:45 INFO Epoch 1: [9428/10940] ---- BYOL Training Loss = 0.3579600155353546
30-01-2023 09:12:13 INFO Epoch 1: [9439/10940] ---- BYOL Training Loss = 0.34570735692977905
30-01-2023 09:12:42 INFO Epoch 1: [9450/10940] ---- BYOL Training Loss = 0.34396418929100037
30-01-2023 09:13:10 INFO Epoch 1: [9461/10940] ---- BYOL Training Loss = 0.3346002697944641
30-01-2023 09:14:39 INFO Epoch 1: [9461/10940] ---- BYOL Validation Loss = 0.34398260712623596
30-01-2023 09:15:07 INFO Epoch 1: [9472/10940] ---- BYOL Training Loss = 0.3506757616996765
30-01-2023 09:15:36 INFO Epoch 1: [9483/10940] ---- BYOL Training Loss = 0.37354978919029236
30-01-2023 09:16:04 INFO Epoch 1: [9494/10940] ---- BYOL Training Loss = 0.38395318388938904
30-01-2023 09:16:32 INFO Epoch 1: [9505/10940] ---- BYOL Training Loss = 0.3972606062889099
30-01-2023 09:18:00 INFO Epoch 1: [9505/10940] ---- BYOL Validation Loss = 0.3279303014278412
30-01-2023 09:18:29 INFO Epoch 1: [9516/10940] ---- BYOL Training Loss = 0.3372412919998169
30-01-2023 09:18:57 INFO Epoch 1: [9527/10940] ---- BYOL Training Loss = 0.3167631924152374
30-01-2023 09:19:25 INFO Epoch 1: [9538/10940] ---- BYOL Training Loss = 0.3070428967475891
30-01-2023 09:19:54 INFO Epoch 1: [9549/10940] ---- BYOL Training Loss = 0.3179931640625
30-01-2023 09:21:22 INFO Epoch 1: [9549/10940] ---- BYOL Validation Loss = 0.34621238708496094
30-01-2023 09:21:50 INFO Epoch 1: [9560/10940] ---- BYOL Training Loss = 0.3425920605659485
30-01-2023 09:22:18 INFO Epoch 1: [9571/10940] ---- BYOL Training Loss = 0.3701699376106262
30-01-2023 09:22:47 INFO Epoch 1: [9582/10940] ---- BYOL Training Loss = 0.3568161129951477
30-01-2023 09:23:15 INFO Epoch 1: [9593/10940] ---- BYOL Training Loss = 0.3857443928718567
30-01-2023 09:24:43 INFO Epoch 1: [9593/10940] ---- BYOL Validation Loss = 0.32750770449638367
30-01-2023 09:25:12 INFO Epoch 1: [9604/10940] ---- BYOL Training Loss = 0.3210589289665222
30-01-2023 09:25:40 INFO Epoch 1: [9615/10940] ---- BYOL Training Loss = 0.2872920036315918
30-01-2023 09:26:09 INFO Epoch 1: [9626/10940] ---- BYOL Training Loss = 0.2985725998878479
30-01-2023 09:26:37 INFO Epoch 1: [9637/10940] ---- BYOL Training Loss = 0.31369566917419434
30-01-2023 09:28:05 INFO Epoch 1: [9637/10940] ---- BYOL Validation Loss = 0.32369449734687805
30-01-2023 09:28:34 INFO Epoch 1: [9648/10940] ---- BYOL Training Loss = 0.2842497229576111
30-01-2023 09:29:02 INFO Epoch 1: [9659/10940] ---- BYOL Training Loss = 0.31506773829460144
30-01-2023 09:29:30 INFO Epoch 1: [9670/10940] ---- BYOL Training Loss = 0.28607240319252014
30-01-2023 09:29:59 INFO Epoch 1: [9681/10940] ---- BYOL Training Loss = 0.25307056307792664
30-01-2023 09:31:27 INFO Epoch 1: [9681/10940] ---- BYOL Validation Loss = 0.32524463534355164
30-01-2023 09:31:55 INFO Epoch 1: [9692/10940] ---- BYOL Training Loss = 0.27384501695632935
30-01-2023 09:32:24 INFO Epoch 1: [9703/10940] ---- BYOL Training Loss = 0.28336119651794434
30-01-2023 09:32:52 INFO Epoch 1: [9714/10940] ---- BYOL Training Loss = 0.2781398892402649
30-01-2023 09:33:21 INFO Epoch 1: [9725/10940] ---- BYOL Training Loss = 0.3549996018409729
30-01-2023 09:34:49 INFO Epoch 1: [9725/10940] ---- BYOL Validation Loss = 0.34503820538520813
30-01-2023 09:35:17 INFO Epoch 1: [9736/10940] ---- BYOL Training Loss = 0.39167022705078125
30-01-2023 09:35:45 INFO Epoch 1: [9747/10940] ---- BYOL Training Loss = 0.3307250738143921
30-01-2023 09:36:14 INFO Epoch 1: [9758/10940] ---- BYOL Training Loss = 0.30311381816864014
30-01-2023 09:36:42 INFO Epoch 1: [9769/10940] ---- BYOL Training Loss = 0.2920387387275696
30-01-2023 09:38:11 INFO Epoch 1: [9769/10940] ---- BYOL Validation Loss = 0.3366968035697937
30-01-2023 09:38:39 INFO Epoch 1: [9780/10940] ---- BYOL Training Loss = 0.27428460121154785
30-01-2023 09:39:08 INFO Epoch 1: [9791/10940] ---- BYOL Training Loss = 0.2824544310569763
30-01-2023 09:39:36 INFO Epoch 1: [9802/10940] ---- BYOL Training Loss = 0.3838910460472107
30-01-2023 09:40:04 INFO Epoch 1: [9813/10940] ---- BYOL Training Loss = 0.39835110306739807
30-01-2023 09:41:33 INFO Epoch 1: [9813/10940] ---- BYOL Validation Loss = 0.3496880531311035
30-01-2023 09:42:01 INFO Epoch 1: [9824/10940] ---- BYOL Training Loss = 0.35462239384651184
30-01-2023 09:42:29 INFO Epoch 1: [9835/10940] ---- BYOL Training Loss = 0.32613521814346313
30-01-2023 09:42:58 INFO Epoch 1: [9846/10940] ---- BYOL Training Loss = 0.29810070991516113
30-01-2023 09:43:26 INFO Epoch 1: [9857/10940] ---- BYOL Training Loss = 0.30264389514923096
30-01-2023 09:44:54 INFO Epoch 1: [9857/10940] ---- BYOL Validation Loss = 0.3363918662071228
30-01-2023 09:45:23 INFO Epoch 1: [9868/10940] ---- BYOL Training Loss = 0.30325862765312195
30-01-2023 09:45:51 INFO Epoch 1: [9879/10940] ---- BYOL Training Loss = 0.3021555542945862
30-01-2023 09:46:20 INFO Epoch 1: [9890/10940] ---- BYOL Training Loss = 0.30216026306152344
30-01-2023 09:46:48 INFO Epoch 1: [9901/10940] ---- BYOL Training Loss = 0.34137314558029175
30-01-2023 09:48:16 INFO Epoch 1: [9901/10940] ---- BYOL Validation Loss = 0.31006017327308655
30-01-2023 09:48:45 INFO Epoch 1: [9912/10940] ---- BYOL Training Loss = 0.30433136224746704
30-01-2023 09:49:13 INFO Epoch 1: [9923/10940] ---- BYOL Training Loss = 0.2564413547515869
30-01-2023 09:49:41 INFO Epoch 1: [9934/10940] ---- BYOL Training Loss = 0.29244285821914673
30-01-2023 09:50:10 INFO Epoch 1: [9945/10940] ---- BYOL Training Loss = 0.3666374087333679
30-01-2023 09:51:38 INFO Epoch 1: [9945/10940] ---- BYOL Validation Loss = 0.3520703911781311
30-01-2023 09:52:06 INFO Epoch 1: [9956/10940] ---- BYOL Training Loss = 0.3713472783565521
30-01-2023 09:52:35 INFO Epoch 1: [9967/10940] ---- BYOL Training Loss = 0.29325345158576965
30-01-2023 09:53:03 INFO Epoch 1: [9978/10940] ---- BYOL Training Loss = 0.30826336145401
30-01-2023 09:53:32 INFO Epoch 1: [9989/10940] ---- BYOL Training Loss = 0.29829496145248413
30-01-2023 09:55:00 INFO Epoch 1: [9989/10940] ---- BYOL Validation Loss = 0.3321281969547272
30-01-2023 09:55:29 INFO Epoch 1: [10000/10940] ---- BYOL Training Loss = 0.3148357570171356
30-01-2023 09:55:57 INFO Epoch 1: [10011/10940] ---- BYOL Training Loss = 0.3779473602771759
30-01-2023 09:56:25 INFO Epoch 1: [10022/10940] ---- BYOL Training Loss = 0.41767391562461853
30-01-2023 09:56:54 INFO Epoch 1: [10033/10940] ---- BYOL Training Loss = 0.37144923210144043
30-01-2023 09:58:22 INFO Epoch 1: [10033/10940] ---- BYOL Validation Loss = 0.3417731821537018
30-01-2023 09:58:51 INFO Epoch 1: [10044/10940] ---- BYOL Training Loss = 0.3608563542366028
30-01-2023 09:59:19 INFO Epoch 1: [10055/10940] ---- BYOL Training Loss = 0.3687923848628998
30-01-2023 09:59:47 INFO Epoch 1: [10066/10940] ---- BYOL Training Loss = 0.32747071981430054
30-01-2023 10:00:16 INFO Epoch 1: [10077/10940] ---- BYOL Training Loss = 0.37341582775115967
30-01-2023 10:01:44 INFO Epoch 1: [10077/10940] ---- BYOL Validation Loss = 0.3365790843963623
30-01-2023 10:02:12 INFO Epoch 1: [10088/10940] ---- BYOL Training Loss = 0.3453613817691803
30-01-2023 10:02:41 INFO Epoch 1: [10099/10940] ---- BYOL Training Loss = 0.31061965227127075
30-01-2023 10:03:09 INFO Epoch 1: [10110/10940] ---- BYOL Training Loss = 0.3183665871620178
30-01-2023 10:03:38 INFO Epoch 1: [10121/10940] ---- BYOL Training Loss = 0.3081319332122803
30-01-2023 10:05:06 INFO Epoch 1: [10121/10940] ---- BYOL Validation Loss = 0.3390483260154724
30-01-2023 10:05:34 INFO Epoch 1: [10132/10940] ---- BYOL Training Loss = 0.3450489640235901
30-01-2023 10:06:03 INFO Epoch 1: [10143/10940] ---- BYOL Training Loss = 0.4042726457118988
30-01-2023 10:06:31 INFO Epoch 1: [10154/10940] ---- BYOL Training Loss = 0.3140450716018677
30-01-2023 10:06:59 INFO Epoch 1: [10165/10940] ---- BYOL Training Loss = 0.2608339190483093
30-01-2023 10:08:27 INFO Epoch 1: [10165/10940] ---- BYOL Validation Loss = 0.33384838700294495
30-01-2023 10:08:56 INFO Epoch 1: [10176/10940] ---- BYOL Training Loss = 0.28198522329330444
30-01-2023 10:09:24 INFO Epoch 1: [10187/10940] ---- BYOL Training Loss = 0.29758602380752563
30-01-2023 10:09:53 INFO Epoch 1: [10198/10940] ---- BYOL Training Loss = 0.3662251830101013
30-01-2023 10:10:21 INFO Epoch 1: [10209/10940] ---- BYOL Training Loss = 0.4023568630218506
30-01-2023 10:11:49 INFO Epoch 1: [10209/10940] ---- BYOL Validation Loss = 0.35129961371421814
30-01-2023 10:12:17 INFO Epoch 1: [10220/10940] ---- BYOL Training Loss = 0.35777175426483154
30-01-2023 10:12:46 INFO Epoch 1: [10231/10940] ---- BYOL Training Loss = 0.33742040395736694
30-01-2023 10:13:14 INFO Epoch 1: [10242/10940] ---- BYOL Training Loss = 0.31800633668899536
30-01-2023 10:13:43 INFO Epoch 1: [10253/10940] ---- BYOL Training Loss = 0.3169862627983093
30-01-2023 10:15:11 INFO Epoch 1: [10253/10940] ---- BYOL Validation Loss = 0.33318158984184265
30-01-2023 10:15:39 INFO Epoch 1: [10264/10940] ---- BYOL Training Loss = 0.33447593450546265
30-01-2023 10:16:08 INFO Epoch 1: [10275/10940] ---- BYOL Training Loss = 0.3419419825077057
30-01-2023 10:16:36 INFO Epoch 1: [10286/10940] ---- BYOL Training Loss = 0.29801326990127563
30-01-2023 10:17:04 INFO Epoch 1: [10297/10940] ---- BYOL Training Loss = 0.29525333642959595
30-01-2023 10:18:32 INFO Epoch 1: [10297/10940] ---- BYOL Validation Loss = 0.3301292061805725
30-01-2023 10:19:01 INFO Epoch 1: [10308/10940] ---- BYOL Training Loss = 0.4134807586669922
30-01-2023 10:19:29 INFO Epoch 1: [10319/10940] ---- BYOL Training Loss = 0.3769895136356354
30-01-2023 10:19:58 INFO Epoch 1: [10330/10940] ---- BYOL Training Loss = 0.2985714077949524
30-01-2023 10:20:26 INFO Epoch 1: [10341/10940] ---- BYOL Training Loss = 0.29476863145828247
30-01-2023 10:21:54 INFO Epoch 1: [10341/10940] ---- BYOL Validation Loss = 0.325164258480072
30-01-2023 10:22:23 INFO Epoch 1: [10352/10940] ---- BYOL Training Loss = 0.2793823182582855
30-01-2023 10:22:51 INFO Epoch 1: [10363/10940] ---- BYOL Training Loss = 0.29486510157585144
30-01-2023 10:23:19 INFO Epoch 1: [10374/10940] ---- BYOL Training Loss = 0.3550121784210205
30-01-2023 10:23:48 INFO Epoch 1: [10385/10940] ---- BYOL Training Loss = 0.33327716588974
30-01-2023 10:25:16 INFO Epoch 1: [10385/10940] ---- BYOL Validation Loss = 0.34359925985336304
30-01-2023 10:25:44 INFO Epoch 1: [10396/10940] ---- BYOL Training Loss = 0.3000572919845581
30-01-2023 10:26:13 INFO Epoch 1: [10407/10940] ---- BYOL Training Loss = 0.3043944239616394
30-01-2023 10:26:41 INFO Epoch 1: [10418/10940] ---- BYOL Training Loss = 0.27306848764419556
30-01-2023 10:27:10 INFO Epoch 1: [10429/10940] ---- BYOL Training Loss = 0.3725655674934387
30-01-2023 10:28:38 INFO Epoch 1: [10429/10940] ---- BYOL Validation Loss = 0.33452683687210083
30-01-2023 10:29:07 INFO Epoch 1: [10440/10940] ---- BYOL Training Loss = 0.40019693970680237
30-01-2023 10:29:35 INFO Epoch 1: [10451/10940] ---- BYOL Training Loss = 0.33004289865493774
30-01-2023 10:30:04 INFO Epoch 1: [10462/10940] ---- BYOL Training Loss = 0.3215501606464386
30-01-2023 10:30:32 INFO Epoch 1: [10473/10940] ---- BYOL Training Loss = 0.32406729459762573
30-01-2023 10:32:00 INFO Epoch 1: [10473/10940] ---- BYOL Validation Loss = 3.095444917678833
30-01-2023 10:32:29 INFO Epoch 1: [10484/10940] ---- BYOL Training Loss = 0.3159402012825012
30-01-2023 10:32:57 INFO Epoch 1: [10495/10940] ---- BYOL Training Loss = 0.27661383152008057
30-01-2023 10:33:26 INFO Epoch 1: [10506/10940] ---- BYOL Training Loss = 0.30019229650497437
30-01-2023 10:33:54 INFO Epoch 1: [10517/10940] ---- BYOL Training Loss = 0.27601462602615356
30-01-2023 10:35:22 INFO Epoch 1: [10517/10940] ---- BYOL Validation Loss = 2.279266357421875
30-01-2023 10:35:51 INFO Epoch 1: [10528/10940] ---- BYOL Training Loss = 0.25721150636672974
30-01-2023 10:36:19 INFO Epoch 1: [10539/10940] ---- BYOL Training Loss = 0.25174790620803833
30-01-2023 10:36:47 INFO Epoch 1: [10550/10940] ---- BYOL Training Loss = 0.30033406615257263
30-01-2023 10:37:16 INFO Epoch 1: [10561/10940] ---- BYOL Training Loss = 0.3576965928077698
30-01-2023 10:38:44 INFO Epoch 1: [10561/10940] ---- BYOL Validation Loss = 0.31783077120780945
30-01-2023 10:39:12 INFO Epoch 1: [10572/10940] ---- BYOL Training Loss = 0.3423198461532593
30-01-2023 10:39:41 INFO Epoch 1: [10583/10940] ---- BYOL Training Loss = 0.30050361156463623
30-01-2023 10:40:09 INFO Epoch 1: [10594/10940] ---- BYOL Training Loss = 0.3320821523666382
30-01-2023 10:40:38 INFO Epoch 1: [10605/10940] ---- BYOL Training Loss = 0.3054317533969879
30-01-2023 10:42:06 INFO Epoch 1: [10605/10940] ---- BYOL Validation Loss = 0.3366015553474426
30-01-2023 10:42:34 INFO Epoch 1: [10616/10940] ---- BYOL Training Loss = 0.26432833075523376
30-01-2023 10:43:03 INFO Epoch 1: [10627/10940] ---- BYOL Training Loss = 0.2788826823234558
30-01-2023 10:43:31 INFO Epoch 1: [10638/10940] ---- BYOL Training Loss = 0.3029302656650543
30-01-2023 10:43:59 INFO Epoch 1: [10649/10940] ---- BYOL Training Loss = 0.2752990126609802
30-01-2023 10:45:28 INFO Epoch 1: [10649/10940] ---- BYOL Validation Loss = 0.32931846380233765
30-01-2023 10:45:56 INFO Epoch 1: [10660/10940] ---- BYOL Training Loss = 0.3517455458641052
30-01-2023 10:46:25 INFO Epoch 1: [10671/10940] ---- BYOL Training Loss = 0.34348824620246887
30-01-2023 10:46:53 INFO Epoch 1: [10682/10940] ---- BYOL Training Loss = 0.28704094886779785
30-01-2023 10:47:22 INFO Epoch 1: [10693/10940] ---- BYOL Training Loss = 0.3117307424545288
30-01-2023 10:48:50 INFO Epoch 1: [10693/10940] ---- BYOL Validation Loss = 0.3377925455570221
30-01-2023 10:49:18 INFO Epoch 1: [10704/10940] ---- BYOL Training Loss = 0.2945931553840637
30-01-2023 10:49:47 INFO Epoch 1: [10715/10940] ---- BYOL Training Loss = 0.3028714060783386
30-01-2023 10:50:15 INFO Epoch 1: [10726/10940] ---- BYOL Training Loss = 0.2768125534057617
30-01-2023 10:50:44 INFO Epoch 1: [10737/10940] ---- BYOL Training Loss = 0.3091598451137543
30-01-2023 10:52:12 INFO Epoch 1: [10737/10940] ---- BYOL Validation Loss = 0.3972051441669464
30-01-2023 10:52:40 INFO Epoch 1: [10748/10940] ---- BYOL Training Loss = 0.3645302355289459
30-01-2023 10:53:09 INFO Epoch 1: [10759/10940] ---- BYOL Training Loss = 0.35629329085350037
30-01-2023 10:53:37 INFO Epoch 1: [10770/10940] ---- BYOL Training Loss = 0.31193214654922485
30-01-2023 10:54:06 INFO Epoch 1: [10781/10940] ---- BYOL Training Loss = 0.3889091908931732
30-01-2023 10:55:34 INFO Epoch 1: [10781/10940] ---- BYOL Validation Loss = 0.3501591980457306
30-01-2023 10:56:03 INFO Epoch 1: [10792/10940] ---- BYOL Training Loss = 0.39506998658180237
30-01-2023 10:56:31 INFO Epoch 1: [10803/10940] ---- BYOL Training Loss = 0.3380448818206787
30-01-2023 10:56:59 INFO Epoch 1: [10814/10940] ---- BYOL Training Loss = 0.30105745792388916
30-01-2023 10:57:28 INFO Epoch 1: [10825/10940] ---- BYOL Training Loss = 0.3666846454143524
30-01-2023 10:58:56 INFO Epoch 1: [10825/10940] ---- BYOL Validation Loss = 0.3383408188819885
30-01-2023 10:59:25 INFO Epoch 1: [10836/10940] ---- BYOL Training Loss = 0.3389052450656891
30-01-2023 10:59:53 INFO Epoch 1: [10847/10940] ---- BYOL Training Loss = 0.29444923996925354
30-01-2023 11:00:22 INFO Epoch 1: [10858/10940] ---- BYOL Training Loss = 0.29263877868652344
30-01-2023 11:00:50 INFO Epoch 1: [10869/10940] ---- BYOL Training Loss = 0.2643854022026062
30-01-2023 11:02:18 INFO Epoch 1: [10869/10940] ---- BYOL Validation Loss = 0.33478909730911255
30-01-2023 11:02:47 INFO Epoch 1: [10880/10940] ---- BYOL Training Loss = 0.28761258721351624
30-01-2023 11:03:15 INFO Epoch 1: [10891/10940] ---- BYOL Training Loss = 0.29134976863861084
30-01-2023 11:03:44 INFO Epoch 1: [10902/10940] ---- BYOL Training Loss = 0.28210288286209106
30-01-2023 11:04:12 INFO Epoch 1: [10913/10940] ---- BYOL Training Loss = 0.2856363356113434
30-01-2023 11:05:40 INFO Epoch 1: [10913/10940] ---- BYOL Validation Loss = 0.3459348678588867
30-01-2023 11:06:09 INFO Epoch 1: [10924/10940] ---- BYOL Training Loss = 0.3357399106025696
30-01-2023 11:06:37 INFO Epoch 1: [10935/10940] ---- BYOL Training Loss = 0.3268909156322479
30-01-2023 11:06:51 INFO Starting Epoch: 2
30-01-2023 11:07:19 INFO Epoch 2: [12/10940] ---- BYOL Training Loss = 0.2974322438240051
30-01-2023 11:07:46 INFO Epoch 2: [23/10940] ---- BYOL Training Loss = 0.28209933638572693
30-01-2023 11:08:14 INFO Epoch 2: [34/10940] ---- BYOL Training Loss = 0.2816317677497864
30-01-2023 11:08:41 INFO Epoch 2: [45/10940] ---- BYOL Training Loss = 0.3270367681980133
30-01-2023 11:10:09 INFO Epoch 2: [45/10940] ---- BYOL Validation Loss = 0.3145691454410553
30-01-2023 11:10:36 INFO Epoch 2: [56/10940] ---- BYOL Training Loss = 0.38444191217422485
30-01-2023 11:11:04 INFO Epoch 2: [67/10940] ---- BYOL Training Loss = 0.33254820108413696
30-01-2023 11:11:31 INFO Epoch 2: [78/10940] ---- BYOL Training Loss = 0.27587297558784485
30-01-2023 11:11:58 INFO Epoch 2: [89/10940] ---- BYOL Training Loss = 0.2597940266132355
30-01-2023 11:13:27 INFO Epoch 2: [89/10940] ---- BYOL Validation Loss = 0.329680860042572
30-01-2023 11:13:54 INFO Epoch 2: [100/10940] ---- BYOL Training Loss = 0.29388749599456787
30-01-2023 11:14:21 INFO Epoch 2: [111/10940] ---- BYOL Training Loss = 0.3031274378299713
30-01-2023 11:14:49 INFO Epoch 2: [122/10940] ---- BYOL Training Loss = 0.33255821466445923
30-01-2023 11:15:16 INFO Epoch 2: [133/10940] ---- BYOL Training Loss = 0.32245197892189026
30-01-2023 11:16:45 INFO Epoch 2: [133/10940] ---- BYOL Validation Loss = 0.3463076055049896
30-01-2023 11:17:12 INFO Epoch 2: [144/10940] ---- BYOL Training Loss = 0.3287945091724396
30-01-2023 11:17:39 INFO Epoch 2: [155/10940] ---- BYOL Training Loss = 0.32420095801353455
30-01-2023 11:18:06 INFO Epoch 2: [166/10940] ---- BYOL Training Loss = 0.3316919207572937
30-01-2023 11:18:34 INFO Epoch 2: [177/10940] ---- BYOL Training Loss = 0.348287969827652
30-01-2023 11:20:02 INFO Epoch 2: [177/10940] ---- BYOL Validation Loss = 0.3192293345928192
30-01-2023 11:20:30 INFO Epoch 2: [188/10940] ---- BYOL Training Loss = 0.27206382155418396
30-01-2023 11:20:57 INFO Epoch 2: [199/10940] ---- BYOL Training Loss = 0.276242196559906
30-01-2023 11:21:25 INFO Epoch 2: [210/10940] ---- BYOL Training Loss = 0.3322022557258606
30-01-2023 11:21:52 INFO Epoch 2: [221/10940] ---- BYOL Training Loss = 0.3385177254676819
30-01-2023 11:23:20 INFO Epoch 2: [221/10940] ---- BYOL Validation Loss = 0.31706878542900085
30-01-2023 11:23:48 INFO Epoch 2: [232/10940] ---- BYOL Training Loss = 0.33149415254592896
30-01-2023 11:24:15 INFO Epoch 2: [243/10940] ---- BYOL Training Loss = 0.34390926361083984
30-01-2023 11:24:43 INFO Epoch 2: [254/10940] ---- BYOL Training Loss = 0.34529465436935425
30-01-2023 11:25:10 INFO Epoch 2: [265/10940] ---- BYOL Training Loss = 0.35629186034202576
30-01-2023 11:26:38 INFO Epoch 2: [265/10940] ---- BYOL Validation Loss = 0.33801862597465515
30-01-2023 11:27:06 INFO Epoch 2: [276/10940] ---- BYOL Training Loss = 0.3424360156059265
30-01-2023 11:27:33 INFO Epoch 2: [287/10940] ---- BYOL Training Loss = 0.346497505903244
30-01-2023 11:28:00 INFO Epoch 2: [298/10940] ---- BYOL Training Loss = 0.3368072211742401
30-01-2023 11:28:28 INFO Epoch 2: [309/10940] ---- BYOL Training Loss = 0.2753378748893738
30-01-2023 11:29:56 INFO Epoch 2: [309/10940] ---- BYOL Validation Loss = 0.3277556002140045
30-01-2023 11:30:24 INFO Epoch 2: [320/10940] ---- BYOL Training Loss = 0.2879261076450348
30-01-2023 11:30:51 INFO Epoch 2: [331/10940] ---- BYOL Training Loss = 0.30512186884880066
30-01-2023 11:31:18 INFO Epoch 2: [342/10940] ---- BYOL Training Loss = 0.3502199947834015
30-01-2023 11:31:46 INFO Epoch 2: [353/10940] ---- BYOL Training Loss = 0.31591323018074036
30-01-2023 11:33:14 INFO Epoch 2: [353/10940] ---- BYOL Validation Loss = 0.32717445492744446
30-01-2023 11:33:41 INFO Epoch 2: [364/10940] ---- BYOL Training Loss = 0.2882968783378601
30-01-2023 11:34:09 INFO Epoch 2: [375/10940] ---- BYOL Training Loss = 0.28691789507865906
30-01-2023 11:34:36 INFO Epoch 2: [386/10940] ---- BYOL Training Loss = 0.3054163455963135
30-01-2023 11:35:04 INFO Epoch 2: [397/10940] ---- BYOL Training Loss = 0.40559253096580505
30-01-2023 11:36:32 INFO Epoch 2: [397/10940] ---- BYOL Validation Loss = 0.33472880721092224
30-01-2023 11:36:59 INFO Epoch 2: [408/10940] ---- BYOL Training Loss = 0.3585585951805115
30-01-2023 11:37:27 INFO Epoch 2: [419/10940] ---- BYOL Training Loss = 0.3020031750202179
30-01-2023 11:37:54 INFO Epoch 2: [430/10940] ---- BYOL Training Loss = 0.3215096592903137
30-01-2023 11:38:22 INFO Epoch 2: [441/10940] ---- BYOL Training Loss = 0.2966035008430481
30-01-2023 11:39:50 INFO Epoch 2: [441/10940] ---- BYOL Validation Loss = 0.3225884735584259
30-01-2023 11:40:18 INFO Epoch 2: [452/10940] ---- BYOL Training Loss = 0.29858407378196716
30-01-2023 11:40:45 INFO Epoch 2: [463/10940] ---- BYOL Training Loss = 0.3616809844970703
30-01-2023 11:41:13 INFO Epoch 2: [474/10940] ---- BYOL Training Loss = 0.32934850454330444
30-01-2023 11:41:40 INFO Epoch 2: [485/10940] ---- BYOL Training Loss = 0.3050333559513092
30-01-2023 11:43:08 INFO Epoch 2: [485/10940] ---- BYOL Validation Loss = 0.3334006369113922
30-01-2023 11:43:36 INFO Epoch 2: [496/10940] ---- BYOL Training Loss = 0.3581175208091736
30-01-2023 11:44:03 INFO Epoch 2: [507/10940] ---- BYOL Training Loss = 0.3352971374988556
30-01-2023 11:44:30 INFO Epoch 2: [518/10940] ---- BYOL Training Loss = 0.2968539595603943
30-01-2023 11:44:58 INFO Epoch 2: [529/10940] ---- BYOL Training Loss = 0.27209019660949707
30-01-2023 11:46:26 INFO Epoch 2: [529/10940] ---- BYOL Validation Loss = 0.3241637647151947
30-01-2023 11:46:53 INFO Epoch 2: [540/10940] ---- BYOL Training Loss = 0.29032909870147705
30-01-2023 11:47:21 INFO Epoch 2: [551/10940] ---- BYOL Training Loss = 0.3794289231300354
30-01-2023 11:47:48 INFO Epoch 2: [562/10940] ---- BYOL Training Loss = 0.32479119300842285
30-01-2023 11:48:16 INFO Epoch 2: [573/10940] ---- BYOL Training Loss = 0.29712367057800293
30-01-2023 11:49:44 INFO Epoch 2: [573/10940] ---- BYOL Validation Loss = 0.3338285982608795
30-01-2023 11:50:12 INFO Epoch 2: [584/10940] ---- BYOL Training Loss = 0.3140983581542969
30-01-2023 11:50:39 INFO Epoch 2: [595/10940] ---- BYOL Training Loss = 0.3197321593761444
30-01-2023 11:51:06 INFO Epoch 2: [606/10940] ---- BYOL Training Loss = 0.30049586296081543
30-01-2023 11:51:34 INFO Epoch 2: [617/10940] ---- BYOL Training Loss = 0.3135327994823456
30-01-2023 11:53:03 INFO Epoch 2: [617/10940] ---- BYOL Validation Loss = 0.325886070728302
30-01-2023 11:53:30 INFO Epoch 2: [628/10940] ---- BYOL Training Loss = 0.3565770089626312
30-01-2023 11:53:57 INFO Epoch 2: [639/10940] ---- BYOL Training Loss = 0.29835373163223267
30-01-2023 11:54:25 INFO Epoch 2: [650/10940] ---- BYOL Training Loss = 0.2784215211868286
30-01-2023 11:54:52 INFO Epoch 2: [661/10940] ---- BYOL Training Loss = 0.29591700434684753
30-01-2023 11:56:20 INFO Epoch 2: [661/10940] ---- BYOL Validation Loss = 0.3122832477092743
30-01-2023 11:56:48 INFO Epoch 2: [672/10940] ---- BYOL Training Loss = 0.3034791350364685
30-01-2023 11:57:15 INFO Epoch 2: [683/10940] ---- BYOL Training Loss = 0.35573095083236694
30-01-2023 11:57:43 INFO Epoch 2: [694/10940] ---- BYOL Training Loss = 0.3577133119106293
30-01-2023 11:58:10 INFO Epoch 2: [705/10940] ---- BYOL Training Loss = 0.3890901505947113
30-01-2023 11:59:39 INFO Epoch 2: [705/10940] ---- BYOL Validation Loss = 0.321891725063324
30-01-2023 12:00:06 INFO Epoch 2: [716/10940] ---- BYOL Training Loss = 0.44586482644081116
30-01-2023 12:00:34 INFO Epoch 2: [727/10940] ---- BYOL Training Loss = 0.38012784719467163
30-01-2023 12:01:01 INFO Epoch 2: [738/10940] ---- BYOL Training Loss = 0.2997654974460602
30-01-2023 12:01:28 INFO Epoch 2: [749/10940] ---- BYOL Training Loss = 0.24369096755981445
30-01-2023 12:02:57 INFO Epoch 2: [749/10940] ---- BYOL Validation Loss = 0.3241496682167053
30-01-2023 12:03:24 INFO Epoch 2: [760/10940] ---- BYOL Training Loss = 0.2379148304462433
30-01-2023 12:03:52 INFO Epoch 2: [771/10940] ---- BYOL Training Loss = 0.26787644624710083
30-01-2023 12:04:19 INFO Epoch 2: [782/10940] ---- BYOL Training Loss = 0.3694029152393341
30-01-2023 12:04:47 INFO Epoch 2: [793/10940] ---- BYOL Training Loss = 0.29910582304000854
30-01-2023 12:06:15 INFO Epoch 2: [793/10940] ---- BYOL Validation Loss = 0.31686878204345703
30-01-2023 12:06:42 INFO Epoch 2: [804/10940] ---- BYOL Training Loss = 0.2831342816352844
30-01-2023 12:07:10 INFO Epoch 2: [815/10940] ---- BYOL Training Loss = 0.38835638761520386
30-01-2023 12:07:37 INFO Epoch 2: [826/10940] ---- BYOL Training Loss = 0.36465543508529663
30-01-2023 12:08:05 INFO Epoch 2: [837/10940] ---- BYOL Training Loss = 0.3314586877822876
30-01-2023 12:09:33 INFO Epoch 2: [837/10940] ---- BYOL Validation Loss = 0.35194525122642517
30-01-2023 12:10:01 INFO Epoch 2: [848/10940] ---- BYOL Training Loss = 0.3128107190132141
30-01-2023 12:10:28 INFO Epoch 2: [859/10940] ---- BYOL Training Loss = 0.3243163228034973
30-01-2023 12:10:56 INFO Epoch 2: [870/10940] ---- BYOL Training Loss = 0.3348519206047058
30-01-2023 12:11:23 INFO Epoch 2: [881/10940] ---- BYOL Training Loss = 0.3467532992362976
30-01-2023 12:12:52 INFO Epoch 2: [881/10940] ---- BYOL Validation Loss = 0.3348439037799835
30-01-2023 12:13:19 INFO Epoch 2: [892/10940] ---- BYOL Training Loss = 0.28848376870155334
30-01-2023 12:13:46 INFO Epoch 2: [903/10940] ---- BYOL Training Loss = 0.28386473655700684
30-01-2023 12:14:14 INFO Epoch 2: [914/10940] ---- BYOL Training Loss = 0.28843262791633606
30-01-2023 12:14:41 INFO Epoch 2: [925/10940] ---- BYOL Training Loss = 0.35206905007362366
30-01-2023 12:16:10 INFO Epoch 2: [925/10940] ---- BYOL Validation Loss = 0.32350918650627136
30-01-2023 12:16:37 INFO Epoch 2: [936/10940] ---- BYOL Training Loss = 0.34486162662506104
30-01-2023 12:17:05 INFO Epoch 2: [947/10940] ---- BYOL Training Loss = 0.29922428727149963
30-01-2023 12:17:32 INFO Epoch 2: [958/10940] ---- BYOL Training Loss = 0.32706379890441895
30-01-2023 12:18:00 INFO Epoch 2: [969/10940] ---- BYOL Training Loss = 0.33123213052749634
30-01-2023 12:19:28 INFO Epoch 2: [969/10940] ---- BYOL Validation Loss = 0.32062485814094543
30-01-2023 12:19:56 INFO Epoch 2: [980/10940] ---- BYOL Training Loss = 0.29861676692962646
30-01-2023 12:20:23 INFO Epoch 2: [991/10940] ---- BYOL Training Loss = 0.33354467153549194
30-01-2023 12:20:51 INFO Epoch 2: [1002/10940] ---- BYOL Training Loss = 0.3152693808078766
30-01-2023 12:21:18 INFO Epoch 2: [1013/10940] ---- BYOL Training Loss = 0.31840085983276367
30-01-2023 12:22:46 INFO Epoch 2: [1013/10940] ---- BYOL Validation Loss = 0.3278990387916565
30-01-2023 12:23:14 INFO Epoch 2: [1024/10940] ---- BYOL Training Loss = 0.36782482266426086
30-01-2023 12:23:41 INFO Epoch 2: [1035/10940] ---- BYOL Training Loss = 0.2850160002708435
30-01-2023 12:24:09 INFO Epoch 2: [1046/10940] ---- BYOL Training Loss = 0.28978490829467773
30-01-2023 12:24:36 INFO Epoch 2: [1057/10940] ---- BYOL Training Loss = 0.30729013681411743
30-01-2023 12:26:04 INFO Epoch 2: [1057/10940] ---- BYOL Validation Loss = 0.3233392834663391
30-01-2023 12:26:32 INFO Epoch 2: [1068/10940] ---- BYOL Training Loss = 0.3143268823623657
30-01-2023 12:26:59 INFO Epoch 2: [1079/10940] ---- BYOL Training Loss = 0.3350796401500702
30-01-2023 12:27:27 INFO Epoch 2: [1090/10940] ---- BYOL Training Loss = 0.35747164487838745
30-01-2023 12:27:54 INFO Epoch 2: [1101/10940] ---- BYOL Training Loss = 0.3307778835296631
30-01-2023 12:29:23 INFO Epoch 2: [1101/10940] ---- BYOL Validation Loss = 0.3334147334098816
30-01-2023 12:29:50 INFO Epoch 2: [1112/10940] ---- BYOL Training Loss = 0.31801140308380127
30-01-2023 12:30:18 INFO Epoch 2: [1123/10940] ---- BYOL Training Loss = 0.31889957189559937
30-01-2023 12:30:45 INFO Epoch 2: [1134/10940] ---- BYOL Training Loss = 0.3283841907978058
30-01-2023 12:31:13 INFO Epoch 2: [1145/10940] ---- BYOL Training Loss = 0.34996452927589417
30-01-2023 12:32:41 INFO Epoch 2: [1145/10940] ---- BYOL Validation Loss = 0.3153931796550751
30-01-2023 12:33:09 INFO Epoch 2: [1156/10940] ---- BYOL Training Loss = 0.34314996004104614
30-01-2023 12:33:36 INFO Epoch 2: [1167/10940] ---- BYOL Training Loss = 0.307295560836792
30-01-2023 12:34:04 INFO Epoch 2: [1178/10940] ---- BYOL Training Loss = 0.2917012870311737
30-01-2023 12:34:31 INFO Epoch 2: [1189/10940] ---- BYOL Training Loss = 0.303181916475296
30-01-2023 12:35:59 INFO Epoch 2: [1189/10940] ---- BYOL Validation Loss = 0.3390691876411438
30-01-2023 12:36:27 INFO Epoch 2: [1200/10940] ---- BYOL Training Loss = 0.27966785430908203
30-01-2023 12:36:54 INFO Epoch 2: [1211/10940] ---- BYOL Training Loss = 0.2570987045764923
30-01-2023 12:37:22 INFO Epoch 2: [1222/10940] ---- BYOL Training Loss = 0.31091922521591187
30-01-2023 12:37:49 INFO Epoch 2: [1233/10940] ---- BYOL Training Loss = 0.36287781596183777
30-01-2023 12:39:17 INFO Epoch 2: [1233/10940] ---- BYOL Validation Loss = 0.31945425271987915
30-01-2023 12:39:45 INFO Epoch 2: [1244/10940] ---- BYOL Training Loss = 0.35012784600257874
30-01-2023 12:40:12 INFO Epoch 2: [1255/10940] ---- BYOL Training Loss = 0.2574392259120941
30-01-2023 12:40:40 INFO Epoch 2: [1266/10940] ---- BYOL Training Loss = 0.2408343255519867
30-01-2023 12:41:08 INFO Epoch 2: [1277/10940] ---- BYOL Training Loss = 0.32305270433425903
30-01-2023 12:42:36 INFO Epoch 2: [1277/10940] ---- BYOL Validation Loss = 0.30918169021606445
30-01-2023 12:43:03 INFO Epoch 2: [1288/10940] ---- BYOL Training Loss = 0.2818087339401245
30-01-2023 12:43:31 INFO Epoch 2: [1299/10940] ---- BYOL Training Loss = 0.2595885396003723
30-01-2023 12:43:58 INFO Epoch 2: [1310/10940] ---- BYOL Training Loss = 0.29739826917648315
30-01-2023 12:44:26 INFO Epoch 2: [1321/10940] ---- BYOL Training Loss = 0.2838705778121948
30-01-2023 12:45:54 INFO Epoch 2: [1321/10940] ---- BYOL Validation Loss = 0.33157140016555786
30-01-2023 12:46:22 INFO Epoch 2: [1332/10940] ---- BYOL Training Loss = 0.2774219214916229
30-01-2023 12:46:49 INFO Epoch 2: [1343/10940] ---- BYOL Training Loss = 0.3228764235973358
30-01-2023 12:47:17 INFO Epoch 2: [1354/10940] ---- BYOL Training Loss = 0.34522271156311035
30-01-2023 12:47:44 INFO Epoch 2: [1365/10940] ---- BYOL Training Loss = 0.34666159749031067
30-01-2023 12:49:12 INFO Epoch 2: [1365/10940] ---- BYOL Validation Loss = 0.31695693731307983
30-01-2023 12:49:40 INFO Epoch 2: [1376/10940] ---- BYOL Training Loss = 0.29689884185791016
30-01-2023 12:50:08 INFO Epoch 2: [1387/10940] ---- BYOL Training Loss = 0.30255258083343506
30-01-2023 12:50:36 INFO Epoch 2: [1398/10940] ---- BYOL Training Loss = 0.3196452260017395
30-01-2023 12:51:03 INFO Epoch 2: [1409/10940] ---- BYOL Training Loss = 0.3166774809360504
30-01-2023 12:52:31 INFO Epoch 2: [1409/10940] ---- BYOL Validation Loss = 0.3166070282459259
30-01-2023 12:52:59 INFO Epoch 2: [1420/10940] ---- BYOL Training Loss = 0.3044375479221344
30-01-2023 12:53:26 INFO Epoch 2: [1431/10940] ---- BYOL Training Loss = 0.31060492992401123
30-01-2023 12:53:54 INFO Epoch 2: [1442/10940] ---- BYOL Training Loss = 0.31457769870758057
30-01-2023 12:54:21 INFO Epoch 2: [1453/10940] ---- BYOL Training Loss = 0.31460267305374146
30-01-2023 12:55:50 INFO Epoch 2: [1453/10940] ---- BYOL Validation Loss = 0.3192172348499298
30-01-2023 12:56:17 INFO Epoch 2: [1464/10940] ---- BYOL Training Loss = 0.2998700737953186
30-01-2023 12:56:45 INFO Epoch 2: [1475/10940] ---- BYOL Training Loss = 0.26826155185699463
30-01-2023 12:57:12 INFO Epoch 2: [1486/10940] ---- BYOL Training Loss = 0.2616580128669739
30-01-2023 12:57:39 INFO Epoch 2: [1497/10940] ---- BYOL Training Loss = 0.3161786198616028
30-01-2023 12:59:08 INFO Epoch 2: [1497/10940] ---- BYOL Validation Loss = 0.3282333016395569
30-01-2023 12:59:35 INFO Epoch 2: [1508/10940] ---- BYOL Training Loss = 0.343767911195755
30-01-2023 13:00:03 INFO Epoch 2: [1519/10940] ---- BYOL Training Loss = 0.28372567892074585
30-01-2023 13:00:31 INFO Epoch 2: [1530/10940] ---- BYOL Training Loss = 0.3028460144996643
30-01-2023 13:00:58 INFO Epoch 2: [1541/10940] ---- BYOL Training Loss = 0.28793030977249146
30-01-2023 13:02:26 INFO Epoch 2: [1541/10940] ---- BYOL Validation Loss = 0.3237634003162384
30-01-2023 13:02:54 INFO Epoch 2: [1552/10940] ---- BYOL Training Loss = 0.308189332485199
30-01-2023 13:03:22 INFO Epoch 2: [1563/10940] ---- BYOL Training Loss = 0.28882601857185364
30-01-2023 13:03:49 INFO Epoch 2: [1574/10940] ---- BYOL Training Loss = 0.31536731123924255
30-01-2023 13:04:16 INFO Epoch 2: [1585/10940] ---- BYOL Training Loss = 0.3079083263874054
30-01-2023 13:05:45 INFO Epoch 2: [1585/10940] ---- BYOL Validation Loss = 0.30351129174232483
30-01-2023 13:06:12 INFO Epoch 2: [1596/10940] ---- BYOL Training Loss = 0.2685365080833435
30-01-2023 13:06:40 INFO Epoch 2: [1607/10940] ---- BYOL Training Loss = 0.30299073457717896
30-01-2023 13:07:07 INFO Epoch 2: [1618/10940] ---- BYOL Training Loss = 0.2958722710609436
30-01-2023 13:07:35 INFO Epoch 2: [1629/10940] ---- BYOL Training Loss = 0.3024197816848755
30-01-2023 13:09:03 INFO Epoch 2: [1629/10940] ---- BYOL Validation Loss = 0.3111565411090851
30-01-2023 13:09:30 INFO Epoch 2: [1640/10940] ---- BYOL Training Loss = 0.3049960136413574
30-01-2023 13:09:58 INFO Epoch 2: [1651/10940] ---- BYOL Training Loss = 0.3131025731563568
30-01-2023 13:10:25 INFO Epoch 2: [1662/10940] ---- BYOL Training Loss = 0.3189524710178375
30-01-2023 13:10:53 INFO Epoch 2: [1673/10940] ---- BYOL Training Loss = 0.2855406403541565
30-01-2023 13:12:21 INFO Epoch 2: [1673/10940] ---- BYOL Validation Loss = 0.3036806881427765
30-01-2023 13:12:49 INFO Epoch 2: [1684/10940] ---- BYOL Training Loss = 0.24877247214317322
30-01-2023 13:13:16 INFO Epoch 2: [1695/10940] ---- BYOL Training Loss = 0.2691583037376404
30-01-2023 13:13:44 INFO Epoch 2: [1706/10940] ---- BYOL Training Loss = 0.29858919978141785
30-01-2023 13:14:11 INFO Epoch 2: [1717/10940] ---- BYOL Training Loss = 0.30266720056533813
30-01-2023 13:15:39 INFO Epoch 2: [1717/10940] ---- BYOL Validation Loss = 0.31036248803138733
30-01-2023 13:16:07 INFO Epoch 2: [1728/10940] ---- BYOL Training Loss = 0.2866523861885071
30-01-2023 13:16:34 INFO Epoch 2: [1739/10940] ---- BYOL Training Loss = 0.27374690771102905
30-01-2023 13:17:02 INFO Epoch 2: [1750/10940] ---- BYOL Training Loss = 0.26244860887527466
30-01-2023 13:17:29 INFO Epoch 2: [1761/10940] ---- BYOL Training Loss = 0.2679247260093689
30-01-2023 13:18:58 INFO Epoch 2: [1761/10940] ---- BYOL Validation Loss = 0.30582475662231445
30-01-2023 13:19:25 INFO Epoch 2: [1772/10940] ---- BYOL Training Loss = 0.29782551527023315
30-01-2023 13:19:53 INFO Epoch 2: [1783/10940] ---- BYOL Training Loss = 0.3137158751487732
30-01-2023 13:20:20 INFO Epoch 2: [1794/10940] ---- BYOL Training Loss = 0.2644736170768738
30-01-2023 13:20:48 INFO Epoch 2: [1805/10940] ---- BYOL Training Loss = 0.2740742564201355
30-01-2023 13:22:16 INFO Epoch 2: [1805/10940] ---- BYOL Validation Loss = 0.3033921420574188
30-01-2023 13:22:43 INFO Epoch 2: [1816/10940] ---- BYOL Training Loss = 0.28071218729019165
30-01-2023 13:23:11 INFO Epoch 2: [1827/10940] ---- BYOL Training Loss = 0.2616063356399536
30-01-2023 13:23:39 INFO Epoch 2: [1838/10940] ---- BYOL Training Loss = 0.30068856477737427
30-01-2023 13:24:06 INFO Epoch 2: [1849/10940] ---- BYOL Training Loss = 0.305109441280365
30-01-2023 13:25:35 INFO Epoch 2: [1849/10940] ---- BYOL Validation Loss = 0.31639114022254944
30-01-2023 13:26:02 INFO Epoch 2: [1860/10940] ---- BYOL Training Loss = 0.33395904302597046
30-01-2023 13:26:30 INFO Epoch 2: [1871/10940] ---- BYOL Training Loss = 0.3281296491622925
30-01-2023 13:26:57 INFO Epoch 2: [1882/10940] ---- BYOL Training Loss = 0.2958366274833679
30-01-2023 13:27:25 INFO Epoch 2: [1893/10940] ---- BYOL Training Loss = 0.3181096613407135
30-01-2023 13:28:53 INFO Epoch 2: [1893/10940] ---- BYOL Validation Loss = 0.3036608397960663
30-01-2023 13:29:21 INFO Epoch 2: [1904/10940] ---- BYOL Training Loss = 0.3303944170475006
30-01-2023 13:29:48 INFO Epoch 2: [1915/10940] ---- BYOL Training Loss = 0.22045573592185974
30-01-2023 13:30:16 INFO Epoch 2: [1926/10940] ---- BYOL Training Loss = 0.2910887897014618
30-01-2023 13:30:44 INFO Epoch 2: [1937/10940] ---- BYOL Training Loss = 0.34120967984199524
30-01-2023 13:32:12 INFO Epoch 2: [1937/10940] ---- BYOL Validation Loss = 0.2959125339984894
30-01-2023 13:32:39 INFO Epoch 2: [1948/10940] ---- BYOL Training Loss = 0.3644530475139618
30-01-2023 13:33:07 INFO Epoch 2: [1959/10940] ---- BYOL Training Loss = 0.3141236901283264
30-01-2023 13:33:35 INFO Epoch 2: [1970/10940] ---- BYOL Training Loss = 0.33360981941223145
30-01-2023 13:34:02 INFO Epoch 2: [1981/10940] ---- BYOL Training Loss = 0.3507102429866791
30-01-2023 13:35:31 INFO Epoch 2: [1981/10940] ---- BYOL Validation Loss = 0.30522701144218445
30-01-2023 13:35:58 INFO Epoch 2: [1992/10940] ---- BYOL Training Loss = 0.341174453496933
30-01-2023 13:36:26 INFO Epoch 2: [2003/10940] ---- BYOL Training Loss = 0.3243664503097534
30-01-2023 13:36:53 INFO Epoch 2: [2014/10940] ---- BYOL Training Loss = 0.27406513690948486
30-01-2023 13:37:21 INFO Epoch 2: [2025/10940] ---- BYOL Training Loss = 0.25411587953567505
30-01-2023 13:38:49 INFO Epoch 2: [2025/10940] ---- BYOL Validation Loss = 0.300548791885376
30-01-2023 13:39:17 INFO Epoch 2: [2036/10940] ---- BYOL Training Loss = 0.2570057213306427
30-01-2023 13:39:44 INFO Epoch 2: [2047/10940] ---- BYOL Training Loss = 0.2767338156700134
30-01-2023 13:40:12 INFO Epoch 2: [2058/10940] ---- BYOL Training Loss = 0.34823372960090637
30-01-2023 13:40:40 INFO Epoch 2: [2069/10940] ---- BYOL Training Loss = 0.34998422861099243
30-01-2023 13:42:08 INFO Epoch 2: [2069/10940] ---- BYOL Validation Loss = 0.31523895263671875
30-01-2023 13:42:35 INFO Epoch 2: [2080/10940] ---- BYOL Training Loss = 0.3418334126472473
30-01-2023 13:43:04 INFO Epoch 2: [2091/10940] ---- BYOL Training Loss = 0.33379313349723816
30-01-2023 13:43:31 INFO Epoch 2: [2102/10940] ---- BYOL Training Loss = 0.24888744950294495
30-01-2023 13:43:59 INFO Epoch 2: [2113/10940] ---- BYOL Training Loss = 0.25030338764190674
30-01-2023 13:45:27 INFO Epoch 2: [2113/10940] ---- BYOL Validation Loss = 0.30260005593299866
30-01-2023 13:45:55 INFO Epoch 2: [2124/10940] ---- BYOL Training Loss = 0.3019988238811493
30-01-2023 13:46:22 INFO Epoch 2: [2135/10940] ---- BYOL Training Loss = 0.30957597494125366
30-01-2023 13:46:50 INFO Epoch 2: [2146/10940] ---- BYOL Training Loss = 0.31029316782951355
30-01-2023 13:47:17 INFO Epoch 2: [2157/10940] ---- BYOL Training Loss = 0.31881624460220337
30-01-2023 13:48:46 INFO Epoch 2: [2157/10940] ---- BYOL Validation Loss = 0.314383327960968
30-01-2023 13:49:13 INFO Epoch 2: [2168/10940] ---- BYOL Training Loss = 0.31210002303123474
30-01-2023 13:49:41 INFO Epoch 2: [2179/10940] ---- BYOL Training Loss = 0.30615681409835815
30-01-2023 13:50:09 INFO Epoch 2: [2190/10940] ---- BYOL Training Loss = 0.27847036719322205
30-01-2023 13:50:36 INFO Epoch 2: [2201/10940] ---- BYOL Training Loss = 0.27412307262420654
30-01-2023 13:52:05 INFO Epoch 2: [2201/10940] ---- BYOL Validation Loss = 0.31023868918418884
30-01-2023 13:52:32 INFO Epoch 2: [2212/10940] ---- BYOL Training Loss = 0.29521769285202026
30-01-2023 13:53:00 INFO Epoch 2: [2223/10940] ---- BYOL Training Loss = 0.2955772578716278
30-01-2023 13:53:28 INFO Epoch 2: [2234/10940] ---- BYOL Training Loss = 0.3085349500179291
30-01-2023 13:53:55 INFO Epoch 2: [2245/10940] ---- BYOL Training Loss = 0.3096446394920349
30-01-2023 13:55:23 INFO Epoch 2: [2245/10940] ---- BYOL Validation Loss = 0.3181830942630768
30-01-2023 13:55:51 INFO Epoch 2: [2256/10940] ---- BYOL Training Loss = 0.294475257396698
30-01-2023 13:56:18 INFO Epoch 2: [2267/10940] ---- BYOL Training Loss = 0.2640593945980072
30-01-2023 13:56:46 INFO Epoch 2: [2278/10940] ---- BYOL Training Loss = 0.24803602695465088
30-01-2023 13:57:14 INFO Epoch 2: [2289/10940] ---- BYOL Training Loss = 0.28373000025749207
30-01-2023 13:58:42 INFO Epoch 2: [2289/10940] ---- BYOL Validation Loss = 0.3040851652622223
30-01-2023 13:59:10 INFO Epoch 2: [2300/10940] ---- BYOL Training Loss = 0.3130246102809906
30-01-2023 13:59:37 INFO Epoch 2: [2311/10940] ---- BYOL Training Loss = 0.2950930595397949
30-01-2023 14:00:05 INFO Epoch 2: [2322/10940] ---- BYOL Training Loss = 0.29162973165512085
30-01-2023 14:00:33 INFO Epoch 2: [2333/10940] ---- BYOL Training Loss = 0.27314719557762146
30-01-2023 14:02:02 INFO Epoch 2: [2333/10940] ---- BYOL Validation Loss = 0.3186207413673401
30-01-2023 14:02:29 INFO Epoch 2: [2344/10940] ---- BYOL Training Loss = 0.23964405059814453
30-01-2023 14:02:57 INFO Epoch 2: [2355/10940] ---- BYOL Training Loss = 0.27904269099235535
30-01-2023 14:03:24 INFO Epoch 2: [2366/10940] ---- BYOL Training Loss = 0.3197569251060486
30-01-2023 14:03:52 INFO Epoch 2: [2377/10940] ---- BYOL Training Loss = 0.2876835763454437
30-01-2023 14:05:20 INFO Epoch 2: [2377/10940] ---- BYOL Validation Loss = 0.3059203028678894
30-01-2023 14:05:48 INFO Epoch 2: [2388/10940] ---- BYOL Training Loss = 0.27953705191612244
30-01-2023 14:06:15 INFO Epoch 2: [2399/10940] ---- BYOL Training Loss = 0.28150784969329834
30-01-2023 14:06:43 INFO Epoch 2: [2410/10940] ---- BYOL Training Loss = 0.30912092328071594
30-01-2023 14:07:10 INFO Epoch 2: [2421/10940] ---- BYOL Training Loss = 0.34267669916152954
30-01-2023 14:08:39 INFO Epoch 2: [2421/10940] ---- BYOL Validation Loss = 0.30366453528404236
30-01-2023 14:09:06 INFO Epoch 2: [2432/10940] ---- BYOL Training Loss = 0.3134262263774872
30-01-2023 14:09:34 INFO Epoch 2: [2443/10940] ---- BYOL Training Loss = 0.31264418363571167
30-01-2023 14:10:02 INFO Epoch 2: [2454/10940] ---- BYOL Training Loss = 0.2970117926597595
30-01-2023 14:10:29 INFO Epoch 2: [2465/10940] ---- BYOL Training Loss = 0.31821244955062866
30-01-2023 14:11:58 INFO Epoch 2: [2465/10940] ---- BYOL Validation Loss = 0.32650789618492126
30-01-2023 14:12:25 INFO Epoch 2: [2476/10940] ---- BYOL Training Loss = 0.3266933560371399
30-01-2023 14:12:53 INFO Epoch 2: [2487/10940] ---- BYOL Training Loss = 0.32656800746917725
30-01-2023 14:13:20 INFO Epoch 2: [2498/10940] ---- BYOL Training Loss = 0.32670632004737854
30-01-2023 14:13:48 INFO Epoch 2: [2509/10940] ---- BYOL Training Loss = 0.2896895706653595
30-01-2023 14:15:16 INFO Epoch 2: [2509/10940] ---- BYOL Validation Loss = 0.3060007393360138
30-01-2023 14:15:44 INFO Epoch 2: [2520/10940] ---- BYOL Training Loss = 0.32132434844970703
30-01-2023 14:16:12 INFO Epoch 2: [2531/10940] ---- BYOL Training Loss = 0.341841459274292
30-01-2023 14:16:39 INFO Epoch 2: [2542/10940] ---- BYOL Training Loss = 0.3171372711658478
30-01-2023 14:17:07 INFO Epoch 2: [2553/10940] ---- BYOL Training Loss = 0.3065528869628906
30-01-2023 14:18:35 INFO Epoch 2: [2553/10940] ---- BYOL Validation Loss = 0.29818615317344666
30-01-2023 14:19:03 INFO Epoch 2: [2564/10940] ---- BYOL Training Loss = 0.29224735498428345
30-01-2023 14:19:30 INFO Epoch 2: [2575/10940] ---- BYOL Training Loss = 0.3452147841453552
30-01-2023 14:19:58 INFO Epoch 2: [2586/10940] ---- BYOL Training Loss = 0.34974247217178345
30-01-2023 14:20:26 INFO Epoch 2: [2597/10940] ---- BYOL Training Loss = 0.2598286271095276
30-01-2023 14:21:54 INFO Epoch 2: [2597/10940] ---- BYOL Validation Loss = 0.30858856439590454
30-01-2023 14:22:22 INFO Epoch 2: [2608/10940] ---- BYOL Training Loss = 0.2773352563381195
30-01-2023 14:22:50 INFO Epoch 2: [2619/10940] ---- BYOL Training Loss = 0.32456105947494507
30-01-2023 14:23:18 INFO Epoch 2: [2630/10940] ---- BYOL Training Loss = 0.30169886350631714
30-01-2023 14:23:45 INFO Epoch 2: [2641/10940] ---- BYOL Training Loss = 0.302396684885025
30-01-2023 14:25:13 INFO Epoch 2: [2641/10940] ---- BYOL Validation Loss = 0.2922249734401703
30-01-2023 14:25:41 INFO Epoch 2: [2652/10940] ---- BYOL Training Loss = 0.2712388038635254
30-01-2023 14:26:08 INFO Epoch 2: [2663/10940] ---- BYOL Training Loss = 0.25929683446884155
30-01-2023 14:26:36 INFO Epoch 2: [2674/10940] ---- BYOL Training Loss = 0.3013976216316223
30-01-2023 14:27:04 INFO Epoch 2: [2685/10940] ---- BYOL Training Loss = 0.28158900141716003
30-01-2023 14:28:32 INFO Epoch 2: [2685/10940] ---- BYOL Validation Loss = 0.3059692680835724
30-01-2023 14:29:00 INFO Epoch 2: [2696/10940] ---- BYOL Training Loss = 0.3326747715473175
30-01-2023 14:29:27 INFO Epoch 2: [2707/10940] ---- BYOL Training Loss = 0.3511769771575928
30-01-2023 14:29:55 INFO Epoch 2: [2718/10940] ---- BYOL Training Loss = 0.2863712012767792
30-01-2023 14:30:23 INFO Epoch 2: [2729/10940] ---- BYOL Training Loss = 0.291639119386673
30-01-2023 14:31:52 INFO Epoch 2: [2729/10940] ---- BYOL Validation Loss = 0.29962000250816345
30-01-2023 14:32:19 INFO Epoch 2: [2740/10940] ---- BYOL Training Loss = 0.23684780299663544
30-01-2023 14:32:47 INFO Epoch 2: [2751/10940] ---- BYOL Training Loss = 0.26671189069747925
30-01-2023 14:33:15 INFO Epoch 2: [2762/10940] ---- BYOL Training Loss = 0.3490317165851593
30-01-2023 14:33:42 INFO Epoch 2: [2773/10940] ---- BYOL Training Loss = 0.35938382148742676
30-01-2023 14:35:10 INFO Epoch 2: [2773/10940] ---- BYOL Validation Loss = 0.30405929684638977
30-01-2023 14:35:38 INFO Epoch 2: [2784/10940] ---- BYOL Training Loss = 0.29098135232925415
30-01-2023 14:36:06 INFO Epoch 2: [2795/10940] ---- BYOL Training Loss = 0.2794862389564514
30-01-2023 14:36:33 INFO Epoch 2: [2806/10940] ---- BYOL Training Loss = 0.2879432737827301
30-01-2023 14:37:01 INFO Epoch 2: [2817/10940] ---- BYOL Training Loss = 0.2817797064781189
30-01-2023 14:38:30 INFO Epoch 2: [2817/10940] ---- BYOL Validation Loss = 0.28939005732536316
30-01-2023 14:38:57 INFO Epoch 2: [2828/10940] ---- BYOL Training Loss = 0.25661760568618774
30-01-2023 14:39:25 INFO Epoch 2: [2839/10940] ---- BYOL Training Loss = 0.24516543745994568
30-01-2023 14:39:53 INFO Epoch 2: [2850/10940] ---- BYOL Training Loss = 0.24128679931163788
30-01-2023 14:40:20 INFO Epoch 2: [2861/10940] ---- BYOL Training Loss = 0.29711443185806274
30-01-2023 14:41:49 INFO Epoch 2: [2861/10940] ---- BYOL Validation Loss = 0.2914998233318329
30-01-2023 14:42:16 INFO Epoch 2: [2872/10940] ---- BYOL Training Loss = 0.27556949853897095
30-01-2023 14:42:44 INFO Epoch 2: [2883/10940] ---- BYOL Training Loss = 0.26417845487594604
30-01-2023 14:43:12 INFO Epoch 2: [2894/10940] ---- BYOL Training Loss = 0.2850862741470337
30-01-2023 14:43:40 INFO Epoch 2: [2905/10940] ---- BYOL Training Loss = 0.2852061092853546
30-01-2023 14:45:08 INFO Epoch 2: [2905/10940] ---- BYOL Validation Loss = 0.2945168614387512
30-01-2023 14:45:36 INFO Epoch 2: [2916/10940] ---- BYOL Training Loss = 0.3324170708656311
30-01-2023 14:46:03 INFO Epoch 2: [2927/10940] ---- BYOL Training Loss = 0.2857641577720642
30-01-2023 14:46:31 INFO Epoch 2: [2938/10940] ---- BYOL Training Loss = 0.23865234851837158
30-01-2023 14:46:58 INFO Epoch 2: [2949/10940] ---- BYOL Training Loss = 0.2792040705680847
30-01-2023 14:48:27 INFO Epoch 2: [2949/10940] ---- BYOL Validation Loss = 0.3094630241394043
30-01-2023 14:48:54 INFO Epoch 2: [2960/10940] ---- BYOL Training Loss = 0.28822529315948486
30-01-2023 14:49:22 INFO Epoch 2: [2971/10940] ---- BYOL Training Loss = 0.285645067691803
30-01-2023 14:49:50 INFO Epoch 2: [2982/10940] ---- BYOL Training Loss = 0.29532554745674133
30-01-2023 14:50:18 INFO Epoch 2: [2993/10940] ---- BYOL Training Loss = 0.335665762424469
30-01-2023 14:51:46 INFO Epoch 2: [2993/10940] ---- BYOL Validation Loss = 0.30368778109550476
30-01-2023 14:52:14 INFO Epoch 2: [3004/10940] ---- BYOL Training Loss = 0.342833012342453
30-01-2023 14:52:42 INFO Epoch 2: [3015/10940] ---- BYOL Training Loss = 0.2877460718154907
30-01-2023 14:53:09 INFO Epoch 2: [3026/10940] ---- BYOL Training Loss = 0.3134094476699829
30-01-2023 14:53:37 INFO Epoch 2: [3037/10940] ---- BYOL Training Loss = 0.27264848351478577
30-01-2023 14:55:05 INFO Epoch 2: [3037/10940] ---- BYOL Validation Loss = 0.29714712500572205
30-01-2023 14:55:33 INFO Epoch 2: [3048/10940] ---- BYOL Training Loss = 0.27707353234291077
30-01-2023 14:56:01 INFO Epoch 2: [3059/10940] ---- BYOL Training Loss = 0.27770644426345825
30-01-2023 14:56:28 INFO Epoch 2: [3070/10940] ---- BYOL Training Loss = 0.28064870834350586
30-01-2023 14:56:56 INFO Epoch 2: [3081/10940] ---- BYOL Training Loss = 0.34693869948387146
30-01-2023 14:58:24 INFO Epoch 2: [3081/10940] ---- BYOL Validation Loss = 0.2948826849460602
30-01-2023 14:58:52 INFO Epoch 2: [3092/10940] ---- BYOL Training Loss = 0.27895838022232056
30-01-2023 14:59:19 INFO Epoch 2: [3103/10940] ---- BYOL Training Loss = 0.2781994342803955
30-01-2023 14:59:47 INFO Epoch 2: [3114/10940] ---- BYOL Training Loss = 0.33509311079978943
30-01-2023 15:00:15 INFO Epoch 2: [3125/10940] ---- BYOL Training Loss = 0.32925018668174744
30-01-2023 15:01:44 INFO Epoch 2: [3125/10940] ---- BYOL Validation Loss = 0.29256922006607056
30-01-2023 15:02:12 INFO Epoch 2: [3136/10940] ---- BYOL Training Loss = 0.336162269115448
30-01-2023 15:02:39 INFO Epoch 2: [3147/10940] ---- BYOL Training Loss = 0.32860106229782104
30-01-2023 15:03:07 INFO Epoch 2: [3158/10940] ---- BYOL Training Loss = 0.3151535391807556
30-01-2023 15:03:34 INFO Epoch 2: [3169/10940] ---- BYOL Training Loss = 0.25280821323394775
30-01-2023 15:05:03 INFO Epoch 2: [3169/10940] ---- BYOL Validation Loss = 0.3052498400211334
30-01-2023 15:05:30 INFO Epoch 2: [3180/10940] ---- BYOL Training Loss = 0.286310076713562
30-01-2023 15:05:58 INFO Epoch 2: [3191/10940] ---- BYOL Training Loss = 0.27166056632995605
30-01-2023 15:06:26 INFO Epoch 2: [3202/10940] ---- BYOL Training Loss = 0.23549890518188477
30-01-2023 15:06:53 INFO Epoch 2: [3213/10940] ---- BYOL Training Loss = 0.23780186474323273
30-01-2023 15:08:22 INFO Epoch 2: [3213/10940] ---- BYOL Validation Loss = 0.2927616536617279
30-01-2023 15:08:49 INFO Epoch 2: [3224/10940] ---- BYOL Training Loss = 0.21267516911029816
30-01-2023 15:09:17 INFO Epoch 2: [3235/10940] ---- BYOL Training Loss = 0.3198239207267761
30-01-2023 15:09:45 INFO Epoch 2: [3246/10940] ---- BYOL Training Loss = 0.33505210280418396
30-01-2023 15:10:13 INFO Epoch 2: [3257/10940] ---- BYOL Training Loss = 0.2922160029411316
30-01-2023 15:11:41 INFO Epoch 2: [3257/10940] ---- BYOL Validation Loss = 0.2876197397708893
30-01-2023 15:12:09 INFO Epoch 2: [3268/10940] ---- BYOL Training Loss = 0.2804751992225647
30-01-2023 15:12:37 INFO Epoch 2: [3279/10940] ---- BYOL Training Loss = 0.2756785750389099
30-01-2023 15:13:04 INFO Epoch 2: [3290/10940] ---- BYOL Training Loss = 0.29205045104026794
30-01-2023 15:13:32 INFO Epoch 2: [3301/10940] ---- BYOL Training Loss = 0.296684592962265
30-01-2023 15:15:00 INFO Epoch 2: [3301/10940] ---- BYOL Validation Loss = 0.30397769808769226
30-01-2023 15:15:28 INFO Epoch 2: [3312/10940] ---- BYOL Training Loss = 0.33016055822372437
30-01-2023 15:15:56 INFO Epoch 2: [3323/10940] ---- BYOL Training Loss = 0.33533599972724915
30-01-2023 15:16:24 INFO Epoch 2: [3334/10940] ---- BYOL Training Loss = 0.3186410963535309
30-01-2023 15:16:51 INFO Epoch 2: [3345/10940] ---- BYOL Training Loss = 0.33936405181884766
30-01-2023 15:18:20 INFO Epoch 2: [3345/10940] ---- BYOL Validation Loss = 0.2925819754600525
30-01-2023 15:18:47 INFO Epoch 2: [3356/10940] ---- BYOL Training Loss = 0.3084257245063782
30-01-2023 15:19:15 INFO Epoch 2: [3367/10940] ---- BYOL Training Loss = 0.31935805082321167
30-01-2023 15:19:42 INFO Epoch 2: [3378/10940] ---- BYOL Training Loss = 0.3138648271560669
30-01-2023 15:20:10 INFO Epoch 2: [3389/10940] ---- BYOL Training Loss = 0.2600460350513458
30-01-2023 15:21:39 INFO Epoch 2: [3389/10940] ---- BYOL Validation Loss = 0.3067507743835449
30-01-2023 15:22:06 INFO Epoch 2: [3400/10940] ---- BYOL Training Loss = 0.25707095861434937
30-01-2023 15:22:34 INFO Epoch 2: [3411/10940] ---- BYOL Training Loss = 0.30228906869888306
30-01-2023 15:23:02 INFO Epoch 2: [3422/10940] ---- BYOL Training Loss = 0.297709196805954
30-01-2023 15:23:30 INFO Epoch 2: [3433/10940] ---- BYOL Training Loss = 0.25648224353790283
30-01-2023 15:24:58 INFO Epoch 2: [3433/10940] ---- BYOL Validation Loss = 0.310485303401947
30-01-2023 15:25:25 INFO Epoch 2: [3444/10940] ---- BYOL Training Loss = 0.29110902547836304
30-01-2023 15:25:53 INFO Epoch 2: [3455/10940] ---- BYOL Training Loss = 0.34806257486343384
30-01-2023 15:26:21 INFO Epoch 2: [3466/10940] ---- BYOL Training Loss = 0.33993813395500183
30-01-2023 15:26:49 INFO Epoch 2: [3477/10940] ---- BYOL Training Loss = 0.2941911816596985
30-01-2023 15:28:17 INFO Epoch 2: [3477/10940] ---- BYOL Validation Loss = 0.2950136661529541
30-01-2023 15:28:45 INFO Epoch 2: [3488/10940] ---- BYOL Training Loss = 0.2745018005371094
30-01-2023 15:29:12 INFO Epoch 2: [3499/10940] ---- BYOL Training Loss = 0.25950220227241516
30-01-2023 15:29:40 INFO Epoch 2: [3510/10940] ---- BYOL Training Loss = 0.2640237808227539
30-01-2023 15:30:08 INFO Epoch 2: [3521/10940] ---- BYOL Training Loss = 0.2778150737285614
30-01-2023 15:31:36 INFO Epoch 2: [3521/10940] ---- BYOL Validation Loss = 0.2856731414794922
30-01-2023 15:32:04 INFO Epoch 2: [3532/10940] ---- BYOL Training Loss = 0.24652734398841858
30-01-2023 15:32:32 INFO Epoch 2: [3543/10940] ---- BYOL Training Loss = 0.2292049676179886
30-01-2023 15:33:00 INFO Epoch 2: [3554/10940] ---- BYOL Training Loss = 0.23717078566551208
30-01-2023 15:33:27 INFO Epoch 2: [3565/10940] ---- BYOL Training Loss = 0.2899869680404663
30-01-2023 15:34:55 INFO Epoch 2: [3565/10940] ---- BYOL Validation Loss = 0.28560078144073486
30-01-2023 15:35:23 INFO Epoch 2: [3576/10940] ---- BYOL Training Loss = 0.30037373304367065
30-01-2023 15:35:51 INFO Epoch 2: [3587/10940] ---- BYOL Training Loss = 0.25429826974868774
30-01-2023 15:36:19 INFO Epoch 2: [3598/10940] ---- BYOL Training Loss = 0.286925733089447
30-01-2023 15:36:46 INFO Epoch 2: [3609/10940] ---- BYOL Training Loss = 0.2608954608440399
30-01-2023 15:38:14 INFO Epoch 2: [3609/10940] ---- BYOL Validation Loss = 0.2792917490005493
30-01-2023 15:38:43 INFO Epoch 2: [3620/10940] ---- BYOL Training Loss = 0.27650296688079834
30-01-2023 15:39:10 INFO Epoch 2: [3631/10940] ---- BYOL Training Loss = 0.2747657299041748
30-01-2023 15:39:38 INFO Epoch 2: [3642/10940] ---- BYOL Training Loss = 0.2985081076622009
30-01-2023 15:40:06 INFO Epoch 2: [3653/10940] ---- BYOL Training Loss = 0.26323840022087097
30-01-2023 15:41:34 INFO Epoch 2: [3653/10940] ---- BYOL Validation Loss = 0.29142269492149353
30-01-2023 15:42:02 INFO Epoch 2: [3664/10940] ---- BYOL Training Loss = 0.29399845004081726
30-01-2023 15:42:29 INFO Epoch 2: [3675/10940] ---- BYOL Training Loss = 0.3039925694465637
30-01-2023 15:42:57 INFO Epoch 2: [3686/10940] ---- BYOL Training Loss = 0.3476201593875885
30-01-2023 15:43:25 INFO Epoch 2: [3697/10940] ---- BYOL Training Loss = 0.2835950553417206
30-01-2023 15:44:53 INFO Epoch 2: [3697/10940] ---- BYOL Validation Loss = 0.28904083371162415
30-01-2023 15:45:21 INFO Epoch 2: [3708/10940] ---- BYOL Training Loss = 0.2212332785129547
30-01-2023 15:45:49 INFO Epoch 2: [3719/10940] ---- BYOL Training Loss = 0.29887762665748596
30-01-2023 15:46:16 INFO Epoch 2: [3730/10940] ---- BYOL Training Loss = 0.2939618229866028
30-01-2023 15:46:44 INFO Epoch 2: [3741/10940] ---- BYOL Training Loss = 0.279629647731781
30-01-2023 15:48:12 INFO Epoch 2: [3741/10940] ---- BYOL Validation Loss = 0.2877720296382904
30-01-2023 15:48:40 INFO Epoch 2: [3752/10940] ---- BYOL Training Loss = 0.29932063817977905
30-01-2023 15:49:08 INFO Epoch 2: [3763/10940] ---- BYOL Training Loss = 0.2596588432788849
30-01-2023 15:49:36 INFO Epoch 2: [3774/10940] ---- BYOL Training Loss = 0.2700454890727997
30-01-2023 15:50:03 INFO Epoch 2: [3785/10940] ---- BYOL Training Loss = 0.3037097156047821
30-01-2023 15:51:32 INFO Epoch 2: [3785/10940] ---- BYOL Validation Loss = 0.31296882033348083
30-01-2023 15:51:59 INFO Epoch 2: [3796/10940] ---- BYOL Training Loss = 0.2957635819911957
30-01-2023 15:52:27 INFO Epoch 2: [3807/10940] ---- BYOL Training Loss = 0.29644984006881714
30-01-2023 15:52:55 INFO Epoch 2: [3818/10940] ---- BYOL Training Loss = 0.29778844118118286
30-01-2023 15:53:23 INFO Epoch 2: [3829/10940] ---- BYOL Training Loss = 0.31867024302482605
30-01-2023 15:54:51 INFO Epoch 2: [3829/10940] ---- BYOL Validation Loss = 0.28728577494621277
30-01-2023 15:55:19 INFO Epoch 2: [3840/10940] ---- BYOL Training Loss = 0.2992376387119293
30-01-2023 15:55:47 INFO Epoch 2: [3851/10940] ---- BYOL Training Loss = 0.29163235425949097
30-01-2023 15:56:14 INFO Epoch 2: [3862/10940] ---- BYOL Training Loss = 0.26751652359962463
30-01-2023 15:56:42 INFO Epoch 2: [3873/10940] ---- BYOL Training Loss = 0.29469043016433716
30-01-2023 15:58:11 INFO Epoch 2: [3873/10940] ---- BYOL Validation Loss = 0.2929549515247345
30-01-2023 15:58:38 INFO Epoch 2: [3884/10940] ---- BYOL Training Loss = 0.3572574257850647
30-01-2023 15:59:06 INFO Epoch 2: [3895/10940] ---- BYOL Training Loss = 0.29775121808052063
30-01-2023 15:59:34 INFO Epoch 2: [3906/10940] ---- BYOL Training Loss = 0.28842073678970337
30-01-2023 16:00:01 INFO Epoch 2: [3917/10940] ---- BYOL Training Loss = 0.28828099370002747
30-01-2023 16:01:30 INFO Epoch 2: [3917/10940] ---- BYOL Validation Loss = 0.2889080345630646
30-01-2023 16:01:57 INFO Epoch 2: [3928/10940] ---- BYOL Training Loss = 0.2647518515586853
30-01-2023 16:02:25 INFO Epoch 2: [3939/10940] ---- BYOL Training Loss = 0.26263201236724854
30-01-2023 16:02:54 INFO Epoch 2: [3950/10940] ---- BYOL Training Loss = 0.2807510495185852
30-01-2023 16:03:21 INFO Epoch 2: [3961/10940] ---- BYOL Training Loss = 0.3017060458660126
30-01-2023 16:04:49 INFO Epoch 2: [3961/10940] ---- BYOL Validation Loss = 0.3019903600215912
30-01-2023 16:05:17 INFO Epoch 2: [3972/10940] ---- BYOL Training Loss = 0.27507925033569336
30-01-2023 16:05:45 INFO Epoch 2: [3983/10940] ---- BYOL Training Loss = 0.2795066237449646
30-01-2023 16:06:13 INFO Epoch 2: [3994/10940] ---- BYOL Training Loss = 0.27306634187698364
30-01-2023 16:06:41 INFO Epoch 2: [4005/10940] ---- BYOL Training Loss = 0.29127538204193115
30-01-2023 16:08:09 INFO Epoch 2: [4005/10940] ---- BYOL Validation Loss = 0.3143315315246582
30-01-2023 16:08:36 INFO Epoch 2: [4016/10940] ---- BYOL Training Loss = 0.31386786699295044
30-01-2023 16:09:04 INFO Epoch 2: [4027/10940] ---- BYOL Training Loss = 0.3010038137435913
30-01-2023 16:09:32 INFO Epoch 2: [4038/10940] ---- BYOL Training Loss = 0.27361124753952026
30-01-2023 16:10:00 INFO Epoch 2: [4049/10940] ---- BYOL Training Loss = 0.3181854486465454
30-01-2023 16:11:28 INFO Epoch 2: [4049/10940] ---- BYOL Validation Loss = 0.294380247592926
30-01-2023 16:11:56 INFO Epoch 2: [4060/10940] ---- BYOL Training Loss = 0.30371761322021484
30-01-2023 16:12:24 INFO Epoch 2: [4071/10940] ---- BYOL Training Loss = 0.34702029824256897
30-01-2023 16:12:51 INFO Epoch 2: [4082/10940] ---- BYOL Training Loss = 0.33492836356163025
30-01-2023 16:13:19 INFO Epoch 2: [4093/10940] ---- BYOL Training Loss = 0.20503756403923035
30-01-2023 16:14:47 INFO Epoch 2: [4093/10940] ---- BYOL Validation Loss = 0.2963808476924896
30-01-2023 16:15:15 INFO Epoch 2: [4104/10940] ---- BYOL Training Loss = 0.23189178109169006
30-01-2023 16:15:43 INFO Epoch 2: [4115/10940] ---- BYOL Training Loss = 0.29973310232162476
30-01-2023 16:16:11 INFO Epoch 2: [4126/10940] ---- BYOL Training Loss = 0.30111220479011536
30-01-2023 16:16:39 INFO Epoch 2: [4137/10940] ---- BYOL Training Loss = 0.32724902033805847
30-01-2023 16:18:07 INFO Epoch 2: [4137/10940] ---- BYOL Validation Loss = 0.2938820421695709
30-01-2023 16:18:35 INFO Epoch 2: [4148/10940] ---- BYOL Training Loss = 0.28229469060897827
30-01-2023 16:19:03 INFO Epoch 2: [4159/10940] ---- BYOL Training Loss = 0.25926584005355835
30-01-2023 16:19:30 INFO Epoch 2: [4170/10940] ---- BYOL Training Loss = 0.3013637065887451
30-01-2023 16:19:58 INFO Epoch 2: [4181/10940] ---- BYOL Training Loss = 0.3304380476474762
30-01-2023 16:21:27 INFO Epoch 2: [4181/10940] ---- BYOL Validation Loss = 0.3051115572452545
30-01-2023 16:21:55 INFO Epoch 2: [4192/10940] ---- BYOL Training Loss = 0.3003368377685547
30-01-2023 16:22:22 INFO Epoch 2: [4203/10940] ---- BYOL Training Loss = 0.25048714876174927
30-01-2023 16:22:50 INFO Epoch 2: [4214/10940] ---- BYOL Training Loss = 0.2710534930229187
30-01-2023 16:23:18 INFO Epoch 2: [4225/10940] ---- BYOL Training Loss = 0.25241485238075256
30-01-2023 16:24:46 INFO Epoch 2: [4225/10940] ---- BYOL Validation Loss = 0.2799350917339325
30-01-2023 16:25:14 INFO Epoch 2: [4236/10940] ---- BYOL Training Loss = 0.2885335385799408
30-01-2023 16:25:42 INFO Epoch 2: [4247/10940] ---- BYOL Training Loss = 0.2971746027469635
30-01-2023 16:26:10 INFO Epoch 2: [4258/10940] ---- BYOL Training Loss = 0.2863515317440033
30-01-2023 16:26:37 INFO Epoch 2: [4269/10940] ---- BYOL Training Loss = 0.23556168377399445
30-01-2023 16:28:05 INFO Epoch 2: [4269/10940] ---- BYOL Validation Loss = 0.27542856335639954
30-01-2023 16:28:33 INFO Epoch 2: [4280/10940] ---- BYOL Training Loss = 0.2656427323818207
30-01-2023 16:29:01 INFO Epoch 2: [4291/10940] ---- BYOL Training Loss = 0.2854245603084564
30-01-2023 16:29:29 INFO Epoch 2: [4302/10940] ---- BYOL Training Loss = 0.27507632970809937
30-01-2023 16:29:57 INFO Epoch 2: [4313/10940] ---- BYOL Training Loss = 0.28961873054504395
30-01-2023 16:31:25 INFO Epoch 2: [4313/10940] ---- BYOL Validation Loss = 0.2777372896671295
30-01-2023 16:31:53 INFO Epoch 2: [4324/10940] ---- BYOL Training Loss = 0.29943978786468506
30-01-2023 16:32:20 INFO Epoch 2: [4335/10940] ---- BYOL Training Loss = 0.3014708161354065
30-01-2023 16:32:48 INFO Epoch 2: [4346/10940] ---- BYOL Training Loss = 0.30230456590652466
30-01-2023 16:33:16 INFO Epoch 2: [4357/10940] ---- BYOL Training Loss = 0.3263252377510071
30-01-2023 16:34:44 INFO Epoch 2: [4357/10940] ---- BYOL Validation Loss = 0.2832706868648529
30-01-2023 16:35:12 INFO Epoch 2: [4368/10940] ---- BYOL Training Loss = 0.2895491123199463
30-01-2023 16:35:40 INFO Epoch 2: [4379/10940] ---- BYOL Training Loss = 0.296172559261322
30-01-2023 16:36:07 INFO Epoch 2: [4390/10940] ---- BYOL Training Loss = 0.3269590437412262
30-01-2023 16:36:35 INFO Epoch 2: [4401/10940] ---- BYOL Training Loss = 0.2998524010181427
30-01-2023 16:38:03 INFO Epoch 2: [4401/10940] ---- BYOL Validation Loss = 0.28134143352508545
30-01-2023 16:38:31 INFO Epoch 2: [4412/10940] ---- BYOL Training Loss = 0.2503806948661804
30-01-2023 16:38:59 INFO Epoch 2: [4423/10940] ---- BYOL Training Loss = 0.26524996757507324
30-01-2023 16:39:27 INFO Epoch 2: [4434/10940] ---- BYOL Training Loss = 0.2799855172634125
30-01-2023 16:39:55 INFO Epoch 2: [4445/10940] ---- BYOL Training Loss = 0.27204203605651855
30-01-2023 16:41:23 INFO Epoch 2: [4445/10940] ---- BYOL Validation Loss = 0.27743855118751526
30-01-2023 16:41:51 INFO Epoch 2: [4456/10940] ---- BYOL Training Loss = 0.2532675862312317
30-01-2023 16:42:19 INFO Epoch 2: [4467/10940] ---- BYOL Training Loss = 0.26814085245132446
30-01-2023 16:42:46 INFO Epoch 2: [4478/10940] ---- BYOL Training Loss = 0.2818083167076111
30-01-2023 16:43:14 INFO Epoch 2: [4489/10940] ---- BYOL Training Loss = 0.24842949211597443
30-01-2023 16:44:42 INFO Epoch 2: [4489/10940] ---- BYOL Validation Loss = 0.2688114047050476
30-01-2023 16:45:10 INFO Epoch 2: [4500/10940] ---- BYOL Training Loss = 0.2535497844219208
30-01-2023 16:45:38 INFO Epoch 2: [4511/10940] ---- BYOL Training Loss = 0.29276806116104126
30-01-2023 16:46:06 INFO Epoch 2: [4522/10940] ---- BYOL Training Loss = 0.29646235704421997
30-01-2023 16:46:34 INFO Epoch 2: [4533/10940] ---- BYOL Training Loss = 0.26872164011001587
30-01-2023 16:48:02 INFO Epoch 2: [4533/10940] ---- BYOL Validation Loss = 0.27562299370765686
30-01-2023 16:48:30 INFO Epoch 2: [4544/10940] ---- BYOL Training Loss = 0.21470382809638977
30-01-2023 16:48:58 INFO Epoch 2: [4555/10940] ---- BYOL Training Loss = 0.22317734360694885
30-01-2023 16:49:25 INFO Epoch 2: [4566/10940] ---- BYOL Training Loss = 0.2708250880241394
30-01-2023 16:49:54 INFO Epoch 2: [4577/10940] ---- BYOL Training Loss = 0.28662484884262085
30-01-2023 16:51:22 INFO Epoch 2: [4577/10940] ---- BYOL Validation Loss = 0.2693440616130829
30-01-2023 16:51:49 INFO Epoch 2: [4588/10940] ---- BYOL Training Loss = 0.2771648168563843
30-01-2023 16:52:17 INFO Epoch 2: [4599/10940] ---- BYOL Training Loss = 0.26884108781814575
30-01-2023 16:52:45 INFO Epoch 2: [4610/10940] ---- BYOL Training Loss = 0.27259546518325806
30-01-2023 16:53:13 INFO Epoch 2: [4621/10940] ---- BYOL Training Loss = 0.26968517899513245
30-01-2023 16:54:41 INFO Epoch 2: [4621/10940] ---- BYOL Validation Loss = 0.2678071856498718
30-01-2023 16:55:09 INFO Epoch 2: [4632/10940] ---- BYOL Training Loss = 0.24289366602897644
30-01-2023 16:55:37 INFO Epoch 2: [4643/10940] ---- BYOL Training Loss = 0.23882082104682922
30-01-2023 16:56:05 INFO Epoch 2: [4654/10940] ---- BYOL Training Loss = 0.2236318588256836
30-01-2023 16:56:32 INFO Epoch 2: [4665/10940] ---- BYOL Training Loss = 0.2812316119670868
30-01-2023 16:58:01 INFO Epoch 2: [4665/10940] ---- BYOL Validation Loss = 0.29145893454551697
30-01-2023 16:58:29 INFO Epoch 2: [4676/10940] ---- BYOL Training Loss = 0.3277621269226074
30-01-2023 16:58:57 INFO Epoch 2: [4687/10940] ---- BYOL Training Loss = 0.26725077629089355
30-01-2023 16:59:24 INFO Epoch 2: [4698/10940] ---- BYOL Training Loss = 0.2563473582267761
30-01-2023 16:59:52 INFO Epoch 2: [4709/10940] ---- BYOL Training Loss = 0.3198578357696533
30-01-2023 17:01:20 INFO Epoch 2: [4709/10940] ---- BYOL Validation Loss = 0.29094940423965454
30-01-2023 17:01:48 INFO Epoch 2: [4720/10940] ---- BYOL Training Loss = 0.31271135807037354
30-01-2023 17:02:16 INFO Epoch 2: [4731/10940] ---- BYOL Training Loss = 0.2772333025932312
30-01-2023 17:02:44 INFO Epoch 2: [4742/10940] ---- BYOL Training Loss = 0.29661446809768677
30-01-2023 17:03:12 INFO Epoch 2: [4753/10940] ---- BYOL Training Loss = 0.3352734446525574
30-01-2023 17:04:40 INFO Epoch 2: [4753/10940] ---- BYOL Validation Loss = 0.3257082402706146
30-01-2023 17:05:08 INFO Epoch 2: [4764/10940] ---- BYOL Training Loss = 0.32260602712631226
30-01-2023 17:05:37 INFO Epoch 2: [4775/10940] ---- BYOL Training Loss = 0.23739536106586456
30-01-2023 17:06:04 INFO Epoch 2: [4786/10940] ---- BYOL Training Loss = 0.2881384491920471
30-01-2023 17:06:32 INFO Epoch 2: [4797/10940] ---- BYOL Training Loss = 0.2714118957519531
30-01-2023 17:08:00 INFO Epoch 2: [4797/10940] ---- BYOL Validation Loss = 0.26166221499443054
30-01-2023 17:08:28 INFO Epoch 2: [4808/10940] ---- BYOL Training Loss = 0.23080411553382874
30-01-2023 17:08:56 INFO Epoch 2: [4819/10940] ---- BYOL Training Loss = 0.2937820553779602
30-01-2023 17:09:24 INFO Epoch 2: [4830/10940] ---- BYOL Training Loss = 0.29911309480667114
30-01-2023 17:09:52 INFO Epoch 2: [4841/10940] ---- BYOL Training Loss = 0.25376835465431213
30-01-2023 17:11:20 INFO Epoch 2: [4841/10940] ---- BYOL Validation Loss = 0.2666180431842804
30-01-2023 17:11:48 INFO Epoch 2: [4852/10940] ---- BYOL Training Loss = 0.2842445969581604
30-01-2023 17:12:16 INFO Epoch 2: [4863/10940] ---- BYOL Training Loss = 0.32215970754623413
30-01-2023 17:12:44 INFO Epoch 2: [4874/10940] ---- BYOL Training Loss = 0.3286144435405731
30-01-2023 17:13:12 INFO Epoch 2: [4885/10940] ---- BYOL Training Loss = 0.3410661816596985
30-01-2023 17:14:40 INFO Epoch 2: [4885/10940] ---- BYOL Validation Loss = 0.273973673582077
30-01-2023 17:15:08 INFO Epoch 2: [4896/10940] ---- BYOL Training Loss = 0.28035131096839905
30-01-2023 17:15:36 INFO Epoch 2: [4907/10940] ---- BYOL Training Loss = 0.2611398696899414
30-01-2023 17:16:03 INFO Epoch 2: [4918/10940] ---- BYOL Training Loss = 0.2568652629852295
30-01-2023 17:16:31 INFO Epoch 2: [4929/10940] ---- BYOL Training Loss = 0.2303226888179779
30-01-2023 17:18:00 INFO Epoch 2: [4929/10940] ---- BYOL Validation Loss = 0.2752419114112854
30-01-2023 17:18:27 INFO Epoch 2: [4940/10940] ---- BYOL Training Loss = 0.26700514554977417
30-01-2023 17:18:55 INFO Epoch 2: [4951/10940] ---- BYOL Training Loss = 0.28382572531700134
30-01-2023 17:19:23 INFO Epoch 2: [4962/10940] ---- BYOL Training Loss = 0.2232663929462433
30-01-2023 17:19:51 INFO Epoch 2: [4973/10940] ---- BYOL Training Loss = 0.24605071544647217
30-01-2023 17:21:19 INFO Epoch 2: [4973/10940] ---- BYOL Validation Loss = 0.2674869894981384
30-01-2023 17:21:47 INFO Epoch 2: [4984/10940] ---- BYOL Training Loss = 0.24623966217041016
30-01-2023 17:22:15 INFO Epoch 2: [4995/10940] ---- BYOL Training Loss = 0.24053096771240234
30-01-2023 17:22:43 INFO Epoch 2: [5006/10940] ---- BYOL Training Loss = 0.27271103858947754
30-01-2023 17:23:11 INFO Epoch 2: [5017/10940] ---- BYOL Training Loss = 0.2614692151546478
30-01-2023 17:24:39 INFO Epoch 2: [5017/10940] ---- BYOL Validation Loss = 0.2742713391780853
30-01-2023 17:25:07 INFO Epoch 2: [5028/10940] ---- BYOL Training Loss = 0.1951853632926941
30-01-2023 17:25:35 INFO Epoch 2: [5039/10940] ---- BYOL Training Loss = 0.24394002556800842
30-01-2023 17:26:03 INFO Epoch 2: [5050/10940] ---- BYOL Training Loss = 0.28824281692504883
30-01-2023 17:26:31 INFO Epoch 2: [5061/10940] ---- BYOL Training Loss = 0.2606131434440613
30-01-2023 17:27:59 INFO Epoch 2: [5061/10940] ---- BYOL Validation Loss = 0.2747061252593994
30-01-2023 17:28:27 INFO Epoch 2: [5072/10940] ---- BYOL Training Loss = 0.26275700330734253
30-01-2023 17:28:55 INFO Epoch 2: [5083/10940] ---- BYOL Training Loss = 0.25345510244369507
30-01-2023 17:29:23 INFO Epoch 2: [5094/10940] ---- BYOL Training Loss = 0.27755430340766907
30-01-2023 17:29:51 INFO Epoch 2: [5105/10940] ---- BYOL Training Loss = 0.369136244058609
30-01-2023 17:31:19 INFO Epoch 2: [5105/10940] ---- BYOL Validation Loss = 0.2852793037891388
30-01-2023 17:31:47 INFO Epoch 2: [5116/10940] ---- BYOL Training Loss = 0.33725211024284363
30-01-2023 17:32:15 INFO Epoch 2: [5127/10940] ---- BYOL Training Loss = 0.28809666633605957
30-01-2023 17:32:43 INFO Epoch 2: [5138/10940] ---- BYOL Training Loss = 0.28748032450675964
30-01-2023 17:33:11 INFO Epoch 2: [5149/10940] ---- BYOL Training Loss = 0.27658265829086304
30-01-2023 17:34:39 INFO Epoch 2: [5149/10940] ---- BYOL Validation Loss = 0.27308088541030884
30-01-2023 17:35:07 INFO Epoch 2: [5160/10940] ---- BYOL Training Loss = 0.23967602849006653
30-01-2023 17:35:36 INFO Epoch 2: [5171/10940] ---- BYOL Training Loss = 0.25791609287261963
30-01-2023 17:36:03 INFO Epoch 2: [5182/10940] ---- BYOL Training Loss = 0.2722519040107727
30-01-2023 17:36:31 INFO Epoch 2: [5193/10940] ---- BYOL Training Loss = 0.2891351580619812
30-01-2023 17:37:59 INFO Epoch 2: [5193/10940] ---- BYOL Validation Loss = 0.2761690020561218
30-01-2023 17:38:27 INFO Epoch 2: [5204/10940] ---- BYOL Training Loss = 0.29936689138412476
30-01-2023 17:38:55 INFO Epoch 2: [5215/10940] ---- BYOL Training Loss = 0.26477983593940735
30-01-2023 17:39:23 INFO Epoch 2: [5226/10940] ---- BYOL Training Loss = 0.24250276386737823
30-01-2023 17:39:51 INFO Epoch 2: [5237/10940] ---- BYOL Training Loss = 0.30025359988212585
30-01-2023 17:41:19 INFO Epoch 2: [5237/10940] ---- BYOL Validation Loss = 0.2740662693977356
30-01-2023 17:41:47 INFO Epoch 2: [5248/10940] ---- BYOL Training Loss = 0.2696453630924225
30-01-2023 17:42:15 INFO Epoch 2: [5259/10940] ---- BYOL Training Loss = 0.23247785866260529
30-01-2023 17:42:43 INFO Epoch 2: [5270/10940] ---- BYOL Training Loss = 0.24840399622917175
30-01-2023 17:43:11 INFO Epoch 2: [5281/10940] ---- BYOL Training Loss = 0.26244235038757324
30-01-2023 17:44:39 INFO Epoch 2: [5281/10940] ---- BYOL Validation Loss = 0.2761700451374054
30-01-2023 17:45:07 INFO Epoch 2: [5292/10940] ---- BYOL Training Loss = 0.23390917479991913
30-01-2023 17:45:34 INFO Epoch 2: [5303/10940] ---- BYOL Training Loss = 0.23115774989128113
30-01-2023 17:46:02 INFO Epoch 2: [5314/10940] ---- BYOL Training Loss = 0.2212153971195221
30-01-2023 17:46:30 INFO Epoch 2: [5325/10940] ---- BYOL Training Loss = 0.22931969165802002
30-01-2023 17:47:58 INFO Epoch 2: [5325/10940] ---- BYOL Validation Loss = 0.2834301292896271
30-01-2023 17:48:26 INFO Epoch 2: [5336/10940] ---- BYOL Training Loss = 0.24172218143939972
30-01-2023 17:48:54 INFO Epoch 2: [5347/10940] ---- BYOL Training Loss = 0.2896267771720886
30-01-2023 17:49:22 INFO Epoch 2: [5358/10940] ---- BYOL Training Loss = 0.2461501657962799
30-01-2023 17:49:50 INFO Epoch 2: [5369/10940] ---- BYOL Training Loss = 0.24032115936279297
30-01-2023 17:51:18 INFO Epoch 2: [5369/10940] ---- BYOL Validation Loss = 0.259491503238678
30-01-2023 17:51:46 INFO Epoch 2: [5380/10940] ---- BYOL Training Loss = 0.22011002898216248
30-01-2023 17:52:14 INFO Epoch 2: [5391/10940] ---- BYOL Training Loss = 0.2551899552345276
30-01-2023 17:52:42 INFO Epoch 2: [5402/10940] ---- BYOL Training Loss = 0.31443724036216736
30-01-2023 17:53:09 INFO Epoch 2: [5413/10940] ---- BYOL Training Loss = 0.22802522778511047
30-01-2023 17:54:38 INFO Epoch 2: [5413/10940] ---- BYOL Validation Loss = 0.2634292542934418
30-01-2023 17:55:05 INFO Epoch 2: [5424/10940] ---- BYOL Training Loss = 0.2628353536128998
30-01-2023 17:55:33 INFO Epoch 2: [5435/10940] ---- BYOL Training Loss = 0.2835909128189087
30-01-2023 17:56:01 INFO Epoch 2: [5446/10940] ---- BYOL Training Loss = 0.27420225739479065
30-01-2023 17:56:29 INFO Epoch 2: [5457/10940] ---- BYOL Training Loss = 0.272548645734787
30-01-2023 17:57:57 INFO Epoch 2: [5457/10940] ---- BYOL Validation Loss = 0.2880095839500427
30-01-2023 17:58:25 INFO Epoch 2: [5468/10940] ---- BYOL Training Loss = 0.2859216332435608
30-01-2023 17:58:53 INFO Epoch 2: [5479/10940] ---- BYOL Training Loss = 0.24777254462242126
30-01-2023 17:59:20 INFO Epoch 2: [5490/10940] ---- BYOL Training Loss = 0.22529399394989014
30-01-2023 17:59:48 INFO Epoch 2: [5501/10940] ---- BYOL Training Loss = 0.2705512046813965
30-01-2023 18:01:16 INFO Epoch 2: [5501/10940] ---- BYOL Validation Loss = 0.2620144486427307
30-01-2023 18:01:44 INFO Epoch 2: [5512/10940] ---- BYOL Training Loss = 0.2727505564689636
30-01-2023 18:02:12 INFO Epoch 2: [5523/10940] ---- BYOL Training Loss = 0.2464839667081833
30-01-2023 18:02:40 INFO Epoch 2: [5534/10940] ---- BYOL Training Loss = 0.21586541831493378
30-01-2023 18:03:08 INFO Epoch 2: [5545/10940] ---- BYOL Training Loss = 0.2156399041414261
30-01-2023 18:04:36 INFO Epoch 2: [5545/10940] ---- BYOL Validation Loss = 0.26607999205589294
30-01-2023 18:05:04 INFO Epoch 2: [5556/10940] ---- BYOL Training Loss = 0.2800217270851135
30-01-2023 18:05:32 INFO Epoch 2: [5567/10940] ---- BYOL Training Loss = 0.28858333826065063
30-01-2023 18:06:00 INFO Epoch 2: [5578/10940] ---- BYOL Training Loss = 0.27511724829673767
30-01-2023 18:06:28 INFO Epoch 2: [5589/10940] ---- BYOL Training Loss = 0.2927570939064026
30-01-2023 18:07:56 INFO Epoch 2: [5589/10940] ---- BYOL Validation Loss = 0.27546828985214233
30-01-2023 18:08:24 INFO Epoch 2: [5600/10940] ---- BYOL Training Loss = 0.3169723153114319
30-01-2023 18:08:52 INFO Epoch 2: [5611/10940] ---- BYOL Training Loss = 0.3257594406604767
30-01-2023 18:09:20 INFO Epoch 2: [5622/10940] ---- BYOL Training Loss = 0.3089475631713867
30-01-2023 18:09:48 INFO Epoch 2: [5633/10940] ---- BYOL Training Loss = 0.2645602524280548
30-01-2023 18:11:16 INFO Epoch 2: [5633/10940] ---- BYOL Validation Loss = 0.2769549489021301
30-01-2023 18:11:44 INFO Epoch 2: [5644/10940] ---- BYOL Training Loss = 0.2523554861545563
30-01-2023 18:12:12 INFO Epoch 2: [5655/10940] ---- BYOL Training Loss = 0.2596302628517151
30-01-2023 18:12:40 INFO Epoch 2: [5666/10940] ---- BYOL Training Loss = 0.25356143712997437
30-01-2023 18:13:08 INFO Epoch 2: [5677/10940] ---- BYOL Training Loss = 0.26919203996658325
30-01-2023 18:14:37 INFO Epoch 2: [5677/10940] ---- BYOL Validation Loss = 0.2839411795139313
30-01-2023 18:15:04 INFO Epoch 2: [5688/10940] ---- BYOL Training Loss = 0.28345972299575806
30-01-2023 18:15:32 INFO Epoch 2: [5699/10940] ---- BYOL Training Loss = 0.26242440938949585
30-01-2023 18:16:00 INFO Epoch 2: [5710/10940] ---- BYOL Training Loss = 0.25152963399887085
30-01-2023 18:16:28 INFO Epoch 2: [5721/10940] ---- BYOL Training Loss = 0.25980111956596375
30-01-2023 18:17:56 INFO Epoch 2: [5721/10940] ---- BYOL Validation Loss = 0.26112890243530273
30-01-2023 18:18:24 INFO Epoch 2: [5732/10940] ---- BYOL Training Loss = 0.241389200091362
30-01-2023 18:18:52 INFO Epoch 2: [5743/10940] ---- BYOL Training Loss = 0.23462322354316711
30-01-2023 18:19:20 INFO Epoch 2: [5754/10940] ---- BYOL Training Loss = 0.24456533789634705
30-01-2023 18:19:48 INFO Epoch 2: [5765/10940] ---- BYOL Training Loss = 0.28504544496536255
30-01-2023 18:21:16 INFO Epoch 2: [5765/10940] ---- BYOL Validation Loss = 0.2722432017326355
30-01-2023 18:21:44 INFO Epoch 2: [5776/10940] ---- BYOL Training Loss = 0.26992368698120117
30-01-2023 18:22:12 INFO Epoch 2: [5787/10940] ---- BYOL Training Loss = 0.27821099758148193
30-01-2023 18:22:40 INFO Epoch 2: [5798/10940] ---- BYOL Training Loss = 0.33746588230133057
30-01-2023 18:23:07 INFO Epoch 2: [5809/10940] ---- BYOL Training Loss = 0.30473026633262634
30-01-2023 18:24:35 INFO Epoch 2: [5809/10940] ---- BYOL Validation Loss = 0.2622540593147278
30-01-2023 18:25:03 INFO Epoch 2: [5820/10940] ---- BYOL Training Loss = 0.2799607813358307
30-01-2023 18:25:31 INFO Epoch 2: [5831/10940] ---- BYOL Training Loss = 0.2362002581357956
30-01-2023 18:25:59 INFO Epoch 2: [5842/10940] ---- BYOL Training Loss = 0.22901365160942078
30-01-2023 18:26:27 INFO Epoch 2: [5853/10940] ---- BYOL Training Loss = 0.2560262084007263
30-01-2023 18:27:55 INFO Epoch 2: [5853/10940] ---- BYOL Validation Loss = 0.2684185206890106
30-01-2023 18:28:23 INFO Epoch 2: [5864/10940] ---- BYOL Training Loss = 0.28394174575805664
30-01-2023 18:28:51 INFO Epoch 2: [5875/10940] ---- BYOL Training Loss = 0.2898711860179901
30-01-2023 18:29:18 INFO Epoch 2: [5886/10940] ---- BYOL Training Loss = 0.24817058444023132
30-01-2023 18:29:46 INFO Epoch 2: [5897/10940] ---- BYOL Training Loss = 0.22769024968147278
30-01-2023 18:31:14 INFO Epoch 2: [5897/10940] ---- BYOL Validation Loss = 0.26358696818351746
30-01-2023 18:31:42 INFO Epoch 2: [5908/10940] ---- BYOL Training Loss = 0.24488838016986847
30-01-2023 18:32:10 INFO Epoch 2: [5919/10940] ---- BYOL Training Loss = 0.20490209758281708
30-01-2023 18:32:38 INFO Epoch 2: [5930/10940] ---- BYOL Training Loss = 0.22949855029582977
30-01-2023 18:33:06 INFO Epoch 2: [5941/10940] ---- BYOL Training Loss = 0.26750272512435913
30-01-2023 18:34:34 INFO Epoch 2: [5941/10940] ---- BYOL Validation Loss = 0.26254794001579285
30-01-2023 18:35:02 INFO Epoch 2: [5952/10940] ---- BYOL Training Loss = 0.28037112951278687
30-01-2023 18:35:30 INFO Epoch 2: [5963/10940] ---- BYOL Training Loss = 0.25625622272491455
30-01-2023 18:35:58 INFO Epoch 2: [5974/10940] ---- BYOL Training Loss = 0.2763996422290802
30-01-2023 18:36:26 INFO Epoch 2: [5985/10940] ---- BYOL Training Loss = 0.25101524591445923
30-01-2023 18:37:54 INFO Epoch 2: [5985/10940] ---- BYOL Validation Loss = 0.26884809136390686
30-01-2023 18:38:22 INFO Epoch 2: [5996/10940] ---- BYOL Training Loss = 0.3216855525970459
30-01-2023 18:38:50 INFO Epoch 2: [6007/10940] ---- BYOL Training Loss = 0.2883076071739197
30-01-2023 18:39:18 INFO Epoch 2: [6018/10940] ---- BYOL Training Loss = 0.23562034964561462
30-01-2023 18:39:46 INFO Epoch 2: [6029/10940] ---- BYOL Training Loss = 0.2651110589504242
30-01-2023 18:41:14 INFO Epoch 2: [6029/10940] ---- BYOL Validation Loss = 0.2686934173107147
30-01-2023 18:41:42 INFO Epoch 2: [6040/10940] ---- BYOL Training Loss = 0.2725968360900879
30-01-2023 18:42:10 INFO Epoch 2: [6051/10940] ---- BYOL Training Loss = 0.264181911945343
30-01-2023 18:42:38 INFO Epoch 2: [6062/10940] ---- BYOL Training Loss = 0.26029127836227417
30-01-2023 18:43:06 INFO Epoch 2: [6073/10940] ---- BYOL Training Loss = 0.2776791453361511
30-01-2023 18:44:34 INFO Epoch 2: [6073/10940] ---- BYOL Validation Loss = 0.2647385895252228
30-01-2023 18:45:02 INFO Epoch 2: [6084/10940] ---- BYOL Training Loss = 0.27352795004844666
30-01-2023 18:45:30 INFO Epoch 2: [6095/10940] ---- BYOL Training Loss = 0.2651887536048889
30-01-2023 18:45:58 INFO Epoch 2: [6106/10940] ---- BYOL Training Loss = 0.2876730263233185
30-01-2023 18:46:26 INFO Epoch 2: [6117/10940] ---- BYOL Training Loss = 0.3149983584880829
30-01-2023 18:47:54 INFO Epoch 2: [6117/10940] ---- BYOL Validation Loss = 0.27911925315856934
30-01-2023 18:48:22 INFO Epoch 2: [6128/10940] ---- BYOL Training Loss = 0.3153325915336609
30-01-2023 18:48:50 INFO Epoch 2: [6139/10940] ---- BYOL Training Loss = 0.3156278431415558
30-01-2023 18:49:18 INFO Epoch 2: [6150/10940] ---- BYOL Training Loss = 0.30236923694610596
30-01-2023 18:49:46 INFO Epoch 2: [6161/10940] ---- BYOL Training Loss = 0.25177252292633057
30-01-2023 18:51:14 INFO Epoch 2: [6161/10940] ---- BYOL Validation Loss = 0.2800353467464447
30-01-2023 18:51:42 INFO Epoch 2: [6172/10940] ---- BYOL Training Loss = 0.26371872425079346
30-01-2023 18:52:10 INFO Epoch 2: [6183/10940] ---- BYOL Training Loss = 0.27225062251091003
30-01-2023 18:52:39 INFO Epoch 2: [6194/10940] ---- BYOL Training Loss = 0.25288334488868713
30-01-2023 18:53:06 INFO Epoch 2: [6205/10940] ---- BYOL Training Loss = 0.24321499466896057
30-01-2023 18:54:34 INFO Epoch 2: [6205/10940] ---- BYOL Validation Loss = 0.27082106471061707
30-01-2023 18:55:02 INFO Epoch 2: [6216/10940] ---- BYOL Training Loss = 0.24659454822540283
30-01-2023 18:55:30 INFO Epoch 2: [6227/10940] ---- BYOL Training Loss = 0.230500265955925
30-01-2023 18:55:58 INFO Epoch 2: [6238/10940] ---- BYOL Training Loss = 0.2883226275444031
30-01-2023 18:56:26 INFO Epoch 2: [6249/10940] ---- BYOL Training Loss = 0.2587665319442749
30-01-2023 18:57:54 INFO Epoch 2: [6249/10940] ---- BYOL Validation Loss = 0.26896587014198303
30-01-2023 18:58:22 INFO Epoch 2: [6260/10940] ---- BYOL Training Loss = 0.25401192903518677
30-01-2023 18:58:50 INFO Epoch 2: [6271/10940] ---- BYOL Training Loss = 0.2582556903362274
30-01-2023 18:59:19 INFO Epoch 2: [6282/10940] ---- BYOL Training Loss = 0.26685529947280884
30-01-2023 18:59:46 INFO Epoch 2: [6293/10940] ---- BYOL Training Loss = 0.23410138487815857
30-01-2023 19:01:15 INFO Epoch 2: [6293/10940] ---- BYOL Validation Loss = 0.2717800736427307
30-01-2023 19:01:43 INFO Epoch 2: [6304/10940] ---- BYOL Training Loss = 0.25825637578964233
30-01-2023 19:02:11 INFO Epoch 2: [6315/10940] ---- BYOL Training Loss = 0.27232328057289124
30-01-2023 19:02:39 INFO Epoch 2: [6326/10940] ---- BYOL Training Loss = 0.2659860849380493
30-01-2023 19:03:07 INFO Epoch 2: [6337/10940] ---- BYOL Training Loss = 0.2847955524921417
30-01-2023 19:04:35 INFO Epoch 2: [6337/10940] ---- BYOL Validation Loss = 0.26728156208992004
30-01-2023 19:05:03 INFO Epoch 2: [6348/10940] ---- BYOL Training Loss = 0.2847209572792053
30-01-2023 19:05:31 INFO Epoch 2: [6359/10940] ---- BYOL Training Loss = 0.2625831961631775
30-01-2023 19:05:59 INFO Epoch 2: [6370/10940] ---- BYOL Training Loss = 0.25413089990615845
30-01-2023 19:06:27 INFO Epoch 2: [6381/10940] ---- BYOL Training Loss = 0.30635523796081543
30-01-2023 19:07:55 INFO Epoch 2: [6381/10940] ---- BYOL Validation Loss = 0.2900555729866028
30-01-2023 19:08:23 INFO Epoch 2: [6392/10940] ---- BYOL Training Loss = 0.28482407331466675
30-01-2023 19:08:51 INFO Epoch 2: [6403/10940] ---- BYOL Training Loss = 0.27920016646385193
30-01-2023 19:09:19 INFO Epoch 2: [6414/10940] ---- BYOL Training Loss = 0.27322322130203247
30-01-2023 19:09:47 INFO Epoch 2: [6425/10940] ---- BYOL Training Loss = 0.23377327620983124
30-01-2023 19:11:15 INFO Epoch 2: [6425/10940] ---- BYOL Validation Loss = 0.2768218219280243
30-01-2023 19:11:44 INFO Epoch 2: [6436/10940] ---- BYOL Training Loss = 0.24647672474384308
30-01-2023 19:12:12 INFO Epoch 2: [6447/10940] ---- BYOL Training Loss = 0.24112510681152344
30-01-2023 19:12:39 INFO Epoch 2: [6458/10940] ---- BYOL Training Loss = 0.24881276488304138
30-01-2023 19:13:07 INFO Epoch 2: [6469/10940] ---- BYOL Training Loss = 0.29877230525016785
30-01-2023 19:14:36 INFO Epoch 2: [6469/10940] ---- BYOL Validation Loss = 0.2622039020061493
30-01-2023 19:15:04 INFO Epoch 2: [6480/10940] ---- BYOL Training Loss = 0.2761530876159668
30-01-2023 19:15:31 INFO Epoch 2: [6491/10940] ---- BYOL Training Loss = 0.26800936460494995
30-01-2023 19:15:59 INFO Epoch 2: [6502/10940] ---- BYOL Training Loss = 0.28598636388778687
30-01-2023 19:16:28 INFO Epoch 2: [6513/10940] ---- BYOL Training Loss = 0.27006328105926514
30-01-2023 19:17:56 INFO Epoch 2: [6513/10940] ---- BYOL Validation Loss = 0.27503255009651184
30-01-2023 19:18:24 INFO Epoch 2: [6524/10940] ---- BYOL Training Loss = 0.22525301575660706
30-01-2023 19:18:52 INFO Epoch 2: [6535/10940] ---- BYOL Training Loss = 0.2688584327697754
30-01-2023 19:19:20 INFO Epoch 2: [6546/10940] ---- BYOL Training Loss = 0.27220800518989563
30-01-2023 19:19:48 INFO Epoch 2: [6557/10940] ---- BYOL Training Loss = 0.2771754860877991
30-01-2023 19:21:16 INFO Epoch 2: [6557/10940] ---- BYOL Validation Loss = 0.26765522360801697
30-01-2023 19:21:44 INFO Epoch 2: [6568/10940] ---- BYOL Training Loss = 0.24536433815956116
30-01-2023 19:22:12 INFO Epoch 2: [6579/10940] ---- BYOL Training Loss = 0.23765583336353302
30-01-2023 19:22:40 INFO Epoch 2: [6590/10940] ---- BYOL Training Loss = 0.24527695775032043
30-01-2023 19:23:08 INFO Epoch 2: [6601/10940] ---- BYOL Training Loss = 0.2620449364185333
30-01-2023 19:24:36 INFO Epoch 2: [6601/10940] ---- BYOL Validation Loss = 0.26490214467048645
30-01-2023 19:25:04 INFO Epoch 2: [6612/10940] ---- BYOL Training Loss = 0.25522667169570923
30-01-2023 19:25:33 INFO Epoch 2: [6623/10940] ---- BYOL Training Loss = 0.2771620452404022
30-01-2023 19:26:01 INFO Epoch 2: [6634/10940] ---- BYOL Training Loss = 0.288203626871109
30-01-2023 19:26:29 INFO Epoch 2: [6645/10940] ---- BYOL Training Loss = 0.2918241322040558
30-01-2023 19:27:57 INFO Epoch 2: [6645/10940] ---- BYOL Validation Loss = 0.28079843521118164
30-01-2023 19:28:25 INFO Epoch 2: [6656/10940] ---- BYOL Training Loss = 0.2845503091812134
30-01-2023 19:28:54 INFO Epoch 2: [6667/10940] ---- BYOL Training Loss = 0.27949437499046326
30-01-2023 19:29:22 INFO Epoch 2: [6678/10940] ---- BYOL Training Loss = 0.28824740648269653
30-01-2023 19:29:50 INFO Epoch 2: [6689/10940] ---- BYOL Training Loss = 0.2518983483314514
30-01-2023 19:31:18 INFO Epoch 2: [6689/10940] ---- BYOL Validation Loss = 0.274331659078598
30-01-2023 19:31:46 INFO Epoch 2: [6700/10940] ---- BYOL Training Loss = 0.2546314299106598
30-01-2023 19:32:14 INFO Epoch 2: [6711/10940] ---- BYOL Training Loss = 0.23801454901695251
30-01-2023 19:32:42 INFO Epoch 2: [6722/10940] ---- BYOL Training Loss = 0.17143306136131287
30-01-2023 19:33:10 INFO Epoch 2: [6733/10940] ---- BYOL Training Loss = 0.2500258684158325
30-01-2023 19:34:39 INFO Epoch 2: [6733/10940] ---- BYOL Validation Loss = 0.2587398588657379
30-01-2023 19:35:07 INFO Epoch 2: [6744/10940] ---- BYOL Training Loss = 0.2634302079677582
30-01-2023 19:35:35 INFO Epoch 2: [6755/10940] ---- BYOL Training Loss = 0.27266746759414673
30-01-2023 19:36:03 INFO Epoch 2: [6766/10940] ---- BYOL Training Loss = 0.26593998074531555
30-01-2023 19:36:31 INFO Epoch 2: [6777/10940] ---- BYOL Training Loss = 0.25211670994758606
30-01-2023 19:37:59 INFO Epoch 2: [6777/10940] ---- BYOL Validation Loss = 0.269408643245697
30-01-2023 19:38:28 INFO Epoch 2: [6788/10940] ---- BYOL Training Loss = 0.3330005407333374
30-01-2023 19:38:55 INFO Epoch 2: [6799/10940] ---- BYOL Training Loss = 0.35218971967697144
30-01-2023 19:39:24 INFO Epoch 2: [6810/10940] ---- BYOL Training Loss = 0.30219343304634094
30-01-2023 19:39:52 INFO Epoch 2: [6821/10940] ---- BYOL Training Loss = 0.24927350878715515
30-01-2023 19:41:20 INFO Epoch 2: [6821/10940] ---- BYOL Validation Loss = 0.2692641317844391
30-01-2023 19:41:48 INFO Epoch 2: [6832/10940] ---- BYOL Training Loss = 0.21010009944438934
30-01-2023 19:42:16 INFO Epoch 2: [6843/10940] ---- BYOL Training Loss = 0.2674284279346466
30-01-2023 19:42:44 INFO Epoch 2: [6854/10940] ---- BYOL Training Loss = 0.27221423387527466
30-01-2023 19:43:13 INFO Epoch 2: [6865/10940] ---- BYOL Training Loss = 0.2440805435180664
30-01-2023 19:44:41 INFO Epoch 2: [6865/10940] ---- BYOL Validation Loss = 0.2811375558376312
30-01-2023 19:45:09 INFO Epoch 2: [6876/10940] ---- BYOL Training Loss = 0.22773465514183044
30-01-2023 19:45:37 INFO Epoch 2: [6887/10940] ---- BYOL Training Loss = 0.2870469093322754
30-01-2023 19:46:06 INFO Epoch 2: [6898/10940] ---- BYOL Training Loss = 0.33180147409439087
30-01-2023 19:46:34 INFO Epoch 2: [6909/10940] ---- BYOL Training Loss = 0.27674442529678345
30-01-2023 19:48:02 INFO Epoch 2: [6909/10940] ---- BYOL Validation Loss = 0.28331565856933594
30-01-2023 19:48:30 INFO Epoch 2: [6920/10940] ---- BYOL Training Loss = 0.25123393535614014
30-01-2023 19:48:58 INFO Epoch 2: [6931/10940] ---- BYOL Training Loss = 0.26074081659317017
30-01-2023 19:49:26 INFO Epoch 2: [6942/10940] ---- BYOL Training Loss = 0.2702862024307251
30-01-2023 19:49:54 INFO Epoch 2: [6953/10940] ---- BYOL Training Loss = 0.28890737891197205
30-01-2023 19:51:23 INFO Epoch 2: [6953/10940] ---- BYOL Validation Loss = 0.2759997546672821
30-01-2023 19:51:51 INFO Epoch 2: [6964/10940] ---- BYOL Training Loss = 0.2898174822330475
30-01-2023 19:52:19 INFO Epoch 2: [6975/10940] ---- BYOL Training Loss = 0.28388985991477966
30-01-2023 19:52:47 INFO Epoch 2: [6986/10940] ---- BYOL Training Loss = 0.2523496747016907
30-01-2023 19:53:15 INFO Epoch 2: [6997/10940] ---- BYOL Training Loss = 0.27690672874450684
30-01-2023 19:54:43 INFO Epoch 2: [6997/10940] ---- BYOL Validation Loss = 0.2747913599014282
30-01-2023 19:55:11 INFO Epoch 2: [7008/10940] ---- BYOL Training Loss = 0.27617576718330383
30-01-2023 19:55:40 INFO Epoch 2: [7019/10940] ---- BYOL Training Loss = 0.2671002745628357
30-01-2023 19:56:08 INFO Epoch 2: [7030/10940] ---- BYOL Training Loss = 0.2884419858455658
30-01-2023 19:56:36 INFO Epoch 2: [7041/10940] ---- BYOL Training Loss = 0.2638585865497589
30-01-2023 19:58:04 INFO Epoch 2: [7041/10940] ---- BYOL Validation Loss = 0.28163066506385803
30-01-2023 19:58:32 INFO Epoch 2: [7052/10940] ---- BYOL Training Loss = 0.28911176323890686
30-01-2023 19:59:00 INFO Epoch 2: [7063/10940] ---- BYOL Training Loss = 0.3204434812068939
30-01-2023 19:59:28 INFO Epoch 2: [7074/10940] ---- BYOL Training Loss = 0.3001594841480255
30-01-2023 19:59:56 INFO Epoch 2: [7085/10940] ---- BYOL Training Loss = 0.2624751031398773
30-01-2023 20:01:25 INFO Epoch 2: [7085/10940] ---- BYOL Validation Loss = 0.27156561613082886
30-01-2023 20:01:53 INFO Epoch 2: [7096/10940] ---- BYOL Training Loss = 0.21779346466064453
30-01-2023 20:02:21 INFO Epoch 2: [7107/10940] ---- BYOL Training Loss = 0.21631142497062683
30-01-2023 20:02:49 INFO Epoch 2: [7118/10940] ---- BYOL Training Loss = 0.2842952609062195
30-01-2023 20:03:17 INFO Epoch 2: [7129/10940] ---- BYOL Training Loss = 0.3096798062324524
30-01-2023 20:04:46 INFO Epoch 2: [7129/10940] ---- BYOL Validation Loss = 0.2704620361328125
30-01-2023 20:05:14 INFO Epoch 2: [7140/10940] ---- BYOL Training Loss = 0.2347114086151123
30-01-2023 20:05:42 INFO Epoch 2: [7151/10940] ---- BYOL Training Loss = 0.22476506233215332
30-01-2023 20:06:10 INFO Epoch 2: [7162/10940] ---- BYOL Training Loss = 0.22269511222839355
30-01-2023 20:06:38 INFO Epoch 2: [7173/10940] ---- BYOL Training Loss = 0.23756837844848633
30-01-2023 20:08:06 INFO Epoch 2: [7173/10940] ---- BYOL Validation Loss = 0.27337294816970825
30-01-2023 20:08:34 INFO Epoch 2: [7184/10940] ---- BYOL Training Loss = 0.22250287234783173
30-01-2023 20:09:03 INFO Epoch 2: [7195/10940] ---- BYOL Training Loss = 0.25913041830062866
30-01-2023 20:09:31 INFO Epoch 2: [7206/10940] ---- BYOL Training Loss = 0.2818620204925537
30-01-2023 20:09:59 INFO Epoch 2: [7217/10940] ---- BYOL Training Loss = 0.23122763633728027
30-01-2023 20:11:27 INFO Epoch 2: [7217/10940] ---- BYOL Validation Loss = 0.26042360067367554
30-01-2023 20:11:55 INFO Epoch 2: [7228/10940] ---- BYOL Training Loss = 0.23008425533771515
30-01-2023 20:12:24 INFO Epoch 2: [7239/10940] ---- BYOL Training Loss = 0.32409003376960754
30-01-2023 20:12:52 INFO Epoch 2: [7250/10940] ---- BYOL Training Loss = 0.2918410897254944
30-01-2023 20:13:20 INFO Epoch 2: [7261/10940] ---- BYOL Training Loss = 0.24662718176841736
30-01-2023 20:14:48 INFO Epoch 2: [7261/10940] ---- BYOL Validation Loss = 0.26453977823257446
30-01-2023 20:15:16 INFO Epoch 2: [7272/10940] ---- BYOL Training Loss = 0.26591169834136963
30-01-2023 20:15:44 INFO Epoch 2: [7283/10940] ---- BYOL Training Loss = 0.2805934548377991
30-01-2023 20:16:13 INFO Epoch 2: [7294/10940] ---- BYOL Training Loss = 0.2791600823402405
30-01-2023 20:16:41 INFO Epoch 2: [7305/10940] ---- BYOL Training Loss = 0.3269566297531128
30-01-2023 20:18:09 INFO Epoch 2: [7305/10940] ---- BYOL Validation Loss = 0.2706981301307678
30-01-2023 20:18:37 INFO Epoch 2: [7316/10940] ---- BYOL Training Loss = 0.2817021906375885
30-01-2023 20:19:05 INFO Epoch 2: [7327/10940] ---- BYOL Training Loss = 0.2569788098335266
30-01-2023 20:19:33 INFO Epoch 2: [7338/10940] ---- BYOL Training Loss = 0.30090755224227905
30-01-2023 20:20:01 INFO Epoch 2: [7349/10940] ---- BYOL Training Loss = 0.3129670023918152
30-01-2023 20:21:30 INFO Epoch 2: [7349/10940] ---- BYOL Validation Loss = 0.27589091658592224
30-01-2023 20:21:58 INFO Epoch 2: [7360/10940] ---- BYOL Training Loss = 0.23908035457134247
30-01-2023 20:22:26 INFO Epoch 2: [7371/10940] ---- BYOL Training Loss = 0.21966557204723358
30-01-2023 20:22:54 INFO Epoch 2: [7382/10940] ---- BYOL Training Loss = 0.25125351548194885
30-01-2023 20:23:22 INFO Epoch 2: [7393/10940] ---- BYOL Training Loss = 0.23692552745342255
30-01-2023 20:24:51 INFO Epoch 2: [7393/10940] ---- BYOL Validation Loss = 0.2634061276912689
30-01-2023 20:25:19 INFO Epoch 2: [7404/10940] ---- BYOL Training Loss = 0.2010924518108368
30-01-2023 20:25:47 INFO Epoch 2: [7415/10940] ---- BYOL Training Loss = 0.289737731218338
30-01-2023 20:26:15 INFO Epoch 2: [7426/10940] ---- BYOL Training Loss = 0.3161136507987976
30-01-2023 20:26:43 INFO Epoch 2: [7437/10940] ---- BYOL Training Loss = 0.31070563197135925
30-01-2023 20:28:12 INFO Epoch 2: [7437/10940] ---- BYOL Validation Loss = 0.2747601866722107
30-01-2023 20:28:40 INFO Epoch 2: [7448/10940] ---- BYOL Training Loss = 0.33556410670280457
30-01-2023 20:29:08 INFO Epoch 2: [7459/10940] ---- BYOL Training Loss = 0.3076532781124115
30-01-2023 20:29:36 INFO Epoch 2: [7470/10940] ---- BYOL Training Loss = 0.2801405191421509
30-01-2023 20:30:04 INFO Epoch 2: [7481/10940] ---- BYOL Training Loss = 0.27693048119544983
30-01-2023 20:31:32 INFO Epoch 2: [7481/10940] ---- BYOL Validation Loss = 0.27270323038101196
30-01-2023 20:32:01 INFO Epoch 2: [7492/10940] ---- BYOL Training Loss = 0.2597246766090393
30-01-2023 20:32:29 INFO Epoch 2: [7503/10940] ---- BYOL Training Loss = 0.30142316222190857
30-01-2023 20:32:57 INFO Epoch 2: [7514/10940] ---- BYOL Training Loss = 0.2629626393318176
30-01-2023 20:33:26 INFO Epoch 2: [7525/10940] ---- BYOL Training Loss = 0.24276070296764374
30-01-2023 20:34:54 INFO Epoch 2: [7525/10940] ---- BYOL Validation Loss = 0.25958266854286194
30-01-2023 20:35:22 INFO Epoch 2: [7536/10940] ---- BYOL Training Loss = 0.24088744819164276
30-01-2023 20:35:50 INFO Epoch 2: [7547/10940] ---- BYOL Training Loss = 0.2962711751461029
30-01-2023 20:36:18 INFO Epoch 2: [7558/10940] ---- BYOL Training Loss = 0.3326156735420227
30-01-2023 20:36:46 INFO Epoch 2: [7569/10940] ---- BYOL Training Loss = 0.28924116492271423
30-01-2023 20:38:15 INFO Epoch 2: [7569/10940] ---- BYOL Validation Loss = 0.26662734150886536
30-01-2023 20:38:43 INFO Epoch 2: [7580/10940] ---- BYOL Training Loss = 0.22101755440235138
30-01-2023 20:39:11 INFO Epoch 2: [7591/10940] ---- BYOL Training Loss = 0.26906728744506836
30-01-2023 20:39:39 INFO Epoch 2: [7602/10940] ---- BYOL Training Loss = 0.2619633078575134
30-01-2023 20:40:08 INFO Epoch 2: [7613/10940] ---- BYOL Training Loss = 0.25903910398483276
30-01-2023 20:41:36 INFO Epoch 2: [7613/10940] ---- BYOL Validation Loss = 0.2595553994178772
30-01-2023 20:42:05 INFO Epoch 2: [7624/10940] ---- BYOL Training Loss = 0.2869182527065277
30-01-2023 20:42:33 INFO Epoch 2: [7635/10940] ---- BYOL Training Loss = 0.3073684275150299
30-01-2023 20:43:01 INFO Epoch 2: [7646/10940] ---- BYOL Training Loss = 0.28672850131988525
30-01-2023 20:43:29 INFO Epoch 2: [7657/10940] ---- BYOL Training Loss = 0.2490825653076172
30-01-2023 20:44:57 INFO Epoch 2: [7657/10940] ---- BYOL Validation Loss = 0.2657541334629059
30-01-2023 20:45:26 INFO Epoch 2: [7668/10940] ---- BYOL Training Loss = 0.2756350338459015
30-01-2023 20:45:54 INFO Epoch 2: [7679/10940] ---- BYOL Training Loss = 0.2831871509552002
30-01-2023 20:46:22 INFO Epoch 2: [7690/10940] ---- BYOL Training Loss = 0.26352745294570923
30-01-2023 20:46:50 INFO Epoch 2: [7701/10940] ---- BYOL Training Loss = 0.23987257480621338
30-01-2023 20:48:18 INFO Epoch 2: [7701/10940] ---- BYOL Validation Loss = 0.2686859667301178
30-01-2023 20:48:46 INFO Epoch 2: [7712/10940] ---- BYOL Training Loss = 0.23593497276306152
30-01-2023 20:49:15 INFO Epoch 2: [7723/10940] ---- BYOL Training Loss = 0.27113986015319824
30-01-2023 20:49:43 INFO Epoch 2: [7734/10940] ---- BYOL Training Loss = 0.2596065402030945
30-01-2023 20:50:11 INFO Epoch 2: [7745/10940] ---- BYOL Training Loss = 0.2590191662311554
30-01-2023 20:51:40 INFO Epoch 2: [7745/10940] ---- BYOL Validation Loss = 0.2624206244945526
30-01-2023 20:52:08 INFO Epoch 2: [7756/10940] ---- BYOL Training Loss = 0.3333626091480255
30-01-2023 20:52:36 INFO Epoch 2: [7767/10940] ---- BYOL Training Loss = 0.32579320669174194
30-01-2023 20:53:04 INFO Epoch 2: [7778/10940] ---- BYOL Training Loss = 0.2757945954799652
30-01-2023 20:53:33 INFO Epoch 2: [7789/10940] ---- BYOL Training Loss = 0.2372605800628662
30-01-2023 20:55:01 INFO Epoch 2: [7789/10940] ---- BYOL Validation Loss = 0.2680482566356659
30-01-2023 20:55:29 INFO Epoch 2: [7800/10940] ---- BYOL Training Loss = 0.2212444245815277
30-01-2023 20:55:57 INFO Epoch 2: [7811/10940] ---- BYOL Training Loss = 0.2710041403770447
30-01-2023 20:56:26 INFO Epoch 2: [7822/10940] ---- BYOL Training Loss = 0.28902941942214966
30-01-2023 20:56:54 INFO Epoch 2: [7833/10940] ---- BYOL Training Loss = 0.2948727607727051
30-01-2023 20:58:22 INFO Epoch 2: [7833/10940] ---- BYOL Validation Loss = 0.26812857389450073
30-01-2023 20:58:50 INFO Epoch 2: [7844/10940] ---- BYOL Training Loss = 0.27690431475639343
30-01-2023 20:59:19 INFO Epoch 2: [7855/10940] ---- BYOL Training Loss = 0.27138757705688477
30-01-2023 20:59:47 INFO Epoch 2: [7866/10940] ---- BYOL Training Loss = 0.26463809609413147
30-01-2023 21:00:15 INFO Epoch 2: [7877/10940] ---- BYOL Training Loss = 0.31724098324775696
30-01-2023 21:01:44 INFO Epoch 2: [7877/10940] ---- BYOL Validation Loss = 0.275286465883255
30-01-2023 21:02:12 INFO Epoch 2: [7888/10940] ---- BYOL Training Loss = 0.2636914551258087
30-01-2023 21:02:40 INFO Epoch 2: [7899/10940] ---- BYOL Training Loss = 0.2168365716934204
30-01-2023 21:03:08 INFO Epoch 2: [7910/10940] ---- BYOL Training Loss = 0.2370423525571823
30-01-2023 21:03:37 INFO Epoch 2: [7921/10940] ---- BYOL Training Loss = 0.24353186786174774
30-01-2023 21:05:05 INFO Epoch 2: [7921/10940] ---- BYOL Validation Loss = 0.2686564028263092
30-01-2023 21:05:33 INFO Epoch 2: [7932/10940] ---- BYOL Training Loss = 0.250923752784729
30-01-2023 21:06:01 INFO Epoch 2: [7943/10940] ---- BYOL Training Loss = 0.2448006570339203
30-01-2023 21:06:30 INFO Epoch 2: [7954/10940] ---- BYOL Training Loss = 0.2453194409608841
30-01-2023 21:06:58 INFO Epoch 2: [7965/10940] ---- BYOL Training Loss = 0.2546986937522888
30-01-2023 21:08:27 INFO Epoch 2: [7965/10940] ---- BYOL Validation Loss = 0.2614426910877228
30-01-2023 21:08:55 INFO Epoch 2: [7976/10940] ---- BYOL Training Loss = 0.24694308638572693
30-01-2023 21:09:23 INFO Epoch 2: [7987/10940] ---- BYOL Training Loss = 0.26417404413223267
30-01-2023 21:09:51 INFO Epoch 2: [7998/10940] ---- BYOL Training Loss = 0.32358914613723755
30-01-2023 21:10:20 INFO Epoch 2: [8009/10940] ---- BYOL Training Loss = 0.28806406259536743
30-01-2023 21:11:48 INFO Epoch 2: [8009/10940] ---- BYOL Validation Loss = 0.28563952445983887
30-01-2023 21:12:16 INFO Epoch 2: [8020/10940] ---- BYOL Training Loss = 0.26261550188064575
30-01-2023 21:12:45 INFO Epoch 2: [8031/10940] ---- BYOL Training Loss = 0.29744988679885864
30-01-2023 21:13:13 INFO Epoch 2: [8042/10940] ---- BYOL Training Loss = 0.2913389503955841
30-01-2023 21:13:41 INFO Epoch 2: [8053/10940] ---- BYOL Training Loss = 0.26532983779907227
30-01-2023 21:15:09 INFO Epoch 2: [8053/10940] ---- BYOL Validation Loss = 0.27334269881248474
30-01-2023 21:15:38 INFO Epoch 2: [8064/10940] ---- BYOL Training Loss = 0.2680073082447052
30-01-2023 21:16:06 INFO Epoch 2: [8075/10940] ---- BYOL Training Loss = 0.26630231738090515
30-01-2023 21:16:34 INFO Epoch 2: [8086/10940] ---- BYOL Training Loss = 0.2772996425628662
30-01-2023 21:17:02 INFO Epoch 2: [8097/10940] ---- BYOL Training Loss = 0.3006138801574707
30-01-2023 21:18:31 INFO Epoch 2: [8097/10940] ---- BYOL Validation Loss = 0.27448770403862
30-01-2023 21:18:59 INFO Epoch 2: [8108/10940] ---- BYOL Training Loss = 0.25164103507995605
30-01-2023 21:19:27 INFO Epoch 2: [8119/10940] ---- BYOL Training Loss = 0.2168327122926712
30-01-2023 21:19:55 INFO Epoch 2: [8130/10940] ---- BYOL Training Loss = 0.2811007499694824
30-01-2023 21:20:24 INFO Epoch 2: [8141/10940] ---- BYOL Training Loss = 0.28283634781837463
30-01-2023 21:21:53 INFO Epoch 2: [8141/10940] ---- BYOL Validation Loss = 0.2743806838989258
30-01-2023 21:22:21 INFO Epoch 2: [8152/10940] ---- BYOL Training Loss = 0.27218523621559143
30-01-2023 21:22:49 INFO Epoch 2: [8163/10940] ---- BYOL Training Loss = 0.2894682288169861
30-01-2023 21:23:18 INFO Epoch 2: [8174/10940] ---- BYOL Training Loss = 0.3025493323802948
30-01-2023 21:23:46 INFO Epoch 2: [8185/10940] ---- BYOL Training Loss = 0.28947731852531433
30-01-2023 21:25:14 INFO Epoch 2: [8185/10940] ---- BYOL Validation Loss = 0.26946601271629333
30-01-2023 21:25:42 INFO Epoch 2: [8196/10940] ---- BYOL Training Loss = 0.3116166889667511
30-01-2023 21:26:11 INFO Epoch 2: [8207/10940] ---- BYOL Training Loss = 0.2969933748245239
30-01-2023 21:26:39 INFO Epoch 2: [8218/10940] ---- BYOL Training Loss = 0.2557303309440613
30-01-2023 21:27:07 INFO Epoch 2: [8229/10940] ---- BYOL Training Loss = 0.23494306206703186
30-01-2023 21:28:36 INFO Epoch 2: [8229/10940] ---- BYOL Validation Loss = 0.2679283320903778
30-01-2023 21:29:04 INFO Epoch 2: [8240/10940] ---- BYOL Training Loss = 0.24937503039836884
30-01-2023 21:29:32 INFO Epoch 2: [8251/10940] ---- BYOL Training Loss = 0.2410585880279541
30-01-2023 21:30:01 INFO Epoch 2: [8262/10940] ---- BYOL Training Loss = 0.1979561746120453
30-01-2023 21:30:29 INFO Epoch 2: [8273/10940] ---- BYOL Training Loss = 0.2161586731672287
30-01-2023 21:31:57 INFO Epoch 2: [8273/10940] ---- BYOL Validation Loss = 0.2696502208709717
30-01-2023 21:32:25 INFO Epoch 2: [8284/10940] ---- BYOL Training Loss = 0.2469961941242218
30-01-2023 21:32:54 INFO Epoch 2: [8295/10940] ---- BYOL Training Loss = 0.2881353497505188
30-01-2023 21:33:22 INFO Epoch 2: [8306/10940] ---- BYOL Training Loss = 0.2964826226234436
30-01-2023 21:33:50 INFO Epoch 2: [8317/10940] ---- BYOL Training Loss = 0.24097271263599396
30-01-2023 21:35:19 INFO Epoch 2: [8317/10940] ---- BYOL Validation Loss = 0.2652345597743988
30-01-2023 21:35:47 INFO Epoch 2: [8328/10940] ---- BYOL Training Loss = 0.24887016415596008
30-01-2023 21:36:16 INFO Epoch 2: [8339/10940] ---- BYOL Training Loss = 0.28199517726898193
30-01-2023 21:36:44 INFO Epoch 2: [8350/10940] ---- BYOL Training Loss = 0.32543373107910156
30-01-2023 21:37:12 INFO Epoch 2: [8361/10940] ---- BYOL Training Loss = 0.28807851672172546
30-01-2023 21:38:40 INFO Epoch 2: [8361/10940] ---- BYOL Validation Loss = 0.27251845598220825
30-01-2023 21:39:08 INFO Epoch 2: [8372/10940] ---- BYOL Training Loss = 0.2444370537996292
30-01-2023 21:39:37 INFO Epoch 2: [8383/10940] ---- BYOL Training Loss = 0.27903109788894653
30-01-2023 21:40:06 INFO Epoch 2: [8394/10940] ---- BYOL Training Loss = 0.2669134736061096
30-01-2023 21:40:34 INFO Epoch 2: [8405/10940] ---- BYOL Training Loss = 0.2449144572019577
30-01-2023 21:42:02 INFO Epoch 2: [8405/10940] ---- BYOL Validation Loss = 0.26164793968200684
30-01-2023 21:42:30 INFO Epoch 2: [8416/10940] ---- BYOL Training Loss = 0.2889280319213867
30-01-2023 21:42:59 INFO Epoch 2: [8427/10940] ---- BYOL Training Loss = 0.2780941128730774
30-01-2023 21:43:27 INFO Epoch 2: [8438/10940] ---- BYOL Training Loss = 0.26813778281211853
30-01-2023 21:43:55 INFO Epoch 2: [8449/10940] ---- BYOL Training Loss = 0.2403702288866043
30-01-2023 21:45:23 INFO Epoch 2: [8449/10940] ---- BYOL Validation Loss = 0.2682657539844513
30-01-2023 21:45:51 INFO Epoch 2: [8460/10940] ---- BYOL Training Loss = 0.2843110263347626
30-01-2023 21:46:19 INFO Epoch 2: [8471/10940] ---- BYOL Training Loss = 0.3033933639526367
30-01-2023 21:46:48 INFO Epoch 2: [8482/10940] ---- BYOL Training Loss = 0.275852769613266
30-01-2023 21:47:16 INFO Epoch 2: [8493/10940] ---- BYOL Training Loss = 0.24852398037910461
30-01-2023 21:48:45 INFO Epoch 2: [8493/10940] ---- BYOL Validation Loss = 0.2637058198451996
30-01-2023 21:49:13 INFO Epoch 2: [8504/10940] ---- BYOL Training Loss = 0.2774902582168579
30-01-2023 21:49:41 INFO Epoch 2: [8515/10940] ---- BYOL Training Loss = 0.2936975955963135
30-01-2023 21:50:10 INFO Epoch 2: [8526/10940] ---- BYOL Training Loss = 0.26194775104522705
30-01-2023 21:50:38 INFO Epoch 2: [8537/10940] ---- BYOL Training Loss = 0.2625161111354828
30-01-2023 21:52:06 INFO Epoch 2: [8537/10940] ---- BYOL Validation Loss = 0.2722068130970001
30-01-2023 21:52:35 INFO Epoch 2: [8548/10940] ---- BYOL Training Loss = 0.252094566822052
30-01-2023 21:53:03 INFO Epoch 2: [8559/10940] ---- BYOL Training Loss = 0.2714831531047821
30-01-2023 21:53:32 INFO Epoch 2: [8570/10940] ---- BYOL Training Loss = 0.2988699972629547
30-01-2023 21:54:00 INFO Epoch 2: [8581/10940] ---- BYOL Training Loss = 0.251264750957489
30-01-2023 21:55:28 INFO Epoch 2: [8581/10940] ---- BYOL Validation Loss = 0.270430326461792
30-01-2023 21:55:57 INFO Epoch 2: [8592/10940] ---- BYOL Training Loss = 0.27695155143737793
30-01-2023 21:56:25 INFO Epoch 2: [8603/10940] ---- BYOL Training Loss = 0.3157561719417572
30-01-2023 21:56:53 INFO Epoch 2: [8614/10940] ---- BYOL Training Loss = 0.30260801315307617
30-01-2023 21:57:22 INFO Epoch 2: [8625/10940] ---- BYOL Training Loss = 0.28272026777267456
30-01-2023 21:58:50 INFO Epoch 2: [8625/10940] ---- BYOL Validation Loss = 0.28185251355171204
30-01-2023 21:59:18 INFO Epoch 2: [8636/10940] ---- BYOL Training Loss = 0.25955113768577576
30-01-2023 21:59:46 INFO Epoch 2: [8647/10940] ---- BYOL Training Loss = 0.27204248309135437
30-01-2023 22:00:15 INFO Epoch 2: [8658/10940] ---- BYOL Training Loss = 0.22034266591072083
30-01-2023 22:00:43 INFO Epoch 2: [8669/10940] ---- BYOL Training Loss = 0.25961834192276
30-01-2023 22:02:12 INFO Epoch 2: [8669/10940] ---- BYOL Validation Loss = 0.2741589844226837
30-01-2023 22:02:40 INFO Epoch 2: [8680/10940] ---- BYOL Training Loss = 0.27965477108955383
30-01-2023 22:03:08 INFO Epoch 2: [8691/10940] ---- BYOL Training Loss = 0.2901206910610199
30-01-2023 22:03:36 INFO Epoch 2: [8702/10940] ---- BYOL Training Loss = 0.2917409837245941
30-01-2023 22:04:04 INFO Epoch 2: [8713/10940] ---- BYOL Training Loss = 0.2687006890773773
30-01-2023 22:05:33 INFO Epoch 2: [8713/10940] ---- BYOL Validation Loss = 0.28060513734817505
30-01-2023 22:06:01 INFO Epoch 2: [8724/10940] ---- BYOL Training Loss = 0.2421255111694336
30-01-2023 22:06:29 INFO Epoch 2: [8735/10940] ---- BYOL Training Loss = 0.28485020995140076
30-01-2023 22:06:58 INFO Epoch 2: [8746/10940] ---- BYOL Training Loss = 0.3019331097602844
30-01-2023 22:07:26 INFO Epoch 2: [8757/10940] ---- BYOL Training Loss = 0.28453516960144043
30-01-2023 22:08:54 INFO Epoch 2: [8757/10940] ---- BYOL Validation Loss = 0.27648112177848816
30-01-2023 22:09:22 INFO Epoch 2: [8768/10940] ---- BYOL Training Loss = 0.2891402244567871
30-01-2023 22:09:50 INFO Epoch 2: [8779/10940] ---- BYOL Training Loss = 0.27762776613235474
30-01-2023 22:10:19 INFO Epoch 2: [8790/10940] ---- BYOL Training Loss = 0.2597496807575226
30-01-2023 22:10:47 INFO Epoch 2: [8801/10940] ---- BYOL Training Loss = 0.2516990303993225
30-01-2023 22:12:15 INFO Epoch 2: [8801/10940] ---- BYOL Validation Loss = 0.2846510410308838
30-01-2023 22:12:43 INFO Epoch 2: [8812/10940] ---- BYOL Training Loss = 0.2896828055381775
30-01-2023 22:13:12 INFO Epoch 2: [8823/10940] ---- BYOL Training Loss = 0.29274782538414
30-01-2023 22:13:40 INFO Epoch 2: [8834/10940] ---- BYOL Training Loss = 0.2801450192928314
30-01-2023 22:14:08 INFO Epoch 2: [8845/10940] ---- BYOL Training Loss = 0.2575441896915436
30-01-2023 22:15:37 INFO Epoch 2: [8845/10940] ---- BYOL Validation Loss = 0.27665409445762634
30-01-2023 22:16:05 INFO Epoch 2: [8856/10940] ---- BYOL Training Loss = 0.23852553963661194
30-01-2023 22:16:33 INFO Epoch 2: [8867/10940] ---- BYOL Training Loss = 0.30597278475761414
30-01-2023 22:17:01 INFO Epoch 2: [8878/10940] ---- BYOL Training Loss = 0.32556384801864624
30-01-2023 22:17:30 INFO Epoch 2: [8889/10940] ---- BYOL Training Loss = 0.2815490663051605
30-01-2023 22:18:58 INFO Epoch 2: [8889/10940] ---- BYOL Validation Loss = 0.27431103587150574
30-01-2023 22:19:26 INFO Epoch 2: [8900/10940] ---- BYOL Training Loss = 0.267006516456604
30-01-2023 22:19:54 INFO Epoch 2: [8911/10940] ---- BYOL Training Loss = 0.2701103091239929
30-01-2023 22:20:23 INFO Epoch 2: [8922/10940] ---- BYOL Training Loss = 0.2744778096675873
30-01-2023 22:20:51 INFO Epoch 2: [8933/10940] ---- BYOL Training Loss = 0.273892343044281
30-01-2023 22:22:19 INFO Epoch 2: [8933/10940] ---- BYOL Validation Loss = 0.263460248708725
30-01-2023 22:22:48 INFO Epoch 2: [8944/10940] ---- BYOL Training Loss = 0.2175038605928421
30-01-2023 22:23:16 INFO Epoch 2: [8955/10940] ---- BYOL Training Loss = 0.2222863882780075
30-01-2023 22:23:44 INFO Epoch 2: [8966/10940] ---- BYOL Training Loss = 0.2281145304441452
30-01-2023 22:24:12 INFO Epoch 2: [8977/10940] ---- BYOL Training Loss = 0.24489864706993103
30-01-2023 22:25:41 INFO Epoch 2: [8977/10940] ---- BYOL Validation Loss = 0.27693697810173035
30-01-2023 22:26:09 INFO Epoch 2: [8988/10940] ---- BYOL Training Loss = 0.27824637293815613
30-01-2023 22:26:37 INFO Epoch 2: [8999/10940] ---- BYOL Training Loss = 0.31462594866752625
30-01-2023 22:27:05 INFO Epoch 2: [9010/10940] ---- BYOL Training Loss = 0.289725661277771
30-01-2023 22:27:33 INFO Epoch 2: [9021/10940] ---- BYOL Training Loss = 0.26523643732070923
30-01-2023 22:29:02 INFO Epoch 2: [9021/10940] ---- BYOL Validation Loss = 0.2702304720878601
30-01-2023 22:29:30 INFO Epoch 2: [9032/10940] ---- BYOL Training Loss = 0.22169938683509827
30-01-2023 22:29:58 INFO Epoch 2: [9043/10940] ---- BYOL Training Loss = 0.2668493986129761
30-01-2023 22:30:26 INFO Epoch 2: [9054/10940] ---- BYOL Training Loss = 0.3003922998905182
30-01-2023 22:30:55 INFO Epoch 2: [9065/10940] ---- BYOL Training Loss = 0.29476842284202576
30-01-2023 22:32:23 INFO Epoch 2: [9065/10940] ---- BYOL Validation Loss = 0.28985682129859924
30-01-2023 22:32:51 INFO Epoch 2: [9076/10940] ---- BYOL Training Loss = 0.2724488377571106
30-01-2023 22:33:20 INFO Epoch 2: [9087/10940] ---- BYOL Training Loss = 0.2779203951358795
30-01-2023 22:33:48 INFO Epoch 2: [9098/10940] ---- BYOL Training Loss = 0.27747842669487
30-01-2023 22:34:16 INFO Epoch 2: [9109/10940] ---- BYOL Training Loss = 0.2640461325645447
30-01-2023 22:35:44 INFO Epoch 2: [9109/10940] ---- BYOL Validation Loss = 0.2714084982872009
30-01-2023 22:36:13 INFO Epoch 2: [9120/10940] ---- BYOL Training Loss = 0.2741650938987732
30-01-2023 22:36:41 INFO Epoch 2: [9131/10940] ---- BYOL Training Loss = 0.27250438928604126
30-01-2023 22:37:09 INFO Epoch 2: [9142/10940] ---- BYOL Training Loss = 0.2776619791984558
30-01-2023 22:37:37 INFO Epoch 2: [9153/10940] ---- BYOL Training Loss = 0.26668688654899597
30-01-2023 22:39:06 INFO Epoch 2: [9153/10940] ---- BYOL Validation Loss = 0.26973599195480347
30-01-2023 22:39:34 INFO Epoch 2: [9164/10940] ---- BYOL Training Loss = 0.2741392254829407
30-01-2023 22:40:02 INFO Epoch 2: [9175/10940] ---- BYOL Training Loss = 0.3027627468109131
30-01-2023 22:40:30 INFO Epoch 2: [9186/10940] ---- BYOL Training Loss = 0.2611575424671173
30-01-2023 22:40:59 INFO Epoch 2: [9197/10940] ---- BYOL Training Loss = 0.24698248505592346
30-01-2023 22:42:27 INFO Epoch 2: [9197/10940] ---- BYOL Validation Loss = 0.27250009775161743
30-01-2023 22:42:55 INFO Epoch 2: [9208/10940] ---- BYOL Training Loss = 0.2587227523326874
30-01-2023 22:43:23 INFO Epoch 2: [9219/10940] ---- BYOL Training Loss = 0.2085084170103073
30-01-2023 22:43:52 INFO Epoch 2: [9230/10940] ---- BYOL Training Loss = 0.24253682792186737
30-01-2023 22:44:20 INFO Epoch 2: [9241/10940] ---- BYOL Training Loss = 0.2768862545490265
30-01-2023 22:45:48 INFO Epoch 2: [9241/10940] ---- BYOL Validation Loss = 0.26996660232543945
30-01-2023 22:46:16 INFO Epoch 2: [9252/10940] ---- BYOL Training Loss = 0.26344114542007446
30-01-2023 22:46:45 INFO Epoch 2: [9263/10940] ---- BYOL Training Loss = 0.3011495769023895
30-01-2023 22:47:13 INFO Epoch 2: [9274/10940] ---- BYOL Training Loss = 0.28976351022720337
30-01-2023 22:47:42 INFO Epoch 2: [9285/10940] ---- BYOL Training Loss = 0.3047616481781006
30-01-2023 22:49:10 INFO Epoch 2: [9285/10940] ---- BYOL Validation Loss = 0.26924753189086914
30-01-2023 22:49:38 INFO Epoch 2: [9296/10940] ---- BYOL Training Loss = 0.2848336696624756
30-01-2023 22:50:07 INFO Epoch 2: [9307/10940] ---- BYOL Training Loss = 0.2817173898220062
30-01-2023 22:50:35 INFO Epoch 2: [9318/10940] ---- BYOL Training Loss = 0.30492618680000305
30-01-2023 22:51:03 INFO Epoch 2: [9329/10940] ---- BYOL Training Loss = 0.2571934759616852
30-01-2023 22:52:32 INFO Epoch 2: [9329/10940] ---- BYOL Validation Loss = 0.2812236249446869
30-01-2023 22:53:01 INFO Epoch 2: [9340/10940] ---- BYOL Training Loss = 0.24874241650104523
30-01-2023 22:53:29 INFO Epoch 2: [9351/10940] ---- BYOL Training Loss = 0.27705731987953186
30-01-2023 22:53:57 INFO Epoch 2: [9362/10940] ---- BYOL Training Loss = 0.28273481130599976
30-01-2023 22:54:25 INFO Epoch 2: [9373/10940] ---- BYOL Training Loss = 0.2949720025062561
30-01-2023 22:55:53 INFO Epoch 2: [9373/10940] ---- BYOL Validation Loss = 0.27730199694633484
30-01-2023 22:56:22 INFO Epoch 2: [9384/10940] ---- BYOL Training Loss = 0.30865973234176636
30-01-2023 22:56:50 INFO Epoch 2: [9395/10940] ---- BYOL Training Loss = 0.2554599642753601
30-01-2023 22:57:18 INFO Epoch 2: [9406/10940] ---- BYOL Training Loss = 0.2856622040271759
30-01-2023 22:57:47 INFO Epoch 2: [9417/10940] ---- BYOL Training Loss = 0.28201138973236084
30-01-2023 22:59:15 INFO Epoch 2: [9417/10940] ---- BYOL Validation Loss = 0.508512556552887
30-01-2023 22:59:43 INFO Epoch 2: [9428/10940] ---- BYOL Training Loss = 0.31821176409721375
30-01-2023 23:00:11 INFO Epoch 2: [9439/10940] ---- BYOL Training Loss = 0.3324863016605377
30-01-2023 23:00:40 INFO Epoch 2: [9450/10940] ---- BYOL Training Loss = 0.28085917234420776
30-01-2023 23:01:08 INFO Epoch 2: [9461/10940] ---- BYOL Training Loss = 0.2515244483947754
30-01-2023 23:02:36 INFO Epoch 2: [9461/10940] ---- BYOL Validation Loss = 0.26645106077194214
30-01-2023 23:03:05 INFO Epoch 2: [9472/10940] ---- BYOL Training Loss = 0.24540522694587708
30-01-2023 23:03:33 INFO Epoch 2: [9483/10940] ---- BYOL Training Loss = 0.2886396050453186
30-01-2023 23:04:02 INFO Epoch 2: [9494/10940] ---- BYOL Training Loss = 0.25555795431137085
30-01-2023 23:04:30 INFO Epoch 2: [9505/10940] ---- BYOL Training Loss = 0.22824935615062714
30-01-2023 23:05:58 INFO Epoch 2: [9505/10940] ---- BYOL Validation Loss = 0.26566243171691895
30-01-2023 23:06:27 INFO Epoch 2: [9516/10940] ---- BYOL Training Loss = 0.2857349216938019
30-01-2023 23:06:55 INFO Epoch 2: [9527/10940] ---- BYOL Training Loss = 0.28724318742752075
30-01-2023 23:07:23 INFO Epoch 2: [9538/10940] ---- BYOL Training Loss = 0.28124871850013733
30-01-2023 23:07:51 INFO Epoch 2: [9549/10940] ---- BYOL Training Loss = 0.2824338674545288
30-01-2023 23:09:19 INFO Epoch 2: [9549/10940] ---- BYOL Validation Loss = 0.2862238883972168
30-01-2023 23:09:48 INFO Epoch 2: [9560/10940] ---- BYOL Training Loss = 0.26778173446655273
30-01-2023 23:10:16 INFO Epoch 2: [9571/10940] ---- BYOL Training Loss = 0.2807061970233917
30-01-2023 23:10:45 INFO Epoch 2: [9582/10940] ---- BYOL Training Loss = 0.2959032356739044
30-01-2023 23:11:13 INFO Epoch 2: [9593/10940] ---- BYOL Training Loss = 0.31592661142349243
30-01-2023 23:12:41 INFO Epoch 2: [9593/10940] ---- BYOL Validation Loss = 0.2857522964477539
30-01-2023 23:13:10 INFO Epoch 2: [9604/10940] ---- BYOL Training Loss = 0.30266642570495605
30-01-2023 23:13:38 INFO Epoch 2: [9615/10940] ---- BYOL Training Loss = 0.3010368347167969
30-01-2023 23:14:06 INFO Epoch 2: [9626/10940] ---- BYOL Training Loss = 0.30740925669670105
30-01-2023 23:14:34 INFO Epoch 2: [9637/10940] ---- BYOL Training Loss = 0.25484684109687805
30-01-2023 23:16:03 INFO Epoch 2: [9637/10940] ---- BYOL Validation Loss = 0.27160099148750305
30-01-2023 23:16:31 INFO Epoch 2: [9648/10940] ---- BYOL Training Loss = 0.2629576325416565
30-01-2023 23:16:59 INFO Epoch 2: [9659/10940] ---- BYOL Training Loss = 0.27011069655418396
30-01-2023 23:17:27 INFO Epoch 2: [9670/10940] ---- BYOL Training Loss = 0.2586778402328491
30-01-2023 23:17:56 INFO Epoch 2: [9681/10940] ---- BYOL Training Loss = 0.2981456518173218
30-01-2023 23:19:24 INFO Epoch 2: [9681/10940] ---- BYOL Validation Loss = 0.271217405796051
30-01-2023 23:19:52 INFO Epoch 2: [9692/10940] ---- BYOL Training Loss = 0.313643217086792
30-01-2023 23:20:20 INFO Epoch 2: [9703/10940] ---- BYOL Training Loss = 0.28755298256874084
30-01-2023 23:20:49 INFO Epoch 2: [9714/10940] ---- BYOL Training Loss = 0.27882230281829834
30-01-2023 23:21:17 INFO Epoch 2: [9725/10940] ---- BYOL Training Loss = 0.29012057185173035
30-01-2023 23:22:45 INFO Epoch 2: [9725/10940] ---- BYOL Validation Loss = 0.2812693417072296
30-01-2023 23:23:14 INFO Epoch 2: [9736/10940] ---- BYOL Training Loss = 0.2863479256629944
30-01-2023 23:23:42 INFO Epoch 2: [9747/10940] ---- BYOL Training Loss = 0.2543236315250397
30-01-2023 23:24:10 INFO Epoch 2: [9758/10940] ---- BYOL Training Loss = 0.27611708641052246
30-01-2023 23:24:38 INFO Epoch 2: [9769/10940] ---- BYOL Training Loss = 0.2846151888370514
30-01-2023 23:26:07 INFO Epoch 2: [9769/10940] ---- BYOL Validation Loss = 0.28310221433639526
30-01-2023 23:26:35 INFO Epoch 2: [9780/10940] ---- BYOL Training Loss = 0.2490878403186798
30-01-2023 23:27:03 INFO Epoch 2: [9791/10940] ---- BYOL Training Loss = 0.2755979001522064
30-01-2023 23:27:31 INFO Epoch 2: [9802/10940] ---- BYOL Training Loss = 0.26758790016174316
30-01-2023 23:28:00 INFO Epoch 2: [9813/10940] ---- BYOL Training Loss = 0.2413322925567627
30-01-2023 23:29:28 INFO Epoch 2: [9813/10940] ---- BYOL Validation Loss = 0.267191618680954
30-01-2023 23:29:56 INFO Epoch 2: [9824/10940] ---- BYOL Training Loss = 0.2949485182762146
30-01-2023 23:30:24 INFO Epoch 2: [9835/10940] ---- BYOL Training Loss = 0.32392722368240356
30-01-2023 23:30:53 INFO Epoch 2: [9846/10940] ---- BYOL Training Loss = 0.29764795303344727
30-01-2023 23:31:21 INFO Epoch 2: [9857/10940] ---- BYOL Training Loss = 0.268113374710083
30-01-2023 23:32:49 INFO Epoch 2: [9857/10940] ---- BYOL Validation Loss = 0.28418904542922974
30-01-2023 23:33:18 INFO Epoch 2: [9868/10940] ---- BYOL Training Loss = 0.28113874793052673
30-01-2023 23:33:46 INFO Epoch 2: [9879/10940] ---- BYOL Training Loss = 0.2524326741695404
30-01-2023 23:34:15 INFO Epoch 2: [9890/10940] ---- BYOL Training Loss = 0.2725267708301544
30-01-2023 23:34:43 INFO Epoch 2: [9901/10940] ---- BYOL Training Loss = 0.2773530185222626
30-01-2023 23:36:11 INFO Epoch 2: [9901/10940] ---- BYOL Validation Loss = 0.25826913118362427
30-01-2023 23:36:40 INFO Epoch 2: [9912/10940] ---- BYOL Training Loss = 0.25829559564590454
30-01-2023 23:37:08 INFO Epoch 2: [9923/10940] ---- BYOL Training Loss = 0.31774187088012695
30-01-2023 23:37:36 INFO Epoch 2: [9934/10940] ---- BYOL Training Loss = 0.2887997329235077
30-01-2023 23:38:04 INFO Epoch 2: [9945/10940] ---- BYOL Training Loss = 0.3168785274028778
30-01-2023 23:39:33 INFO Epoch 2: [9945/10940] ---- BYOL Validation Loss = 0.2756238579750061
30-01-2023 23:40:01 INFO Epoch 2: [9956/10940] ---- BYOL Training Loss = 0.3127865195274353
30-01-2023 23:40:30 INFO Epoch 2: [9967/10940] ---- BYOL Training Loss = 0.2963312864303589
30-01-2023 23:40:58 INFO Epoch 2: [9978/10940] ---- BYOL Training Loss = 0.3019375205039978
30-01-2023 23:41:26 INFO Epoch 2: [9989/10940] ---- BYOL Training Loss = 0.2773582637310028
30-01-2023 23:42:55 INFO Epoch 2: [9989/10940] ---- BYOL Validation Loss = 0.2745436728000641
30-01-2023 23:43:23 INFO Epoch 2: [10000/10940] ---- BYOL Training Loss = 0.2946798801422119
30-01-2023 23:43:51 INFO Epoch 2: [10011/10940] ---- BYOL Training Loss = 0.2921541929244995
30-01-2023 23:44:20 INFO Epoch 2: [10022/10940] ---- BYOL Training Loss = 0.28540632128715515
30-01-2023 23:44:48 INFO Epoch 2: [10033/10940] ---- BYOL Training Loss = 0.33333083987236023
30-01-2023 23:46:16 INFO Epoch 2: [10033/10940] ---- BYOL Validation Loss = 0.2701151669025421
30-01-2023 23:46:45 INFO Epoch 2: [10044/10940] ---- BYOL Training Loss = 0.2851110100746155
30-01-2023 23:47:13 INFO Epoch 2: [10055/10940] ---- BYOL Training Loss = 0.25085216760635376
30-01-2023 23:47:41 INFO Epoch 2: [10066/10940] ---- BYOL Training Loss = 0.3187139928340912
30-01-2023 23:48:10 INFO Epoch 2: [10077/10940] ---- BYOL Training Loss = 0.31104013323783875
30-01-2023 23:49:38 INFO Epoch 2: [10077/10940] ---- BYOL Validation Loss = 0.27554717659950256
30-01-2023 23:50:07 INFO Epoch 2: [10088/10940] ---- BYOL Training Loss = 0.26990407705307007
30-01-2023 23:50:35 INFO Epoch 2: [10099/10940] ---- BYOL Training Loss = 0.25477123260498047
30-01-2023 23:51:03 INFO Epoch 2: [10110/10940] ---- BYOL Training Loss = 0.2503233850002289
30-01-2023 23:51:32 INFO Epoch 2: [10121/10940] ---- BYOL Training Loss = 0.2874539792537689
30-01-2023 23:53:00 INFO Epoch 2: [10121/10940] ---- BYOL Validation Loss = 0.26242557168006897
30-01-2023 23:53:28 INFO Epoch 2: [10132/10940] ---- BYOL Training Loss = 0.2844812870025635
30-01-2023 23:53:57 INFO Epoch 2: [10143/10940] ---- BYOL Training Loss = 0.23676984012126923
30-01-2023 23:54:25 INFO Epoch 2: [10154/10940] ---- BYOL Training Loss = 0.2557813823223114
30-01-2023 23:54:53 INFO Epoch 2: [10165/10940] ---- BYOL Training Loss = 0.28533193469047546
30-01-2023 23:56:22 INFO Epoch 2: [10165/10940] ---- BYOL Validation Loss = 0.2881040871143341
30-01-2023 23:56:50 INFO Epoch 2: [10176/10940] ---- BYOL Training Loss = 0.27402743697166443
30-01-2023 23:57:18 INFO Epoch 2: [10187/10940] ---- BYOL Training Loss = 0.28799790143966675
30-01-2023 23:57:47 INFO Epoch 2: [10198/10940] ---- BYOL Training Loss = 0.2585347294807434
30-01-2023 23:58:15 INFO Epoch 2: [10209/10940] ---- BYOL Training Loss = 0.24160060286521912
30-01-2023 23:59:44 INFO Epoch 2: [10209/10940] ---- BYOL Validation Loss = 0.26230502128601074
31-01-2023 00:00:12 INFO Epoch 2: [10220/10940] ---- BYOL Training Loss = 0.26956161856651306
31-01-2023 00:00:41 INFO Epoch 2: [10231/10940] ---- BYOL Training Loss = 0.25271734595298767
31-01-2023 00:01:09 INFO Epoch 2: [10242/10940] ---- BYOL Training Loss = 0.22062042355537415
31-01-2023 00:01:37 INFO Epoch 2: [10253/10940] ---- BYOL Training Loss = 0.21991300582885742
31-01-2023 00:03:06 INFO Epoch 2: [10253/10940] ---- BYOL Validation Loss = 0.2559162676334381
31-01-2023 00:03:34 INFO Epoch 2: [10264/10940] ---- BYOL Training Loss = 0.24522808194160461
31-01-2023 00:04:03 INFO Epoch 2: [10275/10940] ---- BYOL Training Loss = 0.3075113594532013
31-01-2023 00:04:31 INFO Epoch 2: [10286/10940] ---- BYOL Training Loss = 0.26940783858299255
31-01-2023 00:04:59 INFO Epoch 2: [10297/10940] ---- BYOL Training Loss = 0.29328611493110657
31-01-2023 00:06:27 INFO Epoch 2: [10297/10940] ---- BYOL Validation Loss = 0.27311041951179504
31-01-2023 00:06:56 INFO Epoch 2: [10308/10940] ---- BYOL Training Loss = 0.27848026156425476
31-01-2023 00:07:24 INFO Epoch 2: [10319/10940] ---- BYOL Training Loss = 0.25898826122283936
31-01-2023 00:07:53 INFO Epoch 2: [10330/10940] ---- BYOL Training Loss = 0.30535435676574707
31-01-2023 00:08:21 INFO Epoch 2: [10341/10940] ---- BYOL Training Loss = 0.2867443263530731
31-01-2023 00:09:49 INFO Epoch 2: [10341/10940] ---- BYOL Validation Loss = 0.26567181944847107
31-01-2023 00:10:18 INFO Epoch 2: [10352/10940] ---- BYOL Training Loss = 0.26464125514030457
31-01-2023 00:10:46 INFO Epoch 2: [10363/10940] ---- BYOL Training Loss = 0.2615363299846649
31-01-2023 00:11:14 INFO Epoch 2: [10374/10940] ---- BYOL Training Loss = 0.26528599858283997
31-01-2023 00:11:43 INFO Epoch 2: [10385/10940] ---- BYOL Training Loss = 0.29135650396347046
31-01-2023 00:13:11 INFO Epoch 2: [10385/10940] ---- BYOL Validation Loss = 0.271962970495224
31-01-2023 00:13:39 INFO Epoch 2: [10396/10940] ---- BYOL Training Loss = 0.3047470152378082
31-01-2023 00:14:08 INFO Epoch 2: [10407/10940] ---- BYOL Training Loss = 0.2975175976753235
31-01-2023 00:14:36 INFO Epoch 2: [10418/10940] ---- BYOL Training Loss = 0.25877225399017334
31-01-2023 00:15:05 INFO Epoch 2: [10429/10940] ---- BYOL Training Loss = 0.24036410450935364
31-01-2023 00:16:33 INFO Epoch 2: [10429/10940] ---- BYOL Validation Loss = 0.28519579768180847
31-01-2023 00:17:02 INFO Epoch 2: [10440/10940] ---- BYOL Training Loss = 0.2602127194404602
31-01-2023 00:17:30 INFO Epoch 2: [10451/10940] ---- BYOL Training Loss = 0.26854848861694336
31-01-2023 00:17:59 INFO Epoch 2: [10462/10940] ---- BYOL Training Loss = 0.251126766204834
31-01-2023 00:18:27 INFO Epoch 2: [10473/10940] ---- BYOL Training Loss = 0.23125533759593964
31-01-2023 00:19:55 INFO Epoch 2: [10473/10940] ---- BYOL Validation Loss = 0.27354294061660767
31-01-2023 00:20:24 INFO Epoch 2: [10484/10940] ---- BYOL Training Loss = 0.2247520387172699
31-01-2023 00:20:53 INFO Epoch 2: [10495/10940] ---- BYOL Training Loss = 0.26119405031204224
31-01-2023 00:21:21 INFO Epoch 2: [10506/10940] ---- BYOL Training Loss = 0.2813207805156708
31-01-2023 00:21:49 INFO Epoch 2: [10517/10940] ---- BYOL Training Loss = 0.2920672595500946
31-01-2023 00:23:18 INFO Epoch 2: [10517/10940] ---- BYOL Validation Loss = 0.28733110427856445
31-01-2023 00:23:46 INFO Epoch 2: [10528/10940] ---- BYOL Training Loss = 0.2991867959499359
31-01-2023 00:24:15 INFO Epoch 2: [10539/10940] ---- BYOL Training Loss = 0.2626788914203644
31-01-2023 00:24:43 INFO Epoch 2: [10550/10940] ---- BYOL Training Loss = 0.2479550540447235
31-01-2023 00:25:11 INFO Epoch 2: [10561/10940] ---- BYOL Training Loss = 0.222662091255188
31-01-2023 00:26:40 INFO Epoch 2: [10561/10940] ---- BYOL Validation Loss = 0.2790337800979614
31-01-2023 00:27:08 INFO Epoch 2: [10572/10940] ---- BYOL Training Loss = 0.23597340285778046
31-01-2023 00:27:37 INFO Epoch 2: [10583/10940] ---- BYOL Training Loss = 0.2886374890804291
31-01-2023 00:28:05 INFO Epoch 2: [10594/10940] ---- BYOL Training Loss = 0.2874179482460022
31-01-2023 00:28:33 INFO Epoch 2: [10605/10940] ---- BYOL Training Loss = 0.257750004529953
31-01-2023 00:30:02 INFO Epoch 2: [10605/10940] ---- BYOL Validation Loss = 0.2818426787853241
31-01-2023 00:30:31 INFO Epoch 2: [10616/10940] ---- BYOL Training Loss = 0.24366800487041473
31-01-2023 00:30:59 INFO Epoch 2: [10627/10940] ---- BYOL Training Loss = 0.2518309950828552
31-01-2023 00:31:27 INFO Epoch 2: [10638/10940] ---- BYOL Training Loss = 0.2611704468727112
31-01-2023 00:31:56 INFO Epoch 2: [10649/10940] ---- BYOL Training Loss = 0.2562445104122162
31-01-2023 00:33:24 INFO Epoch 2: [10649/10940] ---- BYOL Validation Loss = 0.2748853266239166
31-01-2023 00:33:52 INFO Epoch 2: [10660/10940] ---- BYOL Training Loss = 0.2551404535770416
31-01-2023 00:34:21 INFO Epoch 2: [10671/10940] ---- BYOL Training Loss = 0.2817131578922272
31-01-2023 00:34:49 INFO Epoch 2: [10682/10940] ---- BYOL Training Loss = 0.28727978467941284
31-01-2023 00:35:18 INFO Epoch 2: [10693/10940] ---- BYOL Training Loss = 0.26224860548973083
31-01-2023 00:36:46 INFO Epoch 2: [10693/10940] ---- BYOL Validation Loss = 0.2594109773635864
31-01-2023 00:37:15 INFO Epoch 2: [10704/10940] ---- BYOL Training Loss = 0.23159842193126678
31-01-2023 00:37:43 INFO Epoch 2: [10715/10940] ---- BYOL Training Loss = 0.21126921474933624
31-01-2023 00:38:11 INFO Epoch 2: [10726/10940] ---- BYOL Training Loss = 0.25849035382270813
31-01-2023 00:38:40 INFO Epoch 2: [10737/10940] ---- BYOL Training Loss = 0.29638656973838806
31-01-2023 00:40:08 INFO Epoch 2: [10737/10940] ---- BYOL Validation Loss = 0.26566141843795776
31-01-2023 00:40:37 INFO Epoch 2: [10748/10940] ---- BYOL Training Loss = 0.3180326819419861
31-01-2023 00:41:05 INFO Epoch 2: [10759/10940] ---- BYOL Training Loss = 0.31011074781417847
31-01-2023 00:41:33 INFO Epoch 2: [10770/10940] ---- BYOL Training Loss = 0.2666815221309662
31-01-2023 00:42:02 INFO Epoch 2: [10781/10940] ---- BYOL Training Loss = 0.27674704790115356
31-01-2023 00:43:30 INFO Epoch 2: [10781/10940] ---- BYOL Validation Loss = 0.26126644015312195
31-01-2023 00:43:58 INFO Epoch 2: [10792/10940] ---- BYOL Training Loss = 0.32293033599853516
31-01-2023 00:44:27 INFO Epoch 2: [10803/10940] ---- BYOL Training Loss = 0.27002450823783875
31-01-2023 00:44:55 INFO Epoch 2: [10814/10940] ---- BYOL Training Loss = 0.260857492685318
31-01-2023 00:45:24 INFO Epoch 2: [10825/10940] ---- BYOL Training Loss = 0.28520965576171875
31-01-2023 00:46:52 INFO Epoch 2: [10825/10940] ---- BYOL Validation Loss = 0.27976036071777344
31-01-2023 00:47:20 INFO Epoch 2: [10836/10940] ---- BYOL Training Loss = 0.2918551564216614
31-01-2023 00:47:49 INFO Epoch 2: [10847/10940] ---- BYOL Training Loss = 0.3073931932449341
31-01-2023 00:48:17 INFO Epoch 2: [10858/10940] ---- BYOL Training Loss = 0.26311415433883667
31-01-2023 00:48:46 INFO Epoch 2: [10869/10940] ---- BYOL Training Loss = 0.2406979501247406
31-01-2023 00:50:14 INFO Epoch 2: [10869/10940] ---- BYOL Validation Loss = 0.29128333926200867
31-01-2023 00:50:42 INFO Epoch 2: [10880/10940] ---- BYOL Training Loss = 0.2597678005695343
31-01-2023 00:51:11 INFO Epoch 2: [10891/10940] ---- BYOL Training Loss = 0.24961571395397186
31-01-2023 00:51:39 INFO Epoch 2: [10902/10940] ---- BYOL Training Loss = 0.25939732789993286
31-01-2023 00:52:08 INFO Epoch 2: [10913/10940] ---- BYOL Training Loss = 0.25730210542678833
31-01-2023 00:53:36 INFO Epoch 2: [10913/10940] ---- BYOL Validation Loss = 0.2720518410205841
31-01-2023 00:54:04 INFO Epoch 2: [10924/10940] ---- BYOL Training Loss = 0.23497851192951202
31-01-2023 00:54:33 INFO Epoch 2: [10935/10940] ---- BYOL Training Loss = 0.23370027542114258
31-01-2023 00:54:46 INFO Starting Epoch: 3
31-01-2023 00:55:15 INFO Epoch 3: [12/10940] ---- BYOL Training Loss = 0.23374201357364655
31-01-2023 00:55:42 INFO Epoch 3: [23/10940] ---- BYOL Training Loss = 0.31090083718299866
31-01-2023 00:56:09 INFO Epoch 3: [34/10940] ---- BYOL Training Loss = 0.32076752185821533
31-01-2023 00:56:37 INFO Epoch 3: [45/10940] ---- BYOL Training Loss = 0.2695593237876892
31-01-2023 00:58:05 INFO Epoch 3: [45/10940] ---- BYOL Validation Loss = 0.27843740582466125
31-01-2023 00:58:32 INFO Epoch 3: [56/10940] ---- BYOL Training Loss = 0.21964892745018005
31-01-2023 00:59:00 INFO Epoch 3: [67/10940] ---- BYOL Training Loss = 0.2412044107913971
31-01-2023 00:59:27 INFO Epoch 3: [78/10940] ---- BYOL Training Loss = 0.23495540022850037
31-01-2023 00:59:54 INFO Epoch 3: [89/10940] ---- BYOL Training Loss = 0.1908344179391861
31-01-2023 01:01:22 INFO Epoch 3: [89/10940] ---- BYOL Validation Loss = 0.2631276547908783
31-01-2023 01:01:50 INFO Epoch 3: [100/10940] ---- BYOL Training Loss = 0.2672715187072754
31-01-2023 01:02:17 INFO Epoch 3: [111/10940] ---- BYOL Training Loss = 0.28549763560295105
31-01-2023 01:02:45 INFO Epoch 3: [122/10940] ---- BYOL Training Loss = 0.24553552269935608
31-01-2023 01:03:12 INFO Epoch 3: [133/10940] ---- BYOL Training Loss = 0.2703357934951782
31-01-2023 01:04:40 INFO Epoch 3: [133/10940] ---- BYOL Validation Loss = 0.27167588472366333
31-01-2023 01:05:08 INFO Epoch 3: [144/10940] ---- BYOL Training Loss = 0.2655549645423889
31-01-2023 01:05:35 INFO Epoch 3: [155/10940] ---- BYOL Training Loss = 0.24160373210906982
31-01-2023 01:06:02 INFO Epoch 3: [166/10940] ---- BYOL Training Loss = 0.2267015427350998
31-01-2023 01:06:30 INFO Epoch 3: [177/10940] ---- BYOL Training Loss = 0.22030678391456604
31-01-2023 01:07:58 INFO Epoch 3: [177/10940] ---- BYOL Validation Loss = 0.26466771960258484
31-01-2023 01:08:26 INFO Epoch 3: [188/10940] ---- BYOL Training Loss = 0.2353055775165558
31-01-2023 01:08:53 INFO Epoch 3: [199/10940] ---- BYOL Training Loss = 0.26590436697006226
31-01-2023 01:09:20 INFO Epoch 3: [210/10940] ---- BYOL Training Loss = 0.2725629210472107
31-01-2023 01:09:47 INFO Epoch 3: [221/10940] ---- BYOL Training Loss = 0.28456681966781616
31-01-2023 01:11:16 INFO Epoch 3: [221/10940] ---- BYOL Validation Loss = 0.2893480360507965
31-01-2023 01:11:43 INFO Epoch 3: [232/10940] ---- BYOL Training Loss = 0.26029160618782043
31-01-2023 01:12:10 INFO Epoch 3: [243/10940] ---- BYOL Training Loss = 0.2458389699459076
31-01-2023 01:12:38 INFO Epoch 3: [254/10940] ---- BYOL Training Loss = 0.2554894685745239
31-01-2023 01:13:05 INFO Epoch 3: [265/10940] ---- BYOL Training Loss = 0.2526312470436096
31-01-2023 01:14:33 INFO Epoch 3: [265/10940] ---- BYOL Validation Loss = 0.2750777006149292
31-01-2023 01:15:01 INFO Epoch 3: [276/10940] ---- BYOL Training Loss = 0.2746279537677765
31-01-2023 01:15:28 INFO Epoch 3: [287/10940] ---- BYOL Training Loss = 0.28290027379989624
31-01-2023 01:15:56 INFO Epoch 3: [298/10940] ---- BYOL Training Loss = 0.2665487825870514
31-01-2023 01:16:23 INFO Epoch 3: [309/10940] ---- BYOL Training Loss = 0.31617313623428345
31-01-2023 01:17:51 INFO Epoch 3: [309/10940] ---- BYOL Validation Loss = 0.2869951128959656
31-01-2023 01:18:18 INFO Epoch 3: [320/10940] ---- BYOL Training Loss = 0.2636585235595703
31-01-2023 01:18:46 INFO Epoch 3: [331/10940] ---- BYOL Training Loss = 0.2820289134979248
31-01-2023 01:19:13 INFO Epoch 3: [342/10940] ---- BYOL Training Loss = 0.3223980963230133
31-01-2023 01:19:40 INFO Epoch 3: [353/10940] ---- BYOL Training Loss = 0.2972225248813629
31-01-2023 01:21:09 INFO Epoch 3: [353/10940] ---- BYOL Validation Loss = 0.2797643840312958
31-01-2023 01:21:36 INFO Epoch 3: [364/10940] ---- BYOL Training Loss = 0.2784018814563751
31-01-2023 01:22:04 INFO Epoch 3: [375/10940] ---- BYOL Training Loss = 0.29663386940956116
31-01-2023 01:22:31 INFO Epoch 3: [386/10940] ---- BYOL Training Loss = 0.27964872121810913
31-01-2023 01:22:58 INFO Epoch 3: [397/10940] ---- BYOL Training Loss = 0.27605700492858887
31-01-2023 01:24:27 INFO Epoch 3: [397/10940] ---- BYOL Validation Loss = 0.28485819697380066
31-01-2023 01:24:54 INFO Epoch 3: [408/10940] ---- BYOL Training Loss = 0.2776041328907013
31-01-2023 01:25:22 INFO Epoch 3: [419/10940] ---- BYOL Training Loss = 0.2697550356388092
31-01-2023 01:25:49 INFO Epoch 3: [430/10940] ---- BYOL Training Loss = 0.29215437173843384
31-01-2023 01:26:16 INFO Epoch 3: [441/10940] ---- BYOL Training Loss = 0.28668326139450073
31-01-2023 01:27:44 INFO Epoch 3: [441/10940] ---- BYOL Validation Loss = 0.2687644064426422
31-01-2023 01:28:12 INFO Epoch 3: [452/10940] ---- BYOL Training Loss = 0.22307772934436798
31-01-2023 01:28:39 INFO Epoch 3: [463/10940] ---- BYOL Training Loss = 0.23993735015392303
31-01-2023 01:29:06 INFO Epoch 3: [474/10940] ---- BYOL Training Loss = 0.29484015703201294
31-01-2023 01:29:34 INFO Epoch 3: [485/10940] ---- BYOL Training Loss = 0.27618128061294556
31-01-2023 01:31:02 INFO Epoch 3: [485/10940] ---- BYOL Validation Loss = 0.2812213599681854
31-01-2023 01:31:30 INFO Epoch 3: [496/10940] ---- BYOL Training Loss = 0.24667811393737793
31-01-2023 01:31:57 INFO Epoch 3: [507/10940] ---- BYOL Training Loss = 0.24855010211467743
31-01-2023 01:32:24 INFO Epoch 3: [518/10940] ---- BYOL Training Loss = 0.2564333379268646
31-01-2023 01:32:52 INFO Epoch 3: [529/10940] ---- BYOL Training Loss = 0.2553059458732605
31-01-2023 01:34:20 INFO Epoch 3: [529/10940] ---- BYOL Validation Loss = 0.2778617739677429
31-01-2023 01:34:47 INFO Epoch 3: [540/10940] ---- BYOL Training Loss = 0.25390711426734924
31-01-2023 01:35:15 INFO Epoch 3: [551/10940] ---- BYOL Training Loss = 0.23744595050811768
31-01-2023 01:35:43 INFO Epoch 3: [562/10940] ---- BYOL Training Loss = 0.26663756370544434
31-01-2023 01:36:10 INFO Epoch 3: [573/10940] ---- BYOL Training Loss = 0.3106902539730072
31-01-2023 01:37:38 INFO Epoch 3: [573/10940] ---- BYOL Validation Loss = 0.287165105342865
31-01-2023 01:38:06 INFO Epoch 3: [584/10940] ---- BYOL Training Loss = 0.3070012032985687
31-01-2023 01:38:34 INFO Epoch 3: [595/10940] ---- BYOL Training Loss = 0.2314067780971527
31-01-2023 01:39:01 INFO Epoch 3: [606/10940] ---- BYOL Training Loss = 0.25072231888771057
31-01-2023 01:39:28 INFO Epoch 3: [617/10940] ---- BYOL Training Loss = 0.288738876581192
31-01-2023 01:40:57 INFO Epoch 3: [617/10940] ---- BYOL Validation Loss = 0.2925577461719513
31-01-2023 01:41:24 INFO Epoch 3: [628/10940] ---- BYOL Training Loss = 0.2893511652946472
31-01-2023 01:41:52 INFO Epoch 3: [639/10940] ---- BYOL Training Loss = 0.2890351414680481
31-01-2023 01:42:19 INFO Epoch 3: [650/10940] ---- BYOL Training Loss = 0.2406374216079712
31-01-2023 01:42:46 INFO Epoch 3: [661/10940] ---- BYOL Training Loss = 0.2382238358259201
31-01-2023 01:44:15 INFO Epoch 3: [661/10940] ---- BYOL Validation Loss = 0.2872214913368225
31-01-2023 01:44:42 INFO Epoch 3: [672/10940] ---- BYOL Training Loss = 0.2507174611091614
31-01-2023 01:45:10 INFO Epoch 3: [683/10940] ---- BYOL Training Loss = 0.23826611042022705
31-01-2023 01:45:37 INFO Epoch 3: [694/10940] ---- BYOL Training Loss = 0.25175541639328003
31-01-2023 01:46:04 INFO Epoch 3: [705/10940] ---- BYOL Training Loss = 0.24790842831134796
31-01-2023 01:47:33 INFO Epoch 3: [705/10940] ---- BYOL Validation Loss = 0.27166351675987244
31-01-2023 01:48:00 INFO Epoch 3: [716/10940] ---- BYOL Training Loss = 0.2572927176952362
31-01-2023 01:48:27 INFO Epoch 3: [727/10940] ---- BYOL Training Loss = 0.288787841796875
31-01-2023 01:48:55 INFO Epoch 3: [738/10940] ---- BYOL Training Loss = 0.29123109579086304
31-01-2023 01:49:22 INFO Epoch 3: [749/10940] ---- BYOL Training Loss = 0.29525789618492126
31-01-2023 01:50:51 INFO Epoch 3: [749/10940] ---- BYOL Validation Loss = 0.2955748736858368
31-01-2023 01:51:18 INFO Epoch 3: [760/10940] ---- BYOL Training Loss = 0.25751885771751404
31-01-2023 01:51:45 INFO Epoch 3: [771/10940] ---- BYOL Training Loss = 0.32607725262641907
31-01-2023 01:52:13 INFO Epoch 3: [782/10940] ---- BYOL Training Loss = 0.32014602422714233
31-01-2023 01:52:40 INFO Epoch 3: [793/10940] ---- BYOL Training Loss = 0.32693058252334595
31-01-2023 01:54:08 INFO Epoch 3: [793/10940] ---- BYOL Validation Loss = 0.29467079043388367
31-01-2023 01:54:36 INFO Epoch 3: [804/10940] ---- BYOL Training Loss = 0.2956983149051666
31-01-2023 01:55:03 INFO Epoch 3: [815/10940] ---- BYOL Training Loss = 0.3019099831581116
31-01-2023 01:55:31 INFO Epoch 3: [826/10940] ---- BYOL Training Loss = 0.31473594903945923
31-01-2023 01:55:58 INFO Epoch 3: [837/10940] ---- BYOL Training Loss = 0.260261595249176
31-01-2023 01:57:27 INFO Epoch 3: [837/10940] ---- BYOL Validation Loss = 0.2857607305049896
31-01-2023 01:57:54 INFO Epoch 3: [848/10940] ---- BYOL Training Loss = 0.24875521659851074
31-01-2023 01:58:22 INFO Epoch 3: [859/10940] ---- BYOL Training Loss = 0.23715606331825256
31-01-2023 01:58:49 INFO Epoch 3: [870/10940] ---- BYOL Training Loss = 0.2187139093875885
31-01-2023 01:59:17 INFO Epoch 3: [881/10940] ---- BYOL Training Loss = 0.2668629586696625
31-01-2023 02:00:45 INFO Epoch 3: [881/10940] ---- BYOL Validation Loss = 0.2818000018596649
31-01-2023 02:01:12 INFO Epoch 3: [892/10940] ---- BYOL Training Loss = 0.32369640469551086
31-01-2023 02:01:40 INFO Epoch 3: [903/10940] ---- BYOL Training Loss = 0.35024145245552063
31-01-2023 02:02:07 INFO Epoch 3: [914/10940] ---- BYOL Training Loss = 0.3001803457736969
31-01-2023 02:02:35 INFO Epoch 3: [925/10940] ---- BYOL Training Loss = 0.27831482887268066
31-01-2023 02:04:03 INFO Epoch 3: [925/10940] ---- BYOL Validation Loss = 0.286628782749176
31-01-2023 02:04:30 INFO Epoch 3: [936/10940] ---- BYOL Training Loss = 0.32390084862709045
31-01-2023 02:04:58 INFO Epoch 3: [947/10940] ---- BYOL Training Loss = 0.2867324650287628
31-01-2023 02:05:25 INFO Epoch 3: [958/10940] ---- BYOL Training Loss = 0.2583787143230438
31-01-2023 02:05:53 INFO Epoch 3: [969/10940] ---- BYOL Training Loss = 0.2945369780063629
31-01-2023 02:07:21 INFO Epoch 3: [969/10940] ---- BYOL Validation Loss = 0.2956756055355072
31-01-2023 02:07:49 INFO Epoch 3: [980/10940] ---- BYOL Training Loss = 0.2953483462333679
31-01-2023 02:08:16 INFO Epoch 3: [991/10940] ---- BYOL Training Loss = 0.3228929936885834
31-01-2023 02:08:43 INFO Epoch 3: [1002/10940] ---- BYOL Training Loss = 0.3405141532421112
31-01-2023 02:09:11 INFO Epoch 3: [1013/10940] ---- BYOL Training Loss = 0.303874135017395
31-01-2023 02:10:39 INFO Epoch 3: [1013/10940] ---- BYOL Validation Loss = 0.2787124216556549
31-01-2023 02:11:07 INFO Epoch 3: [1024/10940] ---- BYOL Training Loss = 0.2873533368110657
31-01-2023 02:11:34 INFO Epoch 3: [1035/10940] ---- BYOL Training Loss = 0.27106574177742004
31-01-2023 02:12:01 INFO Epoch 3: [1046/10940] ---- BYOL Training Loss = 0.3017355799674988
31-01-2023 02:12:29 INFO Epoch 3: [1057/10940] ---- BYOL Training Loss = 0.30146804451942444
31-01-2023 02:13:57 INFO Epoch 3: [1057/10940] ---- BYOL Validation Loss = 0.29787853360176086
31-01-2023 02:14:24 INFO Epoch 3: [1068/10940] ---- BYOL Training Loss = 0.2644858956336975
31-01-2023 02:14:52 INFO Epoch 3: [1079/10940] ---- BYOL Training Loss = 0.26650160551071167
31-01-2023 02:15:20 INFO Epoch 3: [1090/10940] ---- BYOL Training Loss = 0.2600421607494354
31-01-2023 02:15:47 INFO Epoch 3: [1101/10940] ---- BYOL Training Loss = 0.23635435104370117
31-01-2023 02:17:15 INFO Epoch 3: [1101/10940] ---- BYOL Validation Loss = 0.2893303334712982
31-01-2023 02:17:43 INFO Epoch 3: [1112/10940] ---- BYOL Training Loss = 0.32942551374435425
31-01-2023 02:18:11 INFO Epoch 3: [1123/10940] ---- BYOL Training Loss = 0.3378852605819702
31-01-2023 02:18:38 INFO Epoch 3: [1134/10940] ---- BYOL Training Loss = 0.2592429518699646
31-01-2023 02:19:06 INFO Epoch 3: [1145/10940] ---- BYOL Training Loss = 0.2873343527317047
31-01-2023 02:20:34 INFO Epoch 3: [1145/10940] ---- BYOL Validation Loss = 0.2980862259864807
31-01-2023 02:21:02 INFO Epoch 3: [1156/10940] ---- BYOL Training Loss = 0.27171316742897034
31-01-2023 02:21:29 INFO Epoch 3: [1167/10940] ---- BYOL Training Loss = 0.2688947021961212
31-01-2023 02:21:56 INFO Epoch 3: [1178/10940] ---- BYOL Training Loss = 0.2931712567806244
31-01-2023 02:22:24 INFO Epoch 3: [1189/10940] ---- BYOL Training Loss = 0.26921969652175903
31-01-2023 02:23:52 INFO Epoch 3: [1189/10940] ---- BYOL Validation Loss = 0.30039480328559875
31-01-2023 02:24:20 INFO Epoch 3: [1200/10940] ---- BYOL Training Loss = 0.27029281854629517
31-01-2023 02:24:47 INFO Epoch 3: [1211/10940] ---- BYOL Training Loss = 0.2904303967952728
31-01-2023 02:25:14 INFO Epoch 3: [1222/10940] ---- BYOL Training Loss = 0.29200056195259094
31-01-2023 02:25:42 INFO Epoch 3: [1233/10940] ---- BYOL Training Loss = 0.31573668122291565
31-01-2023 02:27:10 INFO Epoch 3: [1233/10940] ---- BYOL Validation Loss = 0.30614301562309265
31-01-2023 02:27:38 INFO Epoch 3: [1244/10940] ---- BYOL Training Loss = 0.32093554735183716
31-01-2023 02:28:05 INFO Epoch 3: [1255/10940] ---- BYOL Training Loss = 0.27506980299949646
31-01-2023 02:28:32 INFO Epoch 3: [1266/10940] ---- BYOL Training Loss = 0.2602783143520355
31-01-2023 02:29:00 INFO Epoch 3: [1277/10940] ---- BYOL Training Loss = 0.29881638288497925
31-01-2023 02:30:28 INFO Epoch 3: [1277/10940] ---- BYOL Validation Loss = 0.2964087426662445
31-01-2023 02:30:55 INFO Epoch 3: [1288/10940] ---- BYOL Training Loss = 0.3176898956298828
31-01-2023 02:31:23 INFO Epoch 3: [1299/10940] ---- BYOL Training Loss = 0.2904142737388611
31-01-2023 02:31:50 INFO Epoch 3: [1310/10940] ---- BYOL Training Loss = 0.32976409792900085
31-01-2023 02:32:18 INFO Epoch 3: [1321/10940] ---- BYOL Training Loss = 0.3831941485404968
31-01-2023 02:33:46 INFO Epoch 3: [1321/10940] ---- BYOL Validation Loss = 0.30106019973754883
31-01-2023 02:34:14 INFO Epoch 3: [1332/10940] ---- BYOL Training Loss = 0.3426579535007477
31-01-2023 02:34:41 INFO Epoch 3: [1343/10940] ---- BYOL Training Loss = 0.37090373039245605
31-01-2023 02:35:09 INFO Epoch 3: [1354/10940] ---- BYOL Training Loss = 0.31664758920669556
31-01-2023 02:35:36 INFO Epoch 3: [1365/10940] ---- BYOL Training Loss = 0.2692093253135681
31-01-2023 02:37:05 INFO Epoch 3: [1365/10940] ---- BYOL Validation Loss = 0.2954343259334564
31-01-2023 02:37:32 INFO Epoch 3: [1376/10940] ---- BYOL Training Loss = 0.28001031279563904
31-01-2023 02:38:00 INFO Epoch 3: [1387/10940] ---- BYOL Training Loss = 0.28882962465286255
31-01-2023 02:38:27 INFO Epoch 3: [1398/10940] ---- BYOL Training Loss = 0.3068338632583618
31-01-2023 02:38:54 INFO Epoch 3: [1409/10940] ---- BYOL Training Loss = 0.2828444242477417
31-01-2023 02:40:23 INFO Epoch 3: [1409/10940] ---- BYOL Validation Loss = 0.2988192141056061
31-01-2023 02:40:50 INFO Epoch 3: [1420/10940] ---- BYOL Training Loss = 0.275921493768692
31-01-2023 02:41:17 INFO Epoch 3: [1431/10940] ---- BYOL Training Loss = 0.34610357880592346
31-01-2023 02:41:45 INFO Epoch 3: [1442/10940] ---- BYOL Training Loss = 0.29802319407463074
31-01-2023 02:42:12 INFO Epoch 3: [1453/10940] ---- BYOL Training Loss = 0.26658838987350464
31-01-2023 02:43:41 INFO Epoch 3: [1453/10940] ---- BYOL Validation Loss = 0.304638147354126
31-01-2023 02:44:08 INFO Epoch 3: [1464/10940] ---- BYOL Training Loss = 0.27647924423217773
31-01-2023 02:44:36 INFO Epoch 3: [1475/10940] ---- BYOL Training Loss = 0.2937361001968384
31-01-2023 02:45:03 INFO Epoch 3: [1486/10940] ---- BYOL Training Loss = 0.3257283568382263
31-01-2023 02:45:31 INFO Epoch 3: [1497/10940] ---- BYOL Training Loss = 0.28024545311927795
31-01-2023 02:46:59 INFO Epoch 3: [1497/10940] ---- BYOL Validation Loss = 0.29918956756591797
31-01-2023 02:47:27 INFO Epoch 3: [1508/10940] ---- BYOL Training Loss = 0.2941926121711731
31-01-2023 02:47:54 INFO Epoch 3: [1519/10940] ---- BYOL Training Loss = 0.29316893219947815
31-01-2023 02:48:22 INFO Epoch 3: [1530/10940] ---- BYOL Training Loss = 0.2663278579711914
31-01-2023 02:48:50 INFO Epoch 3: [1541/10940] ---- BYOL Training Loss = 0.32786840200424194
31-01-2023 02:50:18 INFO Epoch 3: [1541/10940] ---- BYOL Validation Loss = 0.2953719198703766
31-01-2023 02:50:45 INFO Epoch 3: [1552/10940] ---- BYOL Training Loss = 0.32145294547080994
31-01-2023 02:51:13 INFO Epoch 3: [1563/10940] ---- BYOL Training Loss = 0.2711961269378662
31-01-2023 02:51:40 INFO Epoch 3: [1574/10940] ---- BYOL Training Loss = 0.29902327060699463
31-01-2023 02:52:08 INFO Epoch 3: [1585/10940] ---- BYOL Training Loss = 0.29190123081207275
31-01-2023 02:53:36 INFO Epoch 3: [1585/10940] ---- BYOL Validation Loss = 0.3030685484409332
31-01-2023 02:54:04 INFO Epoch 3: [1596/10940] ---- BYOL Training Loss = 0.27570468187332153
31-01-2023 02:54:31 INFO Epoch 3: [1607/10940] ---- BYOL Training Loss = 0.2712240517139435
31-01-2023 02:54:58 INFO Epoch 3: [1618/10940] ---- BYOL Training Loss = 0.25883620977401733
31-01-2023 02:55:26 INFO Epoch 3: [1629/10940] ---- BYOL Training Loss = 0.26995912194252014
31-01-2023 02:56:55 INFO Epoch 3: [1629/10940] ---- BYOL Validation Loss = 0.297836571931839
31-01-2023 02:57:22 INFO Epoch 3: [1640/10940] ---- BYOL Training Loss = 0.2570682168006897
31-01-2023 02:57:49 INFO Epoch 3: [1651/10940] ---- BYOL Training Loss = 0.24168094992637634
31-01-2023 02:58:17 INFO Epoch 3: [1662/10940] ---- BYOL Training Loss = 0.25002890825271606
31-01-2023 02:58:45 INFO Epoch 3: [1673/10940] ---- BYOL Training Loss = 0.26685577630996704
31-01-2023 03:00:13 INFO Epoch 3: [1673/10940] ---- BYOL Validation Loss = 0.2921397089958191
31-01-2023 03:00:41 INFO Epoch 3: [1684/10940] ---- BYOL Training Loss = 0.2646331489086151
31-01-2023 03:01:08 INFO Epoch 3: [1695/10940] ---- BYOL Training Loss = 0.2952408790588379
31-01-2023 03:01:36 INFO Epoch 3: [1706/10940] ---- BYOL Training Loss = 0.2735745310783386
31-01-2023 03:02:03 INFO Epoch 3: [1717/10940] ---- BYOL Training Loss = 0.30265507102012634
31-01-2023 03:03:32 INFO Epoch 3: [1717/10940] ---- BYOL Validation Loss = 0.29023632407188416
31-01-2023 03:03:59 INFO Epoch 3: [1728/10940] ---- BYOL Training Loss = 0.3175550103187561
31-01-2023 03:04:27 INFO Epoch 3: [1739/10940] ---- BYOL Training Loss = 0.2892504334449768
31-01-2023 03:04:54 INFO Epoch 3: [1750/10940] ---- BYOL Training Loss = 0.3080715239048004
31-01-2023 03:05:22 INFO Epoch 3: [1761/10940] ---- BYOL Training Loss = 0.31441032886505127
31-01-2023 03:06:50 INFO Epoch 3: [1761/10940] ---- BYOL Validation Loss = 0.3031233251094818
31-01-2023 03:07:18 INFO Epoch 3: [1772/10940] ---- BYOL Training Loss = 0.2725006341934204
31-01-2023 03:07:45 INFO Epoch 3: [1783/10940] ---- BYOL Training Loss = 0.2125428169965744
31-01-2023 03:08:13 INFO Epoch 3: [1794/10940] ---- BYOL Training Loss = 0.255693644285202
31-01-2023 03:08:41 INFO Epoch 3: [1805/10940] ---- BYOL Training Loss = 0.2697128653526306
31-01-2023 03:10:09 INFO Epoch 3: [1805/10940] ---- BYOL Validation Loss = 0.28571465611457825
31-01-2023 03:10:36 INFO Epoch 3: [1816/10940] ---- BYOL Training Loss = 0.25485700368881226
31-01-2023 03:11:04 INFO Epoch 3: [1827/10940] ---- BYOL Training Loss = 0.28472059965133667
31-01-2023 03:11:31 INFO Epoch 3: [1838/10940] ---- BYOL Training Loss = 0.275067538022995
31-01-2023 03:11:59 INFO Epoch 3: [1849/10940] ---- BYOL Training Loss = 0.23844364285469055
31-01-2023 03:13:27 INFO Epoch 3: [1849/10940] ---- BYOL Validation Loss = 0.29037660360336304
31-01-2023 03:13:55 INFO Epoch 3: [1860/10940] ---- BYOL Training Loss = 0.25947853922843933
31-01-2023 03:14:22 INFO Epoch 3: [1871/10940] ---- BYOL Training Loss = 0.3266385495662689
31-01-2023 03:14:50 INFO Epoch 3: [1882/10940] ---- BYOL Training Loss = 0.35347986221313477
31-01-2023 03:15:18 INFO Epoch 3: [1893/10940] ---- BYOL Training Loss = 0.34913840889930725
31-01-2023 03:16:46 INFO Epoch 3: [1893/10940] ---- BYOL Validation Loss = 0.3035735487937927
31-01-2023 03:17:13 INFO Epoch 3: [1904/10940] ---- BYOL Training Loss = 0.341327965259552
31-01-2023 03:17:41 INFO Epoch 3: [1915/10940] ---- BYOL Training Loss = 0.2853401303291321
31-01-2023 03:18:08 INFO Epoch 3: [1926/10940] ---- BYOL Training Loss = 0.25794896483421326
31-01-2023 03:18:36 INFO Epoch 3: [1937/10940] ---- BYOL Training Loss = 0.28338947892189026
31-01-2023 03:20:04 INFO Epoch 3: [1937/10940] ---- BYOL Validation Loss = 0.2906300723552704
31-01-2023 03:20:31 INFO Epoch 3: [1948/10940] ---- BYOL Training Loss = 0.29664090275764465
31-01-2023 03:20:59 INFO Epoch 3: [1959/10940] ---- BYOL Training Loss = 0.30447402596473694
31-01-2023 03:21:27 INFO Epoch 3: [1970/10940] ---- BYOL Training Loss = 0.3113810420036316
31-01-2023 03:21:54 INFO Epoch 3: [1981/10940] ---- BYOL Training Loss = 0.31791162490844727
31-01-2023 03:23:22 INFO Epoch 3: [1981/10940] ---- BYOL Validation Loss = 0.29350969195365906
31-01-2023 03:23:50 INFO Epoch 3: [1992/10940] ---- BYOL Training Loss = 0.2474452704191208
31-01-2023 03:24:18 INFO Epoch 3: [2003/10940] ---- BYOL Training Loss = 0.23816271126270294
31-01-2023 03:24:45 INFO Epoch 3: [2014/10940] ---- BYOL Training Loss = 0.26276734471321106
31-01-2023 03:25:13 INFO Epoch 3: [2025/10940] ---- BYOL Training Loss = 0.27623996138572693
31-01-2023 03:26:41 INFO Epoch 3: [2025/10940] ---- BYOL Validation Loss = 0.28534236550331116
31-01-2023 03:27:08 INFO Epoch 3: [2036/10940] ---- BYOL Training Loss = 0.23519253730773926
31-01-2023 03:27:36 INFO Epoch 3: [2047/10940] ---- BYOL Training Loss = 0.21192403137683868
31-01-2023 03:28:04 INFO Epoch 3: [2058/10940] ---- BYOL Training Loss = 0.22782599925994873
31-01-2023 03:28:31 INFO Epoch 3: [2069/10940] ---- BYOL Training Loss = 0.27174708247184753
31-01-2023 03:29:59 INFO Epoch 3: [2069/10940] ---- BYOL Validation Loss = 0.2884907126426697
31-01-2023 03:30:27 INFO Epoch 3: [2080/10940] ---- BYOL Training Loss = 0.2971222698688507
31-01-2023 03:30:55 INFO Epoch 3: [2091/10940] ---- BYOL Training Loss = 0.34570664167404175
31-01-2023 03:31:22 INFO Epoch 3: [2102/10940] ---- BYOL Training Loss = 0.2771618962287903
31-01-2023 03:31:50 INFO Epoch 3: [2113/10940] ---- BYOL Training Loss = 0.24146175384521484
31-01-2023 03:33:18 INFO Epoch 3: [2113/10940] ---- BYOL Validation Loss = 0.3303067982196808
31-01-2023 03:33:46 INFO Epoch 3: [2124/10940] ---- BYOL Training Loss = 0.2815960645675659
31-01-2023 03:34:13 INFO Epoch 3: [2135/10940] ---- BYOL Training Loss = 0.2936334013938904
31-01-2023 03:34:41 INFO Epoch 3: [2146/10940] ---- BYOL Training Loss = 0.3155340850353241
31-01-2023 03:35:08 INFO Epoch 3: [2157/10940] ---- BYOL Training Loss = 0.29130494594573975
31-01-2023 03:36:37 INFO Epoch 3: [2157/10940] ---- BYOL Validation Loss = 0.29548391699790955
31-01-2023 03:37:04 INFO Epoch 3: [2168/10940] ---- BYOL Training Loss = 0.26033657789230347
31-01-2023 03:37:32 INFO Epoch 3: [2179/10940] ---- BYOL Training Loss = 0.29673677682876587
31-01-2023 03:38:00 INFO Epoch 3: [2190/10940] ---- BYOL Training Loss = 0.36253875494003296
31-01-2023 03:38:27 INFO Epoch 3: [2201/10940] ---- BYOL Training Loss = 0.3351585566997528
31-01-2023 03:39:55 INFO Epoch 3: [2201/10940] ---- BYOL Validation Loss = 0.29916271567344666
31-01-2023 03:40:23 INFO Epoch 3: [2212/10940] ---- BYOL Training Loss = 0.2547920346260071
31-01-2023 03:40:50 INFO Epoch 3: [2223/10940] ---- BYOL Training Loss = 0.25544577836990356
31-01-2023 03:41:18 INFO Epoch 3: [2234/10940] ---- BYOL Training Loss = 0.2882329523563385
31-01-2023 03:41:45 INFO Epoch 3: [2245/10940] ---- BYOL Training Loss = 0.3045404851436615
31-01-2023 03:43:14 INFO Epoch 3: [2245/10940] ---- BYOL Validation Loss = 0.29953834414482117
31-01-2023 03:43:41 INFO Epoch 3: [2256/10940] ---- BYOL Training Loss = 0.3220818042755127
31-01-2023 03:44:09 INFO Epoch 3: [2267/10940] ---- BYOL Training Loss = 0.30027762055397034
31-01-2023 03:44:37 INFO Epoch 3: [2278/10940] ---- BYOL Training Loss = 0.298519492149353
31-01-2023 03:45:04 INFO Epoch 3: [2289/10940] ---- BYOL Training Loss = 0.2720324993133545
31-01-2023 03:46:32 INFO Epoch 3: [2289/10940] ---- BYOL Validation Loss = 0.28392985463142395
31-01-2023 03:47:00 INFO Epoch 3: [2300/10940] ---- BYOL Training Loss = 0.24829211831092834
31-01-2023 03:47:27 INFO Epoch 3: [2311/10940] ---- BYOL Training Loss = 0.24482187628746033
31-01-2023 03:47:55 INFO Epoch 3: [2322/10940] ---- BYOL Training Loss = 0.2849421799182892
31-01-2023 03:48:23 INFO Epoch 3: [2333/10940] ---- BYOL Training Loss = 0.3048272132873535
31-01-2023 03:49:51 INFO Epoch 3: [2333/10940] ---- BYOL Validation Loss = 0.29285454750061035
31-01-2023 03:50:18 INFO Epoch 3: [2344/10940] ---- BYOL Training Loss = 0.3164953291416168
31-01-2023 03:50:46 INFO Epoch 3: [2355/10940] ---- BYOL Training Loss = 0.30647486448287964
31-01-2023 03:51:13 INFO Epoch 3: [2366/10940] ---- BYOL Training Loss = 0.297865629196167
31-01-2023 03:51:41 INFO Epoch 3: [2377/10940] ---- BYOL Training Loss = 0.2961990237236023
31-01-2023 03:53:09 INFO Epoch 3: [2377/10940] ---- BYOL Validation Loss = 0.30298998951911926
31-01-2023 03:53:37 INFO Epoch 3: [2388/10940] ---- BYOL Training Loss = 0.29370802640914917
31-01-2023 03:54:05 INFO Epoch 3: [2399/10940] ---- BYOL Training Loss = 0.26247087121009827
31-01-2023 03:54:32 INFO Epoch 3: [2410/10940] ---- BYOL Training Loss = 0.3039824366569519
31-01-2023 03:55:00 INFO Epoch 3: [2421/10940] ---- BYOL Training Loss = 0.3209373652935028
31-01-2023 03:56:28 INFO Epoch 3: [2421/10940] ---- BYOL Validation Loss = 0.29534897208213806
31-01-2023 03:56:55 INFO Epoch 3: [2432/10940] ---- BYOL Training Loss = 0.2760147452354431
31-01-2023 03:57:23 INFO Epoch 3: [2443/10940] ---- BYOL Training Loss = 0.3142640292644501
31-01-2023 03:57:50 INFO Epoch 3: [2454/10940] ---- BYOL Training Loss = 0.32213300466537476
31-01-2023 03:58:18 INFO Epoch 3: [2465/10940] ---- BYOL Training Loss = 0.32560089230537415
31-01-2023 03:59:46 INFO Epoch 3: [2465/10940] ---- BYOL Validation Loss = 0.2864740490913391
31-01-2023 04:00:14 INFO Epoch 3: [2476/10940] ---- BYOL Training Loss = 0.27503079175949097
31-01-2023 04:00:42 INFO Epoch 3: [2487/10940] ---- BYOL Training Loss = 0.2778189778327942
31-01-2023 04:01:09 INFO Epoch 3: [2498/10940] ---- BYOL Training Loss = 0.3051060140132904
31-01-2023 04:01:37 INFO Epoch 3: [2509/10940] ---- BYOL Training Loss = 0.2614266574382782
31-01-2023 04:03:05 INFO Epoch 3: [2509/10940] ---- BYOL Validation Loss = 0.289205938577652
31-01-2023 04:03:33 INFO Epoch 3: [2520/10940] ---- BYOL Training Loss = 0.2835034132003784
31-01-2023 04:04:00 INFO Epoch 3: [2531/10940] ---- BYOL Training Loss = 0.2749139070510864
31-01-2023 04:04:28 INFO Epoch 3: [2542/10940] ---- BYOL Training Loss = 0.2664971351623535
31-01-2023 04:04:55 INFO Epoch 3: [2553/10940] ---- BYOL Training Loss = 0.21556596457958221
31-01-2023 04:06:23 INFO Epoch 3: [2553/10940] ---- BYOL Validation Loss = 0.29328569769859314
31-01-2023 04:06:51 INFO Epoch 3: [2564/10940] ---- BYOL Training Loss = 0.2425827533006668
31-01-2023 04:07:19 INFO Epoch 3: [2575/10940] ---- BYOL Training Loss = 0.2508313059806824
31-01-2023 04:07:47 INFO Epoch 3: [2586/10940] ---- BYOL Training Loss = 0.28818702697753906
31-01-2023 04:08:15 INFO Epoch 3: [2597/10940] ---- BYOL Training Loss = 0.25840064883232117
31-01-2023 04:09:43 INFO Epoch 3: [2597/10940] ---- BYOL Validation Loss = 0.3048940598964691
31-01-2023 04:10:11 INFO Epoch 3: [2608/10940] ---- BYOL Training Loss = 0.26488834619522095
31-01-2023 04:10:39 INFO Epoch 3: [2619/10940] ---- BYOL Training Loss = 0.2812780737876892
31-01-2023 04:11:06 INFO Epoch 3: [2630/10940] ---- BYOL Training Loss = 0.2611271142959595
31-01-2023 04:11:34 INFO Epoch 3: [2641/10940] ---- BYOL Training Loss = 0.25095969438552856
31-01-2023 04:13:02 INFO Epoch 3: [2641/10940] ---- BYOL Validation Loss = 0.29314762353897095
31-01-2023 04:13:30 INFO Epoch 3: [2652/10940] ---- BYOL Training Loss = 0.26204484701156616
31-01-2023 04:13:58 INFO Epoch 3: [2663/10940] ---- BYOL Training Loss = 0.2650027275085449
31-01-2023 04:14:25 INFO Epoch 3: [2674/10940] ---- BYOL Training Loss = 0.26358622312545776
31-01-2023 04:14:53 INFO Epoch 3: [2685/10940] ---- BYOL Training Loss = 0.2836616337299347
31-01-2023 04:16:21 INFO Epoch 3: [2685/10940] ---- BYOL Validation Loss = 0.29835614562034607
31-01-2023 04:16:48 INFO Epoch 3: [2696/10940] ---- BYOL Training Loss = 0.3041561543941498
31-01-2023 04:17:16 INFO Epoch 3: [2707/10940] ---- BYOL Training Loss = 0.2647867202758789
31-01-2023 04:17:44 INFO Epoch 3: [2718/10940] ---- BYOL Training Loss = 0.28074654936790466
31-01-2023 04:18:11 INFO Epoch 3: [2729/10940] ---- BYOL Training Loss = 0.3097456991672516
31-01-2023 04:19:40 INFO Epoch 3: [2729/10940] ---- BYOL Validation Loss = 0.30590227246284485
31-01-2023 04:20:08 INFO Epoch 3: [2740/10940] ---- BYOL Training Loss = 0.31429967284202576
31-01-2023 04:20:35 INFO Epoch 3: [2751/10940] ---- BYOL Training Loss = 0.2967228591442108
31-01-2023 04:21:03 INFO Epoch 3: [2762/10940] ---- BYOL Training Loss = 0.2960652709007263
31-01-2023 04:21:31 INFO Epoch 3: [2773/10940] ---- BYOL Training Loss = 0.31802037358283997
31-01-2023 04:22:59 INFO Epoch 3: [2773/10940] ---- BYOL Validation Loss = 0.2928776144981384
31-01-2023 04:23:27 INFO Epoch 3: [2784/10940] ---- BYOL Training Loss = 0.2776908874511719
31-01-2023 04:23:54 INFO Epoch 3: [2795/10940] ---- BYOL Training Loss = 0.273102730512619
31-01-2023 04:24:22 INFO Epoch 3: [2806/10940] ---- BYOL Training Loss = 0.27706074714660645
31-01-2023 04:24:49 INFO Epoch 3: [2817/10940] ---- BYOL Training Loss = 0.30669671297073364
31-01-2023 04:26:18 INFO Epoch 3: [2817/10940] ---- BYOL Validation Loss = 0.30602899193763733
31-01-2023 04:26:45 INFO Epoch 3: [2828/10940] ---- BYOL Training Loss = 0.2891290783882141
31-01-2023 04:27:13 INFO Epoch 3: [2839/10940] ---- BYOL Training Loss = 0.31077471375465393
31-01-2023 04:27:41 INFO Epoch 3: [2850/10940] ---- BYOL Training Loss = 0.2964736521244049
31-01-2023 04:28:08 INFO Epoch 3: [2861/10940] ---- BYOL Training Loss = 0.3253519535064697
31-01-2023 04:29:37 INFO Epoch 3: [2861/10940] ---- BYOL Validation Loss = 0.29929277300834656
31-01-2023 04:30:04 INFO Epoch 3: [2872/10940] ---- BYOL Training Loss = 0.3513581454753876
31-01-2023 04:30:32 INFO Epoch 3: [2883/10940] ---- BYOL Training Loss = 0.3459317982196808
31-01-2023 04:31:00 INFO Epoch 3: [2894/10940] ---- BYOL Training Loss = 0.31186342239379883
31-01-2023 04:31:27 INFO Epoch 3: [2905/10940] ---- BYOL Training Loss = 0.31520336866378784
31-01-2023 04:32:55 INFO Epoch 3: [2905/10940] ---- BYOL Validation Loss = 0.2946415841579437
31-01-2023 04:33:23 INFO Epoch 3: [2916/10940] ---- BYOL Training Loss = 0.31128937005996704
31-01-2023 04:33:51 INFO Epoch 3: [2927/10940] ---- BYOL Training Loss = 0.2579203248023987
31-01-2023 04:34:19 INFO Epoch 3: [2938/10940] ---- BYOL Training Loss = 0.2650904655456543
31-01-2023 04:34:46 INFO Epoch 3: [2949/10940] ---- BYOL Training Loss = 0.30729493498802185
31-01-2023 04:36:14 INFO Epoch 3: [2949/10940] ---- BYOL Validation Loss = 0.3012000024318695
31-01-2023 04:36:42 INFO Epoch 3: [2960/10940] ---- BYOL Training Loss = 0.2867969870567322
31-01-2023 04:37:10 INFO Epoch 3: [2971/10940] ---- BYOL Training Loss = 0.2881281077861786
31-01-2023 04:37:37 INFO Epoch 3: [2982/10940] ---- BYOL Training Loss = 0.25049716234207153
31-01-2023 04:38:05 INFO Epoch 3: [2993/10940] ---- BYOL Training Loss = 0.2610870599746704
31-01-2023 04:39:33 INFO Epoch 3: [2993/10940] ---- BYOL Validation Loss = 0.30471426248550415
31-01-2023 04:40:01 INFO Epoch 3: [3004/10940] ---- BYOL Training Loss = 0.2739446461200714
31-01-2023 04:40:29 INFO Epoch 3: [3015/10940] ---- BYOL Training Loss = 0.25664496421813965
31-01-2023 04:40:57 INFO Epoch 3: [3026/10940] ---- BYOL Training Loss = 0.2909310460090637
31-01-2023 04:41:24 INFO Epoch 3: [3037/10940] ---- BYOL Training Loss = 0.3115426301956177
31-01-2023 04:42:52 INFO Epoch 3: [3037/10940] ---- BYOL Validation Loss = 0.3026462197303772
31-01-2023 04:43:20 INFO Epoch 3: [3048/10940] ---- BYOL Training Loss = 0.32736024260520935
31-01-2023 04:43:48 INFO Epoch 3: [3059/10940] ---- BYOL Training Loss = 0.33240023255348206
31-01-2023 04:44:15 INFO Epoch 3: [3070/10940] ---- BYOL Training Loss = 0.27046316862106323
31-01-2023 04:44:43 INFO Epoch 3: [3081/10940] ---- BYOL Training Loss = 0.2931353449821472
31-01-2023 04:46:11 INFO Epoch 3: [3081/10940] ---- BYOL Validation Loss = 0.28960734605789185
31-01-2023 04:46:39 INFO Epoch 3: [3092/10940] ---- BYOL Training Loss = 0.29513418674468994
31-01-2023 04:47:06 INFO Epoch 3: [3103/10940] ---- BYOL Training Loss = 0.3003721237182617
31-01-2023 04:47:34 INFO Epoch 3: [3114/10940] ---- BYOL Training Loss = 0.29990535974502563
31-01-2023 04:48:01 INFO Epoch 3: [3125/10940] ---- BYOL Training Loss = 0.25635766983032227
31-01-2023 04:49:29 INFO Epoch 3: [3125/10940] ---- BYOL Validation Loss = 0.2878517508506775
31-01-2023 04:49:57 INFO Epoch 3: [3136/10940] ---- BYOL Training Loss = 0.24263355135917664
31-01-2023 04:50:25 INFO Epoch 3: [3147/10940] ---- BYOL Training Loss = 0.2924242913722992
31-01-2023 04:50:53 INFO Epoch 3: [3158/10940] ---- BYOL Training Loss = 0.2788159251213074
31-01-2023 04:51:20 INFO Epoch 3: [3169/10940] ---- BYOL Training Loss = 0.3193379044532776
31-01-2023 04:52:49 INFO Epoch 3: [3169/10940] ---- BYOL Validation Loss = 0.29784610867500305
31-01-2023 04:53:16 INFO Epoch 3: [3180/10940] ---- BYOL Training Loss = 0.2681695520877838
31-01-2023 04:53:44 INFO Epoch 3: [3191/10940] ---- BYOL Training Loss = 0.2426917999982834
31-01-2023 04:54:12 INFO Epoch 3: [3202/10940] ---- BYOL Training Loss = 0.2770631015300751
31-01-2023 04:54:39 INFO Epoch 3: [3213/10940] ---- BYOL Training Loss = 0.27372246980667114
31-01-2023 04:56:07 INFO Epoch 3: [3213/10940] ---- BYOL Validation Loss = 0.29578477144241333
31-01-2023 04:56:36 INFO Epoch 3: [3224/10940] ---- BYOL Training Loss = 0.2831975519657135
31-01-2023 04:57:03 INFO Epoch 3: [3235/10940] ---- BYOL Training Loss = 0.2593045234680176
31-01-2023 04:57:31 INFO Epoch 3: [3246/10940] ---- BYOL Training Loss = 0.3164520859718323
31-01-2023 04:57:59 INFO Epoch 3: [3257/10940] ---- BYOL Training Loss = 0.3263504207134247
31-01-2023 04:59:39 INFO Epoch 3: [3257/10940] ---- BYOL Validation Loss = 0.2902842164039612
31-01-2023 05:00:07 INFO Epoch 3: [3268/10940] ---- BYOL Training Loss = 0.30080151557922363
31-01-2023 05:00:34 INFO Epoch 3: [3279/10940] ---- BYOL Training Loss = 0.31688982248306274
31-01-2023 05:01:02 INFO Epoch 3: [3290/10940] ---- BYOL Training Loss = 0.31856074929237366
31-01-2023 05:01:30 INFO Epoch 3: [3301/10940] ---- BYOL Training Loss = 0.29000595211982727
31-01-2023 05:02:58 INFO Epoch 3: [3301/10940] ---- BYOL Validation Loss = 0.29384979605674744
31-01-2023 05:03:26 INFO Epoch 3: [3312/10940] ---- BYOL Training Loss = 0.31345415115356445
31-01-2023 05:03:53 INFO Epoch 3: [3323/10940] ---- BYOL Training Loss = 0.3210647702217102
31-01-2023 05:04:21 INFO Epoch 3: [3334/10940] ---- BYOL Training Loss = 0.2931550443172455
31-01-2023 05:04:48 INFO Epoch 3: [3345/10940] ---- BYOL Training Loss = 0.2722889184951782
31-01-2023 05:06:17 INFO Epoch 3: [3345/10940] ---- BYOL Validation Loss = 0.2978045344352722
31-01-2023 05:06:44 INFO Epoch 3: [3356/10940] ---- BYOL Training Loss = 0.260062038898468
31-01-2023 05:07:12 INFO Epoch 3: [3367/10940] ---- BYOL Training Loss = 0.28897640109062195
31-01-2023 05:07:40 INFO Epoch 3: [3378/10940] ---- BYOL Training Loss = 0.30583909153938293
31-01-2023 05:08:08 INFO Epoch 3: [3389/10940] ---- BYOL Training Loss = 0.2756480574607849
31-01-2023 05:09:36 INFO Epoch 3: [3389/10940] ---- BYOL Validation Loss = 0.29649072885513306
31-01-2023 05:10:03 INFO Epoch 3: [3400/10940] ---- BYOL Training Loss = 0.29148879647254944
31-01-2023 05:10:31 INFO Epoch 3: [3411/10940] ---- BYOL Training Loss = 0.2985104024410248
31-01-2023 05:10:59 INFO Epoch 3: [3422/10940] ---- BYOL Training Loss = 0.32256704568862915
31-01-2023 05:11:27 INFO Epoch 3: [3433/10940] ---- BYOL Training Loss = 0.29142704606056213
31-01-2023 05:12:55 INFO Epoch 3: [3433/10940] ---- BYOL Validation Loss = 0.3066961467266083
31-01-2023 05:13:23 INFO Epoch 3: [3444/10940] ---- BYOL Training Loss = 0.27203282713890076
31-01-2023 05:13:50 INFO Epoch 3: [3455/10940] ---- BYOL Training Loss = 0.32858413457870483
31-01-2023 05:14:18 INFO Epoch 3: [3466/10940] ---- BYOL Training Loss = 0.3258533179759979
31-01-2023 05:14:45 INFO Epoch 3: [3477/10940] ---- BYOL Training Loss = 0.24992123246192932
31-01-2023 05:16:13 INFO Epoch 3: [3477/10940] ---- BYOL Validation Loss = 0.2897464632987976
31-01-2023 05:16:41 INFO Epoch 3: [3488/10940] ---- BYOL Training Loss = 0.2643009126186371
31-01-2023 05:17:09 INFO Epoch 3: [3499/10940] ---- BYOL Training Loss = 0.3114944100379944
31-01-2023 05:17:36 INFO Epoch 3: [3510/10940] ---- BYOL Training Loss = 0.34165361523628235
31-01-2023 05:18:04 INFO Epoch 3: [3521/10940] ---- BYOL Training Loss = 0.2831796109676361
slurmstepd-landonia22: error: *** JOB 1507988 ON landonia22 CANCELLED AT 2023-01-31T05:19:14 DUE TO TIME LIMIT ***
