30-01-2023 05:20:08 INFO Running main & importing modules...
30-01-2023 05:20:24 INFO Parsed arguments: Namespace(batch_size=32, byol_ema_tau=0.8, debug=False, encoder='resnet18', encoder_layer_idx=-2, epochs=5, experiment_name='b-presnet18-e5-b32-t0_8-p64', input='/disk/scratch_big/s1908368/data', log_interval=1000, lr=0.001, output='/disk/scratch_big/s1908368/output', patch_size=64, pretrain_encoder=True, seed=23, simclr_tau=0.99, train_proportion=0.98, use_byol=True)
30-01-2023 05:20:24 INFO File at /disk/scratch_big/s1908368/data/patch_train_dataset_64.pk: True
30-01-2023 05:20:24 INFO File at /disk/scratch_big/s1908368/data/patch_val_dataset_64.pk: True
30-01-2023 05:20:33 INFO Generated training dataset with 350062 samples.
30-01-2023 05:20:33 INFO Generated validation dataset with 7145 samples.
30-01-2023 05:20:33 INFO Using encoder resnet18 with pretrained weights = True
30-01-2023 05:20:33 INFO Using BYOL with tau = 0.8, with encoder layer index = -2
30-01-2023 05:20:33 INFO Using device: cuda
30-01-2023 05:20:37 INFO Starting Epoch: 1
30-01-2023 05:20:55 INFO Epoch 1: [12/10940] ---- BYOL Training Loss = 2.1814160346984863
30-01-2023 05:21:12 INFO Epoch 1: [23/10940] ---- BYOL Training Loss = 1.6923208236694336
30-01-2023 05:21:29 INFO Epoch 1: [34/10940] ---- BYOL Training Loss = 1.2582252025604248
30-01-2023 05:21:47 INFO Epoch 1: [45/10940] ---- BYOL Training Loss = 1.078070044517517
30-01-2023 05:22:39 INFO Epoch 1: [45/10940] ---- BYOL Validation Loss = 0.9950899481773376
30-01-2023 05:22:56 INFO Epoch 1: [56/10940] ---- BYOL Training Loss = 0.994839072227478
30-01-2023 05:23:13 INFO Epoch 1: [67/10940] ---- BYOL Training Loss = 0.865654468536377
30-01-2023 05:23:31 INFO Epoch 1: [78/10940] ---- BYOL Training Loss = 0.7735003232955933
30-01-2023 05:23:48 INFO Epoch 1: [89/10940] ---- BYOL Training Loss = 0.6780553460121155
30-01-2023 05:24:40 INFO Epoch 1: [89/10940] ---- BYOL Validation Loss = 0.6411522626876831
30-01-2023 05:24:57 INFO Epoch 1: [100/10940] ---- BYOL Training Loss = 0.6874183416366577
30-01-2023 05:25:15 INFO Epoch 1: [111/10940] ---- BYOL Training Loss = 0.6609368920326233
30-01-2023 05:25:32 INFO Epoch 1: [122/10940] ---- BYOL Training Loss = 0.6207329034805298
30-01-2023 05:25:50 INFO Epoch 1: [133/10940] ---- BYOL Training Loss = 0.6114516258239746
30-01-2023 05:26:42 INFO Epoch 1: [133/10940] ---- BYOL Validation Loss = 0.5114848613739014
30-01-2023 05:26:59 INFO Epoch 1: [144/10940] ---- BYOL Training Loss = 0.5749154686927795
30-01-2023 05:27:17 INFO Epoch 1: [155/10940] ---- BYOL Training Loss = 0.5038899183273315
30-01-2023 05:27:34 INFO Epoch 1: [166/10940] ---- BYOL Training Loss = 0.49537724256515503
30-01-2023 05:27:52 INFO Epoch 1: [177/10940] ---- BYOL Training Loss = 0.5869879722595215
30-01-2023 05:28:44 INFO Epoch 1: [177/10940] ---- BYOL Validation Loss = 0.4448104500770569
30-01-2023 05:29:02 INFO Epoch 1: [188/10940] ---- BYOL Training Loss = 0.564937174320221
30-01-2023 05:29:19 INFO Epoch 1: [199/10940] ---- BYOL Training Loss = 0.5122506022453308
30-01-2023 05:29:37 INFO Epoch 1: [210/10940] ---- BYOL Training Loss = 0.46035876870155334
30-01-2023 05:29:54 INFO Epoch 1: [221/10940] ---- BYOL Training Loss = 0.41241654753685
30-01-2023 05:30:46 INFO Epoch 1: [221/10940] ---- BYOL Validation Loss = 0.39775532484054565
30-01-2023 05:31:04 INFO Epoch 1: [232/10940] ---- BYOL Training Loss = 0.47657686471939087
30-01-2023 05:31:21 INFO Epoch 1: [243/10940] ---- BYOL Training Loss = 0.46990084648132324
30-01-2023 05:31:39 INFO Epoch 1: [254/10940] ---- BYOL Training Loss = 0.4483267366886139
30-01-2023 05:31:56 INFO Epoch 1: [265/10940] ---- BYOL Training Loss = 0.4644537568092346
30-01-2023 05:32:48 INFO Epoch 1: [265/10940] ---- BYOL Validation Loss = 0.41111209988594055
30-01-2023 05:33:05 INFO Epoch 1: [276/10940] ---- BYOL Training Loss = 0.4792301654815674
30-01-2023 05:33:23 INFO Epoch 1: [287/10940] ---- BYOL Training Loss = 0.4378342628479004
30-01-2023 05:33:40 INFO Epoch 1: [298/10940] ---- BYOL Training Loss = 0.4334527850151062
30-01-2023 05:33:58 INFO Epoch 1: [309/10940] ---- BYOL Training Loss = 0.4742017686367035
30-01-2023 05:34:50 INFO Epoch 1: [309/10940] ---- BYOL Validation Loss = 0.44951966404914856
30-01-2023 05:35:07 INFO Epoch 1: [320/10940] ---- BYOL Training Loss = 0.48038387298583984
30-01-2023 05:35:25 INFO Epoch 1: [331/10940] ---- BYOL Training Loss = 0.5296199321746826
30-01-2023 05:35:42 INFO Epoch 1: [342/10940] ---- BYOL Training Loss = 0.5277758240699768
30-01-2023 05:36:00 INFO Epoch 1: [353/10940] ---- BYOL Training Loss = 0.49224114418029785
30-01-2023 05:36:52 INFO Epoch 1: [353/10940] ---- BYOL Validation Loss = 0.43153318762779236
30-01-2023 05:37:09 INFO Epoch 1: [364/10940] ---- BYOL Training Loss = 0.5081347227096558
30-01-2023 05:37:27 INFO Epoch 1: [375/10940] ---- BYOL Training Loss = 0.5165110230445862
30-01-2023 05:37:45 INFO Epoch 1: [386/10940] ---- BYOL Training Loss = 0.5279695987701416
30-01-2023 05:38:02 INFO Epoch 1: [397/10940] ---- BYOL Training Loss = 0.5306115746498108
30-01-2023 05:38:54 INFO Epoch 1: [397/10940] ---- BYOL Validation Loss = 0.4127548635005951
30-01-2023 05:39:12 INFO Epoch 1: [408/10940] ---- BYOL Training Loss = 0.46139517426490784
30-01-2023 05:39:29 INFO Epoch 1: [419/10940] ---- BYOL Training Loss = 0.4367738366127014
30-01-2023 05:39:47 INFO Epoch 1: [430/10940] ---- BYOL Training Loss = 0.4342886805534363
30-01-2023 05:40:04 INFO Epoch 1: [441/10940] ---- BYOL Training Loss = 0.36051565408706665
30-01-2023 05:40:57 INFO Epoch 1: [441/10940] ---- BYOL Validation Loss = 0.4090321660041809
30-01-2023 05:41:14 INFO Epoch 1: [452/10940] ---- BYOL Training Loss = 0.39888960123062134
30-01-2023 05:41:31 INFO Epoch 1: [463/10940] ---- BYOL Training Loss = 0.4209863543510437
30-01-2023 05:41:49 INFO Epoch 1: [474/10940] ---- BYOL Training Loss = 0.4423144459724426
30-01-2023 05:42:06 INFO Epoch 1: [485/10940] ---- BYOL Training Loss = 0.3678821921348572
30-01-2023 05:42:59 INFO Epoch 1: [485/10940] ---- BYOL Validation Loss = 0.3914879858493805
30-01-2023 05:43:16 INFO Epoch 1: [496/10940] ---- BYOL Training Loss = 0.3731983006000519
30-01-2023 05:43:33 INFO Epoch 1: [507/10940] ---- BYOL Training Loss = 0.4538893699645996
30-01-2023 05:43:51 INFO Epoch 1: [518/10940] ---- BYOL Training Loss = 0.4284917414188385
30-01-2023 05:44:08 INFO Epoch 1: [529/10940] ---- BYOL Training Loss = 0.42570924758911133
30-01-2023 05:45:00 INFO Epoch 1: [529/10940] ---- BYOL Validation Loss = 0.39175742864608765
30-01-2023 05:45:18 INFO Epoch 1: [540/10940] ---- BYOL Training Loss = 0.42697983980178833
30-01-2023 05:45:35 INFO Epoch 1: [551/10940] ---- BYOL Training Loss = 0.4389750063419342
30-01-2023 05:45:53 INFO Epoch 1: [562/10940] ---- BYOL Training Loss = 0.38383182883262634
30-01-2023 05:46:10 INFO Epoch 1: [573/10940] ---- BYOL Training Loss = 0.3987536132335663
30-01-2023 05:47:02 INFO Epoch 1: [573/10940] ---- BYOL Validation Loss = 0.3879271149635315
30-01-2023 05:47:20 INFO Epoch 1: [584/10940] ---- BYOL Training Loss = 0.37102288007736206
30-01-2023 05:47:37 INFO Epoch 1: [595/10940] ---- BYOL Training Loss = 0.37708890438079834
30-01-2023 05:47:55 INFO Epoch 1: [606/10940] ---- BYOL Training Loss = 0.45046907663345337
30-01-2023 05:48:12 INFO Epoch 1: [617/10940] ---- BYOL Training Loss = 0.457023948431015
30-01-2023 05:49:05 INFO Epoch 1: [617/10940] ---- BYOL Validation Loss = 0.37542468309402466
30-01-2023 05:49:22 INFO Epoch 1: [628/10940] ---- BYOL Training Loss = 0.39916688203811646
30-01-2023 05:49:39 INFO Epoch 1: [639/10940] ---- BYOL Training Loss = 0.46921658515930176
30-01-2023 05:49:57 INFO Epoch 1: [650/10940] ---- BYOL Training Loss = 0.4692741930484772
30-01-2023 05:50:15 INFO Epoch 1: [661/10940] ---- BYOL Training Loss = 0.46022266149520874
30-01-2023 05:51:07 INFO Epoch 1: [661/10940] ---- BYOL Validation Loss = 0.3714872896671295
30-01-2023 05:51:24 INFO Epoch 1: [672/10940] ---- BYOL Training Loss = 0.4902380406856537
30-01-2023 05:51:42 INFO Epoch 1: [683/10940] ---- BYOL Training Loss = 0.4380815029144287
30-01-2023 05:51:59 INFO Epoch 1: [694/10940] ---- BYOL Training Loss = 0.39860811829566956
30-01-2023 05:52:17 INFO Epoch 1: [705/10940] ---- BYOL Training Loss = 0.44038206338882446
30-01-2023 05:53:09 INFO Epoch 1: [705/10940] ---- BYOL Validation Loss = 0.3852818012237549
30-01-2023 05:53:26 INFO Epoch 1: [716/10940] ---- BYOL Training Loss = 0.4410305619239807
30-01-2023 05:53:44 INFO Epoch 1: [727/10940] ---- BYOL Training Loss = 0.4171704649925232
30-01-2023 05:54:02 INFO Epoch 1: [738/10940] ---- BYOL Training Loss = 0.4608291983604431
30-01-2023 05:54:19 INFO Epoch 1: [749/10940] ---- BYOL Training Loss = 0.4194396436214447
30-01-2023 05:55:12 INFO Epoch 1: [749/10940] ---- BYOL Validation Loss = 0.38005515933036804
30-01-2023 05:55:29 INFO Epoch 1: [760/10940] ---- BYOL Training Loss = 0.38156136870384216
30-01-2023 05:55:46 INFO Epoch 1: [771/10940] ---- BYOL Training Loss = 0.35017094016075134
30-01-2023 05:56:04 INFO Epoch 1: [782/10940] ---- BYOL Training Loss = 0.41295281052589417
30-01-2023 05:56:21 INFO Epoch 1: [793/10940] ---- BYOL Training Loss = 0.3528251051902771
30-01-2023 05:57:14 INFO Epoch 1: [793/10940] ---- BYOL Validation Loss = 0.3495575785636902
30-01-2023 05:57:31 INFO Epoch 1: [804/10940] ---- BYOL Training Loss = 0.39282798767089844
30-01-2023 05:57:48 INFO Epoch 1: [815/10940] ---- BYOL Training Loss = 0.4734867513179779
30-01-2023 05:58:06 INFO Epoch 1: [826/10940] ---- BYOL Training Loss = 0.44290247559547424
30-01-2023 05:58:24 INFO Epoch 1: [837/10940] ---- BYOL Training Loss = 0.39793139696121216
30-01-2023 05:59:16 INFO Epoch 1: [837/10940] ---- BYOL Validation Loss = 0.3810950219631195
30-01-2023 05:59:33 INFO Epoch 1: [848/10940] ---- BYOL Training Loss = 0.42878445982933044
30-01-2023 05:59:51 INFO Epoch 1: [859/10940] ---- BYOL Training Loss = 0.4367504119873047
30-01-2023 06:00:08 INFO Epoch 1: [870/10940] ---- BYOL Training Loss = 0.38563892245292664
30-01-2023 06:00:26 INFO Epoch 1: [881/10940] ---- BYOL Training Loss = 0.4135163426399231
30-01-2023 06:01:18 INFO Epoch 1: [881/10940] ---- BYOL Validation Loss = 0.3716484606266022
30-01-2023 06:01:35 INFO Epoch 1: [892/10940] ---- BYOL Training Loss = 0.44632402062416077
30-01-2023 06:01:53 INFO Epoch 1: [903/10940] ---- BYOL Training Loss = 0.365494966506958
30-01-2023 06:02:11 INFO Epoch 1: [914/10940] ---- BYOL Training Loss = 0.362141489982605
30-01-2023 06:02:29 INFO Epoch 1: [925/10940] ---- BYOL Training Loss = 0.40190833806991577
30-01-2023 06:03:21 INFO Epoch 1: [925/10940] ---- BYOL Validation Loss = 0.3542413115501404
30-01-2023 06:03:38 INFO Epoch 1: [936/10940] ---- BYOL Training Loss = 0.39605122804641724
30-01-2023 06:03:56 INFO Epoch 1: [947/10940] ---- BYOL Training Loss = 0.36155790090560913
30-01-2023 06:04:13 INFO Epoch 1: [958/10940] ---- BYOL Training Loss = 0.3996830880641937
30-01-2023 06:04:31 INFO Epoch 1: [969/10940] ---- BYOL Training Loss = 0.40088897943496704
30-01-2023 06:05:23 INFO Epoch 1: [969/10940] ---- BYOL Validation Loss = 0.35646241903305054
30-01-2023 06:05:40 INFO Epoch 1: [980/10940] ---- BYOL Training Loss = 0.40066272020339966
30-01-2023 06:05:58 INFO Epoch 1: [991/10940] ---- BYOL Training Loss = 0.3798215389251709
30-01-2023 06:06:16 INFO Epoch 1: [1002/10940] ---- BYOL Training Loss = 0.3240634799003601
30-01-2023 06:06:33 INFO Epoch 1: [1013/10940] ---- BYOL Training Loss = 0.3109685778617859
30-01-2023 06:07:26 INFO Epoch 1: [1013/10940] ---- BYOL Validation Loss = 0.3562099039554596
30-01-2023 06:07:43 INFO Epoch 1: [1024/10940] ---- BYOL Training Loss = 0.29857951402664185
30-01-2023 06:08:00 INFO Epoch 1: [1035/10940] ---- BYOL Training Loss = 0.3815910220146179
30-01-2023 06:08:18 INFO Epoch 1: [1046/10940] ---- BYOL Training Loss = 0.42804154753685
30-01-2023 06:08:36 INFO Epoch 1: [1057/10940] ---- BYOL Training Loss = 0.41754239797592163
30-01-2023 06:09:28 INFO Epoch 1: [1057/10940] ---- BYOL Validation Loss = 0.37702545523643494
30-01-2023 06:09:45 INFO Epoch 1: [1068/10940] ---- BYOL Training Loss = 0.36419039964675903
30-01-2023 06:10:03 INFO Epoch 1: [1079/10940] ---- BYOL Training Loss = 0.35488536953926086
30-01-2023 06:10:21 INFO Epoch 1: [1090/10940] ---- BYOL Training Loss = 0.3659627437591553
30-01-2023 06:10:38 INFO Epoch 1: [1101/10940] ---- BYOL Training Loss = 0.36821410059928894
30-01-2023 06:11:30 INFO Epoch 1: [1101/10940] ---- BYOL Validation Loss = 0.35767659544944763
30-01-2023 06:11:48 INFO Epoch 1: [1112/10940] ---- BYOL Training Loss = 0.4172183871269226
30-01-2023 06:12:05 INFO Epoch 1: [1123/10940] ---- BYOL Training Loss = 0.4032241702079773
30-01-2023 06:12:23 INFO Epoch 1: [1134/10940] ---- BYOL Training Loss = 0.36859965324401855
30-01-2023 06:12:40 INFO Epoch 1: [1145/10940] ---- BYOL Training Loss = 0.3890533149242401
30-01-2023 06:13:33 INFO Epoch 1: [1145/10940] ---- BYOL Validation Loss = 0.36443379521369934
30-01-2023 06:13:50 INFO Epoch 1: [1156/10940] ---- BYOL Training Loss = 0.3500905930995941
30-01-2023 06:14:07 INFO Epoch 1: [1167/10940] ---- BYOL Training Loss = 0.3801996111869812
30-01-2023 06:14:25 INFO Epoch 1: [1178/10940] ---- BYOL Training Loss = 0.4029664397239685
30-01-2023 06:14:43 INFO Epoch 1: [1189/10940] ---- BYOL Training Loss = 0.3762914836406708
30-01-2023 06:15:35 INFO Epoch 1: [1189/10940] ---- BYOL Validation Loss = 0.3545636534690857
30-01-2023 06:15:53 INFO Epoch 1: [1200/10940] ---- BYOL Training Loss = 0.3183402121067047
30-01-2023 06:16:10 INFO Epoch 1: [1211/10940] ---- BYOL Training Loss = 0.38157814741134644
30-01-2023 06:16:28 INFO Epoch 1: [1222/10940] ---- BYOL Training Loss = 0.42057862877845764
30-01-2023 06:16:46 INFO Epoch 1: [1233/10940] ---- BYOL Training Loss = 0.3822244703769684
30-01-2023 06:17:38 INFO Epoch 1: [1233/10940] ---- BYOL Validation Loss = 0.3555411696434021
30-01-2023 06:17:55 INFO Epoch 1: [1244/10940] ---- BYOL Training Loss = 0.3291394114494324
30-01-2023 06:18:13 INFO Epoch 1: [1255/10940] ---- BYOL Training Loss = 0.2875477075576782
30-01-2023 06:18:30 INFO Epoch 1: [1266/10940] ---- BYOL Training Loss = 0.3182506561279297
30-01-2023 06:18:48 INFO Epoch 1: [1277/10940] ---- BYOL Training Loss = 0.354417622089386
30-01-2023 06:19:40 INFO Epoch 1: [1277/10940] ---- BYOL Validation Loss = 0.3493468761444092
30-01-2023 06:19:58 INFO Epoch 1: [1288/10940] ---- BYOL Training Loss = 0.34277597069740295
30-01-2023 06:20:15 INFO Epoch 1: [1299/10940] ---- BYOL Training Loss = 0.3224756717681885
30-01-2023 06:20:33 INFO Epoch 1: [1310/10940] ---- BYOL Training Loss = 0.36419788002967834
30-01-2023 06:20:50 INFO Epoch 1: [1321/10940] ---- BYOL Training Loss = 0.414009153842926
30-01-2023 06:21:43 INFO Epoch 1: [1321/10940] ---- BYOL Validation Loss = 0.3476727306842804
30-01-2023 06:22:00 INFO Epoch 1: [1332/10940] ---- BYOL Training Loss = 0.33160990476608276
30-01-2023 06:22:18 INFO Epoch 1: [1343/10940] ---- BYOL Training Loss = 0.30525121092796326
30-01-2023 06:22:35 INFO Epoch 1: [1354/10940] ---- BYOL Training Loss = 0.3420754671096802
30-01-2023 06:22:53 INFO Epoch 1: [1365/10940] ---- BYOL Training Loss = 0.3401421904563904
30-01-2023 06:23:45 INFO Epoch 1: [1365/10940] ---- BYOL Validation Loss = 0.3482811748981476
30-01-2023 06:24:02 INFO Epoch 1: [1376/10940] ---- BYOL Training Loss = 0.3310662508010864
30-01-2023 06:24:20 INFO Epoch 1: [1387/10940] ---- BYOL Training Loss = 0.33925434947013855
30-01-2023 06:24:38 INFO Epoch 1: [1398/10940] ---- BYOL Training Loss = 0.40638718008995056
30-01-2023 06:24:55 INFO Epoch 1: [1409/10940] ---- BYOL Training Loss = 0.3628029525279999
30-01-2023 06:25:48 INFO Epoch 1: [1409/10940] ---- BYOL Validation Loss = 0.3345547616481781
30-01-2023 06:26:05 INFO Epoch 1: [1420/10940] ---- BYOL Training Loss = 0.3712446987628937
30-01-2023 06:26:22 INFO Epoch 1: [1431/10940] ---- BYOL Training Loss = 0.3621681034564972
30-01-2023 06:26:40 INFO Epoch 1: [1442/10940] ---- BYOL Training Loss = 0.332438588142395
30-01-2023 06:26:58 INFO Epoch 1: [1453/10940] ---- BYOL Training Loss = 0.33692264556884766
30-01-2023 06:27:50 INFO Epoch 1: [1453/10940] ---- BYOL Validation Loss = 0.34165826439857483
30-01-2023 06:28:08 INFO Epoch 1: [1464/10940] ---- BYOL Training Loss = 0.3802264928817749
30-01-2023 06:28:25 INFO Epoch 1: [1475/10940] ---- BYOL Training Loss = 0.3731953799724579
30-01-2023 06:28:43 INFO Epoch 1: [1486/10940] ---- BYOL Training Loss = 0.3797517716884613
30-01-2023 06:29:01 INFO Epoch 1: [1497/10940] ---- BYOL Training Loss = 0.3807702660560608
30-01-2023 06:29:53 INFO Epoch 1: [1497/10940] ---- BYOL Validation Loss = 0.337394654750824
30-01-2023 06:30:10 INFO Epoch 1: [1508/10940] ---- BYOL Training Loss = 0.3416552245616913
30-01-2023 06:30:28 INFO Epoch 1: [1519/10940] ---- BYOL Training Loss = 0.3929672837257385
30-01-2023 06:30:45 INFO Epoch 1: [1530/10940] ---- BYOL Training Loss = 0.38000911474227905
30-01-2023 06:31:03 INFO Epoch 1: [1541/10940] ---- BYOL Training Loss = 0.31180718541145325
30-01-2023 06:31:55 INFO Epoch 1: [1541/10940] ---- BYOL Validation Loss = 0.34617310762405396
30-01-2023 06:32:13 INFO Epoch 1: [1552/10940] ---- BYOL Training Loss = 0.3627409338951111
30-01-2023 06:32:30 INFO Epoch 1: [1563/10940] ---- BYOL Training Loss = 0.3724944293498993
30-01-2023 06:32:48 INFO Epoch 1: [1574/10940] ---- BYOL Training Loss = 0.37596312165260315
30-01-2023 06:33:05 INFO Epoch 1: [1585/10940] ---- BYOL Training Loss = 0.3865985870361328
30-01-2023 06:33:58 INFO Epoch 1: [1585/10940] ---- BYOL Validation Loss = 0.35280147194862366
30-01-2023 06:34:15 INFO Epoch 1: [1596/10940] ---- BYOL Training Loss = 0.3609815239906311
30-01-2023 06:34:33 INFO Epoch 1: [1607/10940] ---- BYOL Training Loss = 0.38655024766921997
30-01-2023 06:34:50 INFO Epoch 1: [1618/10940] ---- BYOL Training Loss = 0.4024243950843811
30-01-2023 06:35:08 INFO Epoch 1: [1629/10940] ---- BYOL Training Loss = 0.39790764451026917
30-01-2023 06:36:00 INFO Epoch 1: [1629/10940] ---- BYOL Validation Loss = 0.33960476517677307
30-01-2023 06:36:18 INFO Epoch 1: [1640/10940] ---- BYOL Training Loss = 0.3422655165195465
30-01-2023 06:36:35 INFO Epoch 1: [1651/10940] ---- BYOL Training Loss = 0.30657655000686646
30-01-2023 06:36:53 INFO Epoch 1: [1662/10940] ---- BYOL Training Loss = 0.28370848298072815
30-01-2023 06:37:11 INFO Epoch 1: [1673/10940] ---- BYOL Training Loss = 0.3612651228904724
30-01-2023 06:38:03 INFO Epoch 1: [1673/10940] ---- BYOL Validation Loss = 0.33107778429985046
30-01-2023 06:38:20 INFO Epoch 1: [1684/10940] ---- BYOL Training Loss = 0.4060620367527008
30-01-2023 06:38:38 INFO Epoch 1: [1695/10940] ---- BYOL Training Loss = 0.380682110786438
30-01-2023 06:38:55 INFO Epoch 1: [1706/10940] ---- BYOL Training Loss = 0.3368816077709198
30-01-2023 06:39:13 INFO Epoch 1: [1717/10940] ---- BYOL Training Loss = 0.30825477838516235
30-01-2023 06:40:05 INFO Epoch 1: [1717/10940] ---- BYOL Validation Loss = 0.31413745880126953
30-01-2023 06:40:23 INFO Epoch 1: [1728/10940] ---- BYOL Training Loss = 0.3357120752334595
30-01-2023 06:40:41 INFO Epoch 1: [1739/10940] ---- BYOL Training Loss = 0.33574289083480835
30-01-2023 06:40:58 INFO Epoch 1: [1750/10940] ---- BYOL Training Loss = 0.32155126333236694
30-01-2023 06:41:16 INFO Epoch 1: [1761/10940] ---- BYOL Training Loss = 0.30735236406326294
30-01-2023 06:42:08 INFO Epoch 1: [1761/10940] ---- BYOL Validation Loss = 0.3279196321964264
30-01-2023 06:42:26 INFO Epoch 1: [1772/10940] ---- BYOL Training Loss = 0.3166942000389099
30-01-2023 06:42:43 INFO Epoch 1: [1783/10940] ---- BYOL Training Loss = 0.30156806111335754
30-01-2023 06:43:01 INFO Epoch 1: [1794/10940] ---- BYOL Training Loss = 0.34970590472221375
30-01-2023 06:43:19 INFO Epoch 1: [1805/10940] ---- BYOL Training Loss = 0.39966467022895813
30-01-2023 06:44:11 INFO Epoch 1: [1805/10940] ---- BYOL Validation Loss = 0.3199768364429474
30-01-2023 06:44:28 INFO Epoch 1: [1816/10940] ---- BYOL Training Loss = 0.3667176365852356
30-01-2023 06:44:46 INFO Epoch 1: [1827/10940] ---- BYOL Training Loss = 0.31364336609840393
30-01-2023 06:45:04 INFO Epoch 1: [1838/10940] ---- BYOL Training Loss = 0.3390968441963196
30-01-2023 06:45:21 INFO Epoch 1: [1849/10940] ---- BYOL Training Loss = 0.344644695520401
30-01-2023 06:46:14 INFO Epoch 1: [1849/10940] ---- BYOL Validation Loss = 0.30965736508369446
30-01-2023 06:46:31 INFO Epoch 1: [1860/10940] ---- BYOL Training Loss = 0.36606040596961975
30-01-2023 06:46:49 INFO Epoch 1: [1871/10940] ---- BYOL Training Loss = 0.45022526383399963
30-01-2023 06:47:06 INFO Epoch 1: [1882/10940] ---- BYOL Training Loss = 0.3501136898994446
30-01-2023 06:47:24 INFO Epoch 1: [1893/10940] ---- BYOL Training Loss = 0.3070332109928131
30-01-2023 06:48:16 INFO Epoch 1: [1893/10940] ---- BYOL Validation Loss = 0.3108031153678894
30-01-2023 06:48:34 INFO Epoch 1: [1904/10940] ---- BYOL Training Loss = 0.35362938046455383
30-01-2023 06:48:51 INFO Epoch 1: [1915/10940] ---- BYOL Training Loss = 0.37073537707328796
30-01-2023 06:49:09 INFO Epoch 1: [1926/10940] ---- BYOL Training Loss = 0.3683513402938843
30-01-2023 06:49:27 INFO Epoch 1: [1937/10940] ---- BYOL Training Loss = 0.32183748483657837
30-01-2023 06:50:19 INFO Epoch 1: [1937/10940] ---- BYOL Validation Loss = 0.32466983795166016
30-01-2023 06:50:36 INFO Epoch 1: [1948/10940] ---- BYOL Training Loss = 0.35046088695526123
30-01-2023 06:50:54 INFO Epoch 1: [1959/10940] ---- BYOL Training Loss = 0.3293910622596741
30-01-2023 06:51:12 INFO Epoch 1: [1970/10940] ---- BYOL Training Loss = 0.305813729763031
30-01-2023 06:51:30 INFO Epoch 1: [1981/10940] ---- BYOL Training Loss = 0.32272976636886597
30-01-2023 06:52:22 INFO Epoch 1: [1981/10940] ---- BYOL Validation Loss = 0.3243313729763031
30-01-2023 06:52:39 INFO Epoch 1: [1992/10940] ---- BYOL Training Loss = 0.2982260584831238
30-01-2023 06:52:57 INFO Epoch 1: [2003/10940] ---- BYOL Training Loss = 0.32698240876197815
30-01-2023 06:53:15 INFO Epoch 1: [2014/10940] ---- BYOL Training Loss = 0.31514352560043335
30-01-2023 06:53:32 INFO Epoch 1: [2025/10940] ---- BYOL Training Loss = 0.32900771498680115
30-01-2023 06:54:25 INFO Epoch 1: [2025/10940] ---- BYOL Validation Loss = 0.31010937690734863
30-01-2023 06:54:42 INFO Epoch 1: [2036/10940] ---- BYOL Training Loss = 0.30120354890823364
30-01-2023 06:55:00 INFO Epoch 1: [2047/10940] ---- BYOL Training Loss = 0.2837580740451813
30-01-2023 06:55:17 INFO Epoch 1: [2058/10940] ---- BYOL Training Loss = 0.30554357171058655
30-01-2023 06:55:35 INFO Epoch 1: [2069/10940] ---- BYOL Training Loss = 0.2538266181945801
30-01-2023 06:56:27 INFO Epoch 1: [2069/10940] ---- BYOL Validation Loss = 0.31994980573654175
30-01-2023 06:56:45 INFO Epoch 1: [2080/10940] ---- BYOL Training Loss = 0.24373336136341095
30-01-2023 06:57:03 INFO Epoch 1: [2091/10940] ---- BYOL Training Loss = 0.3316795825958252
30-01-2023 06:57:20 INFO Epoch 1: [2102/10940] ---- BYOL Training Loss = 0.32630807161331177
30-01-2023 06:57:38 INFO Epoch 1: [2113/10940] ---- BYOL Training Loss = 0.35181301832199097
30-01-2023 06:58:30 INFO Epoch 1: [2113/10940] ---- BYOL Validation Loss = 0.33259254693984985
30-01-2023 06:58:48 INFO Epoch 1: [2124/10940] ---- BYOL Training Loss = 0.4058121144771576
30-01-2023 06:59:05 INFO Epoch 1: [2135/10940] ---- BYOL Training Loss = 0.3384876251220703
30-01-2023 06:59:23 INFO Epoch 1: [2146/10940] ---- BYOL Training Loss = 0.3743135333061218
30-01-2023 06:59:41 INFO Epoch 1: [2157/10940] ---- BYOL Training Loss = 0.36124998331069946
30-01-2023 07:00:33 INFO Epoch 1: [2157/10940] ---- BYOL Validation Loss = 0.32527145743370056
30-01-2023 07:00:50 INFO Epoch 1: [2168/10940] ---- BYOL Training Loss = 0.30459877848625183
30-01-2023 07:01:08 INFO Epoch 1: [2179/10940] ---- BYOL Training Loss = 0.3457713723182678
30-01-2023 07:01:26 INFO Epoch 1: [2190/10940] ---- BYOL Training Loss = 0.3136657178401947
30-01-2023 07:01:44 INFO Epoch 1: [2201/10940] ---- BYOL Training Loss = 0.30358022451400757
30-01-2023 07:02:36 INFO Epoch 1: [2201/10940] ---- BYOL Validation Loss = 0.3099741041660309
30-01-2023 07:02:53 INFO Epoch 1: [2212/10940] ---- BYOL Training Loss = 0.38092169165611267
30-01-2023 07:03:11 INFO Epoch 1: [2223/10940] ---- BYOL Training Loss = 0.3544895350933075
30-01-2023 07:03:29 INFO Epoch 1: [2234/10940] ---- BYOL Training Loss = 0.30126845836639404
30-01-2023 07:03:47 INFO Epoch 1: [2245/10940] ---- BYOL Training Loss = 0.36192071437835693
30-01-2023 07:04:39 INFO Epoch 1: [2245/10940] ---- BYOL Validation Loss = 0.3230791389942169
30-01-2023 07:04:56 INFO Epoch 1: [2256/10940] ---- BYOL Training Loss = 0.34108394384384155
30-01-2023 07:05:14 INFO Epoch 1: [2267/10940] ---- BYOL Training Loss = 0.3869808614253998
30-01-2023 07:05:32 INFO Epoch 1: [2278/10940] ---- BYOL Training Loss = 0.3634898066520691
30-01-2023 07:05:49 INFO Epoch 1: [2289/10940] ---- BYOL Training Loss = 0.27106142044067383
30-01-2023 07:06:41 INFO Epoch 1: [2289/10940] ---- BYOL Validation Loss = 0.3146178722381592
30-01-2023 07:06:59 INFO Epoch 1: [2300/10940] ---- BYOL Training Loss = 0.3421406149864197
30-01-2023 07:07:17 INFO Epoch 1: [2311/10940] ---- BYOL Training Loss = 0.36017337441444397
30-01-2023 07:07:34 INFO Epoch 1: [2322/10940] ---- BYOL Training Loss = 0.2947072684764862
30-01-2023 07:07:52 INFO Epoch 1: [2333/10940] ---- BYOL Training Loss = 0.3281361162662506
30-01-2023 07:08:44 INFO Epoch 1: [2333/10940] ---- BYOL Validation Loss = 0.3067214787006378
30-01-2023 07:09:02 INFO Epoch 1: [2344/10940] ---- BYOL Training Loss = 0.3056081235408783
30-01-2023 07:09:20 INFO Epoch 1: [2355/10940] ---- BYOL Training Loss = 0.268496036529541
30-01-2023 07:09:37 INFO Epoch 1: [2366/10940] ---- BYOL Training Loss = 0.2770574688911438
30-01-2023 07:09:55 INFO Epoch 1: [2377/10940] ---- BYOL Training Loss = 0.32302340865135193
30-01-2023 07:10:47 INFO Epoch 1: [2377/10940] ---- BYOL Validation Loss = 0.31282398104667664
30-01-2023 07:11:05 INFO Epoch 1: [2388/10940] ---- BYOL Training Loss = 0.3203585743904114
30-01-2023 07:11:22 INFO Epoch 1: [2399/10940] ---- BYOL Training Loss = 0.26762205362319946
30-01-2023 07:11:40 INFO Epoch 1: [2410/10940] ---- BYOL Training Loss = 0.2820361256599426
30-01-2023 07:11:58 INFO Epoch 1: [2421/10940] ---- BYOL Training Loss = 0.3093527555465698
30-01-2023 07:12:50 INFO Epoch 1: [2421/10940] ---- BYOL Validation Loss = 0.32310840487480164
30-01-2023 07:13:07 INFO Epoch 1: [2432/10940] ---- BYOL Training Loss = 0.3092319369316101
30-01-2023 07:13:25 INFO Epoch 1: [2443/10940] ---- BYOL Training Loss = 0.2953261733055115
30-01-2023 07:13:43 INFO Epoch 1: [2454/10940] ---- BYOL Training Loss = 0.31614187359809875
30-01-2023 07:14:01 INFO Epoch 1: [2465/10940] ---- BYOL Training Loss = 0.3937295079231262
30-01-2023 07:14:53 INFO Epoch 1: [2465/10940] ---- BYOL Validation Loss = 0.32420971989631653
30-01-2023 07:15:11 INFO Epoch 1: [2476/10940] ---- BYOL Training Loss = 0.3573344051837921
30-01-2023 07:15:28 INFO Epoch 1: [2487/10940] ---- BYOL Training Loss = 0.33222752809524536
30-01-2023 07:15:46 INFO Epoch 1: [2498/10940] ---- BYOL Training Loss = 0.40321579575538635
30-01-2023 07:16:04 INFO Epoch 1: [2509/10940] ---- BYOL Training Loss = 0.4072933793067932
30-01-2023 07:16:56 INFO Epoch 1: [2509/10940] ---- BYOL Validation Loss = 0.33246442675590515
30-01-2023 07:17:13 INFO Epoch 1: [2520/10940] ---- BYOL Training Loss = 0.32497501373291016
30-01-2023 07:17:31 INFO Epoch 1: [2531/10940] ---- BYOL Training Loss = 0.3624969720840454
30-01-2023 07:17:49 INFO Epoch 1: [2542/10940] ---- BYOL Training Loss = 0.4216562807559967
30-01-2023 07:18:07 INFO Epoch 1: [2553/10940] ---- BYOL Training Loss = 0.3723224103450775
30-01-2023 07:18:59 INFO Epoch 1: [2553/10940] ---- BYOL Validation Loss = 0.310935914516449
30-01-2023 07:19:17 INFO Epoch 1: [2564/10940] ---- BYOL Training Loss = 0.3356052041053772
30-01-2023 07:19:35 INFO Epoch 1: [2575/10940] ---- BYOL Training Loss = 0.36764487624168396
30-01-2023 07:19:52 INFO Epoch 1: [2586/10940] ---- BYOL Training Loss = 0.3671751916408539
30-01-2023 07:20:10 INFO Epoch 1: [2597/10940] ---- BYOL Training Loss = 0.3053279519081116
30-01-2023 07:21:02 INFO Epoch 1: [2597/10940] ---- BYOL Validation Loss = 0.3201260566711426
30-01-2023 07:21:20 INFO Epoch 1: [2608/10940] ---- BYOL Training Loss = 0.31147998571395874
30-01-2023 07:21:37 INFO Epoch 1: [2619/10940] ---- BYOL Training Loss = 0.3505033850669861
30-01-2023 07:21:55 INFO Epoch 1: [2630/10940] ---- BYOL Training Loss = 0.3413597643375397
30-01-2023 07:22:13 INFO Epoch 1: [2641/10940] ---- BYOL Training Loss = 0.33932438492774963
30-01-2023 07:23:05 INFO Epoch 1: [2641/10940] ---- BYOL Validation Loss = 0.31018543243408203
30-01-2023 07:23:23 INFO Epoch 1: [2652/10940] ---- BYOL Training Loss = 0.3223603367805481
30-01-2023 07:23:40 INFO Epoch 1: [2663/10940] ---- BYOL Training Loss = 0.3439003825187683
30-01-2023 07:23:58 INFO Epoch 1: [2674/10940] ---- BYOL Training Loss = 0.3676147162914276
30-01-2023 07:24:16 INFO Epoch 1: [2685/10940] ---- BYOL Training Loss = 0.35706597566604614
30-01-2023 07:25:08 INFO Epoch 1: [2685/10940] ---- BYOL Validation Loss = 0.3207028806209564
30-01-2023 07:25:26 INFO Epoch 1: [2696/10940] ---- BYOL Training Loss = 0.3599552810192108
30-01-2023 07:25:43 INFO Epoch 1: [2707/10940] ---- BYOL Training Loss = 0.3564663529396057
30-01-2023 07:26:01 INFO Epoch 1: [2718/10940] ---- BYOL Training Loss = 0.3492434620857239
30-01-2023 07:26:19 INFO Epoch 1: [2729/10940] ---- BYOL Training Loss = 0.3254063129425049
30-01-2023 07:27:11 INFO Epoch 1: [2729/10940] ---- BYOL Validation Loss = 0.32281461358070374
30-01-2023 07:27:29 INFO Epoch 1: [2740/10940] ---- BYOL Training Loss = 0.2933337092399597
30-01-2023 07:27:46 INFO Epoch 1: [2751/10940] ---- BYOL Training Loss = 0.26402780413627625
30-01-2023 07:28:04 INFO Epoch 1: [2762/10940] ---- BYOL Training Loss = 0.3123735785484314
30-01-2023 07:28:22 INFO Epoch 1: [2773/10940] ---- BYOL Training Loss = 0.312173455953598
30-01-2023 07:29:14 INFO Epoch 1: [2773/10940] ---- BYOL Validation Loss = 0.30798885226249695
30-01-2023 07:29:32 INFO Epoch 1: [2784/10940] ---- BYOL Training Loss = 0.30681657791137695
30-01-2023 07:29:50 INFO Epoch 1: [2795/10940] ---- BYOL Training Loss = 0.36202818155288696
30-01-2023 07:30:07 INFO Epoch 1: [2806/10940] ---- BYOL Training Loss = 0.3961539566516876
30-01-2023 07:30:25 INFO Epoch 1: [2817/10940] ---- BYOL Training Loss = 0.3450056314468384
30-01-2023 07:31:17 INFO Epoch 1: [2817/10940] ---- BYOL Validation Loss = 0.2963548004627228
30-01-2023 07:31:35 INFO Epoch 1: [2828/10940] ---- BYOL Training Loss = 0.34207504987716675
30-01-2023 07:31:52 INFO Epoch 1: [2839/10940] ---- BYOL Training Loss = 0.34240370988845825
30-01-2023 07:32:10 INFO Epoch 1: [2850/10940] ---- BYOL Training Loss = 0.365955650806427
30-01-2023 07:32:28 INFO Epoch 1: [2861/10940] ---- BYOL Training Loss = 0.3524673581123352
30-01-2023 07:33:20 INFO Epoch 1: [2861/10940] ---- BYOL Validation Loss = 0.29797273874282837
30-01-2023 07:33:38 INFO Epoch 1: [2872/10940] ---- BYOL Training Loss = 0.35838013887405396
30-01-2023 07:33:56 INFO Epoch 1: [2883/10940] ---- BYOL Training Loss = 0.32318204641342163
30-01-2023 07:34:13 INFO Epoch 1: [2894/10940] ---- BYOL Training Loss = 0.32508400082588196
30-01-2023 07:34:31 INFO Epoch 1: [2905/10940] ---- BYOL Training Loss = 0.38053762912750244
30-01-2023 07:35:23 INFO Epoch 1: [2905/10940] ---- BYOL Validation Loss = 0.3130054175853729
30-01-2023 07:35:41 INFO Epoch 1: [2916/10940] ---- BYOL Training Loss = 0.3589577376842499
30-01-2023 07:35:58 INFO Epoch 1: [2927/10940] ---- BYOL Training Loss = 0.31665390729904175
30-01-2023 07:36:16 INFO Epoch 1: [2938/10940] ---- BYOL Training Loss = 0.32926806807518005
30-01-2023 07:36:34 INFO Epoch 1: [2949/10940] ---- BYOL Training Loss = 0.3156645894050598
30-01-2023 07:37:27 INFO Epoch 1: [2949/10940] ---- BYOL Validation Loss = 0.3166279196739197
30-01-2023 07:37:44 INFO Epoch 1: [2960/10940] ---- BYOL Training Loss = 0.32261139154434204
30-01-2023 07:38:02 INFO Epoch 1: [2971/10940] ---- BYOL Training Loss = 0.30827194452285767
30-01-2023 07:38:20 INFO Epoch 1: [2982/10940] ---- BYOL Training Loss = 0.2797034978866577
30-01-2023 07:38:37 INFO Epoch 1: [2993/10940] ---- BYOL Training Loss = 0.2666061818599701
30-01-2023 07:39:30 INFO Epoch 1: [2993/10940] ---- BYOL Validation Loss = 0.3094080984592438
30-01-2023 07:39:47 INFO Epoch 1: [3004/10940] ---- BYOL Training Loss = 0.3164352476596832
30-01-2023 07:40:05 INFO Epoch 1: [3015/10940] ---- BYOL Training Loss = 0.3663825988769531
30-01-2023 07:40:23 INFO Epoch 1: [3026/10940] ---- BYOL Training Loss = 0.35047447681427
30-01-2023 07:40:41 INFO Epoch 1: [3037/10940] ---- BYOL Training Loss = 0.3417239487171173
30-01-2023 07:41:33 INFO Epoch 1: [3037/10940] ---- BYOL Validation Loss = 0.3260367810726166
30-01-2023 07:41:51 INFO Epoch 1: [3048/10940] ---- BYOL Training Loss = 0.3477132022380829
30-01-2023 07:42:08 INFO Epoch 1: [3059/10940] ---- BYOL Training Loss = 0.31442975997924805
30-01-2023 07:42:26 INFO Epoch 1: [3070/10940] ---- BYOL Training Loss = 0.2963685393333435
30-01-2023 07:42:44 INFO Epoch 1: [3081/10940] ---- BYOL Training Loss = 0.33291152119636536
30-01-2023 07:43:36 INFO Epoch 1: [3081/10940] ---- BYOL Validation Loss = 0.3159275949001312
30-01-2023 07:43:54 INFO Epoch 1: [3092/10940] ---- BYOL Training Loss = 0.30322104692459106
30-01-2023 07:44:11 INFO Epoch 1: [3103/10940] ---- BYOL Training Loss = 0.3580973744392395
30-01-2023 07:44:29 INFO Epoch 1: [3114/10940] ---- BYOL Training Loss = 0.41120195388793945
30-01-2023 07:44:47 INFO Epoch 1: [3125/10940] ---- BYOL Training Loss = 0.3219089210033417
30-01-2023 07:45:39 INFO Epoch 1: [3125/10940] ---- BYOL Validation Loss = 0.3069898784160614
30-01-2023 07:45:57 INFO Epoch 1: [3136/10940] ---- BYOL Training Loss = 0.29233571887016296
30-01-2023 07:46:15 INFO Epoch 1: [3147/10940] ---- BYOL Training Loss = 0.24313871562480927
30-01-2023 07:46:32 INFO Epoch 1: [3158/10940] ---- BYOL Training Loss = 0.30588021874427795
30-01-2023 07:46:50 INFO Epoch 1: [3169/10940] ---- BYOL Training Loss = 0.3497045934200287
30-01-2023 07:47:42 INFO Epoch 1: [3169/10940] ---- BYOL Validation Loss = 0.30400896072387695
30-01-2023 07:48:00 INFO Epoch 1: [3180/10940] ---- BYOL Training Loss = 0.2920093834400177
30-01-2023 07:48:17 INFO Epoch 1: [3191/10940] ---- BYOL Training Loss = 0.32667940855026245
30-01-2023 07:48:35 INFO Epoch 1: [3202/10940] ---- BYOL Training Loss = 0.34445813298225403
30-01-2023 07:48:53 INFO Epoch 1: [3213/10940] ---- BYOL Training Loss = 0.3297693133354187
30-01-2023 07:49:45 INFO Epoch 1: [3213/10940] ---- BYOL Validation Loss = 0.28574520349502563
30-01-2023 07:50:03 INFO Epoch 1: [3224/10940] ---- BYOL Training Loss = 0.25878989696502686
30-01-2023 07:50:21 INFO Epoch 1: [3235/10940] ---- BYOL Training Loss = 0.2773851156234741
30-01-2023 07:50:39 INFO Epoch 1: [3246/10940] ---- BYOL Training Loss = 0.3923349976539612
30-01-2023 07:50:56 INFO Epoch 1: [3257/10940] ---- BYOL Training Loss = 0.35753756761550903
30-01-2023 07:51:49 INFO Epoch 1: [3257/10940] ---- BYOL Validation Loss = 0.3020416796207428
30-01-2023 07:52:06 INFO Epoch 1: [3268/10940] ---- BYOL Training Loss = 0.28149503469467163
30-01-2023 07:52:24 INFO Epoch 1: [3279/10940] ---- BYOL Training Loss = 0.3042837083339691
30-01-2023 07:52:42 INFO Epoch 1: [3290/10940] ---- BYOL Training Loss = 0.265018492937088
30-01-2023 07:53:00 INFO Epoch 1: [3301/10940] ---- BYOL Training Loss = 0.28094467520713806
30-01-2023 07:53:52 INFO Epoch 1: [3301/10940] ---- BYOL Validation Loss = 0.2962283194065094
30-01-2023 07:54:10 INFO Epoch 1: [3312/10940] ---- BYOL Training Loss = 0.29874610900878906
30-01-2023 07:54:27 INFO Epoch 1: [3323/10940] ---- BYOL Training Loss = 0.3039516508579254
30-01-2023 07:54:45 INFO Epoch 1: [3334/10940] ---- BYOL Training Loss = 0.3410162329673767
30-01-2023 07:55:03 INFO Epoch 1: [3345/10940] ---- BYOL Training Loss = 0.3083612322807312
30-01-2023 07:55:55 INFO Epoch 1: [3345/10940] ---- BYOL Validation Loss = 0.3086395263671875
30-01-2023 07:56:12 INFO Epoch 1: [3356/10940] ---- BYOL Training Loss = 0.2894652187824249
30-01-2023 07:56:30 INFO Epoch 1: [3367/10940] ---- BYOL Training Loss = 0.2812620997428894
30-01-2023 07:56:48 INFO Epoch 1: [3378/10940] ---- BYOL Training Loss = 0.32480424642562866
30-01-2023 07:57:06 INFO Epoch 1: [3389/10940] ---- BYOL Training Loss = 0.3022315204143524
30-01-2023 07:57:59 INFO Epoch 1: [3389/10940] ---- BYOL Validation Loss = 0.31610503792762756
30-01-2023 07:58:16 INFO Epoch 1: [3400/10940] ---- BYOL Training Loss = 0.34096360206604004
30-01-2023 07:58:34 INFO Epoch 1: [3411/10940] ---- BYOL Training Loss = 0.3684224486351013
30-01-2023 07:58:52 INFO Epoch 1: [3422/10940] ---- BYOL Training Loss = 0.31490007042884827
30-01-2023 07:59:10 INFO Epoch 1: [3433/10940] ---- BYOL Training Loss = 0.2773886024951935
30-01-2023 08:00:02 INFO Epoch 1: [3433/10940] ---- BYOL Validation Loss = 0.3059118688106537
30-01-2023 08:00:19 INFO Epoch 1: [3444/10940] ---- BYOL Training Loss = 0.33039990067481995
30-01-2023 08:00:37 INFO Epoch 1: [3455/10940] ---- BYOL Training Loss = 0.30599913001060486
30-01-2023 08:00:55 INFO Epoch 1: [3466/10940] ---- BYOL Training Loss = 0.3296605348587036
30-01-2023 08:01:13 INFO Epoch 1: [3477/10940] ---- BYOL Training Loss = 0.33418160676956177
30-01-2023 08:02:05 INFO Epoch 1: [3477/10940] ---- BYOL Validation Loss = 0.30359259247779846
30-01-2023 08:02:23 INFO Epoch 1: [3488/10940] ---- BYOL Training Loss = 0.30636534094810486
30-01-2023 08:02:41 INFO Epoch 1: [3499/10940] ---- BYOL Training Loss = 0.27373453974723816
30-01-2023 08:02:58 INFO Epoch 1: [3510/10940] ---- BYOL Training Loss = 0.32076019048690796
30-01-2023 08:03:16 INFO Epoch 1: [3521/10940] ---- BYOL Training Loss = 0.3603535294532776
30-01-2023 08:04:08 INFO Epoch 1: [3521/10940] ---- BYOL Validation Loss = 0.2915295958518982
30-01-2023 08:04:26 INFO Epoch 1: [3532/10940] ---- BYOL Training Loss = 0.3337622880935669
30-01-2023 08:04:44 INFO Epoch 1: [3543/10940] ---- BYOL Training Loss = 0.3036455512046814
30-01-2023 08:05:02 INFO Epoch 1: [3554/10940] ---- BYOL Training Loss = 0.3110394775867462
30-01-2023 08:05:20 INFO Epoch 1: [3565/10940] ---- BYOL Training Loss = 0.2935291826725006
30-01-2023 08:06:12 INFO Epoch 1: [3565/10940] ---- BYOL Validation Loss = 0.29567840695381165
30-01-2023 08:06:29 INFO Epoch 1: [3576/10940] ---- BYOL Training Loss = 0.28577616810798645
30-01-2023 08:06:47 INFO Epoch 1: [3587/10940] ---- BYOL Training Loss = 0.3142520785331726
30-01-2023 08:07:05 INFO Epoch 1: [3598/10940] ---- BYOL Training Loss = 0.30818527936935425
30-01-2023 08:07:23 INFO Epoch 1: [3609/10940] ---- BYOL Training Loss = 0.3311872184276581
30-01-2023 08:08:15 INFO Epoch 1: [3609/10940] ---- BYOL Validation Loss = 0.29226818680763245
30-01-2023 08:08:33 INFO Epoch 1: [3620/10940] ---- BYOL Training Loss = 0.34911730885505676
30-01-2023 08:08:50 INFO Epoch 1: [3631/10940] ---- BYOL Training Loss = 0.3329276442527771
30-01-2023 08:09:08 INFO Epoch 1: [3642/10940] ---- BYOL Training Loss = 0.34240299463272095
30-01-2023 08:09:26 INFO Epoch 1: [3653/10940] ---- BYOL Training Loss = 0.31403839588165283
30-01-2023 08:10:18 INFO Epoch 1: [3653/10940] ---- BYOL Validation Loss = 0.3030537962913513
30-01-2023 08:10:36 INFO Epoch 1: [3664/10940] ---- BYOL Training Loss = 0.33307385444641113
30-01-2023 08:10:54 INFO Epoch 1: [3675/10940] ---- BYOL Training Loss = 0.33499374985694885
30-01-2023 08:11:12 INFO Epoch 1: [3686/10940] ---- BYOL Training Loss = 0.32308927178382874
30-01-2023 08:11:30 INFO Epoch 1: [3697/10940] ---- BYOL Training Loss = 0.29739731550216675
30-01-2023 08:12:22 INFO Epoch 1: [3697/10940] ---- BYOL Validation Loss = 0.3072638213634491
30-01-2023 08:12:39 INFO Epoch 1: [3708/10940] ---- BYOL Training Loss = 0.2571461498737335
30-01-2023 08:12:57 INFO Epoch 1: [3719/10940] ---- BYOL Training Loss = 0.3210926651954651
30-01-2023 08:13:15 INFO Epoch 1: [3730/10940] ---- BYOL Training Loss = 0.3512263000011444
30-01-2023 08:13:33 INFO Epoch 1: [3741/10940] ---- BYOL Training Loss = 0.353120356798172
30-01-2023 08:14:25 INFO Epoch 1: [3741/10940] ---- BYOL Validation Loss = 0.3015664517879486
30-01-2023 08:14:43 INFO Epoch 1: [3752/10940] ---- BYOL Training Loss = 0.3246265947818756
30-01-2023 08:15:01 INFO Epoch 1: [3763/10940] ---- BYOL Training Loss = 0.3405727744102478
30-01-2023 08:15:19 INFO Epoch 1: [3774/10940] ---- BYOL Training Loss = 0.3448980748653412
30-01-2023 08:15:36 INFO Epoch 1: [3785/10940] ---- BYOL Training Loss = 0.36585089564323425
30-01-2023 08:16:29 INFO Epoch 1: [3785/10940] ---- BYOL Validation Loss = 0.2938311994075775
30-01-2023 08:16:46 INFO Epoch 1: [3796/10940] ---- BYOL Training Loss = 0.38282260298728943
30-01-2023 08:17:04 INFO Epoch 1: [3807/10940] ---- BYOL Training Loss = 0.35622912645339966
30-01-2023 08:17:22 INFO Epoch 1: [3818/10940] ---- BYOL Training Loss = 0.32303720712661743
30-01-2023 08:17:40 INFO Epoch 1: [3829/10940] ---- BYOL Training Loss = 0.26315948367118835
30-01-2023 08:18:32 INFO Epoch 1: [3829/10940] ---- BYOL Validation Loss = 0.2960333228111267
30-01-2023 08:18:50 INFO Epoch 1: [3840/10940] ---- BYOL Training Loss = 0.2979937195777893
30-01-2023 08:19:08 INFO Epoch 1: [3851/10940] ---- BYOL Training Loss = 0.2961697578430176
30-01-2023 08:19:26 INFO Epoch 1: [3862/10940] ---- BYOL Training Loss = 0.3405504524707794
30-01-2023 08:19:43 INFO Epoch 1: [3873/10940] ---- BYOL Training Loss = 0.3418007791042328
30-01-2023 08:20:36 INFO Epoch 1: [3873/10940] ---- BYOL Validation Loss = 0.3118325173854828
30-01-2023 08:20:53 INFO Epoch 1: [3884/10940] ---- BYOL Training Loss = 0.2965945601463318
30-01-2023 08:21:11 INFO Epoch 1: [3895/10940] ---- BYOL Training Loss = 0.28025946021080017
30-01-2023 08:21:29 INFO Epoch 1: [3906/10940] ---- BYOL Training Loss = 0.33752354979515076
30-01-2023 08:21:47 INFO Epoch 1: [3917/10940] ---- BYOL Training Loss = 0.3463951647281647
30-01-2023 08:22:39 INFO Epoch 1: [3917/10940] ---- BYOL Validation Loss = 0.3106061518192291
30-01-2023 08:22:57 INFO Epoch 1: [3928/10940] ---- BYOL Training Loss = 0.36474528908729553
30-01-2023 08:23:15 INFO Epoch 1: [3939/10940] ---- BYOL Training Loss = 0.35944145917892456
30-01-2023 08:23:33 INFO Epoch 1: [3950/10940] ---- BYOL Training Loss = 0.3051600456237793
30-01-2023 08:23:51 INFO Epoch 1: [3961/10940] ---- BYOL Training Loss = 0.30947965383529663
30-01-2023 08:24:43 INFO Epoch 1: [3961/10940] ---- BYOL Validation Loss = 0.3286142349243164
30-01-2023 08:25:01 INFO Epoch 1: [3972/10940] ---- BYOL Training Loss = 0.3026618957519531
30-01-2023 08:25:18 INFO Epoch 1: [3983/10940] ---- BYOL Training Loss = 0.2993243336677551
30-01-2023 08:25:36 INFO Epoch 1: [3994/10940] ---- BYOL Training Loss = 0.31009727716445923
30-01-2023 08:25:54 INFO Epoch 1: [4005/10940] ---- BYOL Training Loss = 0.29534000158309937
30-01-2023 08:26:46 INFO Epoch 1: [4005/10940] ---- BYOL Validation Loss = 0.29702702164649963
30-01-2023 08:27:04 INFO Epoch 1: [4016/10940] ---- BYOL Training Loss = 0.3368484377861023
30-01-2023 08:27:22 INFO Epoch 1: [4027/10940] ---- BYOL Training Loss = 0.3320627212524414
30-01-2023 08:27:40 INFO Epoch 1: [4038/10940] ---- BYOL Training Loss = 0.3106631636619568
30-01-2023 08:27:58 INFO Epoch 1: [4049/10940] ---- BYOL Training Loss = 0.346733957529068
30-01-2023 08:28:50 INFO Epoch 1: [4049/10940] ---- BYOL Validation Loss = 0.2942342758178711
30-01-2023 08:29:08 INFO Epoch 1: [4060/10940] ---- BYOL Training Loss = 0.34847161173820496
30-01-2023 08:29:25 INFO Epoch 1: [4071/10940] ---- BYOL Training Loss = 0.33902671933174133
30-01-2023 08:29:43 INFO Epoch 1: [4082/10940] ---- BYOL Training Loss = 0.3309135138988495
30-01-2023 08:30:02 INFO Epoch 1: [4093/10940] ---- BYOL Training Loss = 0.32981735467910767
30-01-2023 08:30:54 INFO Epoch 1: [4093/10940] ---- BYOL Validation Loss = 0.2945009768009186
30-01-2023 08:31:11 INFO Epoch 1: [4104/10940] ---- BYOL Training Loss = 0.3347935080528259
30-01-2023 08:31:29 INFO Epoch 1: [4115/10940] ---- BYOL Training Loss = 0.3487437665462494
30-01-2023 08:31:47 INFO Epoch 1: [4126/10940] ---- BYOL Training Loss = 0.36737924814224243
30-01-2023 08:32:05 INFO Epoch 1: [4137/10940] ---- BYOL Training Loss = 0.3521462678909302
30-01-2023 08:32:57 INFO Epoch 1: [4137/10940] ---- BYOL Validation Loss = 0.3057712912559509
30-01-2023 08:33:15 INFO Epoch 1: [4148/10940] ---- BYOL Training Loss = 0.2915220856666565
30-01-2023 08:33:33 INFO Epoch 1: [4159/10940] ---- BYOL Training Loss = 0.27951428294181824
30-01-2023 08:33:51 INFO Epoch 1: [4170/10940] ---- BYOL Training Loss = 0.34325116872787476
30-01-2023 08:34:09 INFO Epoch 1: [4181/10940] ---- BYOL Training Loss = 0.3763989806175232
30-01-2023 08:35:01 INFO Epoch 1: [4181/10940] ---- BYOL Validation Loss = 0.30436787009239197
30-01-2023 08:35:18 INFO Epoch 1: [4192/10940] ---- BYOL Training Loss = 0.3444727659225464
30-01-2023 08:35:36 INFO Epoch 1: [4203/10940] ---- BYOL Training Loss = 0.3188793957233429
30-01-2023 08:35:54 INFO Epoch 1: [4214/10940] ---- BYOL Training Loss = 0.3018419146537781
30-01-2023 08:36:12 INFO Epoch 1: [4225/10940] ---- BYOL Training Loss = 0.262131929397583
30-01-2023 08:37:04 INFO Epoch 1: [4225/10940] ---- BYOL Validation Loss = 0.29527726769447327
30-01-2023 08:37:22 INFO Epoch 1: [4236/10940] ---- BYOL Training Loss = 0.28648191690444946
30-01-2023 08:37:40 INFO Epoch 1: [4247/10940] ---- BYOL Training Loss = 0.33666783571243286
30-01-2023 08:37:58 INFO Epoch 1: [4258/10940] ---- BYOL Training Loss = 0.33740997314453125
30-01-2023 08:38:16 INFO Epoch 1: [4269/10940] ---- BYOL Training Loss = 0.30883753299713135
30-01-2023 08:39:08 INFO Epoch 1: [4269/10940] ---- BYOL Validation Loss = 0.34365659952163696
30-01-2023 08:39:26 INFO Epoch 1: [4280/10940] ---- BYOL Training Loss = 0.30787503719329834
30-01-2023 08:39:43 INFO Epoch 1: [4291/10940] ---- BYOL Training Loss = 0.31692618131637573
30-01-2023 08:40:01 INFO Epoch 1: [4302/10940] ---- BYOL Training Loss = 0.35742661356925964
30-01-2023 08:40:19 INFO Epoch 1: [4313/10940] ---- BYOL Training Loss = 0.33292824029922485
30-01-2023 08:41:11 INFO Epoch 1: [4313/10940] ---- BYOL Validation Loss = 0.29944249987602234
30-01-2023 08:41:29 INFO Epoch 1: [4324/10940] ---- BYOL Training Loss = 0.27997758984565735
30-01-2023 08:41:47 INFO Epoch 1: [4335/10940] ---- BYOL Training Loss = 0.29863354563713074
30-01-2023 08:42:05 INFO Epoch 1: [4346/10940] ---- BYOL Training Loss = 0.33001241087913513
30-01-2023 08:42:23 INFO Epoch 1: [4357/10940] ---- BYOL Training Loss = 0.3187362551689148
30-01-2023 08:43:15 INFO Epoch 1: [4357/10940] ---- BYOL Validation Loss = 0.29605358839035034
30-01-2023 08:43:33 INFO Epoch 1: [4368/10940] ---- BYOL Training Loss = 0.3486539423465729
30-01-2023 08:43:51 INFO Epoch 1: [4379/10940] ---- BYOL Training Loss = 0.3100671172142029
30-01-2023 08:44:08 INFO Epoch 1: [4390/10940] ---- BYOL Training Loss = 0.26845893263816833
30-01-2023 08:44:27 INFO Epoch 1: [4401/10940] ---- BYOL Training Loss = 0.299037903547287
30-01-2023 08:45:19 INFO Epoch 1: [4401/10940] ---- BYOL Validation Loss = 0.29334941506385803
30-01-2023 08:45:36 INFO Epoch 1: [4412/10940] ---- BYOL Training Loss = 0.29711803793907166
30-01-2023 08:45:55 INFO Epoch 1: [4423/10940] ---- BYOL Training Loss = 0.28549516201019287
30-01-2023 08:46:13 INFO Epoch 1: [4434/10940] ---- BYOL Training Loss = 0.2803284525871277
30-01-2023 08:46:30 INFO Epoch 1: [4445/10940] ---- BYOL Training Loss = 0.31188833713531494
30-01-2023 08:47:23 INFO Epoch 1: [4445/10940] ---- BYOL Validation Loss = 0.3041761815547943
30-01-2023 08:47:40 INFO Epoch 1: [4456/10940] ---- BYOL Training Loss = 0.3162451982498169
30-01-2023 08:47:59 INFO Epoch 1: [4467/10940] ---- BYOL Training Loss = 0.3108493685722351
30-01-2023 08:48:16 INFO Epoch 1: [4478/10940] ---- BYOL Training Loss = 0.3218650221824646
30-01-2023 08:48:34 INFO Epoch 1: [4489/10940] ---- BYOL Training Loss = 0.30642804503440857
30-01-2023 08:49:26 INFO Epoch 1: [4489/10940] ---- BYOL Validation Loss = 0.2954266369342804
30-01-2023 08:49:44 INFO Epoch 1: [4500/10940] ---- BYOL Training Loss = 0.3194957673549652
30-01-2023 08:50:02 INFO Epoch 1: [4511/10940] ---- BYOL Training Loss = 0.3222094774246216
30-01-2023 08:50:20 INFO Epoch 1: [4522/10940] ---- BYOL Training Loss = 0.31403452157974243
30-01-2023 08:50:38 INFO Epoch 1: [4533/10940] ---- BYOL Training Loss = 0.373287558555603
30-01-2023 08:51:30 INFO Epoch 1: [4533/10940] ---- BYOL Validation Loss = 0.3094503581523895
30-01-2023 08:51:48 INFO Epoch 1: [4544/10940] ---- BYOL Training Loss = 0.330112099647522
30-01-2023 08:52:06 INFO Epoch 1: [4555/10940] ---- BYOL Training Loss = 0.28409284353256226
30-01-2023 08:52:24 INFO Epoch 1: [4566/10940] ---- BYOL Training Loss = 0.267286479473114
30-01-2023 08:52:42 INFO Epoch 1: [4577/10940] ---- BYOL Training Loss = 0.32734206318855286
30-01-2023 08:53:34 INFO Epoch 1: [4577/10940] ---- BYOL Validation Loss = 0.30208292603492737
30-01-2023 08:53:52 INFO Epoch 1: [4588/10940] ---- BYOL Training Loss = 0.4127911925315857
30-01-2023 08:54:10 INFO Epoch 1: [4599/10940] ---- BYOL Training Loss = 0.33109697699546814
30-01-2023 08:54:27 INFO Epoch 1: [4610/10940] ---- BYOL Training Loss = 0.30131837725639343
30-01-2023 08:54:45 INFO Epoch 1: [4621/10940] ---- BYOL Training Loss = 0.2930894196033478
30-01-2023 08:55:38 INFO Epoch 1: [4621/10940] ---- BYOL Validation Loss = 0.29640981554985046
30-01-2023 08:55:55 INFO Epoch 1: [4632/10940] ---- BYOL Training Loss = 0.2921125292778015
30-01-2023 08:56:13 INFO Epoch 1: [4643/10940] ---- BYOL Training Loss = 0.28926175832748413
30-01-2023 08:56:31 INFO Epoch 1: [4654/10940] ---- BYOL Training Loss = 0.29119521379470825
30-01-2023 08:56:49 INFO Epoch 1: [4665/10940] ---- BYOL Training Loss = 0.26434391736984253
30-01-2023 08:57:41 INFO Epoch 1: [4665/10940] ---- BYOL Validation Loss = 0.29640817642211914
30-01-2023 08:57:59 INFO Epoch 1: [4676/10940] ---- BYOL Training Loss = 0.2849612236022949
30-01-2023 08:58:17 INFO Epoch 1: [4687/10940] ---- BYOL Training Loss = 0.3273509442806244
30-01-2023 08:58:35 INFO Epoch 1: [4698/10940] ---- BYOL Training Loss = 0.34119313955307007
30-01-2023 08:58:53 INFO Epoch 1: [4709/10940] ---- BYOL Training Loss = 0.3660178482532501
30-01-2023 08:59:45 INFO Epoch 1: [4709/10940] ---- BYOL Validation Loss = 0.3787570595741272
30-01-2023 09:00:03 INFO Epoch 1: [4720/10940] ---- BYOL Training Loss = 0.35068249702453613
30-01-2023 09:00:21 INFO Epoch 1: [4731/10940] ---- BYOL Training Loss = 0.3325490653514862
30-01-2023 09:00:38 INFO Epoch 1: [4742/10940] ---- BYOL Training Loss = 0.3248346745967865
30-01-2023 09:00:57 INFO Epoch 1: [4753/10940] ---- BYOL Training Loss = 0.3400941491127014
30-01-2023 09:01:49 INFO Epoch 1: [4753/10940] ---- BYOL Validation Loss = 0.3083633482456207
30-01-2023 09:02:07 INFO Epoch 1: [4764/10940] ---- BYOL Training Loss = 0.35297927260398865
30-01-2023 09:02:24 INFO Epoch 1: [4775/10940] ---- BYOL Training Loss = 0.2546413540840149
30-01-2023 09:02:42 INFO Epoch 1: [4786/10940] ---- BYOL Training Loss = 0.34459277987480164
30-01-2023 09:03:00 INFO Epoch 1: [4797/10940] ---- BYOL Training Loss = 0.3602927625179291
30-01-2023 09:03:53 INFO Epoch 1: [4797/10940] ---- BYOL Validation Loss = 0.29744410514831543
30-01-2023 09:04:10 INFO Epoch 1: [4808/10940] ---- BYOL Training Loss = 0.3235449194908142
30-01-2023 09:04:28 INFO Epoch 1: [4819/10940] ---- BYOL Training Loss = 0.33536022901535034
30-01-2023 09:04:46 INFO Epoch 1: [4830/10940] ---- BYOL Training Loss = 0.3092713952064514
30-01-2023 09:05:04 INFO Epoch 1: [4841/10940] ---- BYOL Training Loss = 0.30925267934799194
30-01-2023 09:05:56 INFO Epoch 1: [4841/10940] ---- BYOL Validation Loss = 0.2848861515522003
30-01-2023 09:06:14 INFO Epoch 1: [4852/10940] ---- BYOL Training Loss = 0.3427527844905853
30-01-2023 09:06:32 INFO Epoch 1: [4863/10940] ---- BYOL Training Loss = 0.30939722061157227
30-01-2023 09:06:50 INFO Epoch 1: [4874/10940] ---- BYOL Training Loss = 0.2974971830844879
30-01-2023 09:07:08 INFO Epoch 1: [4885/10940] ---- BYOL Training Loss = 0.3052929937839508
30-01-2023 09:08:00 INFO Epoch 1: [4885/10940] ---- BYOL Validation Loss = 0.29196614027023315
30-01-2023 09:08:18 INFO Epoch 1: [4896/10940] ---- BYOL Training Loss = 0.3432004451751709
30-01-2023 09:08:36 INFO Epoch 1: [4907/10940] ---- BYOL Training Loss = 0.33914369344711304
30-01-2023 09:08:54 INFO Epoch 1: [4918/10940] ---- BYOL Training Loss = 0.3072497546672821
30-01-2023 09:09:12 INFO Epoch 1: [4929/10940] ---- BYOL Training Loss = 0.2964392900466919
30-01-2023 09:10:04 INFO Epoch 1: [4929/10940] ---- BYOL Validation Loss = 0.29680541157722473
30-01-2023 09:10:22 INFO Epoch 1: [4940/10940] ---- BYOL Training Loss = 0.30599743127822876
30-01-2023 09:10:40 INFO Epoch 1: [4951/10940] ---- BYOL Training Loss = 0.33131784200668335
30-01-2023 09:10:58 INFO Epoch 1: [4962/10940] ---- BYOL Training Loss = 0.36119544506073
30-01-2023 09:11:16 INFO Epoch 1: [4973/10940] ---- BYOL Training Loss = 0.29654625058174133
30-01-2023 09:12:08 INFO Epoch 1: [4973/10940] ---- BYOL Validation Loss = 0.2871624827384949
30-01-2023 09:12:26 INFO Epoch 1: [4984/10940] ---- BYOL Training Loss = 0.23349638283252716
30-01-2023 09:12:44 INFO Epoch 1: [4995/10940] ---- BYOL Training Loss = 0.25478678941726685
30-01-2023 09:13:02 INFO Epoch 1: [5006/10940] ---- BYOL Training Loss = 0.302062451839447
30-01-2023 09:13:20 INFO Epoch 1: [5017/10940] ---- BYOL Training Loss = 0.32615217566490173
30-01-2023 09:14:12 INFO Epoch 1: [5017/10940] ---- BYOL Validation Loss = 0.29136255383491516
30-01-2023 09:14:30 INFO Epoch 1: [5028/10940] ---- BYOL Training Loss = 0.3701896071434021
30-01-2023 09:14:48 INFO Epoch 1: [5039/10940] ---- BYOL Training Loss = 0.3758627772331238
30-01-2023 09:15:06 INFO Epoch 1: [5050/10940] ---- BYOL Training Loss = 0.334705114364624
30-01-2023 09:15:24 INFO Epoch 1: [5061/10940] ---- BYOL Training Loss = 0.33558136224746704
30-01-2023 09:16:16 INFO Epoch 1: [5061/10940] ---- BYOL Validation Loss = 0.29845985770225525
30-01-2023 09:16:34 INFO Epoch 1: [5072/10940] ---- BYOL Training Loss = 0.3011242151260376
30-01-2023 09:16:52 INFO Epoch 1: [5083/10940] ---- BYOL Training Loss = 0.2717929780483246
30-01-2023 09:17:10 INFO Epoch 1: [5094/10940] ---- BYOL Training Loss = 0.3292210102081299
30-01-2023 09:17:28 INFO Epoch 1: [5105/10940] ---- BYOL Training Loss = 0.31777456402778625
30-01-2023 09:18:20 INFO Epoch 1: [5105/10940] ---- BYOL Validation Loss = 0.2970280349254608
30-01-2023 09:18:38 INFO Epoch 1: [5116/10940] ---- BYOL Training Loss = 0.2762109339237213
30-01-2023 09:18:56 INFO Epoch 1: [5127/10940] ---- BYOL Training Loss = 0.25544241070747375
30-01-2023 09:19:14 INFO Epoch 1: [5138/10940] ---- BYOL Training Loss = 0.28409653902053833
30-01-2023 09:19:32 INFO Epoch 1: [5149/10940] ---- BYOL Training Loss = 0.3067930042743683
30-01-2023 09:20:24 INFO Epoch 1: [5149/10940] ---- BYOL Validation Loss = 0.2989109456539154
30-01-2023 09:20:42 INFO Epoch 1: [5160/10940] ---- BYOL Training Loss = 0.28465336561203003
30-01-2023 09:21:00 INFO Epoch 1: [5171/10940] ---- BYOL Training Loss = 0.3228462338447571
30-01-2023 09:21:18 INFO Epoch 1: [5182/10940] ---- BYOL Training Loss = 0.31835031509399414
30-01-2023 09:21:36 INFO Epoch 1: [5193/10940] ---- BYOL Training Loss = 0.30019763112068176
30-01-2023 09:22:28 INFO Epoch 1: [5193/10940] ---- BYOL Validation Loss = 0.2876131236553192
30-01-2023 09:22:46 INFO Epoch 1: [5204/10940] ---- BYOL Training Loss = 0.31579238176345825
30-01-2023 09:23:03 INFO Epoch 1: [5215/10940] ---- BYOL Training Loss = 0.36878570914268494
30-01-2023 09:23:22 INFO Epoch 1: [5226/10940] ---- BYOL Training Loss = 0.3414832651615143
30-01-2023 09:23:40 INFO Epoch 1: [5237/10940] ---- BYOL Training Loss = 0.2949620485305786
30-01-2023 09:24:32 INFO Epoch 1: [5237/10940] ---- BYOL Validation Loss = 0.2837706208229065
30-01-2023 09:24:50 INFO Epoch 1: [5248/10940] ---- BYOL Training Loss = 0.33054885268211365
30-01-2023 09:25:08 INFO Epoch 1: [5259/10940] ---- BYOL Training Loss = 0.28230172395706177
30-01-2023 09:25:26 INFO Epoch 1: [5270/10940] ---- BYOL Training Loss = 0.3025430738925934
30-01-2023 09:25:44 INFO Epoch 1: [5281/10940] ---- BYOL Training Loss = 0.32683104276657104
30-01-2023 09:26:36 INFO Epoch 1: [5281/10940] ---- BYOL Validation Loss = 0.3025283217430115
30-01-2023 09:26:54 INFO Epoch 1: [5292/10940] ---- BYOL Training Loss = 0.372690349817276
30-01-2023 09:27:12 INFO Epoch 1: [5303/10940] ---- BYOL Training Loss = 0.3690776824951172
30-01-2023 09:27:30 INFO Epoch 1: [5314/10940] ---- BYOL Training Loss = 0.2920169234275818
30-01-2023 09:27:48 INFO Epoch 1: [5325/10940] ---- BYOL Training Loss = 0.2871297001838684
30-01-2023 09:28:40 INFO Epoch 1: [5325/10940] ---- BYOL Validation Loss = 0.2826833128929138
30-01-2023 09:28:58 INFO Epoch 1: [5336/10940] ---- BYOL Training Loss = 0.28653889894485474
30-01-2023 09:29:16 INFO Epoch 1: [5347/10940] ---- BYOL Training Loss = 0.289823442697525
30-01-2023 09:29:34 INFO Epoch 1: [5358/10940] ---- BYOL Training Loss = 0.29221412539482117
30-01-2023 09:29:52 INFO Epoch 1: [5369/10940] ---- BYOL Training Loss = 0.3229195475578308
30-01-2023 09:30:44 INFO Epoch 1: [5369/10940] ---- BYOL Validation Loss = 0.29784661531448364
30-01-2023 09:31:02 INFO Epoch 1: [5380/10940] ---- BYOL Training Loss = 0.3030059337615967
30-01-2023 09:31:20 INFO Epoch 1: [5391/10940] ---- BYOL Training Loss = 0.2846050560474396
30-01-2023 09:31:38 INFO Epoch 1: [5402/10940] ---- BYOL Training Loss = 0.2859744429588318
30-01-2023 09:31:56 INFO Epoch 1: [5413/10940] ---- BYOL Training Loss = 0.274675190448761
30-01-2023 09:32:49 INFO Epoch 1: [5413/10940] ---- BYOL Validation Loss = 0.285147100687027
30-01-2023 09:33:06 INFO Epoch 1: [5424/10940] ---- BYOL Training Loss = 0.2696438431739807
30-01-2023 09:33:24 INFO Epoch 1: [5435/10940] ---- BYOL Training Loss = 0.2721406817436218
30-01-2023 09:33:42 INFO Epoch 1: [5446/10940] ---- BYOL Training Loss = 0.28814974427223206
30-01-2023 09:34:00 INFO Epoch 1: [5457/10940] ---- BYOL Training Loss = 0.30895131826400757
30-01-2023 09:34:52 INFO Epoch 1: [5457/10940] ---- BYOL Validation Loss = 0.27287641167640686
30-01-2023 09:35:10 INFO Epoch 1: [5468/10940] ---- BYOL Training Loss = 0.33163121342658997
30-01-2023 09:35:28 INFO Epoch 1: [5479/10940] ---- BYOL Training Loss = 0.3490579128265381
30-01-2023 09:35:46 INFO Epoch 1: [5490/10940] ---- BYOL Training Loss = 0.39656516909599304
30-01-2023 09:36:04 INFO Epoch 1: [5501/10940] ---- BYOL Training Loss = 0.31068822741508484
30-01-2023 09:36:56 INFO Epoch 1: [5501/10940] ---- BYOL Validation Loss = 0.2857684791088104
30-01-2023 09:37:14 INFO Epoch 1: [5512/10940] ---- BYOL Training Loss = 0.2912859320640564
30-01-2023 09:37:32 INFO Epoch 1: [5523/10940] ---- BYOL Training Loss = 0.3491656482219696
30-01-2023 09:37:50 INFO Epoch 1: [5534/10940] ---- BYOL Training Loss = 0.2935793399810791
30-01-2023 09:38:08 INFO Epoch 1: [5545/10940] ---- BYOL Training Loss = 0.27643197774887085
30-01-2023 09:39:00 INFO Epoch 1: [5545/10940] ---- BYOL Validation Loss = 0.2973518371582031
30-01-2023 09:39:18 INFO Epoch 1: [5556/10940] ---- BYOL Training Loss = 0.33360743522644043
30-01-2023 09:39:36 INFO Epoch 1: [5567/10940] ---- BYOL Training Loss = 0.35252323746681213
30-01-2023 09:39:54 INFO Epoch 1: [5578/10940] ---- BYOL Training Loss = 0.2890031933784485
30-01-2023 09:40:12 INFO Epoch 1: [5589/10940] ---- BYOL Training Loss = 0.28602156043052673
30-01-2023 09:41:04 INFO Epoch 1: [5589/10940] ---- BYOL Validation Loss = 0.2857949435710907
30-01-2023 09:41:22 INFO Epoch 1: [5600/10940] ---- BYOL Training Loss = 0.3012771010398865
30-01-2023 09:41:40 INFO Epoch 1: [5611/10940] ---- BYOL Training Loss = 0.2670838236808777
30-01-2023 09:41:58 INFO Epoch 1: [5622/10940] ---- BYOL Training Loss = 0.2762572467327118
30-01-2023 09:42:16 INFO Epoch 1: [5633/10940] ---- BYOL Training Loss = 0.323673278093338
30-01-2023 09:43:09 INFO Epoch 1: [5633/10940] ---- BYOL Validation Loss = 0.29581308364868164
30-01-2023 09:43:26 INFO Epoch 1: [5644/10940] ---- BYOL Training Loss = 0.37669846415519714
30-01-2023 09:43:45 INFO Epoch 1: [5655/10940] ---- BYOL Training Loss = 0.359222948551178
30-01-2023 09:44:03 INFO Epoch 1: [5666/10940] ---- BYOL Training Loss = 0.31611019372940063
30-01-2023 09:44:21 INFO Epoch 1: [5677/10940] ---- BYOL Training Loss = 0.295504629611969
30-01-2023 09:45:13 INFO Epoch 1: [5677/10940] ---- BYOL Validation Loss = 0.29898861050605774
30-01-2023 09:45:30 INFO Epoch 1: [5688/10940] ---- BYOL Training Loss = 0.29383546113967896
30-01-2023 09:45:49 INFO Epoch 1: [5699/10940] ---- BYOL Training Loss = 0.3701786398887634
30-01-2023 09:46:07 INFO Epoch 1: [5710/10940] ---- BYOL Training Loss = 0.395217627286911
30-01-2023 09:46:25 INFO Epoch 1: [5721/10940] ---- BYOL Training Loss = 0.31581389904022217
30-01-2023 09:47:17 INFO Epoch 1: [5721/10940] ---- BYOL Validation Loss = 0.27194100618362427
30-01-2023 09:47:35 INFO Epoch 1: [5732/10940] ---- BYOL Training Loss = 0.2635863423347473
30-01-2023 09:47:54 INFO Epoch 1: [5743/10940] ---- BYOL Training Loss = 0.2513238489627838
30-01-2023 09:48:12 INFO Epoch 1: [5754/10940] ---- BYOL Training Loss = 0.2785751223564148
30-01-2023 09:48:30 INFO Epoch 1: [5765/10940] ---- BYOL Training Loss = 0.3100128173828125
30-01-2023 09:49:22 INFO Epoch 1: [5765/10940] ---- BYOL Validation Loss = 0.2803182303905487
30-01-2023 09:49:40 INFO Epoch 1: [5776/10940] ---- BYOL Training Loss = 0.30326882004737854
30-01-2023 09:49:58 INFO Epoch 1: [5787/10940] ---- BYOL Training Loss = 0.31105345487594604
30-01-2023 09:50:16 INFO Epoch 1: [5798/10940] ---- BYOL Training Loss = 0.3161916434764862
30-01-2023 09:50:34 INFO Epoch 1: [5809/10940] ---- BYOL Training Loss = 0.2501145005226135
30-01-2023 09:51:26 INFO Epoch 1: [5809/10940] ---- BYOL Validation Loss = 0.2799191176891327
30-01-2023 09:51:44 INFO Epoch 1: [5820/10940] ---- BYOL Training Loss = 0.2493247091770172
30-01-2023 09:52:02 INFO Epoch 1: [5831/10940] ---- BYOL Training Loss = 0.3014379143714905
30-01-2023 09:52:20 INFO Epoch 1: [5842/10940] ---- BYOL Training Loss = 0.30693212151527405
30-01-2023 09:52:38 INFO Epoch 1: [5853/10940] ---- BYOL Training Loss = 0.29615503549575806
30-01-2023 09:53:30 INFO Epoch 1: [5853/10940] ---- BYOL Validation Loss = 0.2965116798877716
30-01-2023 09:53:48 INFO Epoch 1: [5864/10940] ---- BYOL Training Loss = 0.3038979172706604
30-01-2023 09:54:06 INFO Epoch 1: [5875/10940] ---- BYOL Training Loss = 0.30180829763412476
30-01-2023 09:54:25 INFO Epoch 1: [5886/10940] ---- BYOL Training Loss = 0.27472567558288574
30-01-2023 09:54:43 INFO Epoch 1: [5897/10940] ---- BYOL Training Loss = 0.2952396869659424
30-01-2023 09:55:35 INFO Epoch 1: [5897/10940] ---- BYOL Validation Loss = 0.27759599685668945
30-01-2023 09:55:53 INFO Epoch 1: [5908/10940] ---- BYOL Training Loss = 0.28693777322769165
30-01-2023 09:56:11 INFO Epoch 1: [5919/10940] ---- BYOL Training Loss = 0.28357404470443726
30-01-2023 09:56:29 INFO Epoch 1: [5930/10940] ---- BYOL Training Loss = 0.305463582277298
30-01-2023 09:56:47 INFO Epoch 1: [5941/10940] ---- BYOL Training Loss = 0.30369362235069275
30-01-2023 09:57:39 INFO Epoch 1: [5941/10940] ---- BYOL Validation Loss = 0.2950553894042969
30-01-2023 09:57:57 INFO Epoch 1: [5952/10940] ---- BYOL Training Loss = 0.306063175201416
30-01-2023 09:58:15 INFO Epoch 1: [5963/10940] ---- BYOL Training Loss = 0.2902868390083313
30-01-2023 09:58:33 INFO Epoch 1: [5974/10940] ---- BYOL Training Loss = 0.3131839632987976
30-01-2023 09:58:52 INFO Epoch 1: [5985/10940] ---- BYOL Training Loss = 0.27199259400367737
30-01-2023 09:59:44 INFO Epoch 1: [5985/10940] ---- BYOL Validation Loss = 0.2866906523704529
30-01-2023 10:00:01 INFO Epoch 1: [5996/10940] ---- BYOL Training Loss = 0.2816554307937622
30-01-2023 10:00:20 INFO Epoch 1: [6007/10940] ---- BYOL Training Loss = 0.3456416726112366
30-01-2023 10:00:38 INFO Epoch 1: [6018/10940] ---- BYOL Training Loss = 0.3398934602737427
30-01-2023 10:00:56 INFO Epoch 1: [6029/10940] ---- BYOL Training Loss = 0.29715198278427124
30-01-2023 10:01:48 INFO Epoch 1: [6029/10940] ---- BYOL Validation Loss = 0.2905169129371643
30-01-2023 10:02:06 INFO Epoch 1: [6040/10940] ---- BYOL Training Loss = 0.2572675347328186
30-01-2023 10:02:24 INFO Epoch 1: [6051/10940] ---- BYOL Training Loss = 0.27963787317276
30-01-2023 10:02:42 INFO Epoch 1: [6062/10940] ---- BYOL Training Loss = 0.3295292258262634
30-01-2023 10:03:00 INFO Epoch 1: [6073/10940] ---- BYOL Training Loss = 0.32920417189598083
30-01-2023 10:03:52 INFO Epoch 1: [6073/10940] ---- BYOL Validation Loss = 0.3437204658985138
30-01-2023 10:04:10 INFO Epoch 1: [6084/10940] ---- BYOL Training Loss = 0.3083696663379669
30-01-2023 10:04:29 INFO Epoch 1: [6095/10940] ---- BYOL Training Loss = 0.3092620372772217
30-01-2023 10:04:47 INFO Epoch 1: [6106/10940] ---- BYOL Training Loss = 0.33845990896224976
30-01-2023 10:05:05 INFO Epoch 1: [6117/10940] ---- BYOL Training Loss = 0.3566165566444397
30-01-2023 10:05:57 INFO Epoch 1: [6117/10940] ---- BYOL Validation Loss = 0.30428606271743774
30-01-2023 10:06:14 INFO Epoch 1: [6128/10940] ---- BYOL Training Loss = 0.31662023067474365
30-01-2023 10:06:33 INFO Epoch 1: [6139/10940] ---- BYOL Training Loss = 0.3077942132949829
30-01-2023 10:06:51 INFO Epoch 1: [6150/10940] ---- BYOL Training Loss = 0.3598891794681549
30-01-2023 10:07:09 INFO Epoch 1: [6161/10940] ---- BYOL Training Loss = 0.336893230676651
30-01-2023 10:08:01 INFO Epoch 1: [6161/10940] ---- BYOL Validation Loss = 0.3002207279205322
30-01-2023 10:08:19 INFO Epoch 1: [6172/10940] ---- BYOL Training Loss = 0.3156692385673523
30-01-2023 10:08:37 INFO Epoch 1: [6183/10940] ---- BYOL Training Loss = 0.30051809549331665
30-01-2023 10:08:55 INFO Epoch 1: [6194/10940] ---- BYOL Training Loss = 0.29594480991363525
30-01-2023 10:09:13 INFO Epoch 1: [6205/10940] ---- BYOL Training Loss = 0.3051152527332306
30-01-2023 10:10:06 INFO Epoch 1: [6205/10940] ---- BYOL Validation Loss = 0.29026034474372864
30-01-2023 10:10:23 INFO Epoch 1: [6216/10940] ---- BYOL Training Loss = 0.3621770739555359
30-01-2023 10:10:42 INFO Epoch 1: [6227/10940] ---- BYOL Training Loss = 0.3423305153846741
30-01-2023 10:11:00 INFO Epoch 1: [6238/10940] ---- BYOL Training Loss = 0.32277244329452515
30-01-2023 10:11:18 INFO Epoch 1: [6249/10940] ---- BYOL Training Loss = 0.35869696736335754
30-01-2023 10:12:10 INFO Epoch 1: [6249/10940] ---- BYOL Validation Loss = 0.3053511083126068
30-01-2023 10:12:28 INFO Epoch 1: [6260/10940] ---- BYOL Training Loss = 0.3460996448993683
30-01-2023 10:12:46 INFO Epoch 1: [6271/10940] ---- BYOL Training Loss = 0.3328322172164917
30-01-2023 10:13:04 INFO Epoch 1: [6282/10940] ---- BYOL Training Loss = 0.3593582808971405
30-01-2023 10:13:22 INFO Epoch 1: [6293/10940] ---- BYOL Training Loss = 0.34512385725975037
30-01-2023 10:14:14 INFO Epoch 1: [6293/10940] ---- BYOL Validation Loss = 0.2826111316680908
30-01-2023 10:14:32 INFO Epoch 1: [6304/10940] ---- BYOL Training Loss = 0.34810006618499756
30-01-2023 10:14:50 INFO Epoch 1: [6315/10940] ---- BYOL Training Loss = 0.3749958872795105
30-01-2023 10:15:09 INFO Epoch 1: [6326/10940] ---- BYOL Training Loss = 0.3620278835296631
30-01-2023 10:15:27 INFO Epoch 1: [6337/10940] ---- BYOL Training Loss = 0.34058165550231934
30-01-2023 10:16:19 INFO Epoch 1: [6337/10940] ---- BYOL Validation Loss = 0.2893699109554291
30-01-2023 10:16:36 INFO Epoch 1: [6348/10940] ---- BYOL Training Loss = 0.290311336517334
30-01-2023 10:16:55 INFO Epoch 1: [6359/10940] ---- BYOL Training Loss = 0.31458866596221924
30-01-2023 10:17:13 INFO Epoch 1: [6370/10940] ---- BYOL Training Loss = 0.3280283212661743
30-01-2023 10:17:31 INFO Epoch 1: [6381/10940] ---- BYOL Training Loss = 0.26104068756103516
30-01-2023 10:18:23 INFO Epoch 1: [6381/10940] ---- BYOL Validation Loss = 0.2828960418701172
30-01-2023 10:18:41 INFO Epoch 1: [6392/10940] ---- BYOL Training Loss = 0.2914474308490753
30-01-2023 10:18:59 INFO Epoch 1: [6403/10940] ---- BYOL Training Loss = 0.3733466565608978
30-01-2023 10:19:17 INFO Epoch 1: [6414/10940] ---- BYOL Training Loss = 0.34737181663513184
30-01-2023 10:19:35 INFO Epoch 1: [6425/10940] ---- BYOL Training Loss = 0.32606175541877747
30-01-2023 10:20:28 INFO Epoch 1: [6425/10940] ---- BYOL Validation Loss = 0.29747360944747925
30-01-2023 10:20:46 INFO Epoch 1: [6436/10940] ---- BYOL Training Loss = 0.34640684723854065
30-01-2023 10:21:04 INFO Epoch 1: [6447/10940] ---- BYOL Training Loss = 0.3502298891544342
30-01-2023 10:21:22 INFO Epoch 1: [6458/10940] ---- BYOL Training Loss = 0.31071650981903076
30-01-2023 10:21:40 INFO Epoch 1: [6469/10940] ---- BYOL Training Loss = 0.2774781882762909
30-01-2023 10:22:32 INFO Epoch 1: [6469/10940] ---- BYOL Validation Loss = 0.29628297686576843
30-01-2023 10:22:50 INFO Epoch 1: [6480/10940] ---- BYOL Training Loss = 0.24161799252033234
30-01-2023 10:23:08 INFO Epoch 1: [6491/10940] ---- BYOL Training Loss = 0.26028043031692505
30-01-2023 10:23:26 INFO Epoch 1: [6502/10940] ---- BYOL Training Loss = 0.3127323091030121
30-01-2023 10:23:44 INFO Epoch 1: [6513/10940] ---- BYOL Training Loss = 0.38587337732315063
30-01-2023 10:24:36 INFO Epoch 1: [6513/10940] ---- BYOL Validation Loss = 0.2972247004508972
30-01-2023 10:24:55 INFO Epoch 1: [6524/10940] ---- BYOL Training Loss = 0.3438265919685364
30-01-2023 10:25:13 INFO Epoch 1: [6535/10940] ---- BYOL Training Loss = 0.27515965700149536
30-01-2023 10:25:31 INFO Epoch 1: [6546/10940] ---- BYOL Training Loss = 0.3226681351661682
30-01-2023 10:25:49 INFO Epoch 1: [6557/10940] ---- BYOL Training Loss = 0.320259690284729
30-01-2023 10:26:41 INFO Epoch 1: [6557/10940] ---- BYOL Validation Loss = 0.2727767527103424
30-01-2023 10:26:59 INFO Epoch 1: [6568/10940] ---- BYOL Training Loss = 0.2918064594268799
30-01-2023 10:27:17 INFO Epoch 1: [6579/10940] ---- BYOL Training Loss = 0.3295952081680298
30-01-2023 10:27:35 INFO Epoch 1: [6590/10940] ---- BYOL Training Loss = 0.3331398367881775
30-01-2023 10:27:54 INFO Epoch 1: [6601/10940] ---- BYOL Training Loss = 0.30001094937324524
30-01-2023 10:28:46 INFO Epoch 1: [6601/10940] ---- BYOL Validation Loss = 0.27923867106437683
30-01-2023 10:29:04 INFO Epoch 1: [6612/10940] ---- BYOL Training Loss = 0.2917463183403015
30-01-2023 10:29:22 INFO Epoch 1: [6623/10940] ---- BYOL Training Loss = 0.260540246963501
30-01-2023 10:29:40 INFO Epoch 1: [6634/10940] ---- BYOL Training Loss = 0.2762216627597809
30-01-2023 10:29:58 INFO Epoch 1: [6645/10940] ---- BYOL Training Loss = 0.3164864182472229
30-01-2023 10:30:51 INFO Epoch 1: [6645/10940] ---- BYOL Validation Loss = 0.28992775082588196
30-01-2023 10:31:08 INFO Epoch 1: [6656/10940] ---- BYOL Training Loss = 0.36045071482658386
30-01-2023 10:31:26 INFO Epoch 1: [6667/10940] ---- BYOL Training Loss = 0.36708900332450867
30-01-2023 10:31:44 INFO Epoch 1: [6678/10940] ---- BYOL Training Loss = 0.3373854458332062
30-01-2023 10:32:03 INFO Epoch 1: [6689/10940] ---- BYOL Training Loss = 0.3215975761413574
30-01-2023 10:32:55 INFO Epoch 1: [6689/10940] ---- BYOL Validation Loss = 0.2977585792541504
30-01-2023 10:33:13 INFO Epoch 1: [6700/10940] ---- BYOL Training Loss = 0.2898576557636261
30-01-2023 10:33:31 INFO Epoch 1: [6711/10940] ---- BYOL Training Loss = 0.28160226345062256
30-01-2023 10:33:50 INFO Epoch 1: [6722/10940] ---- BYOL Training Loss = 0.2707584500312805
30-01-2023 10:34:08 INFO Epoch 1: [6733/10940] ---- BYOL Training Loss = 0.29748237133026123
30-01-2023 10:35:00 INFO Epoch 1: [6733/10940] ---- BYOL Validation Loss = 0.3018866181373596
30-01-2023 10:35:18 INFO Epoch 1: [6744/10940] ---- BYOL Training Loss = 0.3493083119392395
30-01-2023 10:35:36 INFO Epoch 1: [6755/10940] ---- BYOL Training Loss = 0.3394717574119568
30-01-2023 10:35:54 INFO Epoch 1: [6766/10940] ---- BYOL Training Loss = 0.2842680513858795
30-01-2023 10:36:12 INFO Epoch 1: [6777/10940] ---- BYOL Training Loss = 0.29047641158103943
30-01-2023 10:37:05 INFO Epoch 1: [6777/10940] ---- BYOL Validation Loss = 0.2850984036922455
30-01-2023 10:37:22 INFO Epoch 1: [6788/10940] ---- BYOL Training Loss = 0.2809349000453949
30-01-2023 10:37:40 INFO Epoch 1: [6799/10940] ---- BYOL Training Loss = 0.27333977818489075
30-01-2023 10:37:59 INFO Epoch 1: [6810/10940] ---- BYOL Training Loss = 0.2637972831726074
30-01-2023 10:38:17 INFO Epoch 1: [6821/10940] ---- BYOL Training Loss = 0.24796240031719208
30-01-2023 10:39:09 INFO Epoch 1: [6821/10940] ---- BYOL Validation Loss = 0.2823839485645294
30-01-2023 10:39:27 INFO Epoch 1: [6832/10940] ---- BYOL Training Loss = 0.29404687881469727
30-01-2023 10:39:45 INFO Epoch 1: [6843/10940] ---- BYOL Training Loss = 0.30512458086013794
30-01-2023 10:40:03 INFO Epoch 1: [6854/10940] ---- BYOL Training Loss = 0.2723309397697449
30-01-2023 10:40:22 INFO Epoch 1: [6865/10940] ---- BYOL Training Loss = 0.28163668513298035
30-01-2023 10:41:14 INFO Epoch 1: [6865/10940] ---- BYOL Validation Loss = 0.29128244519233704
30-01-2023 10:41:32 INFO Epoch 1: [6876/10940] ---- BYOL Training Loss = 0.2934954762458801
30-01-2023 10:41:50 INFO Epoch 1: [6887/10940] ---- BYOL Training Loss = 0.28897958993911743
30-01-2023 10:42:08 INFO Epoch 1: [6898/10940] ---- BYOL Training Loss = 0.2774485945701599
30-01-2023 10:42:26 INFO Epoch 1: [6909/10940] ---- BYOL Training Loss = 0.3418422341346741
30-01-2023 10:43:18 INFO Epoch 1: [6909/10940] ---- BYOL Validation Loss = 0.2940664291381836
30-01-2023 10:43:37 INFO Epoch 1: [6920/10940] ---- BYOL Training Loss = 0.3716558814048767
30-01-2023 10:43:55 INFO Epoch 1: [6931/10940] ---- BYOL Training Loss = 0.32220369577407837
30-01-2023 10:44:13 INFO Epoch 1: [6942/10940] ---- BYOL Training Loss = 0.26680126786231995
30-01-2023 10:44:31 INFO Epoch 1: [6953/10940] ---- BYOL Training Loss = 0.3224713206291199
30-01-2023 10:45:23 INFO Epoch 1: [6953/10940] ---- BYOL Validation Loss = 0.2991892993450165
30-01-2023 10:45:41 INFO Epoch 1: [6964/10940] ---- BYOL Training Loss = 0.3433890640735626
30-01-2023 10:45:59 INFO Epoch 1: [6975/10940] ---- BYOL Training Loss = 0.3200188875198364
30-01-2023 10:46:17 INFO Epoch 1: [6986/10940] ---- BYOL Training Loss = 0.2837010324001312
30-01-2023 10:46:36 INFO Epoch 1: [6997/10940] ---- BYOL Training Loss = 0.26166531443595886
30-01-2023 10:47:28 INFO Epoch 1: [6997/10940] ---- BYOL Validation Loss = 0.28738853335380554
30-01-2023 10:47:46 INFO Epoch 1: [7008/10940] ---- BYOL Training Loss = 0.31403642892837524
30-01-2023 10:48:04 INFO Epoch 1: [7019/10940] ---- BYOL Training Loss = 0.3367442488670349
30-01-2023 10:48:23 INFO Epoch 1: [7030/10940] ---- BYOL Training Loss = 0.3026893138885498
30-01-2023 10:48:41 INFO Epoch 1: [7041/10940] ---- BYOL Training Loss = 0.3135376572608948
30-01-2023 10:49:33 INFO Epoch 1: [7041/10940] ---- BYOL Validation Loss = 0.5117394328117371
30-01-2023 10:49:51 INFO Epoch 1: [7052/10940] ---- BYOL Training Loss = 0.27157554030418396
30-01-2023 10:50:09 INFO Epoch 1: [7063/10940] ---- BYOL Training Loss = 0.259909063577652
30-01-2023 10:50:27 INFO Epoch 1: [7074/10940] ---- BYOL Training Loss = 0.3055683970451355
30-01-2023 10:50:46 INFO Epoch 1: [7085/10940] ---- BYOL Training Loss = 0.336550772190094
30-01-2023 10:51:38 INFO Epoch 1: [7085/10940] ---- BYOL Validation Loss = 0.29006123542785645
30-01-2023 10:51:56 INFO Epoch 1: [7096/10940] ---- BYOL Training Loss = 0.27993541955947876
30-01-2023 10:52:14 INFO Epoch 1: [7107/10940] ---- BYOL Training Loss = 0.24548184871673584
30-01-2023 10:52:32 INFO Epoch 1: [7118/10940] ---- BYOL Training Loss = 0.28478047251701355
30-01-2023 10:52:50 INFO Epoch 1: [7129/10940] ---- BYOL Training Loss = 0.31505778431892395
30-01-2023 10:53:43 INFO Epoch 1: [7129/10940] ---- BYOL Validation Loss = 0.293185293674469
30-01-2023 10:54:01 INFO Epoch 1: [7140/10940] ---- BYOL Training Loss = 0.3408394753932953
30-01-2023 10:54:19 INFO Epoch 1: [7151/10940] ---- BYOL Training Loss = 0.3426781892776489
30-01-2023 10:54:37 INFO Epoch 1: [7162/10940] ---- BYOL Training Loss = 0.3215253949165344
30-01-2023 10:54:55 INFO Epoch 1: [7173/10940] ---- BYOL Training Loss = 0.31496211886405945
30-01-2023 10:55:48 INFO Epoch 1: [7173/10940] ---- BYOL Validation Loss = 0.30461591482162476
30-01-2023 10:56:06 INFO Epoch 1: [7184/10940] ---- BYOL Training Loss = 0.33282145857810974
30-01-2023 10:56:24 INFO Epoch 1: [7195/10940] ---- BYOL Training Loss = 0.3232141137123108
30-01-2023 10:56:42 INFO Epoch 1: [7206/10940] ---- BYOL Training Loss = 0.341945081949234
30-01-2023 10:57:01 INFO Epoch 1: [7217/10940] ---- BYOL Training Loss = 0.33409085869789124
30-01-2023 10:57:53 INFO Epoch 1: [7217/10940] ---- BYOL Validation Loss = 0.28416064381599426
30-01-2023 10:58:10 INFO Epoch 1: [7228/10940] ---- BYOL Training Loss = 0.35570240020751953
30-01-2023 10:58:29 INFO Epoch 1: [7239/10940] ---- BYOL Training Loss = 0.3516620099544525
30-01-2023 10:58:47 INFO Epoch 1: [7250/10940] ---- BYOL Training Loss = 0.3674324154853821
30-01-2023 10:59:05 INFO Epoch 1: [7261/10940] ---- BYOL Training Loss = 0.3630344867706299
30-01-2023 10:59:58 INFO Epoch 1: [7261/10940] ---- BYOL Validation Loss = 0.28664615750312805
30-01-2023 11:00:15 INFO Epoch 1: [7272/10940] ---- BYOL Training Loss = 0.3648071885108948
30-01-2023 11:00:34 INFO Epoch 1: [7283/10940] ---- BYOL Training Loss = 0.34295934438705444
30-01-2023 11:00:52 INFO Epoch 1: [7294/10940] ---- BYOL Training Loss = 0.3160184919834137
30-01-2023 11:01:10 INFO Epoch 1: [7305/10940] ---- BYOL Training Loss = 0.29947829246520996
30-01-2023 11:02:02 INFO Epoch 1: [7305/10940] ---- BYOL Validation Loss = 0.28985410928726196
30-01-2023 11:02:20 INFO Epoch 1: [7316/10940] ---- BYOL Training Loss = 0.3462778925895691
30-01-2023 11:02:39 INFO Epoch 1: [7327/10940] ---- BYOL Training Loss = 0.3286556601524353
30-01-2023 11:02:57 INFO Epoch 1: [7338/10940] ---- BYOL Training Loss = 0.3367319703102112
30-01-2023 11:03:15 INFO Epoch 1: [7349/10940] ---- BYOL Training Loss = 0.32816657423973083
30-01-2023 11:04:07 INFO Epoch 1: [7349/10940] ---- BYOL Validation Loss = 0.30037036538124084
30-01-2023 11:04:25 INFO Epoch 1: [7360/10940] ---- BYOL Training Loss = 0.3187086284160614
30-01-2023 11:04:44 INFO Epoch 1: [7371/10940] ---- BYOL Training Loss = 0.3490482270717621
30-01-2023 11:05:02 INFO Epoch 1: [7382/10940] ---- BYOL Training Loss = 0.3476595878601074
30-01-2023 11:05:20 INFO Epoch 1: [7393/10940] ---- BYOL Training Loss = 0.31315702199935913
30-01-2023 11:06:12 INFO Epoch 1: [7393/10940] ---- BYOL Validation Loss = 0.2922452986240387
30-01-2023 11:06:30 INFO Epoch 1: [7404/10940] ---- BYOL Training Loss = 0.349843829870224
30-01-2023 11:06:48 INFO Epoch 1: [7415/10940] ---- BYOL Training Loss = 0.2996428906917572
30-01-2023 11:07:07 INFO Epoch 1: [7426/10940] ---- BYOL Training Loss = 0.3230120837688446
30-01-2023 11:07:25 INFO Epoch 1: [7437/10940] ---- BYOL Training Loss = 0.3067137598991394
30-01-2023 11:08:17 INFO Epoch 1: [7437/10940] ---- BYOL Validation Loss = 0.3039070665836334
30-01-2023 11:08:35 INFO Epoch 1: [7448/10940] ---- BYOL Training Loss = 0.3103461265563965
30-01-2023 11:08:53 INFO Epoch 1: [7459/10940] ---- BYOL Training Loss = 0.3356233835220337
30-01-2023 11:09:12 INFO Epoch 1: [7470/10940] ---- BYOL Training Loss = 0.3588452935218811
30-01-2023 11:09:30 INFO Epoch 1: [7481/10940] ---- BYOL Training Loss = 0.35254669189453125
30-01-2023 11:10:22 INFO Epoch 1: [7481/10940] ---- BYOL Validation Loss = 0.29174095392227173
30-01-2023 11:10:40 INFO Epoch 1: [7492/10940] ---- BYOL Training Loss = 0.30617743730545044
30-01-2023 11:10:58 INFO Epoch 1: [7503/10940] ---- BYOL Training Loss = 0.2822323441505432
30-01-2023 11:11:17 INFO Epoch 1: [7514/10940] ---- BYOL Training Loss = 0.3084651827812195
30-01-2023 11:11:35 INFO Epoch 1: [7525/10940] ---- BYOL Training Loss = 0.3470022678375244
30-01-2023 11:12:27 INFO Epoch 1: [7525/10940] ---- BYOL Validation Loss = 0.27798226475715637
30-01-2023 11:12:45 INFO Epoch 1: [7536/10940] ---- BYOL Training Loss = 0.3305695354938507
30-01-2023 11:13:03 INFO Epoch 1: [7547/10940] ---- BYOL Training Loss = 0.3002801537513733
30-01-2023 11:13:21 INFO Epoch 1: [7558/10940] ---- BYOL Training Loss = 0.26381441950798035
30-01-2023 11:13:39 INFO Epoch 1: [7569/10940] ---- BYOL Training Loss = 0.29779666662216187
30-01-2023 11:14:32 INFO Epoch 1: [7569/10940] ---- BYOL Validation Loss = 0.2905387878417969
30-01-2023 11:14:50 INFO Epoch 1: [7580/10940] ---- BYOL Training Loss = 0.3031981289386749
30-01-2023 11:15:08 INFO Epoch 1: [7591/10940] ---- BYOL Training Loss = 0.26935598254203796
30-01-2023 11:15:26 INFO Epoch 1: [7602/10940] ---- BYOL Training Loss = 0.27760666608810425
30-01-2023 11:15:45 INFO Epoch 1: [7613/10940] ---- BYOL Training Loss = 0.23995248973369598
30-01-2023 11:16:37 INFO Epoch 1: [7613/10940] ---- BYOL Validation Loss = 0.2647077441215515
30-01-2023 11:16:55 INFO Epoch 1: [7624/10940] ---- BYOL Training Loss = 0.29565390944480896
30-01-2023 11:17:13 INFO Epoch 1: [7635/10940] ---- BYOL Training Loss = 0.3390926420688629
30-01-2023 11:17:32 INFO Epoch 1: [7646/10940] ---- BYOL Training Loss = 0.2992327809333801
30-01-2023 11:17:50 INFO Epoch 1: [7657/10940] ---- BYOL Training Loss = 0.2893502712249756
30-01-2023 11:18:42 INFO Epoch 1: [7657/10940] ---- BYOL Validation Loss = 0.29448357224464417
30-01-2023 11:19:00 INFO Epoch 1: [7668/10940] ---- BYOL Training Loss = 0.3277442455291748
30-01-2023 11:19:18 INFO Epoch 1: [7679/10940] ---- BYOL Training Loss = 0.33030909299850464
30-01-2023 11:19:37 INFO Epoch 1: [7690/10940] ---- BYOL Training Loss = 0.293499231338501
30-01-2023 11:19:55 INFO Epoch 1: [7701/10940] ---- BYOL Training Loss = 0.30828148126602173
30-01-2023 11:20:47 INFO Epoch 1: [7701/10940] ---- BYOL Validation Loss = 0.2791992723941803
30-01-2023 11:21:05 INFO Epoch 1: [7712/10940] ---- BYOL Training Loss = 0.3364597260951996
30-01-2023 11:21:23 INFO Epoch 1: [7723/10940] ---- BYOL Training Loss = 0.33935004472732544
30-01-2023 11:21:42 INFO Epoch 1: [7734/10940] ---- BYOL Training Loss = 0.23555752635002136
30-01-2023 11:22:00 INFO Epoch 1: [7745/10940] ---- BYOL Training Loss = 0.2200227677822113
30-01-2023 11:22:52 INFO Epoch 1: [7745/10940] ---- BYOL Validation Loss = 0.28543156385421753
30-01-2023 11:23:10 INFO Epoch 1: [7756/10940] ---- BYOL Training Loss = 0.2676205635070801
30-01-2023 11:23:28 INFO Epoch 1: [7767/10940] ---- BYOL Training Loss = 0.27614855766296387
30-01-2023 11:23:47 INFO Epoch 1: [7778/10940] ---- BYOL Training Loss = 0.30147528648376465
30-01-2023 11:24:05 INFO Epoch 1: [7789/10940] ---- BYOL Training Loss = 0.3560047447681427
30-01-2023 11:24:57 INFO Epoch 1: [7789/10940] ---- BYOL Validation Loss = 0.2861557900905609
30-01-2023 11:25:15 INFO Epoch 1: [7800/10940] ---- BYOL Training Loss = 0.30555564165115356
30-01-2023 11:25:34 INFO Epoch 1: [7811/10940] ---- BYOL Training Loss = 0.2789680063724518
30-01-2023 11:25:52 INFO Epoch 1: [7822/10940] ---- BYOL Training Loss = 0.2731417119503021
30-01-2023 11:26:10 INFO Epoch 1: [7833/10940] ---- BYOL Training Loss = 0.269737184047699
30-01-2023 11:27:02 INFO Epoch 1: [7833/10940] ---- BYOL Validation Loss = 0.28463226556777954
30-01-2023 11:27:20 INFO Epoch 1: [7844/10940] ---- BYOL Training Loss = 0.3174157440662384
30-01-2023 11:27:39 INFO Epoch 1: [7855/10940] ---- BYOL Training Loss = 0.30472418665885925
30-01-2023 11:27:57 INFO Epoch 1: [7866/10940] ---- BYOL Training Loss = 0.30007946491241455
30-01-2023 11:28:15 INFO Epoch 1: [7877/10940] ---- BYOL Training Loss = 0.3028939664363861
30-01-2023 11:29:08 INFO Epoch 1: [7877/10940] ---- BYOL Validation Loss = 0.2915286421775818
30-01-2023 11:29:26 INFO Epoch 1: [7888/10940] ---- BYOL Training Loss = 0.3032207190990448
30-01-2023 11:29:44 INFO Epoch 1: [7899/10940] ---- BYOL Training Loss = 0.39158526062965393
30-01-2023 11:30:02 INFO Epoch 1: [7910/10940] ---- BYOL Training Loss = 0.38684457540512085
30-01-2023 11:30:21 INFO Epoch 1: [7921/10940] ---- BYOL Training Loss = 0.2961989939212799
30-01-2023 11:31:13 INFO Epoch 1: [7921/10940] ---- BYOL Validation Loss = 0.28626203536987305
30-01-2023 11:31:31 INFO Epoch 1: [7932/10940] ---- BYOL Training Loss = 0.3156992495059967
30-01-2023 11:31:49 INFO Epoch 1: [7943/10940] ---- BYOL Training Loss = 0.28118568658828735
30-01-2023 11:32:08 INFO Epoch 1: [7954/10940] ---- BYOL Training Loss = 0.2531960904598236
30-01-2023 11:32:26 INFO Epoch 1: [7965/10940] ---- BYOL Training Loss = 0.2877514958381653
30-01-2023 11:33:18 INFO Epoch 1: [7965/10940] ---- BYOL Validation Loss = 0.2883357107639313
30-01-2023 11:33:36 INFO Epoch 1: [7976/10940] ---- BYOL Training Loss = 0.3206615149974823
30-01-2023 11:33:54 INFO Epoch 1: [7987/10940] ---- BYOL Training Loss = 0.3538524806499481
30-01-2023 11:34:13 INFO Epoch 1: [7998/10940] ---- BYOL Training Loss = 0.3276863396167755
30-01-2023 11:34:31 INFO Epoch 1: [8009/10940] ---- BYOL Training Loss = 0.31816115975379944
30-01-2023 11:35:23 INFO Epoch 1: [8009/10940] ---- BYOL Validation Loss = 0.30432096123695374
30-01-2023 11:35:41 INFO Epoch 1: [8020/10940] ---- BYOL Training Loss = 0.29705870151519775
30-01-2023 11:36:00 INFO Epoch 1: [8031/10940] ---- BYOL Training Loss = 0.28634923696517944
30-01-2023 11:36:18 INFO Epoch 1: [8042/10940] ---- BYOL Training Loss = 0.27807268500328064
30-01-2023 11:36:36 INFO Epoch 1: [8053/10940] ---- BYOL Training Loss = 0.2877822518348694
30-01-2023 11:37:29 INFO Epoch 1: [8053/10940] ---- BYOL Validation Loss = 0.29519954323768616
30-01-2023 11:37:46 INFO Epoch 1: [8064/10940] ---- BYOL Training Loss = 0.28350475430488586
30-01-2023 11:38:05 INFO Epoch 1: [8075/10940] ---- BYOL Training Loss = 0.28103527426719666
30-01-2023 11:38:23 INFO Epoch 1: [8086/10940] ---- BYOL Training Loss = 0.24110683798789978
30-01-2023 11:38:41 INFO Epoch 1: [8097/10940] ---- BYOL Training Loss = 0.26729363203048706
30-01-2023 11:39:33 INFO Epoch 1: [8097/10940] ---- BYOL Validation Loss = 0.28970998525619507
30-01-2023 11:39:52 INFO Epoch 1: [8108/10940] ---- BYOL Training Loss = 0.35535451769828796
30-01-2023 11:40:10 INFO Epoch 1: [8119/10940] ---- BYOL Training Loss = 0.31032782793045044
30-01-2023 11:40:28 INFO Epoch 1: [8130/10940] ---- BYOL Training Loss = 0.3001251816749573
30-01-2023 11:40:47 INFO Epoch 1: [8141/10940] ---- BYOL Training Loss = 0.3292563259601593
30-01-2023 11:41:39 INFO Epoch 1: [8141/10940] ---- BYOL Validation Loss = 0.28230199217796326
30-01-2023 11:41:57 INFO Epoch 1: [8152/10940] ---- BYOL Training Loss = 0.3280445337295532
30-01-2023 11:42:15 INFO Epoch 1: [8163/10940] ---- BYOL Training Loss = 0.35402509570121765
30-01-2023 11:42:34 INFO Epoch 1: [8174/10940] ---- BYOL Training Loss = 0.33000436425209045
30-01-2023 11:42:52 INFO Epoch 1: [8185/10940] ---- BYOL Training Loss = 0.34876900911331177
30-01-2023 11:43:44 INFO Epoch 1: [8185/10940] ---- BYOL Validation Loss = 0.2937450110912323
30-01-2023 11:44:02 INFO Epoch 1: [8196/10940] ---- BYOL Training Loss = 0.31356972455978394
30-01-2023 11:44:21 INFO Epoch 1: [8207/10940] ---- BYOL Training Loss = 0.2970113158226013
30-01-2023 11:44:39 INFO Epoch 1: [8218/10940] ---- BYOL Training Loss = 0.28658902645111084
30-01-2023 11:44:57 INFO Epoch 1: [8229/10940] ---- BYOL Training Loss = 0.2687665820121765
30-01-2023 11:45:49 INFO Epoch 1: [8229/10940] ---- BYOL Validation Loss = 0.29514530301094055
30-01-2023 11:46:08 INFO Epoch 1: [8240/10940] ---- BYOL Training Loss = 0.2652674913406372
30-01-2023 11:46:26 INFO Epoch 1: [8251/10940] ---- BYOL Training Loss = 0.26530933380126953
30-01-2023 11:46:44 INFO Epoch 1: [8262/10940] ---- BYOL Training Loss = 0.3299742639064789
30-01-2023 11:47:03 INFO Epoch 1: [8273/10940] ---- BYOL Training Loss = 0.33842721581459045
30-01-2023 11:47:55 INFO Epoch 1: [8273/10940] ---- BYOL Validation Loss = 0.29191017150878906
30-01-2023 11:48:13 INFO Epoch 1: [8284/10940] ---- BYOL Training Loss = 0.315096914768219
30-01-2023 11:48:31 INFO Epoch 1: [8295/10940] ---- BYOL Training Loss = 0.2874961495399475
30-01-2023 11:48:50 INFO Epoch 1: [8306/10940] ---- BYOL Training Loss = 0.32946687936782837
30-01-2023 11:49:08 INFO Epoch 1: [8317/10940] ---- BYOL Training Loss = 0.32838529348373413
30-01-2023 11:50:00 INFO Epoch 1: [8317/10940] ---- BYOL Validation Loss = 0.28914767503738403
30-01-2023 11:50:18 INFO Epoch 1: [8328/10940] ---- BYOL Training Loss = 0.31571176648139954
30-01-2023 11:50:37 INFO Epoch 1: [8339/10940] ---- BYOL Training Loss = 0.3352402150630951
30-01-2023 11:50:55 INFO Epoch 1: [8350/10940] ---- BYOL Training Loss = 0.3750888407230377
30-01-2023 11:51:14 INFO Epoch 1: [8361/10940] ---- BYOL Training Loss = 0.3045639991760254
30-01-2023 11:52:06 INFO Epoch 1: [8361/10940] ---- BYOL Validation Loss = 0.29855337738990784
30-01-2023 11:52:24 INFO Epoch 1: [8372/10940] ---- BYOL Training Loss = 0.2895892858505249
30-01-2023 11:52:42 INFO Epoch 1: [8383/10940] ---- BYOL Training Loss = 0.3205413818359375
30-01-2023 11:53:01 INFO Epoch 1: [8394/10940] ---- BYOL Training Loss = 0.32480743527412415
30-01-2023 11:53:19 INFO Epoch 1: [8405/10940] ---- BYOL Training Loss = 0.36099860072135925
30-01-2023 11:54:12 INFO Epoch 1: [8405/10940] ---- BYOL Validation Loss = 0.2875295579433441
30-01-2023 11:54:30 INFO Epoch 1: [8416/10940] ---- BYOL Training Loss = 0.3465377986431122
30-01-2023 11:54:48 INFO Epoch 1: [8427/10940] ---- BYOL Training Loss = 0.31489312648773193
30-01-2023 11:55:07 INFO Epoch 1: [8438/10940] ---- BYOL Training Loss = 0.2979050576686859
30-01-2023 11:55:25 INFO Epoch 1: [8449/10940] ---- BYOL Training Loss = 0.32731956243515015
30-01-2023 11:56:17 INFO Epoch 1: [8449/10940] ---- BYOL Validation Loss = 0.2862875461578369
30-01-2023 11:56:35 INFO Epoch 1: [8460/10940] ---- BYOL Training Loss = 0.3556908369064331
30-01-2023 11:56:54 INFO Epoch 1: [8471/10940] ---- BYOL Training Loss = 0.3379628360271454
30-01-2023 11:57:12 INFO Epoch 1: [8482/10940] ---- BYOL Training Loss = 0.3326142132282257
30-01-2023 11:57:31 INFO Epoch 1: [8493/10940] ---- BYOL Training Loss = 0.30114904046058655
30-01-2023 11:58:23 INFO Epoch 1: [8493/10940] ---- BYOL Validation Loss = 0.2780476212501526
30-01-2023 11:58:41 INFO Epoch 1: [8504/10940] ---- BYOL Training Loss = 0.28449901938438416
30-01-2023 11:58:59 INFO Epoch 1: [8515/10940] ---- BYOL Training Loss = 0.2958173453807831
30-01-2023 11:59:18 INFO Epoch 1: [8526/10940] ---- BYOL Training Loss = 0.3536785840988159
30-01-2023 11:59:36 INFO Epoch 1: [8537/10940] ---- BYOL Training Loss = 0.33007127046585083
30-01-2023 12:00:28 INFO Epoch 1: [8537/10940] ---- BYOL Validation Loss = 0.27845504879951477
30-01-2023 12:00:46 INFO Epoch 1: [8548/10940] ---- BYOL Training Loss = 0.3175501227378845
30-01-2023 12:01:05 INFO Epoch 1: [8559/10940] ---- BYOL Training Loss = 0.3121775984764099
30-01-2023 12:01:23 INFO Epoch 1: [8570/10940] ---- BYOL Training Loss = 0.2724798023700714
30-01-2023 12:01:42 INFO Epoch 1: [8581/10940] ---- BYOL Training Loss = 0.25198429822921753
30-01-2023 12:02:34 INFO Epoch 1: [8581/10940] ---- BYOL Validation Loss = 0.2751787602901459
30-01-2023 12:02:52 INFO Epoch 1: [8592/10940] ---- BYOL Training Loss = 0.2660568654537201
30-01-2023 12:03:11 INFO Epoch 1: [8603/10940] ---- BYOL Training Loss = 0.23309414088726044
30-01-2023 12:03:29 INFO Epoch 1: [8614/10940] ---- BYOL Training Loss = 0.2841249108314514
30-01-2023 12:03:47 INFO Epoch 1: [8625/10940] ---- BYOL Training Loss = 0.35098356008529663
30-01-2023 12:04:40 INFO Epoch 1: [8625/10940] ---- BYOL Validation Loss = 0.5662476420402527
30-01-2023 12:04:58 INFO Epoch 1: [8636/10940] ---- BYOL Training Loss = 0.31707555055618286
30-01-2023 12:05:16 INFO Epoch 1: [8647/10940] ---- BYOL Training Loss = 0.2844557464122772
30-01-2023 12:05:35 INFO Epoch 1: [8658/10940] ---- BYOL Training Loss = 0.3019493818283081
30-01-2023 12:05:53 INFO Epoch 1: [8669/10940] ---- BYOL Training Loss = 0.35239818692207336
30-01-2023 12:06:45 INFO Epoch 1: [8669/10940] ---- BYOL Validation Loss = 0.2955867648124695
30-01-2023 12:07:04 INFO Epoch 1: [8680/10940] ---- BYOL Training Loss = 0.3714658319950104
30-01-2023 12:07:22 INFO Epoch 1: [8691/10940] ---- BYOL Training Loss = 0.3495124876499176
30-01-2023 12:07:40 INFO Epoch 1: [8702/10940] ---- BYOL Training Loss = 0.38248157501220703
30-01-2023 12:07:59 INFO Epoch 1: [8713/10940] ---- BYOL Training Loss = 0.3537643253803253
30-01-2023 12:08:51 INFO Epoch 1: [8713/10940] ---- BYOL Validation Loss = 0.28245899081230164
30-01-2023 12:09:09 INFO Epoch 1: [8724/10940] ---- BYOL Training Loss = 0.3191840350627899
30-01-2023 12:09:28 INFO Epoch 1: [8735/10940] ---- BYOL Training Loss = 0.3056538701057434
30-01-2023 12:09:46 INFO Epoch 1: [8746/10940] ---- BYOL Training Loss = 0.28948187828063965
30-01-2023 12:10:04 INFO Epoch 1: [8757/10940] ---- BYOL Training Loss = 0.29189202189445496
30-01-2023 12:10:57 INFO Epoch 1: [8757/10940] ---- BYOL Validation Loss = 0.28835412859916687
30-01-2023 12:11:15 INFO Epoch 1: [8768/10940] ---- BYOL Training Loss = 0.3246644139289856
30-01-2023 12:11:33 INFO Epoch 1: [8779/10940] ---- BYOL Training Loss = 0.3576919138431549
30-01-2023 12:11:52 INFO Epoch 1: [8790/10940] ---- BYOL Training Loss = 0.3352721333503723
30-01-2023 12:12:10 INFO Epoch 1: [8801/10940] ---- BYOL Training Loss = 0.2949075400829315
30-01-2023 12:13:02 INFO Epoch 1: [8801/10940] ---- BYOL Validation Loss = 0.2859709560871124
30-01-2023 12:13:20 INFO Epoch 1: [8812/10940] ---- BYOL Training Loss = 0.2765117883682251
30-01-2023 12:13:39 INFO Epoch 1: [8823/10940] ---- BYOL Training Loss = 0.2994984984397888
30-01-2023 12:13:57 INFO Epoch 1: [8834/10940] ---- BYOL Training Loss = 0.3505508303642273
30-01-2023 12:14:16 INFO Epoch 1: [8845/10940] ---- BYOL Training Loss = 0.3490367829799652
30-01-2023 12:15:08 INFO Epoch 1: [8845/10940] ---- BYOL Validation Loss = 0.28144484758377075
30-01-2023 12:15:26 INFO Epoch 1: [8856/10940] ---- BYOL Training Loss = 0.3528840243816376
30-01-2023 12:15:45 INFO Epoch 1: [8867/10940] ---- BYOL Training Loss = 0.30473536252975464
30-01-2023 12:16:03 INFO Epoch 1: [8878/10940] ---- BYOL Training Loss = 0.31717604398727417
30-01-2023 12:16:22 INFO Epoch 1: [8889/10940] ---- BYOL Training Loss = 0.35502389073371887
30-01-2023 12:17:14 INFO Epoch 1: [8889/10940] ---- BYOL Validation Loss = 0.28477296233177185
30-01-2023 12:17:32 INFO Epoch 1: [8900/10940] ---- BYOL Training Loss = 0.355257123708725
30-01-2023 12:17:50 INFO Epoch 1: [8911/10940] ---- BYOL Training Loss = 0.29734277725219727
30-01-2023 12:18:09 INFO Epoch 1: [8922/10940] ---- BYOL Training Loss = 0.27245643734931946
30-01-2023 12:18:27 INFO Epoch 1: [8933/10940] ---- BYOL Training Loss = 0.28673118352890015
30-01-2023 12:19:19 INFO Epoch 1: [8933/10940] ---- BYOL Validation Loss = 0.2827795743942261
30-01-2023 12:19:37 INFO Epoch 1: [8944/10940] ---- BYOL Training Loss = 0.3164210915565491
30-01-2023 12:19:56 INFO Epoch 1: [8955/10940] ---- BYOL Training Loss = 0.28870099782943726
30-01-2023 12:20:14 INFO Epoch 1: [8966/10940] ---- BYOL Training Loss = 0.3031631112098694
30-01-2023 12:20:33 INFO Epoch 1: [8977/10940] ---- BYOL Training Loss = 0.3165382742881775
30-01-2023 12:21:25 INFO Epoch 1: [8977/10940] ---- BYOL Validation Loss = 0.2580103874206543
30-01-2023 12:21:43 INFO Epoch 1: [8988/10940] ---- BYOL Training Loss = 0.30153965950012207
30-01-2023 12:22:02 INFO Epoch 1: [8999/10940] ---- BYOL Training Loss = 0.2473456859588623
30-01-2023 12:22:20 INFO Epoch 1: [9010/10940] ---- BYOL Training Loss = 0.22844359278678894
30-01-2023 12:22:38 INFO Epoch 1: [9021/10940] ---- BYOL Training Loss = 0.2698569893836975
30-01-2023 12:23:31 INFO Epoch 1: [9021/10940] ---- BYOL Validation Loss = 0.27624353766441345
30-01-2023 12:23:49 INFO Epoch 1: [9032/10940] ---- BYOL Training Loss = 0.2996827960014343
30-01-2023 12:24:07 INFO Epoch 1: [9043/10940] ---- BYOL Training Loss = 0.28222718834877014
30-01-2023 12:24:26 INFO Epoch 1: [9054/10940] ---- BYOL Training Loss = 0.24910922348499298
30-01-2023 12:24:44 INFO Epoch 1: [9065/10940] ---- BYOL Training Loss = 0.23084494471549988
30-01-2023 12:25:37 INFO Epoch 1: [9065/10940] ---- BYOL Validation Loss = 0.27085161209106445
30-01-2023 12:25:55 INFO Epoch 1: [9076/10940] ---- BYOL Training Loss = 0.2708238363265991
30-01-2023 12:26:13 INFO Epoch 1: [9087/10940] ---- BYOL Training Loss = 0.33600088953971863
30-01-2023 12:26:32 INFO Epoch 1: [9098/10940] ---- BYOL Training Loss = 0.31999868154525757
30-01-2023 12:26:50 INFO Epoch 1: [9109/10940] ---- BYOL Training Loss = 0.28418439626693726
30-01-2023 12:27:42 INFO Epoch 1: [9109/10940] ---- BYOL Validation Loss = 0.26483097672462463
30-01-2023 12:28:00 INFO Epoch 1: [9120/10940] ---- BYOL Training Loss = 0.28433936834335327
30-01-2023 12:28:19 INFO Epoch 1: [9131/10940] ---- BYOL Training Loss = 0.26541101932525635
30-01-2023 12:28:37 INFO Epoch 1: [9142/10940] ---- BYOL Training Loss = 0.2719489336013794
30-01-2023 12:28:56 INFO Epoch 1: [9153/10940] ---- BYOL Training Loss = 0.28290683031082153
30-01-2023 12:29:48 INFO Epoch 1: [9153/10940] ---- BYOL Validation Loss = 0.26311400532722473
30-01-2023 12:30:06 INFO Epoch 1: [9164/10940] ---- BYOL Training Loss = 0.33150506019592285
30-01-2023 12:30:24 INFO Epoch 1: [9175/10940] ---- BYOL Training Loss = 0.3258357644081116
30-01-2023 12:30:43 INFO Epoch 1: [9186/10940] ---- BYOL Training Loss = 0.2853817939758301
30-01-2023 12:31:01 INFO Epoch 1: [9197/10940] ---- BYOL Training Loss = 0.31088709831237793
30-01-2023 12:31:53 INFO Epoch 1: [9197/10940] ---- BYOL Validation Loss = 0.28814706206321716
30-01-2023 12:32:12 INFO Epoch 1: [9208/10940] ---- BYOL Training Loss = 0.2783844769001007
30-01-2023 12:32:30 INFO Epoch 1: [9219/10940] ---- BYOL Training Loss = 0.2534305155277252
30-01-2023 12:32:48 INFO Epoch 1: [9230/10940] ---- BYOL Training Loss = 0.2832027077674866
30-01-2023 12:33:07 INFO Epoch 1: [9241/10940] ---- BYOL Training Loss = 0.28296589851379395
30-01-2023 12:33:59 INFO Epoch 1: [9241/10940] ---- BYOL Validation Loss = 0.2722032964229584
30-01-2023 12:34:17 INFO Epoch 1: [9252/10940] ---- BYOL Training Loss = 0.3020775616168976
30-01-2023 12:34:36 INFO Epoch 1: [9263/10940] ---- BYOL Training Loss = 0.3458439111709595
30-01-2023 12:34:54 INFO Epoch 1: [9274/10940] ---- BYOL Training Loss = 0.3204042613506317
30-01-2023 12:35:13 INFO Epoch 1: [9285/10940] ---- BYOL Training Loss = 0.32470986247062683
30-01-2023 12:36:05 INFO Epoch 1: [9285/10940] ---- BYOL Validation Loss = 0.2972293198108673
30-01-2023 12:36:23 INFO Epoch 1: [9296/10940] ---- BYOL Training Loss = 0.29872602224349976
30-01-2023 12:36:41 INFO Epoch 1: [9307/10940] ---- BYOL Training Loss = 0.2788252830505371
30-01-2023 12:37:00 INFO Epoch 1: [9318/10940] ---- BYOL Training Loss = 0.30319973826408386
30-01-2023 12:37:18 INFO Epoch 1: [9329/10940] ---- BYOL Training Loss = 0.282518208026886
30-01-2023 12:38:11 INFO Epoch 1: [9329/10940] ---- BYOL Validation Loss = 0.27975255250930786
30-01-2023 12:38:29 INFO Epoch 1: [9340/10940] ---- BYOL Training Loss = 0.27586621046066284
30-01-2023 12:38:47 INFO Epoch 1: [9351/10940] ---- BYOL Training Loss = 0.3008999228477478
30-01-2023 12:39:06 INFO Epoch 1: [9362/10940] ---- BYOL Training Loss = 0.3079153299331665
30-01-2023 12:39:24 INFO Epoch 1: [9373/10940] ---- BYOL Training Loss = 0.2930334210395813
30-01-2023 12:40:16 INFO Epoch 1: [9373/10940] ---- BYOL Validation Loss = 0.28369152545928955
30-01-2023 12:40:35 INFO Epoch 1: [9384/10940] ---- BYOL Training Loss = 0.2929720878601074
30-01-2023 12:40:53 INFO Epoch 1: [9395/10940] ---- BYOL Training Loss = 0.29178738594055176
30-01-2023 12:41:12 INFO Epoch 1: [9406/10940] ---- BYOL Training Loss = 0.2954481244087219
30-01-2023 12:41:30 INFO Epoch 1: [9417/10940] ---- BYOL Training Loss = 0.3037378191947937
30-01-2023 12:42:22 INFO Epoch 1: [9417/10940] ---- BYOL Validation Loss = 0.2770031690597534
30-01-2023 12:42:40 INFO Epoch 1: [9428/10940] ---- BYOL Training Loss = 0.32973307371139526
30-01-2023 12:42:59 INFO Epoch 1: [9439/10940] ---- BYOL Training Loss = 0.3248363435268402
30-01-2023 12:43:17 INFO Epoch 1: [9450/10940] ---- BYOL Training Loss = 0.3076525032520294
30-01-2023 12:43:36 INFO Epoch 1: [9461/10940] ---- BYOL Training Loss = 0.3263520896434784
30-01-2023 12:44:29 INFO Epoch 1: [9461/10940] ---- BYOL Validation Loss = 0.2902674674987793
30-01-2023 12:44:47 INFO Epoch 1: [9472/10940] ---- BYOL Training Loss = 0.29114416241645813
30-01-2023 12:45:05 INFO Epoch 1: [9483/10940] ---- BYOL Training Loss = 0.2949744462966919
30-01-2023 12:45:24 INFO Epoch 1: [9494/10940] ---- BYOL Training Loss = 0.31046774983406067
30-01-2023 12:45:42 INFO Epoch 1: [9505/10940] ---- BYOL Training Loss = 0.3184881806373596
30-01-2023 12:46:34 INFO Epoch 1: [9505/10940] ---- BYOL Validation Loss = 0.2937038838863373
30-01-2023 12:46:52 INFO Epoch 1: [9516/10940] ---- BYOL Training Loss = 0.2897510230541229
30-01-2023 12:47:11 INFO Epoch 1: [9527/10940] ---- BYOL Training Loss = 0.2586580812931061
30-01-2023 12:47:29 INFO Epoch 1: [9538/10940] ---- BYOL Training Loss = 0.2289121150970459
30-01-2023 12:47:48 INFO Epoch 1: [9549/10940] ---- BYOL Training Loss = 0.24775251746177673
30-01-2023 12:48:40 INFO Epoch 1: [9549/10940] ---- BYOL Validation Loss = 0.29358482360839844
30-01-2023 12:48:58 INFO Epoch 1: [9560/10940] ---- BYOL Training Loss = 0.288727343082428
30-01-2023 12:49:17 INFO Epoch 1: [9571/10940] ---- BYOL Training Loss = 0.3029128611087799
30-01-2023 12:49:35 INFO Epoch 1: [9582/10940] ---- BYOL Training Loss = 0.3096081614494324
30-01-2023 12:49:54 INFO Epoch 1: [9593/10940] ---- BYOL Training Loss = 0.29691043496131897
30-01-2023 12:50:46 INFO Epoch 1: [9593/10940] ---- BYOL Validation Loss = 0.2760189473628998
30-01-2023 12:51:04 INFO Epoch 1: [9604/10940] ---- BYOL Training Loss = 0.29896774888038635
30-01-2023 12:51:23 INFO Epoch 1: [9615/10940] ---- BYOL Training Loss = 0.3069798946380615
30-01-2023 12:51:41 INFO Epoch 1: [9626/10940] ---- BYOL Training Loss = 0.29228952527046204
30-01-2023 12:52:00 INFO Epoch 1: [9637/10940] ---- BYOL Training Loss = 0.2755213677883148
30-01-2023 12:52:52 INFO Epoch 1: [9637/10940] ---- BYOL Validation Loss = 0.3006103038787842
30-01-2023 12:53:10 INFO Epoch 1: [9648/10940] ---- BYOL Training Loss = 0.31564703583717346
30-01-2023 12:53:29 INFO Epoch 1: [9659/10940] ---- BYOL Training Loss = 0.3311816453933716
30-01-2023 12:53:47 INFO Epoch 1: [9670/10940] ---- BYOL Training Loss = 0.3268577754497528
30-01-2023 12:54:06 INFO Epoch 1: [9681/10940] ---- BYOL Training Loss = 0.3286069333553314
30-01-2023 12:54:58 INFO Epoch 1: [9681/10940] ---- BYOL Validation Loss = 0.2969227731227875
30-01-2023 12:55:16 INFO Epoch 1: [9692/10940] ---- BYOL Training Loss = 0.3275521397590637
30-01-2023 12:55:35 INFO Epoch 1: [9703/10940] ---- BYOL Training Loss = 0.3005908727645874
30-01-2023 12:55:53 INFO Epoch 1: [9714/10940] ---- BYOL Training Loss = 0.34235119819641113
30-01-2023 12:56:12 INFO Epoch 1: [9725/10940] ---- BYOL Training Loss = 0.3395264744758606
30-01-2023 12:57:04 INFO Epoch 1: [9725/10940] ---- BYOL Validation Loss = 0.2899485230445862
30-01-2023 12:57:23 INFO Epoch 1: [9736/10940] ---- BYOL Training Loss = 0.3582186698913574
30-01-2023 12:57:41 INFO Epoch 1: [9747/10940] ---- BYOL Training Loss = 0.3270340859889984
30-01-2023 12:57:59 INFO Epoch 1: [9758/10940] ---- BYOL Training Loss = 0.26088693737983704
30-01-2023 12:58:18 INFO Epoch 1: [9769/10940] ---- BYOL Training Loss = 0.2618655860424042
30-01-2023 12:59:10 INFO Epoch 1: [9769/10940] ---- BYOL Validation Loss = 0.2798615097999573
30-01-2023 12:59:28 INFO Epoch 1: [9780/10940] ---- BYOL Training Loss = 0.3294784426689148
30-01-2023 12:59:47 INFO Epoch 1: [9791/10940] ---- BYOL Training Loss = 0.29953983426094055
30-01-2023 13:00:06 INFO Epoch 1: [9802/10940] ---- BYOL Training Loss = 0.3241383731365204
30-01-2023 13:00:24 INFO Epoch 1: [9813/10940] ---- BYOL Training Loss = 0.312019944190979
30-01-2023 13:01:16 INFO Epoch 1: [9813/10940] ---- BYOL Validation Loss = 0.2925303280353546
30-01-2023 13:01:35 INFO Epoch 1: [9824/10940] ---- BYOL Training Loss = 0.30334436893463135
30-01-2023 13:01:53 INFO Epoch 1: [9835/10940] ---- BYOL Training Loss = 0.336984246969223
30-01-2023 13:02:12 INFO Epoch 1: [9846/10940] ---- BYOL Training Loss = 0.325137734413147
30-01-2023 13:02:30 INFO Epoch 1: [9857/10940] ---- BYOL Training Loss = 0.28403204679489136
30-01-2023 13:03:22 INFO Epoch 1: [9857/10940] ---- BYOL Validation Loss = 0.3328722417354584
30-01-2023 13:03:40 INFO Epoch 1: [9868/10940] ---- BYOL Training Loss = 0.31449276208877563
30-01-2023 13:03:59 INFO Epoch 1: [9879/10940] ---- BYOL Training Loss = 0.34490981698036194
30-01-2023 13:04:18 INFO Epoch 1: [9890/10940] ---- BYOL Training Loss = 0.31490662693977356
30-01-2023 13:04:36 INFO Epoch 1: [9901/10940] ---- BYOL Training Loss = 0.3435836434364319
30-01-2023 13:05:29 INFO Epoch 1: [9901/10940] ---- BYOL Validation Loss = 0.3171934485435486
30-01-2023 13:05:47 INFO Epoch 1: [9912/10940] ---- BYOL Training Loss = 0.35314029455184937
30-01-2023 13:06:05 INFO Epoch 1: [9923/10940] ---- BYOL Training Loss = 0.32861006259918213
30-01-2023 13:06:24 INFO Epoch 1: [9934/10940] ---- BYOL Training Loss = 0.30159199237823486
30-01-2023 13:06:42 INFO Epoch 1: [9945/10940] ---- BYOL Training Loss = 0.32504990696907043
30-01-2023 13:07:34 INFO Epoch 1: [9945/10940] ---- BYOL Validation Loss = 0.3454723656177521
30-01-2023 13:07:53 INFO Epoch 1: [9956/10940] ---- BYOL Training Loss = 0.3565305173397064
30-01-2023 13:08:11 INFO Epoch 1: [9967/10940] ---- BYOL Training Loss = 0.37104180455207825
30-01-2023 13:08:29 INFO Epoch 1: [9978/10940] ---- BYOL Training Loss = 0.36575135588645935
30-01-2023 13:08:48 INFO Epoch 1: [9989/10940] ---- BYOL Training Loss = 0.42201370000839233
30-01-2023 13:09:40 INFO Epoch 1: [9989/10940] ---- BYOL Validation Loss = 0.3421516418457031
30-01-2023 13:09:58 INFO Epoch 1: [10000/10940] ---- BYOL Training Loss = 0.4118836522102356
30-01-2023 13:10:17 INFO Epoch 1: [10011/10940] ---- BYOL Training Loss = 0.3533582091331482
30-01-2023 13:10:36 INFO Epoch 1: [10022/10940] ---- BYOL Training Loss = 0.36082664132118225
30-01-2023 13:10:54 INFO Epoch 1: [10033/10940] ---- BYOL Training Loss = 0.3435380756855011
30-01-2023 13:11:47 INFO Epoch 1: [10033/10940] ---- BYOL Validation Loss = 0.3404224216938019
30-01-2023 13:12:05 INFO Epoch 1: [10044/10940] ---- BYOL Training Loss = 0.32424014806747437
30-01-2023 13:12:23 INFO Epoch 1: [10055/10940] ---- BYOL Training Loss = 0.3165724277496338
30-01-2023 13:12:42 INFO Epoch 1: [10066/10940] ---- BYOL Training Loss = 0.3607868254184723
30-01-2023 13:13:00 INFO Epoch 1: [10077/10940] ---- BYOL Training Loss = 0.36845043301582336
30-01-2023 13:13:53 INFO Epoch 1: [10077/10940] ---- BYOL Validation Loss = 0.3360545337200165
30-01-2023 13:14:11 INFO Epoch 1: [10088/10940] ---- BYOL Training Loss = 0.3688715994358063
30-01-2023 13:14:29 INFO Epoch 1: [10099/10940] ---- BYOL Training Loss = 0.4272073209285736
30-01-2023 13:14:48 INFO Epoch 1: [10110/10940] ---- BYOL Training Loss = 0.37669405341148376
30-01-2023 13:15:07 INFO Epoch 1: [10121/10940] ---- BYOL Training Loss = 0.3439629077911377
30-01-2023 13:15:59 INFO Epoch 1: [10121/10940] ---- BYOL Validation Loss = 0.3363019526004791
30-01-2023 13:16:17 INFO Epoch 1: [10132/10940] ---- BYOL Training Loss = 0.386699378490448
30-01-2023 13:16:36 INFO Epoch 1: [10143/10940] ---- BYOL Training Loss = 0.34330254793167114
30-01-2023 13:16:54 INFO Epoch 1: [10154/10940] ---- BYOL Training Loss = 0.2662732005119324
30-01-2023 13:17:13 INFO Epoch 1: [10165/10940] ---- BYOL Training Loss = 0.29985910654067993
30-01-2023 13:18:05 INFO Epoch 1: [10165/10940] ---- BYOL Validation Loss = 0.3153657019138336
30-01-2023 13:18:23 INFO Epoch 1: [10176/10940] ---- BYOL Training Loss = 0.3647621273994446
30-01-2023 13:18:42 INFO Epoch 1: [10187/10940] ---- BYOL Training Loss = 0.28968238830566406
30-01-2023 13:19:01 INFO Epoch 1: [10198/10940] ---- BYOL Training Loss = 0.2899076044559479
30-01-2023 13:19:19 INFO Epoch 1: [10209/10940] ---- BYOL Training Loss = 0.39677485823631287
30-01-2023 13:20:11 INFO Epoch 1: [10209/10940] ---- BYOL Validation Loss = 0.32157352566719055
30-01-2023 13:20:30 INFO Epoch 1: [10220/10940] ---- BYOL Training Loss = 0.38835346698760986
30-01-2023 13:20:48 INFO Epoch 1: [10231/10940] ---- BYOL Training Loss = 0.34580716490745544
30-01-2023 13:21:06 INFO Epoch 1: [10242/10940] ---- BYOL Training Loss = 0.3203562796115875
30-01-2023 13:21:25 INFO Epoch 1: [10253/10940] ---- BYOL Training Loss = 0.3397444188594818
30-01-2023 13:22:18 INFO Epoch 1: [10253/10940] ---- BYOL Validation Loss = 0.30646997690200806
30-01-2023 13:22:36 INFO Epoch 1: [10264/10940] ---- BYOL Training Loss = 0.36028924584388733
30-01-2023 13:22:54 INFO Epoch 1: [10275/10940] ---- BYOL Training Loss = 0.3075966238975525
30-01-2023 13:23:13 INFO Epoch 1: [10286/10940] ---- BYOL Training Loss = 0.34003737568855286
30-01-2023 13:23:31 INFO Epoch 1: [10297/10940] ---- BYOL Training Loss = 0.3513701260089874
30-01-2023 13:24:24 INFO Epoch 1: [10297/10940] ---- BYOL Validation Loss = 0.3188939392566681
30-01-2023 13:24:42 INFO Epoch 1: [10308/10940] ---- BYOL Training Loss = 0.351662278175354
30-01-2023 13:25:00 INFO Epoch 1: [10319/10940] ---- BYOL Training Loss = 0.32450318336486816
30-01-2023 13:25:19 INFO Epoch 1: [10330/10940] ---- BYOL Training Loss = 0.3321438729763031
30-01-2023 13:25:38 INFO Epoch 1: [10341/10940] ---- BYOL Training Loss = 0.31318509578704834
30-01-2023 13:26:30 INFO Epoch 1: [10341/10940] ---- BYOL Validation Loss = 0.31796354055404663
30-01-2023 13:26:48 INFO Epoch 1: [10352/10940] ---- BYOL Training Loss = 0.3150419294834137
30-01-2023 13:27:07 INFO Epoch 1: [10363/10940] ---- BYOL Training Loss = 0.3335801064968109
30-01-2023 13:27:26 INFO Epoch 1: [10374/10940] ---- BYOL Training Loss = 0.311581552028656
30-01-2023 13:27:44 INFO Epoch 1: [10385/10940] ---- BYOL Training Loss = 0.3027750551700592
30-01-2023 13:28:36 INFO Epoch 1: [10385/10940] ---- BYOL Validation Loss = 0.31479978561401367
30-01-2023 13:28:54 INFO Epoch 1: [10396/10940] ---- BYOL Training Loss = 0.3117579221725464
30-01-2023 13:29:13 INFO Epoch 1: [10407/10940] ---- BYOL Training Loss = 0.3513859510421753
30-01-2023 13:29:32 INFO Epoch 1: [10418/10940] ---- BYOL Training Loss = 0.3475643992424011
30-01-2023 13:29:51 INFO Epoch 1: [10429/10940] ---- BYOL Training Loss = 0.3487289547920227
30-01-2023 13:30:43 INFO Epoch 1: [10429/10940] ---- BYOL Validation Loss = 0.3263343274593353
30-01-2023 13:31:01 INFO Epoch 1: [10440/10940] ---- BYOL Training Loss = 0.37006351351737976
30-01-2023 13:31:20 INFO Epoch 1: [10451/10940] ---- BYOL Training Loss = 0.3095548450946808
30-01-2023 13:31:38 INFO Epoch 1: [10462/10940] ---- BYOL Training Loss = 0.3414941728115082
30-01-2023 13:31:57 INFO Epoch 1: [10473/10940] ---- BYOL Training Loss = 0.3618655502796173
30-01-2023 13:32:49 INFO Epoch 1: [10473/10940] ---- BYOL Validation Loss = 0.30661725997924805
30-01-2023 13:33:07 INFO Epoch 1: [10484/10940] ---- BYOL Training Loss = 0.33266934752464294
30-01-2023 13:33:26 INFO Epoch 1: [10495/10940] ---- BYOL Training Loss = 0.322858601808548
30-01-2023 13:33:45 INFO Epoch 1: [10506/10940] ---- BYOL Training Loss = 0.3350897431373596
30-01-2023 13:34:03 INFO Epoch 1: [10517/10940] ---- BYOL Training Loss = 0.281840056180954
30-01-2023 13:34:55 INFO Epoch 1: [10517/10940] ---- BYOL Validation Loss = 0.2915545105934143
30-01-2023 13:35:14 INFO Epoch 1: [10528/10940] ---- BYOL Training Loss = 0.29787981510162354
30-01-2023 13:35:32 INFO Epoch 1: [10539/10940] ---- BYOL Training Loss = 0.3608912527561188
30-01-2023 13:35:52 INFO Epoch 1: [10550/10940] ---- BYOL Training Loss = 0.36820653080940247
30-01-2023 13:36:10 INFO Epoch 1: [10561/10940] ---- BYOL Training Loss = 0.29619699716567993
30-01-2023 13:37:02 INFO Epoch 1: [10561/10940] ---- BYOL Validation Loss = 0.29277557134628296
30-01-2023 13:37:20 INFO Epoch 1: [10572/10940] ---- BYOL Training Loss = 0.32107269763946533
30-01-2023 13:37:39 INFO Epoch 1: [10583/10940] ---- BYOL Training Loss = 0.35287073254585266
30-01-2023 13:37:58 INFO Epoch 1: [10594/10940] ---- BYOL Training Loss = 0.3089959919452667
30-01-2023 13:38:17 INFO Epoch 1: [10605/10940] ---- BYOL Training Loss = 0.2976473867893219
30-01-2023 13:39:09 INFO Epoch 1: [10605/10940] ---- BYOL Validation Loss = 0.3004365563392639
30-01-2023 13:39:27 INFO Epoch 1: [10616/10940] ---- BYOL Training Loss = 0.3108940124511719
30-01-2023 13:39:46 INFO Epoch 1: [10627/10940] ---- BYOL Training Loss = 0.33446910977363586
30-01-2023 13:40:04 INFO Epoch 1: [10638/10940] ---- BYOL Training Loss = 0.35093846917152405
30-01-2023 13:40:23 INFO Epoch 1: [10649/10940] ---- BYOL Training Loss = 0.3241331875324249
30-01-2023 13:41:16 INFO Epoch 1: [10649/10940] ---- BYOL Validation Loss = 0.2857660949230194
30-01-2023 13:41:34 INFO Epoch 1: [10660/10940] ---- BYOL Training Loss = 0.31118640303611755
30-01-2023 13:41:52 INFO Epoch 1: [10671/10940] ---- BYOL Training Loss = 0.3310280740261078
30-01-2023 13:42:11 INFO Epoch 1: [10682/10940] ---- BYOL Training Loss = 0.35488632321357727
30-01-2023 13:42:30 INFO Epoch 1: [10693/10940] ---- BYOL Training Loss = 0.33782291412353516
30-01-2023 13:43:22 INFO Epoch 1: [10693/10940] ---- BYOL Validation Loss = 0.2904823124408722
30-01-2023 13:43:41 INFO Epoch 1: [10704/10940] ---- BYOL Training Loss = 0.33124876022338867
30-01-2023 13:43:59 INFO Epoch 1: [10715/10940] ---- BYOL Training Loss = 0.3125399947166443
30-01-2023 13:44:18 INFO Epoch 1: [10726/10940] ---- BYOL Training Loss = 0.279695600271225
30-01-2023 13:44:37 INFO Epoch 1: [10737/10940] ---- BYOL Training Loss = 0.3147403597831726
30-01-2023 13:45:29 INFO Epoch 1: [10737/10940] ---- BYOL Validation Loss = 0.28826266527175903
30-01-2023 13:45:47 INFO Epoch 1: [10748/10940] ---- BYOL Training Loss = 0.35277557373046875
30-01-2023 13:46:06 INFO Epoch 1: [10759/10940] ---- BYOL Training Loss = 0.29668766260147095
30-01-2023 13:46:24 INFO Epoch 1: [10770/10940] ---- BYOL Training Loss = 0.30637121200561523
30-01-2023 13:46:43 INFO Epoch 1: [10781/10940] ---- BYOL Training Loss = 0.33477509021759033
30-01-2023 13:47:36 INFO Epoch 1: [10781/10940] ---- BYOL Validation Loss = 0.3021414577960968
30-01-2023 13:47:54 INFO Epoch 1: [10792/10940] ---- BYOL Training Loss = 0.3300735354423523
30-01-2023 13:48:13 INFO Epoch 1: [10803/10940] ---- BYOL Training Loss = 0.3102012574672699
30-01-2023 13:48:31 INFO Epoch 1: [10814/10940] ---- BYOL Training Loss = 0.30523043870925903
30-01-2023 13:48:50 INFO Epoch 1: [10825/10940] ---- BYOL Training Loss = 0.28245723247528076
30-01-2023 13:49:42 INFO Epoch 1: [10825/10940] ---- BYOL Validation Loss = 0.29732879996299744
30-01-2023 13:50:01 INFO Epoch 1: [10836/10940] ---- BYOL Training Loss = 0.2740645706653595
30-01-2023 13:50:19 INFO Epoch 1: [10847/10940] ---- BYOL Training Loss = 0.3223203718662262
30-01-2023 13:50:38 INFO Epoch 1: [10858/10940] ---- BYOL Training Loss = 0.34231001138687134
30-01-2023 13:50:57 INFO Epoch 1: [10869/10940] ---- BYOL Training Loss = 0.3228257894515991
30-01-2023 13:51:49 INFO Epoch 1: [10869/10940] ---- BYOL Validation Loss = 0.30342668294906616
30-01-2023 13:52:07 INFO Epoch 1: [10880/10940] ---- BYOL Training Loss = 0.3461403548717499
30-01-2023 13:52:26 INFO Epoch 1: [10891/10940] ---- BYOL Training Loss = 0.30113309621810913
30-01-2023 13:52:45 INFO Epoch 1: [10902/10940] ---- BYOL Training Loss = 0.3080083429813385
30-01-2023 13:53:03 INFO Epoch 1: [10913/10940] ---- BYOL Training Loss = 0.34822991490364075
30-01-2023 13:53:56 INFO Epoch 1: [10913/10940] ---- BYOL Validation Loss = 0.3174518644809723
30-01-2023 13:54:14 INFO Epoch 1: [10924/10940] ---- BYOL Training Loss = 0.3395613431930542
30-01-2023 13:54:33 INFO Epoch 1: [10935/10940] ---- BYOL Training Loss = 0.3354858160018921
30-01-2023 13:54:42 INFO Starting Epoch: 2
30-01-2023 13:55:00 INFO Epoch 2: [12/10940] ---- BYOL Training Loss = 0.2732486128807068
30-01-2023 13:55:18 INFO Epoch 2: [23/10940] ---- BYOL Training Loss = 0.3087420165538788
30-01-2023 13:55:35 INFO Epoch 2: [34/10940] ---- BYOL Training Loss = 0.3119050860404968
30-01-2023 13:55:53 INFO Epoch 2: [45/10940] ---- BYOL Training Loss = 0.28661325573921204
30-01-2023 13:56:45 INFO Epoch 2: [45/10940] ---- BYOL Validation Loss = 0.28991422057151794
30-01-2023 13:57:02 INFO Epoch 2: [56/10940] ---- BYOL Training Loss = 0.3233487606048584
30-01-2023 13:57:20 INFO Epoch 2: [67/10940] ---- BYOL Training Loss = 0.3117402195930481
30-01-2023 13:57:38 INFO Epoch 2: [78/10940] ---- BYOL Training Loss = 0.3401380181312561
30-01-2023 13:57:55 INFO Epoch 2: [89/10940] ---- BYOL Training Loss = 0.35756370425224304
30-01-2023 13:58:47 INFO Epoch 2: [89/10940] ---- BYOL Validation Loss = 0.29967719316482544
30-01-2023 13:59:04 INFO Epoch 2: [100/10940] ---- BYOL Training Loss = 0.29817867279052734
30-01-2023 13:59:22 INFO Epoch 2: [111/10940] ---- BYOL Training Loss = 0.3356502950191498
30-01-2023 13:59:40 INFO Epoch 2: [122/10940] ---- BYOL Training Loss = 0.310712993144989
30-01-2023 13:59:57 INFO Epoch 2: [133/10940] ---- BYOL Training Loss = 0.29872316122055054
30-01-2023 14:00:50 INFO Epoch 2: [133/10940] ---- BYOL Validation Loss = 0.30252769589424133
30-01-2023 14:01:07 INFO Epoch 2: [144/10940] ---- BYOL Training Loss = 0.2902221977710724
30-01-2023 14:01:24 INFO Epoch 2: [155/10940] ---- BYOL Training Loss = 0.26467233896255493
30-01-2023 14:01:42 INFO Epoch 2: [166/10940] ---- BYOL Training Loss = 0.2573893666267395
30-01-2023 14:01:59 INFO Epoch 2: [177/10940] ---- BYOL Training Loss = 0.2701602578163147
30-01-2023 14:02:52 INFO Epoch 2: [177/10940] ---- BYOL Validation Loss = 0.2829362750053406
30-01-2023 14:03:09 INFO Epoch 2: [188/10940] ---- BYOL Training Loss = 0.29846060276031494
30-01-2023 14:03:27 INFO Epoch 2: [199/10940] ---- BYOL Training Loss = 0.2827131152153015
30-01-2023 14:03:44 INFO Epoch 2: [210/10940] ---- BYOL Training Loss = 0.30373722314834595
30-01-2023 14:04:02 INFO Epoch 2: [221/10940] ---- BYOL Training Loss = 0.33848726749420166
30-01-2023 14:04:54 INFO Epoch 2: [221/10940] ---- BYOL Validation Loss = 0.2874128520488739
30-01-2023 14:05:11 INFO Epoch 2: [232/10940] ---- BYOL Training Loss = 0.30610644817352295
30-01-2023 14:05:29 INFO Epoch 2: [243/10940] ---- BYOL Training Loss = 0.27311375737190247
30-01-2023 14:05:46 INFO Epoch 2: [254/10940] ---- BYOL Training Loss = 0.2937776744365692
30-01-2023 14:06:04 INFO Epoch 2: [265/10940] ---- BYOL Training Loss = 0.29652613401412964
30-01-2023 14:06:56 INFO Epoch 2: [265/10940] ---- BYOL Validation Loss = 0.29947811365127563
30-01-2023 14:07:13 INFO Epoch 2: [276/10940] ---- BYOL Training Loss = 0.32866328954696655
30-01-2023 14:07:31 INFO Epoch 2: [287/10940] ---- BYOL Training Loss = 0.29838234186172485
30-01-2023 14:07:48 INFO Epoch 2: [298/10940] ---- BYOL Training Loss = 0.31792977452278137
30-01-2023 14:08:06 INFO Epoch 2: [309/10940] ---- BYOL Training Loss = 0.3085399270057678
30-01-2023 14:08:58 INFO Epoch 2: [309/10940] ---- BYOL Validation Loss = 0.28623756766319275
30-01-2023 14:09:16 INFO Epoch 2: [320/10940] ---- BYOL Training Loss = 0.303398996591568
30-01-2023 14:09:33 INFO Epoch 2: [331/10940] ---- BYOL Training Loss = 0.3152574300765991
30-01-2023 14:09:51 INFO Epoch 2: [342/10940] ---- BYOL Training Loss = 0.31916171312332153
30-01-2023 14:10:08 INFO Epoch 2: [353/10940] ---- BYOL Training Loss = 0.347785621881485
30-01-2023 14:11:01 INFO Epoch 2: [353/10940] ---- BYOL Validation Loss = 0.29244107007980347
30-01-2023 14:11:18 INFO Epoch 2: [364/10940] ---- BYOL Training Loss = 0.3734920918941498
30-01-2023 14:11:35 INFO Epoch 2: [375/10940] ---- BYOL Training Loss = 0.2861858308315277
30-01-2023 14:11:53 INFO Epoch 2: [386/10940] ---- BYOL Training Loss = 0.2864733040332794
30-01-2023 14:12:11 INFO Epoch 2: [397/10940] ---- BYOL Training Loss = 0.2949560582637787
30-01-2023 14:13:03 INFO Epoch 2: [397/10940] ---- BYOL Validation Loss = 0.2736976444721222
30-01-2023 14:13:20 INFO Epoch 2: [408/10940] ---- BYOL Training Loss = 0.32608991861343384
30-01-2023 14:13:38 INFO Epoch 2: [419/10940] ---- BYOL Training Loss = 0.3405294418334961
30-01-2023 14:13:55 INFO Epoch 2: [430/10940] ---- BYOL Training Loss = 0.3222582936286926
30-01-2023 14:14:13 INFO Epoch 2: [441/10940] ---- BYOL Training Loss = 0.2922261953353882
30-01-2023 14:15:05 INFO Epoch 2: [441/10940] ---- BYOL Validation Loss = 0.28932347893714905
30-01-2023 14:15:22 INFO Epoch 2: [452/10940] ---- BYOL Training Loss = 0.2844800055027008
30-01-2023 14:15:40 INFO Epoch 2: [463/10940] ---- BYOL Training Loss = 0.29321274161338806
30-01-2023 14:15:57 INFO Epoch 2: [474/10940] ---- BYOL Training Loss = 0.29741746187210083
30-01-2023 14:16:15 INFO Epoch 2: [485/10940] ---- BYOL Training Loss = 0.32075637578964233
30-01-2023 14:17:07 INFO Epoch 2: [485/10940] ---- BYOL Validation Loss = 0.28060320019721985
30-01-2023 14:17:24 INFO Epoch 2: [496/10940] ---- BYOL Training Loss = 0.32531973719596863
30-01-2023 14:17:42 INFO Epoch 2: [507/10940] ---- BYOL Training Loss = 0.3017805814743042
30-01-2023 14:17:59 INFO Epoch 2: [518/10940] ---- BYOL Training Loss = 0.28244298696517944
30-01-2023 14:18:17 INFO Epoch 2: [529/10940] ---- BYOL Training Loss = 0.275260865688324
30-01-2023 14:19:09 INFO Epoch 2: [529/10940] ---- BYOL Validation Loss = 0.2913810610771179
30-01-2023 14:19:26 INFO Epoch 2: [540/10940] ---- BYOL Training Loss = 0.27910712361335754
30-01-2023 14:19:44 INFO Epoch 2: [551/10940] ---- BYOL Training Loss = 0.2818644642829895
30-01-2023 14:20:02 INFO Epoch 2: [562/10940] ---- BYOL Training Loss = 0.308981716632843
30-01-2023 14:20:19 INFO Epoch 2: [573/10940] ---- BYOL Training Loss = 0.3055547773838043
30-01-2023 14:21:12 INFO Epoch 2: [573/10940] ---- BYOL Validation Loss = 0.3029254078865051
30-01-2023 14:21:29 INFO Epoch 2: [584/10940] ---- BYOL Training Loss = 0.33629947900772095
30-01-2023 14:21:46 INFO Epoch 2: [595/10940] ---- BYOL Training Loss = 0.31586164236068726
30-01-2023 14:22:04 INFO Epoch 2: [606/10940] ---- BYOL Training Loss = 0.3298993706703186
30-01-2023 14:22:21 INFO Epoch 2: [617/10940] ---- BYOL Training Loss = 0.33973386883735657
30-01-2023 14:23:14 INFO Epoch 2: [617/10940] ---- BYOL Validation Loss = 0.31201428174972534
30-01-2023 14:23:31 INFO Epoch 2: [628/10940] ---- BYOL Training Loss = 0.28717273473739624
30-01-2023 14:23:48 INFO Epoch 2: [639/10940] ---- BYOL Training Loss = 0.31173330545425415
30-01-2023 14:24:06 INFO Epoch 2: [650/10940] ---- BYOL Training Loss = 0.37062349915504456
30-01-2023 14:24:24 INFO Epoch 2: [661/10940] ---- BYOL Training Loss = 0.3546321392059326
30-01-2023 14:25:16 INFO Epoch 2: [661/10940] ---- BYOL Validation Loss = 0.31475523114204407
30-01-2023 14:25:33 INFO Epoch 2: [672/10940] ---- BYOL Training Loss = 0.31256791949272156
30-01-2023 14:25:51 INFO Epoch 2: [683/10940] ---- BYOL Training Loss = 0.28658589720726013
30-01-2023 14:26:08 INFO Epoch 2: [694/10940] ---- BYOL Training Loss = 0.29493072628974915
30-01-2023 14:26:26 INFO Epoch 2: [705/10940] ---- BYOL Training Loss = 0.3634476065635681
30-01-2023 14:27:18 INFO Epoch 2: [705/10940] ---- BYOL Validation Loss = 0.325703889131546
30-01-2023 14:27:35 INFO Epoch 2: [716/10940] ---- BYOL Training Loss = 0.35273775458335876
30-01-2023 14:27:53 INFO Epoch 2: [727/10940] ---- BYOL Training Loss = 0.3259658217430115
30-01-2023 14:28:11 INFO Epoch 2: [738/10940] ---- BYOL Training Loss = 0.30667394399642944
30-01-2023 14:28:28 INFO Epoch 2: [749/10940] ---- BYOL Training Loss = 0.3035394251346588
30-01-2023 14:29:20 INFO Epoch 2: [749/10940] ---- BYOL Validation Loss = 0.3300953805446625
30-01-2023 14:29:38 INFO Epoch 2: [760/10940] ---- BYOL Training Loss = 0.32278719544410706
30-01-2023 14:29:55 INFO Epoch 2: [771/10940] ---- BYOL Training Loss = 0.3324955105781555
30-01-2023 14:30:13 INFO Epoch 2: [782/10940] ---- BYOL Training Loss = 0.30017703771591187
30-01-2023 14:30:31 INFO Epoch 2: [793/10940] ---- BYOL Training Loss = 0.329179972410202
30-01-2023 14:31:23 INFO Epoch 2: [793/10940] ---- BYOL Validation Loss = 0.33173227310180664
30-01-2023 14:31:40 INFO Epoch 2: [804/10940] ---- BYOL Training Loss = 0.355659544467926
30-01-2023 14:31:58 INFO Epoch 2: [815/10940] ---- BYOL Training Loss = 0.39398717880249023
30-01-2023 14:32:15 INFO Epoch 2: [826/10940] ---- BYOL Training Loss = 0.3223619759082794
30-01-2023 14:32:33 INFO Epoch 2: [837/10940] ---- BYOL Training Loss = 0.3073934316635132
30-01-2023 14:33:25 INFO Epoch 2: [837/10940] ---- BYOL Validation Loss = 0.3107225298881531
30-01-2023 14:33:42 INFO Epoch 2: [848/10940] ---- BYOL Training Loss = 0.3061879277229309
30-01-2023 14:34:00 INFO Epoch 2: [859/10940] ---- BYOL Training Loss = 0.27045464515686035
30-01-2023 14:34:17 INFO Epoch 2: [870/10940] ---- BYOL Training Loss = 0.3127184808254242
30-01-2023 14:34:35 INFO Epoch 2: [881/10940] ---- BYOL Training Loss = 0.34490686655044556
30-01-2023 14:35:27 INFO Epoch 2: [881/10940] ---- BYOL Validation Loss = 0.3125933110713959
30-01-2023 14:35:45 INFO Epoch 2: [892/10940] ---- BYOL Training Loss = 0.33757781982421875
30-01-2023 14:36:02 INFO Epoch 2: [903/10940] ---- BYOL Training Loss = 0.3204066753387451
30-01-2023 14:36:20 INFO Epoch 2: [914/10940] ---- BYOL Training Loss = 0.3347730338573456
30-01-2023 14:36:37 INFO Epoch 2: [925/10940] ---- BYOL Training Loss = 0.36489981412887573
30-01-2023 14:37:30 INFO Epoch 2: [925/10940] ---- BYOL Validation Loss = 0.3155967593193054
30-01-2023 14:37:47 INFO Epoch 2: [936/10940] ---- BYOL Training Loss = 0.35168975591659546
30-01-2023 14:38:05 INFO Epoch 2: [947/10940] ---- BYOL Training Loss = 0.2969686985015869
30-01-2023 14:38:22 INFO Epoch 2: [958/10940] ---- BYOL Training Loss = 0.32437974214553833
30-01-2023 14:38:40 INFO Epoch 2: [969/10940] ---- BYOL Training Loss = 0.37371888756752014
30-01-2023 14:39:32 INFO Epoch 2: [969/10940] ---- BYOL Validation Loss = 0.3202210068702698
30-01-2023 14:39:49 INFO Epoch 2: [980/10940] ---- BYOL Training Loss = 0.3221834897994995
30-01-2023 14:40:07 INFO Epoch 2: [991/10940] ---- BYOL Training Loss = 0.3478618562221527
30-01-2023 14:40:24 INFO Epoch 2: [1002/10940] ---- BYOL Training Loss = 0.37341246008872986
30-01-2023 14:40:42 INFO Epoch 2: [1013/10940] ---- BYOL Training Loss = 0.36516278982162476
30-01-2023 14:41:34 INFO Epoch 2: [1013/10940] ---- BYOL Validation Loss = 0.31655794382095337
30-01-2023 14:41:51 INFO Epoch 2: [1024/10940] ---- BYOL Training Loss = 0.41088205575942993
30-01-2023 14:42:09 INFO Epoch 2: [1035/10940] ---- BYOL Training Loss = 0.3491935431957245
30-01-2023 14:42:27 INFO Epoch 2: [1046/10940] ---- BYOL Training Loss = 0.2956782281398773
30-01-2023 14:42:44 INFO Epoch 2: [1057/10940] ---- BYOL Training Loss = 0.32636624574661255
30-01-2023 14:43:36 INFO Epoch 2: [1057/10940] ---- BYOL Validation Loss = 0.302142858505249
30-01-2023 14:43:54 INFO Epoch 2: [1068/10940] ---- BYOL Training Loss = 0.35288435220718384
30-01-2023 14:44:11 INFO Epoch 2: [1079/10940] ---- BYOL Training Loss = 0.31155261397361755
30-01-2023 14:44:29 INFO Epoch 2: [1090/10940] ---- BYOL Training Loss = 0.28388649225234985
30-01-2023 14:44:47 INFO Epoch 2: [1101/10940] ---- BYOL Training Loss = 0.30172979831695557
30-01-2023 14:45:39 INFO Epoch 2: [1101/10940] ---- BYOL Validation Loss = 0.2958374321460724
30-01-2023 14:45:56 INFO Epoch 2: [1112/10940] ---- BYOL Training Loss = 0.27676233649253845
30-01-2023 14:46:14 INFO Epoch 2: [1123/10940] ---- BYOL Training Loss = 0.2773206830024719
30-01-2023 14:46:31 INFO Epoch 2: [1134/10940] ---- BYOL Training Loss = 0.3256094455718994
30-01-2023 14:46:49 INFO Epoch 2: [1145/10940] ---- BYOL Training Loss = 0.3069177269935608
30-01-2023 14:47:41 INFO Epoch 2: [1145/10940] ---- BYOL Validation Loss = 0.30295705795288086
30-01-2023 14:47:58 INFO Epoch 2: [1156/10940] ---- BYOL Training Loss = 0.2975887060165405
30-01-2023 14:48:16 INFO Epoch 2: [1167/10940] ---- BYOL Training Loss = 0.30444902181625366
30-01-2023 14:48:34 INFO Epoch 2: [1178/10940] ---- BYOL Training Loss = 0.3262614607810974
30-01-2023 14:48:51 INFO Epoch 2: [1189/10940] ---- BYOL Training Loss = 0.31602105498313904
30-01-2023 14:49:44 INFO Epoch 2: [1189/10940] ---- BYOL Validation Loss = 0.28226903080940247
30-01-2023 14:50:01 INFO Epoch 2: [1200/10940] ---- BYOL Training Loss = 0.2900475263595581
30-01-2023 14:50:19 INFO Epoch 2: [1211/10940] ---- BYOL Training Loss = 0.30994129180908203
30-01-2023 14:50:36 INFO Epoch 2: [1222/10940] ---- BYOL Training Loss = 0.35778024792671204
30-01-2023 14:50:54 INFO Epoch 2: [1233/10940] ---- BYOL Training Loss = 0.33255696296691895
30-01-2023 14:51:46 INFO Epoch 2: [1233/10940] ---- BYOL Validation Loss = 0.2993222773075104
30-01-2023 14:52:03 INFO Epoch 2: [1244/10940] ---- BYOL Training Loss = 0.3342632055282593
30-01-2023 14:52:21 INFO Epoch 2: [1255/10940] ---- BYOL Training Loss = 0.336603581905365
30-01-2023 14:52:39 INFO Epoch 2: [1266/10940] ---- BYOL Training Loss = 0.3074062466621399
30-01-2023 14:52:56 INFO Epoch 2: [1277/10940] ---- BYOL Training Loss = 0.27746856212615967
30-01-2023 14:53:49 INFO Epoch 2: [1277/10940] ---- BYOL Validation Loss = 0.3064053952693939
30-01-2023 14:54:06 INFO Epoch 2: [1288/10940] ---- BYOL Training Loss = 0.26957520842552185
30-01-2023 14:54:24 INFO Epoch 2: [1299/10940] ---- BYOL Training Loss = 0.326642781496048
30-01-2023 14:54:41 INFO Epoch 2: [1310/10940] ---- BYOL Training Loss = 0.3372613489627838
30-01-2023 14:54:59 INFO Epoch 2: [1321/10940] ---- BYOL Training Loss = 0.329307496547699
30-01-2023 14:55:51 INFO Epoch 2: [1321/10940] ---- BYOL Validation Loss = 0.3066866099834442
30-01-2023 14:56:08 INFO Epoch 2: [1332/10940] ---- BYOL Training Loss = 0.32767099142074585
30-01-2023 14:56:26 INFO Epoch 2: [1343/10940] ---- BYOL Training Loss = 0.32155245542526245
30-01-2023 14:56:44 INFO Epoch 2: [1354/10940] ---- BYOL Training Loss = 0.3418421149253845
30-01-2023 14:57:01 INFO Epoch 2: [1365/10940] ---- BYOL Training Loss = 0.3489508032798767
30-01-2023 14:57:54 INFO Epoch 2: [1365/10940] ---- BYOL Validation Loss = 0.3142079710960388
30-01-2023 14:58:11 INFO Epoch 2: [1376/10940] ---- BYOL Training Loss = 0.3344801068305969
30-01-2023 14:58:28 INFO Epoch 2: [1387/10940] ---- BYOL Training Loss = 0.3277992308139801
30-01-2023 14:58:46 INFO Epoch 2: [1398/10940] ---- BYOL Training Loss = 0.2874804139137268
30-01-2023 14:59:04 INFO Epoch 2: [1409/10940] ---- BYOL Training Loss = 0.2870403528213501
30-01-2023 14:59:56 INFO Epoch 2: [1409/10940] ---- BYOL Validation Loss = 0.31491443514823914
30-01-2023 15:00:13 INFO Epoch 2: [1420/10940] ---- BYOL Training Loss = 0.3238905072212219
30-01-2023 15:00:31 INFO Epoch 2: [1431/10940] ---- BYOL Training Loss = 0.374121755361557
30-01-2023 15:00:49 INFO Epoch 2: [1442/10940] ---- BYOL Training Loss = 0.3491549789905548
30-01-2023 15:01:06 INFO Epoch 2: [1453/10940] ---- BYOL Training Loss = 0.2923279404640198
30-01-2023 15:01:58 INFO Epoch 2: [1453/10940] ---- BYOL Validation Loss = 0.28798821568489075
30-01-2023 15:02:16 INFO Epoch 2: [1464/10940] ---- BYOL Training Loss = 0.2547816336154938
30-01-2023 15:02:33 INFO Epoch 2: [1475/10940] ---- BYOL Training Loss = 0.29802605509757996
30-01-2023 15:02:51 INFO Epoch 2: [1486/10940] ---- BYOL Training Loss = 0.3085296154022217
30-01-2023 15:03:09 INFO Epoch 2: [1497/10940] ---- BYOL Training Loss = 0.28842300176620483
30-01-2023 15:04:01 INFO Epoch 2: [1497/10940] ---- BYOL Validation Loss = 0.29180654883384705
30-01-2023 15:04:18 INFO Epoch 2: [1508/10940] ---- BYOL Training Loss = 0.2776552140712738
30-01-2023 15:04:36 INFO Epoch 2: [1519/10940] ---- BYOL Training Loss = 0.28022801876068115
30-01-2023 15:04:54 INFO Epoch 2: [1530/10940] ---- BYOL Training Loss = 0.30552971363067627
30-01-2023 15:05:11 INFO Epoch 2: [1541/10940] ---- BYOL Training Loss = 0.33033785223960876
30-01-2023 15:06:03 INFO Epoch 2: [1541/10940] ---- BYOL Validation Loss = 0.29421156644821167
30-01-2023 15:06:21 INFO Epoch 2: [1552/10940] ---- BYOL Training Loss = 0.30839526653289795
30-01-2023 15:06:38 INFO Epoch 2: [1563/10940] ---- BYOL Training Loss = 0.23923459649085999
30-01-2023 15:06:56 INFO Epoch 2: [1574/10940] ---- BYOL Training Loss = 0.25880223512649536
30-01-2023 15:07:14 INFO Epoch 2: [1585/10940] ---- BYOL Training Loss = 0.2794521152973175
30-01-2023 15:08:06 INFO Epoch 2: [1585/10940] ---- BYOL Validation Loss = 0.2850288152694702
30-01-2023 15:08:23 INFO Epoch 2: [1596/10940] ---- BYOL Training Loss = 0.28357547521591187
30-01-2023 15:08:41 INFO Epoch 2: [1607/10940] ---- BYOL Training Loss = 0.3295588791370392
30-01-2023 15:08:59 INFO Epoch 2: [1618/10940] ---- BYOL Training Loss = 0.29599279165267944
30-01-2023 15:09:16 INFO Epoch 2: [1629/10940] ---- BYOL Training Loss = 0.2575490474700928
30-01-2023 15:10:09 INFO Epoch 2: [1629/10940] ---- BYOL Validation Loss = 0.2812710702419281
30-01-2023 15:10:26 INFO Epoch 2: [1640/10940] ---- BYOL Training Loss = 0.2498292177915573
30-01-2023 15:10:43 INFO Epoch 2: [1651/10940] ---- BYOL Training Loss = 0.2804550230503082
30-01-2023 15:11:01 INFO Epoch 2: [1662/10940] ---- BYOL Training Loss = 0.32981130480766296
30-01-2023 15:11:19 INFO Epoch 2: [1673/10940] ---- BYOL Training Loss = 0.3172246813774109
30-01-2023 15:12:11 INFO Epoch 2: [1673/10940] ---- BYOL Validation Loss = 0.2795899510383606
30-01-2023 15:12:28 INFO Epoch 2: [1684/10940] ---- BYOL Training Loss = 0.2803003191947937
30-01-2023 15:12:46 INFO Epoch 2: [1695/10940] ---- BYOL Training Loss = 0.29821857810020447
30-01-2023 15:13:04 INFO Epoch 2: [1706/10940] ---- BYOL Training Loss = 0.34697869420051575
30-01-2023 15:13:21 INFO Epoch 2: [1717/10940] ---- BYOL Training Loss = 0.32160791754722595
30-01-2023 15:14:13 INFO Epoch 2: [1717/10940] ---- BYOL Validation Loss = 0.277902215719223
30-01-2023 15:14:31 INFO Epoch 2: [1728/10940] ---- BYOL Training Loss = 0.27438968420028687
30-01-2023 15:14:49 INFO Epoch 2: [1739/10940] ---- BYOL Training Loss = 0.27719607949256897
30-01-2023 15:15:06 INFO Epoch 2: [1750/10940] ---- BYOL Training Loss = 0.2847437262535095
30-01-2023 15:15:24 INFO Epoch 2: [1761/10940] ---- BYOL Training Loss = 0.2751162648200989
30-01-2023 15:16:16 INFO Epoch 2: [1761/10940] ---- BYOL Validation Loss = 0.27902477979660034
30-01-2023 15:16:34 INFO Epoch 2: [1772/10940] ---- BYOL Training Loss = 0.3005771040916443
30-01-2023 15:16:51 INFO Epoch 2: [1783/10940] ---- BYOL Training Loss = 0.3152231276035309
30-01-2023 15:17:09 INFO Epoch 2: [1794/10940] ---- BYOL Training Loss = 0.28186771273612976
30-01-2023 15:17:27 INFO Epoch 2: [1805/10940] ---- BYOL Training Loss = 0.32231613993644714
30-01-2023 15:18:19 INFO Epoch 2: [1805/10940] ---- BYOL Validation Loss = 0.2816406488418579
30-01-2023 15:18:36 INFO Epoch 2: [1816/10940] ---- BYOL Training Loss = 0.3702874183654785
30-01-2023 15:18:54 INFO Epoch 2: [1827/10940] ---- BYOL Training Loss = 0.293720006942749
30-01-2023 15:19:12 INFO Epoch 2: [1838/10940] ---- BYOL Training Loss = 0.28005191683769226
30-01-2023 15:19:29 INFO Epoch 2: [1849/10940] ---- BYOL Training Loss = 0.2996697425842285
30-01-2023 15:20:21 INFO Epoch 2: [1849/10940] ---- BYOL Validation Loss = 0.28586938977241516
30-01-2023 15:20:39 INFO Epoch 2: [1860/10940] ---- BYOL Training Loss = 0.31925007700920105
30-01-2023 15:20:56 INFO Epoch 2: [1871/10940] ---- BYOL Training Loss = 0.29138511419296265
30-01-2023 15:21:14 INFO Epoch 2: [1882/10940] ---- BYOL Training Loss = 0.26251205801963806
30-01-2023 15:21:32 INFO Epoch 2: [1893/10940] ---- BYOL Training Loss = 0.2883691191673279
30-01-2023 15:22:24 INFO Epoch 2: [1893/10940] ---- BYOL Validation Loss = 0.2946526110172272
30-01-2023 15:22:41 INFO Epoch 2: [1904/10940] ---- BYOL Training Loss = 0.3004447817802429
30-01-2023 15:22:59 INFO Epoch 2: [1915/10940] ---- BYOL Training Loss = 0.35519492626190186
30-01-2023 15:23:16 INFO Epoch 2: [1926/10940] ---- BYOL Training Loss = 0.3720429539680481
30-01-2023 15:23:34 INFO Epoch 2: [1937/10940] ---- BYOL Training Loss = 0.3555307984352112
30-01-2023 15:24:26 INFO Epoch 2: [1937/10940] ---- BYOL Validation Loss = 0.3027081787586212
30-01-2023 15:24:44 INFO Epoch 2: [1948/10940] ---- BYOL Training Loss = 0.39284032583236694
30-01-2023 15:25:02 INFO Epoch 2: [1959/10940] ---- BYOL Training Loss = 0.3612712025642395
30-01-2023 15:25:19 INFO Epoch 2: [1970/10940] ---- BYOL Training Loss = 0.34257957339286804
30-01-2023 15:25:37 INFO Epoch 2: [1981/10940] ---- BYOL Training Loss = 0.34316110610961914
30-01-2023 15:26:29 INFO Epoch 2: [1981/10940] ---- BYOL Validation Loss = 0.3107280731201172
30-01-2023 15:26:47 INFO Epoch 2: [1992/10940] ---- BYOL Training Loss = 0.32887157797813416
30-01-2023 15:27:04 INFO Epoch 2: [2003/10940] ---- BYOL Training Loss = 0.3451562225818634
30-01-2023 15:27:22 INFO Epoch 2: [2014/10940] ---- BYOL Training Loss = 0.34610500931739807
30-01-2023 15:27:40 INFO Epoch 2: [2025/10940] ---- BYOL Training Loss = 0.3607453405857086
30-01-2023 15:28:32 INFO Epoch 2: [2025/10940] ---- BYOL Validation Loss = 0.296100914478302
30-01-2023 15:28:49 INFO Epoch 2: [2036/10940] ---- BYOL Training Loss = 0.33039024472236633
30-01-2023 15:29:07 INFO Epoch 2: [2047/10940] ---- BYOL Training Loss = 0.34250515699386597
30-01-2023 15:29:25 INFO Epoch 2: [2058/10940] ---- BYOL Training Loss = 0.3345533013343811
30-01-2023 15:29:42 INFO Epoch 2: [2069/10940] ---- BYOL Training Loss = 0.32776036858558655
30-01-2023 15:30:34 INFO Epoch 2: [2069/10940] ---- BYOL Validation Loss = 0.30047374963760376
30-01-2023 15:30:52 INFO Epoch 2: [2080/10940] ---- BYOL Training Loss = 0.31308987736701965
30-01-2023 15:31:09 INFO Epoch 2: [2091/10940] ---- BYOL Training Loss = 0.2664017379283905
30-01-2023 15:31:28 INFO Epoch 2: [2102/10940] ---- BYOL Training Loss = 0.2864322066307068
30-01-2023 15:31:45 INFO Epoch 2: [2113/10940] ---- BYOL Training Loss = 0.27814024686813354
30-01-2023 15:32:38 INFO Epoch 2: [2113/10940] ---- BYOL Validation Loss = 0.29187577962875366
30-01-2023 15:32:55 INFO Epoch 2: [2124/10940] ---- BYOL Training Loss = 0.32091665267944336
30-01-2023 15:33:13 INFO Epoch 2: [2135/10940] ---- BYOL Training Loss = 0.32174715399742126
30-01-2023 15:33:30 INFO Epoch 2: [2146/10940] ---- BYOL Training Loss = 0.2861075699329376
30-01-2023 15:33:48 INFO Epoch 2: [2157/10940] ---- BYOL Training Loss = 0.31264951825141907
30-01-2023 15:34:40 INFO Epoch 2: [2157/10940] ---- BYOL Validation Loss = 0.3023180067539215
30-01-2023 15:34:58 INFO Epoch 2: [2168/10940] ---- BYOL Training Loss = 0.3175111413002014
30-01-2023 15:35:15 INFO Epoch 2: [2179/10940] ---- BYOL Training Loss = 0.31409752368927
30-01-2023 15:35:33 INFO Epoch 2: [2190/10940] ---- BYOL Training Loss = 0.3234003186225891
30-01-2023 15:35:51 INFO Epoch 2: [2201/10940] ---- BYOL Training Loss = 0.31874004006385803
30-01-2023 15:36:43 INFO Epoch 2: [2201/10940] ---- BYOL Validation Loss = 0.30201536417007446
30-01-2023 15:37:00 INFO Epoch 2: [2212/10940] ---- BYOL Training Loss = 0.26507869362831116
30-01-2023 15:37:18 INFO Epoch 2: [2223/10940] ---- BYOL Training Loss = 0.2514618933200836
30-01-2023 15:37:36 INFO Epoch 2: [2234/10940] ---- BYOL Training Loss = 0.30521851778030396
30-01-2023 15:37:53 INFO Epoch 2: [2245/10940] ---- BYOL Training Loss = 0.27216997742652893
30-01-2023 15:38:46 INFO Epoch 2: [2245/10940] ---- BYOL Validation Loss = 0.2904219329357147
30-01-2023 15:39:03 INFO Epoch 2: [2256/10940] ---- BYOL Training Loss = 0.3092436194419861
30-01-2023 15:39:21 INFO Epoch 2: [2267/10940] ---- BYOL Training Loss = 0.31516534090042114
30-01-2023 15:39:39 INFO Epoch 2: [2278/10940] ---- BYOL Training Loss = 0.3018626570701599
30-01-2023 15:39:56 INFO Epoch 2: [2289/10940] ---- BYOL Training Loss = 0.3164152204990387
30-01-2023 15:40:48 INFO Epoch 2: [2289/10940] ---- BYOL Validation Loss = 0.3036438524723053
30-01-2023 15:41:06 INFO Epoch 2: [2300/10940] ---- BYOL Training Loss = 0.29914164543151855
30-01-2023 15:41:24 INFO Epoch 2: [2311/10940] ---- BYOL Training Loss = 0.3198254406452179
30-01-2023 15:41:41 INFO Epoch 2: [2322/10940] ---- BYOL Training Loss = 0.2998729348182678
30-01-2023 15:41:59 INFO Epoch 2: [2333/10940] ---- BYOL Training Loss = 0.2925425171852112
30-01-2023 15:42:51 INFO Epoch 2: [2333/10940] ---- BYOL Validation Loss = 0.29948821663856506
30-01-2023 15:43:09 INFO Epoch 2: [2344/10940] ---- BYOL Training Loss = 0.28513485193252563
30-01-2023 15:43:26 INFO Epoch 2: [2355/10940] ---- BYOL Training Loss = 0.27555254101753235
30-01-2023 15:43:44 INFO Epoch 2: [2366/10940] ---- BYOL Training Loss = 0.28798481822013855
30-01-2023 15:44:02 INFO Epoch 2: [2377/10940] ---- BYOL Training Loss = 0.30556970834732056
30-01-2023 15:44:54 INFO Epoch 2: [2377/10940] ---- BYOL Validation Loss = 0.2760649621486664
30-01-2023 15:45:12 INFO Epoch 2: [2388/10940] ---- BYOL Training Loss = 0.32944726943969727
30-01-2023 15:45:29 INFO Epoch 2: [2399/10940] ---- BYOL Training Loss = 0.35671573877334595
30-01-2023 15:45:47 INFO Epoch 2: [2410/10940] ---- BYOL Training Loss = 0.312533438205719
30-01-2023 15:46:05 INFO Epoch 2: [2421/10940] ---- BYOL Training Loss = 0.27345097064971924
30-01-2023 15:46:57 INFO Epoch 2: [2421/10940] ---- BYOL Validation Loss = 0.28893354535102844
30-01-2023 15:47:14 INFO Epoch 2: [2432/10940] ---- BYOL Training Loss = 0.3050146698951721
30-01-2023 15:47:32 INFO Epoch 2: [2443/10940] ---- BYOL Training Loss = 0.33047446608543396
30-01-2023 15:47:50 INFO Epoch 2: [2454/10940] ---- BYOL Training Loss = 0.2943940758705139
30-01-2023 15:48:07 INFO Epoch 2: [2465/10940] ---- BYOL Training Loss = 0.2913043797016144
30-01-2023 15:49:00 INFO Epoch 2: [2465/10940] ---- BYOL Validation Loss = 0.28279271721839905
30-01-2023 15:49:17 INFO Epoch 2: [2476/10940] ---- BYOL Training Loss = 0.2855151295661926
30-01-2023 15:49:35 INFO Epoch 2: [2487/10940] ---- BYOL Training Loss = 0.3005439043045044
30-01-2023 15:49:53 INFO Epoch 2: [2498/10940] ---- BYOL Training Loss = 0.2684721350669861
30-01-2023 15:50:10 INFO Epoch 2: [2509/10940] ---- BYOL Training Loss = 0.31919625401496887
30-01-2023 15:51:03 INFO Epoch 2: [2509/10940] ---- BYOL Validation Loss = 0.28359490633010864
30-01-2023 15:51:20 INFO Epoch 2: [2520/10940] ---- BYOL Training Loss = 0.35791298747062683
30-01-2023 15:51:38 INFO Epoch 2: [2531/10940] ---- BYOL Training Loss = 0.27103111147880554
30-01-2023 15:51:56 INFO Epoch 2: [2542/10940] ---- BYOL Training Loss = 0.2946062982082367
30-01-2023 15:52:13 INFO Epoch 2: [2553/10940] ---- BYOL Training Loss = 0.2957606911659241
30-01-2023 15:53:06 INFO Epoch 2: [2553/10940] ---- BYOL Validation Loss = 0.27323225140571594
30-01-2023 15:53:23 INFO Epoch 2: [2564/10940] ---- BYOL Training Loss = 0.25179076194763184
30-01-2023 15:53:41 INFO Epoch 2: [2575/10940] ---- BYOL Training Loss = 0.2956852316856384
30-01-2023 15:53:58 INFO Epoch 2: [2586/10940] ---- BYOL Training Loss = 0.3287772238254547
30-01-2023 15:54:16 INFO Epoch 2: [2597/10940] ---- BYOL Training Loss = 0.30292776226997375
30-01-2023 15:55:09 INFO Epoch 2: [2597/10940] ---- BYOL Validation Loss = 0.29037198424339294
30-01-2023 15:55:26 INFO Epoch 2: [2608/10940] ---- BYOL Training Loss = 0.31464099884033203
30-01-2023 15:55:44 INFO Epoch 2: [2619/10940] ---- BYOL Training Loss = 0.32310083508491516
30-01-2023 15:56:02 INFO Epoch 2: [2630/10940] ---- BYOL Training Loss = 0.31334424018859863
30-01-2023 15:56:20 INFO Epoch 2: [2641/10940] ---- BYOL Training Loss = 0.31632715463638306
30-01-2023 15:57:12 INFO Epoch 2: [2641/10940] ---- BYOL Validation Loss = 0.2806595265865326
30-01-2023 15:57:29 INFO Epoch 2: [2652/10940] ---- BYOL Training Loss = 0.2935616374015808
30-01-2023 15:57:47 INFO Epoch 2: [2663/10940] ---- BYOL Training Loss = 0.3096188008785248
30-01-2023 15:58:05 INFO Epoch 2: [2674/10940] ---- BYOL Training Loss = 0.3340102434158325
30-01-2023 15:58:22 INFO Epoch 2: [2685/10940] ---- BYOL Training Loss = 0.36334675550460815
30-01-2023 15:59:15 INFO Epoch 2: [2685/10940] ---- BYOL Validation Loss = 0.29065653681755066
30-01-2023 15:59:32 INFO Epoch 2: [2696/10940] ---- BYOL Training Loss = 0.3378961980342865
30-01-2023 15:59:50 INFO Epoch 2: [2707/10940] ---- BYOL Training Loss = 0.31186240911483765
30-01-2023 16:00:08 INFO Epoch 2: [2718/10940] ---- BYOL Training Loss = 0.28261056542396545
30-01-2023 16:00:26 INFO Epoch 2: [2729/10940] ---- BYOL Training Loss = 0.27794745564460754
30-01-2023 16:01:18 INFO Epoch 2: [2729/10940] ---- BYOL Validation Loss = 0.2864241600036621
30-01-2023 16:01:35 INFO Epoch 2: [2740/10940] ---- BYOL Training Loss = 0.30387964844703674
30-01-2023 16:01:53 INFO Epoch 2: [2751/10940] ---- BYOL Training Loss = 0.25614508986473083
30-01-2023 16:02:11 INFO Epoch 2: [2762/10940] ---- BYOL Training Loss = 0.2835001051425934
30-01-2023 16:02:28 INFO Epoch 2: [2773/10940] ---- BYOL Training Loss = 0.36125075817108154
30-01-2023 16:03:20 INFO Epoch 2: [2773/10940] ---- BYOL Validation Loss = 0.28844138979911804
30-01-2023 16:03:38 INFO Epoch 2: [2784/10940] ---- BYOL Training Loss = 0.3389248251914978
30-01-2023 16:03:56 INFO Epoch 2: [2795/10940] ---- BYOL Training Loss = 0.27666452527046204
30-01-2023 16:04:13 INFO Epoch 2: [2806/10940] ---- BYOL Training Loss = 0.2784152030944824
30-01-2023 16:04:31 INFO Epoch 2: [2817/10940] ---- BYOL Training Loss = 0.3183501958847046
30-01-2023 16:05:24 INFO Epoch 2: [2817/10940] ---- BYOL Validation Loss = 0.29113706946372986
30-01-2023 16:05:41 INFO Epoch 2: [2828/10940] ---- BYOL Training Loss = 0.30633512139320374
30-01-2023 16:05:59 INFO Epoch 2: [2839/10940] ---- BYOL Training Loss = 0.3216947913169861
30-01-2023 16:06:16 INFO Epoch 2: [2850/10940] ---- BYOL Training Loss = 0.35405752062797546
30-01-2023 16:06:34 INFO Epoch 2: [2861/10940] ---- BYOL Training Loss = 0.30878812074661255
30-01-2023 16:07:26 INFO Epoch 2: [2861/10940] ---- BYOL Validation Loss = 0.2780258357524872
30-01-2023 16:07:44 INFO Epoch 2: [2872/10940] ---- BYOL Training Loss = 0.2712225019931793
30-01-2023 16:08:02 INFO Epoch 2: [2883/10940] ---- BYOL Training Loss = 0.32267478108406067
30-01-2023 16:08:19 INFO Epoch 2: [2894/10940] ---- BYOL Training Loss = 0.3317621648311615
30-01-2023 16:08:37 INFO Epoch 2: [2905/10940] ---- BYOL Training Loss = 0.2999722361564636
30-01-2023 16:09:29 INFO Epoch 2: [2905/10940] ---- BYOL Validation Loss = 0.28624463081359863
30-01-2023 16:09:47 INFO Epoch 2: [2916/10940] ---- BYOL Training Loss = 0.27228376269340515
30-01-2023 16:10:05 INFO Epoch 2: [2927/10940] ---- BYOL Training Loss = 0.2791171967983246
30-01-2023 16:10:23 INFO Epoch 2: [2938/10940] ---- BYOL Training Loss = 0.3099415898323059
30-01-2023 16:10:40 INFO Epoch 2: [2949/10940] ---- BYOL Training Loss = 0.297039270401001
30-01-2023 16:11:33 INFO Epoch 2: [2949/10940] ---- BYOL Validation Loss = 0.272036075592041
30-01-2023 16:11:50 INFO Epoch 2: [2960/10940] ---- BYOL Training Loss = 0.2854227125644684
30-01-2023 16:12:08 INFO Epoch 2: [2971/10940] ---- BYOL Training Loss = 0.2613217234611511
30-01-2023 16:12:26 INFO Epoch 2: [2982/10940] ---- BYOL Training Loss = 0.31547877192497253
30-01-2023 16:12:43 INFO Epoch 2: [2993/10940] ---- BYOL Training Loss = 0.35324159264564514
30-01-2023 16:13:36 INFO Epoch 2: [2993/10940] ---- BYOL Validation Loss = 0.3104323744773865
30-01-2023 16:13:53 INFO Epoch 2: [3004/10940] ---- BYOL Training Loss = 0.318462610244751
30-01-2023 16:14:11 INFO Epoch 2: [3015/10940] ---- BYOL Training Loss = 0.34879070520401
30-01-2023 16:14:29 INFO Epoch 2: [3026/10940] ---- BYOL Training Loss = 0.35336440801620483
30-01-2023 16:14:47 INFO Epoch 2: [3037/10940] ---- BYOL Training Loss = 0.32598331570625305
30-01-2023 16:15:39 INFO Epoch 2: [3037/10940] ---- BYOL Validation Loss = 0.29858875274658203
30-01-2023 16:15:56 INFO Epoch 2: [3048/10940] ---- BYOL Training Loss = 0.3421086072921753
30-01-2023 16:16:14 INFO Epoch 2: [3059/10940] ---- BYOL Training Loss = 0.305387020111084
30-01-2023 16:16:32 INFO Epoch 2: [3070/10940] ---- BYOL Training Loss = 0.31460052728652954
30-01-2023 16:16:50 INFO Epoch 2: [3081/10940] ---- BYOL Training Loss = 0.3441951274871826
30-01-2023 16:17:42 INFO Epoch 2: [3081/10940] ---- BYOL Validation Loss = 0.2891455292701721
30-01-2023 16:17:59 INFO Epoch 2: [3092/10940] ---- BYOL Training Loss = 0.3102283477783203
30-01-2023 16:18:17 INFO Epoch 2: [3103/10940] ---- BYOL Training Loss = 0.26264894008636475
30-01-2023 16:18:35 INFO Epoch 2: [3114/10940] ---- BYOL Training Loss = 0.28387710452079773
30-01-2023 16:18:53 INFO Epoch 2: [3125/10940] ---- BYOL Training Loss = 0.31151801347732544
30-01-2023 16:19:45 INFO Epoch 2: [3125/10940] ---- BYOL Validation Loss = 0.2878374457359314
30-01-2023 16:20:03 INFO Epoch 2: [3136/10940] ---- BYOL Training Loss = 0.31214773654937744
30-01-2023 16:20:20 INFO Epoch 2: [3147/10940] ---- BYOL Training Loss = 0.3271661400794983
30-01-2023 16:20:38 INFO Epoch 2: [3158/10940] ---- BYOL Training Loss = 0.31216269731521606
30-01-2023 16:20:56 INFO Epoch 2: [3169/10940] ---- BYOL Training Loss = 0.2907942235469818
30-01-2023 16:21:48 INFO Epoch 2: [3169/10940] ---- BYOL Validation Loss = 0.2741675078868866
30-01-2023 16:22:06 INFO Epoch 2: [3180/10940] ---- BYOL Training Loss = 0.28154149651527405
30-01-2023 16:22:24 INFO Epoch 2: [3191/10940] ---- BYOL Training Loss = 0.33212774991989136
30-01-2023 16:22:42 INFO Epoch 2: [3202/10940] ---- BYOL Training Loss = 0.31378376483917236
30-01-2023 16:22:59 INFO Epoch 2: [3213/10940] ---- BYOL Training Loss = 0.2825966477394104
30-01-2023 16:23:52 INFO Epoch 2: [3213/10940] ---- BYOL Validation Loss = 0.2875485122203827
30-01-2023 16:24:09 INFO Epoch 2: [3224/10940] ---- BYOL Training Loss = 0.27144569158554077
30-01-2023 16:24:27 INFO Epoch 2: [3235/10940] ---- BYOL Training Loss = 0.3152411878108978
30-01-2023 16:24:45 INFO Epoch 2: [3246/10940] ---- BYOL Training Loss = 0.3372443914413452
30-01-2023 16:25:02 INFO Epoch 2: [3257/10940] ---- BYOL Training Loss = 0.2985856831073761
30-01-2023 16:25:55 INFO Epoch 2: [3257/10940] ---- BYOL Validation Loss = 0.2866979241371155
30-01-2023 16:26:12 INFO Epoch 2: [3268/10940] ---- BYOL Training Loss = 0.2717346251010895
30-01-2023 16:26:30 INFO Epoch 2: [3279/10940] ---- BYOL Training Loss = 0.27724358439445496
30-01-2023 16:26:48 INFO Epoch 2: [3290/10940] ---- BYOL Training Loss = 0.26464948058128357
30-01-2023 16:27:06 INFO Epoch 2: [3301/10940] ---- BYOL Training Loss = 0.2768610119819641
30-01-2023 16:27:58 INFO Epoch 2: [3301/10940] ---- BYOL Validation Loss = 0.28003039956092834
30-01-2023 16:28:16 INFO Epoch 2: [3312/10940] ---- BYOL Training Loss = 0.272562175989151
30-01-2023 16:28:33 INFO Epoch 2: [3323/10940] ---- BYOL Training Loss = 0.31871020793914795
30-01-2023 16:28:51 INFO Epoch 2: [3334/10940] ---- BYOL Training Loss = 0.31149643659591675
30-01-2023 16:29:09 INFO Epoch 2: [3345/10940] ---- BYOL Training Loss = 0.3187609612941742
30-01-2023 16:30:01 INFO Epoch 2: [3345/10940] ---- BYOL Validation Loss = 0.29478248953819275
30-01-2023 16:30:19 INFO Epoch 2: [3356/10940] ---- BYOL Training Loss = 0.31229469180107117
30-01-2023 16:30:37 INFO Epoch 2: [3367/10940] ---- BYOL Training Loss = 0.27670496702194214
30-01-2023 16:30:55 INFO Epoch 2: [3378/10940] ---- BYOL Training Loss = 0.2807970345020294
30-01-2023 16:31:12 INFO Epoch 2: [3389/10940] ---- BYOL Training Loss = 0.2728918492794037
30-01-2023 16:32:05 INFO Epoch 2: [3389/10940] ---- BYOL Validation Loss = 0.2898271977901459
30-01-2023 16:32:22 INFO Epoch 2: [3400/10940] ---- BYOL Training Loss = 0.279893696308136
30-01-2023 16:32:40 INFO Epoch 2: [3411/10940] ---- BYOL Training Loss = 0.2749672532081604
30-01-2023 16:32:58 INFO Epoch 2: [3422/10940] ---- BYOL Training Loss = 0.296191930770874
30-01-2023 16:33:15 INFO Epoch 2: [3433/10940] ---- BYOL Training Loss = 0.2973794639110565
30-01-2023 16:34:08 INFO Epoch 2: [3433/10940] ---- BYOL Validation Loss = 0.2747672200202942
30-01-2023 16:34:25 INFO Epoch 2: [3444/10940] ---- BYOL Training Loss = 0.27886849641799927
30-01-2023 16:34:43 INFO Epoch 2: [3455/10940] ---- BYOL Training Loss = 0.3019747734069824
30-01-2023 16:35:01 INFO Epoch 2: [3466/10940] ---- BYOL Training Loss = 0.29031339287757874
30-01-2023 16:35:19 INFO Epoch 2: [3477/10940] ---- BYOL Training Loss = 0.24555644392967224
30-01-2023 16:36:11 INFO Epoch 2: [3477/10940] ---- BYOL Validation Loss = 0.3013370931148529
30-01-2023 16:36:28 INFO Epoch 2: [3488/10940] ---- BYOL Training Loss = 0.28974834084510803
30-01-2023 16:36:46 INFO Epoch 2: [3499/10940] ---- BYOL Training Loss = 0.31380122900009155
30-01-2023 16:37:04 INFO Epoch 2: [3510/10940] ---- BYOL Training Loss = 0.3103528618812561
30-01-2023 16:37:22 INFO Epoch 2: [3521/10940] ---- BYOL Training Loss = 0.3128425180912018
30-01-2023 16:38:15 INFO Epoch 2: [3521/10940] ---- BYOL Validation Loss = 0.29198354482650757
30-01-2023 16:38:32 INFO Epoch 2: [3532/10940] ---- BYOL Training Loss = 0.33327725529670715
30-01-2023 16:38:50 INFO Epoch 2: [3543/10940] ---- BYOL Training Loss = 0.34477490186691284
30-01-2023 16:39:08 INFO Epoch 2: [3554/10940] ---- BYOL Training Loss = 0.29632568359375
30-01-2023 16:39:25 INFO Epoch 2: [3565/10940] ---- BYOL Training Loss = 0.3240233063697815
30-01-2023 16:40:18 INFO Epoch 2: [3565/10940] ---- BYOL Validation Loss = 0.2974945902824402
30-01-2023 16:40:35 INFO Epoch 2: [3576/10940] ---- BYOL Training Loss = 0.3064342141151428
30-01-2023 16:40:53 INFO Epoch 2: [3587/10940] ---- BYOL Training Loss = 0.26927611231803894
30-01-2023 16:41:11 INFO Epoch 2: [3598/10940] ---- BYOL Training Loss = 0.28254395723342896
30-01-2023 16:41:29 INFO Epoch 2: [3609/10940] ---- BYOL Training Loss = 0.2818855345249176
30-01-2023 16:42:21 INFO Epoch 2: [3609/10940] ---- BYOL Validation Loss = 0.2822057604789734
30-01-2023 16:42:39 INFO Epoch 2: [3620/10940] ---- BYOL Training Loss = 0.24581842124462128
30-01-2023 16:42:56 INFO Epoch 2: [3631/10940] ---- BYOL Training Loss = 0.2844676077365875
30-01-2023 16:43:14 INFO Epoch 2: [3642/10940] ---- BYOL Training Loss = 0.3281807601451874
30-01-2023 16:43:32 INFO Epoch 2: [3653/10940] ---- BYOL Training Loss = 0.3537641167640686
30-01-2023 16:44:24 INFO Epoch 2: [3653/10940] ---- BYOL Validation Loss = 0.2890048921108246
30-01-2023 16:44:42 INFO Epoch 2: [3664/10940] ---- BYOL Training Loss = 0.29957693815231323
30-01-2023 16:45:00 INFO Epoch 2: [3675/10940] ---- BYOL Training Loss = 0.30292490124702454
30-01-2023 16:45:18 INFO Epoch 2: [3686/10940] ---- BYOL Training Loss = 0.3098178505897522
30-01-2023 16:45:36 INFO Epoch 2: [3697/10940] ---- BYOL Training Loss = 0.2934669852256775
30-01-2023 16:46:28 INFO Epoch 2: [3697/10940] ---- BYOL Validation Loss = 0.2797410190105438
30-01-2023 16:46:45 INFO Epoch 2: [3708/10940] ---- BYOL Training Loss = 0.32527852058410645
30-01-2023 16:47:03 INFO Epoch 2: [3719/10940] ---- BYOL Training Loss = 0.28591445088386536
30-01-2023 16:47:21 INFO Epoch 2: [3730/10940] ---- BYOL Training Loss = 0.2706910967826843
30-01-2023 16:47:39 INFO Epoch 2: [3741/10940] ---- BYOL Training Loss = 0.3180118203163147
30-01-2023 16:48:31 INFO Epoch 2: [3741/10940] ---- BYOL Validation Loss = 0.30050674080848694
30-01-2023 16:48:49 INFO Epoch 2: [3752/10940] ---- BYOL Training Loss = 0.3307996690273285
30-01-2023 16:49:07 INFO Epoch 2: [3763/10940] ---- BYOL Training Loss = 0.27954012155532837
30-01-2023 16:49:24 INFO Epoch 2: [3774/10940] ---- BYOL Training Loss = 0.24896153807640076
30-01-2023 16:49:42 INFO Epoch 2: [3785/10940] ---- BYOL Training Loss = 0.28968432545661926
30-01-2023 16:50:34 INFO Epoch 2: [3785/10940] ---- BYOL Validation Loss = 0.2808802127838135
30-01-2023 16:50:52 INFO Epoch 2: [3796/10940] ---- BYOL Training Loss = 0.33598411083221436
30-01-2023 16:51:10 INFO Epoch 2: [3807/10940] ---- BYOL Training Loss = 0.2920287549495697
30-01-2023 16:51:28 INFO Epoch 2: [3818/10940] ---- BYOL Training Loss = 0.2715259790420532
30-01-2023 16:51:46 INFO Epoch 2: [3829/10940] ---- BYOL Training Loss = 0.345369428396225
30-01-2023 16:52:38 INFO Epoch 2: [3829/10940] ---- BYOL Validation Loss = 0.2997388243675232
30-01-2023 16:52:55 INFO Epoch 2: [3840/10940] ---- BYOL Training Loss = 0.3182589113712311
30-01-2023 16:53:13 INFO Epoch 2: [3851/10940] ---- BYOL Training Loss = 0.24476532638072968
30-01-2023 16:53:31 INFO Epoch 2: [3862/10940] ---- BYOL Training Loss = 0.2594121992588043
30-01-2023 16:53:49 INFO Epoch 2: [3873/10940] ---- BYOL Training Loss = 0.29633721709251404
30-01-2023 16:54:41 INFO Epoch 2: [3873/10940] ---- BYOL Validation Loss = 0.2869063913822174
30-01-2023 16:54:59 INFO Epoch 2: [3884/10940] ---- BYOL Training Loss = 0.2939625382423401
30-01-2023 16:55:17 INFO Epoch 2: [3895/10940] ---- BYOL Training Loss = 0.2933700978755951
30-01-2023 16:55:35 INFO Epoch 2: [3906/10940] ---- BYOL Training Loss = 0.2926391363143921
30-01-2023 16:55:52 INFO Epoch 2: [3917/10940] ---- BYOL Training Loss = 0.27913668751716614
30-01-2023 16:56:45 INFO Epoch 2: [3917/10940] ---- BYOL Validation Loss = 0.28638216853141785
30-01-2023 16:57:02 INFO Epoch 2: [3928/10940] ---- BYOL Training Loss = 0.2829422950744629
30-01-2023 16:57:20 INFO Epoch 2: [3939/10940] ---- BYOL Training Loss = 0.2909991145133972
30-01-2023 16:57:38 INFO Epoch 2: [3950/10940] ---- BYOL Training Loss = 0.3095959424972534
30-01-2023 16:57:56 INFO Epoch 2: [3961/10940] ---- BYOL Training Loss = 0.34668418765068054
30-01-2023 16:58:48 INFO Epoch 2: [3961/10940] ---- BYOL Validation Loss = 0.29582881927490234
30-01-2023 16:59:06 INFO Epoch 2: [3972/10940] ---- BYOL Training Loss = 0.329194039106369
30-01-2023 16:59:24 INFO Epoch 2: [3983/10940] ---- BYOL Training Loss = 0.27489858865737915
30-01-2023 16:59:41 INFO Epoch 2: [3994/10940] ---- BYOL Training Loss = 0.2641039192676544
30-01-2023 16:59:59 INFO Epoch 2: [4005/10940] ---- BYOL Training Loss = 0.2517072558403015
30-01-2023 17:00:51 INFO Epoch 2: [4005/10940] ---- BYOL Validation Loss = 0.28775614500045776
30-01-2023 17:01:09 INFO Epoch 2: [4016/10940] ---- BYOL Training Loss = 0.27493584156036377
30-01-2023 17:01:27 INFO Epoch 2: [4027/10940] ---- BYOL Training Loss = 0.2721099257469177
30-01-2023 17:01:45 INFO Epoch 2: [4038/10940] ---- BYOL Training Loss = 0.2735525965690613
30-01-2023 17:02:03 INFO Epoch 2: [4049/10940] ---- BYOL Training Loss = 0.31733763217926025
30-01-2023 17:02:55 INFO Epoch 2: [4049/10940] ---- BYOL Validation Loss = 0.28190863132476807
30-01-2023 17:03:13 INFO Epoch 2: [4060/10940] ---- BYOL Training Loss = 0.2961815297603607
30-01-2023 17:03:30 INFO Epoch 2: [4071/10940] ---- BYOL Training Loss = 0.2427973449230194
30-01-2023 17:03:49 INFO Epoch 2: [4082/10940] ---- BYOL Training Loss = 0.28548040986061096
30-01-2023 17:04:07 INFO Epoch 2: [4093/10940] ---- BYOL Training Loss = 0.28036704659461975
30-01-2023 17:04:59 INFO Epoch 2: [4093/10940] ---- BYOL Validation Loss = 0.2885603904724121
30-01-2023 17:05:16 INFO Epoch 2: [4104/10940] ---- BYOL Training Loss = 0.2911967933177948
30-01-2023 17:05:34 INFO Epoch 2: [4115/10940] ---- BYOL Training Loss = 0.2917235493659973
30-01-2023 17:05:52 INFO Epoch 2: [4126/10940] ---- BYOL Training Loss = 0.2503165006637573
30-01-2023 17:06:10 INFO Epoch 2: [4137/10940] ---- BYOL Training Loss = 0.2473444938659668
30-01-2023 17:07:02 INFO Epoch 2: [4137/10940] ---- BYOL Validation Loss = 0.27426227927207947
30-01-2023 17:07:20 INFO Epoch 2: [4148/10940] ---- BYOL Training Loss = 0.2707076668739319
30-01-2023 17:07:38 INFO Epoch 2: [4159/10940] ---- BYOL Training Loss = 0.3021997809410095
30-01-2023 17:07:56 INFO Epoch 2: [4170/10940] ---- BYOL Training Loss = 0.3041582703590393
30-01-2023 17:08:14 INFO Epoch 2: [4181/10940] ---- BYOL Training Loss = 0.32042625546455383
30-01-2023 17:09:06 INFO Epoch 2: [4181/10940] ---- BYOL Validation Loss = 0.29561519622802734
30-01-2023 17:09:23 INFO Epoch 2: [4192/10940] ---- BYOL Training Loss = 0.35467076301574707
30-01-2023 17:09:41 INFO Epoch 2: [4203/10940] ---- BYOL Training Loss = 0.31649869680404663
30-01-2023 17:09:59 INFO Epoch 2: [4214/10940] ---- BYOL Training Loss = 0.29755502939224243
30-01-2023 17:10:17 INFO Epoch 2: [4225/10940] ---- BYOL Training Loss = 0.2424640655517578
30-01-2023 17:11:10 INFO Epoch 2: [4225/10940] ---- BYOL Validation Loss = 0.28597259521484375
30-01-2023 17:11:27 INFO Epoch 2: [4236/10940] ---- BYOL Training Loss = 0.2541557848453522
30-01-2023 17:11:45 INFO Epoch 2: [4247/10940] ---- BYOL Training Loss = 0.2919297516345978
30-01-2023 17:12:03 INFO Epoch 2: [4258/10940] ---- BYOL Training Loss = 0.2929992079734802
30-01-2023 17:12:21 INFO Epoch 2: [4269/10940] ---- BYOL Training Loss = 0.3006591200828552
30-01-2023 17:13:13 INFO Epoch 2: [4269/10940] ---- BYOL Validation Loss = 0.28236374258995056
30-01-2023 17:13:31 INFO Epoch 2: [4280/10940] ---- BYOL Training Loss = 0.2944948971271515
30-01-2023 17:13:49 INFO Epoch 2: [4291/10940] ---- BYOL Training Loss = 0.3248703181743622
30-01-2023 17:14:07 INFO Epoch 2: [4302/10940] ---- BYOL Training Loss = 0.3000018000602722
30-01-2023 17:14:25 INFO Epoch 2: [4313/10940] ---- BYOL Training Loss = 0.30819815397262573
30-01-2023 17:15:17 INFO Epoch 2: [4313/10940] ---- BYOL Validation Loss = 0.28263500332832336
30-01-2023 17:15:34 INFO Epoch 2: [4324/10940] ---- BYOL Training Loss = 0.3021782636642456
30-01-2023 17:15:52 INFO Epoch 2: [4335/10940] ---- BYOL Training Loss = 0.32869309186935425
30-01-2023 17:16:10 INFO Epoch 2: [4346/10940] ---- BYOL Training Loss = 0.30609580874443054
30-01-2023 17:16:28 INFO Epoch 2: [4357/10940] ---- BYOL Training Loss = 0.30861401557922363
30-01-2023 17:17:21 INFO Epoch 2: [4357/10940] ---- BYOL Validation Loss = 0.28415146470069885
30-01-2023 17:17:38 INFO Epoch 2: [4368/10940] ---- BYOL Training Loss = 0.3504648804664612
30-01-2023 17:17:56 INFO Epoch 2: [4379/10940] ---- BYOL Training Loss = 0.3291361927986145
30-01-2023 17:18:14 INFO Epoch 2: [4390/10940] ---- BYOL Training Loss = 0.3496248126029968
30-01-2023 17:18:32 INFO Epoch 2: [4401/10940] ---- BYOL Training Loss = 0.2986804246902466
30-01-2023 17:19:24 INFO Epoch 2: [4401/10940] ---- BYOL Validation Loss = 0.2813398838043213
30-01-2023 17:19:42 INFO Epoch 2: [4412/10940] ---- BYOL Training Loss = 0.28111332654953003
30-01-2023 17:20:00 INFO Epoch 2: [4423/10940] ---- BYOL Training Loss = 0.3286821246147156
30-01-2023 17:20:18 INFO Epoch 2: [4434/10940] ---- BYOL Training Loss = 0.3752552270889282
30-01-2023 17:20:35 INFO Epoch 2: [4445/10940] ---- BYOL Training Loss = 0.35325703024864197
30-01-2023 17:21:28 INFO Epoch 2: [4445/10940] ---- BYOL Validation Loss = 0.28779760003089905
30-01-2023 17:21:46 INFO Epoch 2: [4456/10940] ---- BYOL Training Loss = 0.3399282693862915
30-01-2023 17:22:04 INFO Epoch 2: [4467/10940] ---- BYOL Training Loss = 0.3898945450782776
30-01-2023 17:22:21 INFO Epoch 2: [4478/10940] ---- BYOL Training Loss = 0.3189215660095215
30-01-2023 17:22:39 INFO Epoch 2: [4489/10940] ---- BYOL Training Loss = 0.27821749448776245
30-01-2023 17:23:31 INFO Epoch 2: [4489/10940] ---- BYOL Validation Loss = 0.2839001715183258
30-01-2023 17:23:49 INFO Epoch 2: [4500/10940] ---- BYOL Training Loss = 0.3389246463775635
30-01-2023 17:24:07 INFO Epoch 2: [4511/10940] ---- BYOL Training Loss = 0.355696439743042
30-01-2023 17:24:25 INFO Epoch 2: [4522/10940] ---- BYOL Training Loss = 0.3024871349334717
30-01-2023 17:24:43 INFO Epoch 2: [4533/10940] ---- BYOL Training Loss = 0.2570834755897522
30-01-2023 17:25:35 INFO Epoch 2: [4533/10940] ---- BYOL Validation Loss = 0.28279682993888855
30-01-2023 17:25:53 INFO Epoch 2: [4544/10940] ---- BYOL Training Loss = 0.2678220868110657
30-01-2023 17:26:11 INFO Epoch 2: [4555/10940] ---- BYOL Training Loss = 0.30660945177078247
30-01-2023 17:26:28 INFO Epoch 2: [4566/10940] ---- BYOL Training Loss = 0.3441622853279114
30-01-2023 17:26:47 INFO Epoch 2: [4577/10940] ---- BYOL Training Loss = 0.3508354127407074
30-01-2023 17:27:39 INFO Epoch 2: [4577/10940] ---- BYOL Validation Loss = 0.26195064187049866
30-01-2023 17:27:57 INFO Epoch 2: [4588/10940] ---- BYOL Training Loss = 0.2889685332775116
30-01-2023 17:28:14 INFO Epoch 2: [4599/10940] ---- BYOL Training Loss = 0.2865385413169861
30-01-2023 17:28:32 INFO Epoch 2: [4610/10940] ---- BYOL Training Loss = 0.2855207324028015
30-01-2023 17:28:50 INFO Epoch 2: [4621/10940] ---- BYOL Training Loss = 0.3363793194293976
30-01-2023 17:29:43 INFO Epoch 2: [4621/10940] ---- BYOL Validation Loss = 0.26853832602500916
30-01-2023 17:30:00 INFO Epoch 2: [4632/10940] ---- BYOL Training Loss = 0.3276088833808899
30-01-2023 17:30:18 INFO Epoch 2: [4643/10940] ---- BYOL Training Loss = 0.2733888626098633
30-01-2023 17:30:36 INFO Epoch 2: [4654/10940] ---- BYOL Training Loss = 0.2915109097957611
30-01-2023 17:30:54 INFO Epoch 2: [4665/10940] ---- BYOL Training Loss = 0.3205178380012512
30-01-2023 17:31:46 INFO Epoch 2: [4665/10940] ---- BYOL Validation Loss = 0.2726854681968689
30-01-2023 17:32:04 INFO Epoch 2: [4676/10940] ---- BYOL Training Loss = 0.2563430368900299
30-01-2023 17:32:22 INFO Epoch 2: [4687/10940] ---- BYOL Training Loss = 0.2641276717185974
30-01-2023 17:32:40 INFO Epoch 2: [4698/10940] ---- BYOL Training Loss = 0.29669708013534546
30-01-2023 17:32:58 INFO Epoch 2: [4709/10940] ---- BYOL Training Loss = 0.29308265447616577
30-01-2023 17:33:50 INFO Epoch 2: [4709/10940] ---- BYOL Validation Loss = 0.27172917127609253
30-01-2023 17:34:08 INFO Epoch 2: [4720/10940] ---- BYOL Training Loss = 0.31703850626945496
30-01-2023 17:34:26 INFO Epoch 2: [4731/10940] ---- BYOL Training Loss = 0.2739258110523224
30-01-2023 17:34:44 INFO Epoch 2: [4742/10940] ---- BYOL Training Loss = 0.24193648993968964
30-01-2023 17:35:02 INFO Epoch 2: [4753/10940] ---- BYOL Training Loss = 0.24965372681617737
30-01-2023 17:35:54 INFO Epoch 2: [4753/10940] ---- BYOL Validation Loss = 0.2673245072364807
30-01-2023 17:36:12 INFO Epoch 2: [4764/10940] ---- BYOL Training Loss = 0.26209598779678345
30-01-2023 17:36:30 INFO Epoch 2: [4775/10940] ---- BYOL Training Loss = 0.29850372672080994
30-01-2023 17:36:48 INFO Epoch 2: [4786/10940] ---- BYOL Training Loss = 0.3226998746395111
30-01-2023 17:37:05 INFO Epoch 2: [4797/10940] ---- BYOL Training Loss = 0.36013713479042053
30-01-2023 17:37:58 INFO Epoch 2: [4797/10940] ---- BYOL Validation Loss = 0.2757265567779541
30-01-2023 17:38:16 INFO Epoch 2: [4808/10940] ---- BYOL Training Loss = 0.3309837877750397
30-01-2023 17:38:34 INFO Epoch 2: [4819/10940] ---- BYOL Training Loss = 0.28133994340896606
30-01-2023 17:38:52 INFO Epoch 2: [4830/10940] ---- BYOL Training Loss = 0.2797383666038513
30-01-2023 17:39:10 INFO Epoch 2: [4841/10940] ---- BYOL Training Loss = 0.24056291580200195
30-01-2023 17:40:02 INFO Epoch 2: [4841/10940] ---- BYOL Validation Loss = 0.2626376450061798
30-01-2023 17:40:20 INFO Epoch 2: [4852/10940] ---- BYOL Training Loss = 0.2539755702018738
30-01-2023 17:40:38 INFO Epoch 2: [4863/10940] ---- BYOL Training Loss = 0.2992947995662689
30-01-2023 17:40:56 INFO Epoch 2: [4874/10940] ---- BYOL Training Loss = 0.2965756952762604
30-01-2023 17:41:13 INFO Epoch 2: [4885/10940] ---- BYOL Training Loss = 0.2885277569293976
30-01-2023 17:42:06 INFO Epoch 2: [4885/10940] ---- BYOL Validation Loss = 0.2673398554325104
30-01-2023 17:42:23 INFO Epoch 2: [4896/10940] ---- BYOL Training Loss = 0.31027698516845703
30-01-2023 17:42:42 INFO Epoch 2: [4907/10940] ---- BYOL Training Loss = 0.27728766202926636
30-01-2023 17:42:59 INFO Epoch 2: [4918/10940] ---- BYOL Training Loss = 0.2683771252632141
30-01-2023 17:43:17 INFO Epoch 2: [4929/10940] ---- BYOL Training Loss = 0.2956531345844269
30-01-2023 17:44:10 INFO Epoch 2: [4929/10940] ---- BYOL Validation Loss = 0.2756807208061218
30-01-2023 17:44:27 INFO Epoch 2: [4940/10940] ---- BYOL Training Loss = 0.3340050280094147
30-01-2023 17:44:45 INFO Epoch 2: [4951/10940] ---- BYOL Training Loss = 0.33090120553970337
30-01-2023 17:45:04 INFO Epoch 2: [4962/10940] ---- BYOL Training Loss = 0.3022546172142029
30-01-2023 17:45:21 INFO Epoch 2: [4973/10940] ---- BYOL Training Loss = 0.27202215790748596
30-01-2023 17:46:14 INFO Epoch 2: [4973/10940] ---- BYOL Validation Loss = 0.2726289927959442
30-01-2023 17:46:31 INFO Epoch 2: [4984/10940] ---- BYOL Training Loss = 0.2984093129634857
30-01-2023 17:46:49 INFO Epoch 2: [4995/10940] ---- BYOL Training Loss = 0.29233062267303467
30-01-2023 17:47:07 INFO Epoch 2: [5006/10940] ---- BYOL Training Loss = 0.24986818432807922
30-01-2023 17:47:25 INFO Epoch 2: [5017/10940] ---- BYOL Training Loss = 0.2624731957912445
30-01-2023 17:48:18 INFO Epoch 2: [5017/10940] ---- BYOL Validation Loss = 0.2697158455848694
30-01-2023 17:48:35 INFO Epoch 2: [5028/10940] ---- BYOL Training Loss = 0.25697800517082214
30-01-2023 17:48:53 INFO Epoch 2: [5039/10940] ---- BYOL Training Loss = 0.2841675281524658
30-01-2023 17:49:11 INFO Epoch 2: [5050/10940] ---- BYOL Training Loss = 0.2821669280529022
30-01-2023 17:49:29 INFO Epoch 2: [5061/10940] ---- BYOL Training Loss = 0.3077490031719208
30-01-2023 17:50:21 INFO Epoch 2: [5061/10940] ---- BYOL Validation Loss = 0.2735324800014496
30-01-2023 17:50:39 INFO Epoch 2: [5072/10940] ---- BYOL Training Loss = 0.3174038827419281
30-01-2023 17:50:57 INFO Epoch 2: [5083/10940] ---- BYOL Training Loss = 0.2961152195930481
30-01-2023 17:51:15 INFO Epoch 2: [5094/10940] ---- BYOL Training Loss = 0.27924591302871704
30-01-2023 17:51:33 INFO Epoch 2: [5105/10940] ---- BYOL Training Loss = 0.3179042637348175
30-01-2023 17:52:25 INFO Epoch 2: [5105/10940] ---- BYOL Validation Loss = 0.28047531843185425
30-01-2023 17:52:43 INFO Epoch 2: [5116/10940] ---- BYOL Training Loss = 0.2969285845756531
30-01-2023 17:53:01 INFO Epoch 2: [5127/10940] ---- BYOL Training Loss = 0.3133390247821808
30-01-2023 17:53:19 INFO Epoch 2: [5138/10940] ---- BYOL Training Loss = 0.3032480776309967
30-01-2023 17:53:37 INFO Epoch 2: [5149/10940] ---- BYOL Training Loss = 0.2727663815021515
30-01-2023 17:54:29 INFO Epoch 2: [5149/10940] ---- BYOL Validation Loss = 0.27713772654533386
30-01-2023 17:54:47 INFO Epoch 2: [5160/10940] ---- BYOL Training Loss = 0.2753404974937439
30-01-2023 17:55:05 INFO Epoch 2: [5171/10940] ---- BYOL Training Loss = 0.2704470753669739
30-01-2023 17:55:23 INFO Epoch 2: [5182/10940] ---- BYOL Training Loss = 0.2980418801307678
30-01-2023 17:55:41 INFO Epoch 2: [5193/10940] ---- BYOL Training Loss = 0.32306694984436035
30-01-2023 17:56:34 INFO Epoch 2: [5193/10940] ---- BYOL Validation Loss = 0.2805054187774658
30-01-2023 17:56:51 INFO Epoch 2: [5204/10940] ---- BYOL Training Loss = 0.26812535524368286
30-01-2023 17:57:09 INFO Epoch 2: [5215/10940] ---- BYOL Training Loss = 0.2478748857975006
30-01-2023 17:57:27 INFO Epoch 2: [5226/10940] ---- BYOL Training Loss = 0.25459903478622437
30-01-2023 17:57:45 INFO Epoch 2: [5237/10940] ---- BYOL Training Loss = 0.3358036279678345
30-01-2023 17:58:38 INFO Epoch 2: [5237/10940] ---- BYOL Validation Loss = 0.2858256697654724
30-01-2023 17:58:55 INFO Epoch 2: [5248/10940] ---- BYOL Training Loss = 0.3288937509059906
30-01-2023 17:59:13 INFO Epoch 2: [5259/10940] ---- BYOL Training Loss = 0.2759150564670563
30-01-2023 17:59:31 INFO Epoch 2: [5270/10940] ---- BYOL Training Loss = 0.29206669330596924
30-01-2023 17:59:49 INFO Epoch 2: [5281/10940] ---- BYOL Training Loss = 0.3098241686820984
30-01-2023 18:00:42 INFO Epoch 2: [5281/10940] ---- BYOL Validation Loss = 0.28188738226890564
30-01-2023 18:00:59 INFO Epoch 2: [5292/10940] ---- BYOL Training Loss = 0.3038378655910492
30-01-2023 18:01:17 INFO Epoch 2: [5303/10940] ---- BYOL Training Loss = 0.2939758896827698
30-01-2023 18:01:35 INFO Epoch 2: [5314/10940] ---- BYOL Training Loss = 0.3269079327583313
30-01-2023 18:01:54 INFO Epoch 2: [5325/10940] ---- BYOL Training Loss = 0.32711920142173767
30-01-2023 18:02:46 INFO Epoch 2: [5325/10940] ---- BYOL Validation Loss = 0.2864707112312317
30-01-2023 18:03:03 INFO Epoch 2: [5336/10940] ---- BYOL Training Loss = 0.2926197350025177
30-01-2023 18:03:21 INFO Epoch 2: [5347/10940] ---- BYOL Training Loss = 0.2871871590614319
30-01-2023 18:03:39 INFO Epoch 2: [5358/10940] ---- BYOL Training Loss = 0.288377046585083
30-01-2023 18:03:58 INFO Epoch 2: [5369/10940] ---- BYOL Training Loss = 0.3116244971752167
30-01-2023 18:04:50 INFO Epoch 2: [5369/10940] ---- BYOL Validation Loss = 0.29434844851493835
30-01-2023 18:05:08 INFO Epoch 2: [5380/10940] ---- BYOL Training Loss = 0.3199702203273773
30-01-2023 18:05:25 INFO Epoch 2: [5391/10940] ---- BYOL Training Loss = 0.2820051610469818
30-01-2023 18:05:43 INFO Epoch 2: [5402/10940] ---- BYOL Training Loss = 0.317506343126297
30-01-2023 18:06:02 INFO Epoch 2: [5413/10940] ---- BYOL Training Loss = 0.3658900260925293
30-01-2023 18:06:54 INFO Epoch 2: [5413/10940] ---- BYOL Validation Loss = 0.29999175667762756
30-01-2023 18:07:12 INFO Epoch 2: [5424/10940] ---- BYOL Training Loss = 0.35311076045036316
30-01-2023 18:07:30 INFO Epoch 2: [5435/10940] ---- BYOL Training Loss = 0.33413031697273254
30-01-2023 18:07:48 INFO Epoch 2: [5446/10940] ---- BYOL Training Loss = 0.28738000988960266
30-01-2023 18:08:06 INFO Epoch 2: [5457/10940] ---- BYOL Training Loss = 0.2951962351799011
30-01-2023 18:08:58 INFO Epoch 2: [5457/10940] ---- BYOL Validation Loss = 0.30898743867874146
30-01-2023 18:09:16 INFO Epoch 2: [5468/10940] ---- BYOL Training Loss = 0.32468074560165405
30-01-2023 18:09:34 INFO Epoch 2: [5479/10940] ---- BYOL Training Loss = 0.3202722370624542
30-01-2023 18:09:52 INFO Epoch 2: [5490/10940] ---- BYOL Training Loss = 0.3155542016029358
30-01-2023 18:10:10 INFO Epoch 2: [5501/10940] ---- BYOL Training Loss = 0.30564701557159424
30-01-2023 18:11:02 INFO Epoch 2: [5501/10940] ---- BYOL Validation Loss = 0.3167148232460022
30-01-2023 18:11:20 INFO Epoch 2: [5512/10940] ---- BYOL Training Loss = 0.30991217494010925
30-01-2023 18:11:38 INFO Epoch 2: [5523/10940] ---- BYOL Training Loss = 0.29981371760368347
30-01-2023 18:11:56 INFO Epoch 2: [5534/10940] ---- BYOL Training Loss = 0.322491854429245
30-01-2023 18:12:14 INFO Epoch 2: [5545/10940] ---- BYOL Training Loss = 0.3619597256183624
30-01-2023 18:13:07 INFO Epoch 2: [5545/10940] ---- BYOL Validation Loss = 0.32179710268974304
30-01-2023 18:13:24 INFO Epoch 2: [5556/10940] ---- BYOL Training Loss = 0.3066251873970032
30-01-2023 18:13:43 INFO Epoch 2: [5567/10940] ---- BYOL Training Loss = 0.3051358759403229
30-01-2023 18:14:01 INFO Epoch 2: [5578/10940] ---- BYOL Training Loss = 0.290188193321228
30-01-2023 18:14:19 INFO Epoch 2: [5589/10940] ---- BYOL Training Loss = 0.30642473697662354
30-01-2023 18:15:11 INFO Epoch 2: [5589/10940] ---- BYOL Validation Loss = 0.3212721049785614
30-01-2023 18:15:28 INFO Epoch 2: [5600/10940] ---- BYOL Training Loss = 0.3765559196472168
30-01-2023 18:15:47 INFO Epoch 2: [5611/10940] ---- BYOL Training Loss = 0.39439254999160767
30-01-2023 18:16:05 INFO Epoch 2: [5622/10940] ---- BYOL Training Loss = 0.3448152542114258
30-01-2023 18:16:23 INFO Epoch 2: [5633/10940] ---- BYOL Training Loss = 0.32375240325927734
30-01-2023 18:17:15 INFO Epoch 2: [5633/10940] ---- BYOL Validation Loss = 0.32313284277915955
30-01-2023 18:17:33 INFO Epoch 2: [5644/10940] ---- BYOL Training Loss = 0.2876679301261902
30-01-2023 18:17:51 INFO Epoch 2: [5655/10940] ---- BYOL Training Loss = 0.3559730052947998
30-01-2023 18:18:09 INFO Epoch 2: [5666/10940] ---- BYOL Training Loss = 0.372705340385437
30-01-2023 18:18:27 INFO Epoch 2: [5677/10940] ---- BYOL Training Loss = 0.29504525661468506
30-01-2023 18:19:20 INFO Epoch 2: [5677/10940] ---- BYOL Validation Loss = 0.3167486786842346
30-01-2023 18:19:37 INFO Epoch 2: [5688/10940] ---- BYOL Training Loss = 0.3113357424736023
30-01-2023 18:19:55 INFO Epoch 2: [5699/10940] ---- BYOL Training Loss = 0.30932003259658813
30-01-2023 18:20:13 INFO Epoch 2: [5710/10940] ---- BYOL Training Loss = 0.3011801838874817
30-01-2023 18:20:31 INFO Epoch 2: [5721/10940] ---- BYOL Training Loss = 0.3458766043186188
30-01-2023 18:21:24 INFO Epoch 2: [5721/10940] ---- BYOL Validation Loss = 0.30891165137290955
30-01-2023 18:21:41 INFO Epoch 2: [5732/10940] ---- BYOL Training Loss = 0.3599899709224701
30-01-2023 18:21:59 INFO Epoch 2: [5743/10940] ---- BYOL Training Loss = 0.36146602034568787
30-01-2023 18:22:18 INFO Epoch 2: [5754/10940] ---- BYOL Training Loss = 0.3510954976081848
30-01-2023 18:22:36 INFO Epoch 2: [5765/10940] ---- BYOL Training Loss = 0.33413445949554443
30-01-2023 18:23:28 INFO Epoch 2: [5765/10940] ---- BYOL Validation Loss = 0.3184410631656647
30-01-2023 18:23:46 INFO Epoch 2: [5776/10940] ---- BYOL Training Loss = 0.3165394961833954
30-01-2023 18:24:04 INFO Epoch 2: [5787/10940] ---- BYOL Training Loss = 0.3229074478149414
30-01-2023 18:24:22 INFO Epoch 2: [5798/10940] ---- BYOL Training Loss = 0.32797762751579285
30-01-2023 18:24:40 INFO Epoch 2: [5809/10940] ---- BYOL Training Loss = 0.3597515821456909
30-01-2023 18:25:33 INFO Epoch 2: [5809/10940] ---- BYOL Validation Loss = 0.3256777822971344
30-01-2023 18:25:50 INFO Epoch 2: [5820/10940] ---- BYOL Training Loss = 0.34695374965667725
30-01-2023 18:26:08 INFO Epoch 2: [5831/10940] ---- BYOL Training Loss = 0.33266669511795044
30-01-2023 18:26:27 INFO Epoch 2: [5842/10940] ---- BYOL Training Loss = 0.32544761896133423
30-01-2023 18:26:45 INFO Epoch 2: [5853/10940] ---- BYOL Training Loss = 0.34004682302474976
30-01-2023 18:27:37 INFO Epoch 2: [5853/10940] ---- BYOL Validation Loss = 0.30949702858924866
30-01-2023 18:27:55 INFO Epoch 2: [5864/10940] ---- BYOL Training Loss = 0.3327711820602417
30-01-2023 18:28:13 INFO Epoch 2: [5875/10940] ---- BYOL Training Loss = 0.34628885984420776
30-01-2023 18:28:31 INFO Epoch 2: [5886/10940] ---- BYOL Training Loss = 0.3990951180458069
30-01-2023 18:28:49 INFO Epoch 2: [5897/10940] ---- BYOL Training Loss = 0.3774406313896179
30-01-2023 18:29:41 INFO Epoch 2: [5897/10940] ---- BYOL Validation Loss = 0.3266393840312958
30-01-2023 18:29:59 INFO Epoch 2: [5908/10940] ---- BYOL Training Loss = 0.3422335982322693
30-01-2023 18:30:17 INFO Epoch 2: [5919/10940] ---- BYOL Training Loss = 0.3649173378944397
30-01-2023 18:30:36 INFO Epoch 2: [5930/10940] ---- BYOL Training Loss = 0.3571595847606659
30-01-2023 18:30:53 INFO Epoch 2: [5941/10940] ---- BYOL Training Loss = 0.3152165412902832
30-01-2023 18:31:46 INFO Epoch 2: [5941/10940] ---- BYOL Validation Loss = 0.31321242451667786
30-01-2023 18:32:03 INFO Epoch 2: [5952/10940] ---- BYOL Training Loss = 0.27785834670066833
30-01-2023 18:32:21 INFO Epoch 2: [5963/10940] ---- BYOL Training Loss = 0.34594443440437317
30-01-2023 18:32:40 INFO Epoch 2: [5974/10940] ---- BYOL Training Loss = 0.35424551367759705
30-01-2023 18:32:58 INFO Epoch 2: [5985/10940] ---- BYOL Training Loss = 0.37354397773742676
30-01-2023 18:33:50 INFO Epoch 2: [5985/10940] ---- BYOL Validation Loss = 0.31414446234703064
30-01-2023 18:34:08 INFO Epoch 2: [5996/10940] ---- BYOL Training Loss = 0.3882026970386505
30-01-2023 18:34:26 INFO Epoch 2: [6007/10940] ---- BYOL Training Loss = 0.34939906001091003
30-01-2023 18:34:44 INFO Epoch 2: [6018/10940] ---- BYOL Training Loss = 0.30842846632003784
30-01-2023 18:35:02 INFO Epoch 2: [6029/10940] ---- BYOL Training Loss = 0.30806946754455566
30-01-2023 18:35:55 INFO Epoch 2: [6029/10940] ---- BYOL Validation Loss = 0.31206628680229187
30-01-2023 18:36:12 INFO Epoch 2: [6040/10940] ---- BYOL Training Loss = 0.3537743091583252
30-01-2023 18:36:30 INFO Epoch 2: [6051/10940] ---- BYOL Training Loss = 0.3655669093132019
30-01-2023 18:36:49 INFO Epoch 2: [6062/10940] ---- BYOL Training Loss = 0.3805386424064636
30-01-2023 18:37:07 INFO Epoch 2: [6073/10940] ---- BYOL Training Loss = 0.35037559270858765
30-01-2023 18:37:59 INFO Epoch 2: [6073/10940] ---- BYOL Validation Loss = 0.31619128584861755
30-01-2023 18:38:17 INFO Epoch 2: [6084/10940] ---- BYOL Training Loss = 0.3008822798728943
30-01-2023 18:38:35 INFO Epoch 2: [6095/10940] ---- BYOL Training Loss = 0.307267963886261
30-01-2023 18:38:53 INFO Epoch 2: [6106/10940] ---- BYOL Training Loss = 0.3467092514038086
30-01-2023 18:39:11 INFO Epoch 2: [6117/10940] ---- BYOL Training Loss = 0.3783903121948242
30-01-2023 18:40:03 INFO Epoch 2: [6117/10940] ---- BYOL Validation Loss = 0.31077417731285095
30-01-2023 18:40:21 INFO Epoch 2: [6128/10940] ---- BYOL Training Loss = 0.357374906539917
30-01-2023 18:40:39 INFO Epoch 2: [6139/10940] ---- BYOL Training Loss = 0.3349953293800354
30-01-2023 18:40:58 INFO Epoch 2: [6150/10940] ---- BYOL Training Loss = 0.34031420946121216
30-01-2023 18:41:16 INFO Epoch 2: [6161/10940] ---- BYOL Training Loss = 0.38122791051864624
30-01-2023 18:42:08 INFO Epoch 2: [6161/10940] ---- BYOL Validation Loss = 0.3058036267757416
30-01-2023 18:42:26 INFO Epoch 2: [6172/10940] ---- BYOL Training Loss = 0.3330563008785248
30-01-2023 18:42:44 INFO Epoch 2: [6183/10940] ---- BYOL Training Loss = 0.2851109206676483
30-01-2023 18:43:02 INFO Epoch 2: [6194/10940] ---- BYOL Training Loss = 0.3000311851501465
30-01-2023 18:43:20 INFO Epoch 2: [6205/10940] ---- BYOL Training Loss = 0.3036251366138458
30-01-2023 18:44:12 INFO Epoch 2: [6205/10940] ---- BYOL Validation Loss = 0.29635995626449585
30-01-2023 18:44:30 INFO Epoch 2: [6216/10940] ---- BYOL Training Loss = 0.27098819613456726
30-01-2023 18:44:49 INFO Epoch 2: [6227/10940] ---- BYOL Training Loss = 0.3148845434188843
30-01-2023 18:45:07 INFO Epoch 2: [6238/10940] ---- BYOL Training Loss = 0.3443315327167511
30-01-2023 18:45:25 INFO Epoch 2: [6249/10940] ---- BYOL Training Loss = 0.32948917150497437
30-01-2023 18:46:17 INFO Epoch 2: [6249/10940] ---- BYOL Validation Loss = 0.302295058965683
30-01-2023 18:46:35 INFO Epoch 2: [6260/10940] ---- BYOL Training Loss = 0.35633206367492676
30-01-2023 18:46:53 INFO Epoch 2: [6271/10940] ---- BYOL Training Loss = 0.3117296099662781
30-01-2023 18:47:11 INFO Epoch 2: [6282/10940] ---- BYOL Training Loss = 0.3245914578437805
30-01-2023 18:47:29 INFO Epoch 2: [6293/10940] ---- BYOL Training Loss = 0.35574474930763245
30-01-2023 18:48:22 INFO Epoch 2: [6293/10940] ---- BYOL Validation Loss = 0.3052002489566803
30-01-2023 18:48:39 INFO Epoch 2: [6304/10940] ---- BYOL Training Loss = 0.34087666869163513
30-01-2023 18:48:58 INFO Epoch 2: [6315/10940] ---- BYOL Training Loss = 0.3722715973854065
30-01-2023 18:49:16 INFO Epoch 2: [6326/10940] ---- BYOL Training Loss = 0.3574647009372711
30-01-2023 18:49:34 INFO Epoch 2: [6337/10940] ---- BYOL Training Loss = 0.3528381884098053
30-01-2023 18:50:26 INFO Epoch 2: [6337/10940] ---- BYOL Validation Loss = 0.2954161465167999
30-01-2023 18:50:44 INFO Epoch 2: [6348/10940] ---- BYOL Training Loss = 0.3632650375366211
30-01-2023 18:51:02 INFO Epoch 2: [6359/10940] ---- BYOL Training Loss = 0.3143187165260315
30-01-2023 18:51:20 INFO Epoch 2: [6370/10940] ---- BYOL Training Loss = 0.31372085213661194
30-01-2023 18:51:39 INFO Epoch 2: [6381/10940] ---- BYOL Training Loss = 0.2992632985115051
30-01-2023 18:52:31 INFO Epoch 2: [6381/10940] ---- BYOL Validation Loss = 0.2981109917163849
30-01-2023 18:52:49 INFO Epoch 2: [6392/10940] ---- BYOL Training Loss = 0.27008622884750366
30-01-2023 18:53:07 INFO Epoch 2: [6403/10940] ---- BYOL Training Loss = 0.2732226550579071
30-01-2023 18:53:25 INFO Epoch 2: [6414/10940] ---- BYOL Training Loss = 0.255648672580719
30-01-2023 18:53:43 INFO Epoch 2: [6425/10940] ---- BYOL Training Loss = 0.3268149495124817
30-01-2023 18:54:35 INFO Epoch 2: [6425/10940] ---- BYOL Validation Loss = 0.2976522743701935
30-01-2023 18:54:53 INFO Epoch 2: [6436/10940] ---- BYOL Training Loss = 0.32207074761390686
30-01-2023 18:55:12 INFO Epoch 2: [6447/10940] ---- BYOL Training Loss = 0.2806793451309204
30-01-2023 18:55:30 INFO Epoch 2: [6458/10940] ---- BYOL Training Loss = 0.2852776348590851
30-01-2023 18:55:48 INFO Epoch 2: [6469/10940] ---- BYOL Training Loss = 0.32649514079093933
30-01-2023 18:56:40 INFO Epoch 2: [6469/10940] ---- BYOL Validation Loss = 0.36023345589637756
30-01-2023 18:56:58 INFO Epoch 2: [6480/10940] ---- BYOL Training Loss = 0.3619047701358795
30-01-2023 18:57:16 INFO Epoch 2: [6491/10940] ---- BYOL Training Loss = 0.35981014370918274
30-01-2023 18:57:34 INFO Epoch 2: [6502/10940] ---- BYOL Training Loss = 0.3233577013015747
30-01-2023 18:57:53 INFO Epoch 2: [6513/10940] ---- BYOL Training Loss = 0.3273380398750305
30-01-2023 18:58:45 INFO Epoch 2: [6513/10940] ---- BYOL Validation Loss = 0.293130487203598
30-01-2023 18:59:03 INFO Epoch 2: [6524/10940] ---- BYOL Training Loss = 0.3486388325691223
30-01-2023 18:59:21 INFO Epoch 2: [6535/10940] ---- BYOL Training Loss = 0.35491904616355896
30-01-2023 18:59:39 INFO Epoch 2: [6546/10940] ---- BYOL Training Loss = 0.32260602712631226
30-01-2023 18:59:57 INFO Epoch 2: [6557/10940] ---- BYOL Training Loss = 0.2802736461162567
30-01-2023 19:00:50 INFO Epoch 2: [6557/10940] ---- BYOL Validation Loss = 0.2916125953197479
30-01-2023 19:01:07 INFO Epoch 2: [6568/10940] ---- BYOL Training Loss = 0.32049256563186646
30-01-2023 19:01:25 INFO Epoch 2: [6579/10940] ---- BYOL Training Loss = 0.31740421056747437
30-01-2023 19:01:44 INFO Epoch 2: [6590/10940] ---- BYOL Training Loss = 0.3109350800514221
30-01-2023 19:02:02 INFO Epoch 2: [6601/10940] ---- BYOL Training Loss = 0.30947765707969666
30-01-2023 19:02:54 INFO Epoch 2: [6601/10940] ---- BYOL Validation Loss = 0.30062106251716614
30-01-2023 19:03:12 INFO Epoch 2: [6612/10940] ---- BYOL Training Loss = 0.33533382415771484
30-01-2023 19:03:30 INFO Epoch 2: [6623/10940] ---- BYOL Training Loss = 0.34437739849090576
30-01-2023 19:03:49 INFO Epoch 2: [6634/10940] ---- BYOL Training Loss = 0.3142685890197754
30-01-2023 19:04:07 INFO Epoch 2: [6645/10940] ---- BYOL Training Loss = 0.30127933621406555
30-01-2023 19:04:59 INFO Epoch 2: [6645/10940] ---- BYOL Validation Loss = 0.2960343360900879
30-01-2023 19:05:17 INFO Epoch 2: [6656/10940] ---- BYOL Training Loss = 0.30778026580810547
30-01-2023 19:05:35 INFO Epoch 2: [6667/10940] ---- BYOL Training Loss = 0.2853468060493469
30-01-2023 19:05:53 INFO Epoch 2: [6678/10940] ---- BYOL Training Loss = 0.3214148283004761
30-01-2023 19:06:11 INFO Epoch 2: [6689/10940] ---- BYOL Training Loss = 0.3811297118663788
30-01-2023 19:07:04 INFO Epoch 2: [6689/10940] ---- BYOL Validation Loss = 0.3059420883655548
30-01-2023 19:07:21 INFO Epoch 2: [6700/10940] ---- BYOL Training Loss = 0.3513658940792084
30-01-2023 19:07:40 INFO Epoch 2: [6711/10940] ---- BYOL Training Loss = 0.3281773626804352
30-01-2023 19:07:58 INFO Epoch 2: [6722/10940] ---- BYOL Training Loss = 0.3404209017753601
30-01-2023 19:08:16 INFO Epoch 2: [6733/10940] ---- BYOL Training Loss = 0.31471508741378784
30-01-2023 19:09:08 INFO Epoch 2: [6733/10940] ---- BYOL Validation Loss = 0.2979731261730194
30-01-2023 19:09:26 INFO Epoch 2: [6744/10940] ---- BYOL Training Loss = 0.3099760115146637
30-01-2023 19:09:44 INFO Epoch 2: [6755/10940] ---- BYOL Training Loss = 0.26237034797668457
30-01-2023 19:10:03 INFO Epoch 2: [6766/10940] ---- BYOL Training Loss = 0.23605315387248993
30-01-2023 19:10:21 INFO Epoch 2: [6777/10940] ---- BYOL Training Loss = 0.297624796628952
30-01-2023 19:11:13 INFO Epoch 2: [6777/10940] ---- BYOL Validation Loss = 0.2923866808414459
30-01-2023 19:11:31 INFO Epoch 2: [6788/10940] ---- BYOL Training Loss = 0.2822258472442627
30-01-2023 19:11:49 INFO Epoch 2: [6799/10940] ---- BYOL Training Loss = 0.28911489248275757
30-01-2023 19:12:07 INFO Epoch 2: [6810/10940] ---- BYOL Training Loss = 0.34413936734199524
30-01-2023 19:12:26 INFO Epoch 2: [6821/10940] ---- BYOL Training Loss = 0.34851402044296265
30-01-2023 19:13:18 INFO Epoch 2: [6821/10940] ---- BYOL Validation Loss = 0.2871468961238861
30-01-2023 19:13:36 INFO Epoch 2: [6832/10940] ---- BYOL Training Loss = 0.29781779646873474
30-01-2023 19:13:54 INFO Epoch 2: [6843/10940] ---- BYOL Training Loss = 0.31102365255355835
30-01-2023 19:14:12 INFO Epoch 2: [6854/10940] ---- BYOL Training Loss = 0.31669846177101135
30-01-2023 19:14:31 INFO Epoch 2: [6865/10940] ---- BYOL Training Loss = 0.26445406675338745
30-01-2023 19:15:23 INFO Epoch 2: [6865/10940] ---- BYOL Validation Loss = 0.28348007798194885
30-01-2023 19:15:41 INFO Epoch 2: [6876/10940] ---- BYOL Training Loss = 0.28229379653930664
30-01-2023 19:15:59 INFO Epoch 2: [6887/10940] ---- BYOL Training Loss = 0.29815635085105896
30-01-2023 19:16:17 INFO Epoch 2: [6898/10940] ---- BYOL Training Loss = 0.2929489016532898
30-01-2023 19:16:35 INFO Epoch 2: [6909/10940] ---- BYOL Training Loss = 0.27904802560806274
30-01-2023 19:17:28 INFO Epoch 2: [6909/10940] ---- BYOL Validation Loss = 0.2840382158756256
30-01-2023 19:17:45 INFO Epoch 2: [6920/10940] ---- BYOL Training Loss = 0.32018932700157166
30-01-2023 19:18:04 INFO Epoch 2: [6931/10940] ---- BYOL Training Loss = 0.28285855054855347
30-01-2023 19:18:22 INFO Epoch 2: [6942/10940] ---- BYOL Training Loss = 0.29165714979171753
30-01-2023 19:18:40 INFO Epoch 2: [6953/10940] ---- BYOL Training Loss = 0.323842853307724
30-01-2023 19:19:32 INFO Epoch 2: [6953/10940] ---- BYOL Validation Loss = 0.28223302960395813
30-01-2023 19:19:50 INFO Epoch 2: [6964/10940] ---- BYOL Training Loss = 0.3369400203227997
30-01-2023 19:20:09 INFO Epoch 2: [6975/10940] ---- BYOL Training Loss = 0.31728729605674744
30-01-2023 19:20:27 INFO Epoch 2: [6986/10940] ---- BYOL Training Loss = 0.3156995177268982
30-01-2023 19:20:45 INFO Epoch 2: [6997/10940] ---- BYOL Training Loss = 0.3024638891220093
30-01-2023 19:21:37 INFO Epoch 2: [6997/10940] ---- BYOL Validation Loss = 0.2827545702457428
30-01-2023 19:21:55 INFO Epoch 2: [7008/10940] ---- BYOL Training Loss = 0.2778494954109192
30-01-2023 19:22:14 INFO Epoch 2: [7019/10940] ---- BYOL Training Loss = 0.2669840455055237
30-01-2023 19:22:32 INFO Epoch 2: [7030/10940] ---- BYOL Training Loss = 0.32920289039611816
30-01-2023 19:22:50 INFO Epoch 2: [7041/10940] ---- BYOL Training Loss = 0.2978542447090149
30-01-2023 19:23:42 INFO Epoch 2: [7041/10940] ---- BYOL Validation Loss = 0.2874751091003418
30-01-2023 19:24:00 INFO Epoch 2: [7052/10940] ---- BYOL Training Loss = 0.3395417332649231
30-01-2023 19:24:18 INFO Epoch 2: [7063/10940] ---- BYOL Training Loss = 0.32729604840278625
30-01-2023 19:24:37 INFO Epoch 2: [7074/10940] ---- BYOL Training Loss = 0.27836570143699646
30-01-2023 19:24:55 INFO Epoch 2: [7085/10940] ---- BYOL Training Loss = 0.24918301403522491
30-01-2023 19:25:47 INFO Epoch 2: [7085/10940] ---- BYOL Validation Loss = 0.2740457057952881
30-01-2023 19:26:05 INFO Epoch 2: [7096/10940] ---- BYOL Training Loss = 0.3129238486289978
30-01-2023 19:26:23 INFO Epoch 2: [7107/10940] ---- BYOL Training Loss = 0.30795925855636597
30-01-2023 19:26:41 INFO Epoch 2: [7118/10940] ---- BYOL Training Loss = 0.2889252305030823
30-01-2023 19:27:00 INFO Epoch 2: [7129/10940] ---- BYOL Training Loss = 0.3059939444065094
30-01-2023 19:27:52 INFO Epoch 2: [7129/10940] ---- BYOL Validation Loss = 0.28425318002700806
30-01-2023 19:28:10 INFO Epoch 2: [7140/10940] ---- BYOL Training Loss = 0.28185275197029114
30-01-2023 19:28:28 INFO Epoch 2: [7151/10940] ---- BYOL Training Loss = 0.2920796275138855
30-01-2023 19:28:47 INFO Epoch 2: [7162/10940] ---- BYOL Training Loss = 0.2727474272251129
30-01-2023 19:29:05 INFO Epoch 2: [7173/10940] ---- BYOL Training Loss = 0.2715803384780884
30-01-2023 19:29:57 INFO Epoch 2: [7173/10940] ---- BYOL Validation Loss = 0.2782505452632904
30-01-2023 19:30:15 INFO Epoch 2: [7184/10940] ---- BYOL Training Loss = 0.27604976296424866
30-01-2023 19:30:33 INFO Epoch 2: [7195/10940] ---- BYOL Training Loss = 0.2778172791004181
30-01-2023 19:30:52 INFO Epoch 2: [7206/10940] ---- BYOL Training Loss = 0.3063652217388153
30-01-2023 19:31:10 INFO Epoch 2: [7217/10940] ---- BYOL Training Loss = 0.3102809488773346
30-01-2023 19:32:02 INFO Epoch 2: [7217/10940] ---- BYOL Validation Loss = 0.28878292441368103
30-01-2023 19:32:20 INFO Epoch 2: [7228/10940] ---- BYOL Training Loss = 0.34696635603904724
30-01-2023 19:32:39 INFO Epoch 2: [7239/10940] ---- BYOL Training Loss = 0.36500996351242065
30-01-2023 19:32:57 INFO Epoch 2: [7250/10940] ---- BYOL Training Loss = 0.33280235528945923
30-01-2023 19:33:15 INFO Epoch 2: [7261/10940] ---- BYOL Training Loss = 0.3016440272331238
30-01-2023 19:34:08 INFO Epoch 2: [7261/10940] ---- BYOL Validation Loss = 0.28800874948501587
30-01-2023 19:34:26 INFO Epoch 2: [7272/10940] ---- BYOL Training Loss = 0.28935277462005615
30-01-2023 19:34:44 INFO Epoch 2: [7283/10940] ---- BYOL Training Loss = 0.3199090361595154
30-01-2023 19:35:02 INFO Epoch 2: [7294/10940] ---- BYOL Training Loss = 0.28139424324035645
30-01-2023 19:35:20 INFO Epoch 2: [7305/10940] ---- BYOL Training Loss = 0.24814710021018982
30-01-2023 19:36:13 INFO Epoch 2: [7305/10940] ---- BYOL Validation Loss = 0.2879738211631775
30-01-2023 19:36:31 INFO Epoch 2: [7316/10940] ---- BYOL Training Loss = 0.3072803020477295
30-01-2023 19:36:49 INFO Epoch 2: [7327/10940] ---- BYOL Training Loss = 0.3650321364402771
30-01-2023 19:37:07 INFO Epoch 2: [7338/10940] ---- BYOL Training Loss = 0.3148513436317444
30-01-2023 19:37:25 INFO Epoch 2: [7349/10940] ---- BYOL Training Loss = 0.2994754910469055
30-01-2023 19:38:18 INFO Epoch 2: [7349/10940] ---- BYOL Validation Loss = 0.2982529103755951
30-01-2023 19:38:36 INFO Epoch 2: [7360/10940] ---- BYOL Training Loss = 0.31159883737564087
30-01-2023 19:38:54 INFO Epoch 2: [7371/10940] ---- BYOL Training Loss = 0.32403695583343506
30-01-2023 19:39:12 INFO Epoch 2: [7382/10940] ---- BYOL Training Loss = 0.29731330275535583
30-01-2023 19:39:31 INFO Epoch 2: [7393/10940] ---- BYOL Training Loss = 0.2941153049468994
30-01-2023 19:40:23 INFO Epoch 2: [7393/10940] ---- BYOL Validation Loss = 0.2849147319793701
30-01-2023 19:40:41 INFO Epoch 2: [7404/10940] ---- BYOL Training Loss = 0.26436710357666016
30-01-2023 19:40:59 INFO Epoch 2: [7415/10940] ---- BYOL Training Loss = 0.2869848906993866
30-01-2023 19:41:18 INFO Epoch 2: [7426/10940] ---- BYOL Training Loss = 0.3113645017147064
30-01-2023 19:41:36 INFO Epoch 2: [7437/10940] ---- BYOL Training Loss = 0.28984197974205017
30-01-2023 19:42:28 INFO Epoch 2: [7437/10940] ---- BYOL Validation Loss = 0.2802866995334625
30-01-2023 19:42:46 INFO Epoch 2: [7448/10940] ---- BYOL Training Loss = 0.29710060358047485
30-01-2023 19:43:05 INFO Epoch 2: [7459/10940] ---- BYOL Training Loss = 0.294566810131073
30-01-2023 19:43:23 INFO Epoch 2: [7470/10940] ---- BYOL Training Loss = 0.24807152152061462
30-01-2023 19:43:41 INFO Epoch 2: [7481/10940] ---- BYOL Training Loss = 0.2995365262031555
30-01-2023 19:44:33 INFO Epoch 2: [7481/10940] ---- BYOL Validation Loss = 0.28872400522232056
30-01-2023 19:44:51 INFO Epoch 2: [7492/10940] ---- BYOL Training Loss = 0.34032952785491943
30-01-2023 19:45:10 INFO Epoch 2: [7503/10940] ---- BYOL Training Loss = 0.34369224309921265
30-01-2023 19:45:28 INFO Epoch 2: [7514/10940] ---- BYOL Training Loss = 0.31584271788597107
30-01-2023 19:45:46 INFO Epoch 2: [7525/10940] ---- BYOL Training Loss = 0.28025954961776733
30-01-2023 19:46:39 INFO Epoch 2: [7525/10940] ---- BYOL Validation Loss = 0.2888965606689453
30-01-2023 19:46:57 INFO Epoch 2: [7536/10940] ---- BYOL Training Loss = 0.3035533130168915
30-01-2023 19:47:15 INFO Epoch 2: [7547/10940] ---- BYOL Training Loss = 0.27760621905326843
30-01-2023 19:47:34 INFO Epoch 2: [7558/10940] ---- BYOL Training Loss = 0.2996036410331726
30-01-2023 19:47:52 INFO Epoch 2: [7569/10940] ---- BYOL Training Loss = 0.307230681180954
30-01-2023 19:48:44 INFO Epoch 2: [7569/10940] ---- BYOL Validation Loss = 0.2808527648448944
30-01-2023 19:49:02 INFO Epoch 2: [7580/10940] ---- BYOL Training Loss = 0.30131834745407104
30-01-2023 19:49:20 INFO Epoch 2: [7591/10940] ---- BYOL Training Loss = 0.2932121455669403
30-01-2023 19:49:39 INFO Epoch 2: [7602/10940] ---- BYOL Training Loss = 0.2706729769706726
30-01-2023 19:49:57 INFO Epoch 2: [7613/10940] ---- BYOL Training Loss = 0.3116568922996521
30-01-2023 19:50:49 INFO Epoch 2: [7613/10940] ---- BYOL Validation Loss = 0.28264734148979187
30-01-2023 19:51:08 INFO Epoch 2: [7624/10940] ---- BYOL Training Loss = 0.3221920132637024
30-01-2023 19:51:26 INFO Epoch 2: [7635/10940] ---- BYOL Training Loss = 0.29538875818252563
30-01-2023 19:51:44 INFO Epoch 2: [7646/10940] ---- BYOL Training Loss = 0.3019983768463135
30-01-2023 19:52:03 INFO Epoch 2: [7657/10940] ---- BYOL Training Loss = 0.3108978867530823
30-01-2023 19:52:55 INFO Epoch 2: [7657/10940] ---- BYOL Validation Loss = 0.2844494879245758
30-01-2023 19:53:13 INFO Epoch 2: [7668/10940] ---- BYOL Training Loss = 0.3487505316734314
30-01-2023 19:53:31 INFO Epoch 2: [7679/10940] ---- BYOL Training Loss = 0.4139212667942047
30-01-2023 19:53:49 INFO Epoch 2: [7690/10940] ---- BYOL Training Loss = 0.2990667223930359
30-01-2023 19:54:08 INFO Epoch 2: [7701/10940] ---- BYOL Training Loss = 0.24698598682880402
30-01-2023 19:55:00 INFO Epoch 2: [7701/10940] ---- BYOL Validation Loss = 0.2840798497200012
30-01-2023 19:55:18 INFO Epoch 2: [7712/10940] ---- BYOL Training Loss = 0.3067978322505951
30-01-2023 19:55:36 INFO Epoch 2: [7723/10940] ---- BYOL Training Loss = 0.3564907908439636
30-01-2023 19:55:55 INFO Epoch 2: [7734/10940] ---- BYOL Training Loss = 0.3376900851726532
30-01-2023 19:56:13 INFO Epoch 2: [7745/10940] ---- BYOL Training Loss = 0.295518159866333
30-01-2023 19:57:05 INFO Epoch 2: [7745/10940] ---- BYOL Validation Loss = 0.2917673587799072
30-01-2023 19:57:23 INFO Epoch 2: [7756/10940] ---- BYOL Training Loss = 0.26800674200057983
30-01-2023 19:57:42 INFO Epoch 2: [7767/10940] ---- BYOL Training Loss = 0.2742449641227722
30-01-2023 19:58:00 INFO Epoch 2: [7778/10940] ---- BYOL Training Loss = 0.34491539001464844
30-01-2023 19:58:18 INFO Epoch 2: [7789/10940] ---- BYOL Training Loss = 0.34458601474761963
30-01-2023 19:59:11 INFO Epoch 2: [7789/10940] ---- BYOL Validation Loss = 0.2823666036128998
30-01-2023 19:59:29 INFO Epoch 2: [7800/10940] ---- BYOL Training Loss = 0.2676711976528168
30-01-2023 19:59:47 INFO Epoch 2: [7811/10940] ---- BYOL Training Loss = 0.300726056098938
30-01-2023 20:00:05 INFO Epoch 2: [7822/10940] ---- BYOL Training Loss = 0.35599786043167114
30-01-2023 20:00:24 INFO Epoch 2: [7833/10940] ---- BYOL Training Loss = 0.34369951486587524
30-01-2023 20:01:16 INFO Epoch 2: [7833/10940] ---- BYOL Validation Loss = 0.28909072279930115
30-01-2023 20:01:34 INFO Epoch 2: [7844/10940] ---- BYOL Training Loss = 0.3636631369590759
30-01-2023 20:01:52 INFO Epoch 2: [7855/10940] ---- BYOL Training Loss = 0.28597477078437805
30-01-2023 20:02:11 INFO Epoch 2: [7866/10940] ---- BYOL Training Loss = 0.2635393440723419
30-01-2023 20:02:29 INFO Epoch 2: [7877/10940] ---- BYOL Training Loss = 0.3166017532348633
30-01-2023 20:03:22 INFO Epoch 2: [7877/10940] ---- BYOL Validation Loss = 0.27530306577682495
30-01-2023 20:03:40 INFO Epoch 2: [7888/10940] ---- BYOL Training Loss = 0.28699856996536255
30-01-2023 20:03:58 INFO Epoch 2: [7899/10940] ---- BYOL Training Loss = 0.2854102551937103
30-01-2023 20:04:16 INFO Epoch 2: [7910/10940] ---- BYOL Training Loss = 0.2669353485107422
30-01-2023 20:04:35 INFO Epoch 2: [7921/10940] ---- BYOL Training Loss = 0.2828234136104584
30-01-2023 20:05:27 INFO Epoch 2: [7921/10940] ---- BYOL Validation Loss = 0.2823219299316406
30-01-2023 20:05:45 INFO Epoch 2: [7932/10940] ---- BYOL Training Loss = 0.2895545959472656
30-01-2023 20:06:03 INFO Epoch 2: [7943/10940] ---- BYOL Training Loss = 0.2906309962272644
30-01-2023 20:06:22 INFO Epoch 2: [7954/10940] ---- BYOL Training Loss = 0.2982555329799652
30-01-2023 20:06:40 INFO Epoch 2: [7965/10940] ---- BYOL Training Loss = 0.29890498518943787
30-01-2023 20:07:33 INFO Epoch 2: [7965/10940] ---- BYOL Validation Loss = 0.2829461693763733
30-01-2023 20:07:51 INFO Epoch 2: [7976/10940] ---- BYOL Training Loss = 0.3349533677101135
30-01-2023 20:08:09 INFO Epoch 2: [7987/10940] ---- BYOL Training Loss = 0.29964566230773926
30-01-2023 20:08:27 INFO Epoch 2: [7998/10940] ---- BYOL Training Loss = 0.2871522903442383
30-01-2023 20:08:46 INFO Epoch 2: [8009/10940] ---- BYOL Training Loss = 0.28477340936660767
30-01-2023 20:09:38 INFO Epoch 2: [8009/10940] ---- BYOL Validation Loss = 0.2792958915233612
30-01-2023 20:09:56 INFO Epoch 2: [8020/10940] ---- BYOL Training Loss = 0.29000622034072876
30-01-2023 20:10:15 INFO Epoch 2: [8031/10940] ---- BYOL Training Loss = 0.2809129059314728
30-01-2023 20:10:33 INFO Epoch 2: [8042/10940] ---- BYOL Training Loss = 0.24848365783691406
30-01-2023 20:10:51 INFO Epoch 2: [8053/10940] ---- BYOL Training Loss = 0.2671230435371399
30-01-2023 20:11:44 INFO Epoch 2: [8053/10940] ---- BYOL Validation Loss = 0.28809717297554016
30-01-2023 20:12:01 INFO Epoch 2: [8064/10940] ---- BYOL Training Loss = 0.28882092237472534
30-01-2023 20:12:20 INFO Epoch 2: [8075/10940] ---- BYOL Training Loss = 0.24267666041851044
30-01-2023 20:12:38 INFO Epoch 2: [8086/10940] ---- BYOL Training Loss = 0.26124221086502075
30-01-2023 20:12:57 INFO Epoch 2: [8097/10940] ---- BYOL Training Loss = 0.2746230661869049
30-01-2023 20:13:49 INFO Epoch 2: [8097/10940] ---- BYOL Validation Loss = 0.27364498376846313
30-01-2023 20:14:07 INFO Epoch 2: [8108/10940] ---- BYOL Training Loss = 0.29072993993759155
30-01-2023 20:14:25 INFO Epoch 2: [8119/10940] ---- BYOL Training Loss = 0.2801152765750885
30-01-2023 20:14:44 INFO Epoch 2: [8130/10940] ---- BYOL Training Loss = 0.294249951839447
30-01-2023 20:15:02 INFO Epoch 2: [8141/10940] ---- BYOL Training Loss = 0.27700021862983704
30-01-2023 20:15:54 INFO Epoch 2: [8141/10940] ---- BYOL Validation Loss = 0.28923624753952026
30-01-2023 20:16:13 INFO Epoch 2: [8152/10940] ---- BYOL Training Loss = 0.2792111039161682
30-01-2023 20:16:31 INFO Epoch 2: [8163/10940] ---- BYOL Training Loss = 0.29212865233421326
30-01-2023 20:16:49 INFO Epoch 2: [8174/10940] ---- BYOL Training Loss = 0.32319918274879456
30-01-2023 20:17:08 INFO Epoch 2: [8185/10940] ---- BYOL Training Loss = 0.29719236493110657
30-01-2023 20:18:00 INFO Epoch 2: [8185/10940] ---- BYOL Validation Loss = 0.2812517285346985
30-01-2023 20:18:18 INFO Epoch 2: [8196/10940] ---- BYOL Training Loss = 0.293075293302536
30-01-2023 20:18:36 INFO Epoch 2: [8207/10940] ---- BYOL Training Loss = 0.2658863663673401
30-01-2023 20:18:55 INFO Epoch 2: [8218/10940] ---- BYOL Training Loss = 0.2899651825428009
30-01-2023 20:19:13 INFO Epoch 2: [8229/10940] ---- BYOL Training Loss = 0.328631728887558
30-01-2023 20:20:06 INFO Epoch 2: [8229/10940] ---- BYOL Validation Loss = 0.28001219034194946
30-01-2023 20:20:24 INFO Epoch 2: [8240/10940] ---- BYOL Training Loss = 0.3071746528148651
30-01-2023 20:20:43 INFO Epoch 2: [8251/10940] ---- BYOL Training Loss = 0.3032878339290619
30-01-2023 20:21:01 INFO Epoch 2: [8262/10940] ---- BYOL Training Loss = 0.3054405152797699
30-01-2023 20:21:19 INFO Epoch 2: [8273/10940] ---- BYOL Training Loss = 0.30450958013534546
30-01-2023 20:22:12 INFO Epoch 2: [8273/10940] ---- BYOL Validation Loss = 0.2844908833503723
30-01-2023 20:22:30 INFO Epoch 2: [8284/10940] ---- BYOL Training Loss = 0.2777663767337799
30-01-2023 20:22:48 INFO Epoch 2: [8295/10940] ---- BYOL Training Loss = 0.28724414110183716
30-01-2023 20:23:06 INFO Epoch 2: [8306/10940] ---- BYOL Training Loss = 0.31460270285606384
30-01-2023 20:23:25 INFO Epoch 2: [8317/10940] ---- BYOL Training Loss = 0.30038341879844666
30-01-2023 20:24:18 INFO Epoch 2: [8317/10940] ---- BYOL Validation Loss = 0.2842409610748291
30-01-2023 20:24:35 INFO Epoch 2: [8328/10940] ---- BYOL Training Loss = 0.30838802456855774
30-01-2023 20:24:54 INFO Epoch 2: [8339/10940] ---- BYOL Training Loss = 0.3121364116668701
30-01-2023 20:25:12 INFO Epoch 2: [8350/10940] ---- BYOL Training Loss = 0.29599934816360474
30-01-2023 20:25:31 INFO Epoch 2: [8361/10940] ---- BYOL Training Loss = 0.3143031597137451
30-01-2023 20:26:23 INFO Epoch 2: [8361/10940] ---- BYOL Validation Loss = 0.27234262228012085
30-01-2023 20:26:41 INFO Epoch 2: [8372/10940] ---- BYOL Training Loss = 0.2903653681278229
30-01-2023 20:27:00 INFO Epoch 2: [8383/10940] ---- BYOL Training Loss = 0.31945285201072693
30-01-2023 20:27:18 INFO Epoch 2: [8394/10940] ---- BYOL Training Loss = 0.29422837495803833
30-01-2023 20:27:37 INFO Epoch 2: [8405/10940] ---- BYOL Training Loss = 0.29848480224609375
30-01-2023 20:28:29 INFO Epoch 2: [8405/10940] ---- BYOL Validation Loss = 0.2737507224082947
30-01-2023 20:28:47 INFO Epoch 2: [8416/10940] ---- BYOL Training Loss = 0.31740042567253113
30-01-2023 20:29:05 INFO Epoch 2: [8427/10940] ---- BYOL Training Loss = 0.37353503704071045
30-01-2023 20:29:24 INFO Epoch 2: [8438/10940] ---- BYOL Training Loss = 0.3441111147403717
30-01-2023 20:29:42 INFO Epoch 2: [8449/10940] ---- BYOL Training Loss = 0.32379797101020813
30-01-2023 20:30:35 INFO Epoch 2: [8449/10940] ---- BYOL Validation Loss = 0.2781856060028076
30-01-2023 20:30:53 INFO Epoch 2: [8460/10940] ---- BYOL Training Loss = 0.29152151942253113
30-01-2023 20:31:11 INFO Epoch 2: [8471/10940] ---- BYOL Training Loss = 0.27342599630355835
30-01-2023 20:31:30 INFO Epoch 2: [8482/10940] ---- BYOL Training Loss = 0.27901574969291687
30-01-2023 20:31:48 INFO Epoch 2: [8493/10940] ---- BYOL Training Loss = 0.3335654139518738
30-01-2023 20:32:40 INFO Epoch 2: [8493/10940] ---- BYOL Validation Loss = 0.2858709692955017
30-01-2023 20:32:58 INFO Epoch 2: [8504/10940] ---- BYOL Training Loss = 0.36315980553627014
30-01-2023 20:33:17 INFO Epoch 2: [8515/10940] ---- BYOL Training Loss = 0.3105892837047577
30-01-2023 20:33:35 INFO Epoch 2: [8526/10940] ---- BYOL Training Loss = 0.31106263399124146
30-01-2023 20:33:54 INFO Epoch 2: [8537/10940] ---- BYOL Training Loss = 0.31549692153930664
30-01-2023 20:34:46 INFO Epoch 2: [8537/10940] ---- BYOL Validation Loss = 0.27350497245788574
30-01-2023 20:35:04 INFO Epoch 2: [8548/10940] ---- BYOL Training Loss = 0.30927664041519165
30-01-2023 20:35:23 INFO Epoch 2: [8559/10940] ---- BYOL Training Loss = 0.3085312843322754
30-01-2023 20:35:41 INFO Epoch 2: [8570/10940] ---- BYOL Training Loss = 0.3087160885334015
30-01-2023 20:35:59 INFO Epoch 2: [8581/10940] ---- BYOL Training Loss = 0.3107457458972931
30-01-2023 20:36:52 INFO Epoch 2: [8581/10940] ---- BYOL Validation Loss = 0.282298743724823
30-01-2023 20:37:10 INFO Epoch 2: [8592/10940] ---- BYOL Training Loss = 0.2911525368690491
30-01-2023 20:37:28 INFO Epoch 2: [8603/10940] ---- BYOL Training Loss = 0.2984437346458435
30-01-2023 20:37:47 INFO Epoch 2: [8614/10940] ---- BYOL Training Loss = 0.320771187543869
30-01-2023 20:38:05 INFO Epoch 2: [8625/10940] ---- BYOL Training Loss = 0.28885364532470703
30-01-2023 20:38:58 INFO Epoch 2: [8625/10940] ---- BYOL Validation Loss = 0.27365943789482117
30-01-2023 20:39:16 INFO Epoch 2: [8636/10940] ---- BYOL Training Loss = 0.28500300645828247
30-01-2023 20:39:34 INFO Epoch 2: [8647/10940] ---- BYOL Training Loss = 0.2719592750072479
30-01-2023 20:39:53 INFO Epoch 2: [8658/10940] ---- BYOL Training Loss = 0.2518674433231354
30-01-2023 20:40:11 INFO Epoch 2: [8669/10940] ---- BYOL Training Loss = 0.2617205083370209
30-01-2023 20:41:03 INFO Epoch 2: [8669/10940] ---- BYOL Validation Loss = 0.2776181399822235
30-01-2023 20:41:22 INFO Epoch 2: [8680/10940] ---- BYOL Training Loss = 0.25600701570510864
30-01-2023 20:41:40 INFO Epoch 2: [8691/10940] ---- BYOL Training Loss = 0.2881835103034973
30-01-2023 20:41:58 INFO Epoch 2: [8702/10940] ---- BYOL Training Loss = 0.2707880735397339
30-01-2023 20:42:17 INFO Epoch 2: [8713/10940] ---- BYOL Training Loss = 0.27385932207107544
30-01-2023 20:43:10 INFO Epoch 2: [8713/10940] ---- BYOL Validation Loss = 0.2749762535095215
30-01-2023 20:43:28 INFO Epoch 2: [8724/10940] ---- BYOL Training Loss = 0.29455989599227905
30-01-2023 20:43:46 INFO Epoch 2: [8735/10940] ---- BYOL Training Loss = 0.2982665002346039
30-01-2023 20:44:05 INFO Epoch 2: [8746/10940] ---- BYOL Training Loss = 0.2876313328742981
30-01-2023 20:44:23 INFO Epoch 2: [8757/10940] ---- BYOL Training Loss = 0.30875036120414734
30-01-2023 20:45:15 INFO Epoch 2: [8757/10940] ---- BYOL Validation Loss = 0.271441251039505
30-01-2023 20:45:33 INFO Epoch 2: [8768/10940] ---- BYOL Training Loss = 0.27950340509414673
30-01-2023 20:45:52 INFO Epoch 2: [8779/10940] ---- BYOL Training Loss = 0.2983558773994446
30-01-2023 20:46:10 INFO Epoch 2: [8790/10940] ---- BYOL Training Loss = 0.30725064873695374
30-01-2023 20:46:29 INFO Epoch 2: [8801/10940] ---- BYOL Training Loss = 0.30084681510925293
30-01-2023 20:47:21 INFO Epoch 2: [8801/10940] ---- BYOL Validation Loss = 0.2750399708747864
30-01-2023 20:47:39 INFO Epoch 2: [8812/10940] ---- BYOL Training Loss = 0.32489100098609924
30-01-2023 20:47:58 INFO Epoch 2: [8823/10940] ---- BYOL Training Loss = 0.32119178771972656
30-01-2023 20:48:16 INFO Epoch 2: [8834/10940] ---- BYOL Training Loss = 0.2607535719871521
30-01-2023 20:48:35 INFO Epoch 2: [8845/10940] ---- BYOL Training Loss = 0.2664080262184143
30-01-2023 20:49:27 INFO Epoch 2: [8845/10940] ---- BYOL Validation Loss = 0.2770870625972748
30-01-2023 20:49:45 INFO Epoch 2: [8856/10940] ---- BYOL Training Loss = 0.34768009185791016
30-01-2023 20:50:03 INFO Epoch 2: [8867/10940] ---- BYOL Training Loss = 0.3249879479408264
30-01-2023 20:50:22 INFO Epoch 2: [8878/10940] ---- BYOL Training Loss = 0.2863718867301941
30-01-2023 20:50:40 INFO Epoch 2: [8889/10940] ---- BYOL Training Loss = 0.2720452547073364
30-01-2023 20:51:33 INFO Epoch 2: [8889/10940] ---- BYOL Validation Loss = 0.272828608751297
30-01-2023 20:51:51 INFO Epoch 2: [8900/10940] ---- BYOL Training Loss = 0.32054880261421204
30-01-2023 20:52:09 INFO Epoch 2: [8911/10940] ---- BYOL Training Loss = 0.2893741726875305
30-01-2023 20:52:28 INFO Epoch 2: [8922/10940] ---- BYOL Training Loss = 0.2573530077934265
30-01-2023 20:52:46 INFO Epoch 2: [8933/10940] ---- BYOL Training Loss = 0.25370118021965027
30-01-2023 20:53:38 INFO Epoch 2: [8933/10940] ---- BYOL Validation Loss = 0.27553296089172363
30-01-2023 20:53:56 INFO Epoch 2: [8944/10940] ---- BYOL Training Loss = 0.3100755512714386
30-01-2023 20:54:15 INFO Epoch 2: [8955/10940] ---- BYOL Training Loss = 0.31408870220184326
30-01-2023 20:54:33 INFO Epoch 2: [8966/10940] ---- BYOL Training Loss = 0.33183616399765015
30-01-2023 20:54:51 INFO Epoch 2: [8977/10940] ---- BYOL Training Loss = 0.35548755526542664
30-01-2023 20:55:44 INFO Epoch 2: [8977/10940] ---- BYOL Validation Loss = 0.27127549052238464
30-01-2023 20:56:02 INFO Epoch 2: [8988/10940] ---- BYOL Training Loss = 0.32394471764564514
30-01-2023 20:56:20 INFO Epoch 2: [8999/10940] ---- BYOL Training Loss = 0.27218687534332275
30-01-2023 20:56:39 INFO Epoch 2: [9010/10940] ---- BYOL Training Loss = 0.2490944117307663
30-01-2023 20:56:57 INFO Epoch 2: [9021/10940] ---- BYOL Training Loss = 0.24137575924396515
30-01-2023 20:57:50 INFO Epoch 2: [9021/10940] ---- BYOL Validation Loss = 0.26152274012565613
30-01-2023 20:58:08 INFO Epoch 2: [9032/10940] ---- BYOL Training Loss = 0.2679005265235901
30-01-2023 20:58:26 INFO Epoch 2: [9043/10940] ---- BYOL Training Loss = 0.28498131036758423
30-01-2023 20:58:45 INFO Epoch 2: [9054/10940] ---- BYOL Training Loss = 0.2497648298740387
30-01-2023 20:59:03 INFO Epoch 2: [9065/10940] ---- BYOL Training Loss = 0.26486214995384216
30-01-2023 20:59:56 INFO Epoch 2: [9065/10940] ---- BYOL Validation Loss = 0.28030234575271606
30-01-2023 21:00:14 INFO Epoch 2: [9076/10940] ---- BYOL Training Loss = 0.28017282485961914
30-01-2023 21:00:32 INFO Epoch 2: [9087/10940] ---- BYOL Training Loss = 0.28984761238098145
30-01-2023 21:00:51 INFO Epoch 2: [9098/10940] ---- BYOL Training Loss = 0.2564147710800171
30-01-2023 21:01:09 INFO Epoch 2: [9109/10940] ---- BYOL Training Loss = 0.25456029176712036
30-01-2023 21:02:01 INFO Epoch 2: [9109/10940] ---- BYOL Validation Loss = 0.27678364515304565
30-01-2023 21:02:19 INFO Epoch 2: [9120/10940] ---- BYOL Training Loss = 0.30902552604675293
30-01-2023 21:02:38 INFO Epoch 2: [9131/10940] ---- BYOL Training Loss = 0.30690476298332214
30-01-2023 21:02:56 INFO Epoch 2: [9142/10940] ---- BYOL Training Loss = 0.33563750982284546
30-01-2023 21:03:15 INFO Epoch 2: [9153/10940] ---- BYOL Training Loss = 0.30672940611839294
30-01-2023 21:04:07 INFO Epoch 2: [9153/10940] ---- BYOL Validation Loss = 0.2630651295185089
30-01-2023 21:04:25 INFO Epoch 2: [9164/10940] ---- BYOL Training Loss = 0.32431986927986145
30-01-2023 21:04:43 INFO Epoch 2: [9175/10940] ---- BYOL Training Loss = 0.3071104884147644
30-01-2023 21:05:02 INFO Epoch 2: [9186/10940] ---- BYOL Training Loss = 0.2545950412750244
30-01-2023 21:05:20 INFO Epoch 2: [9197/10940] ---- BYOL Training Loss = 0.25883588194847107
30-01-2023 21:06:13 INFO Epoch 2: [9197/10940] ---- BYOL Validation Loss = 0.2640068829059601
30-01-2023 21:06:31 INFO Epoch 2: [9208/10940] ---- BYOL Training Loss = 0.26646435260772705
30-01-2023 21:06:49 INFO Epoch 2: [9219/10940] ---- BYOL Training Loss = 0.26027220487594604
30-01-2023 21:07:08 INFO Epoch 2: [9230/10940] ---- BYOL Training Loss = 0.2818799614906311
30-01-2023 21:07:26 INFO Epoch 2: [9241/10940] ---- BYOL Training Loss = 0.29494842886924744
30-01-2023 21:08:18 INFO Epoch 2: [9241/10940] ---- BYOL Validation Loss = 0.266259104013443
30-01-2023 21:08:36 INFO Epoch 2: [9252/10940] ---- BYOL Training Loss = 0.26793625950813293
30-01-2023 21:08:55 INFO Epoch 2: [9263/10940] ---- BYOL Training Loss = 0.26830536127090454
30-01-2023 21:09:13 INFO Epoch 2: [9274/10940] ---- BYOL Training Loss = 0.2929798662662506
30-01-2023 21:09:32 INFO Epoch 2: [9285/10940] ---- BYOL Training Loss = 0.27214735746383667
30-01-2023 21:10:24 INFO Epoch 2: [9285/10940] ---- BYOL Validation Loss = 0.2669983506202698
30-01-2023 21:10:42 INFO Epoch 2: [9296/10940] ---- BYOL Training Loss = 0.25952884554862976
30-01-2023 21:11:01 INFO Epoch 2: [9307/10940] ---- BYOL Training Loss = 0.25339004397392273
30-01-2023 21:11:19 INFO Epoch 2: [9318/10940] ---- BYOL Training Loss = 0.2660894989967346
30-01-2023 21:11:38 INFO Epoch 2: [9329/10940] ---- BYOL Training Loss = 0.26664528250694275
30-01-2023 21:12:30 INFO Epoch 2: [9329/10940] ---- BYOL Validation Loss = 0.26369649171829224
30-01-2023 21:12:48 INFO Epoch 2: [9340/10940] ---- BYOL Training Loss = 0.2553016245365143
30-01-2023 21:13:07 INFO Epoch 2: [9351/10940] ---- BYOL Training Loss = 0.2933482229709625
30-01-2023 21:13:25 INFO Epoch 2: [9362/10940] ---- BYOL Training Loss = 0.31501325964927673
30-01-2023 21:13:44 INFO Epoch 2: [9373/10940] ---- BYOL Training Loss = 0.27704936265945435
30-01-2023 21:14:36 INFO Epoch 2: [9373/10940] ---- BYOL Validation Loss = 0.27821069955825806
30-01-2023 21:14:54 INFO Epoch 2: [9384/10940] ---- BYOL Training Loss = 0.270906537771225
30-01-2023 21:15:13 INFO Epoch 2: [9395/10940] ---- BYOL Training Loss = 0.3170276880264282
30-01-2023 21:15:31 INFO Epoch 2: [9406/10940] ---- BYOL Training Loss = 0.3015459179878235
30-01-2023 21:15:50 INFO Epoch 2: [9417/10940] ---- BYOL Training Loss = 0.2856377363204956
30-01-2023 21:16:42 INFO Epoch 2: [9417/10940] ---- BYOL Validation Loss = 0.27947893738746643
30-01-2023 21:17:00 INFO Epoch 2: [9428/10940] ---- BYOL Training Loss = 0.3275795876979828
30-01-2023 21:17:19 INFO Epoch 2: [9439/10940] ---- BYOL Training Loss = 0.3173518776893616
30-01-2023 21:17:37 INFO Epoch 2: [9450/10940] ---- BYOL Training Loss = 0.2750707268714905
30-01-2023 21:17:56 INFO Epoch 2: [9461/10940] ---- BYOL Training Loss = 0.24165353178977966
30-01-2023 21:18:48 INFO Epoch 2: [9461/10940] ---- BYOL Validation Loss = 0.2714199125766754
30-01-2023 21:19:06 INFO Epoch 2: [9472/10940] ---- BYOL Training Loss = 0.271761953830719
30-01-2023 21:19:24 INFO Epoch 2: [9483/10940] ---- BYOL Training Loss = 0.30125051736831665
30-01-2023 21:19:43 INFO Epoch 2: [9494/10940] ---- BYOL Training Loss = 0.2927023768424988
30-01-2023 21:20:01 INFO Epoch 2: [9505/10940] ---- BYOL Training Loss = 0.2942517399787903
30-01-2023 21:20:54 INFO Epoch 2: [9505/10940] ---- BYOL Validation Loss = 0.2613377869129181
30-01-2023 21:21:12 INFO Epoch 2: [9516/10940] ---- BYOL Training Loss = 0.2545609772205353
30-01-2023 21:21:30 INFO Epoch 2: [9527/10940] ---- BYOL Training Loss = 0.25636613368988037
30-01-2023 21:21:49 INFO Epoch 2: [9538/10940] ---- BYOL Training Loss = 0.3208840489387512
30-01-2023 21:22:07 INFO Epoch 2: [9549/10940] ---- BYOL Training Loss = 0.29932501912117004
30-01-2023 21:23:00 INFO Epoch 2: [9549/10940] ---- BYOL Validation Loss = 0.2655600607395172
30-01-2023 21:23:18 INFO Epoch 2: [9560/10940] ---- BYOL Training Loss = 0.2879938781261444
30-01-2023 21:23:36 INFO Epoch 2: [9571/10940] ---- BYOL Training Loss = 0.3243022859096527
30-01-2023 21:23:55 INFO Epoch 2: [9582/10940] ---- BYOL Training Loss = 0.30773016810417175
30-01-2023 21:24:13 INFO Epoch 2: [9593/10940] ---- BYOL Training Loss = 0.290902316570282
30-01-2023 21:25:05 INFO Epoch 2: [9593/10940] ---- BYOL Validation Loss = 0.2650969624519348
30-01-2023 21:25:24 INFO Epoch 2: [9604/10940] ---- BYOL Training Loss = 0.31350767612457275
30-01-2023 21:25:42 INFO Epoch 2: [9615/10940] ---- BYOL Training Loss = 0.2827877104282379
30-01-2023 21:26:01 INFO Epoch 2: [9626/10940] ---- BYOL Training Loss = 0.2971685528755188
30-01-2023 21:26:19 INFO Epoch 2: [9637/10940] ---- BYOL Training Loss = 0.2981887459754944
30-01-2023 21:27:12 INFO Epoch 2: [9637/10940] ---- BYOL Validation Loss = 0.27072373032569885
30-01-2023 21:27:30 INFO Epoch 2: [9648/10940] ---- BYOL Training Loss = 0.27420705556869507
30-01-2023 21:27:48 INFO Epoch 2: [9659/10940] ---- BYOL Training Loss = 0.2657870650291443
30-01-2023 21:28:07 INFO Epoch 2: [9670/10940] ---- BYOL Training Loss = 0.2889396548271179
30-01-2023 21:28:26 INFO Epoch 2: [9681/10940] ---- BYOL Training Loss = 0.27806732058525085
30-01-2023 21:29:18 INFO Epoch 2: [9681/10940] ---- BYOL Validation Loss = 0.27215754985809326
30-01-2023 21:29:36 INFO Epoch 2: [9692/10940] ---- BYOL Training Loss = 0.29710444808006287
30-01-2023 21:29:54 INFO Epoch 2: [9703/10940] ---- BYOL Training Loss = 0.34587034583091736
30-01-2023 21:30:13 INFO Epoch 2: [9714/10940] ---- BYOL Training Loss = 0.3297748863697052
30-01-2023 21:30:31 INFO Epoch 2: [9725/10940] ---- BYOL Training Loss = 0.29251334071159363
30-01-2023 21:31:24 INFO Epoch 2: [9725/10940] ---- BYOL Validation Loss = 0.2634795308113098
30-01-2023 21:31:42 INFO Epoch 2: [9736/10940] ---- BYOL Training Loss = 0.2459639012813568
30-01-2023 21:32:00 INFO Epoch 2: [9747/10940] ---- BYOL Training Loss = 0.2692050039768219
30-01-2023 21:32:19 INFO Epoch 2: [9758/10940] ---- BYOL Training Loss = 0.3126777410507202
30-01-2023 21:32:37 INFO Epoch 2: [9769/10940] ---- BYOL Training Loss = 0.30823254585266113
30-01-2023 21:33:30 INFO Epoch 2: [9769/10940] ---- BYOL Validation Loss = 0.26908379793167114
30-01-2023 21:33:48 INFO Epoch 2: [9780/10940] ---- BYOL Training Loss = 0.27914100885391235
30-01-2023 21:34:06 INFO Epoch 2: [9791/10940] ---- BYOL Training Loss = 0.26829010248184204
30-01-2023 21:34:25 INFO Epoch 2: [9802/10940] ---- BYOL Training Loss = 0.2515239119529724
30-01-2023 21:34:43 INFO Epoch 2: [9813/10940] ---- BYOL Training Loss = 0.24647757411003113
30-01-2023 21:35:35 INFO Epoch 2: [9813/10940] ---- BYOL Validation Loss = 0.2631843090057373
30-01-2023 21:35:54 INFO Epoch 2: [9824/10940] ---- BYOL Training Loss = 0.29556724429130554
30-01-2023 21:36:12 INFO Epoch 2: [9835/10940] ---- BYOL Training Loss = 0.31455299258232117
30-01-2023 21:36:31 INFO Epoch 2: [9846/10940] ---- BYOL Training Loss = 0.2964802086353302
30-01-2023 21:36:49 INFO Epoch 2: [9857/10940] ---- BYOL Training Loss = 0.2820950150489807
30-01-2023 21:37:42 INFO Epoch 2: [9857/10940] ---- BYOL Validation Loss = 0.2606705129146576
30-01-2023 21:38:00 INFO Epoch 2: [9868/10940] ---- BYOL Training Loss = 0.26820623874664307
30-01-2023 21:38:18 INFO Epoch 2: [9879/10940] ---- BYOL Training Loss = 0.2665441930294037
30-01-2023 21:38:37 INFO Epoch 2: [9890/10940] ---- BYOL Training Loss = 0.28224027156829834
30-01-2023 21:38:56 INFO Epoch 2: [9901/10940] ---- BYOL Training Loss = 0.2874850034713745
30-01-2023 21:39:48 INFO Epoch 2: [9901/10940] ---- BYOL Validation Loss = 0.2680569291114807
30-01-2023 21:40:06 INFO Epoch 2: [9912/10940] ---- BYOL Training Loss = 0.3170667290687561
30-01-2023 21:40:24 INFO Epoch 2: [9923/10940] ---- BYOL Training Loss = 0.2509097754955292
30-01-2023 21:40:43 INFO Epoch 2: [9934/10940] ---- BYOL Training Loss = 0.226720929145813
30-01-2023 21:41:01 INFO Epoch 2: [9945/10940] ---- BYOL Training Loss = 0.22436591982841492
30-01-2023 21:41:54 INFO Epoch 2: [9945/10940] ---- BYOL Validation Loss = 0.25513842701911926
30-01-2023 21:42:12 INFO Epoch 2: [9956/10940] ---- BYOL Training Loss = 0.20654229819774628
30-01-2023 21:42:31 INFO Epoch 2: [9967/10940] ---- BYOL Training Loss = 0.23766359686851501
30-01-2023 21:42:49 INFO Epoch 2: [9978/10940] ---- BYOL Training Loss = 0.24491146206855774
30-01-2023 21:43:08 INFO Epoch 2: [9989/10940] ---- BYOL Training Loss = 0.2689829170703888
30-01-2023 21:44:00 INFO Epoch 2: [9989/10940] ---- BYOL Validation Loss = 0.26656395196914673
30-01-2023 21:44:18 INFO Epoch 2: [10000/10940] ---- BYOL Training Loss = 0.29655885696411133
30-01-2023 21:44:37 INFO Epoch 2: [10011/10940] ---- BYOL Training Loss = 0.27854782342910767
30-01-2023 21:44:55 INFO Epoch 2: [10022/10940] ---- BYOL Training Loss = 0.25214454531669617
30-01-2023 21:45:14 INFO Epoch 2: [10033/10940] ---- BYOL Training Loss = 0.31798797845840454
30-01-2023 21:46:06 INFO Epoch 2: [10033/10940] ---- BYOL Validation Loss = 0.26258230209350586
30-01-2023 21:46:24 INFO Epoch 2: [10044/10940] ---- BYOL Training Loss = 0.41368985176086426
30-01-2023 21:46:43 INFO Epoch 2: [10055/10940] ---- BYOL Training Loss = 0.33087077736854553
30-01-2023 21:47:01 INFO Epoch 2: [10066/10940] ---- BYOL Training Loss = 0.2731245160102844
30-01-2023 21:47:20 INFO Epoch 2: [10077/10940] ---- BYOL Training Loss = 0.27578240633010864
30-01-2023 21:48:12 INFO Epoch 2: [10077/10940] ---- BYOL Validation Loss = 0.2544548511505127
30-01-2023 21:48:30 INFO Epoch 2: [10088/10940] ---- BYOL Training Loss = 0.27085429430007935
30-01-2023 21:48:49 INFO Epoch 2: [10099/10940] ---- BYOL Training Loss = 0.26316729187965393
30-01-2023 21:49:07 INFO Epoch 2: [10110/10940] ---- BYOL Training Loss = 0.286276638507843
30-01-2023 21:49:26 INFO Epoch 2: [10121/10940] ---- BYOL Training Loss = 0.2636871039867401
30-01-2023 21:50:18 INFO Epoch 2: [10121/10940] ---- BYOL Validation Loss = 0.25911521911621094
30-01-2023 21:50:37 INFO Epoch 2: [10132/10940] ---- BYOL Training Loss = 0.2651706337928772
30-01-2023 21:50:55 INFO Epoch 2: [10143/10940] ---- BYOL Training Loss = 0.26720601320266724
30-01-2023 21:51:14 INFO Epoch 2: [10154/10940] ---- BYOL Training Loss = 0.2680358290672302
30-01-2023 21:51:32 INFO Epoch 2: [10165/10940] ---- BYOL Training Loss = 0.32172685861587524
30-01-2023 21:52:24 INFO Epoch 2: [10165/10940] ---- BYOL Validation Loss = 0.2525758147239685
30-01-2023 21:52:43 INFO Epoch 2: [10176/10940] ---- BYOL Training Loss = 0.3152870833873749
30-01-2023 21:53:01 INFO Epoch 2: [10187/10940] ---- BYOL Training Loss = 0.2840629518032074
30-01-2023 21:53:20 INFO Epoch 2: [10198/10940] ---- BYOL Training Loss = 0.27436116337776184
30-01-2023 21:53:39 INFO Epoch 2: [10209/10940] ---- BYOL Training Loss = 0.22826528549194336
30-01-2023 21:54:31 INFO Epoch 2: [10209/10940] ---- BYOL Validation Loss = 0.25714749097824097
30-01-2023 21:54:49 INFO Epoch 2: [10220/10940] ---- BYOL Training Loss = 0.2552415430545807
30-01-2023 21:55:08 INFO Epoch 2: [10231/10940] ---- BYOL Training Loss = 0.29362499713897705
30-01-2023 21:55:26 INFO Epoch 2: [10242/10940] ---- BYOL Training Loss = 0.266925573348999
30-01-2023 21:55:45 INFO Epoch 2: [10253/10940] ---- BYOL Training Loss = 0.28566938638687134
30-01-2023 21:56:37 INFO Epoch 2: [10253/10940] ---- BYOL Validation Loss = 0.2611263692378998
30-01-2023 21:56:55 INFO Epoch 2: [10264/10940] ---- BYOL Training Loss = 0.28720635175704956
30-01-2023 21:57:14 INFO Epoch 2: [10275/10940] ---- BYOL Training Loss = 0.23658430576324463
30-01-2023 21:57:33 INFO Epoch 2: [10286/10940] ---- BYOL Training Loss = 0.2842901349067688
30-01-2023 21:57:52 INFO Epoch 2: [10297/10940] ---- BYOL Training Loss = 0.2911462187767029
30-01-2023 21:58:44 INFO Epoch 2: [10297/10940] ---- BYOL Validation Loss = 0.2670885920524597
30-01-2023 21:59:02 INFO Epoch 2: [10308/10940] ---- BYOL Training Loss = 0.2622654438018799
30-01-2023 21:59:20 INFO Epoch 2: [10319/10940] ---- BYOL Training Loss = 0.2672606408596039
30-01-2023 21:59:39 INFO Epoch 2: [10330/10940] ---- BYOL Training Loss = 0.2702943980693817
30-01-2023 21:59:58 INFO Epoch 2: [10341/10940] ---- BYOL Training Loss = 0.30007970333099365
30-01-2023 22:00:50 INFO Epoch 2: [10341/10940] ---- BYOL Validation Loss = 0.26595228910446167
30-01-2023 22:01:08 INFO Epoch 2: [10352/10940] ---- BYOL Training Loss = 0.28533023595809937
30-01-2023 22:01:27 INFO Epoch 2: [10363/10940] ---- BYOL Training Loss = 0.26690512895584106
30-01-2023 22:01:46 INFO Epoch 2: [10374/10940] ---- BYOL Training Loss = 0.2686094641685486
30-01-2023 22:02:04 INFO Epoch 2: [10385/10940] ---- BYOL Training Loss = 0.27512088418006897
30-01-2023 22:02:57 INFO Epoch 2: [10385/10940] ---- BYOL Validation Loss = 0.2624606192111969
30-01-2023 22:03:15 INFO Epoch 2: [10396/10940] ---- BYOL Training Loss = 0.28831911087036133
30-01-2023 22:03:33 INFO Epoch 2: [10407/10940] ---- BYOL Training Loss = 0.2763313055038452
30-01-2023 22:03:52 INFO Epoch 2: [10418/10940] ---- BYOL Training Loss = 0.24736399948596954
30-01-2023 22:04:11 INFO Epoch 2: [10429/10940] ---- BYOL Training Loss = 0.24807541072368622
30-01-2023 22:05:03 INFO Epoch 2: [10429/10940] ---- BYOL Validation Loss = 0.25213590264320374
30-01-2023 22:05:21 INFO Epoch 2: [10440/10940] ---- BYOL Training Loss = 0.24517984688282013
30-01-2023 22:05:40 INFO Epoch 2: [10451/10940] ---- BYOL Training Loss = 0.25792190432548523
30-01-2023 22:05:59 INFO Epoch 2: [10462/10940] ---- BYOL Training Loss = 0.2924230098724365
30-01-2023 22:06:17 INFO Epoch 2: [10473/10940] ---- BYOL Training Loss = 0.2652474641799927
30-01-2023 22:07:09 INFO Epoch 2: [10473/10940] ---- BYOL Validation Loss = 0.26287856698036194
30-01-2023 22:07:28 INFO Epoch 2: [10484/10940] ---- BYOL Training Loss = 0.24269604682922363
30-01-2023 22:07:46 INFO Epoch 2: [10495/10940] ---- BYOL Training Loss = 0.31563106179237366
30-01-2023 22:08:05 INFO Epoch 2: [10506/10940] ---- BYOL Training Loss = 0.32238370180130005
30-01-2023 22:08:23 INFO Epoch 2: [10517/10940] ---- BYOL Training Loss = 0.27762138843536377
30-01-2023 22:09:16 INFO Epoch 2: [10517/10940] ---- BYOL Validation Loss = 0.2538510262966156
30-01-2023 22:09:34 INFO Epoch 2: [10528/10940] ---- BYOL Training Loss = 0.3252165913581848
30-01-2023 22:09:53 INFO Epoch 2: [10539/10940] ---- BYOL Training Loss = 0.3005547523498535
30-01-2023 22:10:12 INFO Epoch 2: [10550/10940] ---- BYOL Training Loss = 0.3062066435813904
30-01-2023 22:10:30 INFO Epoch 2: [10561/10940] ---- BYOL Training Loss = 0.31076377630233765
30-01-2023 22:11:22 INFO Epoch 2: [10561/10940] ---- BYOL Validation Loss = 0.2600262761116028
30-01-2023 22:11:41 INFO Epoch 2: [10572/10940] ---- BYOL Training Loss = 0.2923734486103058
30-01-2023 22:12:00 INFO Epoch 2: [10583/10940] ---- BYOL Training Loss = 0.2451460063457489
30-01-2023 22:12:18 INFO Epoch 2: [10594/10940] ---- BYOL Training Loss = 0.26179689168930054
30-01-2023 22:12:37 INFO Epoch 2: [10605/10940] ---- BYOL Training Loss = 0.25923416018486023
30-01-2023 22:13:29 INFO Epoch 2: [10605/10940] ---- BYOL Validation Loss = 0.26375332474708557
30-01-2023 22:13:47 INFO Epoch 2: [10616/10940] ---- BYOL Training Loss = 0.31271252036094666
30-01-2023 22:14:06 INFO Epoch 2: [10627/10940] ---- BYOL Training Loss = 0.33888164162635803
30-01-2023 22:14:25 INFO Epoch 2: [10638/10940] ---- BYOL Training Loss = 0.3016483187675476
30-01-2023 22:14:43 INFO Epoch 2: [10649/10940] ---- BYOL Training Loss = 0.29773491621017456
30-01-2023 22:15:36 INFO Epoch 2: [10649/10940] ---- BYOL Validation Loss = 0.2557636797428131
30-01-2023 22:15:54 INFO Epoch 2: [10660/10940] ---- BYOL Training Loss = 0.2663688063621521
30-01-2023 22:16:12 INFO Epoch 2: [10671/10940] ---- BYOL Training Loss = 0.25433117151260376
30-01-2023 22:16:31 INFO Epoch 2: [10682/10940] ---- BYOL Training Loss = 0.2706795632839203
30-01-2023 22:16:50 INFO Epoch 2: [10693/10940] ---- BYOL Training Loss = 0.2813020348548889
30-01-2023 22:17:42 INFO Epoch 2: [10693/10940] ---- BYOL Validation Loss = 0.2614831328392029
30-01-2023 22:18:01 INFO Epoch 2: [10704/10940] ---- BYOL Training Loss = 0.27607741951942444
30-01-2023 22:18:19 INFO Epoch 2: [10715/10940] ---- BYOL Training Loss = 0.22768473625183105
30-01-2023 22:18:38 INFO Epoch 2: [10726/10940] ---- BYOL Training Loss = 0.279441237449646
30-01-2023 22:18:56 INFO Epoch 2: [10737/10940] ---- BYOL Training Loss = 0.29430779814720154
30-01-2023 22:19:49 INFO Epoch 2: [10737/10940] ---- BYOL Validation Loss = 0.261656790971756
30-01-2023 22:20:07 INFO Epoch 2: [10748/10940] ---- BYOL Training Loss = 0.3110962510108948
30-01-2023 22:20:25 INFO Epoch 2: [10759/10940] ---- BYOL Training Loss = 0.3043939769268036
30-01-2023 22:20:44 INFO Epoch 2: [10770/10940] ---- BYOL Training Loss = 0.2638580799102783
30-01-2023 22:21:03 INFO Epoch 2: [10781/10940] ---- BYOL Training Loss = 0.2938675284385681
30-01-2023 22:21:55 INFO Epoch 2: [10781/10940] ---- BYOL Validation Loss = 0.2562560439109802
30-01-2023 22:22:13 INFO Epoch 2: [10792/10940] ---- BYOL Training Loss = 0.2889041006565094
30-01-2023 22:22:32 INFO Epoch 2: [10803/10940] ---- BYOL Training Loss = 0.28337833285331726
30-01-2023 22:22:50 INFO Epoch 2: [10814/10940] ---- BYOL Training Loss = 0.2700216472148895
30-01-2023 22:23:09 INFO Epoch 2: [10825/10940] ---- BYOL Training Loss = 0.2613505721092224
30-01-2023 22:24:02 INFO Epoch 2: [10825/10940] ---- BYOL Validation Loss = 0.2729893922805786
30-01-2023 22:24:20 INFO Epoch 2: [10836/10940] ---- BYOL Training Loss = 0.30144038796424866
30-01-2023 22:24:38 INFO Epoch 2: [10847/10940] ---- BYOL Training Loss = 0.2874191999435425
30-01-2023 22:24:57 INFO Epoch 2: [10858/10940] ---- BYOL Training Loss = 0.27803775668144226
30-01-2023 22:25:15 INFO Epoch 2: [10869/10940] ---- BYOL Training Loss = 0.2732837200164795
30-01-2023 22:26:08 INFO Epoch 2: [10869/10940] ---- BYOL Validation Loss = 0.27291879057884216
30-01-2023 22:26:26 INFO Epoch 2: [10880/10940] ---- BYOL Training Loss = 0.28794145584106445
30-01-2023 22:26:45 INFO Epoch 2: [10891/10940] ---- BYOL Training Loss = 0.3091508150100708
30-01-2023 22:27:03 INFO Epoch 2: [10902/10940] ---- BYOL Training Loss = 0.31066808104515076
30-01-2023 22:27:22 INFO Epoch 2: [10913/10940] ---- BYOL Training Loss = 0.33003896474838257
30-01-2023 22:28:14 INFO Epoch 2: [10913/10940] ---- BYOL Validation Loss = 0.27267584204673767
30-01-2023 22:28:32 INFO Epoch 2: [10924/10940] ---- BYOL Training Loss = 0.3207259774208069
30-01-2023 22:28:51 INFO Epoch 2: [10935/10940] ---- BYOL Training Loss = 0.24790707230567932
30-01-2023 22:29:00 INFO Starting Epoch: 3
30-01-2023 22:29:18 INFO Epoch 3: [12/10940] ---- BYOL Training Loss = 0.36827072501182556
30-01-2023 22:29:36 INFO Epoch 3: [23/10940] ---- BYOL Training Loss = 0.3364173471927643
30-01-2023 22:29:54 INFO Epoch 3: [34/10940] ---- BYOL Training Loss = 0.273630827665329
30-01-2023 22:30:11 INFO Epoch 3: [45/10940] ---- BYOL Training Loss = 0.3120066225528717
30-01-2023 22:31:03 INFO Epoch 3: [45/10940] ---- BYOL Validation Loss = 0.26808273792266846
30-01-2023 22:31:21 INFO Epoch 3: [56/10940] ---- BYOL Training Loss = 0.3061128854751587
30-01-2023 22:31:38 INFO Epoch 3: [67/10940] ---- BYOL Training Loss = 0.21686573326587677
30-01-2023 22:31:56 INFO Epoch 3: [78/10940] ---- BYOL Training Loss = 0.23307958245277405
30-01-2023 22:32:13 INFO Epoch 3: [89/10940] ---- BYOL Training Loss = 0.25478750467300415
30-01-2023 22:33:06 INFO Epoch 3: [89/10940] ---- BYOL Validation Loss = 0.26101189851760864
30-01-2023 22:33:23 INFO Epoch 3: [100/10940] ---- BYOL Training Loss = 0.26100102066993713
30-01-2023 22:33:40 INFO Epoch 3: [111/10940] ---- BYOL Training Loss = 0.2866218686103821
30-01-2023 22:33:58 INFO Epoch 3: [122/10940] ---- BYOL Training Loss = 0.29819896817207336
30-01-2023 22:34:15 INFO Epoch 3: [133/10940] ---- BYOL Training Loss = 0.304455041885376
30-01-2023 22:35:07 INFO Epoch 3: [133/10940] ---- BYOL Validation Loss = 0.25382891297340393
30-01-2023 22:35:25 INFO Epoch 3: [144/10940] ---- BYOL Training Loss = 0.2482018917798996
30-01-2023 22:35:42 INFO Epoch 3: [155/10940] ---- BYOL Training Loss = 0.23700234293937683
30-01-2023 22:35:59 INFO Epoch 3: [166/10940] ---- BYOL Training Loss = 0.26918888092041016
30-01-2023 22:36:17 INFO Epoch 3: [177/10940] ---- BYOL Training Loss = 0.3126886487007141
30-01-2023 22:37:09 INFO Epoch 3: [177/10940] ---- BYOL Validation Loss = 0.2658393681049347
30-01-2023 22:37:26 INFO Epoch 3: [188/10940] ---- BYOL Training Loss = 0.31376761198043823
30-01-2023 22:37:44 INFO Epoch 3: [199/10940] ---- BYOL Training Loss = 0.2521609663963318
30-01-2023 22:38:01 INFO Epoch 3: [210/10940] ---- BYOL Training Loss = 0.26254013180732727
30-01-2023 22:38:19 INFO Epoch 3: [221/10940] ---- BYOL Training Loss = 0.23695433139801025
30-01-2023 22:39:11 INFO Epoch 3: [221/10940] ---- BYOL Validation Loss = 0.25592347979545593
30-01-2023 22:39:28 INFO Epoch 3: [232/10940] ---- BYOL Training Loss = 0.24704179167747498
30-01-2023 22:39:46 INFO Epoch 3: [243/10940] ---- BYOL Training Loss = 0.27203670144081116
30-01-2023 22:40:03 INFO Epoch 3: [254/10940] ---- BYOL Training Loss = 0.27338266372680664
30-01-2023 22:40:21 INFO Epoch 3: [265/10940] ---- BYOL Training Loss = 0.2513287365436554
30-01-2023 22:41:13 INFO Epoch 3: [265/10940] ---- BYOL Validation Loss = 0.2529941201210022
30-01-2023 22:41:30 INFO Epoch 3: [276/10940] ---- BYOL Training Loss = 0.19108310341835022
30-01-2023 22:41:48 INFO Epoch 3: [287/10940] ---- BYOL Training Loss = 0.21198931336402893
30-01-2023 22:42:05 INFO Epoch 3: [298/10940] ---- BYOL Training Loss = 0.2781277894973755
30-01-2023 22:42:23 INFO Epoch 3: [309/10940] ---- BYOL Training Loss = 0.244905024766922
30-01-2023 22:43:15 INFO Epoch 3: [309/10940] ---- BYOL Validation Loss = 0.25483283400535583
30-01-2023 22:43:32 INFO Epoch 3: [320/10940] ---- BYOL Training Loss = 0.20273837447166443
30-01-2023 22:43:50 INFO Epoch 3: [331/10940] ---- BYOL Training Loss = 0.24920789897441864
30-01-2023 22:44:07 INFO Epoch 3: [342/10940] ---- BYOL Training Loss = 0.26250120997428894
30-01-2023 22:44:25 INFO Epoch 3: [353/10940] ---- BYOL Training Loss = 0.24858157336711884
30-01-2023 22:45:17 INFO Epoch 3: [353/10940] ---- BYOL Validation Loss = 0.24939404428005219
30-01-2023 22:45:34 INFO Epoch 3: [364/10940] ---- BYOL Training Loss = 0.22142072021961212
30-01-2023 22:45:52 INFO Epoch 3: [375/10940] ---- BYOL Training Loss = 0.29227009415626526
30-01-2023 22:46:09 INFO Epoch 3: [386/10940] ---- BYOL Training Loss = 0.3003692030906677
30-01-2023 22:46:27 INFO Epoch 3: [397/10940] ---- BYOL Training Loss = 0.25777706503868103
30-01-2023 22:47:19 INFO Epoch 3: [397/10940] ---- BYOL Validation Loss = 0.24891409277915955
30-01-2023 22:47:36 INFO Epoch 3: [408/10940] ---- BYOL Training Loss = 0.2446552962064743
30-01-2023 22:47:54 INFO Epoch 3: [419/10940] ---- BYOL Training Loss = 0.23375360667705536
30-01-2023 22:48:11 INFO Epoch 3: [430/10940] ---- BYOL Training Loss = 0.24109096825122833
30-01-2023 22:48:29 INFO Epoch 3: [441/10940] ---- BYOL Training Loss = 0.255793035030365
30-01-2023 22:49:21 INFO Epoch 3: [441/10940] ---- BYOL Validation Loss = 0.2472262680530548
30-01-2023 22:49:38 INFO Epoch 3: [452/10940] ---- BYOL Training Loss = 0.275945246219635
30-01-2023 22:49:56 INFO Epoch 3: [463/10940] ---- BYOL Training Loss = 0.25007757544517517
30-01-2023 22:50:13 INFO Epoch 3: [474/10940] ---- BYOL Training Loss = 0.29093870520591736
30-01-2023 22:50:31 INFO Epoch 3: [485/10940] ---- BYOL Training Loss = 0.30043402314186096
30-01-2023 22:51:23 INFO Epoch 3: [485/10940] ---- BYOL Validation Loss = 0.24666941165924072
30-01-2023 22:51:40 INFO Epoch 3: [496/10940] ---- BYOL Training Loss = 0.2703733742237091
30-01-2023 22:51:58 INFO Epoch 3: [507/10940] ---- BYOL Training Loss = 0.2923501133918762
30-01-2023 22:52:16 INFO Epoch 3: [518/10940] ---- BYOL Training Loss = 0.2689840793609619
30-01-2023 22:52:33 INFO Epoch 3: [529/10940] ---- BYOL Training Loss = 0.2835973799228668
30-01-2023 22:53:25 INFO Epoch 3: [529/10940] ---- BYOL Validation Loss = 0.24581687152385712
30-01-2023 22:53:43 INFO Epoch 3: [540/10940] ---- BYOL Training Loss = 0.2955425977706909
30-01-2023 22:54:00 INFO Epoch 3: [551/10940] ---- BYOL Training Loss = 0.24786846339702606
30-01-2023 22:54:18 INFO Epoch 3: [562/10940] ---- BYOL Training Loss = 0.2331777811050415
30-01-2023 22:54:35 INFO Epoch 3: [573/10940] ---- BYOL Training Loss = 0.2622327506542206
30-01-2023 22:55:27 INFO Epoch 3: [573/10940] ---- BYOL Validation Loss = 0.25855356454849243
30-01-2023 22:55:45 INFO Epoch 3: [584/10940] ---- BYOL Training Loss = 0.2640843689441681
30-01-2023 22:56:02 INFO Epoch 3: [595/10940] ---- BYOL Training Loss = 0.21833506226539612
30-01-2023 22:56:20 INFO Epoch 3: [606/10940] ---- BYOL Training Loss = 0.25638583302497864
30-01-2023 22:56:37 INFO Epoch 3: [617/10940] ---- BYOL Training Loss = 0.264502614736557
30-01-2023 22:57:30 INFO Epoch 3: [617/10940] ---- BYOL Validation Loss = 0.2534264028072357
30-01-2023 22:57:47 INFO Epoch 3: [628/10940] ---- BYOL Training Loss = 0.2655240595340729
30-01-2023 22:58:04 INFO Epoch 3: [639/10940] ---- BYOL Training Loss = 0.23264341056346893
30-01-2023 22:58:22 INFO Epoch 3: [650/10940] ---- BYOL Training Loss = 0.20729891955852509
30-01-2023 22:58:39 INFO Epoch 3: [661/10940] ---- BYOL Training Loss = 0.22825655341148376
30-01-2023 22:59:32 INFO Epoch 3: [661/10940] ---- BYOL Validation Loss = 0.25200310349464417
30-01-2023 22:59:49 INFO Epoch 3: [672/10940] ---- BYOL Training Loss = 0.2345808446407318
30-01-2023 23:00:06 INFO Epoch 3: [683/10940] ---- BYOL Training Loss = 0.2649882733821869
30-01-2023 23:00:24 INFO Epoch 3: [694/10940] ---- BYOL Training Loss = 0.2692834734916687
30-01-2023 23:00:42 INFO Epoch 3: [705/10940] ---- BYOL Training Loss = 0.26462846994400024
30-01-2023 23:01:34 INFO Epoch 3: [705/10940] ---- BYOL Validation Loss = 0.24638864398002625
30-01-2023 23:01:51 INFO Epoch 3: [716/10940] ---- BYOL Training Loss = 0.27737531065940857
30-01-2023 23:02:09 INFO Epoch 3: [727/10940] ---- BYOL Training Loss = 0.2722577750682831
30-01-2023 23:02:26 INFO Epoch 3: [738/10940] ---- BYOL Training Loss = 0.263782799243927
30-01-2023 23:02:44 INFO Epoch 3: [749/10940] ---- BYOL Training Loss = 0.22320270538330078
30-01-2023 23:03:36 INFO Epoch 3: [749/10940] ---- BYOL Validation Loss = 0.2539081275463104
30-01-2023 23:03:53 INFO Epoch 3: [760/10940] ---- BYOL Training Loss = 0.21486219763755798
30-01-2023 23:04:11 INFO Epoch 3: [771/10940] ---- BYOL Training Loss = 0.20683637261390686
30-01-2023 23:04:29 INFO Epoch 3: [782/10940] ---- BYOL Training Loss = 0.2105066478252411
30-01-2023 23:04:46 INFO Epoch 3: [793/10940] ---- BYOL Training Loss = 0.28250426054000854
30-01-2023 23:05:38 INFO Epoch 3: [793/10940] ---- BYOL Validation Loss = 0.24410425126552582
30-01-2023 23:05:56 INFO Epoch 3: [804/10940] ---- BYOL Training Loss = 0.31003281474113464
30-01-2023 23:06:13 INFO Epoch 3: [815/10940] ---- BYOL Training Loss = 0.3141726553440094
30-01-2023 23:06:31 INFO Epoch 3: [826/10940] ---- BYOL Training Loss = 0.2614189684391022
30-01-2023 23:06:48 INFO Epoch 3: [837/10940] ---- BYOL Training Loss = 0.25791624188423157
30-01-2023 23:07:41 INFO Epoch 3: [837/10940] ---- BYOL Validation Loss = 0.24508237838745117
30-01-2023 23:07:58 INFO Epoch 3: [848/10940] ---- BYOL Training Loss = 0.26075655221939087
30-01-2023 23:08:16 INFO Epoch 3: [859/10940] ---- BYOL Training Loss = 0.239173024892807
30-01-2023 23:08:33 INFO Epoch 3: [870/10940] ---- BYOL Training Loss = 0.2151350975036621
30-01-2023 23:08:51 INFO Epoch 3: [881/10940] ---- BYOL Training Loss = 0.2091713398694992
30-01-2023 23:09:43 INFO Epoch 3: [881/10940] ---- BYOL Validation Loss = 0.24465696513652802
30-01-2023 23:10:00 INFO Epoch 3: [892/10940] ---- BYOL Training Loss = 0.25072410702705383
30-01-2023 23:10:18 INFO Epoch 3: [903/10940] ---- BYOL Training Loss = 0.2827286720275879
30-01-2023 23:10:36 INFO Epoch 3: [914/10940] ---- BYOL Training Loss = 0.24993011355400085
30-01-2023 23:10:53 INFO Epoch 3: [925/10940] ---- BYOL Training Loss = 0.2766548693180084
30-01-2023 23:11:45 INFO Epoch 3: [925/10940] ---- BYOL Validation Loss = 0.24955415725708008
30-01-2023 23:12:03 INFO Epoch 3: [936/10940] ---- BYOL Training Loss = 0.27689993381500244
30-01-2023 23:12:20 INFO Epoch 3: [947/10940] ---- BYOL Training Loss = 0.24468927085399628
30-01-2023 23:12:38 INFO Epoch 3: [958/10940] ---- BYOL Training Loss = 0.25660231709480286
30-01-2023 23:12:55 INFO Epoch 3: [969/10940] ---- BYOL Training Loss = 0.24053294956684113
30-01-2023 23:13:48 INFO Epoch 3: [969/10940] ---- BYOL Validation Loss = 0.24395619332790375
30-01-2023 23:14:05 INFO Epoch 3: [980/10940] ---- BYOL Training Loss = 0.24682430922985077
30-01-2023 23:14:22 INFO Epoch 3: [991/10940] ---- BYOL Training Loss = 0.26135995984077454
30-01-2023 23:14:40 INFO Epoch 3: [1002/10940] ---- BYOL Training Loss = 0.2826910614967346
30-01-2023 23:14:58 INFO Epoch 3: [1013/10940] ---- BYOL Training Loss = 0.24647128582000732
30-01-2023 23:15:50 INFO Epoch 3: [1013/10940] ---- BYOL Validation Loss = 0.24342134594917297
30-01-2023 23:16:07 INFO Epoch 3: [1024/10940] ---- BYOL Training Loss = 0.2523372769355774
30-01-2023 23:16:25 INFO Epoch 3: [1035/10940] ---- BYOL Training Loss = 0.2580474615097046
30-01-2023 23:16:42 INFO Epoch 3: [1046/10940] ---- BYOL Training Loss = 0.2723037600517273
30-01-2023 23:17:00 INFO Epoch 3: [1057/10940] ---- BYOL Training Loss = 0.2878742218017578
30-01-2023 23:17:52 INFO Epoch 3: [1057/10940] ---- BYOL Validation Loss = 0.2495620995759964
30-01-2023 23:18:10 INFO Epoch 3: [1068/10940] ---- BYOL Training Loss = 0.26606401801109314
30-01-2023 23:18:27 INFO Epoch 3: [1079/10940] ---- BYOL Training Loss = 0.2519811987876892
30-01-2023 23:18:45 INFO Epoch 3: [1090/10940] ---- BYOL Training Loss = 0.22195520997047424
30-01-2023 23:19:02 INFO Epoch 3: [1101/10940] ---- BYOL Training Loss = 0.21440379321575165
30-01-2023 23:19:55 INFO Epoch 3: [1101/10940] ---- BYOL Validation Loss = 0.2465895265340805
30-01-2023 23:20:12 INFO Epoch 3: [1112/10940] ---- BYOL Training Loss = 0.21548163890838623
30-01-2023 23:20:30 INFO Epoch 3: [1123/10940] ---- BYOL Training Loss = 0.21855345368385315
30-01-2023 23:20:47 INFO Epoch 3: [1134/10940] ---- BYOL Training Loss = 0.23004977405071259
30-01-2023 23:21:05 INFO Epoch 3: [1145/10940] ---- BYOL Training Loss = 0.21482761204242706
30-01-2023 23:21:57 INFO Epoch 3: [1145/10940] ---- BYOL Validation Loss = 0.25341957807540894
30-01-2023 23:22:14 INFO Epoch 3: [1156/10940] ---- BYOL Training Loss = 0.18083682656288147
30-01-2023 23:22:32 INFO Epoch 3: [1167/10940] ---- BYOL Training Loss = 0.21200788021087646
30-01-2023 23:22:49 INFO Epoch 3: [1178/10940] ---- BYOL Training Loss = 0.2660548985004425
30-01-2023 23:23:07 INFO Epoch 3: [1189/10940] ---- BYOL Training Loss = 0.2954663634300232
30-01-2023 23:23:59 INFO Epoch 3: [1189/10940] ---- BYOL Validation Loss = 0.2512490451335907
30-01-2023 23:24:17 INFO Epoch 3: [1200/10940] ---- BYOL Training Loss = 0.29299432039260864
30-01-2023 23:24:35 INFO Epoch 3: [1211/10940] ---- BYOL Training Loss = 0.28393012285232544
30-01-2023 23:24:52 INFO Epoch 3: [1222/10940] ---- BYOL Training Loss = 0.2966190278530121
30-01-2023 23:25:10 INFO Epoch 3: [1233/10940] ---- BYOL Training Loss = 0.32848668098449707
30-01-2023 23:26:02 INFO Epoch 3: [1233/10940] ---- BYOL Validation Loss = 0.2587677538394928
30-01-2023 23:26:19 INFO Epoch 3: [1244/10940] ---- BYOL Training Loss = 0.3011432886123657
30-01-2023 23:26:37 INFO Epoch 3: [1255/10940] ---- BYOL Training Loss = 0.29915356636047363
30-01-2023 23:26:55 INFO Epoch 3: [1266/10940] ---- BYOL Training Loss = 0.2967503070831299
30-01-2023 23:27:12 INFO Epoch 3: [1277/10940] ---- BYOL Training Loss = 0.25660163164138794
30-01-2023 23:28:05 INFO Epoch 3: [1277/10940] ---- BYOL Validation Loss = 0.26606568694114685
30-01-2023 23:28:22 INFO Epoch 3: [1288/10940] ---- BYOL Training Loss = 0.26586195826530457
30-01-2023 23:28:40 INFO Epoch 3: [1299/10940] ---- BYOL Training Loss = 0.24237456917762756
30-01-2023 23:28:57 INFO Epoch 3: [1310/10940] ---- BYOL Training Loss = 0.23608358204364777
30-01-2023 23:29:15 INFO Epoch 3: [1321/10940] ---- BYOL Training Loss = 0.2640702426433563
30-01-2023 23:30:07 INFO Epoch 3: [1321/10940] ---- BYOL Validation Loss = 0.24782928824424744
30-01-2023 23:30:24 INFO Epoch 3: [1332/10940] ---- BYOL Training Loss = 0.23486419022083282
30-01-2023 23:30:42 INFO Epoch 3: [1343/10940] ---- BYOL Training Loss = 0.2190767526626587
30-01-2023 23:31:00 INFO Epoch 3: [1354/10940] ---- BYOL Training Loss = 0.26617103815078735
30-01-2023 23:31:17 INFO Epoch 3: [1365/10940] ---- BYOL Training Loss = 0.2808206379413605
30-01-2023 23:32:09 INFO Epoch 3: [1365/10940] ---- BYOL Validation Loss = 0.24619027972221375
30-01-2023 23:32:27 INFO Epoch 3: [1376/10940] ---- BYOL Training Loss = 0.29241207242012024
30-01-2023 23:32:44 INFO Epoch 3: [1387/10940] ---- BYOL Training Loss = 0.3052235245704651
30-01-2023 23:33:02 INFO Epoch 3: [1398/10940] ---- BYOL Training Loss = 0.25810930132865906
30-01-2023 23:33:20 INFO Epoch 3: [1409/10940] ---- BYOL Training Loss = 0.24455738067626953
30-01-2023 23:34:12 INFO Epoch 3: [1409/10940] ---- BYOL Validation Loss = 0.2446698397397995
30-01-2023 23:34:29 INFO Epoch 3: [1420/10940] ---- BYOL Training Loss = 0.22749707102775574
30-01-2023 23:34:47 INFO Epoch 3: [1431/10940] ---- BYOL Training Loss = 0.21923771500587463
30-01-2023 23:35:04 INFO Epoch 3: [1442/10940] ---- BYOL Training Loss = 0.24841289222240448
30-01-2023 23:35:22 INFO Epoch 3: [1453/10940] ---- BYOL Training Loss = 0.2612062394618988
30-01-2023 23:36:14 INFO Epoch 3: [1453/10940] ---- BYOL Validation Loss = 0.24394650757312775
30-01-2023 23:36:32 INFO Epoch 3: [1464/10940] ---- BYOL Training Loss = 0.20939648151397705
30-01-2023 23:36:49 INFO Epoch 3: [1475/10940] ---- BYOL Training Loss = 0.2057625949382782
30-01-2023 23:37:07 INFO Epoch 3: [1486/10940] ---- BYOL Training Loss = 0.20377814769744873
30-01-2023 23:37:24 INFO Epoch 3: [1497/10940] ---- BYOL Training Loss = 0.22630564868450165
30-01-2023 23:38:17 INFO Epoch 3: [1497/10940] ---- BYOL Validation Loss = 0.24403922259807587
30-01-2023 23:38:35 INFO Epoch 3: [1508/10940] ---- BYOL Training Loss = 0.25422215461730957
30-01-2023 23:38:52 INFO Epoch 3: [1519/10940] ---- BYOL Training Loss = 0.24885061383247375
30-01-2023 23:39:10 INFO Epoch 3: [1530/10940] ---- BYOL Training Loss = 0.2806165814399719
30-01-2023 23:39:28 INFO Epoch 3: [1541/10940] ---- BYOL Training Loss = 0.25065040588378906
30-01-2023 23:40:20 INFO Epoch 3: [1541/10940] ---- BYOL Validation Loss = 0.2319716215133667
30-01-2023 23:40:37 INFO Epoch 3: [1552/10940] ---- BYOL Training Loss = 0.2538869380950928
30-01-2023 23:40:55 INFO Epoch 3: [1563/10940] ---- BYOL Training Loss = 0.2698605954647064
30-01-2023 23:41:13 INFO Epoch 3: [1574/10940] ---- BYOL Training Loss = 0.23246720433235168
30-01-2023 23:41:30 INFO Epoch 3: [1585/10940] ---- BYOL Training Loss = 0.24313394725322723
30-01-2023 23:42:23 INFO Epoch 3: [1585/10940] ---- BYOL Validation Loss = 0.2553479075431824
30-01-2023 23:42:40 INFO Epoch 3: [1596/10940] ---- BYOL Training Loss = 0.25213903188705444
30-01-2023 23:42:58 INFO Epoch 3: [1607/10940] ---- BYOL Training Loss = 0.2358221560716629
30-01-2023 23:43:15 INFO Epoch 3: [1618/10940] ---- BYOL Training Loss = 0.2214764654636383
30-01-2023 23:43:33 INFO Epoch 3: [1629/10940] ---- BYOL Training Loss = 0.28880783915519714
30-01-2023 23:44:25 INFO Epoch 3: [1629/10940] ---- BYOL Validation Loss = 0.24033431708812714
30-01-2023 23:44:43 INFO Epoch 3: [1640/10940] ---- BYOL Training Loss = 0.2779042422771454
30-01-2023 23:45:00 INFO Epoch 3: [1651/10940] ---- BYOL Training Loss = 0.2530745267868042
30-01-2023 23:45:18 INFO Epoch 3: [1662/10940] ---- BYOL Training Loss = 0.2544097304344177
30-01-2023 23:45:36 INFO Epoch 3: [1673/10940] ---- BYOL Training Loss = 0.2094457894563675
30-01-2023 23:46:28 INFO Epoch 3: [1673/10940] ---- BYOL Validation Loss = 0.2367343157529831
30-01-2023 23:46:45 INFO Epoch 3: [1684/10940] ---- BYOL Training Loss = 0.2526776194572449
30-01-2023 23:47:03 INFO Epoch 3: [1695/10940] ---- BYOL Training Loss = 0.26394370198249817
30-01-2023 23:47:21 INFO Epoch 3: [1706/10940] ---- BYOL Training Loss = 0.21894533932209015
30-01-2023 23:47:38 INFO Epoch 3: [1717/10940] ---- BYOL Training Loss = 0.20978441834449768
30-01-2023 23:48:31 INFO Epoch 3: [1717/10940] ---- BYOL Validation Loss = 0.2509467303752899
30-01-2023 23:48:48 INFO Epoch 3: [1728/10940] ---- BYOL Training Loss = 0.24441544711589813
30-01-2023 23:49:06 INFO Epoch 3: [1739/10940] ---- BYOL Training Loss = 0.23133499920368195
30-01-2023 23:49:23 INFO Epoch 3: [1750/10940] ---- BYOL Training Loss = 0.22127237915992737
30-01-2023 23:49:41 INFO Epoch 3: [1761/10940] ---- BYOL Training Loss = 0.20933985710144043
30-01-2023 23:50:34 INFO Epoch 3: [1761/10940] ---- BYOL Validation Loss = 0.22943785786628723
30-01-2023 23:50:51 INFO Epoch 3: [1772/10940] ---- BYOL Training Loss = 0.18895742297172546
30-01-2023 23:51:08 INFO Epoch 3: [1783/10940] ---- BYOL Training Loss = 0.1942148357629776
30-01-2023 23:51:26 INFO Epoch 3: [1794/10940] ---- BYOL Training Loss = 0.2822563946247101
30-01-2023 23:51:44 INFO Epoch 3: [1805/10940] ---- BYOL Training Loss = 0.28177008032798767
30-01-2023 23:52:36 INFO Epoch 3: [1805/10940] ---- BYOL Validation Loss = 0.2412566840648651
30-01-2023 23:52:53 INFO Epoch 3: [1816/10940] ---- BYOL Training Loss = 0.2460809201002121
30-01-2023 23:53:11 INFO Epoch 3: [1827/10940] ---- BYOL Training Loss = 0.28952556848526
30-01-2023 23:53:29 INFO Epoch 3: [1838/10940] ---- BYOL Training Loss = 0.2791292071342468
30-01-2023 23:53:46 INFO Epoch 3: [1849/10940] ---- BYOL Training Loss = 0.26226499676704407
30-01-2023 23:54:39 INFO Epoch 3: [1849/10940] ---- BYOL Validation Loss = 0.23786687850952148
30-01-2023 23:54:56 INFO Epoch 3: [1860/10940] ---- BYOL Training Loss = 0.24108536541461945
30-01-2023 23:55:14 INFO Epoch 3: [1871/10940] ---- BYOL Training Loss = 0.25776994228363037
30-01-2023 23:55:32 INFO Epoch 3: [1882/10940] ---- BYOL Training Loss = 0.2774840295314789
30-01-2023 23:55:50 INFO Epoch 3: [1893/10940] ---- BYOL Training Loss = 0.24325446784496307
30-01-2023 23:56:42 INFO Epoch 3: [1893/10940] ---- BYOL Validation Loss = 0.22593173384666443
30-01-2023 23:57:00 INFO Epoch 3: [1904/10940] ---- BYOL Training Loss = 0.24877700209617615
30-01-2023 23:57:17 INFO Epoch 3: [1915/10940] ---- BYOL Training Loss = 0.2389344871044159
30-01-2023 23:57:35 INFO Epoch 3: [1926/10940] ---- BYOL Training Loss = 0.23767802119255066
30-01-2023 23:57:53 INFO Epoch 3: [1937/10940] ---- BYOL Training Loss = 0.22658860683441162
30-01-2023 23:58:45 INFO Epoch 3: [1937/10940] ---- BYOL Validation Loss = 0.22858549654483795
30-01-2023 23:59:02 INFO Epoch 3: [1948/10940] ---- BYOL Training Loss = 0.27931660413742065
30-01-2023 23:59:20 INFO Epoch 3: [1959/10940] ---- BYOL Training Loss = 0.29790157079696655
30-01-2023 23:59:38 INFO Epoch 3: [1970/10940] ---- BYOL Training Loss = 0.2504540979862213
30-01-2023 23:59:55 INFO Epoch 3: [1981/10940] ---- BYOL Training Loss = 0.27499818801879883
slurmstepd-landonia23: error: slurm_get_node_energy: Connection refused
slurmstepd-landonia23: error: _get_joules_task: can't get info from slurmd
31-01-2023 00:00:48 INFO Epoch 3: [1981/10940] ---- BYOL Validation Loss = 0.23340877890586853
31-01-2023 00:01:05 INFO Epoch 3: [1992/10940] ---- BYOL Training Loss = 0.2852429449558258
31-01-2023 00:01:23 INFO Epoch 3: [2003/10940] ---- BYOL Training Loss = 0.2610742449760437
31-01-2023 00:01:41 INFO Epoch 3: [2014/10940] ---- BYOL Training Loss = 0.2731223702430725
31-01-2023 00:01:58 INFO Epoch 3: [2025/10940] ---- BYOL Training Loss = 0.2876547873020172
31-01-2023 00:02:51 INFO Epoch 3: [2025/10940] ---- BYOL Validation Loss = 0.24445608258247375
31-01-2023 00:03:08 INFO Epoch 3: [2036/10940] ---- BYOL Training Loss = 0.26398080587387085
31-01-2023 00:03:26 INFO Epoch 3: [2047/10940] ---- BYOL Training Loss = 0.2603616714477539
31-01-2023 00:03:44 INFO Epoch 3: [2058/10940] ---- BYOL Training Loss = 0.28124964237213135
31-01-2023 00:04:01 INFO Epoch 3: [2069/10940] ---- BYOL Training Loss = 0.24002286791801453
31-01-2023 00:04:54 INFO Epoch 3: [2069/10940] ---- BYOL Validation Loss = 0.24203930795192719
31-01-2023 00:05:11 INFO Epoch 3: [2080/10940] ---- BYOL Training Loss = 0.22111420333385468
31-01-2023 00:05:29 INFO Epoch 3: [2091/10940] ---- BYOL Training Loss = 0.2456933706998825
31-01-2023 00:05:46 INFO Epoch 3: [2102/10940] ---- BYOL Training Loss = 0.28226596117019653
31-01-2023 00:06:04 INFO Epoch 3: [2113/10940] ---- BYOL Training Loss = 0.2614671289920807
31-01-2023 00:06:57 INFO Epoch 3: [2113/10940] ---- BYOL Validation Loss = 0.23788945376873016
31-01-2023 00:07:14 INFO Epoch 3: [2124/10940] ---- BYOL Training Loss = 0.23671559989452362
31-01-2023 00:07:32 INFO Epoch 3: [2135/10940] ---- BYOL Training Loss = 0.25613075494766235
31-01-2023 00:07:49 INFO Epoch 3: [2146/10940] ---- BYOL Training Loss = 0.23626086115837097
31-01-2023 00:08:07 INFO Epoch 3: [2157/10940] ---- BYOL Training Loss = 0.19704701006412506
31-01-2023 00:08:59 INFO Epoch 3: [2157/10940] ---- BYOL Validation Loss = 0.2451227456331253
31-01-2023 00:09:17 INFO Epoch 3: [2168/10940] ---- BYOL Training Loss = 0.23617354035377502
31-01-2023 00:09:34 INFO Epoch 3: [2179/10940] ---- BYOL Training Loss = 0.22979894280433655
31-01-2023 00:09:52 INFO Epoch 3: [2190/10940] ---- BYOL Training Loss = 0.249518483877182
31-01-2023 00:10:10 INFO Epoch 3: [2201/10940] ---- BYOL Training Loss = 0.24475093185901642
31-01-2023 00:11:03 INFO Epoch 3: [2201/10940] ---- BYOL Validation Loss = 0.23963962495326996
31-01-2023 00:11:20 INFO Epoch 3: [2212/10940] ---- BYOL Training Loss = 0.20840874314308167
31-01-2023 00:11:38 INFO Epoch 3: [2223/10940] ---- BYOL Training Loss = 0.1841244399547577
31-01-2023 00:11:56 INFO Epoch 3: [2234/10940] ---- BYOL Training Loss = 0.20707640051841736
31-01-2023 00:12:13 INFO Epoch 3: [2245/10940] ---- BYOL Training Loss = 0.2550138235092163
31-01-2023 00:13:06 INFO Epoch 3: [2245/10940] ---- BYOL Validation Loss = 0.23648592829704285
31-01-2023 00:13:23 INFO Epoch 3: [2256/10940] ---- BYOL Training Loss = 0.2908598780632019
31-01-2023 00:13:41 INFO Epoch 3: [2267/10940] ---- BYOL Training Loss = 0.27075880765914917
31-01-2023 00:13:59 INFO Epoch 3: [2278/10940] ---- BYOL Training Loss = 0.29777172207832336
31-01-2023 00:14:16 INFO Epoch 3: [2289/10940] ---- BYOL Training Loss = 0.26561012864112854
31-01-2023 00:15:09 INFO Epoch 3: [2289/10940] ---- BYOL Validation Loss = 0.2417687326669693
31-01-2023 00:15:26 INFO Epoch 3: [2300/10940] ---- BYOL Training Loss = 0.24809932708740234
31-01-2023 00:15:44 INFO Epoch 3: [2311/10940] ---- BYOL Training Loss = 0.24075491726398468
31-01-2023 00:16:01 INFO Epoch 3: [2322/10940] ---- BYOL Training Loss = 0.25478440523147583
31-01-2023 00:16:20 INFO Epoch 3: [2333/10940] ---- BYOL Training Loss = 0.2825703024864197
31-01-2023 00:17:12 INFO Epoch 3: [2333/10940] ---- BYOL Validation Loss = 0.24257639050483704
31-01-2023 00:17:29 INFO Epoch 3: [2344/10940] ---- BYOL Training Loss = 0.2743395268917084
31-01-2023 00:17:47 INFO Epoch 3: [2355/10940] ---- BYOL Training Loss = 0.19420386850833893
31-01-2023 00:18:05 INFO Epoch 3: [2366/10940] ---- BYOL Training Loss = 0.20292405784130096
31-01-2023 00:18:22 INFO Epoch 3: [2377/10940] ---- BYOL Training Loss = 0.2750774025917053
31-01-2023 00:19:15 INFO Epoch 3: [2377/10940] ---- BYOL Validation Loss = 0.24367700517177582
31-01-2023 00:19:32 INFO Epoch 3: [2388/10940] ---- BYOL Training Loss = 0.2845931649208069
31-01-2023 00:19:50 INFO Epoch 3: [2399/10940] ---- BYOL Training Loss = 0.23470810055732727
31-01-2023 00:20:07 INFO Epoch 3: [2410/10940] ---- BYOL Training Loss = 0.22858664393424988
31-01-2023 00:20:25 INFO Epoch 3: [2421/10940] ---- BYOL Training Loss = 0.22541122138500214
31-01-2023 00:21:17 INFO Epoch 3: [2421/10940] ---- BYOL Validation Loss = 0.23799993097782135
31-01-2023 00:21:35 INFO Epoch 3: [2432/10940] ---- BYOL Training Loss = 0.23596420884132385
31-01-2023 00:21:52 INFO Epoch 3: [2443/10940] ---- BYOL Training Loss = 0.26077932119369507
31-01-2023 00:22:11 INFO Epoch 3: [2454/10940] ---- BYOL Training Loss = 0.22042174637317657
31-01-2023 00:22:28 INFO Epoch 3: [2465/10940] ---- BYOL Training Loss = 0.23898115754127502
31-01-2023 00:23:21 INFO Epoch 3: [2465/10940] ---- BYOL Validation Loss = 0.23730622231960297
31-01-2023 00:23:38 INFO Epoch 3: [2476/10940] ---- BYOL Training Loss = 0.3043690323829651
31-01-2023 00:23:56 INFO Epoch 3: [2487/10940] ---- BYOL Training Loss = 0.298037588596344
31-01-2023 00:24:14 INFO Epoch 3: [2498/10940] ---- BYOL Training Loss = 0.2634744942188263
31-01-2023 00:24:31 INFO Epoch 3: [2509/10940] ---- BYOL Training Loss = 0.26646071672439575
31-01-2023 00:25:24 INFO Epoch 3: [2509/10940] ---- BYOL Validation Loss = 0.2386913001537323
31-01-2023 00:25:41 INFO Epoch 3: [2520/10940] ---- BYOL Training Loss = 0.23692718148231506
31-01-2023 00:25:59 INFO Epoch 3: [2531/10940] ---- BYOL Training Loss = 0.2520393431186676
31-01-2023 00:26:17 INFO Epoch 3: [2542/10940] ---- BYOL Training Loss = 0.2854459881782532
31-01-2023 00:26:34 INFO Epoch 3: [2553/10940] ---- BYOL Training Loss = 0.24398548901081085
31-01-2023 00:27:26 INFO Epoch 3: [2553/10940] ---- BYOL Validation Loss = 0.2435145229101181
31-01-2023 00:27:44 INFO Epoch 3: [2564/10940] ---- BYOL Training Loss = 0.22530686855316162
31-01-2023 00:28:02 INFO Epoch 3: [2575/10940] ---- BYOL Training Loss = 0.22274890542030334
31-01-2023 00:28:20 INFO Epoch 3: [2586/10940] ---- BYOL Training Loss = 0.25904691219329834
31-01-2023 00:28:37 INFO Epoch 3: [2597/10940] ---- BYOL Training Loss = 0.2756061851978302
31-01-2023 00:29:29 INFO Epoch 3: [2597/10940] ---- BYOL Validation Loss = 0.23804707825183868
31-01-2023 00:29:47 INFO Epoch 3: [2608/10940] ---- BYOL Training Loss = 0.24831362068653107
31-01-2023 00:30:04 INFO Epoch 3: [2619/10940] ---- BYOL Training Loss = 0.2211308777332306
31-01-2023 00:30:22 INFO Epoch 3: [2630/10940] ---- BYOL Training Loss = 0.24559417366981506
31-01-2023 00:30:40 INFO Epoch 3: [2641/10940] ---- BYOL Training Loss = 0.23508329689502716
31-01-2023 00:31:32 INFO Epoch 3: [2641/10940] ---- BYOL Validation Loss = 0.2425234317779541
31-01-2023 00:31:49 INFO Epoch 3: [2652/10940] ---- BYOL Training Loss = 0.2639242708683014
31-01-2023 00:32:07 INFO Epoch 3: [2663/10940] ---- BYOL Training Loss = 0.26041311025619507
31-01-2023 00:32:25 INFO Epoch 3: [2674/10940] ---- BYOL Training Loss = 0.2544490694999695
31-01-2023 00:32:43 INFO Epoch 3: [2685/10940] ---- BYOL Training Loss = 0.26852256059646606
31-01-2023 00:33:35 INFO Epoch 3: [2685/10940] ---- BYOL Validation Loss = 0.23275208473205566
31-01-2023 00:33:53 INFO Epoch 3: [2696/10940] ---- BYOL Training Loss = 0.2565228044986725
31-01-2023 00:34:11 INFO Epoch 3: [2707/10940] ---- BYOL Training Loss = 0.23889359831809998
31-01-2023 00:34:28 INFO Epoch 3: [2718/10940] ---- BYOL Training Loss = 0.2206672728061676
31-01-2023 00:34:46 INFO Epoch 3: [2729/10940] ---- BYOL Training Loss = 0.24732641875743866
31-01-2023 00:35:38 INFO Epoch 3: [2729/10940] ---- BYOL Validation Loss = 0.2257211059331894
31-01-2023 00:35:56 INFO Epoch 3: [2740/10940] ---- BYOL Training Loss = 0.23400020599365234
31-01-2023 00:36:14 INFO Epoch 3: [2751/10940] ---- BYOL Training Loss = 0.24575373530387878
31-01-2023 00:36:32 INFO Epoch 3: [2762/10940] ---- BYOL Training Loss = 0.251992404460907
31-01-2023 00:36:50 INFO Epoch 3: [2773/10940] ---- BYOL Training Loss = 0.23958130180835724
31-01-2023 00:37:42 INFO Epoch 3: [2773/10940] ---- BYOL Validation Loss = 0.23232029378414154
31-01-2023 00:37:59 INFO Epoch 3: [2784/10940] ---- BYOL Training Loss = 0.2386549711227417
31-01-2023 00:38:17 INFO Epoch 3: [2795/10940] ---- BYOL Training Loss = 0.2272246778011322
31-01-2023 00:38:35 INFO Epoch 3: [2806/10940] ---- BYOL Training Loss = 0.21561852097511292
31-01-2023 00:38:53 INFO Epoch 3: [2817/10940] ---- BYOL Training Loss = 0.21181435883045197
31-01-2023 00:39:45 INFO Epoch 3: [2817/10940] ---- BYOL Validation Loss = 0.23845025897026062
31-01-2023 00:40:02 INFO Epoch 3: [2828/10940] ---- BYOL Training Loss = 0.2483045607805252
31-01-2023 00:40:20 INFO Epoch 3: [2839/10940] ---- BYOL Training Loss = 0.24000947177410126
31-01-2023 00:40:38 INFO Epoch 3: [2850/10940] ---- BYOL Training Loss = 0.27348971366882324
31-01-2023 00:40:55 INFO Epoch 3: [2861/10940] ---- BYOL Training Loss = 0.25368809700012207
31-01-2023 00:41:47 INFO Epoch 3: [2861/10940] ---- BYOL Validation Loss = 0.23498491942882538
31-01-2023 00:42:05 INFO Epoch 3: [2872/10940] ---- BYOL Training Loss = 0.23860251903533936
31-01-2023 00:42:23 INFO Epoch 3: [2883/10940] ---- BYOL Training Loss = 0.21923168003559113
31-01-2023 00:42:41 INFO Epoch 3: [2894/10940] ---- BYOL Training Loss = 0.26230818033218384
31-01-2023 00:42:59 INFO Epoch 3: [2905/10940] ---- BYOL Training Loss = 0.27600470185279846
31-01-2023 00:43:51 INFO Epoch 3: [2905/10940] ---- BYOL Validation Loss = 0.2198237031698227
31-01-2023 00:44:08 INFO Epoch 3: [2916/10940] ---- BYOL Training Loss = 0.27427786588668823
31-01-2023 00:44:26 INFO Epoch 3: [2927/10940] ---- BYOL Training Loss = 0.2508624196052551
31-01-2023 00:44:44 INFO Epoch 3: [2938/10940] ---- BYOL Training Loss = 0.2304607629776001
31-01-2023 00:45:02 INFO Epoch 3: [2949/10940] ---- BYOL Training Loss = 0.2616106867790222
31-01-2023 00:45:54 INFO Epoch 3: [2949/10940] ---- BYOL Validation Loss = 0.22983069717884064
31-01-2023 00:46:11 INFO Epoch 3: [2960/10940] ---- BYOL Training Loss = 0.2928922176361084
31-01-2023 00:46:29 INFO Epoch 3: [2971/10940] ---- BYOL Training Loss = 0.29516440629959106
31-01-2023 00:46:47 INFO Epoch 3: [2982/10940] ---- BYOL Training Loss = 0.2705523669719696
31-01-2023 00:47:05 INFO Epoch 3: [2993/10940] ---- BYOL Training Loss = 0.24434742331504822
31-01-2023 00:47:57 INFO Epoch 3: [2993/10940] ---- BYOL Validation Loss = 0.2332640439271927
31-01-2023 00:48:15 INFO Epoch 3: [3004/10940] ---- BYOL Training Loss = 0.18016819655895233
31-01-2023 00:48:32 INFO Epoch 3: [3015/10940] ---- BYOL Training Loss = 0.21648231148719788
31-01-2023 00:48:50 INFO Epoch 3: [3026/10940] ---- BYOL Training Loss = 0.2360052615404129
31-01-2023 00:49:08 INFO Epoch 3: [3037/10940] ---- BYOL Training Loss = 0.23716160655021667
31-01-2023 00:50:00 INFO Epoch 3: [3037/10940] ---- BYOL Validation Loss = 0.2295142263174057
31-01-2023 00:50:18 INFO Epoch 3: [3048/10940] ---- BYOL Training Loss = 0.2746969759464264
31-01-2023 00:50:36 INFO Epoch 3: [3059/10940] ---- BYOL Training Loss = 0.2728408873081207
31-01-2023 00:50:54 INFO Epoch 3: [3070/10940] ---- BYOL Training Loss = 0.2177118957042694
31-01-2023 00:51:12 INFO Epoch 3: [3081/10940] ---- BYOL Training Loss = 0.2487962245941162
31-01-2023 00:52:04 INFO Epoch 3: [3081/10940] ---- BYOL Validation Loss = 0.2332904040813446
31-01-2023 00:52:21 INFO Epoch 3: [3092/10940] ---- BYOL Training Loss = 0.27344873547554016
31-01-2023 00:52:39 INFO Epoch 3: [3103/10940] ---- BYOL Training Loss = 0.26928338408470154
31-01-2023 00:52:57 INFO Epoch 3: [3114/10940] ---- BYOL Training Loss = 0.2871784567832947
31-01-2023 00:53:15 INFO Epoch 3: [3125/10940] ---- BYOL Training Loss = 0.2793622612953186
31-01-2023 00:54:07 INFO Epoch 3: [3125/10940] ---- BYOL Validation Loss = 0.23893609642982483
31-01-2023 00:54:24 INFO Epoch 3: [3136/10940] ---- BYOL Training Loss = 0.2406138926744461
31-01-2023 00:54:42 INFO Epoch 3: [3147/10940] ---- BYOL Training Loss = 0.2330356389284134
31-01-2023 00:55:00 INFO Epoch 3: [3158/10940] ---- BYOL Training Loss = 0.24566106498241425
31-01-2023 00:55:18 INFO Epoch 3: [3169/10940] ---- BYOL Training Loss = 0.2477918118238449
31-01-2023 00:56:10 INFO Epoch 3: [3169/10940] ---- BYOL Validation Loss = 0.22800849378108978
31-01-2023 00:56:28 INFO Epoch 3: [3180/10940] ---- BYOL Training Loss = 0.27841466665267944
31-01-2023 00:56:46 INFO Epoch 3: [3191/10940] ---- BYOL Training Loss = 0.2741435170173645
31-01-2023 00:57:03 INFO Epoch 3: [3202/10940] ---- BYOL Training Loss = 0.24200531840324402
31-01-2023 00:57:21 INFO Epoch 3: [3213/10940] ---- BYOL Training Loss = 0.21691687405109406
31-01-2023 00:58:13 INFO Epoch 3: [3213/10940] ---- BYOL Validation Loss = 0.2321254014968872
31-01-2023 00:58:31 INFO Epoch 3: [3224/10940] ---- BYOL Training Loss = 0.2433343380689621
31-01-2023 00:58:49 INFO Epoch 3: [3235/10940] ---- BYOL Training Loss = 0.26938268542289734
31-01-2023 00:59:07 INFO Epoch 3: [3246/10940] ---- BYOL Training Loss = 0.241366907954216
31-01-2023 00:59:24 INFO Epoch 3: [3257/10940] ---- BYOL Training Loss = 0.22441622614860535
31-01-2023 01:00:17 INFO Epoch 3: [3257/10940] ---- BYOL Validation Loss = 0.23131178319454193
31-01-2023 01:00:34 INFO Epoch 3: [3268/10940] ---- BYOL Training Loss = 0.22941824793815613
31-01-2023 01:00:52 INFO Epoch 3: [3279/10940] ---- BYOL Training Loss = 0.28526902198791504
31-01-2023 01:01:09 INFO Epoch 3: [3290/10940] ---- BYOL Training Loss = 0.2722911238670349
31-01-2023 01:01:27 INFO Epoch 3: [3301/10940] ---- BYOL Training Loss = 0.2530779242515564
31-01-2023 01:02:20 INFO Epoch 3: [3301/10940] ---- BYOL Validation Loss = 0.23380878567695618
31-01-2023 01:02:37 INFO Epoch 3: [3312/10940] ---- BYOL Training Loss = 0.21890561282634735
31-01-2023 01:02:55 INFO Epoch 3: [3323/10940] ---- BYOL Training Loss = 0.1978461742401123
31-01-2023 01:03:13 INFO Epoch 3: [3334/10940] ---- BYOL Training Loss = 0.21984343230724335
31-01-2023 01:03:31 INFO Epoch 3: [3345/10940] ---- BYOL Training Loss = 0.24149246513843536
31-01-2023 01:04:23 INFO Epoch 3: [3345/10940] ---- BYOL Validation Loss = 0.22844198346138
31-01-2023 01:04:40 INFO Epoch 3: [3356/10940] ---- BYOL Training Loss = 0.22508946061134338
31-01-2023 01:04:58 INFO Epoch 3: [3367/10940] ---- BYOL Training Loss = 0.2387998104095459
31-01-2023 01:05:16 INFO Epoch 3: [3378/10940] ---- BYOL Training Loss = 0.2508317828178406
31-01-2023 01:05:34 INFO Epoch 3: [3389/10940] ---- BYOL Training Loss = 0.2065938264131546
31-01-2023 01:06:26 INFO Epoch 3: [3389/10940] ---- BYOL Validation Loss = 0.22807718813419342
31-01-2023 01:06:44 INFO Epoch 3: [3400/10940] ---- BYOL Training Loss = 0.19985470175743103
31-01-2023 01:07:02 INFO Epoch 3: [3411/10940] ---- BYOL Training Loss = 0.19815488159656525
31-01-2023 01:07:20 INFO Epoch 3: [3422/10940] ---- BYOL Training Loss = 0.2638685703277588
31-01-2023 01:07:37 INFO Epoch 3: [3433/10940] ---- BYOL Training Loss = 0.28576093912124634
31-01-2023 01:08:30 INFO Epoch 3: [3433/10940] ---- BYOL Validation Loss = 0.22656956315040588
31-01-2023 01:08:47 INFO Epoch 3: [3444/10940] ---- BYOL Training Loss = 0.28178372979164124
31-01-2023 01:09:05 INFO Epoch 3: [3455/10940] ---- BYOL Training Loss = 0.2650710642337799
31-01-2023 01:09:23 INFO Epoch 3: [3466/10940] ---- BYOL Training Loss = 0.24175290763378143
31-01-2023 01:09:41 INFO Epoch 3: [3477/10940] ---- BYOL Training Loss = 0.22037000954151154
31-01-2023 01:10:33 INFO Epoch 3: [3477/10940] ---- BYOL Validation Loss = 0.22524993121623993
31-01-2023 01:10:50 INFO Epoch 3: [3488/10940] ---- BYOL Training Loss = 0.26354533433914185
31-01-2023 01:11:08 INFO Epoch 3: [3499/10940] ---- BYOL Training Loss = 0.2471492737531662
31-01-2023 01:11:26 INFO Epoch 3: [3510/10940] ---- BYOL Training Loss = 0.21844813227653503
31-01-2023 01:11:44 INFO Epoch 3: [3521/10940] ---- BYOL Training Loss = 0.2054441273212433
31-01-2023 01:12:36 INFO Epoch 3: [3521/10940] ---- BYOL Validation Loss = 0.22027333080768585
31-01-2023 01:12:54 INFO Epoch 3: [3532/10940] ---- BYOL Training Loss = 0.24139630794525146
31-01-2023 01:13:11 INFO Epoch 3: [3543/10940] ---- BYOL Training Loss = 0.24319155514240265
31-01-2023 01:13:30 INFO Epoch 3: [3554/10940] ---- BYOL Training Loss = 0.2197156697511673
31-01-2023 01:13:47 INFO Epoch 3: [3565/10940] ---- BYOL Training Loss = 0.22034072875976562
31-01-2023 01:14:40 INFO Epoch 3: [3565/10940] ---- BYOL Validation Loss = 0.21993812918663025
31-01-2023 01:14:57 INFO Epoch 3: [3576/10940] ---- BYOL Training Loss = 0.22877278923988342
31-01-2023 01:15:15 INFO Epoch 3: [3587/10940] ---- BYOL Training Loss = 0.2203126698732376
31-01-2023 01:15:33 INFO Epoch 3: [3598/10940] ---- BYOL Training Loss = 0.21250848472118378
31-01-2023 01:15:50 INFO Epoch 3: [3609/10940] ---- BYOL Training Loss = 0.22014220058918
31-01-2023 01:16:43 INFO Epoch 3: [3609/10940] ---- BYOL Validation Loss = 0.22121016681194305
31-01-2023 01:17:00 INFO Epoch 3: [3620/10940] ---- BYOL Training Loss = 0.24042394757270813
31-01-2023 01:17:19 INFO Epoch 3: [3631/10940] ---- BYOL Training Loss = 0.24233996868133545
31-01-2023 01:17:36 INFO Epoch 3: [3642/10940] ---- BYOL Training Loss = 0.28151407837867737
31-01-2023 01:17:54 INFO Epoch 3: [3653/10940] ---- BYOL Training Loss = 0.24723728001117706
31-01-2023 01:18:46 INFO Epoch 3: [3653/10940] ---- BYOL Validation Loss = 0.228529691696167
31-01-2023 01:19:04 INFO Epoch 3: [3664/10940] ---- BYOL Training Loss = 0.22343187034130096
31-01-2023 01:19:22 INFO Epoch 3: [3675/10940] ---- BYOL Training Loss = 0.21796011924743652
31-01-2023 01:19:39 INFO Epoch 3: [3686/10940] ---- BYOL Training Loss = 0.19374412298202515
31-01-2023 01:19:57 INFO Epoch 3: [3697/10940] ---- BYOL Training Loss = 0.2299376279115677
31-01-2023 01:20:50 INFO Epoch 3: [3697/10940] ---- BYOL Validation Loss = 0.2263752520084381
31-01-2023 01:21:07 INFO Epoch 3: [3708/10940] ---- BYOL Training Loss = 0.24463483691215515
31-01-2023 01:21:25 INFO Epoch 3: [3719/10940] ---- BYOL Training Loss = 0.20935913920402527
31-01-2023 01:21:43 INFO Epoch 3: [3730/10940] ---- BYOL Training Loss = 0.24280396103858948
31-01-2023 01:22:01 INFO Epoch 3: [3741/10940] ---- BYOL Training Loss = 0.27083083987236023
31-01-2023 01:22:53 INFO Epoch 3: [3741/10940] ---- BYOL Validation Loss = 0.22169406712055206
31-01-2023 01:23:11 INFO Epoch 3: [3752/10940] ---- BYOL Training Loss = 0.24564623832702637
31-01-2023 01:23:28 INFO Epoch 3: [3763/10940] ---- BYOL Training Loss = 0.2468024492263794
31-01-2023 01:23:46 INFO Epoch 3: [3774/10940] ---- BYOL Training Loss = 0.23709912598133087
31-01-2023 01:24:04 INFO Epoch 3: [3785/10940] ---- BYOL Training Loss = 0.24229221045970917
31-01-2023 01:24:56 INFO Epoch 3: [3785/10940] ---- BYOL Validation Loss = 0.22451548278331757
31-01-2023 01:25:14 INFO Epoch 3: [3796/10940] ---- BYOL Training Loss = 0.25591835379600525
31-01-2023 01:25:32 INFO Epoch 3: [3807/10940] ---- BYOL Training Loss = 0.24919669330120087
31-01-2023 01:25:50 INFO Epoch 3: [3818/10940] ---- BYOL Training Loss = 0.23986729979515076
31-01-2023 01:26:08 INFO Epoch 3: [3829/10940] ---- BYOL Training Loss = 0.24598559737205505
31-01-2023 01:27:00 INFO Epoch 3: [3829/10940] ---- BYOL Validation Loss = 0.22196541726589203
31-01-2023 01:27:17 INFO Epoch 3: [3840/10940] ---- BYOL Training Loss = 0.2326507270336151
31-01-2023 01:27:35 INFO Epoch 3: [3851/10940] ---- BYOL Training Loss = 0.23240211606025696
31-01-2023 01:27:54 INFO Epoch 3: [3862/10940] ---- BYOL Training Loss = 0.24061742424964905
31-01-2023 01:28:11 INFO Epoch 3: [3873/10940] ---- BYOL Training Loss = 0.2433331310749054
31-01-2023 01:29:04 INFO Epoch 3: [3873/10940] ---- BYOL Validation Loss = 0.2207442969083786
31-01-2023 01:29:21 INFO Epoch 3: [3884/10940] ---- BYOL Training Loss = 0.2382504940032959
31-01-2023 01:29:39 INFO Epoch 3: [3895/10940] ---- BYOL Training Loss = 0.22941982746124268
31-01-2023 01:29:57 INFO Epoch 3: [3906/10940] ---- BYOL Training Loss = 0.22477133572101593
31-01-2023 01:30:15 INFO Epoch 3: [3917/10940] ---- BYOL Training Loss = 0.23634788393974304
31-01-2023 01:31:07 INFO Epoch 3: [3917/10940] ---- BYOL Validation Loss = 0.204514279961586
31-01-2023 01:31:25 INFO Epoch 3: [3928/10940] ---- BYOL Training Loss = 0.2513492703437805
31-01-2023 01:31:43 INFO Epoch 3: [3939/10940] ---- BYOL Training Loss = 0.25957196950912476
31-01-2023 01:32:00 INFO Epoch 3: [3950/10940] ---- BYOL Training Loss = 0.26895350217819214
31-01-2023 01:32:18 INFO Epoch 3: [3961/10940] ---- BYOL Training Loss = 0.2337992936372757
31-01-2023 01:33:11 INFO Epoch 3: [3961/10940] ---- BYOL Validation Loss = 0.22956211864948273
31-01-2023 01:33:28 INFO Epoch 3: [3972/10940] ---- BYOL Training Loss = 0.27151745557785034
31-01-2023 01:33:46 INFO Epoch 3: [3983/10940] ---- BYOL Training Loss = 0.27654433250427246
31-01-2023 01:34:04 INFO Epoch 3: [3994/10940] ---- BYOL Training Loss = 0.25266462564468384
31-01-2023 01:34:22 INFO Epoch 3: [4005/10940] ---- BYOL Training Loss = 0.25304165482521057
31-01-2023 01:35:14 INFO Epoch 3: [4005/10940] ---- BYOL Validation Loss = 0.22145649790763855
31-01-2023 01:35:32 INFO Epoch 3: [4016/10940] ---- BYOL Training Loss = 0.21957962214946747
31-01-2023 01:35:50 INFO Epoch 3: [4027/10940] ---- BYOL Training Loss = 0.23289993405342102
31-01-2023 01:36:08 INFO Epoch 3: [4038/10940] ---- BYOL Training Loss = 0.2585222125053406
31-01-2023 01:36:25 INFO Epoch 3: [4049/10940] ---- BYOL Training Loss = 0.24910537898540497
31-01-2023 01:37:18 INFO Epoch 3: [4049/10940] ---- BYOL Validation Loss = 0.2205691635608673
31-01-2023 01:37:36 INFO Epoch 3: [4060/10940] ---- BYOL Training Loss = 0.2607477009296417
31-01-2023 01:37:53 INFO Epoch 3: [4071/10940] ---- BYOL Training Loss = 0.2129724770784378
31-01-2023 01:38:11 INFO Epoch 3: [4082/10940] ---- BYOL Training Loss = 0.18035711348056793
31-01-2023 01:38:29 INFO Epoch 3: [4093/10940] ---- BYOL Training Loss = 0.22402186691761017
31-01-2023 01:39:21 INFO Epoch 3: [4093/10940] ---- BYOL Validation Loss = 0.2180931568145752
31-01-2023 01:39:39 INFO Epoch 3: [4104/10940] ---- BYOL Training Loss = 0.26235565543174744
31-01-2023 01:39:57 INFO Epoch 3: [4115/10940] ---- BYOL Training Loss = 0.23536209762096405
31-01-2023 01:40:15 INFO Epoch 3: [4126/10940] ---- BYOL Training Loss = 0.22240838408470154
31-01-2023 01:40:33 INFO Epoch 3: [4137/10940] ---- BYOL Training Loss = 0.18128567934036255
31-01-2023 01:41:25 INFO Epoch 3: [4137/10940] ---- BYOL Validation Loss = 0.2131613790988922
31-01-2023 01:41:43 INFO Epoch 3: [4148/10940] ---- BYOL Training Loss = 0.21521008014678955
31-01-2023 01:42:00 INFO Epoch 3: [4159/10940] ---- BYOL Training Loss = 0.23362955451011658
31-01-2023 01:42:18 INFO Epoch 3: [4170/10940] ---- BYOL Training Loss = 0.23253285884857178
31-01-2023 01:42:36 INFO Epoch 3: [4181/10940] ---- BYOL Training Loss = 0.2591313421726227
31-01-2023 01:43:28 INFO Epoch 3: [4181/10940] ---- BYOL Validation Loss = 0.2198428213596344
31-01-2023 01:43:46 INFO Epoch 3: [4192/10940] ---- BYOL Training Loss = 0.23470187187194824
31-01-2023 01:44:04 INFO Epoch 3: [4203/10940] ---- BYOL Training Loss = 0.21307285130023956
31-01-2023 01:44:22 INFO Epoch 3: [4214/10940] ---- BYOL Training Loss = 0.23119907081127167
31-01-2023 01:44:40 INFO Epoch 3: [4225/10940] ---- BYOL Training Loss = 0.26247650384902954
31-01-2023 01:45:32 INFO Epoch 3: [4225/10940] ---- BYOL Validation Loss = 0.21134202182292938
31-01-2023 01:45:50 INFO Epoch 3: [4236/10940] ---- BYOL Training Loss = 0.28567853569984436
31-01-2023 01:46:08 INFO Epoch 3: [4247/10940] ---- BYOL Training Loss = 0.22608759999275208
31-01-2023 01:46:26 INFO Epoch 3: [4258/10940] ---- BYOL Training Loss = 0.21842201054096222
31-01-2023 01:46:44 INFO Epoch 3: [4269/10940] ---- BYOL Training Loss = 0.26442602276802063
31-01-2023 01:47:36 INFO Epoch 3: [4269/10940] ---- BYOL Validation Loss = 0.2179507166147232
31-01-2023 01:47:54 INFO Epoch 3: [4280/10940] ---- BYOL Training Loss = 0.25526681542396545
31-01-2023 01:48:12 INFO Epoch 3: [4291/10940] ---- BYOL Training Loss = 0.2131088525056839
31-01-2023 01:48:30 INFO Epoch 3: [4302/10940] ---- BYOL Training Loss = 0.23138204216957092
31-01-2023 01:48:48 INFO Epoch 3: [4313/10940] ---- BYOL Training Loss = 0.2398834228515625
31-01-2023 01:49:40 INFO Epoch 3: [4313/10940] ---- BYOL Validation Loss = 0.21849854290485382
31-01-2023 01:49:58 INFO Epoch 3: [4324/10940] ---- BYOL Training Loss = 0.21407654881477356
31-01-2023 01:50:15 INFO Epoch 3: [4335/10940] ---- BYOL Training Loss = 0.21271495521068573
31-01-2023 01:50:33 INFO Epoch 3: [4346/10940] ---- BYOL Training Loss = 0.25161832571029663
31-01-2023 01:50:51 INFO Epoch 3: [4357/10940] ---- BYOL Training Loss = 0.28828221559524536
31-01-2023 01:51:43 INFO Epoch 3: [4357/10940] ---- BYOL Validation Loss = 0.21106553077697754
31-01-2023 01:52:01 INFO Epoch 3: [4368/10940] ---- BYOL Training Loss = 0.22551457583904266
31-01-2023 01:52:19 INFO Epoch 3: [4379/10940] ---- BYOL Training Loss = 0.20986755192279816
31-01-2023 01:52:37 INFO Epoch 3: [4390/10940] ---- BYOL Training Loss = 0.22045886516571045
31-01-2023 01:52:55 INFO Epoch 3: [4401/10940] ---- BYOL Training Loss = 0.21726365387439728
31-01-2023 01:53:47 INFO Epoch 3: [4401/10940] ---- BYOL Validation Loss = 0.221220001578331
31-01-2023 01:54:05 INFO Epoch 3: [4412/10940] ---- BYOL Training Loss = 0.24172349274158478
31-01-2023 01:54:23 INFO Epoch 3: [4423/10940] ---- BYOL Training Loss = 0.268343985080719
31-01-2023 01:54:40 INFO Epoch 3: [4434/10940] ---- BYOL Training Loss = 0.22728721797466278
31-01-2023 01:54:59 INFO Epoch 3: [4445/10940] ---- BYOL Training Loss = 0.22549395263195038
31-01-2023 01:55:51 INFO Epoch 3: [4445/10940] ---- BYOL Validation Loss = 0.21504569053649902
31-01-2023 01:56:09 INFO Epoch 3: [4456/10940] ---- BYOL Training Loss = 0.24388369917869568
31-01-2023 01:56:26 INFO Epoch 3: [4467/10940] ---- BYOL Training Loss = 0.21846124529838562
31-01-2023 01:56:44 INFO Epoch 3: [4478/10940] ---- BYOL Training Loss = 0.235648512840271
31-01-2023 01:57:02 INFO Epoch 3: [4489/10940] ---- BYOL Training Loss = 0.24944965541362762
31-01-2023 01:57:55 INFO Epoch 3: [4489/10940] ---- BYOL Validation Loss = 0.21792985498905182
31-01-2023 01:58:12 INFO Epoch 3: [4500/10940] ---- BYOL Training Loss = 0.230006143450737
31-01-2023 01:58:30 INFO Epoch 3: [4511/10940] ---- BYOL Training Loss = 0.21297219395637512
31-01-2023 01:58:48 INFO Epoch 3: [4522/10940] ---- BYOL Training Loss = 0.23603947460651398
31-01-2023 01:59:06 INFO Epoch 3: [4533/10940] ---- BYOL Training Loss = 0.2574050724506378
31-01-2023 01:59:58 INFO Epoch 3: [4533/10940] ---- BYOL Validation Loss = 0.22999943792819977
31-01-2023 02:00:16 INFO Epoch 3: [4544/10940] ---- BYOL Training Loss = 0.24181394279003143
31-01-2023 02:00:34 INFO Epoch 3: [4555/10940] ---- BYOL Training Loss = 0.21440330147743225
31-01-2023 02:00:52 INFO Epoch 3: [4566/10940] ---- BYOL Training Loss = 0.22204606235027313
31-01-2023 02:01:10 INFO Epoch 3: [4577/10940] ---- BYOL Training Loss = 0.24343402683734894
31-01-2023 02:02:02 INFO Epoch 3: [4577/10940] ---- BYOL Validation Loss = 0.21701137721538544
31-01-2023 02:02:20 INFO Epoch 3: [4588/10940] ---- BYOL Training Loss = 0.19927093386650085
31-01-2023 02:02:38 INFO Epoch 3: [4599/10940] ---- BYOL Training Loss = 0.19070209562778473
31-01-2023 02:02:56 INFO Epoch 3: [4610/10940] ---- BYOL Training Loss = 0.23529720306396484
31-01-2023 02:03:14 INFO Epoch 3: [4621/10940] ---- BYOL Training Loss = 0.24716520309448242
31-01-2023 02:04:06 INFO Epoch 3: [4621/10940] ---- BYOL Validation Loss = 0.22961147129535675
31-01-2023 02:04:24 INFO Epoch 3: [4632/10940] ---- BYOL Training Loss = 0.22997236251831055
31-01-2023 02:04:42 INFO Epoch 3: [4643/10940] ---- BYOL Training Loss = 0.2719108462333679
31-01-2023 02:05:00 INFO Epoch 3: [4654/10940] ---- BYOL Training Loss = 0.2115267813205719
31-01-2023 02:05:17 INFO Epoch 3: [4665/10940] ---- BYOL Training Loss = 0.18319110572338104
31-01-2023 02:06:10 INFO Epoch 3: [4665/10940] ---- BYOL Validation Loss = 0.22422610223293304
31-01-2023 02:06:28 INFO Epoch 3: [4676/10940] ---- BYOL Training Loss = 0.18830087780952454
31-01-2023 02:06:46 INFO Epoch 3: [4687/10940] ---- BYOL Training Loss = 0.20443856716156006
31-01-2023 02:07:03 INFO Epoch 3: [4698/10940] ---- BYOL Training Loss = 0.2564646601676941
31-01-2023 02:07:21 INFO Epoch 3: [4709/10940] ---- BYOL Training Loss = 0.23671182990074158
31-01-2023 02:08:14 INFO Epoch 3: [4709/10940] ---- BYOL Validation Loss = 0.22276847064495087
31-01-2023 02:08:31 INFO Epoch 3: [4720/10940] ---- BYOL Training Loss = 0.26853179931640625
31-01-2023 02:08:50 INFO Epoch 3: [4731/10940] ---- BYOL Training Loss = 0.27907025814056396
31-01-2023 02:09:07 INFO Epoch 3: [4742/10940] ---- BYOL Training Loss = 0.20694796741008759
31-01-2023 02:09:25 INFO Epoch 3: [4753/10940] ---- BYOL Training Loss = 0.19838231801986694
31-01-2023 02:10:18 INFO Epoch 3: [4753/10940] ---- BYOL Validation Loss = 0.23256389796733856
31-01-2023 02:10:35 INFO Epoch 3: [4764/10940] ---- BYOL Training Loss = 0.2728617787361145
31-01-2023 02:10:53 INFO Epoch 3: [4775/10940] ---- BYOL Training Loss = 0.2931961417198181
31-01-2023 02:11:11 INFO Epoch 3: [4786/10940] ---- BYOL Training Loss = 0.21710200607776642
31-01-2023 02:11:30 INFO Epoch 3: [4797/10940] ---- BYOL Training Loss = 0.26606065034866333
31-01-2023 02:12:22 INFO Epoch 3: [4797/10940] ---- BYOL Validation Loss = 0.2235318273305893
31-01-2023 02:12:39 INFO Epoch 3: [4808/10940] ---- BYOL Training Loss = 0.30815988779067993
31-01-2023 02:12:57 INFO Epoch 3: [4819/10940] ---- BYOL Training Loss = 0.24686217308044434
31-01-2023 02:13:15 INFO Epoch 3: [4830/10940] ---- BYOL Training Loss = 0.246172696352005
31-01-2023 02:13:33 INFO Epoch 3: [4841/10940] ---- BYOL Training Loss = 0.22348114848136902
31-01-2023 02:14:26 INFO Epoch 3: [4841/10940] ---- BYOL Validation Loss = 0.23384079337120056
31-01-2023 02:14:43 INFO Epoch 3: [4852/10940] ---- BYOL Training Loss = 0.209280326962471
31-01-2023 02:15:01 INFO Epoch 3: [4863/10940] ---- BYOL Training Loss = 0.23039564490318298
31-01-2023 02:15:19 INFO Epoch 3: [4874/10940] ---- BYOL Training Loss = 0.2220412939786911
31-01-2023 02:15:37 INFO Epoch 3: [4885/10940] ---- BYOL Training Loss = 0.24205279350280762
31-01-2023 02:16:29 INFO Epoch 3: [4885/10940] ---- BYOL Validation Loss = 0.23367370665073395
31-01-2023 02:16:47 INFO Epoch 3: [4896/10940] ---- BYOL Training Loss = 0.2505672872066498
31-01-2023 02:17:05 INFO Epoch 3: [4907/10940] ---- BYOL Training Loss = 0.22687876224517822
31-01-2023 02:17:23 INFO Epoch 3: [4918/10940] ---- BYOL Training Loss = 0.2361994981765747
31-01-2023 02:17:41 INFO Epoch 3: [4929/10940] ---- BYOL Training Loss = 0.22529931366443634
31-01-2023 02:18:33 INFO Epoch 3: [4929/10940] ---- BYOL Validation Loss = 0.22800980508327484
31-01-2023 02:18:51 INFO Epoch 3: [4940/10940] ---- BYOL Training Loss = 0.2344982624053955
31-01-2023 02:19:09 INFO Epoch 3: [4951/10940] ---- BYOL Training Loss = 0.2890109121799469
31-01-2023 02:19:27 INFO Epoch 3: [4962/10940] ---- BYOL Training Loss = 0.26609891653060913
31-01-2023 02:19:45 INFO Epoch 3: [4973/10940] ---- BYOL Training Loss = 0.2160530537366867
31-01-2023 02:20:37 INFO Epoch 3: [4973/10940] ---- BYOL Validation Loss = 0.23285624384880066
31-01-2023 02:20:55 INFO Epoch 3: [4984/10940] ---- BYOL Training Loss = 0.23474881052970886
31-01-2023 02:21:13 INFO Epoch 3: [4995/10940] ---- BYOL Training Loss = 0.21839149296283722
31-01-2023 02:21:31 INFO Epoch 3: [5006/10940] ---- BYOL Training Loss = 0.23994068801403046
31-01-2023 02:21:49 INFO Epoch 3: [5017/10940] ---- BYOL Training Loss = 0.2351052314043045
31-01-2023 02:22:41 INFO Epoch 3: [5017/10940] ---- BYOL Validation Loss = 0.23591718077659607
31-01-2023 02:22:59 INFO Epoch 3: [5028/10940] ---- BYOL Training Loss = 0.23104047775268555
31-01-2023 02:23:17 INFO Epoch 3: [5039/10940] ---- BYOL Training Loss = 0.2616160213947296
31-01-2023 02:23:35 INFO Epoch 3: [5050/10940] ---- BYOL Training Loss = 0.26449277997016907
31-01-2023 02:23:53 INFO Epoch 3: [5061/10940] ---- BYOL Training Loss = 0.24237926304340363
31-01-2023 02:24:45 INFO Epoch 3: [5061/10940] ---- BYOL Validation Loss = 0.2422420233488083
31-01-2023 02:25:03 INFO Epoch 3: [5072/10940] ---- BYOL Training Loss = 0.24638617038726807
31-01-2023 02:25:21 INFO Epoch 3: [5083/10940] ---- BYOL Training Loss = 0.24755820631980896
31-01-2023 02:25:39 INFO Epoch 3: [5094/10940] ---- BYOL Training Loss = 0.2662380337715149
31-01-2023 02:25:57 INFO Epoch 3: [5105/10940] ---- BYOL Training Loss = 0.28273436427116394
31-01-2023 02:26:49 INFO Epoch 3: [5105/10940] ---- BYOL Validation Loss = 0.24612613022327423
31-01-2023 02:27:07 INFO Epoch 3: [5116/10940] ---- BYOL Training Loss = 0.28010818362236023
31-01-2023 02:27:25 INFO Epoch 3: [5127/10940] ---- BYOL Training Loss = 0.27556198835372925
31-01-2023 02:27:43 INFO Epoch 3: [5138/10940] ---- BYOL Training Loss = 0.27899497747421265
31-01-2023 02:28:00 INFO Epoch 3: [5149/10940] ---- BYOL Training Loss = 0.24844786524772644
31-01-2023 02:28:53 INFO Epoch 3: [5149/10940] ---- BYOL Validation Loss = 0.2576924264431
31-01-2023 02:29:11 INFO Epoch 3: [5160/10940] ---- BYOL Training Loss = 0.24272754788398743
31-01-2023 02:29:29 INFO Epoch 3: [5171/10940] ---- BYOL Training Loss = 0.24455928802490234
31-01-2023 02:29:47 INFO Epoch 3: [5182/10940] ---- BYOL Training Loss = 0.2461129128932953
31-01-2023 02:30:05 INFO Epoch 3: [5193/10940] ---- BYOL Training Loss = 0.2776069641113281
31-01-2023 02:30:57 INFO Epoch 3: [5193/10940] ---- BYOL Validation Loss = 0.28145021200180054
31-01-2023 02:31:15 INFO Epoch 3: [5204/10940] ---- BYOL Training Loss = 0.2635095715522766
31-01-2023 02:31:33 INFO Epoch 3: [5215/10940] ---- BYOL Training Loss = 0.2484583556652069
31-01-2023 02:31:51 INFO Epoch 3: [5226/10940] ---- BYOL Training Loss = 0.271074116230011
31-01-2023 02:32:09 INFO Epoch 3: [5237/10940] ---- BYOL Training Loss = 0.2741483449935913
31-01-2023 02:33:01 INFO Epoch 3: [5237/10940] ---- BYOL Validation Loss = 0.2550516426563263
31-01-2023 02:33:19 INFO Epoch 3: [5248/10940] ---- BYOL Training Loss = 0.280595600605011
31-01-2023 02:33:37 INFO Epoch 3: [5259/10940] ---- BYOL Training Loss = 0.27403855323791504
31-01-2023 02:33:55 INFO Epoch 3: [5270/10940] ---- BYOL Training Loss = 0.25180453062057495
31-01-2023 02:34:13 INFO Epoch 3: [5281/10940] ---- BYOL Training Loss = 0.23712444305419922
31-01-2023 02:35:05 INFO Epoch 3: [5281/10940] ---- BYOL Validation Loss = 0.26544418931007385
31-01-2023 02:35:23 INFO Epoch 3: [5292/10940] ---- BYOL Training Loss = 0.24866542220115662
31-01-2023 02:35:40 INFO Epoch 3: [5303/10940] ---- BYOL Training Loss = 0.271689772605896
31-01-2023 02:35:59 INFO Epoch 3: [5314/10940] ---- BYOL Training Loss = 0.25046688318252563
31-01-2023 02:36:17 INFO Epoch 3: [5325/10940] ---- BYOL Training Loss = 0.2799425423145294
31-01-2023 02:37:09 INFO Epoch 3: [5325/10940] ---- BYOL Validation Loss = 0.2426881045103073
31-01-2023 02:37:26 INFO Epoch 3: [5336/10940] ---- BYOL Training Loss = 0.26364341378211975
31-01-2023 02:37:44 INFO Epoch 3: [5347/10940] ---- BYOL Training Loss = 0.24671252071857452
31-01-2023 02:38:03 INFO Epoch 3: [5358/10940] ---- BYOL Training Loss = 0.27733051776885986
31-01-2023 02:38:21 INFO Epoch 3: [5369/10940] ---- BYOL Training Loss = 0.2470022439956665
31-01-2023 02:39:13 INFO Epoch 3: [5369/10940] ---- BYOL Validation Loss = 0.2541908621788025
31-01-2023 02:39:31 INFO Epoch 3: [5380/10940] ---- BYOL Training Loss = 0.2643071711063385
31-01-2023 02:39:49 INFO Epoch 3: [5391/10940] ---- BYOL Training Loss = 0.26981475949287415
31-01-2023 02:40:07 INFO Epoch 3: [5402/10940] ---- BYOL Training Loss = 0.2330532968044281
31-01-2023 02:40:25 INFO Epoch 3: [5413/10940] ---- BYOL Training Loss = 0.27486029267311096
31-01-2023 02:41:17 INFO Epoch 3: [5413/10940] ---- BYOL Validation Loss = 0.2494446039199829
31-01-2023 02:41:35 INFO Epoch 3: [5424/10940] ---- BYOL Training Loss = 0.26917654275894165
31-01-2023 02:41:53 INFO Epoch 3: [5435/10940] ---- BYOL Training Loss = 0.26449838280677795
31-01-2023 02:42:11 INFO Epoch 3: [5446/10940] ---- BYOL Training Loss = 0.2704945206642151
31-01-2023 02:42:29 INFO Epoch 3: [5457/10940] ---- BYOL Training Loss = 0.2711966633796692
31-01-2023 02:43:21 INFO Epoch 3: [5457/10940] ---- BYOL Validation Loss = 0.25194740295410156
31-01-2023 02:43:39 INFO Epoch 3: [5468/10940] ---- BYOL Training Loss = 0.24879905581474304
31-01-2023 02:43:57 INFO Epoch 3: [5479/10940] ---- BYOL Training Loss = 0.24587123095989227
31-01-2023 02:44:15 INFO Epoch 3: [5490/10940] ---- BYOL Training Loss = 0.22912856936454773
31-01-2023 02:44:33 INFO Epoch 3: [5501/10940] ---- BYOL Training Loss = 0.25632381439208984
31-01-2023 02:45:25 INFO Epoch 3: [5501/10940] ---- BYOL Validation Loss = 0.2518938481807709
31-01-2023 02:45:43 INFO Epoch 3: [5512/10940] ---- BYOL Training Loss = 0.30735287070274353
31-01-2023 02:46:01 INFO Epoch 3: [5523/10940] ---- BYOL Training Loss = 0.29158225655555725
31-01-2023 02:46:19 INFO Epoch 3: [5534/10940] ---- BYOL Training Loss = 0.285250723361969
31-01-2023 02:46:37 INFO Epoch 3: [5545/10940] ---- BYOL Training Loss = 0.28965243697166443
31-01-2023 02:47:29 INFO Epoch 3: [5545/10940] ---- BYOL Validation Loss = 0.25634846091270447
31-01-2023 02:47:47 INFO Epoch 3: [5556/10940] ---- BYOL Training Loss = 0.2972434163093567
31-01-2023 02:48:05 INFO Epoch 3: [5567/10940] ---- BYOL Training Loss = 0.2957305312156677
31-01-2023 02:48:23 INFO Epoch 3: [5578/10940] ---- BYOL Training Loss = 0.25065380334854126
31-01-2023 02:48:42 INFO Epoch 3: [5589/10940] ---- BYOL Training Loss = 0.2623087763786316
31-01-2023 02:49:34 INFO Epoch 3: [5589/10940] ---- BYOL Validation Loss = 0.23531600832939148
31-01-2023 02:49:51 INFO Epoch 3: [5600/10940] ---- BYOL Training Loss = 0.2566813826560974
31-01-2023 02:50:09 INFO Epoch 3: [5611/10940] ---- BYOL Training Loss = 0.2402501404285431
31-01-2023 02:50:28 INFO Epoch 3: [5622/10940] ---- BYOL Training Loss = 0.23068025708198547
31-01-2023 02:50:46 INFO Epoch 3: [5633/10940] ---- BYOL Training Loss = 0.2604594826698303
31-01-2023 02:51:38 INFO Epoch 3: [5633/10940] ---- BYOL Validation Loss = 0.24782757461071014
31-01-2023 02:51:56 INFO Epoch 3: [5644/10940] ---- BYOL Training Loss = 0.2720363736152649
31-01-2023 02:52:14 INFO Epoch 3: [5655/10940] ---- BYOL Training Loss = 0.2645733952522278
31-01-2023 02:52:32 INFO Epoch 3: [5666/10940] ---- BYOL Training Loss = 0.2682393193244934
31-01-2023 02:52:50 INFO Epoch 3: [5677/10940] ---- BYOL Training Loss = 0.28322526812553406
31-01-2023 02:53:42 INFO Epoch 3: [5677/10940] ---- BYOL Validation Loss = 0.2439769208431244
31-01-2023 02:54:00 INFO Epoch 3: [5688/10940] ---- BYOL Training Loss = 0.2612053453922272
31-01-2023 02:54:18 INFO Epoch 3: [5699/10940] ---- BYOL Training Loss = 0.2528893053531647
31-01-2023 02:54:36 INFO Epoch 3: [5710/10940] ---- BYOL Training Loss = 0.24760766327381134
31-01-2023 02:54:54 INFO Epoch 3: [5721/10940] ---- BYOL Training Loss = 0.23719756305217743
31-01-2023 02:55:46 INFO Epoch 3: [5721/10940] ---- BYOL Validation Loss = 0.23569639027118683
31-01-2023 02:56:04 INFO Epoch 3: [5732/10940] ---- BYOL Training Loss = 0.27558112144470215
31-01-2023 02:56:22 INFO Epoch 3: [5743/10940] ---- BYOL Training Loss = 0.2772626280784607
31-01-2023 02:56:40 INFO Epoch 3: [5754/10940] ---- BYOL Training Loss = 0.24659840762615204
31-01-2023 02:56:58 INFO Epoch 3: [5765/10940] ---- BYOL Training Loss = 0.23129132390022278
31-01-2023 02:57:51 INFO Epoch 3: [5765/10940] ---- BYOL Validation Loss = 0.2387770265340805
31-01-2023 02:58:09 INFO Epoch 3: [5776/10940] ---- BYOL Training Loss = 0.22688138484954834
31-01-2023 02:58:27 INFO Epoch 3: [5787/10940] ---- BYOL Training Loss = 0.23628607392311096
31-01-2023 02:58:45 INFO Epoch 3: [5798/10940] ---- BYOL Training Loss = 0.24004468321800232
31-01-2023 02:59:03 INFO Epoch 3: [5809/10940] ---- BYOL Training Loss = 0.23762989044189453
31-01-2023 02:59:55 INFO Epoch 3: [5809/10940] ---- BYOL Validation Loss = 0.22924396395683289
31-01-2023 03:00:13 INFO Epoch 3: [5820/10940] ---- BYOL Training Loss = 0.24457624554634094
31-01-2023 03:00:31 INFO Epoch 3: [5831/10940] ---- BYOL Training Loss = 0.21293315291404724
31-01-2023 03:00:49 INFO Epoch 3: [5842/10940] ---- BYOL Training Loss = 0.24969074130058289
31-01-2023 03:01:07 INFO Epoch 3: [5853/10940] ---- BYOL Training Loss = 0.2606128752231598
31-01-2023 03:01:59 INFO Epoch 3: [5853/10940] ---- BYOL Validation Loss = 0.23148390650749207
31-01-2023 03:02:17 INFO Epoch 3: [5864/10940] ---- BYOL Training Loss = 0.2306961566209793
31-01-2023 03:02:36 INFO Epoch 3: [5875/10940] ---- BYOL Training Loss = 0.21552273631095886
31-01-2023 03:02:54 INFO Epoch 3: [5886/10940] ---- BYOL Training Loss = 0.2317865788936615
31-01-2023 03:03:12 INFO Epoch 3: [5897/10940] ---- BYOL Training Loss = 0.20824924111366272
31-01-2023 03:04:04 INFO Epoch 3: [5897/10940] ---- BYOL Validation Loss = 0.2246936410665512
31-01-2023 03:04:22 INFO Epoch 3: [5908/10940] ---- BYOL Training Loss = 0.2353728711605072
31-01-2023 03:04:40 INFO Epoch 3: [5919/10940] ---- BYOL Training Loss = 0.23679694533348083
31-01-2023 03:04:58 INFO Epoch 3: [5930/10940] ---- BYOL Training Loss = 0.24114954471588135
31-01-2023 03:05:16 INFO Epoch 3: [5941/10940] ---- BYOL Training Loss = 0.22329914569854736
31-01-2023 03:06:09 INFO Epoch 3: [5941/10940] ---- BYOL Validation Loss = 0.22316043078899384
31-01-2023 03:06:27 INFO Epoch 3: [5952/10940] ---- BYOL Training Loss = 0.23959653079509735
31-01-2023 03:06:45 INFO Epoch 3: [5963/10940] ---- BYOL Training Loss = 0.2377484291791916
31-01-2023 03:07:03 INFO Epoch 3: [5974/10940] ---- BYOL Training Loss = 0.2599402070045471
31-01-2023 03:07:21 INFO Epoch 3: [5985/10940] ---- BYOL Training Loss = 0.3129638433456421
31-01-2023 03:08:13 INFO Epoch 3: [5985/10940] ---- BYOL Validation Loss = 0.22326305508613586
31-01-2023 03:08:31 INFO Epoch 3: [5996/10940] ---- BYOL Training Loss = 0.2437928169965744
31-01-2023 03:08:49 INFO Epoch 3: [6007/10940] ---- BYOL Training Loss = 0.26957282423973083
31-01-2023 03:09:07 INFO Epoch 3: [6018/10940] ---- BYOL Training Loss = 0.2648288607597351
31-01-2023 03:09:25 INFO Epoch 3: [6029/10940] ---- BYOL Training Loss = 0.2602258026599884
31-01-2023 03:10:17 INFO Epoch 3: [6029/10940] ---- BYOL Validation Loss = 0.22654907405376434
31-01-2023 03:10:35 INFO Epoch 3: [6040/10940] ---- BYOL Training Loss = 0.23022718727588654
31-01-2023 03:10:53 INFO Epoch 3: [6051/10940] ---- BYOL Training Loss = 0.20624785125255585
31-01-2023 03:11:12 INFO Epoch 3: [6062/10940] ---- BYOL Training Loss = 0.22980542480945587
31-01-2023 03:11:30 INFO Epoch 3: [6073/10940] ---- BYOL Training Loss = 0.28220805525779724
31-01-2023 03:12:22 INFO Epoch 3: [6073/10940] ---- BYOL Validation Loss = 0.23226793110370636
31-01-2023 03:12:40 INFO Epoch 3: [6084/10940] ---- BYOL Training Loss = 0.2582249641418457
31-01-2023 03:12:58 INFO Epoch 3: [6095/10940] ---- BYOL Training Loss = 0.21734002232551575
31-01-2023 03:13:16 INFO Epoch 3: [6106/10940] ---- BYOL Training Loss = 0.22580328583717346
31-01-2023 03:13:34 INFO Epoch 3: [6117/10940] ---- BYOL Training Loss = 0.2370656430721283
31-01-2023 03:14:26 INFO Epoch 3: [6117/10940] ---- BYOL Validation Loss = 0.2356061190366745
31-01-2023 03:14:44 INFO Epoch 3: [6128/10940] ---- BYOL Training Loss = 0.21905860304832458
31-01-2023 03:15:02 INFO Epoch 3: [6139/10940] ---- BYOL Training Loss = 0.2337806671857834
31-01-2023 03:15:21 INFO Epoch 3: [6150/10940] ---- BYOL Training Loss = 0.2899676561355591
31-01-2023 03:15:39 INFO Epoch 3: [6161/10940] ---- BYOL Training Loss = 0.2600361406803131
31-01-2023 03:16:31 INFO Epoch 3: [6161/10940] ---- BYOL Validation Loss = 0.2227613776922226
31-01-2023 03:16:49 INFO Epoch 3: [6172/10940] ---- BYOL Training Loss = 0.23704512417316437
31-01-2023 03:17:07 INFO Epoch 3: [6183/10940] ---- BYOL Training Loss = 0.2078293263912201
31-01-2023 03:17:25 INFO Epoch 3: [6194/10940] ---- BYOL Training Loss = 0.25244542956352234
31-01-2023 03:17:43 INFO Epoch 3: [6205/10940] ---- BYOL Training Loss = 0.2984125018119812
31-01-2023 03:18:35 INFO Epoch 3: [6205/10940] ---- BYOL Validation Loss = 0.22937393188476562
31-01-2023 03:18:53 INFO Epoch 3: [6216/10940] ---- BYOL Training Loss = 0.2687009871006012
31-01-2023 03:19:11 INFO Epoch 3: [6227/10940] ---- BYOL Training Loss = 0.24238309264183044
31-01-2023 03:19:29 INFO Epoch 3: [6238/10940] ---- BYOL Training Loss = 0.2473515272140503
31-01-2023 03:19:48 INFO Epoch 3: [6249/10940] ---- BYOL Training Loss = 0.251001238822937
31-01-2023 03:20:40 INFO Epoch 3: [6249/10940] ---- BYOL Validation Loss = 0.227989062666893
31-01-2023 03:20:58 INFO Epoch 3: [6260/10940] ---- BYOL Training Loss = 0.2677941918373108
31-01-2023 03:21:16 INFO Epoch 3: [6271/10940] ---- BYOL Training Loss = 0.24143779277801514
31-01-2023 03:21:34 INFO Epoch 3: [6282/10940] ---- BYOL Training Loss = 0.2308933436870575
31-01-2023 03:21:52 INFO Epoch 3: [6293/10940] ---- BYOL Training Loss = 0.2078896313905716
31-01-2023 03:22:44 INFO Epoch 3: [6293/10940] ---- BYOL Validation Loss = 0.22400440275669098
31-01-2023 03:23:02 INFO Epoch 3: [6304/10940] ---- BYOL Training Loss = 0.21480000019073486
31-01-2023 03:23:20 INFO Epoch 3: [6315/10940] ---- BYOL Training Loss = 0.24184837937355042
31-01-2023 03:23:38 INFO Epoch 3: [6326/10940] ---- BYOL Training Loss = 0.23263409733772278
31-01-2023 03:23:57 INFO Epoch 3: [6337/10940] ---- BYOL Training Loss = 0.2246112823486328
31-01-2023 03:24:49 INFO Epoch 3: [6337/10940] ---- BYOL Validation Loss = 0.21527047455310822
31-01-2023 03:25:07 INFO Epoch 3: [6348/10940] ---- BYOL Training Loss = 0.22978568077087402
31-01-2023 03:25:25 INFO Epoch 3: [6359/10940] ---- BYOL Training Loss = 0.28317078948020935
31-01-2023 03:25:43 INFO Epoch 3: [6370/10940] ---- BYOL Training Loss = 0.25073695182800293
31-01-2023 03:26:01 INFO Epoch 3: [6381/10940] ---- BYOL Training Loss = 0.2659446597099304
31-01-2023 03:26:53 INFO Epoch 3: [6381/10940] ---- BYOL Validation Loss = 0.1831110715866089
31-01-2023 03:27:11 INFO Epoch 3: [6392/10940] ---- BYOL Training Loss = 0.2447601556777954
31-01-2023 03:27:29 INFO Epoch 3: [6403/10940] ---- BYOL Training Loss = 0.21137967705726624
31-01-2023 03:27:48 INFO Epoch 3: [6414/10940] ---- BYOL Training Loss = 0.23604169487953186
31-01-2023 03:28:06 INFO Epoch 3: [6425/10940] ---- BYOL Training Loss = 0.2362738847732544
31-01-2023 03:28:58 INFO Epoch 3: [6425/10940] ---- BYOL Validation Loss = 0.21086399257183075
31-01-2023 03:29:16 INFO Epoch 3: [6436/10940] ---- BYOL Training Loss = 0.21326550841331482
31-01-2023 03:29:34 INFO Epoch 3: [6447/10940] ---- BYOL Training Loss = 0.2150297462940216
31-01-2023 03:29:52 INFO Epoch 3: [6458/10940] ---- BYOL Training Loss = 0.23187291622161865
31-01-2023 03:30:10 INFO Epoch 3: [6469/10940] ---- BYOL Training Loss = 0.20269139111042023
31-01-2023 03:31:03 INFO Epoch 3: [6469/10940] ---- BYOL Validation Loss = 0.2034064680337906
31-01-2023 03:31:20 INFO Epoch 3: [6480/10940] ---- BYOL Training Loss = 0.1916133165359497
31-01-2023 03:31:38 INFO Epoch 3: [6491/10940] ---- BYOL Training Loss = 0.22884294390678406
31-01-2023 03:31:57 INFO Epoch 3: [6502/10940] ---- BYOL Training Loss = 0.2692757546901703
31-01-2023 03:32:15 INFO Epoch 3: [6513/10940] ---- BYOL Training Loss = 0.27334049344062805
31-01-2023 03:33:07 INFO Epoch 3: [6513/10940] ---- BYOL Validation Loss = 0.21449041366577148
31-01-2023 03:33:25 INFO Epoch 3: [6524/10940] ---- BYOL Training Loss = 0.26831871271133423
31-01-2023 03:33:43 INFO Epoch 3: [6535/10940] ---- BYOL Training Loss = 0.2673611342906952
31-01-2023 03:34:01 INFO Epoch 3: [6546/10940] ---- BYOL Training Loss = 0.23460301756858826
31-01-2023 03:34:19 INFO Epoch 3: [6557/10940] ---- BYOL Training Loss = 0.22567176818847656
31-01-2023 03:35:12 INFO Epoch 3: [6557/10940] ---- BYOL Validation Loss = 0.2190220057964325
31-01-2023 03:35:29 INFO Epoch 3: [6568/10940] ---- BYOL Training Loss = 0.24321457743644714
31-01-2023 03:35:48 INFO Epoch 3: [6579/10940] ---- BYOL Training Loss = 0.19088509678840637
31-01-2023 03:36:06 INFO Epoch 3: [6590/10940] ---- BYOL Training Loss = 0.18528521060943604
31-01-2023 03:36:24 INFO Epoch 3: [6601/10940] ---- BYOL Training Loss = 0.20969057083129883
31-01-2023 03:37:16 INFO Epoch 3: [6601/10940] ---- BYOL Validation Loss = 0.22020064294338226
31-01-2023 03:37:34 INFO Epoch 3: [6612/10940] ---- BYOL Training Loss = 0.25814488530158997
31-01-2023 03:37:52 INFO Epoch 3: [6623/10940] ---- BYOL Training Loss = 0.24693839251995087
31-01-2023 03:38:10 INFO Epoch 3: [6634/10940] ---- BYOL Training Loss = 0.18706923723220825
31-01-2023 03:38:28 INFO Epoch 3: [6645/10940] ---- BYOL Training Loss = 0.21068806946277618
31-01-2023 03:39:21 INFO Epoch 3: [6645/10940] ---- BYOL Validation Loss = 0.2092987447977066
31-01-2023 03:39:39 INFO Epoch 3: [6656/10940] ---- BYOL Training Loss = 0.21100933849811554
31-01-2023 03:39:57 INFO Epoch 3: [6667/10940] ---- BYOL Training Loss = 0.22727937996387482
31-01-2023 03:40:15 INFO Epoch 3: [6678/10940] ---- BYOL Training Loss = 0.22136835753917694
31-01-2023 03:40:33 INFO Epoch 3: [6689/10940] ---- BYOL Training Loss = 0.2525683343410492
31-01-2023 03:41:25 INFO Epoch 3: [6689/10940] ---- BYOL Validation Loss = 0.20319649577140808
31-01-2023 03:41:43 INFO Epoch 3: [6700/10940] ---- BYOL Training Loss = 0.22367286682128906
31-01-2023 03:42:01 INFO Epoch 3: [6711/10940] ---- BYOL Training Loss = 0.2182813584804535
31-01-2023 03:42:19 INFO Epoch 3: [6722/10940] ---- BYOL Training Loss = 0.24984559416770935
31-01-2023 03:42:38 INFO Epoch 3: [6733/10940] ---- BYOL Training Loss = 0.2390429526567459
31-01-2023 03:43:30 INFO Epoch 3: [6733/10940] ---- BYOL Validation Loss = 0.21452046930789948
31-01-2023 03:43:48 INFO Epoch 3: [6744/10940] ---- BYOL Training Loss = 0.20030221343040466
31-01-2023 03:44:06 INFO Epoch 3: [6755/10940] ---- BYOL Training Loss = 0.24653181433677673
31-01-2023 03:44:24 INFO Epoch 3: [6766/10940] ---- BYOL Training Loss = 0.2776259481906891
31-01-2023 03:44:42 INFO Epoch 3: [6777/10940] ---- BYOL Training Loss = 0.25406432151794434
31-01-2023 03:45:35 INFO Epoch 3: [6777/10940] ---- BYOL Validation Loss = 0.21364542841911316
31-01-2023 03:45:52 INFO Epoch 3: [6788/10940] ---- BYOL Training Loss = 0.2649030089378357
31-01-2023 03:46:10 INFO Epoch 3: [6799/10940] ---- BYOL Training Loss = 0.23556537926197052
31-01-2023 03:46:29 INFO Epoch 3: [6810/10940] ---- BYOL Training Loss = 0.24592411518096924
31-01-2023 03:46:47 INFO Epoch 3: [6821/10940] ---- BYOL Training Loss = 0.2392611801624298
31-01-2023 03:47:39 INFO Epoch 3: [6821/10940] ---- BYOL Validation Loss = 0.2246394157409668
31-01-2023 03:47:57 INFO Epoch 3: [6832/10940] ---- BYOL Training Loss = 0.2056216448545456
31-01-2023 03:48:15 INFO Epoch 3: [6843/10940] ---- BYOL Training Loss = 0.20961005985736847
31-01-2023 03:48:33 INFO Epoch 3: [6854/10940] ---- BYOL Training Loss = 0.22233621776103973
31-01-2023 03:48:52 INFO Epoch 3: [6865/10940] ---- BYOL Training Loss = 0.23843030631542206
31-01-2023 03:49:44 INFO Epoch 3: [6865/10940] ---- BYOL Validation Loss = 0.21369756758213043
31-01-2023 03:50:02 INFO Epoch 3: [6876/10940] ---- BYOL Training Loss = 0.2513480484485626
31-01-2023 03:50:20 INFO Epoch 3: [6887/10940] ---- BYOL Training Loss = 0.28089219331741333
31-01-2023 03:50:38 INFO Epoch 3: [6898/10940] ---- BYOL Training Loss = 0.28513750433921814
31-01-2023 03:50:56 INFO Epoch 3: [6909/10940] ---- BYOL Training Loss = 0.2342807799577713
31-01-2023 03:51:49 INFO Epoch 3: [6909/10940] ---- BYOL Validation Loss = 0.21799632906913757
31-01-2023 03:52:07 INFO Epoch 3: [6920/10940] ---- BYOL Training Loss = 0.22033901512622833
31-01-2023 03:52:25 INFO Epoch 3: [6931/10940] ---- BYOL Training Loss = 0.2586260437965393
31-01-2023 03:52:43 INFO Epoch 3: [6942/10940] ---- BYOL Training Loss = 0.2530410885810852
31-01-2023 03:53:02 INFO Epoch 3: [6953/10940] ---- BYOL Training Loss = 0.25974714756011963
31-01-2023 03:53:54 INFO Epoch 3: [6953/10940] ---- BYOL Validation Loss = 0.20838461816310883
31-01-2023 03:54:12 INFO Epoch 3: [6964/10940] ---- BYOL Training Loss = 0.26744523644447327
31-01-2023 03:54:30 INFO Epoch 3: [6975/10940] ---- BYOL Training Loss = 0.24551883339881897
31-01-2023 03:54:48 INFO Epoch 3: [6986/10940] ---- BYOL Training Loss = 0.20708143711090088
31-01-2023 03:55:06 INFO Epoch 3: [6997/10940] ---- BYOL Training Loss = 0.21931776404380798
31-01-2023 03:55:59 INFO Epoch 3: [6997/10940] ---- BYOL Validation Loss = 0.21894192695617676
31-01-2023 03:56:16 INFO Epoch 3: [7008/10940] ---- BYOL Training Loss = 0.2004762887954712
31-01-2023 03:56:34 INFO Epoch 3: [7019/10940] ---- BYOL Training Loss = 0.26114794611930847
31-01-2023 03:56:53 INFO Epoch 3: [7030/10940] ---- BYOL Training Loss = 0.25379833579063416
31-01-2023 03:57:11 INFO Epoch 3: [7041/10940] ---- BYOL Training Loss = 0.23911985754966736
31-01-2023 03:58:03 INFO Epoch 3: [7041/10940] ---- BYOL Validation Loss = 0.21994109451770782
31-01-2023 03:58:21 INFO Epoch 3: [7052/10940] ---- BYOL Training Loss = 0.2730405330657959
31-01-2023 03:58:39 INFO Epoch 3: [7063/10940] ---- BYOL Training Loss = 0.2607850432395935
31-01-2023 03:58:58 INFO Epoch 3: [7074/10940] ---- BYOL Training Loss = 0.2580675184726715
31-01-2023 03:59:16 INFO Epoch 3: [7085/10940] ---- BYOL Training Loss = 0.22757939994335175
31-01-2023 04:00:08 INFO Epoch 3: [7085/10940] ---- BYOL Validation Loss = 0.21105632185935974
31-01-2023 04:00:26 INFO Epoch 3: [7096/10940] ---- BYOL Training Loss = 0.2565711438655853
31-01-2023 04:00:44 INFO Epoch 3: [7107/10940] ---- BYOL Training Loss = 0.24305510520935059
31-01-2023 04:01:02 INFO Epoch 3: [7118/10940] ---- BYOL Training Loss = 0.22118563950061798
31-01-2023 04:01:20 INFO Epoch 3: [7129/10940] ---- BYOL Training Loss = 0.23864416778087616
31-01-2023 04:02:12 INFO Epoch 3: [7129/10940] ---- BYOL Validation Loss = 0.21769747138023376
31-01-2023 04:02:30 INFO Epoch 3: [7140/10940] ---- BYOL Training Loss = 0.21019423007965088
31-01-2023 04:02:49 INFO Epoch 3: [7151/10940] ---- BYOL Training Loss = 0.19540762901306152
31-01-2023 04:03:07 INFO Epoch 3: [7162/10940] ---- BYOL Training Loss = 0.19633258879184723
31-01-2023 04:03:25 INFO Epoch 3: [7173/10940] ---- BYOL Training Loss = 0.2667153775691986
31-01-2023 04:04:17 INFO Epoch 3: [7173/10940] ---- BYOL Validation Loss = 0.22121794521808624
31-01-2023 04:04:35 INFO Epoch 3: [7184/10940] ---- BYOL Training Loss = 0.28337767720222473
31-01-2023 04:04:54 INFO Epoch 3: [7195/10940] ---- BYOL Training Loss = 0.24437101185321808
31-01-2023 04:05:12 INFO Epoch 3: [7206/10940] ---- BYOL Training Loss = 0.24639303982257843
31-01-2023 04:05:30 INFO Epoch 3: [7217/10940] ---- BYOL Training Loss = 0.24789993464946747
31-01-2023 04:06:23 INFO Epoch 3: [7217/10940] ---- BYOL Validation Loss = 0.21810133755207062
31-01-2023 04:06:40 INFO Epoch 3: [7228/10940] ---- BYOL Training Loss = 0.2178453654050827
31-01-2023 04:06:58 INFO Epoch 3: [7239/10940] ---- BYOL Training Loss = 0.2287077158689499
31-01-2023 04:07:17 INFO Epoch 3: [7250/10940] ---- BYOL Training Loss = 0.22297056019306183
31-01-2023 04:07:35 INFO Epoch 3: [7261/10940] ---- BYOL Training Loss = 0.18916168808937073
31-01-2023 04:08:27 INFO Epoch 3: [7261/10940] ---- BYOL Validation Loss = 0.21078240871429443
31-01-2023 04:08:45 INFO Epoch 3: [7272/10940] ---- BYOL Training Loss = 0.17605465650558472
31-01-2023 04:09:03 INFO Epoch 3: [7283/10940] ---- BYOL Training Loss = 0.20172390341758728
31-01-2023 04:09:22 INFO Epoch 3: [7294/10940] ---- BYOL Training Loss = 0.23110513389110565
31-01-2023 04:09:40 INFO Epoch 3: [7305/10940] ---- BYOL Training Loss = 0.22067418694496155
31-01-2023 04:10:32 INFO Epoch 3: [7305/10940] ---- BYOL Validation Loss = 0.21777403354644775
31-01-2023 04:10:50 INFO Epoch 3: [7316/10940] ---- BYOL Training Loss = 0.25904664397239685
31-01-2023 04:11:08 INFO Epoch 3: [7327/10940] ---- BYOL Training Loss = 0.2230774164199829
31-01-2023 04:11:26 INFO Epoch 3: [7338/10940] ---- BYOL Training Loss = 0.218462273478508
31-01-2023 04:11:44 INFO Epoch 3: [7349/10940] ---- BYOL Training Loss = 0.25545966625213623
31-01-2023 04:12:37 INFO Epoch 3: [7349/10940] ---- BYOL Validation Loss = 0.21911247074604034
31-01-2023 04:12:55 INFO Epoch 3: [7360/10940] ---- BYOL Training Loss = 0.26473841071128845
31-01-2023 04:13:13 INFO Epoch 3: [7371/10940] ---- BYOL Training Loss = 0.24467888474464417
31-01-2023 04:13:31 INFO Epoch 3: [7382/10940] ---- BYOL Training Loss = 0.23299574851989746
31-01-2023 04:13:49 INFO Epoch 3: [7393/10940] ---- BYOL Training Loss = 0.2521422803401947
31-01-2023 04:14:42 INFO Epoch 3: [7393/10940] ---- BYOL Validation Loss = 0.22578753530979156
31-01-2023 04:15:00 INFO Epoch 3: [7404/10940] ---- BYOL Training Loss = 0.1988435536623001
31-01-2023 04:15:18 INFO Epoch 3: [7415/10940] ---- BYOL Training Loss = 0.20780809223651886
31-01-2023 04:15:36 INFO Epoch 3: [7426/10940] ---- BYOL Training Loss = 0.21900734305381775
31-01-2023 04:15:55 INFO Epoch 3: [7437/10940] ---- BYOL Training Loss = 0.24730949103832245
31-01-2023 04:16:47 INFO Epoch 3: [7437/10940] ---- BYOL Validation Loss = 0.2148822695016861
31-01-2023 04:17:05 INFO Epoch 3: [7448/10940] ---- BYOL Training Loss = 0.2414688766002655
31-01-2023 04:17:23 INFO Epoch 3: [7459/10940] ---- BYOL Training Loss = 0.21293380856513977
31-01-2023 04:17:42 INFO Epoch 3: [7470/10940] ---- BYOL Training Loss = 0.239543154835701
31-01-2023 04:18:00 INFO Epoch 3: [7481/10940] ---- BYOL Training Loss = 0.24493929743766785
31-01-2023 04:18:52 INFO Epoch 3: [7481/10940] ---- BYOL Validation Loss = 0.22052589058876038
31-01-2023 04:19:10 INFO Epoch 3: [7492/10940] ---- BYOL Training Loss = 0.23665647208690643
31-01-2023 04:19:28 INFO Epoch 3: [7503/10940] ---- BYOL Training Loss = 0.19536983966827393
31-01-2023 04:19:46 INFO Epoch 3: [7514/10940] ---- BYOL Training Loss = 0.21752126514911652
31-01-2023 04:20:05 INFO Epoch 3: [7525/10940] ---- BYOL Training Loss = 0.22993941605091095
31-01-2023 04:20:57 INFO Epoch 3: [7525/10940] ---- BYOL Validation Loss = 0.21243824064731598
31-01-2023 04:21:15 INFO Epoch 3: [7536/10940] ---- BYOL Training Loss = 0.25964969396591187
31-01-2023 04:21:33 INFO Epoch 3: [7547/10940] ---- BYOL Training Loss = 0.29362952709198
31-01-2023 04:21:51 INFO Epoch 3: [7558/10940] ---- BYOL Training Loss = 0.22207355499267578
31-01-2023 04:22:10 INFO Epoch 3: [7569/10940] ---- BYOL Training Loss = 0.20851902663707733
31-01-2023 04:23:02 INFO Epoch 3: [7569/10940] ---- BYOL Validation Loss = 0.1833936870098114
31-01-2023 04:23:20 INFO Epoch 3: [7580/10940] ---- BYOL Training Loss = 0.23796388506889343
31-01-2023 04:23:38 INFO Epoch 3: [7591/10940] ---- BYOL Training Loss = 0.2395782768726349
31-01-2023 04:23:57 INFO Epoch 3: [7602/10940] ---- BYOL Training Loss = 0.23864886164665222
31-01-2023 04:24:15 INFO Epoch 3: [7613/10940] ---- BYOL Training Loss = 0.25888580083847046
31-01-2023 04:25:07 INFO Epoch 3: [7613/10940] ---- BYOL Validation Loss = 0.20091666281223297
31-01-2023 04:25:25 INFO Epoch 3: [7624/10940] ---- BYOL Training Loss = 0.2638353705406189
31-01-2023 04:25:43 INFO Epoch 3: [7635/10940] ---- BYOL Training Loss = 0.2726309895515442
31-01-2023 04:26:02 INFO Epoch 3: [7646/10940] ---- BYOL Training Loss = 0.27196699380874634
31-01-2023 04:26:20 INFO Epoch 3: [7657/10940] ---- BYOL Training Loss = 0.2732939124107361
31-01-2023 04:27:12 INFO Epoch 3: [7657/10940] ---- BYOL Validation Loss = 0.2251890003681183
31-01-2023 04:27:30 INFO Epoch 3: [7668/10940] ---- BYOL Training Loss = 0.24647589027881622
31-01-2023 04:27:48 INFO Epoch 3: [7679/10940] ---- BYOL Training Loss = 0.19054166972637177
31-01-2023 04:28:07 INFO Epoch 3: [7690/10940] ---- BYOL Training Loss = 0.17428383231163025
31-01-2023 04:28:25 INFO Epoch 3: [7701/10940] ---- BYOL Training Loss = 0.20948128402233124
31-01-2023 04:29:17 INFO Epoch 3: [7701/10940] ---- BYOL Validation Loss = 0.22275832295417786
31-01-2023 04:29:35 INFO Epoch 3: [7712/10940] ---- BYOL Training Loss = 0.21241740882396698
31-01-2023 04:29:53 INFO Epoch 3: [7723/10940] ---- BYOL Training Loss = 0.20438417792320251
31-01-2023 04:30:12 INFO Epoch 3: [7734/10940] ---- BYOL Training Loss = 0.21405303478240967
31-01-2023 04:30:30 INFO Epoch 3: [7745/10940] ---- BYOL Training Loss = 0.2087612897157669
31-01-2023 04:31:22 INFO Epoch 3: [7745/10940] ---- BYOL Validation Loss = 0.20594897866249084
31-01-2023 04:31:40 INFO Epoch 3: [7756/10940] ---- BYOL Training Loss = 0.2036040723323822
31-01-2023 04:31:59 INFO Epoch 3: [7767/10940] ---- BYOL Training Loss = 0.2223837673664093
31-01-2023 04:32:17 INFO Epoch 3: [7778/10940] ---- BYOL Training Loss = 0.21618983149528503
31-01-2023 04:32:35 INFO Epoch 3: [7789/10940] ---- BYOL Training Loss = 0.1951601356267929
31-01-2023 04:33:28 INFO Epoch 3: [7789/10940] ---- BYOL Validation Loss = 0.20962199568748474
31-01-2023 04:33:45 INFO Epoch 3: [7800/10940] ---- BYOL Training Loss = 0.23180797696113586
31-01-2023 04:34:04 INFO Epoch 3: [7811/10940] ---- BYOL Training Loss = 0.2837236821651459
31-01-2023 04:34:22 INFO Epoch 3: [7822/10940] ---- BYOL Training Loss = 0.2156563252210617
31-01-2023 04:34:41 INFO Epoch 3: [7833/10940] ---- BYOL Training Loss = 0.21248593926429749
31-01-2023 04:35:33 INFO Epoch 3: [7833/10940] ---- BYOL Validation Loss = 0.21417805552482605
31-01-2023 04:35:51 INFO Epoch 3: [7844/10940] ---- BYOL Training Loss = 0.24519595503807068
31-01-2023 04:36:09 INFO Epoch 3: [7855/10940] ---- BYOL Training Loss = 0.2537505030632019
31-01-2023 04:36:27 INFO Epoch 3: [7866/10940] ---- BYOL Training Loss = 0.240107923746109
31-01-2023 04:36:46 INFO Epoch 3: [7877/10940] ---- BYOL Training Loss = 0.2134658545255661
31-01-2023 04:37:38 INFO Epoch 3: [7877/10940] ---- BYOL Validation Loss = 0.21481016278266907
31-01-2023 04:37:56 INFO Epoch 3: [7888/10940] ---- BYOL Training Loss = 0.2292242795228958
31-01-2023 04:38:14 INFO Epoch 3: [7899/10940] ---- BYOL Training Loss = 0.23584027588367462
31-01-2023 04:38:33 INFO Epoch 3: [7910/10940] ---- BYOL Training Loss = 0.1884804666042328
31-01-2023 04:38:51 INFO Epoch 3: [7921/10940] ---- BYOL Training Loss = 0.18837428092956543
31-01-2023 04:39:43 INFO Epoch 3: [7921/10940] ---- BYOL Validation Loss = 0.2082240730524063
31-01-2023 04:40:01 INFO Epoch 3: [7932/10940] ---- BYOL Training Loss = 0.22692689299583435
31-01-2023 04:40:20 INFO Epoch 3: [7943/10940] ---- BYOL Training Loss = 0.22508633136749268
31-01-2023 04:40:38 INFO Epoch 3: [7954/10940] ---- BYOL Training Loss = 0.2605755925178528
31-01-2023 04:40:56 INFO Epoch 3: [7965/10940] ---- BYOL Training Loss = 0.2755414843559265
31-01-2023 04:41:48 INFO Epoch 3: [7965/10940] ---- BYOL Validation Loss = 0.20883914828300476
31-01-2023 04:42:07 INFO Epoch 3: [7976/10940] ---- BYOL Training Loss = 0.2715153098106384
31-01-2023 04:42:25 INFO Epoch 3: [7987/10940] ---- BYOL Training Loss = 0.2694530189037323
31-01-2023 04:42:43 INFO Epoch 3: [7998/10940] ---- BYOL Training Loss = 0.24330082535743713
31-01-2023 04:43:02 INFO Epoch 3: [8009/10940] ---- BYOL Training Loss = 0.23382878303527832
31-01-2023 04:43:54 INFO Epoch 3: [8009/10940] ---- BYOL Validation Loss = 0.20719365775585175
31-01-2023 04:44:12 INFO Epoch 3: [8020/10940] ---- BYOL Training Loss = 0.2040283977985382
31-01-2023 04:44:30 INFO Epoch 3: [8031/10940] ---- BYOL Training Loss = 0.21914300322532654
31-01-2023 04:44:48 INFO Epoch 3: [8042/10940] ---- BYOL Training Loss = 0.23264281451702118
31-01-2023 04:45:06 INFO Epoch 3: [8053/10940] ---- BYOL Training Loss = 0.22964291274547577
31-01-2023 04:45:59 INFO Epoch 3: [8053/10940] ---- BYOL Validation Loss = 0.21414698660373688
31-01-2023 04:46:16 INFO Epoch 3: [8064/10940] ---- BYOL Training Loss = 0.258802592754364
31-01-2023 04:46:35 INFO Epoch 3: [8075/10940] ---- BYOL Training Loss = 0.2701614499092102
31-01-2023 04:46:53 INFO Epoch 3: [8086/10940] ---- BYOL Training Loss = 0.21995027363300323
31-01-2023 04:47:11 INFO Epoch 3: [8097/10940] ---- BYOL Training Loss = 0.2390722781419754
31-01-2023 04:48:04 INFO Epoch 3: [8097/10940] ---- BYOL Validation Loss = 0.19052433967590332
31-01-2023 04:48:22 INFO Epoch 3: [8108/10940] ---- BYOL Training Loss = 0.24012187123298645
31-01-2023 04:48:40 INFO Epoch 3: [8119/10940] ---- BYOL Training Loss = 0.24719080328941345
31-01-2023 04:48:58 INFO Epoch 3: [8130/10940] ---- BYOL Training Loss = 0.2761450409889221
31-01-2023 04:49:17 INFO Epoch 3: [8141/10940] ---- BYOL Training Loss = 0.2861543297767639
31-01-2023 04:50:09 INFO Epoch 3: [8141/10940] ---- BYOL Validation Loss = 0.226847305893898
31-01-2023 04:50:27 INFO Epoch 3: [8152/10940] ---- BYOL Training Loss = 0.24778449535369873
31-01-2023 04:50:45 INFO Epoch 3: [8163/10940] ---- BYOL Training Loss = 0.22451794147491455
31-01-2023 04:51:04 INFO Epoch 3: [8174/10940] ---- BYOL Training Loss = 0.2248200625181198
31-01-2023 04:51:22 INFO Epoch 3: [8185/10940] ---- BYOL Training Loss = 0.21262359619140625
31-01-2023 04:52:14 INFO Epoch 3: [8185/10940] ---- BYOL Validation Loss = 0.22536294162273407
31-01-2023 04:52:32 INFO Epoch 3: [8196/10940] ---- BYOL Training Loss = 0.2014705389738083
31-01-2023 04:52:51 INFO Epoch 3: [8207/10940] ---- BYOL Training Loss = 0.21174879372119904
31-01-2023 04:53:09 INFO Epoch 3: [8218/10940] ---- BYOL Training Loss = 0.2477189302444458
31-01-2023 04:53:27 INFO Epoch 3: [8229/10940] ---- BYOL Training Loss = 0.25861412286758423
31-01-2023 04:54:20 INFO Epoch 3: [8229/10940] ---- BYOL Validation Loss = 0.21600142121315002
31-01-2023 04:54:38 INFO Epoch 3: [8240/10940] ---- BYOL Training Loss = 0.23810581862926483
31-01-2023 04:54:56 INFO Epoch 3: [8251/10940] ---- BYOL Training Loss = 0.2115638256072998
31-01-2023 04:55:14 INFO Epoch 3: [8262/10940] ---- BYOL Training Loss = 0.24523809552192688
31-01-2023 04:55:33 INFO Epoch 3: [8273/10940] ---- BYOL Training Loss = 0.23142528533935547
31-01-2023 04:56:25 INFO Epoch 3: [8273/10940] ---- BYOL Validation Loss = 0.21899832785129547
31-01-2023 04:56:43 INFO Epoch 3: [8284/10940] ---- BYOL Training Loss = 0.22145883738994598
31-01-2023 04:57:01 INFO Epoch 3: [8295/10940] ---- BYOL Training Loss = 0.21500495076179504
31-01-2023 04:57:20 INFO Epoch 3: [8306/10940] ---- BYOL Training Loss = 0.19651679694652557
31-01-2023 04:57:38 INFO Epoch 3: [8317/10940] ---- BYOL Training Loss = 0.23607321083545685
31-01-2023 04:58:30 INFO Epoch 3: [8317/10940] ---- BYOL Validation Loss = 0.21462178230285645
31-01-2023 04:58:48 INFO Epoch 3: [8328/10940] ---- BYOL Training Loss = 0.24294647574424744
31-01-2023 04:59:07 INFO Epoch 3: [8339/10940] ---- BYOL Training Loss = 0.24047359824180603
31-01-2023 04:59:25 INFO Epoch 3: [8350/10940] ---- BYOL Training Loss = 0.24015657603740692
31-01-2023 04:59:43 INFO Epoch 3: [8361/10940] ---- BYOL Training Loss = 0.24908538162708282
31-01-2023 05:00:36 INFO Epoch 3: [8361/10940] ---- BYOL Validation Loss = 0.21903522312641144
31-01-2023 05:00:54 INFO Epoch 3: [8372/10940] ---- BYOL Training Loss = 0.254710853099823
31-01-2023 05:01:12 INFO Epoch 3: [8383/10940] ---- BYOL Training Loss = 0.25392091274261475
31-01-2023 05:01:30 INFO Epoch 3: [8394/10940] ---- BYOL Training Loss = 0.2375023066997528
31-01-2023 05:01:49 INFO Epoch 3: [8405/10940] ---- BYOL Training Loss = 0.2553030848503113
31-01-2023 05:02:41 INFO Epoch 3: [8405/10940] ---- BYOL Validation Loss = 0.21473455429077148
31-01-2023 05:02:59 INFO Epoch 3: [8416/10940] ---- BYOL Training Loss = 0.2269057333469391
31-01-2023 05:03:17 INFO Epoch 3: [8427/10940] ---- BYOL Training Loss = 0.21025781333446503
31-01-2023 05:03:36 INFO Epoch 3: [8438/10940] ---- BYOL Training Loss = 0.23703190684318542
31-01-2023 05:03:54 INFO Epoch 3: [8449/10940] ---- BYOL Training Loss = 0.22664602100849152
31-01-2023 05:04:47 INFO Epoch 3: [8449/10940] ---- BYOL Validation Loss = 0.21298091113567352
31-01-2023 05:05:04 INFO Epoch 3: [8460/10940] ---- BYOL Training Loss = 0.22477130591869354
31-01-2023 05:05:23 INFO Epoch 3: [8471/10940] ---- BYOL Training Loss = 0.21040597558021545
31-01-2023 05:05:41 INFO Epoch 3: [8482/10940] ---- BYOL Training Loss = 0.1944819688796997
31-01-2023 05:06:00 INFO Epoch 3: [8493/10940] ---- BYOL Training Loss = 0.22562070190906525
31-01-2023 05:06:52 INFO Epoch 3: [8493/10940] ---- BYOL Validation Loss = 0.20662185549736023
31-01-2023 05:07:10 INFO Epoch 3: [8504/10940] ---- BYOL Training Loss = 0.2269987165927887
31-01-2023 05:07:28 INFO Epoch 3: [8515/10940] ---- BYOL Training Loss = 0.16957134008407593
31-01-2023 05:07:47 INFO Epoch 3: [8526/10940] ---- BYOL Training Loss = 0.17889314889907837
31-01-2023 05:08:05 INFO Epoch 3: [8537/10940] ---- BYOL Training Loss = 0.204176664352417
31-01-2023 05:08:57 INFO Epoch 3: [8537/10940] ---- BYOL Validation Loss = 0.19584332406520844
31-01-2023 05:09:15 INFO Epoch 3: [8548/10940] ---- BYOL Training Loss = 0.22849717736244202
31-01-2023 05:09:34 INFO Epoch 3: [8559/10940] ---- BYOL Training Loss = 0.2643313407897949
31-01-2023 05:09:52 INFO Epoch 3: [8570/10940] ---- BYOL Training Loss = 0.2386760711669922
31-01-2023 05:10:10 INFO Epoch 3: [8581/10940] ---- BYOL Training Loss = 0.2200532853603363
31-01-2023 05:11:03 INFO Epoch 3: [8581/10940] ---- BYOL Validation Loss = 0.23183824121952057
31-01-2023 05:11:21 INFO Epoch 3: [8592/10940] ---- BYOL Training Loss = 0.23794297873973846
31-01-2023 05:11:39 INFO Epoch 3: [8603/10940] ---- BYOL Training Loss = 0.22200536727905273
31-01-2023 05:11:58 INFO Epoch 3: [8614/10940] ---- BYOL Training Loss = 0.21053674817085266
31-01-2023 05:12:16 INFO Epoch 3: [8625/10940] ---- BYOL Training Loss = 0.19010967016220093
31-01-2023 05:13:08 INFO Epoch 3: [8625/10940] ---- BYOL Validation Loss = 0.2088981568813324
31-01-2023 05:13:26 INFO Epoch 3: [8636/10940] ---- BYOL Training Loss = 0.1708677113056183
31-01-2023 05:13:44 INFO Epoch 3: [8647/10940] ---- BYOL Training Loss = 0.21541643142700195
31-01-2023 05:14:03 INFO Epoch 3: [8658/10940] ---- BYOL Training Loss = 0.25091537833213806
31-01-2023 05:14:21 INFO Epoch 3: [8669/10940] ---- BYOL Training Loss = 0.24702224135398865
31-01-2023 05:15:14 INFO Epoch 3: [8669/10940] ---- BYOL Validation Loss = 0.2120244950056076
31-01-2023 05:15:32 INFO Epoch 3: [8680/10940] ---- BYOL Training Loss = 0.24304798245429993
31-01-2023 05:15:50 INFO Epoch 3: [8691/10940] ---- BYOL Training Loss = 0.21243278682231903
31-01-2023 05:16:08 INFO Epoch 3: [8702/10940] ---- BYOL Training Loss = 0.18379443883895874
31-01-2023 05:16:27 INFO Epoch 3: [8713/10940] ---- BYOL Training Loss = 0.19937315583229065
31-01-2023 05:17:19 INFO Epoch 3: [8713/10940] ---- BYOL Validation Loss = 0.20046374201774597
31-01-2023 05:17:37 INFO Epoch 3: [8724/10940] ---- BYOL Training Loss = 0.1959533393383026
31-01-2023 05:17:55 INFO Epoch 3: [8735/10940] ---- BYOL Training Loss = 0.22751501202583313
31-01-2023 05:18:14 INFO Epoch 3: [8746/10940] ---- BYOL Training Loss = 0.235752135515213
31-01-2023 05:18:32 INFO Epoch 3: [8757/10940] ---- BYOL Training Loss = 0.20540550351142883
31-01-2023 05:19:24 INFO Epoch 3: [8757/10940] ---- BYOL Validation Loss = 0.2002532184123993
31-01-2023 05:19:43 INFO Epoch 3: [8768/10940] ---- BYOL Training Loss = 0.22615857422351837
31-01-2023 05:20:01 INFO Epoch 3: [8779/10940] ---- BYOL Training Loss = 0.2612811028957367
31-01-2023 05:20:19 INFO Epoch 3: [8790/10940] ---- BYOL Training Loss = 0.230034738779068
31-01-2023 05:20:38 INFO Epoch 3: [8801/10940] ---- BYOL Training Loss = 0.22766602039337158
31-01-2023 05:21:30 INFO Epoch 3: [8801/10940] ---- BYOL Validation Loss = 0.20678214728832245
31-01-2023 05:21:48 INFO Epoch 3: [8812/10940] ---- BYOL Training Loss = 0.21738044917583466
31-01-2023 05:22:06 INFO Epoch 3: [8823/10940] ---- BYOL Training Loss = 0.20155763626098633
31-01-2023 05:22:25 INFO Epoch 3: [8834/10940] ---- BYOL Training Loss = 0.2200555056333542
31-01-2023 05:22:43 INFO Epoch 3: [8845/10940] ---- BYOL Training Loss = 0.2830435335636139
31-01-2023 05:23:35 INFO Epoch 3: [8845/10940] ---- BYOL Validation Loss = 0.20251549780368805
31-01-2023 05:23:53 INFO Epoch 3: [8856/10940] ---- BYOL Training Loss = 0.2956847548484802
31-01-2023 05:24:12 INFO Epoch 3: [8867/10940] ---- BYOL Training Loss = 0.2787228524684906
31-01-2023 05:24:30 INFO Epoch 3: [8878/10940] ---- BYOL Training Loss = 0.26891979575157166
31-01-2023 05:24:49 INFO Epoch 3: [8889/10940] ---- BYOL Training Loss = 0.26338595151901245
31-01-2023 05:25:41 INFO Epoch 3: [8889/10940] ---- BYOL Validation Loss = 0.21006961166858673
31-01-2023 05:25:59 INFO Epoch 3: [8900/10940] ---- BYOL Training Loss = 0.2652823030948639
31-01-2023 05:26:17 INFO Epoch 3: [8911/10940] ---- BYOL Training Loss = 0.2292538583278656
31-01-2023 05:26:36 INFO Epoch 3: [8922/10940] ---- BYOL Training Loss = 0.23258188366889954
31-01-2023 05:26:54 INFO Epoch 3: [8933/10940] ---- BYOL Training Loss = 0.27688509225845337
31-01-2023 05:27:46 INFO Epoch 3: [8933/10940] ---- BYOL Validation Loss = 0.208595871925354
31-01-2023 05:28:04 INFO Epoch 3: [8944/10940] ---- BYOL Training Loss = 0.23209527134895325
31-01-2023 05:28:23 INFO Epoch 3: [8955/10940] ---- BYOL Training Loss = 0.21972207725048065
31-01-2023 05:28:41 INFO Epoch 3: [8966/10940] ---- BYOL Training Loss = 0.2568875253200531
31-01-2023 05:29:00 INFO Epoch 3: [8977/10940] ---- BYOL Training Loss = 0.24863603711128235
31-01-2023 05:29:52 INFO Epoch 3: [8977/10940] ---- BYOL Validation Loss = 0.2109784185886383
31-01-2023 05:30:10 INFO Epoch 3: [8988/10940] ---- BYOL Training Loss = 0.27798762917518616
31-01-2023 05:30:28 INFO Epoch 3: [8999/10940] ---- BYOL Training Loss = 0.2291831076145172
31-01-2023 05:30:47 INFO Epoch 3: [9010/10940] ---- BYOL Training Loss = 0.20833086967468262
31-01-2023 05:31:05 INFO Epoch 3: [9021/10940] ---- BYOL Training Loss = 0.2510567307472229
31-01-2023 05:31:57 INFO Epoch 3: [9021/10940] ---- BYOL Validation Loss = 0.19655439257621765
31-01-2023 05:32:15 INFO Epoch 3: [9032/10940] ---- BYOL Training Loss = 0.2379244863986969
31-01-2023 05:32:34 INFO Epoch 3: [9043/10940] ---- BYOL Training Loss = 0.20103850960731506
31-01-2023 05:32:52 INFO Epoch 3: [9054/10940] ---- BYOL Training Loss = 0.17021198570728302
31-01-2023 05:33:11 INFO Epoch 3: [9065/10940] ---- BYOL Training Loss = 0.21866652369499207
31-01-2023 05:34:03 INFO Epoch 3: [9065/10940] ---- BYOL Validation Loss = 0.2152457982301712
31-01-2023 05:34:21 INFO Epoch 3: [9076/10940] ---- BYOL Training Loss = 0.28089889883995056
31-01-2023 05:34:39 INFO Epoch 3: [9087/10940] ---- BYOL Training Loss = 0.26150792837142944
31-01-2023 05:34:58 INFO Epoch 3: [9098/10940] ---- BYOL Training Loss = 0.25601866841316223
31-01-2023 05:35:16 INFO Epoch 3: [9109/10940] ---- BYOL Training Loss = 0.19314387440681458
31-01-2023 05:36:09 INFO Epoch 3: [9109/10940] ---- BYOL Validation Loss = 0.17932605743408203
31-01-2023 05:36:27 INFO Epoch 3: [9120/10940] ---- BYOL Training Loss = 0.20590591430664062
31-01-2023 05:36:45 INFO Epoch 3: [9131/10940] ---- BYOL Training Loss = 0.24468965828418732
31-01-2023 05:37:03 INFO Epoch 3: [9142/10940] ---- BYOL Training Loss = 0.22553177177906036
31-01-2023 05:37:22 INFO Epoch 3: [9153/10940] ---- BYOL Training Loss = 0.21952542662620544
31-01-2023 05:38:14 INFO Epoch 3: [9153/10940] ---- BYOL Validation Loss = 0.19714923202991486
31-01-2023 05:38:32 INFO Epoch 3: [9164/10940] ---- BYOL Training Loss = 0.2042124718427658
31-01-2023 05:38:51 INFO Epoch 3: [9175/10940] ---- BYOL Training Loss = 0.20396657288074493
31-01-2023 05:39:09 INFO Epoch 3: [9186/10940] ---- BYOL Training Loss = 0.2437698096036911
31-01-2023 05:39:28 INFO Epoch 3: [9197/10940] ---- BYOL Training Loss = 0.24876518547534943
31-01-2023 05:40:20 INFO Epoch 3: [9197/10940] ---- BYOL Validation Loss = 0.20713220536708832
31-01-2023 05:40:38 INFO Epoch 3: [9208/10940] ---- BYOL Training Loss = 0.205278679728508
31-01-2023 05:40:56 INFO Epoch 3: [9219/10940] ---- BYOL Training Loss = 0.23406216502189636
31-01-2023 05:41:15 INFO Epoch 3: [9230/10940] ---- BYOL Training Loss = 0.20567891001701355
31-01-2023 05:41:33 INFO Epoch 3: [9241/10940] ---- BYOL Training Loss = 0.2361639440059662
31-01-2023 05:42:26 INFO Epoch 3: [9241/10940] ---- BYOL Validation Loss = 0.19301602244377136
31-01-2023 05:42:44 INFO Epoch 3: [9252/10940] ---- BYOL Training Loss = 0.23675532639026642
31-01-2023 05:43:02 INFO Epoch 3: [9263/10940] ---- BYOL Training Loss = 0.25430649518966675
31-01-2023 05:43:21 INFO Epoch 3: [9274/10940] ---- BYOL Training Loss = 0.24281728267669678
31-01-2023 05:43:39 INFO Epoch 3: [9285/10940] ---- BYOL Training Loss = 0.1856844276189804
31-01-2023 05:44:31 INFO Epoch 3: [9285/10940] ---- BYOL Validation Loss = 0.1813858449459076
31-01-2023 05:44:49 INFO Epoch 3: [9296/10940] ---- BYOL Training Loss = 0.17452938854694366
31-01-2023 05:45:08 INFO Epoch 3: [9307/10940] ---- BYOL Training Loss = 0.214992955327034
31-01-2023 05:45:26 INFO Epoch 3: [9318/10940] ---- BYOL Training Loss = 0.22361013293266296
31-01-2023 05:45:45 INFO Epoch 3: [9329/10940] ---- BYOL Training Loss = 0.20719310641288757
31-01-2023 05:46:38 INFO Epoch 3: [9329/10940] ---- BYOL Validation Loss = 0.20733727514743805
31-01-2023 05:46:56 INFO Epoch 3: [9340/10940] ---- BYOL Training Loss = 0.19543910026550293
31-01-2023 05:47:14 INFO Epoch 3: [9351/10940] ---- BYOL Training Loss = 0.2939181327819824
31-01-2023 05:47:33 INFO Epoch 3: [9362/10940] ---- BYOL Training Loss = 0.31438615918159485
31-01-2023 05:47:51 INFO Epoch 3: [9373/10940] ---- BYOL Training Loss = 0.22530725598335266
31-01-2023 05:48:44 INFO Epoch 3: [9373/10940] ---- BYOL Validation Loss = 0.2179570347070694
31-01-2023 05:49:02 INFO Epoch 3: [9384/10940] ---- BYOL Training Loss = 0.19383372366428375
31-01-2023 05:49:20 INFO Epoch 3: [9395/10940] ---- BYOL Training Loss = 0.2931397557258606
31-01-2023 05:49:39 INFO Epoch 3: [9406/10940] ---- BYOL Training Loss = 0.27815061807632446
31-01-2023 05:49:57 INFO Epoch 3: [9417/10940] ---- BYOL Training Loss = 0.20307376980781555
31-01-2023 05:50:49 INFO Epoch 3: [9417/10940] ---- BYOL Validation Loss = 0.20608046650886536
31-01-2023 05:51:07 INFO Epoch 3: [9428/10940] ---- BYOL Training Loss = 0.2210676670074463
31-01-2023 05:51:26 INFO Epoch 3: [9439/10940] ---- BYOL Training Loss = 0.2291814088821411
31-01-2023 05:51:44 INFO Epoch 3: [9450/10940] ---- BYOL Training Loss = 0.25484925508499146
31-01-2023 05:52:03 INFO Epoch 3: [9461/10940] ---- BYOL Training Loss = 0.29544496536254883
31-01-2023 05:52:55 INFO Epoch 3: [9461/10940] ---- BYOL Validation Loss = 0.19067491590976715
31-01-2023 05:53:13 INFO Epoch 3: [9472/10940] ---- BYOL Training Loss = 0.2700110077857971
31-01-2023 05:53:31 INFO Epoch 3: [9483/10940] ---- BYOL Training Loss = 0.2756693363189697
31-01-2023 05:53:50 INFO Epoch 3: [9494/10940] ---- BYOL Training Loss = 0.25887781381607056
31-01-2023 05:54:08 INFO Epoch 3: [9505/10940] ---- BYOL Training Loss = 0.22593018412590027
31-01-2023 05:55:00 INFO Epoch 3: [9505/10940] ---- BYOL Validation Loss = 0.21148620545864105
31-01-2023 05:55:19 INFO Epoch 3: [9516/10940] ---- BYOL Training Loss = 0.21159322559833527
31-01-2023 05:55:37 INFO Epoch 3: [9527/10940] ---- BYOL Training Loss = 0.1978474259376526
31-01-2023 05:55:55 INFO Epoch 3: [9538/10940] ---- BYOL Training Loss = 0.23047013580799103
31-01-2023 05:56:14 INFO Epoch 3: [9549/10940] ---- BYOL Training Loss = 0.2723636329174042
31-01-2023 05:57:06 INFO Epoch 3: [9549/10940] ---- BYOL Validation Loss = 0.22378556430339813
31-01-2023 05:57:24 INFO Epoch 3: [9560/10940] ---- BYOL Training Loss = 0.27237778902053833
31-01-2023 05:57:43 INFO Epoch 3: [9571/10940] ---- BYOL Training Loss = 0.2404250204563141
31-01-2023 05:58:01 INFO Epoch 3: [9582/10940] ---- BYOL Training Loss = 0.24018339812755585
31-01-2023 05:58:19 INFO Epoch 3: [9593/10940] ---- BYOL Training Loss = 0.22184833884239197
31-01-2023 05:59:12 INFO Epoch 3: [9593/10940] ---- BYOL Validation Loss = 0.21202169358730316
31-01-2023 05:59:30 INFO Epoch 3: [9604/10940] ---- BYOL Training Loss = 0.2092834711074829
31-01-2023 05:59:48 INFO Epoch 3: [9615/10940] ---- BYOL Training Loss = 0.21432825922966003
31-01-2023 06:00:07 INFO Epoch 3: [9626/10940] ---- BYOL Training Loss = 0.22280855476856232
31-01-2023 06:00:25 INFO Epoch 3: [9637/10940] ---- BYOL Training Loss = 0.18506357073783875
31-01-2023 06:01:18 INFO Epoch 3: [9637/10940] ---- BYOL Validation Loss = 0.20157422125339508
31-01-2023 06:01:36 INFO Epoch 3: [9648/10940] ---- BYOL Training Loss = 0.177591934800148
31-01-2023 06:01:55 INFO Epoch 3: [9659/10940] ---- BYOL Training Loss = 0.19693204760551453
31-01-2023 06:02:13 INFO Epoch 3: [9670/10940] ---- BYOL Training Loss = 0.2342861145734787
31-01-2023 06:02:32 INFO Epoch 3: [9681/10940] ---- BYOL Training Loss = 0.2858445346355438
31-01-2023 06:03:24 INFO Epoch 3: [9681/10940] ---- BYOL Validation Loss = 0.19397296011447906
31-01-2023 06:03:42 INFO Epoch 3: [9692/10940] ---- BYOL Training Loss = 0.2181800901889801
31-01-2023 06:04:00 INFO Epoch 3: [9703/10940] ---- BYOL Training Loss = 0.22490569949150085
31-01-2023 06:04:19 INFO Epoch 3: [9714/10940] ---- BYOL Training Loss = 0.24524350464344025
31-01-2023 06:04:37 INFO Epoch 3: [9725/10940] ---- BYOL Training Loss = 0.2920113205909729
31-01-2023 06:05:29 INFO Epoch 3: [9725/10940] ---- BYOL Validation Loss = 0.20750628411769867
31-01-2023 06:05:48 INFO Epoch 3: [9736/10940] ---- BYOL Training Loss = 0.2887106239795685
31-01-2023 06:06:06 INFO Epoch 3: [9747/10940] ---- BYOL Training Loss = 0.23880648612976074
31-01-2023 06:06:25 INFO Epoch 3: [9758/10940] ---- BYOL Training Loss = 0.27497830986976624
31-01-2023 06:06:43 INFO Epoch 3: [9769/10940] ---- BYOL Training Loss = 0.30286115407943726
31-01-2023 06:07:36 INFO Epoch 3: [9769/10940] ---- BYOL Validation Loss = 0.21429364383220673
31-01-2023 06:07:54 INFO Epoch 3: [9780/10940] ---- BYOL Training Loss = 0.27222535014152527
31-01-2023 06:08:12 INFO Epoch 3: [9791/10940] ---- BYOL Training Loss = 0.27966323494911194
31-01-2023 06:08:31 INFO Epoch 3: [9802/10940] ---- BYOL Training Loss = 0.24477621912956238
31-01-2023 06:08:49 INFO Epoch 3: [9813/10940] ---- BYOL Training Loss = 0.22512848675251007
31-01-2023 06:09:42 INFO Epoch 3: [9813/10940] ---- BYOL Validation Loss = 0.1865803748369217
31-01-2023 06:10:00 INFO Epoch 3: [9824/10940] ---- BYOL Training Loss = 0.23738357424736023
31-01-2023 06:10:18 INFO Epoch 3: [9835/10940] ---- BYOL Training Loss = 0.2806014120578766
31-01-2023 06:10:37 INFO Epoch 3: [9846/10940] ---- BYOL Training Loss = 0.2584272027015686
31-01-2023 06:10:55 INFO Epoch 3: [9857/10940] ---- BYOL Training Loss = 0.22814805805683136
31-01-2023 06:11:47 INFO Epoch 3: [9857/10940] ---- BYOL Validation Loss = 0.19972217082977295
31-01-2023 06:12:06 INFO Epoch 3: [9868/10940] ---- BYOL Training Loss = 0.25620564818382263
31-01-2023 06:12:24 INFO Epoch 3: [9879/10940] ---- BYOL Training Loss = 0.25634244084358215
31-01-2023 06:12:43 INFO Epoch 3: [9890/10940] ---- BYOL Training Loss = 0.2094656229019165
31-01-2023 06:13:01 INFO Epoch 3: [9901/10940] ---- BYOL Training Loss = 0.23442935943603516
31-01-2023 06:13:54 INFO Epoch 3: [9901/10940] ---- BYOL Validation Loss = 0.18748776614665985
31-01-2023 06:14:12 INFO Epoch 3: [9912/10940] ---- BYOL Training Loss = 0.22663474082946777
31-01-2023 06:14:31 INFO Epoch 3: [9923/10940] ---- BYOL Training Loss = 0.1926080882549286
31-01-2023 06:14:49 INFO Epoch 3: [9934/10940] ---- BYOL Training Loss = 0.18581610918045044
31-01-2023 06:15:08 INFO Epoch 3: [9945/10940] ---- BYOL Training Loss = 0.18640756607055664
31-01-2023 06:16:00 INFO Epoch 3: [9945/10940] ---- BYOL Validation Loss = 0.1991211622953415
31-01-2023 06:16:18 INFO Epoch 3: [9956/10940] ---- BYOL Training Loss = 0.20015950500965118
31-01-2023 06:16:36 INFO Epoch 3: [9967/10940] ---- BYOL Training Loss = 0.18993735313415527
31-01-2023 06:16:55 INFO Epoch 3: [9978/10940] ---- BYOL Training Loss = 0.2604108452796936
31-01-2023 06:17:14 INFO Epoch 3: [9989/10940] ---- BYOL Training Loss = 0.27916163206100464
31-01-2023 06:18:06 INFO Epoch 3: [9989/10940] ---- BYOL Validation Loss = 0.20560012757778168
31-01-2023 06:18:24 INFO Epoch 3: [10000/10940] ---- BYOL Training Loss = 0.27258846163749695
31-01-2023 06:18:43 INFO Epoch 3: [10011/10940] ---- BYOL Training Loss = 0.27498143911361694
31-01-2023 06:19:01 INFO Epoch 3: [10022/10940] ---- BYOL Training Loss = 0.329826295375824
31-01-2023 06:19:20 INFO Epoch 3: [10033/10940] ---- BYOL Training Loss = 0.3411400318145752
31-01-2023 06:20:12 INFO Epoch 3: [10033/10940] ---- BYOL Validation Loss = 0.18560846149921417
31-01-2023 06:20:30 INFO Epoch 3: [10044/10940] ---- BYOL Training Loss = 0.23767605423927307
31-01-2023 06:20:49 INFO Epoch 3: [10055/10940] ---- BYOL Training Loss = 0.28240323066711426
31-01-2023 06:21:07 INFO Epoch 3: [10066/10940] ---- BYOL Training Loss = 0.2822033166885376
31-01-2023 06:21:26 INFO Epoch 3: [10077/10940] ---- BYOL Training Loss = 0.24646136164665222
31-01-2023 06:22:18 INFO Epoch 3: [10077/10940] ---- BYOL Validation Loss = 0.19110608100891113
31-01-2023 06:22:37 INFO Epoch 3: [10088/10940] ---- BYOL Training Loss = 0.23517295718193054
31-01-2023 06:22:55 INFO Epoch 3: [10099/10940] ---- BYOL Training Loss = 0.1963159739971161
31-01-2023 06:23:14 INFO Epoch 3: [10110/10940] ---- BYOL Training Loss = 0.19982989132404327
31-01-2023 06:23:32 INFO Epoch 3: [10121/10940] ---- BYOL Training Loss = 0.3121189475059509
31-01-2023 06:24:25 INFO Epoch 3: [10121/10940] ---- BYOL Validation Loss = 0.18650077283382416
31-01-2023 06:24:43 INFO Epoch 3: [10132/10940] ---- BYOL Training Loss = 0.3166908621788025
31-01-2023 06:25:02 INFO Epoch 3: [10143/10940] ---- BYOL Training Loss = 0.21214142441749573
31-01-2023 06:25:20 INFO Epoch 3: [10154/10940] ---- BYOL Training Loss = 0.2437783181667328
31-01-2023 06:25:39 INFO Epoch 3: [10165/10940] ---- BYOL Training Loss = 0.23600348830223083
31-01-2023 06:26:31 INFO Epoch 3: [10165/10940] ---- BYOL Validation Loss = 0.19088207185268402
31-01-2023 06:26:49 INFO Epoch 3: [10176/10940] ---- BYOL Training Loss = 0.25116658210754395
31-01-2023 06:27:08 INFO Epoch 3: [10187/10940] ---- BYOL Training Loss = 0.2430424988269806
31-01-2023 06:27:26 INFO Epoch 3: [10198/10940] ---- BYOL Training Loss = 0.26118046045303345
31-01-2023 06:27:44 INFO Epoch 3: [10209/10940] ---- BYOL Training Loss = 0.24985387921333313
31-01-2023 06:28:37 INFO Epoch 3: [10209/10940] ---- BYOL Validation Loss = 0.189254492521286
31-01-2023 06:28:55 INFO Epoch 3: [10220/10940] ---- BYOL Training Loss = 0.22294683754444122
31-01-2023 06:29:14 INFO Epoch 3: [10231/10940] ---- BYOL Training Loss = 0.22557631134986877
31-01-2023 06:29:32 INFO Epoch 3: [10242/10940] ---- BYOL Training Loss = 0.20122070610523224
31-01-2023 06:29:51 INFO Epoch 3: [10253/10940] ---- BYOL Training Loss = 0.22030885517597198
31-01-2023 06:30:43 INFO Epoch 3: [10253/10940] ---- BYOL Validation Loss = 0.188150092959404
31-01-2023 06:31:01 INFO Epoch 3: [10264/10940] ---- BYOL Training Loss = 0.21533820033073425
31-01-2023 06:31:20 INFO Epoch 3: [10275/10940] ---- BYOL Training Loss = 0.17540773749351501
31-01-2023 06:31:38 INFO Epoch 3: [10286/10940] ---- BYOL Training Loss = 0.1990574151277542
31-01-2023 06:31:57 INFO Epoch 3: [10297/10940] ---- BYOL Training Loss = 0.21407172083854675
31-01-2023 06:32:49 INFO Epoch 3: [10297/10940] ---- BYOL Validation Loss = 0.18102853000164032
31-01-2023 06:33:08 INFO Epoch 3: [10308/10940] ---- BYOL Training Loss = 0.2763892412185669
31-01-2023 06:33:26 INFO Epoch 3: [10319/10940] ---- BYOL Training Loss = 0.2341606318950653
31-01-2023 06:33:45 INFO Epoch 3: [10330/10940] ---- BYOL Training Loss = 0.16697485744953156
31-01-2023 06:34:03 INFO Epoch 3: [10341/10940] ---- BYOL Training Loss = 0.2263472080230713
31-01-2023 06:34:55 INFO Epoch 3: [10341/10940] ---- BYOL Validation Loss = 0.16542601585388184
31-01-2023 06:35:14 INFO Epoch 3: [10352/10940] ---- BYOL Training Loss = 0.2954328656196594
31-01-2023 06:35:32 INFO Epoch 3: [10363/10940] ---- BYOL Training Loss = 0.25866127014160156
31-01-2023 06:35:51 INFO Epoch 3: [10374/10940] ---- BYOL Training Loss = 0.24312777817249298
31-01-2023 06:36:09 INFO Epoch 3: [10385/10940] ---- BYOL Training Loss = 0.23617446422576904
31-01-2023 06:37:02 INFO Epoch 3: [10385/10940] ---- BYOL Validation Loss = 0.20699571073055267
31-01-2023 06:37:20 INFO Epoch 3: [10396/10940] ---- BYOL Training Loss = 0.20887088775634766
31-01-2023 06:37:39 INFO Epoch 3: [10407/10940] ---- BYOL Training Loss = 0.22391588985919952
31-01-2023 06:37:57 INFO Epoch 3: [10418/10940] ---- BYOL Training Loss = 0.25759103894233704
31-01-2023 06:38:16 INFO Epoch 3: [10429/10940] ---- BYOL Training Loss = 0.26575666666030884
31-01-2023 06:39:08 INFO Epoch 3: [10429/10940] ---- BYOL Validation Loss = 0.1892446130514145
31-01-2023 06:39:26 INFO Epoch 3: [10440/10940] ---- BYOL Training Loss = 0.25379544496536255
31-01-2023 06:39:45 INFO Epoch 3: [10451/10940] ---- BYOL Training Loss = 0.2716370224952698
31-01-2023 06:40:04 INFO Epoch 3: [10462/10940] ---- BYOL Training Loss = 0.25968730449676514
31-01-2023 06:40:22 INFO Epoch 3: [10473/10940] ---- BYOL Training Loss = 0.294114887714386
31-01-2023 06:41:14 INFO Epoch 3: [10473/10940] ---- BYOL Validation Loss = 0.21345141530036926
31-01-2023 06:41:33 INFO Epoch 3: [10484/10940] ---- BYOL Training Loss = 0.3003193736076355
31-01-2023 06:41:51 INFO Epoch 3: [10495/10940] ---- BYOL Training Loss = 0.2780122458934784
31-01-2023 06:42:10 INFO Epoch 3: [10506/10940] ---- BYOL Training Loss = 0.25344187021255493
31-01-2023 06:42:29 INFO Epoch 3: [10517/10940] ---- BYOL Training Loss = 0.2701314091682434
31-01-2023 06:43:21 INFO Epoch 3: [10517/10940] ---- BYOL Validation Loss = 0.2091275304555893
31-01-2023 06:43:39 INFO Epoch 3: [10528/10940] ---- BYOL Training Loss = 0.2468762844800949
31-01-2023 06:43:58 INFO Epoch 3: [10539/10940] ---- BYOL Training Loss = 0.2501956820487976
31-01-2023 06:44:17 INFO Epoch 3: [10550/10940] ---- BYOL Training Loss = 0.23409488797187805
31-01-2023 06:44:35 INFO Epoch 3: [10561/10940] ---- BYOL Training Loss = 0.22221553325653076
31-01-2023 06:45:27 INFO Epoch 3: [10561/10940] ---- BYOL Validation Loss = 0.2079506665468216
31-01-2023 06:45:45 INFO Epoch 3: [10572/10940] ---- BYOL Training Loss = 0.26131385564804077
31-01-2023 06:46:04 INFO Epoch 3: [10583/10940] ---- BYOL Training Loss = 0.2594827711582184
31-01-2023 06:46:23 INFO Epoch 3: [10594/10940] ---- BYOL Training Loss = 0.2426253855228424
31-01-2023 06:46:41 INFO Epoch 3: [10605/10940] ---- BYOL Training Loss = 0.2239723950624466
31-01-2023 06:47:34 INFO Epoch 3: [10605/10940] ---- BYOL Validation Loss = 0.22147846221923828
31-01-2023 06:47:52 INFO Epoch 3: [10616/10940] ---- BYOL Training Loss = 0.256723016500473
31-01-2023 06:48:11 INFO Epoch 3: [10627/10940] ---- BYOL Training Loss = 0.2316395789384842
31-01-2023 06:48:29 INFO Epoch 3: [10638/10940] ---- BYOL Training Loss = 0.21442146599292755
31-01-2023 06:48:48 INFO Epoch 3: [10649/10940] ---- BYOL Training Loss = 0.24605989456176758
31-01-2023 06:49:40 INFO Epoch 3: [10649/10940] ---- BYOL Validation Loss = 0.1977197378873825
31-01-2023 06:49:58 INFO Epoch 3: [10660/10940] ---- BYOL Training Loss = 0.21173253655433655
31-01-2023 06:50:17 INFO Epoch 3: [10671/10940] ---- BYOL Training Loss = 0.19756004214286804
31-01-2023 06:50:35 INFO Epoch 3: [10682/10940] ---- BYOL Training Loss = 0.24154917895793915
31-01-2023 06:50:54 INFO Epoch 3: [10693/10940] ---- BYOL Training Loss = 0.2011561393737793
31-01-2023 06:51:47 INFO Epoch 3: [10693/10940] ---- BYOL Validation Loss = 0.16252733767032623
31-01-2023 06:52:05 INFO Epoch 3: [10704/10940] ---- BYOL Training Loss = 0.241124227643013
31-01-2023 06:52:23 INFO Epoch 3: [10715/10940] ---- BYOL Training Loss = 0.26103347539901733
31-01-2023 06:52:42 INFO Epoch 3: [10726/10940] ---- BYOL Training Loss = 0.2713465094566345
31-01-2023 06:53:00 INFO Epoch 3: [10737/10940] ---- BYOL Training Loss = 0.23609332740306854
31-01-2023 06:53:52 INFO Epoch 3: [10737/10940] ---- BYOL Validation Loss = 0.21362969279289246
31-01-2023 06:54:11 INFO Epoch 3: [10748/10940] ---- BYOL Training Loss = 0.22378309071063995
31-01-2023 06:54:29 INFO Epoch 3: [10759/10940] ---- BYOL Training Loss = 0.2469833791255951
31-01-2023 06:54:48 INFO Epoch 3: [10770/10940] ---- BYOL Training Loss = 0.24144336581230164
31-01-2023 06:55:07 INFO Epoch 3: [10781/10940] ---- BYOL Training Loss = 0.19101664423942566
31-01-2023 06:55:59 INFO Epoch 3: [10781/10940] ---- BYOL Validation Loss = 0.20155806839466095
31-01-2023 06:56:18 INFO Epoch 3: [10792/10940] ---- BYOL Training Loss = 0.16602905094623566
31-01-2023 06:56:36 INFO Epoch 3: [10803/10940] ---- BYOL Training Loss = 0.1779101938009262
31-01-2023 06:56:54 INFO Epoch 3: [10814/10940] ---- BYOL Training Loss = 0.20545408129692078
31-01-2023 06:57:13 INFO Epoch 3: [10825/10940] ---- BYOL Training Loss = 0.18763987720012665
31-01-2023 06:58:06 INFO Epoch 3: [10825/10940] ---- BYOL Validation Loss = 0.192278653383255
31-01-2023 06:58:24 INFO Epoch 3: [10836/10940] ---- BYOL Training Loss = 0.19106625020503998
31-01-2023 06:58:43 INFO Epoch 3: [10847/10940] ---- BYOL Training Loss = 0.20597770810127258
31-01-2023 06:59:01 INFO Epoch 3: [10858/10940] ---- BYOL Training Loss = 0.24066877365112305
31-01-2023 06:59:20 INFO Epoch 3: [10869/10940] ---- BYOL Training Loss = 0.20315930247306824
31-01-2023 07:00:12 INFO Epoch 3: [10869/10940] ---- BYOL Validation Loss = 0.17547835409641266
31-01-2023 07:00:30 INFO Epoch 3: [10880/10940] ---- BYOL Training Loss = 0.24892103672027588
31-01-2023 07:00:49 INFO Epoch 3: [10891/10940] ---- BYOL Training Loss = 0.25134310126304626
31-01-2023 07:01:08 INFO Epoch 3: [10902/10940] ---- BYOL Training Loss = 0.20538417994976044
31-01-2023 07:01:27 INFO Epoch 3: [10913/10940] ---- BYOL Training Loss = 0.19241425395011902
31-01-2023 07:02:19 INFO Epoch 3: [10913/10940] ---- BYOL Validation Loss = 0.18714025616645813
31-01-2023 07:02:37 INFO Epoch 3: [10924/10940] ---- BYOL Training Loss = 0.18163320422172546
31-01-2023 07:02:55 INFO Epoch 3: [10935/10940] ---- BYOL Training Loss = 0.2056211531162262
31-01-2023 07:03:05 INFO Starting Epoch: 4
31-01-2023 07:03:23 INFO Epoch 4: [12/10940] ---- BYOL Training Loss = 0.15754063427448273
31-01-2023 07:03:41 INFO Epoch 4: [23/10940] ---- BYOL Training Loss = 0.17017695307731628
31-01-2023 07:03:58 INFO Epoch 4: [34/10940] ---- BYOL Training Loss = 0.2035229504108429
31-01-2023 07:04:16 INFO Epoch 4: [45/10940] ---- BYOL Training Loss = 0.22236475348472595
31-01-2023 07:05:08 INFO Epoch 4: [45/10940] ---- BYOL Validation Loss = 0.18535682559013367
31-01-2023 07:05:25 INFO Epoch 4: [56/10940] ---- BYOL Training Loss = 0.21453598141670227
31-01-2023 07:05:43 INFO Epoch 4: [67/10940] ---- BYOL Training Loss = 0.1880466192960739
31-01-2023 07:06:00 INFO Epoch 4: [78/10940] ---- BYOL Training Loss = 0.17630603909492493
31-01-2023 07:06:18 INFO Epoch 4: [89/10940] ---- BYOL Training Loss = 0.20317812263965607
31-01-2023 07:07:10 INFO Epoch 4: [89/10940] ---- BYOL Validation Loss = 0.19054007530212402
31-01-2023 07:07:27 INFO Epoch 4: [100/10940] ---- BYOL Training Loss = 0.23181656002998352
31-01-2023 07:07:45 INFO Epoch 4: [111/10940] ---- BYOL Training Loss = 0.2233283519744873
31-01-2023 07:08:02 INFO Epoch 4: [122/10940] ---- BYOL Training Loss = 0.23298807442188263
31-01-2023 07:08:20 INFO Epoch 4: [133/10940] ---- BYOL Training Loss = 0.2264232635498047
31-01-2023 07:09:12 INFO Epoch 4: [133/10940] ---- BYOL Validation Loss = 0.20742705464363098
31-01-2023 07:09:29 INFO Epoch 4: [144/10940] ---- BYOL Training Loss = 0.2554434537887573
31-01-2023 07:09:47 INFO Epoch 4: [155/10940] ---- BYOL Training Loss = 0.2231672704219818
31-01-2023 07:10:04 INFO Epoch 4: [166/10940] ---- BYOL Training Loss = 0.19290408492088318
31-01-2023 07:10:22 INFO Epoch 4: [177/10940] ---- BYOL Training Loss = 0.19004544615745544
31-01-2023 07:11:14 INFO Epoch 4: [177/10940] ---- BYOL Validation Loss = 0.20600976049900055
31-01-2023 07:11:31 INFO Epoch 4: [188/10940] ---- BYOL Training Loss = 0.20509788393974304
31-01-2023 07:11:49 INFO Epoch 4: [199/10940] ---- BYOL Training Loss = 0.20218054950237274
31-01-2023 07:12:06 INFO Epoch 4: [210/10940] ---- BYOL Training Loss = 0.1973988115787506
31-01-2023 07:12:24 INFO Epoch 4: [221/10940] ---- BYOL Training Loss = 0.20118865370750427
31-01-2023 07:13:16 INFO Epoch 4: [221/10940] ---- BYOL Validation Loss = 0.21526090800762177
31-01-2023 07:13:33 INFO Epoch 4: [232/10940] ---- BYOL Training Loss = 0.24126458168029785
31-01-2023 07:13:51 INFO Epoch 4: [243/10940] ---- BYOL Training Loss = 0.22683672606945038
31-01-2023 07:14:08 INFO Epoch 4: [254/10940] ---- BYOL Training Loss = 0.19204217195510864
31-01-2023 07:14:26 INFO Epoch 4: [265/10940] ---- BYOL Training Loss = 0.2066284418106079
31-01-2023 07:15:18 INFO Epoch 4: [265/10940] ---- BYOL Validation Loss = 0.2132216840982437
31-01-2023 07:15:35 INFO Epoch 4: [276/10940] ---- BYOL Training Loss = 0.20762288570404053
31-01-2023 07:15:53 INFO Epoch 4: [287/10940] ---- BYOL Training Loss = 0.20469315350055695
31-01-2023 07:16:10 INFO Epoch 4: [298/10940] ---- BYOL Training Loss = 0.20046262443065643
31-01-2023 07:16:28 INFO Epoch 4: [309/10940] ---- BYOL Training Loss = 0.21650175750255585
31-01-2023 07:17:20 INFO Epoch 4: [309/10940] ---- BYOL Validation Loss = 0.20487141609191895
31-01-2023 07:17:38 INFO Epoch 4: [320/10940] ---- BYOL Training Loss = 0.24133124947547913
31-01-2023 07:17:55 INFO Epoch 4: [331/10940] ---- BYOL Training Loss = 0.25757065415382385
31-01-2023 07:18:12 INFO Epoch 4: [342/10940] ---- BYOL Training Loss = 0.24398453533649445
31-01-2023 07:18:30 INFO Epoch 4: [353/10940] ---- BYOL Training Loss = 0.22714228928089142
31-01-2023 07:19:22 INFO Epoch 4: [353/10940] ---- BYOL Validation Loss = 0.21527217328548431
31-01-2023 07:19:40 INFO Epoch 4: [364/10940] ---- BYOL Training Loss = 0.22079244256019592
31-01-2023 07:19:57 INFO Epoch 4: [375/10940] ---- BYOL Training Loss = 0.20992927253246307
31-01-2023 07:20:15 INFO Epoch 4: [386/10940] ---- BYOL Training Loss = 0.2116352617740631
31-01-2023 07:20:32 INFO Epoch 4: [397/10940] ---- BYOL Training Loss = 0.2346201390028
31-01-2023 07:21:25 INFO Epoch 4: [397/10940] ---- BYOL Validation Loss = 0.20421640574932098
31-01-2023 07:21:42 INFO Epoch 4: [408/10940] ---- BYOL Training Loss = 0.22360458970069885
31-01-2023 07:21:59 INFO Epoch 4: [419/10940] ---- BYOL Training Loss = 0.27184391021728516
31-01-2023 07:22:17 INFO Epoch 4: [430/10940] ---- BYOL Training Loss = 0.2667064070701599
31-01-2023 07:22:34 INFO Epoch 4: [441/10940] ---- BYOL Training Loss = 0.22641725838184357
31-01-2023 07:23:27 INFO Epoch 4: [441/10940] ---- BYOL Validation Loss = 0.20106713473796844
31-01-2023 07:23:44 INFO Epoch 4: [452/10940] ---- BYOL Training Loss = 0.2112365961074829
31-01-2023 07:24:01 INFO Epoch 4: [463/10940] ---- BYOL Training Loss = 0.20958057045936584
31-01-2023 07:24:19 INFO Epoch 4: [474/10940] ---- BYOL Training Loss = 0.19063851237297058
31-01-2023 07:24:37 INFO Epoch 4: [485/10940] ---- BYOL Training Loss = 0.21851766109466553
31-01-2023 07:25:29 INFO Epoch 4: [485/10940] ---- BYOL Validation Loss = 0.21822474896907806
31-01-2023 07:25:46 INFO Epoch 4: [496/10940] ---- BYOL Training Loss = 0.22462506592273712
31-01-2023 07:26:04 INFO Epoch 4: [507/10940] ---- BYOL Training Loss = 0.21555152535438538
31-01-2023 07:26:21 INFO Epoch 4: [518/10940] ---- BYOL Training Loss = 0.21935462951660156
31-01-2023 07:26:39 INFO Epoch 4: [529/10940] ---- BYOL Training Loss = 0.20058181881904602
31-01-2023 07:27:31 INFO Epoch 4: [529/10940] ---- BYOL Validation Loss = 0.20362749695777893
31-01-2023 07:27:48 INFO Epoch 4: [540/10940] ---- BYOL Training Loss = 0.24070751667022705
31-01-2023 07:28:06 INFO Epoch 4: [551/10940] ---- BYOL Training Loss = 0.24139785766601562
31-01-2023 07:28:23 INFO Epoch 4: [562/10940] ---- BYOL Training Loss = 0.1928229182958603
31-01-2023 07:28:41 INFO Epoch 4: [573/10940] ---- BYOL Training Loss = 0.1951351910829544
31-01-2023 07:29:33 INFO Epoch 4: [573/10940] ---- BYOL Validation Loss = 0.2063230723142624
31-01-2023 07:29:51 INFO Epoch 4: [584/10940] ---- BYOL Training Loss = 0.23151350021362305
31-01-2023 07:30:09 INFO Epoch 4: [595/10940] ---- BYOL Training Loss = 0.24711143970489502
31-01-2023 07:30:26 INFO Epoch 4: [606/10940] ---- BYOL Training Loss = 0.23925574123859406
31-01-2023 07:30:44 INFO Epoch 4: [617/10940] ---- BYOL Training Loss = 0.23462872207164764
31-01-2023 07:31:36 INFO Epoch 4: [617/10940] ---- BYOL Validation Loss = 0.20112650096416473
31-01-2023 07:31:53 INFO Epoch 4: [628/10940] ---- BYOL Training Loss = 0.20470306277275085
31-01-2023 07:32:11 INFO Epoch 4: [639/10940] ---- BYOL Training Loss = 0.19611647725105286
31-01-2023 07:32:28 INFO Epoch 4: [650/10940] ---- BYOL Training Loss = 0.1808302104473114
31-01-2023 07:32:46 INFO Epoch 4: [661/10940] ---- BYOL Training Loss = 0.19520461559295654
31-01-2023 07:33:38 INFO Epoch 4: [661/10940] ---- BYOL Validation Loss = 0.18382756412029266
31-01-2023 07:33:56 INFO Epoch 4: [672/10940] ---- BYOL Training Loss = 0.2325739562511444
31-01-2023 07:34:13 INFO Epoch 4: [683/10940] ---- BYOL Training Loss = 0.2394876480102539
31-01-2023 07:34:31 INFO Epoch 4: [694/10940] ---- BYOL Training Loss = 0.2112504541873932
31-01-2023 07:34:48 INFO Epoch 4: [705/10940] ---- BYOL Training Loss = 0.2159595787525177
31-01-2023 07:35:41 INFO Epoch 4: [705/10940] ---- BYOL Validation Loss = 0.20351256430149078
31-01-2023 07:35:58 INFO Epoch 4: [716/10940] ---- BYOL Training Loss = 0.2208227813243866
31-01-2023 07:36:16 INFO Epoch 4: [727/10940] ---- BYOL Training Loss = 0.22223921120166779
31-01-2023 07:36:33 INFO Epoch 4: [738/10940] ---- BYOL Training Loss = 0.21773722767829895
31-01-2023 07:36:51 INFO Epoch 4: [749/10940] ---- BYOL Training Loss = 0.19747743010520935
31-01-2023 07:37:43 INFO Epoch 4: [749/10940] ---- BYOL Validation Loss = 0.19026465713977814
31-01-2023 07:38:00 INFO Epoch 4: [760/10940] ---- BYOL Training Loss = 0.1972205489873886
31-01-2023 07:38:18 INFO Epoch 4: [771/10940] ---- BYOL Training Loss = 0.23830096423625946
31-01-2023 07:38:35 INFO Epoch 4: [782/10940] ---- BYOL Training Loss = 0.2389465868473053
31-01-2023 07:38:53 INFO Epoch 4: [793/10940] ---- BYOL Training Loss = 0.22949250042438507
31-01-2023 07:39:45 INFO Epoch 4: [793/10940] ---- BYOL Validation Loss = 0.18614241480827332
31-01-2023 07:40:02 INFO Epoch 4: [804/10940] ---- BYOL Training Loss = 0.1820906698703766
31-01-2023 07:40:20 INFO Epoch 4: [815/10940] ---- BYOL Training Loss = 0.20533016324043274
31-01-2023 07:40:37 INFO Epoch 4: [826/10940] ---- BYOL Training Loss = 0.2202422320842743
31-01-2023 07:40:55 INFO Epoch 4: [837/10940] ---- BYOL Training Loss = 0.2350766658782959
31-01-2023 07:41:47 INFO Epoch 4: [837/10940] ---- BYOL Validation Loss = 0.19660882651805878
31-01-2023 07:42:04 INFO Epoch 4: [848/10940] ---- BYOL Training Loss = 0.21904948353767395
31-01-2023 07:42:22 INFO Epoch 4: [859/10940] ---- BYOL Training Loss = 0.2034256011247635
31-01-2023 07:42:40 INFO Epoch 4: [870/10940] ---- BYOL Training Loss = 0.2797570824623108
31-01-2023 07:42:57 INFO Epoch 4: [881/10940] ---- BYOL Training Loss = 0.2212226688861847
31-01-2023 07:43:49 INFO Epoch 4: [881/10940] ---- BYOL Validation Loss = 0.2033166140317917
31-01-2023 07:44:07 INFO Epoch 4: [892/10940] ---- BYOL Training Loss = 0.239201620221138
31-01-2023 07:44:24 INFO Epoch 4: [903/10940] ---- BYOL Training Loss = 0.2181052416563034
31-01-2023 07:44:42 INFO Epoch 4: [914/10940] ---- BYOL Training Loss = 0.1825506091117859
31-01-2023 07:44:59 INFO Epoch 4: [925/10940] ---- BYOL Training Loss = 0.16446851193904877
31-01-2023 07:45:51 INFO Epoch 4: [925/10940] ---- BYOL Validation Loss = 0.19675365090370178
31-01-2023 07:46:09 INFO Epoch 4: [936/10940] ---- BYOL Training Loss = 0.21470806002616882
31-01-2023 07:46:26 INFO Epoch 4: [947/10940] ---- BYOL Training Loss = 0.23125186562538147
31-01-2023 07:46:44 INFO Epoch 4: [958/10940] ---- BYOL Training Loss = 0.20538368821144104
31-01-2023 07:47:02 INFO Epoch 4: [969/10940] ---- BYOL Training Loss = 0.22372844815254211
31-01-2023 07:47:54 INFO Epoch 4: [969/10940] ---- BYOL Validation Loss = 0.1881314367055893
31-01-2023 07:48:11 INFO Epoch 4: [980/10940] ---- BYOL Training Loss = 0.2005576342344284
31-01-2023 07:48:29 INFO Epoch 4: [991/10940] ---- BYOL Training Loss = 0.2080274075269699
31-01-2023 07:48:46 INFO Epoch 4: [1002/10940] ---- BYOL Training Loss = 0.22589249908924103
31-01-2023 07:49:04 INFO Epoch 4: [1013/10940] ---- BYOL Training Loss = 0.19852231442928314
31-01-2023 07:49:56 INFO Epoch 4: [1013/10940] ---- BYOL Validation Loss = 0.17037399113178253
31-01-2023 07:50:13 INFO Epoch 4: [1024/10940] ---- BYOL Training Loss = 0.17110469937324524
31-01-2023 07:50:31 INFO Epoch 4: [1035/10940] ---- BYOL Training Loss = 0.19455990195274353
31-01-2023 07:50:48 INFO Epoch 4: [1046/10940] ---- BYOL Training Loss = 0.1763007640838623
31-01-2023 07:51:06 INFO Epoch 4: [1057/10940] ---- BYOL Training Loss = 0.18803200125694275
31-01-2023 07:51:58 INFO Epoch 4: [1057/10940] ---- BYOL Validation Loss = 0.150775745511055
31-01-2023 07:52:15 INFO Epoch 4: [1068/10940] ---- BYOL Training Loss = 0.19802682101726532
31-01-2023 07:52:33 INFO Epoch 4: [1079/10940] ---- BYOL Training Loss = 0.18261191248893738
31-01-2023 07:52:50 INFO Epoch 4: [1090/10940] ---- BYOL Training Loss = 0.18538424372673035
31-01-2023 07:53:08 INFO Epoch 4: [1101/10940] ---- BYOL Training Loss = 0.25763532519340515
31-01-2023 07:54:00 INFO Epoch 4: [1101/10940] ---- BYOL Validation Loss = 0.18497633934020996
31-01-2023 07:54:17 INFO Epoch 4: [1112/10940] ---- BYOL Training Loss = 0.2564867436885834
31-01-2023 07:54:35 INFO Epoch 4: [1123/10940] ---- BYOL Training Loss = 0.19327381253242493
31-01-2023 07:54:53 INFO Epoch 4: [1134/10940] ---- BYOL Training Loss = 0.18946264684200287
31-01-2023 07:55:10 INFO Epoch 4: [1145/10940] ---- BYOL Training Loss = 0.24878808856010437
31-01-2023 07:56:03 INFO Epoch 4: [1145/10940] ---- BYOL Validation Loss = 0.19344757497310638
31-01-2023 07:56:20 INFO Epoch 4: [1156/10940] ---- BYOL Training Loss = 0.24936895072460175
31-01-2023 07:56:37 INFO Epoch 4: [1167/10940] ---- BYOL Training Loss = 0.19369855523109436
31-01-2023 07:56:55 INFO Epoch 4: [1178/10940] ---- BYOL Training Loss = 0.2394605427980423
31-01-2023 07:57:13 INFO Epoch 4: [1189/10940] ---- BYOL Training Loss = 0.24446973204612732
31-01-2023 07:58:05 INFO Epoch 4: [1189/10940] ---- BYOL Validation Loss = 0.19860990345478058
31-01-2023 07:58:22 INFO Epoch 4: [1200/10940] ---- BYOL Training Loss = 0.20848548412322998
31-01-2023 07:58:40 INFO Epoch 4: [1211/10940] ---- BYOL Training Loss = 0.20081713795661926
31-01-2023 07:58:57 INFO Epoch 4: [1222/10940] ---- BYOL Training Loss = 0.21547135710716248
31-01-2023 07:59:15 INFO Epoch 4: [1233/10940] ---- BYOL Training Loss = 0.2028658092021942
31-01-2023 08:00:07 INFO Epoch 4: [1233/10940] ---- BYOL Validation Loss = 0.19697503745555878
31-01-2023 08:00:24 INFO Epoch 4: [1244/10940] ---- BYOL Training Loss = 0.17940400540828705
31-01-2023 08:00:42 INFO Epoch 4: [1255/10940] ---- BYOL Training Loss = 0.17994019389152527
31-01-2023 08:01:00 INFO Epoch 4: [1266/10940] ---- BYOL Training Loss = 0.17227758467197418
31-01-2023 08:01:17 INFO Epoch 4: [1277/10940] ---- BYOL Training Loss = 0.22827482223510742
31-01-2023 08:02:09 INFO Epoch 4: [1277/10940] ---- BYOL Validation Loss = 0.19827575981616974
31-01-2023 08:02:27 INFO Epoch 4: [1288/10940] ---- BYOL Training Loss = 0.26669085025787354
31-01-2023 08:02:44 INFO Epoch 4: [1299/10940] ---- BYOL Training Loss = 0.23989173769950867
31-01-2023 08:03:02 INFO Epoch 4: [1310/10940] ---- BYOL Training Loss = 0.21452867984771729
31-01-2023 08:03:20 INFO Epoch 4: [1321/10940] ---- BYOL Training Loss = 0.2136351764202118
31-01-2023 08:04:12 INFO Epoch 4: [1321/10940] ---- BYOL Validation Loss = 0.19829323887825012
31-01-2023 08:04:29 INFO Epoch 4: [1332/10940] ---- BYOL Training Loss = 0.21488070487976074
31-01-2023 08:04:47 INFO Epoch 4: [1343/10940] ---- BYOL Training Loss = 0.21795901656150818
31-01-2023 08:05:04 INFO Epoch 4: [1354/10940] ---- BYOL Training Loss = 0.1995842158794403
31-01-2023 08:05:22 INFO Epoch 4: [1365/10940] ---- BYOL Training Loss = 0.21385478973388672
31-01-2023 08:06:14 INFO Epoch 4: [1365/10940] ---- BYOL Validation Loss = 0.19971029460430145
31-01-2023 08:06:31 INFO Epoch 4: [1376/10940] ---- BYOL Training Loss = 0.2327512800693512
31-01-2023 08:06:49 INFO Epoch 4: [1387/10940] ---- BYOL Training Loss = 0.1866690218448639
31-01-2023 08:07:06 INFO Epoch 4: [1398/10940] ---- BYOL Training Loss = 0.18853381276130676
31-01-2023 08:07:24 INFO Epoch 4: [1409/10940] ---- BYOL Training Loss = 0.22742041945457458
31-01-2023 08:08:16 INFO Epoch 4: [1409/10940] ---- BYOL Validation Loss = 0.20128829777240753
31-01-2023 08:08:33 INFO Epoch 4: [1420/10940] ---- BYOL Training Loss = 0.18301904201507568
31-01-2023 08:08:51 INFO Epoch 4: [1431/10940] ---- BYOL Training Loss = 0.15569815039634705
31-01-2023 08:09:09 INFO Epoch 4: [1442/10940] ---- BYOL Training Loss = 0.1749231517314911
31-01-2023 08:09:27 INFO Epoch 4: [1453/10940] ---- BYOL Training Loss = 0.2216053307056427
31-01-2023 08:10:19 INFO Epoch 4: [1453/10940] ---- BYOL Validation Loss = 0.17343352735042572
31-01-2023 08:10:36 INFO Epoch 4: [1464/10940] ---- BYOL Training Loss = 0.17753711342811584
31-01-2023 08:10:54 INFO Epoch 4: [1475/10940] ---- BYOL Training Loss = 0.19947518408298492
31-01-2023 08:11:11 INFO Epoch 4: [1486/10940] ---- BYOL Training Loss = 0.18847714364528656
31-01-2023 08:11:29 INFO Epoch 4: [1497/10940] ---- BYOL Training Loss = 0.1944575309753418
31-01-2023 08:12:21 INFO Epoch 4: [1497/10940] ---- BYOL Validation Loss = 0.17769144475460052
31-01-2023 08:12:38 INFO Epoch 4: [1508/10940] ---- BYOL Training Loss = 0.21494433283805847
31-01-2023 08:12:56 INFO Epoch 4: [1519/10940] ---- BYOL Training Loss = 0.1968601495027542
31-01-2023 08:13:14 INFO Epoch 4: [1530/10940] ---- BYOL Training Loss = 0.22486305236816406
31-01-2023 08:13:31 INFO Epoch 4: [1541/10940] ---- BYOL Training Loss = 0.22270052134990692
31-01-2023 08:14:24 INFO Epoch 4: [1541/10940] ---- BYOL Validation Loss = 0.19882695376873016
31-01-2023 08:14:41 INFO Epoch 4: [1552/10940] ---- BYOL Training Loss = 0.2030850648880005
31-01-2023 08:14:59 INFO Epoch 4: [1563/10940] ---- BYOL Training Loss = 0.2093454897403717
31-01-2023 08:15:16 INFO Epoch 4: [1574/10940] ---- BYOL Training Loss = 0.2575032711029053
31-01-2023 08:15:34 INFO Epoch 4: [1585/10940] ---- BYOL Training Loss = 0.2568358778953552
31-01-2023 08:16:26 INFO Epoch 4: [1585/10940] ---- BYOL Validation Loss = 0.1986675262451172
31-01-2023 08:16:43 INFO Epoch 4: [1596/10940] ---- BYOL Training Loss = 0.19090674817562103
31-01-2023 08:17:01 INFO Epoch 4: [1607/10940] ---- BYOL Training Loss = 0.20459015667438507
31-01-2023 08:17:18 INFO Epoch 4: [1618/10940] ---- BYOL Training Loss = 0.195921391248703
31-01-2023 08:17:36 INFO Epoch 4: [1629/10940] ---- BYOL Training Loss = 0.1816977560520172
31-01-2023 08:18:28 INFO Epoch 4: [1629/10940] ---- BYOL Validation Loss = 0.19153307378292084
31-01-2023 08:18:46 INFO Epoch 4: [1640/10940] ---- BYOL Training Loss = 0.21857991814613342
31-01-2023 08:19:03 INFO Epoch 4: [1651/10940] ---- BYOL Training Loss = 0.18770667910575867
31-01-2023 08:19:21 INFO Epoch 4: [1662/10940] ---- BYOL Training Loss = 0.1931963413953781
31-01-2023 08:19:39 INFO Epoch 4: [1673/10940] ---- BYOL Training Loss = 0.19207614660263062
31-01-2023 08:20:31 INFO Epoch 4: [1673/10940] ---- BYOL Validation Loss = 0.17660441994667053
31-01-2023 08:20:48 INFO Epoch 4: [1684/10940] ---- BYOL Training Loss = 0.23378083109855652
31-01-2023 08:21:06 INFO Epoch 4: [1695/10940] ---- BYOL Training Loss = 0.33755847811698914
31-01-2023 08:21:24 INFO Epoch 4: [1706/10940] ---- BYOL Training Loss = 0.2686006724834442
31-01-2023 08:21:41 INFO Epoch 4: [1717/10940] ---- BYOL Training Loss = 0.2146444022655487
31-01-2023 08:22:33 INFO Epoch 4: [1717/10940] ---- BYOL Validation Loss = 0.18914195895195007
31-01-2023 08:22:51 INFO Epoch 4: [1728/10940] ---- BYOL Training Loss = 0.23122532665729523
31-01-2023 08:23:08 INFO Epoch 4: [1739/10940] ---- BYOL Training Loss = 0.1976495087146759
31-01-2023 08:23:26 INFO Epoch 4: [1750/10940] ---- BYOL Training Loss = 0.21397808194160461
31-01-2023 08:23:44 INFO Epoch 4: [1761/10940] ---- BYOL Training Loss = 0.20771217346191406
31-01-2023 08:24:36 INFO Epoch 4: [1761/10940] ---- BYOL Validation Loss = 0.20346686244010925
31-01-2023 08:24:53 INFO Epoch 4: [1772/10940] ---- BYOL Training Loss = 0.1924825757741928
31-01-2023 08:25:11 INFO Epoch 4: [1783/10940] ---- BYOL Training Loss = 0.23300178349018097
31-01-2023 08:25:28 INFO Epoch 4: [1794/10940] ---- BYOL Training Loss = 0.23726709187030792
31-01-2023 08:25:46 INFO Epoch 4: [1805/10940] ---- BYOL Training Loss = 0.22237499058246613
31-01-2023 08:26:38 INFO Epoch 4: [1805/10940] ---- BYOL Validation Loss = 0.19931422173976898
31-01-2023 08:26:56 INFO Epoch 4: [1816/10940] ---- BYOL Training Loss = 0.21045222878456116
31-01-2023 08:27:13 INFO Epoch 4: [1827/10940] ---- BYOL Training Loss = 0.19459205865859985
31-01-2023 08:27:31 INFO Epoch 4: [1838/10940] ---- BYOL Training Loss = 0.18770454823970795
31-01-2023 08:27:49 INFO Epoch 4: [1849/10940] ---- BYOL Training Loss = 0.19101300835609436
31-01-2023 08:28:41 INFO Epoch 4: [1849/10940] ---- BYOL Validation Loss = 0.1764117330312729
31-01-2023 08:28:58 INFO Epoch 4: [1860/10940] ---- BYOL Training Loss = 0.19942310452461243
31-01-2023 08:29:16 INFO Epoch 4: [1871/10940] ---- BYOL Training Loss = 0.21298162639141083
31-01-2023 08:29:34 INFO Epoch 4: [1882/10940] ---- BYOL Training Loss = 0.26293712854385376
31-01-2023 08:29:52 INFO Epoch 4: [1893/10940] ---- BYOL Training Loss = 0.3005180358886719
31-01-2023 08:30:44 INFO Epoch 4: [1893/10940] ---- BYOL Validation Loss = 0.19598276913166046
31-01-2023 08:31:01 INFO Epoch 4: [1904/10940] ---- BYOL Training Loss = 0.248653843998909
31-01-2023 08:31:19 INFO Epoch 4: [1915/10940] ---- BYOL Training Loss = 0.20418524742126465
31-01-2023 08:31:37 INFO Epoch 4: [1926/10940] ---- BYOL Training Loss = 0.16867183148860931
31-01-2023 08:31:54 INFO Epoch 4: [1937/10940] ---- BYOL Training Loss = 0.17095541954040527
31-01-2023 08:32:46 INFO Epoch 4: [1937/10940] ---- BYOL Validation Loss = 0.1744619458913803
31-01-2023 08:33:04 INFO Epoch 4: [1948/10940] ---- BYOL Training Loss = 0.20261117815971375
31-01-2023 08:33:21 INFO Epoch 4: [1959/10940] ---- BYOL Training Loss = 0.2188328504562378
31-01-2023 08:33:39 INFO Epoch 4: [1970/10940] ---- BYOL Training Loss = 0.2080899477005005
31-01-2023 08:33:57 INFO Epoch 4: [1981/10940] ---- BYOL Training Loss = 0.18981999158859253
31-01-2023 08:34:49 INFO Epoch 4: [1981/10940] ---- BYOL Validation Loss = 0.20339559018611908
31-01-2023 08:35:06 INFO Epoch 4: [1992/10940] ---- BYOL Training Loss = 0.1938357651233673
31-01-2023 08:35:24 INFO Epoch 4: [2003/10940] ---- BYOL Training Loss = 0.17713414132595062
31-01-2023 08:35:42 INFO Epoch 4: [2014/10940] ---- BYOL Training Loss = 0.18921607732772827
31-01-2023 08:35:59 INFO Epoch 4: [2025/10940] ---- BYOL Training Loss = 0.191692054271698
31-01-2023 08:36:52 INFO Epoch 4: [2025/10940] ---- BYOL Validation Loss = 0.15113531053066254
31-01-2023 08:37:09 INFO Epoch 4: [2036/10940] ---- BYOL Training Loss = 0.18482530117034912
31-01-2023 08:37:27 INFO Epoch 4: [2047/10940] ---- BYOL Training Loss = 0.20638683438301086
31-01-2023 08:37:45 INFO Epoch 4: [2058/10940] ---- BYOL Training Loss = 0.1905614137649536
31-01-2023 08:38:02 INFO Epoch 4: [2069/10940] ---- BYOL Training Loss = 0.17827561497688293
31-01-2023 08:38:55 INFO Epoch 4: [2069/10940] ---- BYOL Validation Loss = 0.16811397671699524
31-01-2023 08:39:12 INFO Epoch 4: [2080/10940] ---- BYOL Training Loss = 0.1670481115579605
31-01-2023 08:39:30 INFO Epoch 4: [2091/10940] ---- BYOL Training Loss = 0.1790592521429062
31-01-2023 08:39:47 INFO Epoch 4: [2102/10940] ---- BYOL Training Loss = 0.18373703956604004
31-01-2023 08:40:05 INFO Epoch 4: [2113/10940] ---- BYOL Training Loss = 0.2143353521823883
31-01-2023 08:40:57 INFO Epoch 4: [2113/10940] ---- BYOL Validation Loss = 0.1652713567018509
31-01-2023 08:41:15 INFO Epoch 4: [2124/10940] ---- BYOL Training Loss = 0.20556631684303284
31-01-2023 08:41:32 INFO Epoch 4: [2135/10940] ---- BYOL Training Loss = 0.17390111088752747
31-01-2023 08:41:50 INFO Epoch 4: [2146/10940] ---- BYOL Training Loss = 0.1685965359210968
31-01-2023 08:42:08 INFO Epoch 4: [2157/10940] ---- BYOL Training Loss = 0.16741643846035004
31-01-2023 08:43:00 INFO Epoch 4: [2157/10940] ---- BYOL Validation Loss = 0.184281587600708
31-01-2023 08:43:17 INFO Epoch 4: [2168/10940] ---- BYOL Training Loss = 0.21681180596351624
31-01-2023 08:43:35 INFO Epoch 4: [2179/10940] ---- BYOL Training Loss = 0.25381025671958923
31-01-2023 08:43:53 INFO Epoch 4: [2190/10940] ---- BYOL Training Loss = 0.2141769677400589
31-01-2023 08:44:11 INFO Epoch 4: [2201/10940] ---- BYOL Training Loss = 0.14383342862129211
31-01-2023 08:45:03 INFO Epoch 4: [2201/10940] ---- BYOL Validation Loss = 0.18025445938110352
31-01-2023 08:45:20 INFO Epoch 4: [2212/10940] ---- BYOL Training Loss = 0.1688951551914215
31-01-2023 08:45:38 INFO Epoch 4: [2223/10940] ---- BYOL Training Loss = 0.185315802693367
31-01-2023 08:45:56 INFO Epoch 4: [2234/10940] ---- BYOL Training Loss = 0.18230733275413513
31-01-2023 08:46:13 INFO Epoch 4: [2245/10940] ---- BYOL Training Loss = 0.26274359226226807
31-01-2023 08:47:06 INFO Epoch 4: [2245/10940] ---- BYOL Validation Loss = 0.16659413278102875
31-01-2023 08:47:23 INFO Epoch 4: [2256/10940] ---- BYOL Training Loss = 0.23244938254356384
31-01-2023 08:47:41 INFO Epoch 4: [2267/10940] ---- BYOL Training Loss = 0.2242496907711029
31-01-2023 08:47:58 INFO Epoch 4: [2278/10940] ---- BYOL Training Loss = 0.2213650643825531
31-01-2023 08:48:16 INFO Epoch 4: [2289/10940] ---- BYOL Training Loss = 0.1946277618408203
31-01-2023 08:49:08 INFO Epoch 4: [2289/10940] ---- BYOL Validation Loss = 0.19495756924152374
31-01-2023 08:49:25 INFO Epoch 4: [2300/10940] ---- BYOL Training Loss = 0.22549352049827576
31-01-2023 08:49:43 INFO Epoch 4: [2311/10940] ---- BYOL Training Loss = 0.1980130523443222
31-01-2023 08:50:01 INFO Epoch 4: [2322/10940] ---- BYOL Training Loss = 0.19152037799358368
31-01-2023 08:50:19 INFO Epoch 4: [2333/10940] ---- BYOL Training Loss = 0.22194774448871613
31-01-2023 08:51:11 INFO Epoch 4: [2333/10940] ---- BYOL Validation Loss = 0.20678594708442688
31-01-2023 08:51:28 INFO Epoch 4: [2344/10940] ---- BYOL Training Loss = 0.1984163522720337
31-01-2023 08:51:46 INFO Epoch 4: [2355/10940] ---- BYOL Training Loss = 0.22732865810394287
31-01-2023 08:52:04 INFO Epoch 4: [2366/10940] ---- BYOL Training Loss = 0.2299921065568924
31-01-2023 08:52:22 INFO Epoch 4: [2377/10940] ---- BYOL Training Loss = 0.20736952126026154
31-01-2023 08:53:14 INFO Epoch 4: [2377/10940] ---- BYOL Validation Loss = 0.20610393583774567
31-01-2023 08:53:31 INFO Epoch 4: [2388/10940] ---- BYOL Training Loss = 0.2106938660144806
31-01-2023 08:53:49 INFO Epoch 4: [2399/10940] ---- BYOL Training Loss = 0.20083507895469666
31-01-2023 08:54:06 INFO Epoch 4: [2410/10940] ---- BYOL Training Loss = 0.18295854330062866
31-01-2023 08:54:24 INFO Epoch 4: [2421/10940] ---- BYOL Training Loss = 0.20133881270885468
31-01-2023 08:55:16 INFO Epoch 4: [2421/10940] ---- BYOL Validation Loss = 0.17870023846626282
31-01-2023 08:55:34 INFO Epoch 4: [2432/10940] ---- BYOL Training Loss = 0.19991549849510193
31-01-2023 08:55:52 INFO Epoch 4: [2443/10940] ---- BYOL Training Loss = 0.17214417457580566
31-01-2023 08:56:09 INFO Epoch 4: [2454/10940] ---- BYOL Training Loss = 0.17024417221546173
31-01-2023 08:56:27 INFO Epoch 4: [2465/10940] ---- BYOL Training Loss = 0.21884307265281677
31-01-2023 08:57:19 INFO Epoch 4: [2465/10940] ---- BYOL Validation Loss = 0.17768803238868713
31-01-2023 08:57:37 INFO Epoch 4: [2476/10940] ---- BYOL Training Loss = 0.22249706089496613
31-01-2023 08:57:54 INFO Epoch 4: [2487/10940] ---- BYOL Training Loss = 0.23768572509288788
31-01-2023 08:58:12 INFO Epoch 4: [2498/10940] ---- BYOL Training Loss = 0.20210111141204834
31-01-2023 08:58:30 INFO Epoch 4: [2509/10940] ---- BYOL Training Loss = 0.20227749645709991
31-01-2023 08:59:22 INFO Epoch 4: [2509/10940] ---- BYOL Validation Loss = 0.1844608038663864
31-01-2023 08:59:39 INFO Epoch 4: [2520/10940] ---- BYOL Training Loss = 0.23761090636253357
31-01-2023 08:59:57 INFO Epoch 4: [2531/10940] ---- BYOL Training Loss = 0.27031365036964417
31-01-2023 09:00:15 INFO Epoch 4: [2542/10940] ---- BYOL Training Loss = 0.23555712401866913
31-01-2023 09:00:33 INFO Epoch 4: [2553/10940] ---- BYOL Training Loss = 0.25274908542633057
31-01-2023 09:01:25 INFO Epoch 4: [2553/10940] ---- BYOL Validation Loss = 0.15918251872062683
31-01-2023 09:01:42 INFO Epoch 4: [2564/10940] ---- BYOL Training Loss = 0.2547021508216858
31-01-2023 09:02:00 INFO Epoch 4: [2575/10940] ---- BYOL Training Loss = 0.23884408175945282
31-01-2023 09:02:18 INFO Epoch 4: [2586/10940] ---- BYOL Training Loss = 0.19161909818649292
31-01-2023 09:02:36 INFO Epoch 4: [2597/10940] ---- BYOL Training Loss = 0.1821947544813156
31-01-2023 09:03:28 INFO Epoch 4: [2597/10940] ---- BYOL Validation Loss = 0.19680704176425934
31-01-2023 09:03:45 INFO Epoch 4: [2608/10940] ---- BYOL Training Loss = 0.20211413502693176
31-01-2023 09:04:03 INFO Epoch 4: [2619/10940] ---- BYOL Training Loss = 0.212381511926651
31-01-2023 09:04:21 INFO Epoch 4: [2630/10940] ---- BYOL Training Loss = 0.19758827984333038
31-01-2023 09:04:38 INFO Epoch 4: [2641/10940] ---- BYOL Training Loss = 0.21860530972480774
31-01-2023 09:05:30 INFO Epoch 4: [2641/10940] ---- BYOL Validation Loss = 0.18170244991779327
31-01-2023 09:05:48 INFO Epoch 4: [2652/10940] ---- BYOL Training Loss = 0.21049919724464417
31-01-2023 09:06:06 INFO Epoch 4: [2663/10940] ---- BYOL Training Loss = 0.1563567817211151
31-01-2023 09:06:24 INFO Epoch 4: [2674/10940] ---- BYOL Training Loss = 0.18041205406188965
31-01-2023 09:06:41 INFO Epoch 4: [2685/10940] ---- BYOL Training Loss = 0.25455242395401
31-01-2023 09:07:33 INFO Epoch 4: [2685/10940] ---- BYOL Validation Loss = 0.1704198271036148
31-01-2023 09:07:51 INFO Epoch 4: [2696/10940] ---- BYOL Training Loss = 0.24322549998760223
31-01-2023 09:08:09 INFO Epoch 4: [2707/10940] ---- BYOL Training Loss = 0.18387678265571594
31-01-2023 09:08:26 INFO Epoch 4: [2718/10940] ---- BYOL Training Loss = 0.17322346568107605
31-01-2023 09:08:44 INFO Epoch 4: [2729/10940] ---- BYOL Training Loss = 0.16353294253349304
31-01-2023 09:09:36 INFO Epoch 4: [2729/10940] ---- BYOL Validation Loss = 0.19275133311748505
31-01-2023 09:09:54 INFO Epoch 4: [2740/10940] ---- BYOL Training Loss = 0.2001558095216751
31-01-2023 09:10:11 INFO Epoch 4: [2751/10940] ---- BYOL Training Loss = 0.22616665065288544
31-01-2023 09:10:29 INFO Epoch 4: [2762/10940] ---- BYOL Training Loss = 0.20526042580604553
31-01-2023 09:10:47 INFO Epoch 4: [2773/10940] ---- BYOL Training Loss = 0.19364605844020844
31-01-2023 09:11:39 INFO Epoch 4: [2773/10940] ---- BYOL Validation Loss = 0.16605952382087708
31-01-2023 09:11:57 INFO Epoch 4: [2784/10940] ---- BYOL Training Loss = 0.23035910725593567
31-01-2023 09:12:15 INFO Epoch 4: [2795/10940] ---- BYOL Training Loss = 0.261579692363739
31-01-2023 09:12:32 INFO Epoch 4: [2806/10940] ---- BYOL Training Loss = 0.22107455134391785
31-01-2023 09:12:50 INFO Epoch 4: [2817/10940] ---- BYOL Training Loss = 0.2137390375137329
31-01-2023 09:13:42 INFO Epoch 4: [2817/10940] ---- BYOL Validation Loss = 0.16521218419075012
31-01-2023 09:13:59 INFO Epoch 4: [2828/10940] ---- BYOL Training Loss = 0.186977818608284
31-01-2023 09:14:17 INFO Epoch 4: [2839/10940] ---- BYOL Training Loss = 0.176641583442688
31-01-2023 09:14:35 INFO Epoch 4: [2850/10940] ---- BYOL Training Loss = 0.17478689551353455
31-01-2023 09:14:53 INFO Epoch 4: [2861/10940] ---- BYOL Training Loss = 0.1784491240978241
31-01-2023 09:15:45 INFO Epoch 4: [2861/10940] ---- BYOL Validation Loss = 0.1714802235364914
31-01-2023 09:16:03 INFO Epoch 4: [2872/10940] ---- BYOL Training Loss = 0.18361060321331024
31-01-2023 09:16:20 INFO Epoch 4: [2883/10940] ---- BYOL Training Loss = 0.185899555683136
31-01-2023 09:16:38 INFO Epoch 4: [2894/10940] ---- BYOL Training Loss = 0.17775142192840576
31-01-2023 09:16:56 INFO Epoch 4: [2905/10940] ---- BYOL Training Loss = 0.17667105793952942
31-01-2023 09:17:48 INFO Epoch 4: [2905/10940] ---- BYOL Validation Loss = 0.15737459063529968
31-01-2023 09:18:05 INFO Epoch 4: [2916/10940] ---- BYOL Training Loss = 0.222821906208992
31-01-2023 09:18:23 INFO Epoch 4: [2927/10940] ---- BYOL Training Loss = 0.21643483638763428
31-01-2023 09:18:41 INFO Epoch 4: [2938/10940] ---- BYOL Training Loss = 0.24452996253967285
31-01-2023 09:18:59 INFO Epoch 4: [2949/10940] ---- BYOL Training Loss = 0.31658118963241577
31-01-2023 09:19:51 INFO Epoch 4: [2949/10940] ---- BYOL Validation Loss = 0.1975456178188324
31-01-2023 09:20:08 INFO Epoch 4: [2960/10940] ---- BYOL Training Loss = 0.2574433982372284
31-01-2023 09:20:26 INFO Epoch 4: [2971/10940] ---- BYOL Training Loss = 0.2399848997592926
31-01-2023 09:20:44 INFO Epoch 4: [2982/10940] ---- BYOL Training Loss = 0.20711417496204376
31-01-2023 09:21:02 INFO Epoch 4: [2993/10940] ---- BYOL Training Loss = 0.2118189036846161
31-01-2023 09:21:54 INFO Epoch 4: [2993/10940] ---- BYOL Validation Loss = 0.18933948874473572
31-01-2023 09:22:11 INFO Epoch 4: [3004/10940] ---- BYOL Training Loss = 0.19722206890583038
31-01-2023 09:22:29 INFO Epoch 4: [3015/10940] ---- BYOL Training Loss = 0.2463434934616089
31-01-2023 09:22:47 INFO Epoch 4: [3026/10940] ---- BYOL Training Loss = 0.28364723920822144
31-01-2023 09:23:05 INFO Epoch 4: [3037/10940] ---- BYOL Training Loss = 0.2171388566493988
31-01-2023 09:23:57 INFO Epoch 4: [3037/10940] ---- BYOL Validation Loss = 0.18935830891132355
31-01-2023 09:24:15 INFO Epoch 4: [3048/10940] ---- BYOL Training Loss = 0.16506962478160858
31-01-2023 09:24:33 INFO Epoch 4: [3059/10940] ---- BYOL Training Loss = 0.20459842681884766
31-01-2023 09:24:50 INFO Epoch 4: [3070/10940] ---- BYOL Training Loss = 0.17916680872440338
31-01-2023 09:25:08 INFO Epoch 4: [3081/10940] ---- BYOL Training Loss = 0.21660077571868896
31-01-2023 09:26:00 INFO Epoch 4: [3081/10940] ---- BYOL Validation Loss = 0.15909945964813232
31-01-2023 09:26:18 INFO Epoch 4: [3092/10940] ---- BYOL Training Loss = 0.2515239417552948
31-01-2023 09:26:35 INFO Epoch 4: [3103/10940] ---- BYOL Training Loss = 0.2558439373970032
31-01-2023 09:26:53 INFO Epoch 4: [3114/10940] ---- BYOL Training Loss = 0.25303179025650024
31-01-2023 09:27:11 INFO Epoch 4: [3125/10940] ---- BYOL Training Loss = 0.1832299381494522
31-01-2023 09:28:03 INFO Epoch 4: [3125/10940] ---- BYOL Validation Loss = 0.155069038271904
31-01-2023 09:28:21 INFO Epoch 4: [3136/10940] ---- BYOL Training Loss = 0.20180943608283997
31-01-2023 09:28:39 INFO Epoch 4: [3147/10940] ---- BYOL Training Loss = 0.2482776641845703
31-01-2023 09:28:56 INFO Epoch 4: [3158/10940] ---- BYOL Training Loss = 0.22777387499809265
31-01-2023 09:29:14 INFO Epoch 4: [3169/10940] ---- BYOL Training Loss = 0.18564778566360474
31-01-2023 09:30:06 INFO Epoch 4: [3169/10940] ---- BYOL Validation Loss = 0.19547857344150543
31-01-2023 09:30:24 INFO Epoch 4: [3180/10940] ---- BYOL Training Loss = 0.1814756542444229
31-01-2023 09:30:42 INFO Epoch 4: [3191/10940] ---- BYOL Training Loss = 0.20750108361244202
31-01-2023 09:30:59 INFO Epoch 4: [3202/10940] ---- BYOL Training Loss = 0.19617651402950287
31-01-2023 09:31:17 INFO Epoch 4: [3213/10940] ---- BYOL Training Loss = 0.1877964287996292
31-01-2023 09:32:09 INFO Epoch 4: [3213/10940] ---- BYOL Validation Loss = 0.14991436898708344
31-01-2023 09:32:27 INFO Epoch 4: [3224/10940] ---- BYOL Training Loss = 0.21095581352710724
31-01-2023 09:32:45 INFO Epoch 4: [3235/10940] ---- BYOL Training Loss = 0.19204318523406982
31-01-2023 09:33:03 INFO Epoch 4: [3246/10940] ---- BYOL Training Loss = 0.21851027011871338
31-01-2023 09:33:20 INFO Epoch 4: [3257/10940] ---- BYOL Training Loss = 0.22998777031898499
31-01-2023 09:34:13 INFO Epoch 4: [3257/10940] ---- BYOL Validation Loss = 0.17952916026115417
31-01-2023 09:34:30 INFO Epoch 4: [3268/10940] ---- BYOL Training Loss = 0.24522168934345245
31-01-2023 09:34:48 INFO Epoch 4: [3279/10940] ---- BYOL Training Loss = 0.24743065237998962
31-01-2023 09:35:06 INFO Epoch 4: [3290/10940] ---- BYOL Training Loss = 0.20501255989074707
31-01-2023 09:35:24 INFO Epoch 4: [3301/10940] ---- BYOL Training Loss = 0.19672909379005432
31-01-2023 09:36:16 INFO Epoch 4: [3301/10940] ---- BYOL Validation Loss = 0.19266875088214874
31-01-2023 09:36:33 INFO Epoch 4: [3312/10940] ---- BYOL Training Loss = 0.21598680317401886
31-01-2023 09:36:51 INFO Epoch 4: [3323/10940] ---- BYOL Training Loss = 0.21584296226501465
31-01-2023 09:37:09 INFO Epoch 4: [3334/10940] ---- BYOL Training Loss = 0.2051876336336136
31-01-2023 09:37:27 INFO Epoch 4: [3345/10940] ---- BYOL Training Loss = 0.22583551704883575
31-01-2023 09:38:19 INFO Epoch 4: [3345/10940] ---- BYOL Validation Loss = 0.1859363615512848
31-01-2023 09:38:36 INFO Epoch 4: [3356/10940] ---- BYOL Training Loss = 0.23978689312934875
31-01-2023 09:38:54 INFO Epoch 4: [3367/10940] ---- BYOL Training Loss = 0.2187178134918213
31-01-2023 09:39:12 INFO Epoch 4: [3378/10940] ---- BYOL Training Loss = 0.1897388994693756
31-01-2023 09:39:30 INFO Epoch 4: [3389/10940] ---- BYOL Training Loss = 0.19911633431911469
31-01-2023 09:40:22 INFO Epoch 4: [3389/10940] ---- BYOL Validation Loss = 0.19014252722263336
31-01-2023 09:40:40 INFO Epoch 4: [3400/10940] ---- BYOL Training Loss = 0.16709870100021362
31-01-2023 09:40:57 INFO Epoch 4: [3411/10940] ---- BYOL Training Loss = 0.17374680936336517
31-01-2023 09:41:15 INFO Epoch 4: [3422/10940] ---- BYOL Training Loss = 0.21992483735084534
31-01-2023 09:41:33 INFO Epoch 4: [3433/10940] ---- BYOL Training Loss = 0.25258103013038635
31-01-2023 09:42:25 INFO Epoch 4: [3433/10940] ---- BYOL Validation Loss = 0.18800614774227142
31-01-2023 09:42:43 INFO Epoch 4: [3444/10940] ---- BYOL Training Loss = 0.2528630793094635
31-01-2023 09:43:00 INFO Epoch 4: [3455/10940] ---- BYOL Training Loss = 0.21256399154663086
31-01-2023 09:43:19 INFO Epoch 4: [3466/10940] ---- BYOL Training Loss = 0.2509813904762268
31-01-2023 09:43:36 INFO Epoch 4: [3477/10940] ---- BYOL Training Loss = 0.2334032952785492
31-01-2023 09:44:29 INFO Epoch 4: [3477/10940] ---- BYOL Validation Loss = 0.19205184280872345
31-01-2023 09:44:46 INFO Epoch 4: [3488/10940] ---- BYOL Training Loss = 0.19454878568649292
31-01-2023 09:45:04 INFO Epoch 4: [3499/10940] ---- BYOL Training Loss = 0.18151995539665222
31-01-2023 09:45:22 INFO Epoch 4: [3510/10940] ---- BYOL Training Loss = 0.19177672266960144
31-01-2023 09:45:39 INFO Epoch 4: [3521/10940] ---- BYOL Training Loss = 0.20978204905986786
31-01-2023 09:46:32 INFO Epoch 4: [3521/10940] ---- BYOL Validation Loss = 0.18918146193027496
31-01-2023 09:46:49 INFO Epoch 4: [3532/10940] ---- BYOL Training Loss = 0.18712879717350006
31-01-2023 09:47:07 INFO Epoch 4: [3543/10940] ---- BYOL Training Loss = 0.1979532390832901
31-01-2023 09:47:25 INFO Epoch 4: [3554/10940] ---- BYOL Training Loss = 0.21743245422840118
31-01-2023 09:47:43 INFO Epoch 4: [3565/10940] ---- BYOL Training Loss = 0.1780140995979309
31-01-2023 09:48:35 INFO Epoch 4: [3565/10940] ---- BYOL Validation Loss = 0.1725275218486786
31-01-2023 09:48:52 INFO Epoch 4: [3576/10940] ---- BYOL Training Loss = 0.14854910969734192
31-01-2023 09:49:10 INFO Epoch 4: [3587/10940] ---- BYOL Training Loss = 0.15809302031993866
31-01-2023 09:49:28 INFO Epoch 4: [3598/10940] ---- BYOL Training Loss = 0.23934456706047058
31-01-2023 09:49:46 INFO Epoch 4: [3609/10940] ---- BYOL Training Loss = 0.24894468486309052
31-01-2023 09:50:38 INFO Epoch 4: [3609/10940] ---- BYOL Validation Loss = 0.16694076359272003
31-01-2023 09:50:56 INFO Epoch 4: [3620/10940] ---- BYOL Training Loss = 0.21888050436973572
31-01-2023 09:51:14 INFO Epoch 4: [3631/10940] ---- BYOL Training Loss = 0.2105296552181244
31-01-2023 09:51:32 INFO Epoch 4: [3642/10940] ---- BYOL Training Loss = 0.2837951183319092
31-01-2023 09:51:49 INFO Epoch 4: [3653/10940] ---- BYOL Training Loss = 0.21993084251880646
31-01-2023 09:52:42 INFO Epoch 4: [3653/10940] ---- BYOL Validation Loss = 0.18333002924919128
31-01-2023 09:52:59 INFO Epoch 4: [3664/10940] ---- BYOL Training Loss = 0.22541043162345886
31-01-2023 09:53:17 INFO Epoch 4: [3675/10940] ---- BYOL Training Loss = 0.2346419095993042
31-01-2023 09:53:35 INFO Epoch 4: [3686/10940] ---- BYOL Training Loss = 0.2158500701189041
31-01-2023 09:53:53 INFO Epoch 4: [3697/10940] ---- BYOL Training Loss = 0.22195056080818176
31-01-2023 09:54:45 INFO Epoch 4: [3697/10940] ---- BYOL Validation Loss = 0.22795416414737701
31-01-2023 09:55:02 INFO Epoch 4: [3708/10940] ---- BYOL Training Loss = 0.24572846293449402
31-01-2023 09:55:20 INFO Epoch 4: [3719/10940] ---- BYOL Training Loss = 0.24377195537090302
31-01-2023 09:55:38 INFO Epoch 4: [3730/10940] ---- BYOL Training Loss = 0.21127450466156006
31-01-2023 09:55:56 INFO Epoch 4: [3741/10940] ---- BYOL Training Loss = 0.2032405585050583
31-01-2023 09:56:48 INFO Epoch 4: [3741/10940] ---- BYOL Validation Loss = 0.2053832709789276
31-01-2023 09:57:06 INFO Epoch 4: [3752/10940] ---- BYOL Training Loss = 0.22772136330604553
31-01-2023 09:57:24 INFO Epoch 4: [3763/10940] ---- BYOL Training Loss = 0.22588786482810974
31-01-2023 09:57:42 INFO Epoch 4: [3774/10940] ---- BYOL Training Loss = 0.21997392177581787
31-01-2023 09:57:59 INFO Epoch 4: [3785/10940] ---- BYOL Training Loss = 0.2527415156364441
31-01-2023 09:58:52 INFO Epoch 4: [3785/10940] ---- BYOL Validation Loss = 0.21130968630313873
31-01-2023 09:59:09 INFO Epoch 4: [3796/10940] ---- BYOL Training Loss = 0.23448920249938965
31-01-2023 09:59:27 INFO Epoch 4: [3807/10940] ---- BYOL Training Loss = 0.1887243092060089
31-01-2023 09:59:45 INFO Epoch 4: [3818/10940] ---- BYOL Training Loss = 0.16792313754558563
31-01-2023 10:00:03 INFO Epoch 4: [3829/10940] ---- BYOL Training Loss = 0.21935689449310303
31-01-2023 10:00:55 INFO Epoch 4: [3829/10940] ---- BYOL Validation Loss = 0.20566678047180176
31-01-2023 10:01:13 INFO Epoch 4: [3840/10940] ---- BYOL Training Loss = 0.22536258399486542
31-01-2023 10:01:30 INFO Epoch 4: [3851/10940] ---- BYOL Training Loss = 0.21679279208183289
31-01-2023 10:01:48 INFO Epoch 4: [3862/10940] ---- BYOL Training Loss = 0.21042843163013458
31-01-2023 10:02:06 INFO Epoch 4: [3873/10940] ---- BYOL Training Loss = 0.21762435138225555
31-01-2023 10:02:58 INFO Epoch 4: [3873/10940] ---- BYOL Validation Loss = 0.19866666197776794
31-01-2023 10:03:16 INFO Epoch 4: [3884/10940] ---- BYOL Training Loss = 0.21869178116321564
31-01-2023 10:03:34 INFO Epoch 4: [3895/10940] ---- BYOL Training Loss = 0.1891058385372162
31-01-2023 10:03:52 INFO Epoch 4: [3906/10940] ---- BYOL Training Loss = 0.19077475368976593
31-01-2023 10:04:10 INFO Epoch 4: [3917/10940] ---- BYOL Training Loss = 0.19360972940921783
31-01-2023 10:05:02 INFO Epoch 4: [3917/10940] ---- BYOL Validation Loss = 0.19867588579654694
31-01-2023 10:05:20 INFO Epoch 4: [3928/10940] ---- BYOL Training Loss = 0.17550665140151978
31-01-2023 10:05:37 INFO Epoch 4: [3939/10940] ---- BYOL Training Loss = 0.16119666397571564
31-01-2023 10:05:55 INFO Epoch 4: [3950/10940] ---- BYOL Training Loss = 0.18090181052684784
31-01-2023 10:06:13 INFO Epoch 4: [3961/10940] ---- BYOL Training Loss = 0.21289198100566864
31-01-2023 10:07:06 INFO Epoch 4: [3961/10940] ---- BYOL Validation Loss = 0.19800207018852234
31-01-2023 10:07:23 INFO Epoch 4: [3972/10940] ---- BYOL Training Loss = 0.21815800666809082
31-01-2023 10:07:41 INFO Epoch 4: [3983/10940] ---- BYOL Training Loss = 0.20745813846588135
31-01-2023 10:07:59 INFO Epoch 4: [3994/10940] ---- BYOL Training Loss = 0.22462019324302673
31-01-2023 10:08:17 INFO Epoch 4: [4005/10940] ---- BYOL Training Loss = 0.2547745406627655
31-01-2023 10:09:09 INFO Epoch 4: [4005/10940] ---- BYOL Validation Loss = 0.20775608718395233
31-01-2023 10:09:26 INFO Epoch 4: [4016/10940] ---- BYOL Training Loss = 0.2548840641975403
31-01-2023 10:09:45 INFO Epoch 4: [4027/10940] ---- BYOL Training Loss = 0.24022379517555237
31-01-2023 10:10:03 INFO Epoch 4: [4038/10940] ---- BYOL Training Loss = 0.20254698395729065
31-01-2023 10:10:20 INFO Epoch 4: [4049/10940] ---- BYOL Training Loss = 0.17598798871040344
31-01-2023 10:11:12 INFO Epoch 4: [4049/10940] ---- BYOL Validation Loss = 0.194712296128273
31-01-2023 10:11:30 INFO Epoch 4: [4060/10940] ---- BYOL Training Loss = 0.1727474331855774
31-01-2023 10:11:48 INFO Epoch 4: [4071/10940] ---- BYOL Training Loss = 0.20497997105121613
31-01-2023 10:12:06 INFO Epoch 4: [4082/10940] ---- BYOL Training Loss = 0.23634247481822968
31-01-2023 10:12:23 INFO Epoch 4: [4093/10940] ---- BYOL Training Loss = 0.23014815151691437
31-01-2023 10:13:16 INFO Epoch 4: [4093/10940] ---- BYOL Validation Loss = 0.19122956693172455
31-01-2023 10:13:34 INFO Epoch 4: [4104/10940] ---- BYOL Training Loss = 0.19599471986293793
31-01-2023 10:13:51 INFO Epoch 4: [4115/10940] ---- BYOL Training Loss = 0.19298137724399567
31-01-2023 10:14:09 INFO Epoch 4: [4126/10940] ---- BYOL Training Loss = 0.24202576279640198
31-01-2023 10:14:27 INFO Epoch 4: [4137/10940] ---- BYOL Training Loss = 0.21235676109790802
31-01-2023 10:15:19 INFO Epoch 4: [4137/10940] ---- BYOL Validation Loss = 0.19367454946041107
31-01-2023 10:15:37 INFO Epoch 4: [4148/10940] ---- BYOL Training Loss = 0.16584640741348267
31-01-2023 10:15:55 INFO Epoch 4: [4159/10940] ---- BYOL Training Loss = 0.1675621122121811
31-01-2023 10:16:13 INFO Epoch 4: [4170/10940] ---- BYOL Training Loss = 0.1884499043226242
31-01-2023 10:16:31 INFO Epoch 4: [4181/10940] ---- BYOL Training Loss = 0.20863723754882812
31-01-2023 10:17:23 INFO Epoch 4: [4181/10940] ---- BYOL Validation Loss = 0.17520663142204285
31-01-2023 10:17:40 INFO Epoch 4: [4192/10940] ---- BYOL Training Loss = 0.17098836600780487
31-01-2023 10:17:58 INFO Epoch 4: [4203/10940] ---- BYOL Training Loss = 0.18654415011405945
31-01-2023 10:18:16 INFO Epoch 4: [4214/10940] ---- BYOL Training Loss = 0.1713051199913025
31-01-2023 10:18:34 INFO Epoch 4: [4225/10940] ---- BYOL Training Loss = 0.16691266000270844
31-01-2023 10:19:26 INFO Epoch 4: [4225/10940] ---- BYOL Validation Loss = 0.1686636209487915
31-01-2023 10:19:44 INFO Epoch 4: [4236/10940] ---- BYOL Training Loss = 0.20001384615898132
31-01-2023 10:20:02 INFO Epoch 4: [4247/10940] ---- BYOL Training Loss = 0.20072945952415466
31-01-2023 10:20:20 INFO Epoch 4: [4258/10940] ---- BYOL Training Loss = 0.1837213784456253
31-01-2023 10:20:38 INFO Epoch 4: [4269/10940] ---- BYOL Training Loss = 0.1645759642124176
31-01-2023 10:21:30 INFO Epoch 4: [4269/10940] ---- BYOL Validation Loss = 0.14659583568572998
31-01-2023 10:21:48 INFO Epoch 4: [4280/10940] ---- BYOL Training Loss = 0.1592557728290558
31-01-2023 10:22:06 INFO Epoch 4: [4291/10940] ---- BYOL Training Loss = 0.22190065681934357
31-01-2023 10:22:24 INFO Epoch 4: [4302/10940] ---- BYOL Training Loss = 0.2367471158504486
31-01-2023 10:22:41 INFO Epoch 4: [4313/10940] ---- BYOL Training Loss = 0.24048399925231934
31-01-2023 10:23:34 INFO Epoch 4: [4313/10940] ---- BYOL Validation Loss = 0.1971099078655243
31-01-2023 10:23:51 INFO Epoch 4: [4324/10940] ---- BYOL Training Loss = 0.24363374710083008
31-01-2023 10:24:09 INFO Epoch 4: [4335/10940] ---- BYOL Training Loss = 0.2350151091814041
31-01-2023 10:24:27 INFO Epoch 4: [4346/10940] ---- BYOL Training Loss = 0.2017858922481537
31-01-2023 10:24:45 INFO Epoch 4: [4357/10940] ---- BYOL Training Loss = 0.18153010308742523
31-01-2023 10:25:37 INFO Epoch 4: [4357/10940] ---- BYOL Validation Loss = 0.17400358617305756
31-01-2023 10:25:55 INFO Epoch 4: [4368/10940] ---- BYOL Training Loss = 0.16236931085586548
31-01-2023 10:26:13 INFO Epoch 4: [4379/10940] ---- BYOL Training Loss = 0.15693461894989014
31-01-2023 10:26:30 INFO Epoch 4: [4390/10940] ---- BYOL Training Loss = 0.18285301327705383
31-01-2023 10:26:48 INFO Epoch 4: [4401/10940] ---- BYOL Training Loss = 0.18940719962120056
31-01-2023 10:27:41 INFO Epoch 4: [4401/10940] ---- BYOL Validation Loss = 0.1207914724946022
31-01-2023 10:27:59 INFO Epoch 4: [4412/10940] ---- BYOL Training Loss = 0.14769136905670166
31-01-2023 10:28:16 INFO Epoch 4: [4423/10940] ---- BYOL Training Loss = 0.1713746190071106
31-01-2023 10:28:34 INFO Epoch 4: [4434/10940] ---- BYOL Training Loss = 0.17431209981441498
31-01-2023 10:28:52 INFO Epoch 4: [4445/10940] ---- BYOL Training Loss = 0.21808061003684998
31-01-2023 10:29:44 INFO Epoch 4: [4445/10940] ---- BYOL Validation Loss = 0.1365853101015091
31-01-2023 10:30:02 INFO Epoch 4: [4456/10940] ---- BYOL Training Loss = 0.22146837413311005
31-01-2023 10:30:20 INFO Epoch 4: [4467/10940] ---- BYOL Training Loss = 0.2175845354795456
31-01-2023 10:30:38 INFO Epoch 4: [4478/10940] ---- BYOL Training Loss = 0.2231699526309967
31-01-2023 10:30:56 INFO Epoch 4: [4489/10940] ---- BYOL Training Loss = 0.18915456533432007
31-01-2023 10:31:48 INFO Epoch 4: [4489/10940] ---- BYOL Validation Loss = 0.17352397739887238
31-01-2023 10:32:06 INFO Epoch 4: [4500/10940] ---- BYOL Training Loss = 0.19008059799671173
31-01-2023 10:32:24 INFO Epoch 4: [4511/10940] ---- BYOL Training Loss = 0.2004091739654541
31-01-2023 10:32:42 INFO Epoch 4: [4522/10940] ---- BYOL Training Loss = 0.18863804638385773
31-01-2023 10:33:00 INFO Epoch 4: [4533/10940] ---- BYOL Training Loss = 0.17561911046504974
31-01-2023 10:33:52 INFO Epoch 4: [4533/10940] ---- BYOL Validation Loss = 0.16663716733455658
31-01-2023 10:34:10 INFO Epoch 4: [4544/10940] ---- BYOL Training Loss = 0.15048626065254211
31-01-2023 10:34:27 INFO Epoch 4: [4555/10940] ---- BYOL Training Loss = 0.23079359531402588
31-01-2023 10:34:45 INFO Epoch 4: [4566/10940] ---- BYOL Training Loss = 0.2601724863052368
31-01-2023 10:35:04 INFO Epoch 4: [4577/10940] ---- BYOL Training Loss = 0.19567087292671204
31-01-2023 10:35:56 INFO Epoch 4: [4577/10940] ---- BYOL Validation Loss = 0.17822577059268951
31-01-2023 10:36:13 INFO Epoch 4: [4588/10940] ---- BYOL Training Loss = 0.17273519933223724
31-01-2023 10:36:31 INFO Epoch 4: [4599/10940] ---- BYOL Training Loss = 0.16435103118419647
31-01-2023 10:36:49 INFO Epoch 4: [4610/10940] ---- BYOL Training Loss = 0.1925213634967804
31-01-2023 10:37:07 INFO Epoch 4: [4621/10940] ---- BYOL Training Loss = 0.16073700785636902
31-01-2023 10:37:59 INFO Epoch 4: [4621/10940] ---- BYOL Validation Loss = 0.1826389580965042
31-01-2023 10:38:17 INFO Epoch 4: [4632/10940] ---- BYOL Training Loss = 0.1713515967130661
31-01-2023 10:38:35 INFO Epoch 4: [4643/10940] ---- BYOL Training Loss = 0.19427119195461273
31-01-2023 10:38:53 INFO Epoch 4: [4654/10940] ---- BYOL Training Loss = 0.20421913266181946
31-01-2023 10:39:11 INFO Epoch 4: [4665/10940] ---- BYOL Training Loss = 0.19413140416145325
31-01-2023 10:40:03 INFO Epoch 4: [4665/10940] ---- BYOL Validation Loss = 0.1836065948009491
31-01-2023 10:40:20 INFO Epoch 4: [4676/10940] ---- BYOL Training Loss = 0.21420052647590637
31-01-2023 10:40:39 INFO Epoch 4: [4687/10940] ---- BYOL Training Loss = 0.18849697709083557
31-01-2023 10:40:57 INFO Epoch 4: [4698/10940] ---- BYOL Training Loss = 0.21269753575325012
31-01-2023 10:41:15 INFO Epoch 4: [4709/10940] ---- BYOL Training Loss = 0.20495669543743134
31-01-2023 10:42:07 INFO Epoch 4: [4709/10940] ---- BYOL Validation Loss = 0.18907950818538666
31-01-2023 10:42:24 INFO Epoch 4: [4720/10940] ---- BYOL Training Loss = 0.1743282824754715
31-01-2023 10:42:42 INFO Epoch 4: [4731/10940] ---- BYOL Training Loss = 0.19948223233222961
31-01-2023 10:43:01 INFO Epoch 4: [4742/10940] ---- BYOL Training Loss = 0.20445704460144043
31-01-2023 10:43:18 INFO Epoch 4: [4753/10940] ---- BYOL Training Loss = 0.16425873339176178
31-01-2023 10:44:11 INFO Epoch 4: [4753/10940] ---- BYOL Validation Loss = 0.14798763394355774
31-01-2023 10:44:28 INFO Epoch 4: [4764/10940] ---- BYOL Training Loss = 0.1633402556180954
31-01-2023 10:44:46 INFO Epoch 4: [4775/10940] ---- BYOL Training Loss = 0.18581900000572205
31-01-2023 10:45:04 INFO Epoch 4: [4786/10940] ---- BYOL Training Loss = 0.21051327884197235
31-01-2023 10:45:22 INFO Epoch 4: [4797/10940] ---- BYOL Training Loss = 0.19116011261940002
31-01-2023 10:46:14 INFO Epoch 4: [4797/10940] ---- BYOL Validation Loss = 0.1499885469675064
31-01-2023 10:46:32 INFO Epoch 4: [4808/10940] ---- BYOL Training Loss = 0.15939171612262726
31-01-2023 10:46:50 INFO Epoch 4: [4819/10940] ---- BYOL Training Loss = 0.2084253579378128
31-01-2023 10:47:08 INFO Epoch 4: [4830/10940] ---- BYOL Training Loss = 0.1708228886127472
31-01-2023 10:47:26 INFO Epoch 4: [4841/10940] ---- BYOL Training Loss = 0.16570048034191132
31-01-2023 10:48:18 INFO Epoch 4: [4841/10940] ---- BYOL Validation Loss = 0.16633270680904388
31-01-2023 10:48:36 INFO Epoch 4: [4852/10940] ---- BYOL Training Loss = 0.22252991795539856
31-01-2023 10:48:54 INFO Epoch 4: [4863/10940] ---- BYOL Training Loss = 0.2834179103374481
31-01-2023 10:49:12 INFO Epoch 4: [4874/10940] ---- BYOL Training Loss = 0.21021321415901184
31-01-2023 10:49:30 INFO Epoch 4: [4885/10940] ---- BYOL Training Loss = 0.1868564784526825
31-01-2023 10:50:22 INFO Epoch 4: [4885/10940] ---- BYOL Validation Loss = 0.1894071102142334
31-01-2023 10:50:39 INFO Epoch 4: [4896/10940] ---- BYOL Training Loss = 0.1994599997997284
31-01-2023 10:50:57 INFO Epoch 4: [4907/10940] ---- BYOL Training Loss = 0.26834091544151306
31-01-2023 10:51:16 INFO Epoch 4: [4918/10940] ---- BYOL Training Loss = 0.2535633146762848
31-01-2023 10:51:34 INFO Epoch 4: [4929/10940] ---- BYOL Training Loss = 0.18785490095615387
31-01-2023 10:52:26 INFO Epoch 4: [4929/10940] ---- BYOL Validation Loss = 0.17853610217571259
31-01-2023 10:52:43 INFO Epoch 4: [4940/10940] ---- BYOL Training Loss = 0.17774230241775513
31-01-2023 10:53:01 INFO Epoch 4: [4951/10940] ---- BYOL Training Loss = 0.20049381256103516
31-01-2023 10:53:20 INFO Epoch 4: [4962/10940] ---- BYOL Training Loss = 0.2265181839466095
31-01-2023 10:53:37 INFO Epoch 4: [4973/10940] ---- BYOL Training Loss = 0.23621077835559845
31-01-2023 10:54:30 INFO Epoch 4: [4973/10940] ---- BYOL Validation Loss = 0.1599734127521515
31-01-2023 10:54:47 INFO Epoch 4: [4984/10940] ---- BYOL Training Loss = 0.24095723032951355
31-01-2023 10:55:05 INFO Epoch 4: [4995/10940] ---- BYOL Training Loss = 0.22348591685295105
31-01-2023 10:55:23 INFO Epoch 4: [5006/10940] ---- BYOL Training Loss = 0.22441589832305908
31-01-2023 10:55:41 INFO Epoch 4: [5017/10940] ---- BYOL Training Loss = 0.2454177439212799
31-01-2023 10:56:33 INFO Epoch 4: [5017/10940] ---- BYOL Validation Loss = 0.15297545492649078
31-01-2023 10:56:51 INFO Epoch 4: [5028/10940] ---- BYOL Training Loss = 0.2507266700267792
31-01-2023 10:57:09 INFO Epoch 4: [5039/10940] ---- BYOL Training Loss = 0.20133468508720398
31-01-2023 10:57:27 INFO Epoch 4: [5050/10940] ---- BYOL Training Loss = 0.18684422969818115
31-01-2023 10:57:45 INFO Epoch 4: [5061/10940] ---- BYOL Training Loss = 0.1797632873058319
31-01-2023 10:58:37 INFO Epoch 4: [5061/10940] ---- BYOL Validation Loss = 0.1556246429681778
31-01-2023 10:58:55 INFO Epoch 4: [5072/10940] ---- BYOL Training Loss = 0.15962772071361542
31-01-2023 10:59:13 INFO Epoch 4: [5083/10940] ---- BYOL Training Loss = 0.2026320993900299
31-01-2023 10:59:31 INFO Epoch 4: [5094/10940] ---- BYOL Training Loss = 0.2021263837814331
31-01-2023 10:59:49 INFO Epoch 4: [5105/10940] ---- BYOL Training Loss = 0.1657995581626892
31-01-2023 11:00:41 INFO Epoch 4: [5105/10940] ---- BYOL Validation Loss = 0.14965292811393738
31-01-2023 11:00:59 INFO Epoch 4: [5116/10940] ---- BYOL Training Loss = 0.21774974465370178
31-01-2023 11:01:17 INFO Epoch 4: [5127/10940] ---- BYOL Training Loss = 0.25720685720443726
31-01-2023 11:01:35 INFO Epoch 4: [5138/10940] ---- BYOL Training Loss = 0.220445916056633
31-01-2023 11:01:53 INFO Epoch 4: [5149/10940] ---- BYOL Training Loss = 0.20319418609142303
31-01-2023 11:02:45 INFO Epoch 4: [5149/10940] ---- BYOL Validation Loss = 0.17663954198360443
31-01-2023 11:03:03 INFO Epoch 4: [5160/10940] ---- BYOL Training Loss = 0.1970919817686081
31-01-2023 11:03:21 INFO Epoch 4: [5171/10940] ---- BYOL Training Loss = 0.24949702620506287
31-01-2023 11:03:39 INFO Epoch 4: [5182/10940] ---- BYOL Training Loss = 0.25642919540405273
31-01-2023 11:03:57 INFO Epoch 4: [5193/10940] ---- BYOL Training Loss = 0.1989443004131317
31-01-2023 11:04:49 INFO Epoch 4: [5193/10940] ---- BYOL Validation Loss = 0.17446668446063995
31-01-2023 11:05:07 INFO Epoch 4: [5204/10940] ---- BYOL Training Loss = 0.21687038242816925
31-01-2023 11:05:25 INFO Epoch 4: [5215/10940] ---- BYOL Training Loss = 0.1937921941280365
31-01-2023 11:05:43 INFO Epoch 4: [5226/10940] ---- BYOL Training Loss = 0.20255455374717712
31-01-2023 11:06:01 INFO Epoch 4: [5237/10940] ---- BYOL Training Loss = 0.2176741659641266
31-01-2023 11:06:53 INFO Epoch 4: [5237/10940] ---- BYOL Validation Loss = 0.1834801882505417
31-01-2023 11:07:11 INFO Epoch 4: [5248/10940] ---- BYOL Training Loss = 0.21569350361824036
31-01-2023 11:07:29 INFO Epoch 4: [5259/10940] ---- BYOL Training Loss = 0.19576546549797058
31-01-2023 11:07:47 INFO Epoch 4: [5270/10940] ---- BYOL Training Loss = 0.1874023824930191
31-01-2023 11:08:05 INFO Epoch 4: [5281/10940] ---- BYOL Training Loss = 0.20461499691009521
31-01-2023 11:08:58 INFO Epoch 4: [5281/10940] ---- BYOL Validation Loss = 0.18056140840053558
31-01-2023 11:09:15 INFO Epoch 4: [5292/10940] ---- BYOL Training Loss = 0.1914563924074173
31-01-2023 11:09:33 INFO Epoch 4: [5303/10940] ---- BYOL Training Loss = 0.1788172870874405
31-01-2023 11:09:51 INFO Epoch 4: [5314/10940] ---- BYOL Training Loss = 0.22583436965942383
31-01-2023 11:10:10 INFO Epoch 4: [5325/10940] ---- BYOL Training Loss = 0.21278221905231476
31-01-2023 11:11:02 INFO Epoch 4: [5325/10940] ---- BYOL Validation Loss = 0.17544136941432953
31-01-2023 11:11:19 INFO Epoch 4: [5336/10940] ---- BYOL Training Loss = 0.1607639193534851
31-01-2023 11:11:37 INFO Epoch 4: [5347/10940] ---- BYOL Training Loss = 0.199102982878685
31-01-2023 11:11:55 INFO Epoch 4: [5358/10940] ---- BYOL Training Loss = 0.2881370186805725
31-01-2023 11:12:13 INFO Epoch 4: [5369/10940] ---- BYOL Training Loss = 0.23985376954078674
31-01-2023 11:13:06 INFO Epoch 4: [5369/10940] ---- BYOL Validation Loss = 0.18146075308322906
31-01-2023 11:13:24 INFO Epoch 4: [5380/10940] ---- BYOL Training Loss = 0.20112478733062744
31-01-2023 11:13:42 INFO Epoch 4: [5391/10940] ---- BYOL Training Loss = 0.18951115012168884
31-01-2023 11:14:00 INFO Epoch 4: [5402/10940] ---- BYOL Training Loss = 0.2105748951435089
31-01-2023 11:14:18 INFO Epoch 4: [5413/10940] ---- BYOL Training Loss = 0.20653049647808075
31-01-2023 11:15:10 INFO Epoch 4: [5413/10940] ---- BYOL Validation Loss = 0.16774725914001465
31-01-2023 11:15:28 INFO Epoch 4: [5424/10940] ---- BYOL Training Loss = 0.20060810446739197
31-01-2023 11:15:46 INFO Epoch 4: [5435/10940] ---- BYOL Training Loss = 0.19063234329223633
31-01-2023 11:16:04 INFO Epoch 4: [5446/10940] ---- BYOL Training Loss = 0.1759406179189682
31-01-2023 11:16:22 INFO Epoch 4: [5457/10940] ---- BYOL Training Loss = 0.15661658346652985
31-01-2023 11:17:14 INFO Epoch 4: [5457/10940] ---- BYOL Validation Loss = 0.11981111019849777
31-01-2023 11:17:32 INFO Epoch 4: [5468/10940] ---- BYOL Training Loss = 0.1827172338962555
31-01-2023 11:17:50 INFO Epoch 4: [5479/10940] ---- BYOL Training Loss = 0.2351774424314499
31-01-2023 11:18:08 INFO Epoch 4: [5490/10940] ---- BYOL Training Loss = 0.1948000192642212
31-01-2023 11:18:26 INFO Epoch 4: [5501/10940] ---- BYOL Training Loss = 0.17714665830135345
31-01-2023 11:19:18 INFO Epoch 4: [5501/10940] ---- BYOL Validation Loss = 0.15794667601585388
31-01-2023 11:19:36 INFO Epoch 4: [5512/10940] ---- BYOL Training Loss = 0.2703824043273926
31-01-2023 11:19:54 INFO Epoch 4: [5523/10940] ---- BYOL Training Loss = 0.2749031186103821
31-01-2023 11:20:12 INFO Epoch 4: [5534/10940] ---- BYOL Training Loss = 0.21800288558006287
31-01-2023 11:20:30 INFO Epoch 4: [5545/10940] ---- BYOL Training Loss = 0.20655135810375214
31-01-2023 11:21:23 INFO Epoch 4: [5545/10940] ---- BYOL Validation Loss = 0.1138799861073494
31-01-2023 11:21:40 INFO Epoch 4: [5556/10940] ---- BYOL Training Loss = 0.17909017205238342
31-01-2023 11:21:58 INFO Epoch 4: [5567/10940] ---- BYOL Training Loss = 0.15808819234371185
31-01-2023 11:22:17 INFO Epoch 4: [5578/10940] ---- BYOL Training Loss = 0.17439204454421997
31-01-2023 11:22:35 INFO Epoch 4: [5589/10940] ---- BYOL Training Loss = 0.18429695069789886
31-01-2023 11:23:27 INFO Epoch 4: [5589/10940] ---- BYOL Validation Loss = 0.07982432842254639
31-01-2023 11:23:45 INFO Epoch 4: [5600/10940] ---- BYOL Training Loss = 0.17700855433940887
31-01-2023 11:24:03 INFO Epoch 4: [5611/10940] ---- BYOL Training Loss = 0.2416510134935379
31-01-2023 11:24:21 INFO Epoch 4: [5622/10940] ---- BYOL Training Loss = 0.2877855598926544
31-01-2023 11:24:39 INFO Epoch 4: [5633/10940] ---- BYOL Training Loss = 0.20403137803077698
31-01-2023 11:25:31 INFO Epoch 4: [5633/10940] ---- BYOL Validation Loss = 0.16837361454963684
31-01-2023 11:25:49 INFO Epoch 4: [5644/10940] ---- BYOL Training Loss = 0.2207503318786621
31-01-2023 11:26:07 INFO Epoch 4: [5655/10940] ---- BYOL Training Loss = 0.23070044815540314
31-01-2023 11:26:25 INFO Epoch 4: [5666/10940] ---- BYOL Training Loss = 0.16819964349269867
31-01-2023 11:26:43 INFO Epoch 4: [5677/10940] ---- BYOL Training Loss = 0.19037243723869324
31-01-2023 11:27:35 INFO Epoch 4: [5677/10940] ---- BYOL Validation Loss = 0.18467018008232117
31-01-2023 11:27:53 INFO Epoch 4: [5688/10940] ---- BYOL Training Loss = 0.2782164514064789
31-01-2023 11:28:11 INFO Epoch 4: [5699/10940] ---- BYOL Training Loss = 0.24523332715034485
31-01-2023 11:28:29 INFO Epoch 4: [5710/10940] ---- BYOL Training Loss = 0.20126645267009735
31-01-2023 11:28:47 INFO Epoch 4: [5721/10940] ---- BYOL Training Loss = 0.2234536111354828
31-01-2023 11:29:40 INFO Epoch 4: [5721/10940] ---- BYOL Validation Loss = 0.1839267909526825
31-01-2023 11:29:57 INFO Epoch 4: [5732/10940] ---- BYOL Training Loss = 0.2530044913291931
31-01-2023 11:30:15 INFO Epoch 4: [5743/10940] ---- BYOL Training Loss = 0.23158416152000427
31-01-2023 11:30:34 INFO Epoch 4: [5754/10940] ---- BYOL Training Loss = 0.17740032076835632
31-01-2023 11:30:52 INFO Epoch 4: [5765/10940] ---- BYOL Training Loss = 0.1938035637140274
31-01-2023 11:31:44 INFO Epoch 4: [5765/10940] ---- BYOL Validation Loss = 0.1884392946958542
31-01-2023 11:32:02 INFO Epoch 4: [5776/10940] ---- BYOL Training Loss = 0.21338267624378204
31-01-2023 11:32:20 INFO Epoch 4: [5787/10940] ---- BYOL Training Loss = 0.2017470896244049
31-01-2023 11:32:38 INFO Epoch 4: [5798/10940] ---- BYOL Training Loss = 0.20881196856498718
31-01-2023 11:32:56 INFO Epoch 4: [5809/10940] ---- BYOL Training Loss = 0.22389742732048035
31-01-2023 11:33:49 INFO Epoch 4: [5809/10940] ---- BYOL Validation Loss = 0.16380059719085693
31-01-2023 11:34:06 INFO Epoch 4: [5820/10940] ---- BYOL Training Loss = 0.18434974551200867
31-01-2023 11:34:24 INFO Epoch 4: [5831/10940] ---- BYOL Training Loss = 0.15700222551822662
31-01-2023 11:34:43 INFO Epoch 4: [5842/10940] ---- BYOL Training Loss = 0.22627682983875275
31-01-2023 11:35:01 INFO Epoch 4: [5853/10940] ---- BYOL Training Loss = 0.22029347717761993
31-01-2023 11:35:53 INFO Epoch 4: [5853/10940] ---- BYOL Validation Loss = 0.15018042922019958
31-01-2023 11:36:11 INFO Epoch 4: [5864/10940] ---- BYOL Training Loss = 0.17373618483543396
31-01-2023 11:36:29 INFO Epoch 4: [5875/10940] ---- BYOL Training Loss = 0.17148388922214508
31-01-2023 11:36:47 INFO Epoch 4: [5886/10940] ---- BYOL Training Loss = 0.26283782720565796
31-01-2023 11:37:05 INFO Epoch 4: [5897/10940] ---- BYOL Training Loss = 0.23601248860359192
31-01-2023 11:37:57 INFO Epoch 4: [5897/10940] ---- BYOL Validation Loss = 0.16581249237060547
31-01-2023 11:38:15 INFO Epoch 4: [5908/10940] ---- BYOL Training Loss = 0.19843563437461853
31-01-2023 11:38:33 INFO Epoch 4: [5919/10940] ---- BYOL Training Loss = 0.25252798199653625
31-01-2023 11:38:52 INFO Epoch 4: [5930/10940] ---- BYOL Training Loss = 0.20875892043113708
31-01-2023 11:39:10 INFO Epoch 4: [5941/10940] ---- BYOL Training Loss = 0.23608124256134033
31-01-2023 11:40:02 INFO Epoch 4: [5941/10940] ---- BYOL Validation Loss = 0.14415933191776276
31-01-2023 11:40:19 INFO Epoch 4: [5952/10940] ---- BYOL Training Loss = 0.25776034593582153
31-01-2023 11:40:38 INFO Epoch 4: [5963/10940] ---- BYOL Training Loss = 0.17258962988853455
31-01-2023 11:40:56 INFO Epoch 4: [5974/10940] ---- BYOL Training Loss = 0.1695420742034912
31-01-2023 11:41:14 INFO Epoch 4: [5985/10940] ---- BYOL Training Loss = 0.18900296092033386
31-01-2023 11:42:06 INFO Epoch 4: [5985/10940] ---- BYOL Validation Loss = 0.1524660885334015
31-01-2023 11:42:24 INFO Epoch 4: [5996/10940] ---- BYOL Training Loss = 0.18423275649547577
31-01-2023 11:42:42 INFO Epoch 4: [6007/10940] ---- BYOL Training Loss = 0.1512753665447235
31-01-2023 11:43:00 INFO Epoch 4: [6018/10940] ---- BYOL Training Loss = 0.19892358779907227
31-01-2023 11:43:18 INFO Epoch 4: [6029/10940] ---- BYOL Training Loss = 0.2708927392959595
31-01-2023 11:44:10 INFO Epoch 4: [6029/10940] ---- BYOL Validation Loss = 0.17406724393367767
31-01-2023 11:44:28 INFO Epoch 4: [6040/10940] ---- BYOL Training Loss = 0.2532981336116791
31-01-2023 11:44:46 INFO Epoch 4: [6051/10940] ---- BYOL Training Loss = 0.25591498613357544
31-01-2023 11:45:05 INFO Epoch 4: [6062/10940] ---- BYOL Training Loss = 0.20559470355510712
31-01-2023 11:45:23 INFO Epoch 4: [6073/10940] ---- BYOL Training Loss = 0.17939850687980652
31-01-2023 11:46:15 INFO Epoch 4: [6073/10940] ---- BYOL Validation Loss = 0.17858852446079254
31-01-2023 11:46:33 INFO Epoch 4: [6084/10940] ---- BYOL Training Loss = 0.2085130512714386
31-01-2023 11:46:51 INFO Epoch 4: [6095/10940] ---- BYOL Training Loss = 0.2216242253780365
31-01-2023 11:47:09 INFO Epoch 4: [6106/10940] ---- BYOL Training Loss = 0.22611722350120544
31-01-2023 11:47:27 INFO Epoch 4: [6117/10940] ---- BYOL Training Loss = 0.27521181106567383
31-01-2023 11:48:20 INFO Epoch 4: [6117/10940] ---- BYOL Validation Loss = 0.20115968585014343
31-01-2023 11:48:37 INFO Epoch 4: [6128/10940] ---- BYOL Training Loss = 0.25405898690223694
31-01-2023 11:48:55 INFO Epoch 4: [6139/10940] ---- BYOL Training Loss = 0.2293936312198639
31-01-2023 11:49:14 INFO Epoch 4: [6150/10940] ---- BYOL Training Loss = 0.2221696823835373
31-01-2023 11:49:32 INFO Epoch 4: [6161/10940] ---- BYOL Training Loss = 0.22067204117774963
31-01-2023 11:50:24 INFO Epoch 4: [6161/10940] ---- BYOL Validation Loss = 0.22745265066623688
31-01-2023 11:50:42 INFO Epoch 4: [6172/10940] ---- BYOL Training Loss = 0.1977691948413849
31-01-2023 11:51:00 INFO Epoch 4: [6183/10940] ---- BYOL Training Loss = 0.226833775639534
31-01-2023 11:51:18 INFO Epoch 4: [6194/10940] ---- BYOL Training Loss = 0.260702908039093
31-01-2023 11:51:36 INFO Epoch 4: [6205/10940] ---- BYOL Training Loss = 0.24259376525878906
31-01-2023 11:52:29 INFO Epoch 4: [6205/10940] ---- BYOL Validation Loss = 0.20229358971118927
31-01-2023 11:52:46 INFO Epoch 4: [6216/10940] ---- BYOL Training Loss = 0.23818214237689972
31-01-2023 11:53:04 INFO Epoch 4: [6227/10940] ---- BYOL Training Loss = 0.3104357123374939
31-01-2023 11:53:23 INFO Epoch 4: [6238/10940] ---- BYOL Training Loss = 0.2863660454750061
31-01-2023 11:53:41 INFO Epoch 4: [6249/10940] ---- BYOL Training Loss = 0.23810513317584991
31-01-2023 11:54:33 INFO Epoch 4: [6249/10940] ---- BYOL Validation Loss = 0.23923000693321228
31-01-2023 11:54:51 INFO Epoch 4: [6260/10940] ---- BYOL Training Loss = 0.2879529893398285
31-01-2023 11:55:09 INFO Epoch 4: [6271/10940] ---- BYOL Training Loss = 0.3385424315929413
31-01-2023 11:55:27 INFO Epoch 4: [6282/10940] ---- BYOL Training Loss = 0.290545791387558
31-01-2023 11:55:45 INFO Epoch 4: [6293/10940] ---- BYOL Training Loss = 0.2686934769153595
31-01-2023 11:56:38 INFO Epoch 4: [6293/10940] ---- BYOL Validation Loss = 0.2690337896347046
31-01-2023 11:56:55 INFO Epoch 4: [6304/10940] ---- BYOL Training Loss = 0.3213525712490082
31-01-2023 11:57:14 INFO Epoch 4: [6315/10940] ---- BYOL Training Loss = 0.32766395807266235
31-01-2023 11:57:32 INFO Epoch 4: [6326/10940] ---- BYOL Training Loss = 0.26884883642196655
31-01-2023 11:57:50 INFO Epoch 4: [6337/10940] ---- BYOL Training Loss = 0.24024298787117004
31-01-2023 11:58:42 INFO Epoch 4: [6337/10940] ---- BYOL Validation Loss = 0.258728951215744
31-01-2023 11:59:00 INFO Epoch 4: [6348/10940] ---- BYOL Training Loss = 0.2516748309135437
31-01-2023 11:59:18 INFO Epoch 4: [6359/10940] ---- BYOL Training Loss = 0.24198086559772491
31-01-2023 11:59:36 INFO Epoch 4: [6370/10940] ---- BYOL Training Loss = 0.22955207526683807
31-01-2023 11:59:55 INFO Epoch 4: [6381/10940] ---- BYOL Training Loss = 0.23445522785186768
31-01-2023 12:00:47 INFO Epoch 4: [6381/10940] ---- BYOL Validation Loss = 0.22798290848731995
31-01-2023 12:01:05 INFO Epoch 4: [6392/10940] ---- BYOL Training Loss = 0.26750844717025757
31-01-2023 12:01:23 INFO Epoch 4: [6403/10940] ---- BYOL Training Loss = 0.2504783272743225
31-01-2023 12:01:41 INFO Epoch 4: [6414/10940] ---- BYOL Training Loss = 0.2476596087217331
31-01-2023 12:01:59 INFO Epoch 4: [6425/10940] ---- BYOL Training Loss = 0.2575283944606781
31-01-2023 12:02:51 INFO Epoch 4: [6425/10940] ---- BYOL Validation Loss = 0.2064359039068222
31-01-2023 12:03:09 INFO Epoch 4: [6436/10940] ---- BYOL Training Loss = 0.2112666368484497
31-01-2023 12:03:28 INFO Epoch 4: [6447/10940] ---- BYOL Training Loss = 0.19661171734333038
31-01-2023 12:03:46 INFO Epoch 4: [6458/10940] ---- BYOL Training Loss = 0.21484918892383575
31-01-2023 12:04:04 INFO Epoch 4: [6469/10940] ---- BYOL Training Loss = 0.2117932289838791
31-01-2023 12:04:56 INFO Epoch 4: [6469/10940] ---- BYOL Validation Loss = 0.1734866052865982
31-01-2023 12:05:14 INFO Epoch 4: [6480/10940] ---- BYOL Training Loss = 0.21469180285930634
31-01-2023 12:05:32 INFO Epoch 4: [6491/10940] ---- BYOL Training Loss = 0.21857114136219025
31-01-2023 12:05:50 INFO Epoch 4: [6502/10940] ---- BYOL Training Loss = 0.24923810362815857
31-01-2023 12:06:09 INFO Epoch 4: [6513/10940] ---- BYOL Training Loss = 0.21946239471435547
31-01-2023 12:07:01 INFO Epoch 4: [6513/10940] ---- BYOL Validation Loss = 0.17689578235149384
31-01-2023 12:07:18 INFO Epoch 4: [6524/10940] ---- BYOL Training Loss = 0.20426006615161896
31-01-2023 12:07:37 INFO Epoch 4: [6535/10940] ---- BYOL Training Loss = 0.240113765001297
31-01-2023 12:07:55 INFO Epoch 4: [6546/10940] ---- BYOL Training Loss = 0.26773601770401
31-01-2023 12:08:13 INFO Epoch 4: [6557/10940] ---- BYOL Training Loss = 0.21693702042102814
31-01-2023 12:09:05 INFO Epoch 4: [6557/10940] ---- BYOL Validation Loss = 0.19548062980175018
31-01-2023 12:09:23 INFO Epoch 4: [6568/10940] ---- BYOL Training Loss = 0.18422803282737732
31-01-2023 12:09:41 INFO Epoch 4: [6579/10940] ---- BYOL Training Loss = 0.1664029061794281
31-01-2023 12:09:59 INFO Epoch 4: [6590/10940] ---- BYOL Training Loss = 0.21539536118507385
31-01-2023 12:10:18 INFO Epoch 4: [6601/10940] ---- BYOL Training Loss = 0.24471859633922577
31-01-2023 12:11:10 INFO Epoch 4: [6601/10940] ---- BYOL Validation Loss = 0.1844702512025833
31-01-2023 12:11:27 INFO Epoch 4: [6612/10940] ---- BYOL Training Loss = 0.2663586437702179
31-01-2023 12:11:46 INFO Epoch 4: [6623/10940] ---- BYOL Training Loss = 0.24350440502166748
31-01-2023 12:12:04 INFO Epoch 4: [6634/10940] ---- BYOL Training Loss = 0.2037571221590042
31-01-2023 12:12:22 INFO Epoch 4: [6645/10940] ---- BYOL Training Loss = 0.2098197042942047
31-01-2023 12:13:14 INFO Epoch 4: [6645/10940] ---- BYOL Validation Loss = 0.165451318025589
31-01-2023 12:13:32 INFO Epoch 4: [6656/10940] ---- BYOL Training Loss = 0.19807419180870056
31-01-2023 12:13:50 INFO Epoch 4: [6667/10940] ---- BYOL Training Loss = 0.1887054741382599
31-01-2023 12:14:09 INFO Epoch 4: [6678/10940] ---- BYOL Training Loss = 0.21716973185539246
31-01-2023 12:14:27 INFO Epoch 4: [6689/10940] ---- BYOL Training Loss = 0.28657177090644836
31-01-2023 12:15:19 INFO Epoch 4: [6689/10940] ---- BYOL Validation Loss = 0.18176594376564026
31-01-2023 12:15:37 INFO Epoch 4: [6700/10940] ---- BYOL Training Loss = 0.2645362615585327
31-01-2023 12:15:55 INFO Epoch 4: [6711/10940] ---- BYOL Training Loss = 0.2565479278564453
31-01-2023 12:16:14 INFO Epoch 4: [6722/10940] ---- BYOL Training Loss = 0.23811261355876923
31-01-2023 12:16:32 INFO Epoch 4: [6733/10940] ---- BYOL Training Loss = 0.24388650059700012
31-01-2023 12:17:24 INFO Epoch 4: [6733/10940] ---- BYOL Validation Loss = 0.18779578804969788
31-01-2023 12:17:42 INFO Epoch 4: [6744/10940] ---- BYOL Training Loss = 0.2659371495246887
31-01-2023 12:18:00 INFO Epoch 4: [6755/10940] ---- BYOL Training Loss = 0.23829162120819092
31-01-2023 12:18:18 INFO Epoch 4: [6766/10940] ---- BYOL Training Loss = 0.2184453010559082
31-01-2023 12:18:36 INFO Epoch 4: [6777/10940] ---- BYOL Training Loss = 0.2231188267469406
31-01-2023 12:19:29 INFO Epoch 4: [6777/10940] ---- BYOL Validation Loss = 0.18990816175937653
31-01-2023 12:19:46 INFO Epoch 4: [6788/10940] ---- BYOL Training Loss = 0.23104126751422882
31-01-2023 12:20:05 INFO Epoch 4: [6799/10940] ---- BYOL Training Loss = 0.26202571392059326
31-01-2023 12:20:23 INFO Epoch 4: [6810/10940] ---- BYOL Training Loss = 0.29288482666015625
31-01-2023 12:20:41 INFO Epoch 4: [6821/10940] ---- BYOL Training Loss = 0.25203171372413635
31-01-2023 12:21:33 INFO Epoch 4: [6821/10940] ---- BYOL Validation Loss = 0.17879463732242584
31-01-2023 12:21:51 INFO Epoch 4: [6832/10940] ---- BYOL Training Loss = 0.2005826234817505
31-01-2023 12:22:10 INFO Epoch 4: [6843/10940] ---- BYOL Training Loss = 0.22398439049720764
31-01-2023 12:22:28 INFO Epoch 4: [6854/10940] ---- BYOL Training Loss = 0.21221891045570374
31-01-2023 12:22:46 INFO Epoch 4: [6865/10940] ---- BYOL Training Loss = 0.27297598123550415
31-01-2023 12:23:38 INFO Epoch 4: [6865/10940] ---- BYOL Validation Loss = 0.1809641271829605
31-01-2023 12:23:56 INFO Epoch 4: [6876/10940] ---- BYOL Training Loss = 0.28998711705207825
31-01-2023 12:24:14 INFO Epoch 4: [6887/10940] ---- BYOL Training Loss = 0.2494121491909027
31-01-2023 12:24:32 INFO Epoch 4: [6898/10940] ---- BYOL Training Loss = 0.20341666042804718
31-01-2023 12:24:51 INFO Epoch 4: [6909/10940] ---- BYOL Training Loss = 0.18979093432426453
31-01-2023 12:25:43 INFO Epoch 4: [6909/10940] ---- BYOL Validation Loss = 0.1673179715871811
31-01-2023 12:26:01 INFO Epoch 4: [6920/10940] ---- BYOL Training Loss = 0.25224047899246216
31-01-2023 12:26:19 INFO Epoch 4: [6931/10940] ---- BYOL Training Loss = 0.28983253240585327
31-01-2023 12:26:37 INFO Epoch 4: [6942/10940] ---- BYOL Training Loss = 0.2256881445646286
31-01-2023 12:26:56 INFO Epoch 4: [6953/10940] ---- BYOL Training Loss = 0.25615349411964417
31-01-2023 12:27:48 INFO Epoch 4: [6953/10940] ---- BYOL Validation Loss = 0.1896364390850067
31-01-2023 12:28:06 INFO Epoch 4: [6964/10940] ---- BYOL Training Loss = 0.28912079334259033
31-01-2023 12:28:24 INFO Epoch 4: [6975/10940] ---- BYOL Training Loss = 0.23726117610931396
31-01-2023 12:28:42 INFO Epoch 4: [6986/10940] ---- BYOL Training Loss = 0.27114981412887573
31-01-2023 12:29:01 INFO Epoch 4: [6997/10940] ---- BYOL Training Loss = 0.267723023891449
31-01-2023 12:29:53 INFO Epoch 4: [6997/10940] ---- BYOL Validation Loss = 0.22021031379699707
31-01-2023 12:30:11 INFO Epoch 4: [7008/10940] ---- BYOL Training Loss = 0.2243715077638626
31-01-2023 12:30:29 INFO Epoch 4: [7019/10940] ---- BYOL Training Loss = 0.1931060254573822
31-01-2023 12:30:47 INFO Epoch 4: [7030/10940] ---- BYOL Training Loss = 0.1893227994441986
31-01-2023 12:31:05 INFO Epoch 4: [7041/10940] ---- BYOL Training Loss = 0.19732457399368286
31-01-2023 12:31:58 INFO Epoch 4: [7041/10940] ---- BYOL Validation Loss = 0.19123849272727966
31-01-2023 12:32:15 INFO Epoch 4: [7052/10940] ---- BYOL Training Loss = 0.28265470266342163
31-01-2023 12:32:34 INFO Epoch 4: [7063/10940] ---- BYOL Training Loss = 0.2893502414226532
31-01-2023 12:32:52 INFO Epoch 4: [7074/10940] ---- BYOL Training Loss = 0.18777063488960266
31-01-2023 12:33:10 INFO Epoch 4: [7085/10940] ---- BYOL Training Loss = 0.2122236043214798
31-01-2023 12:34:03 INFO Epoch 4: [7085/10940] ---- BYOL Validation Loss = 0.20552396774291992
31-01-2023 12:34:21 INFO Epoch 4: [7096/10940] ---- BYOL Training Loss = 0.2382661998271942
31-01-2023 12:34:39 INFO Epoch 4: [7107/10940] ---- BYOL Training Loss = 0.2556200325489044
31-01-2023 12:34:57 INFO Epoch 4: [7118/10940] ---- BYOL Training Loss = 0.25824153423309326
31-01-2023 12:35:15 INFO Epoch 4: [7129/10940] ---- BYOL Training Loss = 0.24324360489845276
31-01-2023 12:36:08 INFO Epoch 4: [7129/10940] ---- BYOL Validation Loss = 0.2066330909729004
31-01-2023 12:36:25 INFO Epoch 4: [7140/10940] ---- BYOL Training Loss = 0.19091437757015228
31-01-2023 12:36:44 INFO Epoch 4: [7151/10940] ---- BYOL Training Loss = 0.16581407189369202
31-01-2023 12:37:02 INFO Epoch 4: [7162/10940] ---- BYOL Training Loss = 0.25341522693634033
31-01-2023 12:37:20 INFO Epoch 4: [7173/10940] ---- BYOL Training Loss = 0.27852874994277954
31-01-2023 12:38:13 INFO Epoch 4: [7173/10940] ---- BYOL Validation Loss = 0.11768440157175064
31-01-2023 12:38:30 INFO Epoch 4: [7184/10940] ---- BYOL Training Loss = 0.25423163175582886
31-01-2023 12:38:48 INFO Epoch 4: [7195/10940] ---- BYOL Training Loss = 0.32670772075653076
31-01-2023 12:39:07 INFO Epoch 4: [7206/10940] ---- BYOL Training Loss = 0.3321411609649658
31-01-2023 12:39:25 INFO Epoch 4: [7217/10940] ---- BYOL Training Loss = 0.20339949429035187
31-01-2023 12:40:17 INFO Epoch 4: [7217/10940] ---- BYOL Validation Loss = 0.1863633096218109
31-01-2023 12:40:35 INFO Epoch 4: [7228/10940] ---- BYOL Training Loss = 0.19348911941051483
31-01-2023 12:40:54 INFO Epoch 4: [7239/10940] ---- BYOL Training Loss = 0.17580503225326538
31-01-2023 12:41:12 INFO Epoch 4: [7250/10940] ---- BYOL Training Loss = 0.1630123406648636
31-01-2023 12:41:30 INFO Epoch 4: [7261/10940] ---- BYOL Training Loss = 0.18419606983661652
31-01-2023 12:42:23 INFO Epoch 4: [7261/10940] ---- BYOL Validation Loss = 0.15507027506828308
31-01-2023 12:42:41 INFO Epoch 4: [7272/10940] ---- BYOL Training Loss = 0.2293979376554489
31-01-2023 12:42:59 INFO Epoch 4: [7283/10940] ---- BYOL Training Loss = 0.25599953532218933
31-01-2023 12:43:17 INFO Epoch 4: [7294/10940] ---- BYOL Training Loss = 0.2285277545452118
31-01-2023 12:43:35 INFO Epoch 4: [7305/10940] ---- BYOL Training Loss = 0.1714693009853363
31-01-2023 12:44:28 INFO Epoch 4: [7305/10940] ---- BYOL Validation Loss = 0.17746107280254364
31-01-2023 12:44:46 INFO Epoch 4: [7316/10940] ---- BYOL Training Loss = 0.18567867577075958
31-01-2023 12:45:04 INFO Epoch 4: [7327/10940] ---- BYOL Training Loss = 0.2335563600063324
31-01-2023 12:45:22 INFO Epoch 4: [7338/10940] ---- BYOL Training Loss = 0.19871798157691956
31-01-2023 12:45:41 INFO Epoch 4: [7349/10940] ---- BYOL Training Loss = 0.19171878695487976
31-01-2023 12:46:33 INFO Epoch 4: [7349/10940] ---- BYOL Validation Loss = 0.13176093995571136
31-01-2023 12:46:51 INFO Epoch 4: [7360/10940] ---- BYOL Training Loss = 0.17921842634677887
31-01-2023 12:47:09 INFO Epoch 4: [7371/10940] ---- BYOL Training Loss = 0.20398572087287903
31-01-2023 12:47:27 INFO Epoch 4: [7382/10940] ---- BYOL Training Loss = 0.1720767319202423
31-01-2023 12:47:46 INFO Epoch 4: [7393/10940] ---- BYOL Training Loss = 0.2505161166191101
31-01-2023 12:48:38 INFO Epoch 4: [7393/10940] ---- BYOL Validation Loss = 0.14402629435062408
31-01-2023 12:48:56 INFO Epoch 4: [7404/10940] ---- BYOL Training Loss = 0.27925390005111694
31-01-2023 12:49:14 INFO Epoch 4: [7415/10940] ---- BYOL Training Loss = 0.2280665636062622
31-01-2023 12:49:33 INFO Epoch 4: [7426/10940] ---- BYOL Training Loss = 0.21637018024921417
31-01-2023 12:49:51 INFO Epoch 4: [7437/10940] ---- BYOL Training Loss = 0.2159406691789627
31-01-2023 12:50:43 INFO Epoch 4: [7437/10940] ---- BYOL Validation Loss = 0.17193365097045898
31-01-2023 12:51:01 INFO Epoch 4: [7448/10940] ---- BYOL Training Loss = 0.19559350609779358
31-01-2023 12:51:19 INFO Epoch 4: [7459/10940] ---- BYOL Training Loss = 0.2008122205734253
31-01-2023 12:51:38 INFO Epoch 4: [7470/10940] ---- BYOL Training Loss = 0.23934271931648254
31-01-2023 12:51:56 INFO Epoch 4: [7481/10940] ---- BYOL Training Loss = 0.2520401179790497
31-01-2023 12:52:48 INFO Epoch 4: [7481/10940] ---- BYOL Validation Loss = 0.19626112282276154
31-01-2023 12:53:06 INFO Epoch 4: [7492/10940] ---- BYOL Training Loss = 0.21186205744743347
31-01-2023 12:53:25 INFO Epoch 4: [7503/10940] ---- BYOL Training Loss = 0.1980266273021698
31-01-2023 12:53:43 INFO Epoch 4: [7514/10940] ---- BYOL Training Loss = 0.19893822073936462
31-01-2023 12:54:01 INFO Epoch 4: [7525/10940] ---- BYOL Training Loss = 0.1681692898273468
31-01-2023 12:54:53 INFO Epoch 4: [7525/10940] ---- BYOL Validation Loss = 0.18819865584373474
31-01-2023 12:55:11 INFO Epoch 4: [7536/10940] ---- BYOL Training Loss = 0.16655182838439941
31-01-2023 12:55:29 INFO Epoch 4: [7547/10940] ---- BYOL Training Loss = 0.20392930507659912
31-01-2023 12:55:48 INFO Epoch 4: [7558/10940] ---- BYOL Training Loss = 0.22925320267677307
31-01-2023 12:56:06 INFO Epoch 4: [7569/10940] ---- BYOL Training Loss = 0.20600298047065735
31-01-2023 12:56:59 INFO Epoch 4: [7569/10940] ---- BYOL Validation Loss = 0.17901088297367096
31-01-2023 12:57:16 INFO Epoch 4: [7580/10940] ---- BYOL Training Loss = 0.19966426491737366
31-01-2023 12:57:35 INFO Epoch 4: [7591/10940] ---- BYOL Training Loss = 0.20910175144672394
31-01-2023 12:57:53 INFO Epoch 4: [7602/10940] ---- BYOL Training Loss = 0.22349214553833008
31-01-2023 12:58:11 INFO Epoch 4: [7613/10940] ---- BYOL Training Loss = 0.2157396823167801
31-01-2023 12:59:04 INFO Epoch 4: [7613/10940] ---- BYOL Validation Loss = 0.17663654685020447
31-01-2023 12:59:22 INFO Epoch 4: [7624/10940] ---- BYOL Training Loss = 0.15955448150634766
31-01-2023 12:59:40 INFO Epoch 4: [7635/10940] ---- BYOL Training Loss = 0.175997793674469
31-01-2023 12:59:58 INFO Epoch 4: [7646/10940] ---- BYOL Training Loss = 0.16771438717842102
31-01-2023 13:00:17 INFO Epoch 4: [7657/10940] ---- BYOL Training Loss = 0.18525578081607819
31-01-2023 13:01:09 INFO Epoch 4: [7657/10940] ---- BYOL Validation Loss = 0.14044374227523804
31-01-2023 13:01:27 INFO Epoch 4: [7668/10940] ---- BYOL Training Loss = 0.2624146342277527
31-01-2023 13:01:45 INFO Epoch 4: [7679/10940] ---- BYOL Training Loss = 0.2719065546989441
31-01-2023 13:02:04 INFO Epoch 4: [7690/10940] ---- BYOL Training Loss = 0.17678499221801758
31-01-2023 13:02:22 INFO Epoch 4: [7701/10940] ---- BYOL Training Loss = 0.22411887347698212
31-01-2023 13:03:14 INFO Epoch 4: [7701/10940] ---- BYOL Validation Loss = 0.1829952448606491
31-01-2023 13:03:32 INFO Epoch 4: [7712/10940] ---- BYOL Training Loss = 0.23464682698249817
31-01-2023 13:03:51 INFO Epoch 4: [7723/10940] ---- BYOL Training Loss = 0.19040504097938538
31-01-2023 13:04:09 INFO Epoch 4: [7734/10940] ---- BYOL Training Loss = 0.20221085846424103
31-01-2023 13:04:27 INFO Epoch 4: [7745/10940] ---- BYOL Training Loss = 0.24504037201404572
31-01-2023 13:05:19 INFO Epoch 4: [7745/10940] ---- BYOL Validation Loss = 0.18293079733848572
31-01-2023 13:05:38 INFO Epoch 4: [7756/10940] ---- BYOL Training Loss = 0.24793727695941925
31-01-2023 13:05:56 INFO Epoch 4: [7767/10940] ---- BYOL Training Loss = 0.241122767329216
31-01-2023 13:06:14 INFO Epoch 4: [7778/10940] ---- BYOL Training Loss = 0.1882895529270172
31-01-2023 13:06:32 INFO Epoch 4: [7789/10940] ---- BYOL Training Loss = 0.2234572470188141
31-01-2023 13:07:25 INFO Epoch 4: [7789/10940] ---- BYOL Validation Loss = 0.20450447499752045
31-01-2023 13:07:43 INFO Epoch 4: [7800/10940] ---- BYOL Training Loss = 0.23108430206775665
31-01-2023 13:08:01 INFO Epoch 4: [7811/10940] ---- BYOL Training Loss = 0.20996157824993134
31-01-2023 13:08:19 INFO Epoch 4: [7822/10940] ---- BYOL Training Loss = 0.21491961181163788
31-01-2023 13:08:37 INFO Epoch 4: [7833/10940] ---- BYOL Training Loss = 0.21702928841114044
31-01-2023 13:09:30 INFO Epoch 4: [7833/10940] ---- BYOL Validation Loss = 0.1888590157032013
31-01-2023 13:09:48 INFO Epoch 4: [7844/10940] ---- BYOL Training Loss = 0.22582855820655823
31-01-2023 13:10:06 INFO Epoch 4: [7855/10940] ---- BYOL Training Loss = 0.21481037139892578
31-01-2023 13:10:24 INFO Epoch 4: [7866/10940] ---- BYOL Training Loss = 0.18461322784423828
31-01-2023 13:10:42 INFO Epoch 4: [7877/10940] ---- BYOL Training Loss = 0.23566651344299316
31-01-2023 13:11:35 INFO Epoch 4: [7877/10940] ---- BYOL Validation Loss = 0.18985922634601593
31-01-2023 13:11:53 INFO Epoch 4: [7888/10940] ---- BYOL Training Loss = 0.26335257291793823
31-01-2023 13:12:11 INFO Epoch 4: [7899/10940] ---- BYOL Training Loss = 0.20852622389793396
31-01-2023 13:12:29 INFO Epoch 4: [7910/10940] ---- BYOL Training Loss = 0.2549261152744293
31-01-2023 13:12:48 INFO Epoch 4: [7921/10940] ---- BYOL Training Loss = 0.2766801714897156
31-01-2023 13:13:40 INFO Epoch 4: [7921/10940] ---- BYOL Validation Loss = 0.15239927172660828
31-01-2023 13:13:58 INFO Epoch 4: [7932/10940] ---- BYOL Training Loss = 0.23513250052928925
31-01-2023 13:14:16 INFO Epoch 4: [7943/10940] ---- BYOL Training Loss = 0.2091609686613083
31-01-2023 13:14:35 INFO Epoch 4: [7954/10940] ---- BYOL Training Loss = 0.20854654908180237
31-01-2023 13:14:53 INFO Epoch 4: [7965/10940] ---- BYOL Training Loss = 0.22752745449543
31-01-2023 13:15:45 INFO Epoch 4: [7965/10940] ---- BYOL Validation Loss = 0.1897214949131012
31-01-2023 13:16:03 INFO Epoch 4: [7976/10940] ---- BYOL Training Loss = 0.22352921962738037
31-01-2023 13:16:22 INFO Epoch 4: [7987/10940] ---- BYOL Training Loss = 0.2217755764722824
31-01-2023 13:16:40 INFO Epoch 4: [7998/10940] ---- BYOL Training Loss = 0.20445410907268524
31-01-2023 13:16:58 INFO Epoch 4: [8009/10940] ---- BYOL Training Loss = 0.20177380740642548
31-01-2023 13:17:50 INFO Epoch 4: [8009/10940] ---- BYOL Validation Loss = 0.1604859083890915
31-01-2023 13:18:09 INFO Epoch 4: [8020/10940] ---- BYOL Training Loss = 0.2074785679578781
31-01-2023 13:18:27 INFO Epoch 4: [8031/10940] ---- BYOL Training Loss = 0.20727849006652832
31-01-2023 13:18:45 INFO Epoch 4: [8042/10940] ---- BYOL Training Loss = 0.20273089408874512
31-01-2023 13:19:03 INFO Epoch 4: [8053/10940] ---- BYOL Training Loss = 0.19520387053489685
31-01-2023 13:19:56 INFO Epoch 4: [8053/10940] ---- BYOL Validation Loss = 0.1362808644771576
31-01-2023 13:20:14 INFO Epoch 4: [8064/10940] ---- BYOL Training Loss = 0.23313891887664795
slurmstepd-landonia23: error: *** JOB 1507981 ON landonia23 CANCELLED AT 2023-01-31T13:20:15 DUE TO TIME LIMIT ***
