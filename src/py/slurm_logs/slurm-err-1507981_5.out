29-01-2023 21:31:02 INFO Running main & importing modules...
29-01-2023 21:31:18 INFO Parsed arguments: Namespace(batch_size=32, byol_ema_tau=0.99, debug=False, encoder='resnet34', encoder_layer_idx=-2, epochs=5, experiment_name='b-presnet34-e5-b32-t0_99-p64', input='/disk/scratch_big/s1908368/data', log_interval=1000, lr=0.001, output='/disk/scratch_big/s1908368/output', patch_size=64, pretrain_encoder=True, seed=23, simclr_tau=0.99, train_proportion=0.98, use_byol=True)
29-01-2023 21:31:18 INFO File at /disk/scratch_big/s1908368/data/patch_train_dataset_64.pk: True
29-01-2023 21:31:18 INFO File at /disk/scratch_big/s1908368/data/patch_val_dataset_64.pk: True
29-01-2023 21:31:27 INFO Generated training dataset with 350062 samples.
29-01-2023 21:31:27 INFO Generated validation dataset with 7145 samples.
Downloading: "https://download.pytorch.org/models/resnet34-b627a593.pth" to /home/s1908368/.cache/torch/hub/checkpoints/resnet34-b627a593.pth
  0%|          | 0.00/83.3M [00:00<?, ?B/s]  5%|▍         | 4.01M/83.3M [00:00<00:01, 42.0MB/s] 11%|█▏        | 9.42M/83.3M [00:00<00:01, 50.7MB/s] 18%|█▊        | 15.3M/83.3M [00:00<00:01, 54.5MB/s] 26%|██▌       | 21.3M/83.3M [00:00<00:01, 56.2MB/s] 32%|███▏      | 27.0M/83.3M [00:00<00:01, 57.6MB/s] 39%|███▉      | 32.5M/83.3M [00:00<00:00, 57.2MB/s] 46%|████▌     | 38.4M/83.3M [00:00<00:00, 58.8MB/s] 53%|█████▎    | 44.0M/83.3M [00:00<00:00, 58.7MB/s] 60%|█████▉    | 49.6M/83.3M [00:00<00:00, 51.5MB/s] 67%|██████▋   | 55.9M/83.3M [00:01<00:00, 55.0MB/s] 74%|███████▎  | 61.4M/83.3M [00:01<00:00, 55.6MB/s] 81%|████████  | 67.1M/83.3M [00:01<00:00, 56.7MB/s] 87%|████████▋ | 72.5M/83.3M [00:01<00:00, 56.9MB/s] 94%|█████████▎| 78.0M/83.3M [00:01<00:00, 56.9MB/s]100%|██████████| 83.3M/83.3M [00:01<00:00, 55.9MB/s]
29-01-2023 21:31:34 INFO Using encoder resnet34 with pretrained weights = True
29-01-2023 21:31:35 INFO Using BYOL with tau = 0.99, with encoder layer index = -2
29-01-2023 21:31:35 INFO Using device: cuda
29-01-2023 21:31:38 INFO Starting Epoch: 1
29-01-2023 21:32:06 INFO Epoch 1: [12/10940] ---- BYOL Training Loss = 2.020303249359131
29-01-2023 21:32:33 INFO Epoch 1: [23/10940] ---- BYOL Training Loss = 1.670899748802185
29-01-2023 21:33:00 INFO Epoch 1: [34/10940] ---- BYOL Training Loss = 1.5430127382278442
29-01-2023 21:33:27 INFO Epoch 1: [45/10940] ---- BYOL Training Loss = 1.382337212562561
29-01-2023 21:34:55 INFO Epoch 1: [45/10940] ---- BYOL Validation Loss = 1.4893014430999756
29-01-2023 21:35:22 INFO Epoch 1: [56/10940] ---- BYOL Training Loss = 1.2338200807571411
29-01-2023 21:35:50 INFO Epoch 1: [67/10940] ---- BYOL Training Loss = 1.1686427593231201
29-01-2023 21:36:17 INFO Epoch 1: [78/10940] ---- BYOL Training Loss = 1.0731106996536255
29-01-2023 21:36:44 INFO Epoch 1: [89/10940] ---- BYOL Training Loss = 1.0061759948730469
29-01-2023 21:38:12 INFO Epoch 1: [89/10940] ---- BYOL Validation Loss = 1.0333160161972046
29-01-2023 21:38:40 INFO Epoch 1: [100/10940] ---- BYOL Training Loss = 0.9687415957450867
29-01-2023 21:39:07 INFO Epoch 1: [111/10940] ---- BYOL Training Loss = 0.8832204937934875
29-01-2023 21:39:35 INFO Epoch 1: [122/10940] ---- BYOL Training Loss = 0.8114118576049805
29-01-2023 21:40:02 INFO Epoch 1: [133/10940] ---- BYOL Training Loss = 0.7434061765670776
29-01-2023 21:41:30 INFO Epoch 1: [133/10940] ---- BYOL Validation Loss = 0.8045403361320496
29-01-2023 21:41:58 INFO Epoch 1: [144/10940] ---- BYOL Training Loss = 0.7234949469566345
29-01-2023 21:42:25 INFO Epoch 1: [155/10940] ---- BYOL Training Loss = 0.752840518951416
29-01-2023 21:42:53 INFO Epoch 1: [166/10940] ---- BYOL Training Loss = 0.7097095251083374
29-01-2023 21:43:20 INFO Epoch 1: [177/10940] ---- BYOL Training Loss = 0.6519280076026917
29-01-2023 21:44:48 INFO Epoch 1: [177/10940] ---- BYOL Validation Loss = 0.7169575095176697
29-01-2023 21:45:16 INFO Epoch 1: [188/10940] ---- BYOL Training Loss = 0.6472891569137573
29-01-2023 21:45:43 INFO Epoch 1: [199/10940] ---- BYOL Training Loss = 0.5978744626045227
29-01-2023 21:46:10 INFO Epoch 1: [210/10940] ---- BYOL Training Loss = 0.653539776802063
29-01-2023 21:46:38 INFO Epoch 1: [221/10940] ---- BYOL Training Loss = 0.656387448310852
29-01-2023 21:48:06 INFO Epoch 1: [221/10940] ---- BYOL Validation Loss = 0.5985680818557739
29-01-2023 21:48:33 INFO Epoch 1: [232/10940] ---- BYOL Training Loss = 0.5742591023445129
29-01-2023 21:49:01 INFO Epoch 1: [243/10940] ---- BYOL Training Loss = 0.5500671863555908
29-01-2023 21:49:28 INFO Epoch 1: [254/10940] ---- BYOL Training Loss = 0.5779033303260803
29-01-2023 21:49:56 INFO Epoch 1: [265/10940] ---- BYOL Training Loss = 0.6663986444473267
29-01-2023 21:51:24 INFO Epoch 1: [265/10940] ---- BYOL Validation Loss = 0.5863770246505737
29-01-2023 21:51:51 INFO Epoch 1: [276/10940] ---- BYOL Training Loss = 0.6567376255989075
29-01-2023 21:52:18 INFO Epoch 1: [287/10940] ---- BYOL Training Loss = 0.6714438796043396
29-01-2023 21:52:46 INFO Epoch 1: [298/10940] ---- BYOL Training Loss = 0.6940599679946899
29-01-2023 21:53:13 INFO Epoch 1: [309/10940] ---- BYOL Training Loss = 0.6129812598228455
29-01-2023 21:54:41 INFO Epoch 1: [309/10940] ---- BYOL Validation Loss = 0.5592783093452454
29-01-2023 21:55:09 INFO Epoch 1: [320/10940] ---- BYOL Training Loss = 0.5920631885528564
29-01-2023 21:55:36 INFO Epoch 1: [331/10940] ---- BYOL Training Loss = 0.5111289620399475
29-01-2023 21:56:04 INFO Epoch 1: [342/10940] ---- BYOL Training Loss = 0.48836079239845276
29-01-2023 21:56:31 INFO Epoch 1: [353/10940] ---- BYOL Training Loss = 0.5327812433242798
29-01-2023 21:57:59 INFO Epoch 1: [353/10940] ---- BYOL Validation Loss = 0.5099876523017883
29-01-2023 21:58:27 INFO Epoch 1: [364/10940] ---- BYOL Training Loss = 0.5956131219863892
29-01-2023 21:58:54 INFO Epoch 1: [375/10940] ---- BYOL Training Loss = 0.555303692817688
29-01-2023 21:59:21 INFO Epoch 1: [386/10940] ---- BYOL Training Loss = 0.5045894384384155
29-01-2023 21:59:49 INFO Epoch 1: [397/10940] ---- BYOL Training Loss = 0.5419910550117493
29-01-2023 22:01:17 INFO Epoch 1: [397/10940] ---- BYOL Validation Loss = 0.4838273823261261
29-01-2023 22:01:44 INFO Epoch 1: [408/10940] ---- BYOL Training Loss = 0.5326504707336426
29-01-2023 22:02:12 INFO Epoch 1: [419/10940] ---- BYOL Training Loss = 0.4725002348423004
29-01-2023 22:02:39 INFO Epoch 1: [430/10940] ---- BYOL Training Loss = 0.4699246287345886
29-01-2023 22:03:07 INFO Epoch 1: [441/10940] ---- BYOL Training Loss = 0.44204211235046387
29-01-2023 22:04:34 INFO Epoch 1: [441/10940] ---- BYOL Validation Loss = 0.45695167779922485
29-01-2023 22:05:02 INFO Epoch 1: [452/10940] ---- BYOL Training Loss = 0.49411171674728394
29-01-2023 22:05:29 INFO Epoch 1: [463/10940] ---- BYOL Training Loss = 0.5276806950569153
29-01-2023 22:05:57 INFO Epoch 1: [474/10940] ---- BYOL Training Loss = 0.46062198281288147
29-01-2023 22:06:25 INFO Epoch 1: [485/10940] ---- BYOL Training Loss = 0.41563719511032104
29-01-2023 22:07:53 INFO Epoch 1: [485/10940] ---- BYOL Validation Loss = 0.44182783365249634
29-01-2023 22:08:21 INFO Epoch 1: [496/10940] ---- BYOL Training Loss = 0.40995439887046814
29-01-2023 22:08:48 INFO Epoch 1: [507/10940] ---- BYOL Training Loss = 0.4330601096153259
29-01-2023 22:09:16 INFO Epoch 1: [518/10940] ---- BYOL Training Loss = 0.45056208968162537
29-01-2023 22:09:43 INFO Epoch 1: [529/10940] ---- BYOL Training Loss = 0.4756471514701843
29-01-2023 22:11:11 INFO Epoch 1: [529/10940] ---- BYOL Validation Loss = 0.44277042150497437
29-01-2023 22:11:38 INFO Epoch 1: [540/10940] ---- BYOL Training Loss = 0.45377999544143677
29-01-2023 22:12:06 INFO Epoch 1: [551/10940] ---- BYOL Training Loss = 0.38957494497299194
29-01-2023 22:12:34 INFO Epoch 1: [562/10940] ---- BYOL Training Loss = 0.4083053469657898
29-01-2023 22:13:01 INFO Epoch 1: [573/10940] ---- BYOL Training Loss = 0.4239234924316406
29-01-2023 22:14:29 INFO Epoch 1: [573/10940] ---- BYOL Validation Loss = 0.41420361399650574
29-01-2023 22:14:57 INFO Epoch 1: [584/10940] ---- BYOL Training Loss = 0.4251640737056732
29-01-2023 22:15:25 INFO Epoch 1: [595/10940] ---- BYOL Training Loss = 0.44033747911453247
29-01-2023 22:15:52 INFO Epoch 1: [606/10940] ---- BYOL Training Loss = 0.3985902667045593
29-01-2023 22:16:20 INFO Epoch 1: [617/10940] ---- BYOL Training Loss = 0.3769068121910095
29-01-2023 22:17:48 INFO Epoch 1: [617/10940] ---- BYOL Validation Loss = 0.41106006503105164
29-01-2023 22:18:16 INFO Epoch 1: [628/10940] ---- BYOL Training Loss = 0.3583313822746277
29-01-2023 22:18:43 INFO Epoch 1: [639/10940] ---- BYOL Training Loss = 0.44665661454200745
29-01-2023 22:19:11 INFO Epoch 1: [650/10940] ---- BYOL Training Loss = 0.42037877440452576
29-01-2023 22:19:38 INFO Epoch 1: [661/10940] ---- BYOL Training Loss = 0.39790791273117065
29-01-2023 22:21:06 INFO Epoch 1: [661/10940] ---- BYOL Validation Loss = 0.4082368314266205
29-01-2023 22:21:34 INFO Epoch 1: [672/10940] ---- BYOL Training Loss = 0.38841697573661804
29-01-2023 22:22:01 INFO Epoch 1: [683/10940] ---- BYOL Training Loss = 0.3743029236793518
29-01-2023 22:22:29 INFO Epoch 1: [694/10940] ---- BYOL Training Loss = 0.3991667330265045
29-01-2023 22:22:56 INFO Epoch 1: [705/10940] ---- BYOL Training Loss = 0.395379900932312
29-01-2023 22:24:24 INFO Epoch 1: [705/10940] ---- BYOL Validation Loss = 0.3925115168094635
29-01-2023 22:24:51 INFO Epoch 1: [716/10940] ---- BYOL Training Loss = 0.418826162815094
29-01-2023 22:25:19 INFO Epoch 1: [727/10940] ---- BYOL Training Loss = 0.4436250329017639
29-01-2023 22:25:47 INFO Epoch 1: [738/10940] ---- BYOL Training Loss = 0.4136630594730377
29-01-2023 22:26:14 INFO Epoch 1: [749/10940] ---- BYOL Training Loss = 0.3802068829536438
29-01-2023 22:27:42 INFO Epoch 1: [749/10940] ---- BYOL Validation Loss = 0.3901125490665436
29-01-2023 22:28:11 INFO Epoch 1: [760/10940] ---- BYOL Training Loss = 0.34707289934158325
29-01-2023 22:28:38 INFO Epoch 1: [771/10940] ---- BYOL Training Loss = 0.3448556065559387
29-01-2023 22:29:06 INFO Epoch 1: [782/10940] ---- BYOL Training Loss = 0.4352172911167145
29-01-2023 22:29:33 INFO Epoch 1: [793/10940] ---- BYOL Training Loss = 0.3889875113964081
29-01-2023 22:31:01 INFO Epoch 1: [793/10940] ---- BYOL Validation Loss = 0.3958571255207062
29-01-2023 22:31:29 INFO Epoch 1: [804/10940] ---- BYOL Training Loss = 0.36200374364852905
29-01-2023 22:31:56 INFO Epoch 1: [815/10940] ---- BYOL Training Loss = 0.3570777177810669
29-01-2023 22:32:24 INFO Epoch 1: [826/10940] ---- BYOL Training Loss = 0.35698848962783813
29-01-2023 22:32:52 INFO Epoch 1: [837/10940] ---- BYOL Training Loss = 0.44100484251976013
29-01-2023 22:34:19 INFO Epoch 1: [837/10940] ---- BYOL Validation Loss = 0.41170448064804077
29-01-2023 22:34:47 INFO Epoch 1: [848/10940] ---- BYOL Training Loss = 0.5027028322219849
29-01-2023 22:35:15 INFO Epoch 1: [859/10940] ---- BYOL Training Loss = 0.4257968068122864
29-01-2023 22:35:42 INFO Epoch 1: [870/10940] ---- BYOL Training Loss = 0.3865554630756378
29-01-2023 22:36:10 INFO Epoch 1: [881/10940] ---- BYOL Training Loss = 0.38970351219177246
29-01-2023 22:37:37 INFO Epoch 1: [881/10940] ---- BYOL Validation Loss = 0.39214807748794556
29-01-2023 22:38:05 INFO Epoch 1: [892/10940] ---- BYOL Training Loss = 0.38556286692619324
29-01-2023 22:38:33 INFO Epoch 1: [903/10940] ---- BYOL Training Loss = 0.41010087728500366
29-01-2023 22:39:00 INFO Epoch 1: [914/10940] ---- BYOL Training Loss = 0.4243866801261902
29-01-2023 22:39:28 INFO Epoch 1: [925/10940] ---- BYOL Training Loss = 0.44403988122940063
29-01-2023 22:40:56 INFO Epoch 1: [925/10940] ---- BYOL Validation Loss = 0.38897085189819336
29-01-2023 22:41:23 INFO Epoch 1: [936/10940] ---- BYOL Training Loss = 0.4134325087070465
29-01-2023 22:41:51 INFO Epoch 1: [947/10940] ---- BYOL Training Loss = 0.38741713762283325
29-01-2023 22:42:18 INFO Epoch 1: [958/10940] ---- BYOL Training Loss = 0.43937626481056213
29-01-2023 22:42:46 INFO Epoch 1: [969/10940] ---- BYOL Training Loss = 0.4782118797302246
29-01-2023 22:44:14 INFO Epoch 1: [969/10940] ---- BYOL Validation Loss = 0.4012986123561859
29-01-2023 22:44:41 INFO Epoch 1: [980/10940] ---- BYOL Training Loss = 0.4056485593318939
29-01-2023 22:45:09 INFO Epoch 1: [991/10940] ---- BYOL Training Loss = 0.36211806535720825
29-01-2023 22:45:36 INFO Epoch 1: [1002/10940] ---- BYOL Training Loss = 0.40146541595458984
29-01-2023 22:46:04 INFO Epoch 1: [1013/10940] ---- BYOL Training Loss = 0.4041227698326111
29-01-2023 22:47:32 INFO Epoch 1: [1013/10940] ---- BYOL Validation Loss = 0.3848526179790497
29-01-2023 22:47:59 INFO Epoch 1: [1024/10940] ---- BYOL Training Loss = 0.448937326669693
29-01-2023 22:48:27 INFO Epoch 1: [1035/10940] ---- BYOL Training Loss = 0.3825145661830902
29-01-2023 22:48:55 INFO Epoch 1: [1046/10940] ---- BYOL Training Loss = 0.36109569668769836
29-01-2023 22:49:22 INFO Epoch 1: [1057/10940] ---- BYOL Training Loss = 0.40379396080970764
29-01-2023 22:50:50 INFO Epoch 1: [1057/10940] ---- BYOL Validation Loss = 0.381016343832016
29-01-2023 22:51:18 INFO Epoch 1: [1068/10940] ---- BYOL Training Loss = 0.4147206246852875
29-01-2023 22:51:45 INFO Epoch 1: [1079/10940] ---- BYOL Training Loss = 0.38507816195487976
29-01-2023 22:52:13 INFO Epoch 1: [1090/10940] ---- BYOL Training Loss = 0.3943403661251068
29-01-2023 22:52:40 INFO Epoch 1: [1101/10940] ---- BYOL Training Loss = 0.38028424978256226
29-01-2023 22:54:08 INFO Epoch 1: [1101/10940] ---- BYOL Validation Loss = 0.37208154797554016
29-01-2023 22:54:36 INFO Epoch 1: [1112/10940] ---- BYOL Training Loss = 0.3822634816169739
29-01-2023 22:55:03 INFO Epoch 1: [1123/10940] ---- BYOL Training Loss = 0.43818992376327515
29-01-2023 22:55:31 INFO Epoch 1: [1134/10940] ---- BYOL Training Loss = 0.4826272130012512
29-01-2023 22:55:58 INFO Epoch 1: [1145/10940] ---- BYOL Training Loss = 0.46614426374435425
29-01-2023 22:57:26 INFO Epoch 1: [1145/10940] ---- BYOL Validation Loss = 0.3912177085876465
29-01-2023 22:57:54 INFO Epoch 1: [1156/10940] ---- BYOL Training Loss = 0.41271552443504333
29-01-2023 22:58:22 INFO Epoch 1: [1167/10940] ---- BYOL Training Loss = 0.37023669481277466
29-01-2023 22:58:50 INFO Epoch 1: [1178/10940] ---- BYOL Training Loss = 0.3691050708293915
29-01-2023 22:59:17 INFO Epoch 1: [1189/10940] ---- BYOL Training Loss = 0.3738400340080261
29-01-2023 23:00:45 INFO Epoch 1: [1189/10940] ---- BYOL Validation Loss = 0.3879627585411072
29-01-2023 23:01:13 INFO Epoch 1: [1200/10940] ---- BYOL Training Loss = 0.3712540566921234
29-01-2023 23:01:41 INFO Epoch 1: [1211/10940] ---- BYOL Training Loss = 0.40169113874435425
29-01-2023 23:02:08 INFO Epoch 1: [1222/10940] ---- BYOL Training Loss = 0.43808406591415405
29-01-2023 23:02:36 INFO Epoch 1: [1233/10940] ---- BYOL Training Loss = 0.453627347946167
29-01-2023 23:04:04 INFO Epoch 1: [1233/10940] ---- BYOL Validation Loss = 0.3844320476055145
29-01-2023 23:04:31 INFO Epoch 1: [1244/10940] ---- BYOL Training Loss = 0.3989033102989197
29-01-2023 23:04:59 INFO Epoch 1: [1255/10940] ---- BYOL Training Loss = 0.394517719745636
29-01-2023 23:05:27 INFO Epoch 1: [1266/10940] ---- BYOL Training Loss = 0.4414687752723694
29-01-2023 23:05:55 INFO Epoch 1: [1277/10940] ---- BYOL Training Loss = 0.41252008080482483
29-01-2023 23:07:22 INFO Epoch 1: [1277/10940] ---- BYOL Validation Loss = 0.3783234655857086
29-01-2023 23:07:50 INFO Epoch 1: [1288/10940] ---- BYOL Training Loss = 0.4019147455692291
29-01-2023 23:08:18 INFO Epoch 1: [1299/10940] ---- BYOL Training Loss = 0.35459333658218384
29-01-2023 23:08:45 INFO Epoch 1: [1310/10940] ---- BYOL Training Loss = 0.3315291106700897
29-01-2023 23:09:13 INFO Epoch 1: [1321/10940] ---- BYOL Training Loss = 0.3819393515586853
29-01-2023 23:10:41 INFO Epoch 1: [1321/10940] ---- BYOL Validation Loss = 0.3874123990535736
29-01-2023 23:11:08 INFO Epoch 1: [1332/10940] ---- BYOL Training Loss = 0.36314573884010315
29-01-2023 23:11:36 INFO Epoch 1: [1343/10940] ---- BYOL Training Loss = 0.32630544900894165
29-01-2023 23:12:03 INFO Epoch 1: [1354/10940] ---- BYOL Training Loss = 0.3782237768173218
29-01-2023 23:12:31 INFO Epoch 1: [1365/10940] ---- BYOL Training Loss = 0.4178241193294525
29-01-2023 23:13:59 INFO Epoch 1: [1365/10940] ---- BYOL Validation Loss = 0.39801231026649475
29-01-2023 23:14:26 INFO Epoch 1: [1376/10940] ---- BYOL Training Loss = 0.4074115753173828
29-01-2023 23:14:54 INFO Epoch 1: [1387/10940] ---- BYOL Training Loss = 0.41010934114456177
29-01-2023 23:15:22 INFO Epoch 1: [1398/10940] ---- BYOL Training Loss = 0.390781432390213
29-01-2023 23:15:49 INFO Epoch 1: [1409/10940] ---- BYOL Training Loss = 0.3978654742240906
29-01-2023 23:17:17 INFO Epoch 1: [1409/10940] ---- BYOL Validation Loss = 0.3696592152118683
29-01-2023 23:17:45 INFO Epoch 1: [1420/10940] ---- BYOL Training Loss = 0.3936588168144226
29-01-2023 23:18:13 INFO Epoch 1: [1431/10940] ---- BYOL Training Loss = 0.4078836441040039
29-01-2023 23:18:40 INFO Epoch 1: [1442/10940] ---- BYOL Training Loss = 0.3965194821357727
29-01-2023 23:19:08 INFO Epoch 1: [1453/10940] ---- BYOL Training Loss = 0.3626357913017273
29-01-2023 23:20:36 INFO Epoch 1: [1453/10940] ---- BYOL Validation Loss = 0.3597901165485382
29-01-2023 23:21:03 INFO Epoch 1: [1464/10940] ---- BYOL Training Loss = 0.37842032313346863
29-01-2023 23:21:31 INFO Epoch 1: [1475/10940] ---- BYOL Training Loss = 0.3953910171985626
29-01-2023 23:21:59 INFO Epoch 1: [1486/10940] ---- BYOL Training Loss = 0.3849804103374481
29-01-2023 23:22:26 INFO Epoch 1: [1497/10940] ---- BYOL Training Loss = 0.38945522904396057
29-01-2023 23:23:54 INFO Epoch 1: [1497/10940] ---- BYOL Validation Loss = 0.37503480911254883
29-01-2023 23:24:22 INFO Epoch 1: [1508/10940] ---- BYOL Training Loss = 0.3772180676460266
29-01-2023 23:24:49 INFO Epoch 1: [1519/10940] ---- BYOL Training Loss = 0.3589155673980713
29-01-2023 23:25:17 INFO Epoch 1: [1530/10940] ---- BYOL Training Loss = 0.38208460807800293
29-01-2023 23:25:45 INFO Epoch 1: [1541/10940] ---- BYOL Training Loss = 0.36841464042663574
29-01-2023 23:27:12 INFO Epoch 1: [1541/10940] ---- BYOL Validation Loss = 0.36268946528434753
29-01-2023 23:27:40 INFO Epoch 1: [1552/10940] ---- BYOL Training Loss = 0.3775564134120941
29-01-2023 23:28:08 INFO Epoch 1: [1563/10940] ---- BYOL Training Loss = 0.3860592246055603
29-01-2023 23:28:35 INFO Epoch 1: [1574/10940] ---- BYOL Training Loss = 0.3557034134864807
29-01-2023 23:29:03 INFO Epoch 1: [1585/10940] ---- BYOL Training Loss = 0.4002685546875
29-01-2023 23:30:31 INFO Epoch 1: [1585/10940] ---- BYOL Validation Loss = 0.36792054772377014
29-01-2023 23:30:58 INFO Epoch 1: [1596/10940] ---- BYOL Training Loss = 0.4059712290763855
29-01-2023 23:31:26 INFO Epoch 1: [1607/10940] ---- BYOL Training Loss = 0.3998047113418579
29-01-2023 23:31:53 INFO Epoch 1: [1618/10940] ---- BYOL Training Loss = 0.43342486023902893
29-01-2023 23:32:21 INFO Epoch 1: [1629/10940] ---- BYOL Training Loss = 0.35941725969314575
29-01-2023 23:33:49 INFO Epoch 1: [1629/10940] ---- BYOL Validation Loss = 0.3693462312221527
29-01-2023 23:34:16 INFO Epoch 1: [1640/10940] ---- BYOL Training Loss = 0.36044222116470337
29-01-2023 23:34:44 INFO Epoch 1: [1651/10940] ---- BYOL Training Loss = 0.39704135060310364
29-01-2023 23:35:11 INFO Epoch 1: [1662/10940] ---- BYOL Training Loss = 0.38337022066116333
29-01-2023 23:35:39 INFO Epoch 1: [1673/10940] ---- BYOL Training Loss = 0.3722265362739563
29-01-2023 23:37:07 INFO Epoch 1: [1673/10940] ---- BYOL Validation Loss = 0.371329128742218
29-01-2023 23:37:35 INFO Epoch 1: [1684/10940] ---- BYOL Training Loss = 0.3507157564163208
29-01-2023 23:38:02 INFO Epoch 1: [1695/10940] ---- BYOL Training Loss = 0.351229727268219
29-01-2023 23:38:30 INFO Epoch 1: [1706/10940] ---- BYOL Training Loss = 0.3825828433036804
29-01-2023 23:38:58 INFO Epoch 1: [1717/10940] ---- BYOL Training Loss = 0.3905390202999115
29-01-2023 23:40:25 INFO Epoch 1: [1717/10940] ---- BYOL Validation Loss = 0.37054723501205444
29-01-2023 23:40:53 INFO Epoch 1: [1728/10940] ---- BYOL Training Loss = 0.3899608552455902
29-01-2023 23:41:21 INFO Epoch 1: [1739/10940] ---- BYOL Training Loss = 0.38064444065093994
29-01-2023 23:41:48 INFO Epoch 1: [1750/10940] ---- BYOL Training Loss = 0.3948131799697876
29-01-2023 23:42:16 INFO Epoch 1: [1761/10940] ---- BYOL Training Loss = 0.4008511006832123
29-01-2023 23:43:44 INFO Epoch 1: [1761/10940] ---- BYOL Validation Loss = 0.4374317526817322
29-01-2023 23:44:11 INFO Epoch 1: [1772/10940] ---- BYOL Training Loss = 0.38024264574050903
29-01-2023 23:44:39 INFO Epoch 1: [1783/10940] ---- BYOL Training Loss = 0.37731823325157166
29-01-2023 23:45:07 INFO Epoch 1: [1794/10940] ---- BYOL Training Loss = 0.3923947513103485
29-01-2023 23:45:35 INFO Epoch 1: [1805/10940] ---- BYOL Training Loss = 0.37864482402801514
29-01-2023 23:47:02 INFO Epoch 1: [1805/10940] ---- BYOL Validation Loss = 0.35786566138267517
29-01-2023 23:47:30 INFO Epoch 1: [1816/10940] ---- BYOL Training Loss = 0.35397079586982727
29-01-2023 23:47:58 INFO Epoch 1: [1827/10940] ---- BYOL Training Loss = 0.34805911779403687
29-01-2023 23:48:25 INFO Epoch 1: [1838/10940] ---- BYOL Training Loss = 0.35491466522216797
29-01-2023 23:48:53 INFO Epoch 1: [1849/10940] ---- BYOL Training Loss = 0.3298233449459076
29-01-2023 23:50:21 INFO Epoch 1: [1849/10940] ---- BYOL Validation Loss = 0.36229291558265686
29-01-2023 23:50:48 INFO Epoch 1: [1860/10940] ---- BYOL Training Loss = 0.3409864902496338
29-01-2023 23:51:16 INFO Epoch 1: [1871/10940] ---- BYOL Training Loss = 0.35949811339378357
29-01-2023 23:51:43 INFO Epoch 1: [1882/10940] ---- BYOL Training Loss = 0.33093565702438354
29-01-2023 23:52:11 INFO Epoch 1: [1893/10940] ---- BYOL Training Loss = 0.36043184995651245
29-01-2023 23:53:39 INFO Epoch 1: [1893/10940] ---- BYOL Validation Loss = 0.36188003420829773
29-01-2023 23:54:07 INFO Epoch 1: [1904/10940] ---- BYOL Training Loss = 0.31009870767593384
29-01-2023 23:54:34 INFO Epoch 1: [1915/10940] ---- BYOL Training Loss = 0.3212932050228119
29-01-2023 23:55:03 INFO Epoch 1: [1926/10940] ---- BYOL Training Loss = 0.3510037660598755
29-01-2023 23:55:30 INFO Epoch 1: [1937/10940] ---- BYOL Training Loss = 0.40635743737220764
29-01-2023 23:56:58 INFO Epoch 1: [1937/10940] ---- BYOL Validation Loss = 0.37442418932914734
29-01-2023 23:57:26 INFO Epoch 1: [1948/10940] ---- BYOL Training Loss = 0.3605910837650299
29-01-2023 23:57:53 INFO Epoch 1: [1959/10940] ---- BYOL Training Loss = 0.31439778208732605
29-01-2023 23:58:21 INFO Epoch 1: [1970/10940] ---- BYOL Training Loss = 0.3755366802215576
29-01-2023 23:58:49 INFO Epoch 1: [1981/10940] ---- BYOL Training Loss = 0.37620943784713745
30-01-2023 00:00:17 INFO Epoch 1: [1981/10940] ---- BYOL Validation Loss = 0.3686976432800293
30-01-2023 00:00:44 INFO Epoch 1: [1992/10940] ---- BYOL Training Loss = 0.3481808304786682
30-01-2023 00:01:12 INFO Epoch 1: [2003/10940] ---- BYOL Training Loss = 0.34263694286346436
30-01-2023 00:01:39 INFO Epoch 1: [2014/10940] ---- BYOL Training Loss = 0.3333631753921509
30-01-2023 00:02:07 INFO Epoch 1: [2025/10940] ---- BYOL Training Loss = 0.3351370096206665
30-01-2023 00:03:35 INFO Epoch 1: [2025/10940] ---- BYOL Validation Loss = 0.34801599383354187
30-01-2023 00:04:03 INFO Epoch 1: [2036/10940] ---- BYOL Training Loss = 0.3209643065929413
30-01-2023 00:04:30 INFO Epoch 1: [2047/10940] ---- BYOL Training Loss = 0.3165057897567749
30-01-2023 00:04:58 INFO Epoch 1: [2058/10940] ---- BYOL Training Loss = 0.3051394820213318
30-01-2023 00:05:26 INFO Epoch 1: [2069/10940] ---- BYOL Training Loss = 0.3157532811164856
30-01-2023 00:06:54 INFO Epoch 1: [2069/10940] ---- BYOL Validation Loss = 0.3379157483577728
30-01-2023 00:07:22 INFO Epoch 1: [2080/10940] ---- BYOL Training Loss = 0.32279616594314575
30-01-2023 00:07:50 INFO Epoch 1: [2091/10940] ---- BYOL Training Loss = 0.35150858759880066
30-01-2023 00:08:17 INFO Epoch 1: [2102/10940] ---- BYOL Training Loss = 0.35274678468704224
30-01-2023 00:08:45 INFO Epoch 1: [2113/10940] ---- BYOL Training Loss = 0.33154842257499695
30-01-2023 00:10:13 INFO Epoch 1: [2113/10940] ---- BYOL Validation Loss = 0.342386931180954
30-01-2023 00:10:41 INFO Epoch 1: [2124/10940] ---- BYOL Training Loss = 0.35574859380722046
30-01-2023 00:11:09 INFO Epoch 1: [2135/10940] ---- BYOL Training Loss = 0.36556798219680786
30-01-2023 00:11:37 INFO Epoch 1: [2146/10940] ---- BYOL Training Loss = 0.3542642593383789
30-01-2023 00:12:04 INFO Epoch 1: [2157/10940] ---- BYOL Training Loss = 0.3512921929359436
30-01-2023 00:13:32 INFO Epoch 1: [2157/10940] ---- BYOL Validation Loss = 0.3491891324520111
30-01-2023 00:14:00 INFO Epoch 1: [2168/10940] ---- BYOL Training Loss = 0.3250535726547241
30-01-2023 00:14:28 INFO Epoch 1: [2179/10940] ---- BYOL Training Loss = 0.34880393743515015
30-01-2023 00:14:56 INFO Epoch 1: [2190/10940] ---- BYOL Training Loss = 0.3583274781703949
30-01-2023 00:15:23 INFO Epoch 1: [2201/10940] ---- BYOL Training Loss = 0.3556871712207794
30-01-2023 00:16:51 INFO Epoch 1: [2201/10940] ---- BYOL Validation Loss = 0.34137266874313354
30-01-2023 00:17:19 INFO Epoch 1: [2212/10940] ---- BYOL Training Loss = 0.34738415479660034
30-01-2023 00:17:47 INFO Epoch 1: [2223/10940] ---- BYOL Training Loss = 0.3565031886100769
30-01-2023 00:18:14 INFO Epoch 1: [2234/10940] ---- BYOL Training Loss = 0.36625662446022034
30-01-2023 00:18:42 INFO Epoch 1: [2245/10940] ---- BYOL Training Loss = 0.3206671178340912
30-01-2023 00:20:10 INFO Epoch 1: [2245/10940] ---- BYOL Validation Loss = 0.3398458659648895
30-01-2023 00:20:38 INFO Epoch 1: [2256/10940] ---- BYOL Training Loss = 0.3559068441390991
30-01-2023 00:21:06 INFO Epoch 1: [2267/10940] ---- BYOL Training Loss = 0.3543696999549866
30-01-2023 00:21:33 INFO Epoch 1: [2278/10940] ---- BYOL Training Loss = 0.3329077363014221
30-01-2023 00:22:01 INFO Epoch 1: [2289/10940] ---- BYOL Training Loss = 0.33102065324783325
30-01-2023 00:23:29 INFO Epoch 1: [2289/10940] ---- BYOL Validation Loss = 0.3407922387123108
30-01-2023 00:23:56 INFO Epoch 1: [2300/10940] ---- BYOL Training Loss = 0.3935052454471588
30-01-2023 00:24:24 INFO Epoch 1: [2311/10940] ---- BYOL Training Loss = 0.37244582176208496
30-01-2023 00:24:52 INFO Epoch 1: [2322/10940] ---- BYOL Training Loss = 0.3143146336078644
30-01-2023 00:25:19 INFO Epoch 1: [2333/10940] ---- BYOL Training Loss = 0.3318304717540741
30-01-2023 00:26:47 INFO Epoch 1: [2333/10940] ---- BYOL Validation Loss = 0.3428334593772888
30-01-2023 00:27:15 INFO Epoch 1: [2344/10940] ---- BYOL Training Loss = 0.327157199382782
30-01-2023 00:27:43 INFO Epoch 1: [2355/10940] ---- BYOL Training Loss = 0.32614666223526
30-01-2023 00:28:11 INFO Epoch 1: [2366/10940] ---- BYOL Training Loss = 0.30032527446746826
30-01-2023 00:28:38 INFO Epoch 1: [2377/10940] ---- BYOL Training Loss = 0.3678896427154541
30-01-2023 00:30:06 INFO Epoch 1: [2377/10940] ---- BYOL Validation Loss = 0.3469446301460266
30-01-2023 00:30:34 INFO Epoch 1: [2388/10940] ---- BYOL Training Loss = 0.3474431335926056
30-01-2023 00:31:02 INFO Epoch 1: [2399/10940] ---- BYOL Training Loss = 0.35857275128364563
30-01-2023 00:31:29 INFO Epoch 1: [2410/10940] ---- BYOL Training Loss = 0.3673584461212158
30-01-2023 00:31:57 INFO Epoch 1: [2421/10940] ---- BYOL Training Loss = 0.3582545518875122
30-01-2023 00:33:25 INFO Epoch 1: [2421/10940] ---- BYOL Validation Loss = 0.3486590087413788
30-01-2023 00:33:53 INFO Epoch 1: [2432/10940] ---- BYOL Training Loss = 0.3560484051704407
30-01-2023 00:34:20 INFO Epoch 1: [2443/10940] ---- BYOL Training Loss = 0.35482269525527954
30-01-2023 00:34:48 INFO Epoch 1: [2454/10940] ---- BYOL Training Loss = 0.3753731846809387
30-01-2023 00:35:16 INFO Epoch 1: [2465/10940] ---- BYOL Training Loss = 0.3874450623989105
30-01-2023 00:36:44 INFO Epoch 1: [2465/10940] ---- BYOL Validation Loss = 0.34385350346565247
30-01-2023 00:37:11 INFO Epoch 1: [2476/10940] ---- BYOL Training Loss = 0.4042566418647766
30-01-2023 00:37:39 INFO Epoch 1: [2487/10940] ---- BYOL Training Loss = 0.3476715683937073
30-01-2023 00:38:07 INFO Epoch 1: [2498/10940] ---- BYOL Training Loss = 0.3242092728614807
30-01-2023 00:38:34 INFO Epoch 1: [2509/10940] ---- BYOL Training Loss = 0.32430967688560486
30-01-2023 00:40:02 INFO Epoch 1: [2509/10940] ---- BYOL Validation Loss = 0.3372556269168854
30-01-2023 00:40:30 INFO Epoch 1: [2520/10940] ---- BYOL Training Loss = 0.3562549650669098
30-01-2023 00:40:58 INFO Epoch 1: [2531/10940] ---- BYOL Training Loss = 0.3558497130870819
30-01-2023 00:41:25 INFO Epoch 1: [2542/10940] ---- BYOL Training Loss = 0.32548946142196655
30-01-2023 00:41:53 INFO Epoch 1: [2553/10940] ---- BYOL Training Loss = 0.32760733366012573
30-01-2023 00:43:21 INFO Epoch 1: [2553/10940] ---- BYOL Validation Loss = 0.3402322232723236
30-01-2023 00:43:49 INFO Epoch 1: [2564/10940] ---- BYOL Training Loss = 0.3421230912208557
30-01-2023 00:44:17 INFO Epoch 1: [2575/10940] ---- BYOL Training Loss = 0.36156898736953735
30-01-2023 00:44:44 INFO Epoch 1: [2586/10940] ---- BYOL Training Loss = 0.3233935236930847
30-01-2023 00:45:12 INFO Epoch 1: [2597/10940] ---- BYOL Training Loss = 0.33836668729782104
30-01-2023 00:46:40 INFO Epoch 1: [2597/10940] ---- BYOL Validation Loss = 0.33713001012802124
30-01-2023 00:47:08 INFO Epoch 1: [2608/10940] ---- BYOL Training Loss = 0.3608694076538086
30-01-2023 00:47:36 INFO Epoch 1: [2619/10940] ---- BYOL Training Loss = 0.35350340604782104
30-01-2023 00:48:03 INFO Epoch 1: [2630/10940] ---- BYOL Training Loss = 0.34680119156837463
30-01-2023 00:48:31 INFO Epoch 1: [2641/10940] ---- BYOL Training Loss = 0.3448140025138855
30-01-2023 00:49:59 INFO Epoch 1: [2641/10940] ---- BYOL Validation Loss = 0.3505294620990753
30-01-2023 00:50:27 INFO Epoch 1: [2652/10940] ---- BYOL Training Loss = 0.38050276041030884
30-01-2023 00:50:55 INFO Epoch 1: [2663/10940] ---- BYOL Training Loss = 0.3671444058418274
30-01-2023 00:51:23 INFO Epoch 1: [2674/10940] ---- BYOL Training Loss = 0.3712696433067322
30-01-2023 00:51:50 INFO Epoch 1: [2685/10940] ---- BYOL Training Loss = 0.35592666268348694
30-01-2023 00:53:18 INFO Epoch 1: [2685/10940] ---- BYOL Validation Loss = 0.3287588953971863
30-01-2023 00:53:46 INFO Epoch 1: [2696/10940] ---- BYOL Training Loss = 0.3718888759613037
30-01-2023 00:54:14 INFO Epoch 1: [2707/10940] ---- BYOL Training Loss = 0.3676311671733856
30-01-2023 00:54:41 INFO Epoch 1: [2718/10940] ---- BYOL Training Loss = 0.34930354356765747
30-01-2023 00:55:09 INFO Epoch 1: [2729/10940] ---- BYOL Training Loss = 0.36606839299201965
30-01-2023 00:56:37 INFO Epoch 1: [2729/10940] ---- BYOL Validation Loss = 0.33155569434165955
30-01-2023 00:57:05 INFO Epoch 1: [2740/10940] ---- BYOL Training Loss = 0.3569377660751343
30-01-2023 00:57:33 INFO Epoch 1: [2751/10940] ---- BYOL Training Loss = 0.32540783286094666
30-01-2023 00:58:01 INFO Epoch 1: [2762/10940] ---- BYOL Training Loss = 0.3300941586494446
30-01-2023 00:58:28 INFO Epoch 1: [2773/10940] ---- BYOL Training Loss = 0.3634795844554901
30-01-2023 00:59:56 INFO Epoch 1: [2773/10940] ---- BYOL Validation Loss = 0.3328741490840912
30-01-2023 01:00:24 INFO Epoch 1: [2784/10940] ---- BYOL Training Loss = 0.33559268712997437
30-01-2023 01:00:52 INFO Epoch 1: [2795/10940] ---- BYOL Training Loss = 0.30800241231918335
30-01-2023 01:01:20 INFO Epoch 1: [2806/10940] ---- BYOL Training Loss = 0.30339351296424866
30-01-2023 01:01:47 INFO Epoch 1: [2817/10940] ---- BYOL Training Loss = 0.2574586570262909
30-01-2023 01:03:15 INFO Epoch 1: [2817/10940] ---- BYOL Validation Loss = 0.33352088928222656
30-01-2023 01:03:43 INFO Epoch 1: [2828/10940] ---- BYOL Training Loss = 0.2697455585002899
30-01-2023 01:04:11 INFO Epoch 1: [2839/10940] ---- BYOL Training Loss = 0.3121277689933777
30-01-2023 01:04:39 INFO Epoch 1: [2850/10940] ---- BYOL Training Loss = 0.34741103649139404
30-01-2023 01:05:06 INFO Epoch 1: [2861/10940] ---- BYOL Training Loss = 0.3518039584159851
30-01-2023 01:06:34 INFO Epoch 1: [2861/10940] ---- BYOL Validation Loss = 0.335438996553421
30-01-2023 01:07:02 INFO Epoch 1: [2872/10940] ---- BYOL Training Loss = 0.3124710023403168
30-01-2023 01:07:30 INFO Epoch 1: [2883/10940] ---- BYOL Training Loss = 0.2980453372001648
30-01-2023 01:07:58 INFO Epoch 1: [2894/10940] ---- BYOL Training Loss = 0.3619289994239807
30-01-2023 01:08:26 INFO Epoch 1: [2905/10940] ---- BYOL Training Loss = 0.39768797159194946
30-01-2023 01:09:54 INFO Epoch 1: [2905/10940] ---- BYOL Validation Loss = 0.3291652798652649
30-01-2023 01:10:22 INFO Epoch 1: [2916/10940] ---- BYOL Training Loss = 0.3347850441932678
30-01-2023 01:10:50 INFO Epoch 1: [2927/10940] ---- BYOL Training Loss = 0.31573548913002014
30-01-2023 01:11:18 INFO Epoch 1: [2938/10940] ---- BYOL Training Loss = 0.30598771572113037
30-01-2023 01:11:46 INFO Epoch 1: [2949/10940] ---- BYOL Training Loss = 0.2941984534263611
30-01-2023 01:13:14 INFO Epoch 1: [2949/10940] ---- BYOL Validation Loss = 0.3293045461177826
30-01-2023 01:13:41 INFO Epoch 1: [2960/10940] ---- BYOL Training Loss = 0.30769991874694824
30-01-2023 01:14:09 INFO Epoch 1: [2971/10940] ---- BYOL Training Loss = 0.35546600818634033
30-01-2023 01:14:37 INFO Epoch 1: [2982/10940] ---- BYOL Training Loss = 0.3661109209060669
30-01-2023 01:15:05 INFO Epoch 1: [2993/10940] ---- BYOL Training Loss = 0.36078399419784546
30-01-2023 01:16:33 INFO Epoch 1: [2993/10940] ---- BYOL Validation Loss = 0.3271316885948181
30-01-2023 01:17:01 INFO Epoch 1: [3004/10940] ---- BYOL Training Loss = 0.3557119071483612
30-01-2023 01:17:28 INFO Epoch 1: [3015/10940] ---- BYOL Training Loss = 0.34441086649894714
30-01-2023 01:17:56 INFO Epoch 1: [3026/10940] ---- BYOL Training Loss = 0.35903388261795044
30-01-2023 01:18:24 INFO Epoch 1: [3037/10940] ---- BYOL Training Loss = 0.3828542232513428
30-01-2023 01:19:52 INFO Epoch 1: [3037/10940] ---- BYOL Validation Loss = 0.3281993865966797
30-01-2023 01:20:20 INFO Epoch 1: [3048/10940] ---- BYOL Training Loss = 0.3517405390739441
30-01-2023 01:20:48 INFO Epoch 1: [3059/10940] ---- BYOL Training Loss = 0.3269155025482178
30-01-2023 01:21:16 INFO Epoch 1: [3070/10940] ---- BYOL Training Loss = 0.32631999254226685
30-01-2023 01:21:44 INFO Epoch 1: [3081/10940] ---- BYOL Training Loss = 0.3584720492362976
30-01-2023 01:23:11 INFO Epoch 1: [3081/10940] ---- BYOL Validation Loss = 0.3295230269432068
30-01-2023 01:23:39 INFO Epoch 1: [3092/10940] ---- BYOL Training Loss = 0.3929976522922516
30-01-2023 01:24:07 INFO Epoch 1: [3103/10940] ---- BYOL Training Loss = 0.3712562918663025
30-01-2023 01:24:34 INFO Epoch 1: [3114/10940] ---- BYOL Training Loss = 0.31006374955177307
30-01-2023 01:25:02 INFO Epoch 1: [3125/10940] ---- BYOL Training Loss = 0.30297860503196716
30-01-2023 01:26:30 INFO Epoch 1: [3125/10940] ---- BYOL Validation Loss = 0.34089136123657227
30-01-2023 01:26:58 INFO Epoch 1: [3136/10940] ---- BYOL Training Loss = 0.327310174703598
30-01-2023 01:27:26 INFO Epoch 1: [3147/10940] ---- BYOL Training Loss = 0.3457326591014862
30-01-2023 01:27:54 INFO Epoch 1: [3158/10940] ---- BYOL Training Loss = 0.3383757770061493
30-01-2023 01:28:21 INFO Epoch 1: [3169/10940] ---- BYOL Training Loss = 0.34532630443573
30-01-2023 01:29:49 INFO Epoch 1: [3169/10940] ---- BYOL Validation Loss = 0.32571908831596375
30-01-2023 01:30:17 INFO Epoch 1: [3180/10940] ---- BYOL Training Loss = 0.33007189631462097
30-01-2023 01:30:45 INFO Epoch 1: [3191/10940] ---- BYOL Training Loss = 0.31708386540412903
30-01-2023 01:31:13 INFO Epoch 1: [3202/10940] ---- BYOL Training Loss = 0.35816702246665955
30-01-2023 01:31:41 INFO Epoch 1: [3213/10940] ---- BYOL Training Loss = 0.3340417742729187
30-01-2023 01:33:09 INFO Epoch 1: [3213/10940] ---- BYOL Validation Loss = 0.3246963322162628
30-01-2023 01:33:36 INFO Epoch 1: [3224/10940] ---- BYOL Training Loss = 0.3109813630580902
30-01-2023 01:34:04 INFO Epoch 1: [3235/10940] ---- BYOL Training Loss = 0.31281396746635437
30-01-2023 01:34:32 INFO Epoch 1: [3246/10940] ---- BYOL Training Loss = 0.3270464539527893
30-01-2023 01:34:59 INFO Epoch 1: [3257/10940] ---- BYOL Training Loss = 0.3203451335430145
30-01-2023 01:36:27 INFO Epoch 1: [3257/10940] ---- BYOL Validation Loss = 0.323781818151474
30-01-2023 01:36:55 INFO Epoch 1: [3268/10940] ---- BYOL Training Loss = 0.38430970907211304
30-01-2023 01:37:23 INFO Epoch 1: [3279/10940] ---- BYOL Training Loss = 0.3313179612159729
30-01-2023 01:37:51 INFO Epoch 1: [3290/10940] ---- BYOL Training Loss = 0.2881106436252594
30-01-2023 01:38:18 INFO Epoch 1: [3301/10940] ---- BYOL Training Loss = 0.32070422172546387
30-01-2023 01:39:46 INFO Epoch 1: [3301/10940] ---- BYOL Validation Loss = 0.37192249298095703
30-01-2023 01:40:14 INFO Epoch 1: [3312/10940] ---- BYOL Training Loss = 0.32123231887817383
30-01-2023 01:40:41 INFO Epoch 1: [3323/10940] ---- BYOL Training Loss = 0.3137753903865814
30-01-2023 01:41:09 INFO Epoch 1: [3334/10940] ---- BYOL Training Loss = 0.37316828966140747
30-01-2023 01:41:37 INFO Epoch 1: [3345/10940] ---- BYOL Training Loss = 0.35651206970214844
30-01-2023 01:43:05 INFO Epoch 1: [3345/10940] ---- BYOL Validation Loss = 0.330009788274765
30-01-2023 01:43:33 INFO Epoch 1: [3356/10940] ---- BYOL Training Loss = 0.3462173342704773
30-01-2023 01:44:01 INFO Epoch 1: [3367/10940] ---- BYOL Training Loss = 0.3531613349914551
30-01-2023 01:44:28 INFO Epoch 1: [3378/10940] ---- BYOL Training Loss = 0.3449762463569641
30-01-2023 01:44:56 INFO Epoch 1: [3389/10940] ---- BYOL Training Loss = 0.3035391867160797
30-01-2023 01:46:24 INFO Epoch 1: [3389/10940] ---- BYOL Validation Loss = 0.31715720891952515
30-01-2023 01:46:52 INFO Epoch 1: [3400/10940] ---- BYOL Training Loss = 0.30003154277801514
30-01-2023 01:47:20 INFO Epoch 1: [3411/10940] ---- BYOL Training Loss = 0.33962538838386536
30-01-2023 01:47:48 INFO Epoch 1: [3422/10940] ---- BYOL Training Loss = 0.32898539304733276
30-01-2023 01:48:15 INFO Epoch 1: [3433/10940] ---- BYOL Training Loss = 0.3104616105556488
30-01-2023 01:49:43 INFO Epoch 1: [3433/10940] ---- BYOL Validation Loss = 0.3100792467594147
30-01-2023 01:50:11 INFO Epoch 1: [3444/10940] ---- BYOL Training Loss = 0.34077566862106323
30-01-2023 01:50:39 INFO Epoch 1: [3455/10940] ---- BYOL Training Loss = 0.3483067452907562
30-01-2023 01:51:07 INFO Epoch 1: [3466/10940] ---- BYOL Training Loss = 0.30834484100341797
30-01-2023 01:51:35 INFO Epoch 1: [3477/10940] ---- BYOL Training Loss = 0.3291182816028595
30-01-2023 01:53:03 INFO Epoch 1: [3477/10940] ---- BYOL Validation Loss = 0.3206039369106293
30-01-2023 01:53:31 INFO Epoch 1: [3488/10940] ---- BYOL Training Loss = 0.3211621344089508
30-01-2023 01:53:58 INFO Epoch 1: [3499/10940] ---- BYOL Training Loss = 0.2948540449142456
30-01-2023 01:54:26 INFO Epoch 1: [3510/10940] ---- BYOL Training Loss = 0.31841611862182617
30-01-2023 01:54:54 INFO Epoch 1: [3521/10940] ---- BYOL Training Loss = 0.3535972833633423
30-01-2023 01:56:22 INFO Epoch 1: [3521/10940] ---- BYOL Validation Loss = 0.32198366522789
30-01-2023 01:56:49 INFO Epoch 1: [3532/10940] ---- BYOL Training Loss = 0.35737553238868713
30-01-2023 01:57:18 INFO Epoch 1: [3543/10940] ---- BYOL Training Loss = 0.35364440083503723
30-01-2023 01:57:45 INFO Epoch 1: [3554/10940] ---- BYOL Training Loss = 0.3058796525001526
30-01-2023 01:58:13 INFO Epoch 1: [3565/10940] ---- BYOL Training Loss = 0.2493802011013031
30-01-2023 01:59:41 INFO Epoch 1: [3565/10940] ---- BYOL Validation Loss = 0.3111535608768463
30-01-2023 02:00:09 INFO Epoch 1: [3576/10940] ---- BYOL Training Loss = 0.28310421109199524
30-01-2023 02:00:37 INFO Epoch 1: [3587/10940] ---- BYOL Training Loss = 0.3057231307029724
30-01-2023 02:01:06 INFO Epoch 1: [3598/10940] ---- BYOL Training Loss = 0.29127246141433716
30-01-2023 02:01:33 INFO Epoch 1: [3609/10940] ---- BYOL Training Loss = 0.3092765808105469
30-01-2023 02:03:01 INFO Epoch 1: [3609/10940] ---- BYOL Validation Loss = 0.3102245628833771
30-01-2023 02:03:29 INFO Epoch 1: [3620/10940] ---- BYOL Training Loss = 0.319661021232605
30-01-2023 02:03:57 INFO Epoch 1: [3631/10940] ---- BYOL Training Loss = 0.2825583517551422
30-01-2023 02:04:24 INFO Epoch 1: [3642/10940] ---- BYOL Training Loss = 0.32647788524627686
30-01-2023 02:04:52 INFO Epoch 1: [3653/10940] ---- BYOL Training Loss = 0.35052624344825745
30-01-2023 02:06:20 INFO Epoch 1: [3653/10940] ---- BYOL Validation Loss = 0.32544130086898804
30-01-2023 02:06:48 INFO Epoch 1: [3664/10940] ---- BYOL Training Loss = 0.32202020287513733
30-01-2023 02:07:16 INFO Epoch 1: [3675/10940] ---- BYOL Training Loss = 0.31724244356155396
30-01-2023 02:07:44 INFO Epoch 1: [3686/10940] ---- BYOL Training Loss = 0.33540913462638855
30-01-2023 02:08:11 INFO Epoch 1: [3697/10940] ---- BYOL Training Loss = 0.3284161686897278
30-01-2023 02:09:39 INFO Epoch 1: [3697/10940] ---- BYOL Validation Loss = 0.3172443211078644
30-01-2023 02:10:07 INFO Epoch 1: [3708/10940] ---- BYOL Training Loss = 0.2922046184539795
30-01-2023 02:10:35 INFO Epoch 1: [3719/10940] ---- BYOL Training Loss = 0.3137778043746948
30-01-2023 02:11:03 INFO Epoch 1: [3730/10940] ---- BYOL Training Loss = 0.3184449076652527
30-01-2023 02:11:31 INFO Epoch 1: [3741/10940] ---- BYOL Training Loss = 0.3102867603302002
30-01-2023 02:12:59 INFO Epoch 1: [3741/10940] ---- BYOL Validation Loss = 0.32218629121780396
30-01-2023 02:13:27 INFO Epoch 1: [3752/10940] ---- BYOL Training Loss = 0.30043262243270874
30-01-2023 02:13:54 INFO Epoch 1: [3763/10940] ---- BYOL Training Loss = 0.30384621024131775
30-01-2023 02:14:22 INFO Epoch 1: [3774/10940] ---- BYOL Training Loss = 0.3228396475315094
30-01-2023 02:14:50 INFO Epoch 1: [3785/10940] ---- BYOL Training Loss = 0.29154977202415466
30-01-2023 02:16:18 INFO Epoch 1: [3785/10940] ---- BYOL Validation Loss = 0.31463512778282166
30-01-2023 02:16:46 INFO Epoch 1: [3796/10940] ---- BYOL Training Loss = 0.3426051139831543
30-01-2023 02:17:14 INFO Epoch 1: [3807/10940] ---- BYOL Training Loss = 0.34241944551467896
30-01-2023 02:17:42 INFO Epoch 1: [3818/10940] ---- BYOL Training Loss = 0.327964723110199
30-01-2023 02:18:10 INFO Epoch 1: [3829/10940] ---- BYOL Training Loss = 0.3252728581428528
30-01-2023 02:19:38 INFO Epoch 1: [3829/10940] ---- BYOL Validation Loss = 0.3083849549293518
30-01-2023 02:20:06 INFO Epoch 1: [3840/10940] ---- BYOL Training Loss = 0.2988671064376831
30-01-2023 02:20:34 INFO Epoch 1: [3851/10940] ---- BYOL Training Loss = 0.3276452422142029
30-01-2023 02:21:02 INFO Epoch 1: [3862/10940] ---- BYOL Training Loss = 0.2968692481517792
30-01-2023 02:21:30 INFO Epoch 1: [3873/10940] ---- BYOL Training Loss = 0.2670621871948242
30-01-2023 02:22:58 INFO Epoch 1: [3873/10940] ---- BYOL Validation Loss = 0.3124607503414154
30-01-2023 02:23:26 INFO Epoch 1: [3884/10940] ---- BYOL Training Loss = 0.27550697326660156
30-01-2023 02:23:54 INFO Epoch 1: [3895/10940] ---- BYOL Training Loss = 0.2774394154548645
30-01-2023 02:24:21 INFO Epoch 1: [3906/10940] ---- BYOL Training Loss = 0.2721688747406006
30-01-2023 02:24:49 INFO Epoch 1: [3917/10940] ---- BYOL Training Loss = 0.289861261844635
30-01-2023 02:26:17 INFO Epoch 1: [3917/10940] ---- BYOL Validation Loss = 0.31419187784194946
30-01-2023 02:26:45 INFO Epoch 1: [3928/10940] ---- BYOL Training Loss = 0.3074878454208374
30-01-2023 02:27:13 INFO Epoch 1: [3939/10940] ---- BYOL Training Loss = 0.30356907844543457
30-01-2023 02:27:41 INFO Epoch 1: [3950/10940] ---- BYOL Training Loss = 0.31289198994636536
30-01-2023 02:28:09 INFO Epoch 1: [3961/10940] ---- BYOL Training Loss = 0.3137388527393341
30-01-2023 02:29:36 INFO Epoch 1: [3961/10940] ---- BYOL Validation Loss = 0.3117505609989166
30-01-2023 02:30:05 INFO Epoch 1: [3972/10940] ---- BYOL Training Loss = 0.2954520583152771
30-01-2023 02:30:33 INFO Epoch 1: [3983/10940] ---- BYOL Training Loss = 0.29567474126815796
30-01-2023 02:31:01 INFO Epoch 1: [3994/10940] ---- BYOL Training Loss = 0.30916792154312134
30-01-2023 02:31:29 INFO Epoch 1: [4005/10940] ---- BYOL Training Loss = 0.2941966950893402
30-01-2023 02:32:57 INFO Epoch 1: [4005/10940] ---- BYOL Validation Loss = 0.31761592626571655
30-01-2023 02:33:24 INFO Epoch 1: [4016/10940] ---- BYOL Training Loss = 0.3192327618598938
30-01-2023 02:33:52 INFO Epoch 1: [4027/10940] ---- BYOL Training Loss = 0.3450002372264862
30-01-2023 02:34:20 INFO Epoch 1: [4038/10940] ---- BYOL Training Loss = 0.3399450182914734
30-01-2023 02:34:48 INFO Epoch 1: [4049/10940] ---- BYOL Training Loss = 0.3327406048774719
30-01-2023 02:36:16 INFO Epoch 1: [4049/10940] ---- BYOL Validation Loss = 0.31765952706336975
30-01-2023 02:36:44 INFO Epoch 1: [4060/10940] ---- BYOL Training Loss = 0.3589284420013428
30-01-2023 02:37:12 INFO Epoch 1: [4071/10940] ---- BYOL Training Loss = 0.3591878116130829
30-01-2023 02:37:39 INFO Epoch 1: [4082/10940] ---- BYOL Training Loss = 0.3317812383174896
30-01-2023 02:38:07 INFO Epoch 1: [4093/10940] ---- BYOL Training Loss = 0.3431491255760193
30-01-2023 02:39:35 INFO Epoch 1: [4093/10940] ---- BYOL Validation Loss = 0.3073221743106842
30-01-2023 02:40:03 INFO Epoch 1: [4104/10940] ---- BYOL Training Loss = 0.3517516553401947
30-01-2023 02:40:31 INFO Epoch 1: [4115/10940] ---- BYOL Training Loss = 0.3894222676753998
30-01-2023 02:40:59 INFO Epoch 1: [4126/10940] ---- BYOL Training Loss = 0.33663874864578247
30-01-2023 02:41:27 INFO Epoch 1: [4137/10940] ---- BYOL Training Loss = 0.2938084900379181
30-01-2023 02:42:54 INFO Epoch 1: [4137/10940] ---- BYOL Validation Loss = 0.3078545033931732
30-01-2023 02:43:22 INFO Epoch 1: [4148/10940] ---- BYOL Training Loss = 0.2915135324001312
30-01-2023 02:43:50 INFO Epoch 1: [4159/10940] ---- BYOL Training Loss = 0.29240986704826355
30-01-2023 02:44:18 INFO Epoch 1: [4170/10940] ---- BYOL Training Loss = 0.3125448226928711
30-01-2023 02:44:46 INFO Epoch 1: [4181/10940] ---- BYOL Training Loss = 0.3128832280635834
30-01-2023 02:46:14 INFO Epoch 1: [4181/10940] ---- BYOL Validation Loss = 0.31173181533813477
30-01-2023 02:46:42 INFO Epoch 1: [4192/10940] ---- BYOL Training Loss = 0.3167180120944977
30-01-2023 02:47:09 INFO Epoch 1: [4203/10940] ---- BYOL Training Loss = 0.329591304063797
30-01-2023 02:47:37 INFO Epoch 1: [4214/10940] ---- BYOL Training Loss = 0.3227691650390625
30-01-2023 02:48:06 INFO Epoch 1: [4225/10940] ---- BYOL Training Loss = 0.3108504116535187
30-01-2023 02:49:34 INFO Epoch 1: [4225/10940] ---- BYOL Validation Loss = 0.3214602768421173
30-01-2023 02:50:01 INFO Epoch 1: [4236/10940] ---- BYOL Training Loss = 0.3028039336204529
30-01-2023 02:50:29 INFO Epoch 1: [4247/10940] ---- BYOL Training Loss = 0.2883663475513458
30-01-2023 02:50:57 INFO Epoch 1: [4258/10940] ---- BYOL Training Loss = 0.2920188009738922
30-01-2023 02:51:25 INFO Epoch 1: [4269/10940] ---- BYOL Training Loss = 0.32087525725364685
30-01-2023 02:52:53 INFO Epoch 1: [4269/10940] ---- BYOL Validation Loss = 0.3142153322696686
30-01-2023 02:53:21 INFO Epoch 1: [4280/10940] ---- BYOL Training Loss = 0.29340752959251404
30-01-2023 02:53:49 INFO Epoch 1: [4291/10940] ---- BYOL Training Loss = 0.3042564392089844
30-01-2023 02:54:17 INFO Epoch 1: [4302/10940] ---- BYOL Training Loss = 0.34702736139297485
30-01-2023 02:54:45 INFO Epoch 1: [4313/10940] ---- BYOL Training Loss = 0.36530643701553345
30-01-2023 02:56:12 INFO Epoch 1: [4313/10940] ---- BYOL Validation Loss = 0.3086206316947937
30-01-2023 02:56:40 INFO Epoch 1: [4324/10940] ---- BYOL Training Loss = 0.3535616099834442
30-01-2023 02:57:08 INFO Epoch 1: [4335/10940] ---- BYOL Training Loss = 0.35986191034317017
30-01-2023 02:57:36 INFO Epoch 1: [4346/10940] ---- BYOL Training Loss = 0.34839892387390137
30-01-2023 02:58:04 INFO Epoch 1: [4357/10940] ---- BYOL Training Loss = 0.33448055386543274
30-01-2023 02:59:32 INFO Epoch 1: [4357/10940] ---- BYOL Validation Loss = 0.3119700253009796
30-01-2023 03:00:00 INFO Epoch 1: [4368/10940] ---- BYOL Training Loss = 0.29805895686149597
30-01-2023 03:00:28 INFO Epoch 1: [4379/10940] ---- BYOL Training Loss = 0.2893370985984802
30-01-2023 03:00:56 INFO Epoch 1: [4390/10940] ---- BYOL Training Loss = 0.3395637571811676
30-01-2023 03:01:24 INFO Epoch 1: [4401/10940] ---- BYOL Training Loss = 0.33463868498802185
30-01-2023 03:02:51 INFO Epoch 1: [4401/10940] ---- BYOL Validation Loss = 0.3119641840457916
30-01-2023 03:03:19 INFO Epoch 1: [4412/10940] ---- BYOL Training Loss = 0.3120127320289612
30-01-2023 03:03:47 INFO Epoch 1: [4423/10940] ---- BYOL Training Loss = 0.28692036867141724
30-01-2023 03:04:15 INFO Epoch 1: [4434/10940] ---- BYOL Training Loss = 0.3076498806476593
30-01-2023 03:04:43 INFO Epoch 1: [4445/10940] ---- BYOL Training Loss = 0.3406502306461334
30-01-2023 03:06:11 INFO Epoch 1: [4445/10940] ---- BYOL Validation Loss = 0.31785717606544495
30-01-2023 03:06:39 INFO Epoch 1: [4456/10940] ---- BYOL Training Loss = 0.34106558561325073
30-01-2023 03:07:07 INFO Epoch 1: [4467/10940] ---- BYOL Training Loss = 0.30845877528190613
30-01-2023 03:07:34 INFO Epoch 1: [4478/10940] ---- BYOL Training Loss = 0.2670916020870209
30-01-2023 03:08:03 INFO Epoch 1: [4489/10940] ---- BYOL Training Loss = 0.2868063449859619
30-01-2023 03:09:30 INFO Epoch 1: [4489/10940] ---- BYOL Validation Loss = 0.3096533417701721
30-01-2023 03:09:58 INFO Epoch 1: [4500/10940] ---- BYOL Training Loss = 0.3014219403266907
30-01-2023 03:10:26 INFO Epoch 1: [4511/10940] ---- BYOL Training Loss = 0.3188094198703766
30-01-2023 03:10:54 INFO Epoch 1: [4522/10940] ---- BYOL Training Loss = 0.34360450506210327
30-01-2023 03:11:22 INFO Epoch 1: [4533/10940] ---- BYOL Training Loss = 0.3178078532218933
30-01-2023 03:12:50 INFO Epoch 1: [4533/10940] ---- BYOL Validation Loss = 0.32262352108955383
30-01-2023 03:13:18 INFO Epoch 1: [4544/10940] ---- BYOL Training Loss = 0.31114593148231506
30-01-2023 03:13:46 INFO Epoch 1: [4555/10940] ---- BYOL Training Loss = 0.2888355851173401
30-01-2023 03:14:14 INFO Epoch 1: [4566/10940] ---- BYOL Training Loss = 0.29237234592437744
30-01-2023 03:14:41 INFO Epoch 1: [4577/10940] ---- BYOL Training Loss = 0.30445173382759094
30-01-2023 03:16:09 INFO Epoch 1: [4577/10940] ---- BYOL Validation Loss = 0.3055507242679596
30-01-2023 03:16:37 INFO Epoch 1: [4588/10940] ---- BYOL Training Loss = 0.31657254695892334
30-01-2023 03:17:05 INFO Epoch 1: [4599/10940] ---- BYOL Training Loss = 0.2808137536048889
30-01-2023 03:17:33 INFO Epoch 1: [4610/10940] ---- BYOL Training Loss = 0.28332167863845825
30-01-2023 03:18:01 INFO Epoch 1: [4621/10940] ---- BYOL Training Loss = 0.31269314885139465
30-01-2023 03:19:29 INFO Epoch 1: [4621/10940] ---- BYOL Validation Loss = 0.3121200203895569
30-01-2023 03:19:57 INFO Epoch 1: [4632/10940] ---- BYOL Training Loss = 0.29693278670310974
30-01-2023 03:20:25 INFO Epoch 1: [4643/10940] ---- BYOL Training Loss = 0.31361880898475647
30-01-2023 03:20:53 INFO Epoch 1: [4654/10940] ---- BYOL Training Loss = 0.29904454946517944
30-01-2023 03:21:21 INFO Epoch 1: [4665/10940] ---- BYOL Training Loss = 0.3009208142757416
30-01-2023 03:22:49 INFO Epoch 1: [4665/10940] ---- BYOL Validation Loss = 0.305623322725296
30-01-2023 03:23:16 INFO Epoch 1: [4676/10940] ---- BYOL Training Loss = 0.3155835270881653
30-01-2023 03:23:44 INFO Epoch 1: [4687/10940] ---- BYOL Training Loss = 0.31150469183921814
30-01-2023 03:24:13 INFO Epoch 1: [4698/10940] ---- BYOL Training Loss = 0.2975482642650604
30-01-2023 03:24:40 INFO Epoch 1: [4709/10940] ---- BYOL Training Loss = 0.32347041368484497
30-01-2023 03:26:08 INFO Epoch 1: [4709/10940] ---- BYOL Validation Loss = 0.31293728947639465
30-01-2023 03:26:36 INFO Epoch 1: [4720/10940] ---- BYOL Training Loss = 0.3052438795566559
30-01-2023 03:27:04 INFO Epoch 1: [4731/10940] ---- BYOL Training Loss = 0.2691945433616638
30-01-2023 03:27:31 INFO Epoch 1: [4742/10940] ---- BYOL Training Loss = 0.2923583686351776
30-01-2023 03:28:00 INFO Epoch 1: [4753/10940] ---- BYOL Training Loss = 0.26236194372177124
30-01-2023 03:29:27 INFO Epoch 1: [4753/10940] ---- BYOL Validation Loss = 0.3079075217247009
30-01-2023 03:29:55 INFO Epoch 1: [4764/10940] ---- BYOL Training Loss = 0.3020363748073578
30-01-2023 03:30:23 INFO Epoch 1: [4775/10940] ---- BYOL Training Loss = 0.35358065366744995
30-01-2023 03:30:51 INFO Epoch 1: [4786/10940] ---- BYOL Training Loss = 0.3213743269443512
30-01-2023 03:31:19 INFO Epoch 1: [4797/10940] ---- BYOL Training Loss = 0.2816794216632843
30-01-2023 03:32:47 INFO Epoch 1: [4797/10940] ---- BYOL Validation Loss = 0.3090367615222931
30-01-2023 03:33:15 INFO Epoch 1: [4808/10940] ---- BYOL Training Loss = 0.27516740560531616
30-01-2023 03:33:43 INFO Epoch 1: [4819/10940] ---- BYOL Training Loss = 0.26441580057144165
30-01-2023 03:34:11 INFO Epoch 1: [4830/10940] ---- BYOL Training Loss = 0.2876967787742615
30-01-2023 03:34:39 INFO Epoch 1: [4841/10940] ---- BYOL Training Loss = 0.31419289112091064
30-01-2023 03:36:07 INFO Epoch 1: [4841/10940] ---- BYOL Validation Loss = 0.3215043246746063
30-01-2023 03:36:35 INFO Epoch 1: [4852/10940] ---- BYOL Training Loss = 0.33992305397987366
30-01-2023 03:37:03 INFO Epoch 1: [4863/10940] ---- BYOL Training Loss = 0.33749455213546753
30-01-2023 03:37:31 INFO Epoch 1: [4874/10940] ---- BYOL Training Loss = 0.33165648579597473
30-01-2023 03:37:59 INFO Epoch 1: [4885/10940] ---- BYOL Training Loss = 0.25828081369400024
30-01-2023 03:39:27 INFO Epoch 1: [4885/10940] ---- BYOL Validation Loss = 0.3022894561290741
30-01-2023 03:39:55 INFO Epoch 1: [4896/10940] ---- BYOL Training Loss = 0.2936013340950012
30-01-2023 03:40:23 INFO Epoch 1: [4907/10940] ---- BYOL Training Loss = 0.3323151171207428
30-01-2023 03:40:51 INFO Epoch 1: [4918/10940] ---- BYOL Training Loss = 0.31062737107276917
30-01-2023 03:41:19 INFO Epoch 1: [4929/10940] ---- BYOL Training Loss = 0.31547266244888306
30-01-2023 03:42:46 INFO Epoch 1: [4929/10940] ---- BYOL Validation Loss = 0.3117769658565521
30-01-2023 03:43:14 INFO Epoch 1: [4940/10940] ---- BYOL Training Loss = 0.3488360047340393
30-01-2023 03:43:42 INFO Epoch 1: [4951/10940] ---- BYOL Training Loss = 0.3206448554992676
30-01-2023 03:44:11 INFO Epoch 1: [4962/10940] ---- BYOL Training Loss = 0.32528987526893616
30-01-2023 03:44:38 INFO Epoch 1: [4973/10940] ---- BYOL Training Loss = 0.33569860458374023
30-01-2023 03:46:06 INFO Epoch 1: [4973/10940] ---- BYOL Validation Loss = 0.3137141764163971
30-01-2023 03:46:34 INFO Epoch 1: [4984/10940] ---- BYOL Training Loss = 0.32988351583480835
30-01-2023 03:47:02 INFO Epoch 1: [4995/10940] ---- BYOL Training Loss = 0.3256738781929016
30-01-2023 03:47:30 INFO Epoch 1: [5006/10940] ---- BYOL Training Loss = 0.31789347529411316
30-01-2023 03:47:58 INFO Epoch 1: [5017/10940] ---- BYOL Training Loss = 0.35060739517211914
30-01-2023 03:49:26 INFO Epoch 1: [5017/10940] ---- BYOL Validation Loss = 0.3040338158607483
30-01-2023 03:49:54 INFO Epoch 1: [5028/10940] ---- BYOL Training Loss = 0.31953755021095276
30-01-2023 03:50:22 INFO Epoch 1: [5039/10940] ---- BYOL Training Loss = 0.2554871439933777
30-01-2023 03:50:50 INFO Epoch 1: [5050/10940] ---- BYOL Training Loss = 0.2666994631290436
30-01-2023 03:51:18 INFO Epoch 1: [5061/10940] ---- BYOL Training Loss = 0.29726269841194153
30-01-2023 03:52:46 INFO Epoch 1: [5061/10940] ---- BYOL Validation Loss = 0.29525503516197205
30-01-2023 03:53:14 INFO Epoch 1: [5072/10940] ---- BYOL Training Loss = 0.2912308871746063
30-01-2023 03:53:42 INFO Epoch 1: [5083/10940] ---- BYOL Training Loss = 0.2927945554256439
30-01-2023 03:54:10 INFO Epoch 1: [5094/10940] ---- BYOL Training Loss = 0.32129552960395813
30-01-2023 03:54:38 INFO Epoch 1: [5105/10940] ---- BYOL Training Loss = 0.3277934193611145
30-01-2023 03:56:06 INFO Epoch 1: [5105/10940] ---- BYOL Validation Loss = 0.30331656336784363
30-01-2023 03:56:34 INFO Epoch 1: [5116/10940] ---- BYOL Training Loss = 0.3274407684803009
30-01-2023 03:57:02 INFO Epoch 1: [5127/10940] ---- BYOL Training Loss = 0.2879651188850403
30-01-2023 03:57:30 INFO Epoch 1: [5138/10940] ---- BYOL Training Loss = 0.28976550698280334
30-01-2023 03:57:58 INFO Epoch 1: [5149/10940] ---- BYOL Training Loss = 0.27343329787254333
30-01-2023 03:59:26 INFO Epoch 1: [5149/10940] ---- BYOL Validation Loss = 0.30578893423080444
30-01-2023 03:59:54 INFO Epoch 1: [5160/10940] ---- BYOL Training Loss = 0.28441110253334045
30-01-2023 04:00:22 INFO Epoch 1: [5171/10940] ---- BYOL Training Loss = 0.3016369938850403
30-01-2023 04:00:50 INFO Epoch 1: [5182/10940] ---- BYOL Training Loss = 0.3014894127845764
30-01-2023 04:01:18 INFO Epoch 1: [5193/10940] ---- BYOL Training Loss = 0.29625624418258667
30-01-2023 04:02:46 INFO Epoch 1: [5193/10940] ---- BYOL Validation Loss = 0.3082406222820282
30-01-2023 04:03:15 INFO Epoch 1: [5204/10940] ---- BYOL Training Loss = 0.29822367429733276
30-01-2023 04:03:43 INFO Epoch 1: [5215/10940] ---- BYOL Training Loss = 0.29050955176353455
30-01-2023 04:04:10 INFO Epoch 1: [5226/10940] ---- BYOL Training Loss = 0.3094101846218109
30-01-2023 04:04:39 INFO Epoch 1: [5237/10940] ---- BYOL Training Loss = 0.34366336464881897
30-01-2023 04:06:07 INFO Epoch 1: [5237/10940] ---- BYOL Validation Loss = 0.3080940544605255
30-01-2023 04:06:34 INFO Epoch 1: [5248/10940] ---- BYOL Training Loss = 0.341342031955719
30-01-2023 04:07:02 INFO Epoch 1: [5259/10940] ---- BYOL Training Loss = 0.32835257053375244
30-01-2023 04:07:30 INFO Epoch 1: [5270/10940] ---- BYOL Training Loss = 0.3226417899131775
30-01-2023 04:07:58 INFO Epoch 1: [5281/10940] ---- BYOL Training Loss = 0.31451064348220825
30-01-2023 04:09:26 INFO Epoch 1: [5281/10940] ---- BYOL Validation Loss = 0.30643197894096375
30-01-2023 04:09:55 INFO Epoch 1: [5292/10940] ---- BYOL Training Loss = 0.2927681505680084
30-01-2023 04:10:23 INFO Epoch 1: [5303/10940] ---- BYOL Training Loss = 0.3501144051551819
30-01-2023 04:10:51 INFO Epoch 1: [5314/10940] ---- BYOL Training Loss = 0.2909567058086395
30-01-2023 04:11:19 INFO Epoch 1: [5325/10940] ---- BYOL Training Loss = 0.2962581515312195
30-01-2023 04:12:47 INFO Epoch 1: [5325/10940] ---- BYOL Validation Loss = 0.3021155297756195
30-01-2023 04:13:15 INFO Epoch 1: [5336/10940] ---- BYOL Training Loss = 0.33285772800445557
30-01-2023 04:13:43 INFO Epoch 1: [5347/10940] ---- BYOL Training Loss = 0.2939915060997009
30-01-2023 04:14:11 INFO Epoch 1: [5358/10940] ---- BYOL Training Loss = 0.2777593731880188
30-01-2023 04:14:39 INFO Epoch 1: [5369/10940] ---- BYOL Training Loss = 0.30894795060157776
30-01-2023 04:16:07 INFO Epoch 1: [5369/10940] ---- BYOL Validation Loss = 0.31231027841567993
30-01-2023 04:16:35 INFO Epoch 1: [5380/10940] ---- BYOL Training Loss = 0.269687294960022
30-01-2023 04:17:02 INFO Epoch 1: [5391/10940] ---- BYOL Training Loss = 0.26716348528862
30-01-2023 04:17:30 INFO Epoch 1: [5402/10940] ---- BYOL Training Loss = 0.29600098729133606
30-01-2023 04:17:58 INFO Epoch 1: [5413/10940] ---- BYOL Training Loss = 0.32108038663864136
30-01-2023 04:19:26 INFO Epoch 1: [5413/10940] ---- BYOL Validation Loss = 0.30833807587623596
30-01-2023 04:19:54 INFO Epoch 1: [5424/10940] ---- BYOL Training Loss = 0.30376362800598145
30-01-2023 04:20:22 INFO Epoch 1: [5435/10940] ---- BYOL Training Loss = 0.3011109232902527
30-01-2023 04:20:50 INFO Epoch 1: [5446/10940] ---- BYOL Training Loss = 0.2982541024684906
30-01-2023 04:21:18 INFO Epoch 1: [5457/10940] ---- BYOL Training Loss = 0.3031357526779175
30-01-2023 04:22:46 INFO Epoch 1: [5457/10940] ---- BYOL Validation Loss = 0.30271878838539124
30-01-2023 04:23:14 INFO Epoch 1: [5468/10940] ---- BYOL Training Loss = 0.3627282679080963
30-01-2023 04:23:42 INFO Epoch 1: [5479/10940] ---- BYOL Training Loss = 0.35791754722595215
30-01-2023 04:24:10 INFO Epoch 1: [5490/10940] ---- BYOL Training Loss = 0.3443332612514496
30-01-2023 04:24:38 INFO Epoch 1: [5501/10940] ---- BYOL Training Loss = 0.3145579397678375
30-01-2023 04:26:06 INFO Epoch 1: [5501/10940] ---- BYOL Validation Loss = 0.31634721159935
30-01-2023 04:26:34 INFO Epoch 1: [5512/10940] ---- BYOL Training Loss = 0.3159133791923523
30-01-2023 04:27:02 INFO Epoch 1: [5523/10940] ---- BYOL Training Loss = 0.3238418698310852
30-01-2023 04:27:30 INFO Epoch 1: [5534/10940] ---- BYOL Training Loss = 0.3015971779823303
30-01-2023 04:27:59 INFO Epoch 1: [5545/10940] ---- BYOL Training Loss = 0.30968934297561646
30-01-2023 04:29:26 INFO Epoch 1: [5545/10940] ---- BYOL Validation Loss = 0.30520668625831604
30-01-2023 04:29:55 INFO Epoch 1: [5556/10940] ---- BYOL Training Loss = 0.3250933289527893
30-01-2023 04:30:23 INFO Epoch 1: [5567/10940] ---- BYOL Training Loss = 0.3033183813095093
30-01-2023 04:30:51 INFO Epoch 1: [5578/10940] ---- BYOL Training Loss = 0.31422531604766846
30-01-2023 04:31:19 INFO Epoch 1: [5589/10940] ---- BYOL Training Loss = 0.29417499899864197
30-01-2023 04:32:47 INFO Epoch 1: [5589/10940] ---- BYOL Validation Loss = 0.2996579110622406
30-01-2023 04:33:15 INFO Epoch 1: [5600/10940] ---- BYOL Training Loss = 0.3042062520980835
30-01-2023 04:33:43 INFO Epoch 1: [5611/10940] ---- BYOL Training Loss = 0.30759283900260925
30-01-2023 04:34:11 INFO Epoch 1: [5622/10940] ---- BYOL Training Loss = 0.3022821545600891
30-01-2023 04:34:39 INFO Epoch 1: [5633/10940] ---- BYOL Training Loss = 0.3418982923030853
30-01-2023 04:36:07 INFO Epoch 1: [5633/10940] ---- BYOL Validation Loss = 0.30308833718299866
30-01-2023 04:36:35 INFO Epoch 1: [5644/10940] ---- BYOL Training Loss = 0.3376643657684326
30-01-2023 04:37:03 INFO Epoch 1: [5655/10940] ---- BYOL Training Loss = 0.2841739058494568
30-01-2023 04:37:31 INFO Epoch 1: [5666/10940] ---- BYOL Training Loss = 0.2749093174934387
30-01-2023 04:37:59 INFO Epoch 1: [5677/10940] ---- BYOL Training Loss = 0.30554476380348206
30-01-2023 04:39:27 INFO Epoch 1: [5677/10940] ---- BYOL Validation Loss = 0.30832424759864807
30-01-2023 04:39:55 INFO Epoch 1: [5688/10940] ---- BYOL Training Loss = 0.31574714183807373
30-01-2023 04:40:23 INFO Epoch 1: [5699/10940] ---- BYOL Training Loss = 0.3510042130947113
30-01-2023 04:40:51 INFO Epoch 1: [5710/10940] ---- BYOL Training Loss = 0.35219866037368774
30-01-2023 04:41:20 INFO Epoch 1: [5721/10940] ---- BYOL Training Loss = 0.3452269732952118
30-01-2023 04:42:47 INFO Epoch 1: [5721/10940] ---- BYOL Validation Loss = 0.3100798726081848
30-01-2023 04:43:15 INFO Epoch 1: [5732/10940] ---- BYOL Training Loss = 0.30584198236465454
30-01-2023 04:43:43 INFO Epoch 1: [5743/10940] ---- BYOL Training Loss = 0.3295116126537323
30-01-2023 04:44:11 INFO Epoch 1: [5754/10940] ---- BYOL Training Loss = 0.3329339325428009
30-01-2023 04:44:39 INFO Epoch 1: [5765/10940] ---- BYOL Training Loss = 0.2987446188926697
30-01-2023 04:46:07 INFO Epoch 1: [5765/10940] ---- BYOL Validation Loss = 0.3049294054508209
30-01-2023 04:46:35 INFO Epoch 1: [5776/10940] ---- BYOL Training Loss = 0.30910560488700867
30-01-2023 04:47:03 INFO Epoch 1: [5787/10940] ---- BYOL Training Loss = 0.2995070815086365
30-01-2023 04:47:31 INFO Epoch 1: [5798/10940] ---- BYOL Training Loss = 0.29860204458236694
30-01-2023 04:47:59 INFO Epoch 1: [5809/10940] ---- BYOL Training Loss = 0.3211062252521515
30-01-2023 04:49:27 INFO Epoch 1: [5809/10940] ---- BYOL Validation Loss = 0.30904531478881836
30-01-2023 04:49:55 INFO Epoch 1: [5820/10940] ---- BYOL Training Loss = 0.3356413245201111
30-01-2023 04:50:23 INFO Epoch 1: [5831/10940] ---- BYOL Training Loss = 0.35233381390571594
30-01-2023 04:50:51 INFO Epoch 1: [5842/10940] ---- BYOL Training Loss = 0.32609498500823975
30-01-2023 04:51:19 INFO Epoch 1: [5853/10940] ---- BYOL Training Loss = 0.3320348560810089
30-01-2023 04:52:47 INFO Epoch 1: [5853/10940] ---- BYOL Validation Loss = 0.3095007538795471
30-01-2023 04:53:15 INFO Epoch 1: [5864/10940] ---- BYOL Training Loss = 0.372466504573822
30-01-2023 04:53:43 INFO Epoch 1: [5875/10940] ---- BYOL Training Loss = 0.3719164729118347
30-01-2023 04:54:12 INFO Epoch 1: [5886/10940] ---- BYOL Training Loss = 0.32314422726631165
30-01-2023 04:54:40 INFO Epoch 1: [5897/10940] ---- BYOL Training Loss = 0.2988036274909973
30-01-2023 04:56:07 INFO Epoch 1: [5897/10940] ---- BYOL Validation Loss = 0.3038454055786133
30-01-2023 04:56:35 INFO Epoch 1: [5908/10940] ---- BYOL Training Loss = 0.37276071310043335
30-01-2023 04:57:03 INFO Epoch 1: [5919/10940] ---- BYOL Training Loss = 0.35326099395751953
30-01-2023 04:57:32 INFO Epoch 1: [5930/10940] ---- BYOL Training Loss = 0.3155542016029358
30-01-2023 04:57:59 INFO Epoch 1: [5941/10940] ---- BYOL Training Loss = 0.3267037272453308
30-01-2023 04:59:27 INFO Epoch 1: [5941/10940] ---- BYOL Validation Loss = 0.30407264828681946
30-01-2023 04:59:55 INFO Epoch 1: [5952/10940] ---- BYOL Training Loss = 0.3042837083339691
30-01-2023 05:00:23 INFO Epoch 1: [5963/10940] ---- BYOL Training Loss = 0.3119466304779053
30-01-2023 05:00:51 INFO Epoch 1: [5974/10940] ---- BYOL Training Loss = 0.3260558545589447
30-01-2023 05:01:19 INFO Epoch 1: [5985/10940] ---- BYOL Training Loss = 0.30617374181747437
30-01-2023 05:02:47 INFO Epoch 1: [5985/10940] ---- BYOL Validation Loss = 0.30221274495124817
30-01-2023 05:03:15 INFO Epoch 1: [5996/10940] ---- BYOL Training Loss = 0.3262585997581482
30-01-2023 05:03:43 INFO Epoch 1: [6007/10940] ---- BYOL Training Loss = 0.3350830674171448
30-01-2023 05:04:11 INFO Epoch 1: [6018/10940] ---- BYOL Training Loss = 0.34545472264289856
30-01-2023 05:04:39 INFO Epoch 1: [6029/10940] ---- BYOL Training Loss = 0.32502853870391846
30-01-2023 05:06:07 INFO Epoch 1: [6029/10940] ---- BYOL Validation Loss = 0.3057915270328522
30-01-2023 05:06:35 INFO Epoch 1: [6040/10940] ---- BYOL Training Loss = 0.3154618740081787
30-01-2023 05:07:03 INFO Epoch 1: [6051/10940] ---- BYOL Training Loss = 0.2810761034488678
30-01-2023 05:07:31 INFO Epoch 1: [6062/10940] ---- BYOL Training Loss = 0.2826305031776428
30-01-2023 05:07:59 INFO Epoch 1: [6073/10940] ---- BYOL Training Loss = 0.2479696273803711
30-01-2023 05:09:27 INFO Epoch 1: [6073/10940] ---- BYOL Validation Loss = 0.2987542748451233
30-01-2023 05:09:55 INFO Epoch 1: [6084/10940] ---- BYOL Training Loss = 0.3069700300693512
30-01-2023 05:10:24 INFO Epoch 1: [6095/10940] ---- BYOL Training Loss = 0.33950498700141907
30-01-2023 05:10:52 INFO Epoch 1: [6106/10940] ---- BYOL Training Loss = 0.3019385039806366
30-01-2023 05:11:20 INFO Epoch 1: [6117/10940] ---- BYOL Training Loss = 0.280239462852478
30-01-2023 05:12:47 INFO Epoch 1: [6117/10940] ---- BYOL Validation Loss = 0.29209253191947937
30-01-2023 05:13:15 INFO Epoch 1: [6128/10940] ---- BYOL Training Loss = 0.29269343614578247
30-01-2023 05:13:44 INFO Epoch 1: [6139/10940] ---- BYOL Training Loss = 0.3133303225040436
30-01-2023 05:14:12 INFO Epoch 1: [6150/10940] ---- BYOL Training Loss = 0.28283122181892395
30-01-2023 05:14:40 INFO Epoch 1: [6161/10940] ---- BYOL Training Loss = 0.28640246391296387
30-01-2023 05:16:07 INFO Epoch 1: [6161/10940] ---- BYOL Validation Loss = 0.30250856280326843
30-01-2023 05:16:36 INFO Epoch 1: [6172/10940] ---- BYOL Training Loss = 0.28954368829727173
30-01-2023 05:17:04 INFO Epoch 1: [6183/10940] ---- BYOL Training Loss = 0.3001847267150879
30-01-2023 05:17:32 INFO Epoch 1: [6194/10940] ---- BYOL Training Loss = 0.32494983077049255
30-01-2023 05:18:00 INFO Epoch 1: [6205/10940] ---- BYOL Training Loss = 0.31952816247940063
30-01-2023 05:19:28 INFO Epoch 1: [6205/10940] ---- BYOL Validation Loss = 0.30355390906333923
30-01-2023 05:19:56 INFO Epoch 1: [6216/10940] ---- BYOL Training Loss = 0.2397792786359787
30-01-2023 05:20:24 INFO Epoch 1: [6227/10940] ---- BYOL Training Loss = 0.2644478678703308
30-01-2023 05:20:52 INFO Epoch 1: [6238/10940] ---- BYOL Training Loss = 0.2857271730899811
30-01-2023 05:21:20 INFO Epoch 1: [6249/10940] ---- BYOL Training Loss = 0.30868270993232727
30-01-2023 05:22:48 INFO Epoch 1: [6249/10940] ---- BYOL Validation Loss = 0.3080694377422333
30-01-2023 05:23:17 INFO Epoch 1: [6260/10940] ---- BYOL Training Loss = 0.3198404908180237
30-01-2023 05:23:45 INFO Epoch 1: [6271/10940] ---- BYOL Training Loss = 0.2643924951553345
30-01-2023 05:24:13 INFO Epoch 1: [6282/10940] ---- BYOL Training Loss = 0.30025744438171387
30-01-2023 05:24:41 INFO Epoch 1: [6293/10940] ---- BYOL Training Loss = 0.3287965655326843
30-01-2023 05:26:09 INFO Epoch 1: [6293/10940] ---- BYOL Validation Loss = 0.30691632628440857
30-01-2023 05:26:37 INFO Epoch 1: [6304/10940] ---- BYOL Training Loss = 0.30474233627319336
30-01-2023 05:27:05 INFO Epoch 1: [6315/10940] ---- BYOL Training Loss = 0.32887718081474304
30-01-2023 05:27:33 INFO Epoch 1: [6326/10940] ---- BYOL Training Loss = 0.35431772470474243
30-01-2023 05:28:01 INFO Epoch 1: [6337/10940] ---- BYOL Training Loss = 0.3132876455783844
30-01-2023 05:29:29 INFO Epoch 1: [6337/10940] ---- BYOL Validation Loss = 0.30239126086235046
30-01-2023 05:29:57 INFO Epoch 1: [6348/10940] ---- BYOL Training Loss = 0.3333389163017273
30-01-2023 05:30:25 INFO Epoch 1: [6359/10940] ---- BYOL Training Loss = 0.27303630113601685
30-01-2023 05:30:53 INFO Epoch 1: [6370/10940] ---- BYOL Training Loss = 0.27527302503585815
30-01-2023 05:31:21 INFO Epoch 1: [6381/10940] ---- BYOL Training Loss = 0.30515938997268677
30-01-2023 05:32:49 INFO Epoch 1: [6381/10940] ---- BYOL Validation Loss = 0.2991831600666046
30-01-2023 05:33:17 INFO Epoch 1: [6392/10940] ---- BYOL Training Loss = 0.3081497251987457
30-01-2023 05:33:46 INFO Epoch 1: [6403/10940] ---- BYOL Training Loss = 0.2742290794849396
30-01-2023 05:34:14 INFO Epoch 1: [6414/10940] ---- BYOL Training Loss = 0.27205032110214233
30-01-2023 05:34:42 INFO Epoch 1: [6425/10940] ---- BYOL Training Loss = 0.27951058745384216
30-01-2023 05:36:09 INFO Epoch 1: [6425/10940] ---- BYOL Validation Loss = 0.2984318435192108
30-01-2023 05:36:38 INFO Epoch 1: [6436/10940] ---- BYOL Training Loss = 0.28727856278419495
30-01-2023 05:37:06 INFO Epoch 1: [6447/10940] ---- BYOL Training Loss = 0.2565891444683075
30-01-2023 05:37:34 INFO Epoch 1: [6458/10940] ---- BYOL Training Loss = 0.24866387248039246
30-01-2023 05:38:02 INFO Epoch 1: [6469/10940] ---- BYOL Training Loss = 0.2727600932121277
30-01-2023 05:39:29 INFO Epoch 1: [6469/10940] ---- BYOL Validation Loss = 0.29652854800224304
30-01-2023 05:39:58 INFO Epoch 1: [6480/10940] ---- BYOL Training Loss = 0.2820318341255188
30-01-2023 05:40:26 INFO Epoch 1: [6491/10940] ---- BYOL Training Loss = 0.30357280373573303
30-01-2023 05:40:54 INFO Epoch 1: [6502/10940] ---- BYOL Training Loss = 0.31151047348976135
30-01-2023 05:41:22 INFO Epoch 1: [6513/10940] ---- BYOL Training Loss = 0.3109091818332672
30-01-2023 05:42:50 INFO Epoch 1: [6513/10940] ---- BYOL Validation Loss = 0.2985974848270416
30-01-2023 05:43:18 INFO Epoch 1: [6524/10940] ---- BYOL Training Loss = 0.3536631166934967
30-01-2023 05:43:46 INFO Epoch 1: [6535/10940] ---- BYOL Training Loss = 0.3411346673965454
30-01-2023 05:44:14 INFO Epoch 1: [6546/10940] ---- BYOL Training Loss = 0.3236957788467407
30-01-2023 05:44:42 INFO Epoch 1: [6557/10940] ---- BYOL Training Loss = 0.32748809456825256
30-01-2023 05:46:10 INFO Epoch 1: [6557/10940] ---- BYOL Validation Loss = 0.301663339138031
30-01-2023 05:46:38 INFO Epoch 1: [6568/10940] ---- BYOL Training Loss = 0.35266730189323425
30-01-2023 05:47:06 INFO Epoch 1: [6579/10940] ---- BYOL Training Loss = 0.3573790490627289
30-01-2023 05:47:34 INFO Epoch 1: [6590/10940] ---- BYOL Training Loss = 0.33328184485435486
30-01-2023 05:48:02 INFO Epoch 1: [6601/10940] ---- BYOL Training Loss = 0.3410152792930603
30-01-2023 05:49:30 INFO Epoch 1: [6601/10940] ---- BYOL Validation Loss = 0.3031885325908661
30-01-2023 05:49:58 INFO Epoch 1: [6612/10940] ---- BYOL Training Loss = 0.2881706953048706
30-01-2023 05:50:26 INFO Epoch 1: [6623/10940] ---- BYOL Training Loss = 0.28325048089027405
30-01-2023 05:50:54 INFO Epoch 1: [6634/10940] ---- BYOL Training Loss = 0.31574684381484985
30-01-2023 05:51:22 INFO Epoch 1: [6645/10940] ---- BYOL Training Loss = 0.27049195766448975
30-01-2023 05:52:50 INFO Epoch 1: [6645/10940] ---- BYOL Validation Loss = 0.30346569418907166
30-01-2023 05:53:18 INFO Epoch 1: [6656/10940] ---- BYOL Training Loss = 0.281946063041687
30-01-2023 05:53:46 INFO Epoch 1: [6667/10940] ---- BYOL Training Loss = 0.2617579698562622
30-01-2023 05:54:14 INFO Epoch 1: [6678/10940] ---- BYOL Training Loss = 0.23738689720630646
30-01-2023 05:54:42 INFO Epoch 1: [6689/10940] ---- BYOL Training Loss = 0.2879911959171295
30-01-2023 05:56:10 INFO Epoch 1: [6689/10940] ---- BYOL Validation Loss = 0.2933933138847351
30-01-2023 05:56:38 INFO Epoch 1: [6700/10940] ---- BYOL Training Loss = 0.2510335445404053
30-01-2023 05:57:07 INFO Epoch 1: [6711/10940] ---- BYOL Training Loss = 0.2728533148765564
30-01-2023 05:57:34 INFO Epoch 1: [6722/10940] ---- BYOL Training Loss = 0.3058743476867676
30-01-2023 05:58:02 INFO Epoch 1: [6733/10940] ---- BYOL Training Loss = 0.3285675346851349
30-01-2023 05:59:30 INFO Epoch 1: [6733/10940] ---- BYOL Validation Loss = 0.29720041155815125
30-01-2023 05:59:59 INFO Epoch 1: [6744/10940] ---- BYOL Training Loss = 0.3092350363731384
30-01-2023 06:00:27 INFO Epoch 1: [6755/10940] ---- BYOL Training Loss = 0.30470243096351624
30-01-2023 06:00:55 INFO Epoch 1: [6766/10940] ---- BYOL Training Loss = 0.3360019028186798
30-01-2023 06:01:23 INFO Epoch 1: [6777/10940] ---- BYOL Training Loss = 0.3231980502605438
30-01-2023 06:02:51 INFO Epoch 1: [6777/10940] ---- BYOL Validation Loss = 0.29381898045539856
30-01-2023 06:03:19 INFO Epoch 1: [6788/10940] ---- BYOL Training Loss = 0.2906855046749115
30-01-2023 06:03:47 INFO Epoch 1: [6799/10940] ---- BYOL Training Loss = 0.30152782797813416
30-01-2023 06:04:16 INFO Epoch 1: [6810/10940] ---- BYOL Training Loss = 0.30936509370803833
30-01-2023 06:04:44 INFO Epoch 1: [6821/10940] ---- BYOL Training Loss = 0.2805081605911255
30-01-2023 06:06:12 INFO Epoch 1: [6821/10940] ---- BYOL Validation Loss = 0.28907448053359985
30-01-2023 06:06:40 INFO Epoch 1: [6832/10940] ---- BYOL Training Loss = 0.25393420457839966
30-01-2023 06:07:08 INFO Epoch 1: [6843/10940] ---- BYOL Training Loss = 0.2768996059894562
30-01-2023 06:07:36 INFO Epoch 1: [6854/10940] ---- BYOL Training Loss = 0.27859988808631897
30-01-2023 06:08:04 INFO Epoch 1: [6865/10940] ---- BYOL Training Loss = 0.2838945984840393
30-01-2023 06:09:32 INFO Epoch 1: [6865/10940] ---- BYOL Validation Loss = 0.2943929135799408
30-01-2023 06:10:00 INFO Epoch 1: [6876/10940] ---- BYOL Training Loss = 0.28856468200683594
30-01-2023 06:10:28 INFO Epoch 1: [6887/10940] ---- BYOL Training Loss = 0.27932286262512207
30-01-2023 06:10:57 INFO Epoch 1: [6898/10940] ---- BYOL Training Loss = 0.2551892399787903
30-01-2023 06:11:25 INFO Epoch 1: [6909/10940] ---- BYOL Training Loss = 0.25976601243019104
30-01-2023 06:12:53 INFO Epoch 1: [6909/10940] ---- BYOL Validation Loss = 0.2932750880718231
30-01-2023 06:13:21 INFO Epoch 1: [6920/10940] ---- BYOL Training Loss = 0.2422594130039215
30-01-2023 06:13:50 INFO Epoch 1: [6931/10940] ---- BYOL Training Loss = 0.2630631923675537
30-01-2023 06:14:18 INFO Epoch 1: [6942/10940] ---- BYOL Training Loss = 0.3083938956260681
30-01-2023 06:14:46 INFO Epoch 1: [6953/10940] ---- BYOL Training Loss = 0.29207614064216614
30-01-2023 06:16:14 INFO Epoch 1: [6953/10940] ---- BYOL Validation Loss = 0.2990074157714844
30-01-2023 06:16:42 INFO Epoch 1: [6964/10940] ---- BYOL Training Loss = 0.2889801859855652
30-01-2023 06:17:10 INFO Epoch 1: [6975/10940] ---- BYOL Training Loss = 0.2943482995033264
30-01-2023 06:17:38 INFO Epoch 1: [6986/10940] ---- BYOL Training Loss = 0.29018595814704895
30-01-2023 06:18:07 INFO Epoch 1: [6997/10940] ---- BYOL Training Loss = 0.27933305501937866
30-01-2023 06:19:35 INFO Epoch 1: [6997/10940] ---- BYOL Validation Loss = 0.2951723635196686
30-01-2023 06:20:03 INFO Epoch 1: [7008/10940] ---- BYOL Training Loss = 0.32389482855796814
30-01-2023 06:20:31 INFO Epoch 1: [7019/10940] ---- BYOL Training Loss = 0.34574249386787415
30-01-2023 06:20:59 INFO Epoch 1: [7030/10940] ---- BYOL Training Loss = 0.2954545021057129
30-01-2023 06:21:27 INFO Epoch 1: [7041/10940] ---- BYOL Training Loss = 0.283882200717926
30-01-2023 06:22:55 INFO Epoch 1: [7041/10940] ---- BYOL Validation Loss = 0.2931373417377472
30-01-2023 06:23:23 INFO Epoch 1: [7052/10940] ---- BYOL Training Loss = 0.27773845195770264
30-01-2023 06:23:52 INFO Epoch 1: [7063/10940] ---- BYOL Training Loss = 0.3051029145717621
30-01-2023 06:24:20 INFO Epoch 1: [7074/10940] ---- BYOL Training Loss = 0.2939055860042572
30-01-2023 06:24:48 INFO Epoch 1: [7085/10940] ---- BYOL Training Loss = 0.29349544644355774
30-01-2023 06:26:16 INFO Epoch 1: [7085/10940] ---- BYOL Validation Loss = 0.30989041924476624
30-01-2023 06:26:45 INFO Epoch 1: [7096/10940] ---- BYOL Training Loss = 0.29822131991386414
30-01-2023 06:27:13 INFO Epoch 1: [7107/10940] ---- BYOL Training Loss = 0.2998051345348358
30-01-2023 06:27:41 INFO Epoch 1: [7118/10940] ---- BYOL Training Loss = 0.32121342420578003
30-01-2023 06:28:09 INFO Epoch 1: [7129/10940] ---- BYOL Training Loss = 0.299164742231369
30-01-2023 06:29:37 INFO Epoch 1: [7129/10940] ---- BYOL Validation Loss = 0.29965415596961975
30-01-2023 06:30:06 INFO Epoch 1: [7140/10940] ---- BYOL Training Loss = 0.30411675572395325
30-01-2023 06:30:34 INFO Epoch 1: [7151/10940] ---- BYOL Training Loss = 0.3004937171936035
30-01-2023 06:31:02 INFO Epoch 1: [7162/10940] ---- BYOL Training Loss = 0.29811447858810425
30-01-2023 06:31:30 INFO Epoch 1: [7173/10940] ---- BYOL Training Loss = 0.28782564401626587
30-01-2023 06:32:58 INFO Epoch 1: [7173/10940] ---- BYOL Validation Loss = 0.3116523325443268
30-01-2023 06:33:26 INFO Epoch 1: [7184/10940] ---- BYOL Training Loss = 0.27739447355270386
30-01-2023 06:33:54 INFO Epoch 1: [7195/10940] ---- BYOL Training Loss = 0.28428348898887634
30-01-2023 06:34:23 INFO Epoch 1: [7206/10940] ---- BYOL Training Loss = 0.2845025956630707
30-01-2023 06:34:51 INFO Epoch 1: [7217/10940] ---- BYOL Training Loss = 0.31428268551826477
30-01-2023 06:36:18 INFO Epoch 1: [7217/10940] ---- BYOL Validation Loss = 0.28876253962516785
30-01-2023 06:36:46 INFO Epoch 1: [7228/10940] ---- BYOL Training Loss = 0.3207615911960602
30-01-2023 06:37:15 INFO Epoch 1: [7239/10940] ---- BYOL Training Loss = 0.27046507596969604
30-01-2023 06:37:43 INFO Epoch 1: [7250/10940] ---- BYOL Training Loss = 0.27376416325569153
30-01-2023 06:38:11 INFO Epoch 1: [7261/10940] ---- BYOL Training Loss = 0.3096861243247986
30-01-2023 06:39:39 INFO Epoch 1: [7261/10940] ---- BYOL Validation Loss = 0.29217928647994995
30-01-2023 06:40:08 INFO Epoch 1: [7272/10940] ---- BYOL Training Loss = 0.31385090947151184
30-01-2023 06:40:36 INFO Epoch 1: [7283/10940] ---- BYOL Training Loss = 0.2814657986164093
30-01-2023 06:41:04 INFO Epoch 1: [7294/10940] ---- BYOL Training Loss = 0.3066525459289551
30-01-2023 06:41:32 INFO Epoch 1: [7305/10940] ---- BYOL Training Loss = 0.3102830946445465
30-01-2023 06:43:00 INFO Epoch 1: [7305/10940] ---- BYOL Validation Loss = 0.29788556694984436
30-01-2023 06:43:29 INFO Epoch 1: [7316/10940] ---- BYOL Training Loss = 0.2975859045982361
30-01-2023 06:43:57 INFO Epoch 1: [7327/10940] ---- BYOL Training Loss = 0.2985239326953888
30-01-2023 06:44:25 INFO Epoch 1: [7338/10940] ---- BYOL Training Loss = 0.26147300004959106
30-01-2023 06:44:54 INFO Epoch 1: [7349/10940] ---- BYOL Training Loss = 0.3126438856124878
30-01-2023 06:46:22 INFO Epoch 1: [7349/10940] ---- BYOL Validation Loss = 0.3035765290260315
30-01-2023 06:46:50 INFO Epoch 1: [7360/10940] ---- BYOL Training Loss = 0.32306838035583496
30-01-2023 06:47:19 INFO Epoch 1: [7371/10940] ---- BYOL Training Loss = 0.30990082025527954
30-01-2023 06:47:47 INFO Epoch 1: [7382/10940] ---- BYOL Training Loss = 0.32280653715133667
30-01-2023 06:48:15 INFO Epoch 1: [7393/10940] ---- BYOL Training Loss = 0.3175683319568634
30-01-2023 06:49:43 INFO Epoch 1: [7393/10940] ---- BYOL Validation Loss = 0.29504531621932983
30-01-2023 06:50:12 INFO Epoch 1: [7404/10940] ---- BYOL Training Loss = 0.2829967141151428
30-01-2023 06:50:40 INFO Epoch 1: [7415/10940] ---- BYOL Training Loss = 0.3025725483894348
30-01-2023 06:51:08 INFO Epoch 1: [7426/10940] ---- BYOL Training Loss = 0.3368064761161804
30-01-2023 06:51:37 INFO Epoch 1: [7437/10940] ---- BYOL Training Loss = 0.284174382686615
30-01-2023 06:53:04 INFO Epoch 1: [7437/10940] ---- BYOL Validation Loss = 0.2847874164581299
30-01-2023 06:53:33 INFO Epoch 1: [7448/10940] ---- BYOL Training Loss = 0.2711573839187622
30-01-2023 06:54:01 INFO Epoch 1: [7459/10940] ---- BYOL Training Loss = 0.2894635498523712
30-01-2023 06:54:29 INFO Epoch 1: [7470/10940] ---- BYOL Training Loss = 0.30228057503700256
30-01-2023 06:54:57 INFO Epoch 1: [7481/10940] ---- BYOL Training Loss = 0.28375881910324097
30-01-2023 06:56:25 INFO Epoch 1: [7481/10940] ---- BYOL Validation Loss = 0.28542548418045044
30-01-2023 06:56:53 INFO Epoch 1: [7492/10940] ---- BYOL Training Loss = 0.29017549753189087
30-01-2023 06:57:22 INFO Epoch 1: [7503/10940] ---- BYOL Training Loss = 0.27316445112228394
30-01-2023 06:57:50 INFO Epoch 1: [7514/10940] ---- BYOL Training Loss = 0.2798024117946625
30-01-2023 06:58:18 INFO Epoch 1: [7525/10940] ---- BYOL Training Loss = 0.27774205803871155
30-01-2023 06:59:46 INFO Epoch 1: [7525/10940] ---- BYOL Validation Loss = 0.28682103753089905
30-01-2023 07:00:15 INFO Epoch 1: [7536/10940] ---- BYOL Training Loss = 0.29080361127853394
30-01-2023 07:00:43 INFO Epoch 1: [7547/10940] ---- BYOL Training Loss = 0.2664460241794586
30-01-2023 07:01:11 INFO Epoch 1: [7558/10940] ---- BYOL Training Loss = 0.25872185826301575
30-01-2023 07:01:40 INFO Epoch 1: [7569/10940] ---- BYOL Training Loss = 0.2824569046497345
30-01-2023 07:03:08 INFO Epoch 1: [7569/10940] ---- BYOL Validation Loss = 0.2999337613582611
30-01-2023 07:03:36 INFO Epoch 1: [7580/10940] ---- BYOL Training Loss = 0.26685893535614014
30-01-2023 07:04:04 INFO Epoch 1: [7591/10940] ---- BYOL Training Loss = 0.29356932640075684
30-01-2023 07:04:32 INFO Epoch 1: [7602/10940] ---- BYOL Training Loss = 0.30147987604141235
30-01-2023 07:05:00 INFO Epoch 1: [7613/10940] ---- BYOL Training Loss = 0.3221486210823059
30-01-2023 07:06:28 INFO Epoch 1: [7613/10940] ---- BYOL Validation Loss = 0.29476019740104675
30-01-2023 07:06:56 INFO Epoch 1: [7624/10940] ---- BYOL Training Loss = 0.3076779544353485
30-01-2023 07:07:25 INFO Epoch 1: [7635/10940] ---- BYOL Training Loss = 0.2687544822692871
30-01-2023 07:07:53 INFO Epoch 1: [7646/10940] ---- BYOL Training Loss = 0.31508687138557434
30-01-2023 07:08:21 INFO Epoch 1: [7657/10940] ---- BYOL Training Loss = 0.30879002809524536
30-01-2023 07:09:49 INFO Epoch 1: [7657/10940] ---- BYOL Validation Loss = 0.2934098243713379
30-01-2023 07:10:18 INFO Epoch 1: [7668/10940] ---- BYOL Training Loss = 0.2842428386211395
30-01-2023 07:10:46 INFO Epoch 1: [7679/10940] ---- BYOL Training Loss = 0.2836213707923889
30-01-2023 07:11:14 INFO Epoch 1: [7690/10940] ---- BYOL Training Loss = 0.2756521999835968
30-01-2023 07:11:43 INFO Epoch 1: [7701/10940] ---- BYOL Training Loss = 0.30074620246887207
30-01-2023 07:13:10 INFO Epoch 1: [7701/10940] ---- BYOL Validation Loss = 0.29405754804611206
30-01-2023 07:13:39 INFO Epoch 1: [7712/10940] ---- BYOL Training Loss = 0.31670621037483215
30-01-2023 07:14:07 INFO Epoch 1: [7723/10940] ---- BYOL Training Loss = 0.3257957398891449
30-01-2023 07:14:35 INFO Epoch 1: [7734/10940] ---- BYOL Training Loss = 0.3140046000480652
30-01-2023 07:15:03 INFO Epoch 1: [7745/10940] ---- BYOL Training Loss = 0.30053284764289856
30-01-2023 07:16:31 INFO Epoch 1: [7745/10940] ---- BYOL Validation Loss = 0.30257096886634827
30-01-2023 07:16:59 INFO Epoch 1: [7756/10940] ---- BYOL Training Loss = 0.30789315700531006
30-01-2023 07:17:28 INFO Epoch 1: [7767/10940] ---- BYOL Training Loss = 0.3145805597305298
30-01-2023 07:17:56 INFO Epoch 1: [7778/10940] ---- BYOL Training Loss = 0.2938278615474701
30-01-2023 07:18:25 INFO Epoch 1: [7789/10940] ---- BYOL Training Loss = 0.2830863893032074
30-01-2023 07:19:52 INFO Epoch 1: [7789/10940] ---- BYOL Validation Loss = 0.29541927576065063
30-01-2023 07:20:21 INFO Epoch 1: [7800/10940] ---- BYOL Training Loss = 0.3103010654449463
30-01-2023 07:20:49 INFO Epoch 1: [7811/10940] ---- BYOL Training Loss = 0.3234831690788269
30-01-2023 07:21:18 INFO Epoch 1: [7822/10940] ---- BYOL Training Loss = 0.2937694787979126
30-01-2023 07:21:46 INFO Epoch 1: [7833/10940] ---- BYOL Training Loss = 0.2868896424770355
30-01-2023 07:23:13 INFO Epoch 1: [7833/10940] ---- BYOL Validation Loss = 0.30178287625312805
30-01-2023 07:23:42 INFO Epoch 1: [7844/10940] ---- BYOL Training Loss = 0.34251493215560913
30-01-2023 07:24:10 INFO Epoch 1: [7855/10940] ---- BYOL Training Loss = 0.3204450309276581
30-01-2023 07:24:38 INFO Epoch 1: [7866/10940] ---- BYOL Training Loss = 0.30715212225914
30-01-2023 07:25:06 INFO Epoch 1: [7877/10940] ---- BYOL Training Loss = 0.3298965394496918
30-01-2023 07:26:34 INFO Epoch 1: [7877/10940] ---- BYOL Validation Loss = 0.2930380702018738
30-01-2023 07:27:03 INFO Epoch 1: [7888/10940] ---- BYOL Training Loss = 0.2796631455421448
30-01-2023 07:27:31 INFO Epoch 1: [7899/10940] ---- BYOL Training Loss = 0.25043192505836487
30-01-2023 07:27:59 INFO Epoch 1: [7910/10940] ---- BYOL Training Loss = 0.23126161098480225
30-01-2023 07:28:28 INFO Epoch 1: [7921/10940] ---- BYOL Training Loss = 0.25884243845939636
30-01-2023 07:29:55 INFO Epoch 1: [7921/10940] ---- BYOL Validation Loss = 0.2853269577026367
30-01-2023 07:30:24 INFO Epoch 1: [7932/10940] ---- BYOL Training Loss = 0.2983587980270386
30-01-2023 07:30:53 INFO Epoch 1: [7943/10940] ---- BYOL Training Loss = 0.31096771359443665
30-01-2023 07:31:21 INFO Epoch 1: [7954/10940] ---- BYOL Training Loss = 0.2737340033054352
30-01-2023 07:31:49 INFO Epoch 1: [7965/10940] ---- BYOL Training Loss = 0.28435438871383667
30-01-2023 07:33:16 INFO Epoch 1: [7965/10940] ---- BYOL Validation Loss = 0.28582367300987244
30-01-2023 07:33:45 INFO Epoch 1: [7976/10940] ---- BYOL Training Loss = 0.30832839012145996
30-01-2023 07:34:13 INFO Epoch 1: [7987/10940] ---- BYOL Training Loss = 0.2661623954772949
30-01-2023 07:34:41 INFO Epoch 1: [7998/10940] ---- BYOL Training Loss = 0.27735185623168945
30-01-2023 07:35:10 INFO Epoch 1: [8009/10940] ---- BYOL Training Loss = 0.28105658292770386
30-01-2023 07:36:38 INFO Epoch 1: [8009/10940] ---- BYOL Validation Loss = 0.290740042924881
30-01-2023 07:37:06 INFO Epoch 1: [8020/10940] ---- BYOL Training Loss = 0.28806495666503906
30-01-2023 07:37:34 INFO Epoch 1: [8031/10940] ---- BYOL Training Loss = 0.3147091865539551
30-01-2023 07:38:02 INFO Epoch 1: [8042/10940] ---- BYOL Training Loss = 0.2886910140514374
30-01-2023 07:38:31 INFO Epoch 1: [8053/10940] ---- BYOL Training Loss = 0.3068252503871918
30-01-2023 07:39:58 INFO Epoch 1: [8053/10940] ---- BYOL Validation Loss = 0.2894604206085205
30-01-2023 07:40:27 INFO Epoch 1: [8064/10940] ---- BYOL Training Loss = 0.31810641288757324
30-01-2023 07:40:55 INFO Epoch 1: [8075/10940] ---- BYOL Training Loss = 0.306787371635437
30-01-2023 07:41:23 INFO Epoch 1: [8086/10940] ---- BYOL Training Loss = 0.27963799238204956
30-01-2023 07:41:52 INFO Epoch 1: [8097/10940] ---- BYOL Training Loss = 0.25562649965286255
30-01-2023 07:43:19 INFO Epoch 1: [8097/10940] ---- BYOL Validation Loss = 0.28317466378211975
30-01-2023 07:43:48 INFO Epoch 1: [8108/10940] ---- BYOL Training Loss = 0.29625770449638367
30-01-2023 07:44:16 INFO Epoch 1: [8119/10940] ---- BYOL Training Loss = 0.3147744834423065
30-01-2023 07:44:44 INFO Epoch 1: [8130/10940] ---- BYOL Training Loss = 0.2898580729961395
30-01-2023 07:45:13 INFO Epoch 1: [8141/10940] ---- BYOL Training Loss = 0.30958321690559387
30-01-2023 07:46:40 INFO Epoch 1: [8141/10940] ---- BYOL Validation Loss = 0.2802618443965912
30-01-2023 07:47:08 INFO Epoch 1: [8152/10940] ---- BYOL Training Loss = 0.33386415243148804
30-01-2023 07:47:37 INFO Epoch 1: [8163/10940] ---- BYOL Training Loss = 0.30587077140808105
30-01-2023 07:48:05 INFO Epoch 1: [8174/10940] ---- BYOL Training Loss = 0.33132225275039673
30-01-2023 07:48:33 INFO Epoch 1: [8185/10940] ---- BYOL Training Loss = 0.2932493984699249
30-01-2023 07:50:01 INFO Epoch 1: [8185/10940] ---- BYOL Validation Loss = 0.29094138741493225
30-01-2023 07:50:30 INFO Epoch 1: [8196/10940] ---- BYOL Training Loss = 0.3273191452026367
30-01-2023 07:50:58 INFO Epoch 1: [8207/10940] ---- BYOL Training Loss = 0.3022956848144531
30-01-2023 07:51:26 INFO Epoch 1: [8218/10940] ---- BYOL Training Loss = 0.290237158536911
30-01-2023 07:51:55 INFO Epoch 1: [8229/10940] ---- BYOL Training Loss = 0.32899409532546997
30-01-2023 07:53:22 INFO Epoch 1: [8229/10940] ---- BYOL Validation Loss = 0.29822757840156555
30-01-2023 07:53:51 INFO Epoch 1: [8240/10940] ---- BYOL Training Loss = 0.29577791690826416
30-01-2023 07:54:19 INFO Epoch 1: [8251/10940] ---- BYOL Training Loss = 0.27487561106681824
30-01-2023 07:54:48 INFO Epoch 1: [8262/10940] ---- BYOL Training Loss = 0.2740080952644348
30-01-2023 07:55:16 INFO Epoch 1: [8273/10940] ---- BYOL Training Loss = 0.26304900646209717
30-01-2023 07:56:43 INFO Epoch 1: [8273/10940] ---- BYOL Validation Loss = 0.28513625264167786
30-01-2023 07:57:12 INFO Epoch 1: [8284/10940] ---- BYOL Training Loss = 0.28392037749290466
30-01-2023 07:57:40 INFO Epoch 1: [8295/10940] ---- BYOL Training Loss = 0.30886349081993103
30-01-2023 07:58:08 INFO Epoch 1: [8306/10940] ---- BYOL Training Loss = 0.28427374362945557
30-01-2023 07:58:37 INFO Epoch 1: [8317/10940] ---- BYOL Training Loss = 0.24574294686317444
30-01-2023 08:00:04 INFO Epoch 1: [8317/10940] ---- BYOL Validation Loss = 0.2819177508354187
30-01-2023 08:00:33 INFO Epoch 1: [8328/10940] ---- BYOL Training Loss = 0.28940609097480774
30-01-2023 08:01:01 INFO Epoch 1: [8339/10940] ---- BYOL Training Loss = 0.3137042224407196
30-01-2023 08:01:29 INFO Epoch 1: [8350/10940] ---- BYOL Training Loss = 0.30646032094955444
30-01-2023 08:01:57 INFO Epoch 1: [8361/10940] ---- BYOL Training Loss = 0.30968669056892395
30-01-2023 08:03:25 INFO Epoch 1: [8361/10940] ---- BYOL Validation Loss = 0.2798648476600647
30-01-2023 08:03:53 INFO Epoch 1: [8372/10940] ---- BYOL Training Loss = 0.307064950466156
30-01-2023 08:04:22 INFO Epoch 1: [8383/10940] ---- BYOL Training Loss = 0.3078245222568512
30-01-2023 08:04:50 INFO Epoch 1: [8394/10940] ---- BYOL Training Loss = 0.313016414642334
30-01-2023 08:05:19 INFO Epoch 1: [8405/10940] ---- BYOL Training Loss = 0.27182453870773315
30-01-2023 08:06:47 INFO Epoch 1: [8405/10940] ---- BYOL Validation Loss = 0.2878992259502411
30-01-2023 08:07:15 INFO Epoch 1: [8416/10940] ---- BYOL Training Loss = 0.27594441175460815
30-01-2023 08:07:43 INFO Epoch 1: [8427/10940] ---- BYOL Training Loss = 0.30238819122314453
30-01-2023 08:08:11 INFO Epoch 1: [8438/10940] ---- BYOL Training Loss = 0.30865392088890076
30-01-2023 08:08:40 INFO Epoch 1: [8449/10940] ---- BYOL Training Loss = 0.28844526410102844
30-01-2023 08:10:07 INFO Epoch 1: [8449/10940] ---- BYOL Validation Loss = 0.2938236594200134
30-01-2023 08:10:36 INFO Epoch 1: [8460/10940] ---- BYOL Training Loss = 0.28113478422164917
30-01-2023 08:11:04 INFO Epoch 1: [8471/10940] ---- BYOL Training Loss = 0.28406867384910583
30-01-2023 08:11:32 INFO Epoch 1: [8482/10940] ---- BYOL Training Loss = 0.25428909063339233
30-01-2023 08:12:01 INFO Epoch 1: [8493/10940] ---- BYOL Training Loss = 0.27252522110939026
30-01-2023 08:13:28 INFO Epoch 1: [8493/10940] ---- BYOL Validation Loss = 0.2894325852394104
30-01-2023 08:13:57 INFO Epoch 1: [8504/10940] ---- BYOL Training Loss = 0.2965204119682312
30-01-2023 08:14:25 INFO Epoch 1: [8515/10940] ---- BYOL Training Loss = 0.31086084246635437
30-01-2023 08:14:53 INFO Epoch 1: [8526/10940] ---- BYOL Training Loss = 0.2963408827781677
30-01-2023 08:15:22 INFO Epoch 1: [8537/10940] ---- BYOL Training Loss = 0.304243803024292
30-01-2023 08:16:49 INFO Epoch 1: [8537/10940] ---- BYOL Validation Loss = 0.28607186675071716
30-01-2023 08:17:18 INFO Epoch 1: [8548/10940] ---- BYOL Training Loss = 0.244161456823349
30-01-2023 08:17:46 INFO Epoch 1: [8559/10940] ---- BYOL Training Loss = 0.2867538034915924
30-01-2023 08:18:15 INFO Epoch 1: [8570/10940] ---- BYOL Training Loss = 0.3094029128551483
30-01-2023 08:18:43 INFO Epoch 1: [8581/10940] ---- BYOL Training Loss = 0.2846182584762573
30-01-2023 08:20:11 INFO Epoch 1: [8581/10940] ---- BYOL Validation Loss = 0.2934785485267639
30-01-2023 08:20:39 INFO Epoch 1: [8592/10940] ---- BYOL Training Loss = 0.27169889211654663
30-01-2023 08:21:08 INFO Epoch 1: [8603/10940] ---- BYOL Training Loss = 0.24582047760486603
30-01-2023 08:21:36 INFO Epoch 1: [8614/10940] ---- BYOL Training Loss = 0.2927390933036804
30-01-2023 08:22:04 INFO Epoch 1: [8625/10940] ---- BYOL Training Loss = 0.3048565983772278
30-01-2023 08:23:32 INFO Epoch 1: [8625/10940] ---- BYOL Validation Loss = 0.2887245714664459
30-01-2023 08:24:00 INFO Epoch 1: [8636/10940] ---- BYOL Training Loss = 0.3392051160335541
30-01-2023 08:24:29 INFO Epoch 1: [8647/10940] ---- BYOL Training Loss = 0.3184630870819092
30-01-2023 08:24:57 INFO Epoch 1: [8658/10940] ---- BYOL Training Loss = 0.3165149688720703
30-01-2023 08:25:26 INFO Epoch 1: [8669/10940] ---- BYOL Training Loss = 0.3575183153152466
30-01-2023 08:26:53 INFO Epoch 1: [8669/10940] ---- BYOL Validation Loss = 0.3016974627971649
30-01-2023 08:27:22 INFO Epoch 1: [8680/10940] ---- BYOL Training Loss = 0.32845357060432434
30-01-2023 08:27:50 INFO Epoch 1: [8691/10940] ---- BYOL Training Loss = 0.30955958366394043
30-01-2023 08:28:18 INFO Epoch 1: [8702/10940] ---- BYOL Training Loss = 0.32753607630729675
30-01-2023 08:28:47 INFO Epoch 1: [8713/10940] ---- BYOL Training Loss = 0.2916427254676819
30-01-2023 08:30:14 INFO Epoch 1: [8713/10940] ---- BYOL Validation Loss = 0.2930002510547638
30-01-2023 08:30:42 INFO Epoch 1: [8724/10940] ---- BYOL Training Loss = 0.29800134897232056
30-01-2023 08:31:11 INFO Epoch 1: [8735/10940] ---- BYOL Training Loss = 0.3130777180194855
30-01-2023 08:31:39 INFO Epoch 1: [8746/10940] ---- BYOL Training Loss = 0.3249463140964508
30-01-2023 08:32:08 INFO Epoch 1: [8757/10940] ---- BYOL Training Loss = 0.30543121695518494
30-01-2023 08:33:36 INFO Epoch 1: [8757/10940] ---- BYOL Validation Loss = 0.30585864186286926
30-01-2023 08:34:04 INFO Epoch 1: [8768/10940] ---- BYOL Training Loss = 0.3317260146141052
30-01-2023 08:34:32 INFO Epoch 1: [8779/10940] ---- BYOL Training Loss = 0.29506856203079224
30-01-2023 08:35:00 INFO Epoch 1: [8790/10940] ---- BYOL Training Loss = 0.29174885153770447
30-01-2023 08:35:29 INFO Epoch 1: [8801/10940] ---- BYOL Training Loss = 0.29708462953567505
30-01-2023 08:36:56 INFO Epoch 1: [8801/10940] ---- BYOL Validation Loss = 0.29786258935928345
30-01-2023 08:37:24 INFO Epoch 1: [8812/10940] ---- BYOL Training Loss = 0.2750456631183624
30-01-2023 08:37:53 INFO Epoch 1: [8823/10940] ---- BYOL Training Loss = 0.2879202365875244
30-01-2023 08:38:22 INFO Epoch 1: [8834/10940] ---- BYOL Training Loss = 0.30708810687065125
30-01-2023 08:38:50 INFO Epoch 1: [8845/10940] ---- BYOL Training Loss = 0.2812095880508423
30-01-2023 08:40:18 INFO Epoch 1: [8845/10940] ---- BYOL Validation Loss = 0.2898615300655365
30-01-2023 08:40:46 INFO Epoch 1: [8856/10940] ---- BYOL Training Loss = 0.32501479983329773
30-01-2023 08:41:14 INFO Epoch 1: [8867/10940] ---- BYOL Training Loss = 0.31602439284324646
30-01-2023 08:41:43 INFO Epoch 1: [8878/10940] ---- BYOL Training Loss = 0.28910672664642334
30-01-2023 08:42:11 INFO Epoch 1: [8889/10940] ---- BYOL Training Loss = 0.2952776849269867
30-01-2023 08:43:39 INFO Epoch 1: [8889/10940] ---- BYOL Validation Loss = 0.2852730453014374
30-01-2023 08:44:08 INFO Epoch 1: [8900/10940] ---- BYOL Training Loss = 0.2889237105846405
30-01-2023 08:44:36 INFO Epoch 1: [8911/10940] ---- BYOL Training Loss = 0.29926571249961853
30-01-2023 08:45:04 INFO Epoch 1: [8922/10940] ---- BYOL Training Loss = 0.3131002187728882
30-01-2023 08:45:32 INFO Epoch 1: [8933/10940] ---- BYOL Training Loss = 0.33239421248435974
30-01-2023 08:47:00 INFO Epoch 1: [8933/10940] ---- BYOL Validation Loss = 0.28971797227859497
30-01-2023 08:47:28 INFO Epoch 1: [8944/10940] ---- BYOL Training Loss = 0.3278677463531494
30-01-2023 08:47:57 INFO Epoch 1: [8955/10940] ---- BYOL Training Loss = 0.3238813281059265
30-01-2023 08:48:25 INFO Epoch 1: [8966/10940] ---- BYOL Training Loss = 0.2907683253288269
30-01-2023 08:48:54 INFO Epoch 1: [8977/10940] ---- BYOL Training Loss = 0.2573605179786682
30-01-2023 08:50:21 INFO Epoch 1: [8977/10940] ---- BYOL Validation Loss = 0.28995317220687866
30-01-2023 08:50:50 INFO Epoch 1: [8988/10940] ---- BYOL Training Loss = 0.27688202261924744
30-01-2023 08:51:18 INFO Epoch 1: [8999/10940] ---- BYOL Training Loss = 0.3174341320991516
30-01-2023 08:51:47 INFO Epoch 1: [9010/10940] ---- BYOL Training Loss = 0.3167741298675537
30-01-2023 08:52:15 INFO Epoch 1: [9021/10940] ---- BYOL Training Loss = 0.30258211493492126
30-01-2023 08:53:43 INFO Epoch 1: [9021/10940] ---- BYOL Validation Loss = 0.28870776295661926
30-01-2023 08:54:11 INFO Epoch 1: [9032/10940] ---- BYOL Training Loss = 0.2943027913570404
30-01-2023 08:54:40 INFO Epoch 1: [9043/10940] ---- BYOL Training Loss = 0.33672165870666504
30-01-2023 08:55:08 INFO Epoch 1: [9054/10940] ---- BYOL Training Loss = 0.3568301796913147
30-01-2023 08:55:36 INFO Epoch 1: [9065/10940] ---- BYOL Training Loss = 0.3224589228630066
30-01-2023 08:57:04 INFO Epoch 1: [9065/10940] ---- BYOL Validation Loss = 0.2843194901943207
30-01-2023 08:57:33 INFO Epoch 1: [9076/10940] ---- BYOL Training Loss = 0.2831347584724426
30-01-2023 08:58:01 INFO Epoch 1: [9087/10940] ---- BYOL Training Loss = 0.2942432463169098
30-01-2023 08:58:29 INFO Epoch 1: [9098/10940] ---- BYOL Training Loss = 0.28358393907546997
30-01-2023 08:58:58 INFO Epoch 1: [9109/10940] ---- BYOL Training Loss = 0.28846603631973267
30-01-2023 09:00:26 INFO Epoch 1: [9109/10940] ---- BYOL Validation Loss = 0.2866764962673187
30-01-2023 09:00:54 INFO Epoch 1: [9120/10940] ---- BYOL Training Loss = 0.2794763445854187
30-01-2023 09:01:23 INFO Epoch 1: [9131/10940] ---- BYOL Training Loss = 0.2723782956600189
30-01-2023 09:01:51 INFO Epoch 1: [9142/10940] ---- BYOL Training Loss = 0.27456146478652954
30-01-2023 09:02:19 INFO Epoch 1: [9153/10940] ---- BYOL Training Loss = 0.2626993954181671
30-01-2023 09:03:47 INFO Epoch 1: [9153/10940] ---- BYOL Validation Loss = 0.2864704132080078
30-01-2023 09:04:16 INFO Epoch 1: [9164/10940] ---- BYOL Training Loss = 0.25908204913139343
30-01-2023 09:04:44 INFO Epoch 1: [9175/10940] ---- BYOL Training Loss = 0.28606948256492615
30-01-2023 09:05:12 INFO Epoch 1: [9186/10940] ---- BYOL Training Loss = 0.29047873616218567
30-01-2023 09:05:41 INFO Epoch 1: [9197/10940] ---- BYOL Training Loss = 0.25965213775634766
30-01-2023 09:07:08 INFO Epoch 1: [9197/10940] ---- BYOL Validation Loss = 0.29361143708229065
30-01-2023 09:07:36 INFO Epoch 1: [9208/10940] ---- BYOL Training Loss = 0.27243340015411377
30-01-2023 09:08:05 INFO Epoch 1: [9219/10940] ---- BYOL Training Loss = 0.28174975514411926
30-01-2023 09:08:34 INFO Epoch 1: [9230/10940] ---- BYOL Training Loss = 0.27608722448349
30-01-2023 09:09:02 INFO Epoch 1: [9241/10940] ---- BYOL Training Loss = 0.28246065974235535
30-01-2023 09:10:30 INFO Epoch 1: [9241/10940] ---- BYOL Validation Loss = 0.29647430777549744
30-01-2023 09:10:58 INFO Epoch 1: [9252/10940] ---- BYOL Training Loss = 0.2734295427799225
30-01-2023 09:11:26 INFO Epoch 1: [9263/10940] ---- BYOL Training Loss = 0.32891783118247986
30-01-2023 09:11:55 INFO Epoch 1: [9274/10940] ---- BYOL Training Loss = 0.31851106882095337
30-01-2023 09:12:23 INFO Epoch 1: [9285/10940] ---- BYOL Training Loss = 0.295381635427475
30-01-2023 09:13:51 INFO Epoch 1: [9285/10940] ---- BYOL Validation Loss = 0.2860698401927948
30-01-2023 09:14:20 INFO Epoch 1: [9296/10940] ---- BYOL Training Loss = 0.29287785291671753
30-01-2023 09:14:48 INFO Epoch 1: [9307/10940] ---- BYOL Training Loss = 0.32300472259521484
30-01-2023 09:15:16 INFO Epoch 1: [9318/10940] ---- BYOL Training Loss = 0.3595863878726959
30-01-2023 09:15:45 INFO Epoch 1: [9329/10940] ---- BYOL Training Loss = 0.312417596578598
30-01-2023 09:17:12 INFO Epoch 1: [9329/10940] ---- BYOL Validation Loss = 0.2916770577430725
30-01-2023 09:17:41 INFO Epoch 1: [9340/10940] ---- BYOL Training Loss = 0.296409010887146
30-01-2023 09:18:09 INFO Epoch 1: [9351/10940] ---- BYOL Training Loss = 0.30536264181137085
30-01-2023 09:18:37 INFO Epoch 1: [9362/10940] ---- BYOL Training Loss = 0.29249897599220276
30-01-2023 09:19:06 INFO Epoch 1: [9373/10940] ---- BYOL Training Loss = 0.26449665427207947
30-01-2023 09:20:33 INFO Epoch 1: [9373/10940] ---- BYOL Validation Loss = 0.28557196259498596
30-01-2023 09:21:02 INFO Epoch 1: [9384/10940] ---- BYOL Training Loss = 0.26826226711273193
30-01-2023 09:21:30 INFO Epoch 1: [9395/10940] ---- BYOL Training Loss = 0.29248398542404175
30-01-2023 09:21:59 INFO Epoch 1: [9406/10940] ---- BYOL Training Loss = 0.3171539604663849
30-01-2023 09:22:27 INFO Epoch 1: [9417/10940] ---- BYOL Training Loss = 0.3187474310398102
30-01-2023 09:23:55 INFO Epoch 1: [9417/10940] ---- BYOL Validation Loss = 0.28679296374320984
30-01-2023 09:24:23 INFO Epoch 1: [9428/10940] ---- BYOL Training Loss = 0.30348312854766846
30-01-2023 09:24:52 INFO Epoch 1: [9439/10940] ---- BYOL Training Loss = 0.29966816306114197
30-01-2023 09:25:20 INFO Epoch 1: [9450/10940] ---- BYOL Training Loss = 0.3272002339363098
30-01-2023 09:25:49 INFO Epoch 1: [9461/10940] ---- BYOL Training Loss = 0.3175361156463623
30-01-2023 09:27:16 INFO Epoch 1: [9461/10940] ---- BYOL Validation Loss = 0.2812933325767517
30-01-2023 09:27:45 INFO Epoch 1: [9472/10940] ---- BYOL Training Loss = 0.32030290365219116
30-01-2023 09:28:13 INFO Epoch 1: [9483/10940] ---- BYOL Training Loss = 0.33529359102249146
30-01-2023 09:28:42 INFO Epoch 1: [9494/10940] ---- BYOL Training Loss = 0.3238151967525482
30-01-2023 09:29:10 INFO Epoch 1: [9505/10940] ---- BYOL Training Loss = 0.32077014446258545
30-01-2023 09:30:37 INFO Epoch 1: [9505/10940] ---- BYOL Validation Loss = 0.2870129942893982
30-01-2023 09:31:06 INFO Epoch 1: [9516/10940] ---- BYOL Training Loss = 0.3036741316318512
30-01-2023 09:31:34 INFO Epoch 1: [9527/10940] ---- BYOL Training Loss = 0.30881911516189575
30-01-2023 09:32:03 INFO Epoch 1: [9538/10940] ---- BYOL Training Loss = 0.3113657832145691
30-01-2023 09:32:31 INFO Epoch 1: [9549/10940] ---- BYOL Training Loss = 0.29656726121902466
30-01-2023 09:33:59 INFO Epoch 1: [9549/10940] ---- BYOL Validation Loss = 0.29465028643608093
30-01-2023 09:34:27 INFO Epoch 1: [9560/10940] ---- BYOL Training Loss = 0.2774721384048462
30-01-2023 09:34:56 INFO Epoch 1: [9571/10940] ---- BYOL Training Loss = 0.2638104557991028
30-01-2023 09:35:24 INFO Epoch 1: [9582/10940] ---- BYOL Training Loss = 0.3126658797264099
30-01-2023 09:35:53 INFO Epoch 1: [9593/10940] ---- BYOL Training Loss = 0.3191617429256439
30-01-2023 09:37:21 INFO Epoch 1: [9593/10940] ---- BYOL Validation Loss = 0.2966666519641876
30-01-2023 09:37:49 INFO Epoch 1: [9604/10940] ---- BYOL Training Loss = 0.27079933881759644
30-01-2023 09:38:17 INFO Epoch 1: [9615/10940] ---- BYOL Training Loss = 0.24316520988941193
30-01-2023 09:38:46 INFO Epoch 1: [9626/10940] ---- BYOL Training Loss = 0.28334492444992065
30-01-2023 09:39:14 INFO Epoch 1: [9637/10940] ---- BYOL Training Loss = 0.2801268994808197
30-01-2023 09:40:42 INFO Epoch 1: [9637/10940] ---- BYOL Validation Loss = 0.2884434163570404
30-01-2023 09:41:11 INFO Epoch 1: [9648/10940] ---- BYOL Training Loss = 0.30768662691116333
30-01-2023 09:41:39 INFO Epoch 1: [9659/10940] ---- BYOL Training Loss = 0.3570696711540222
30-01-2023 09:42:07 INFO Epoch 1: [9670/10940] ---- BYOL Training Loss = 0.34091323614120483
30-01-2023 09:42:36 INFO Epoch 1: [9681/10940] ---- BYOL Training Loss = 0.28234124183654785
30-01-2023 09:44:04 INFO Epoch 1: [9681/10940] ---- BYOL Validation Loss = 0.276070237159729
30-01-2023 09:44:32 INFO Epoch 1: [9692/10940] ---- BYOL Training Loss = 0.3081824779510498
30-01-2023 09:45:01 INFO Epoch 1: [9703/10940] ---- BYOL Training Loss = 0.29591378569602966
30-01-2023 09:45:29 INFO Epoch 1: [9714/10940] ---- BYOL Training Loss = 0.27709680795669556
30-01-2023 09:45:58 INFO Epoch 1: [9725/10940] ---- BYOL Training Loss = 0.28002259135246277
30-01-2023 09:47:25 INFO Epoch 1: [9725/10940] ---- BYOL Validation Loss = 0.29026225209236145
30-01-2023 09:47:54 INFO Epoch 1: [9736/10940] ---- BYOL Training Loss = 0.2960423231124878
30-01-2023 09:48:22 INFO Epoch 1: [9747/10940] ---- BYOL Training Loss = 0.2969570755958557
30-01-2023 09:48:51 INFO Epoch 1: [9758/10940] ---- BYOL Training Loss = 0.27482497692108154
30-01-2023 09:49:19 INFO Epoch 1: [9769/10940] ---- BYOL Training Loss = 0.29462164640426636
30-01-2023 09:50:46 INFO Epoch 1: [9769/10940] ---- BYOL Validation Loss = 0.2949519157409668
30-01-2023 09:51:15 INFO Epoch 1: [9780/10940] ---- BYOL Training Loss = 0.2993395924568176
30-01-2023 09:51:43 INFO Epoch 1: [9791/10940] ---- BYOL Training Loss = 0.2708352208137512
30-01-2023 09:52:12 INFO Epoch 1: [9802/10940] ---- BYOL Training Loss = 0.2495562732219696
30-01-2023 09:52:40 INFO Epoch 1: [9813/10940] ---- BYOL Training Loss = 0.3027518391609192
30-01-2023 09:54:08 INFO Epoch 1: [9813/10940] ---- BYOL Validation Loss = 0.2927003502845764
30-01-2023 09:54:37 INFO Epoch 1: [9824/10940] ---- BYOL Training Loss = 0.35320380330085754
30-01-2023 09:55:05 INFO Epoch 1: [9835/10940] ---- BYOL Training Loss = 0.3317512571811676
30-01-2023 09:55:34 INFO Epoch 1: [9846/10940] ---- BYOL Training Loss = 0.2889356017112732
30-01-2023 09:56:02 INFO Epoch 1: [9857/10940] ---- BYOL Training Loss = 0.2895464301109314
30-01-2023 09:57:30 INFO Epoch 1: [9857/10940] ---- BYOL Validation Loss = 0.29070860147476196
30-01-2023 09:57:59 INFO Epoch 1: [9868/10940] ---- BYOL Training Loss = 0.3169201612472534
30-01-2023 09:58:27 INFO Epoch 1: [9879/10940] ---- BYOL Training Loss = 0.29699987173080444
30-01-2023 09:58:56 INFO Epoch 1: [9890/10940] ---- BYOL Training Loss = 0.2544081509113312
30-01-2023 09:59:24 INFO Epoch 1: [9901/10940] ---- BYOL Training Loss = 0.27640458941459656
30-01-2023 10:00:52 INFO Epoch 1: [9901/10940] ---- BYOL Validation Loss = 0.2939123809337616
30-01-2023 10:01:20 INFO Epoch 1: [9912/10940] ---- BYOL Training Loss = 0.2638029456138611
30-01-2023 10:01:49 INFO Epoch 1: [9923/10940] ---- BYOL Training Loss = 0.27621495723724365
30-01-2023 10:02:18 INFO Epoch 1: [9934/10940] ---- BYOL Training Loss = 0.3037109971046448
30-01-2023 10:02:46 INFO Epoch 1: [9945/10940] ---- BYOL Training Loss = 0.31858354806900024
30-01-2023 10:04:14 INFO Epoch 1: [9945/10940] ---- BYOL Validation Loss = 0.29161685705184937
30-01-2023 10:04:43 INFO Epoch 1: [9956/10940] ---- BYOL Training Loss = 0.32556214928627014
30-01-2023 10:05:11 INFO Epoch 1: [9967/10940] ---- BYOL Training Loss = 0.3057955801486969
30-01-2023 10:05:39 INFO Epoch 1: [9978/10940] ---- BYOL Training Loss = 0.2801056504249573
30-01-2023 10:06:08 INFO Epoch 1: [9989/10940] ---- BYOL Training Loss = 0.330440878868103
30-01-2023 10:07:36 INFO Epoch 1: [9989/10940] ---- BYOL Validation Loss = 0.30166107416152954
30-01-2023 10:08:04 INFO Epoch 1: [10000/10940] ---- BYOL Training Loss = 0.3204967975616455
30-01-2023 10:08:33 INFO Epoch 1: [10011/10940] ---- BYOL Training Loss = 0.28233715891838074
30-01-2023 10:09:01 INFO Epoch 1: [10022/10940] ---- BYOL Training Loss = 0.30981677770614624
30-01-2023 10:09:30 INFO Epoch 1: [10033/10940] ---- BYOL Training Loss = 0.2961316704750061
30-01-2023 10:10:58 INFO Epoch 1: [10033/10940] ---- BYOL Validation Loss = 0.2885458767414093
30-01-2023 10:11:26 INFO Epoch 1: [10044/10940] ---- BYOL Training Loss = 0.2567518353462219
30-01-2023 10:11:54 INFO Epoch 1: [10055/10940] ---- BYOL Training Loss = 0.254281610250473
30-01-2023 10:12:23 INFO Epoch 1: [10066/10940] ---- BYOL Training Loss = 0.2873651683330536
30-01-2023 10:12:51 INFO Epoch 1: [10077/10940] ---- BYOL Training Loss = 0.317446231842041
30-01-2023 10:14:19 INFO Epoch 1: [10077/10940] ---- BYOL Validation Loss = 0.2927808165550232
30-01-2023 10:14:48 INFO Epoch 1: [10088/10940] ---- BYOL Training Loss = 0.28115469217300415
30-01-2023 10:15:16 INFO Epoch 1: [10099/10940] ---- BYOL Training Loss = 0.2772790193557739
30-01-2023 10:15:45 INFO Epoch 1: [10110/10940] ---- BYOL Training Loss = 0.3476710915565491
30-01-2023 10:16:13 INFO Epoch 1: [10121/10940] ---- BYOL Training Loss = 0.3634597659111023
30-01-2023 10:17:41 INFO Epoch 1: [10121/10940] ---- BYOL Validation Loss = 0.28794020414352417
30-01-2023 10:18:10 INFO Epoch 1: [10132/10940] ---- BYOL Training Loss = 0.3004649579524994
30-01-2023 10:18:38 INFO Epoch 1: [10143/10940] ---- BYOL Training Loss = 0.315631628036499
30-01-2023 10:19:07 INFO Epoch 1: [10154/10940] ---- BYOL Training Loss = 0.33171921968460083
30-01-2023 10:19:35 INFO Epoch 1: [10165/10940] ---- BYOL Training Loss = 0.3254774510860443
30-01-2023 10:21:03 INFO Epoch 1: [10165/10940] ---- BYOL Validation Loss = 0.29749631881713867
30-01-2023 10:21:32 INFO Epoch 1: [10176/10940] ---- BYOL Training Loss = 0.3240628242492676
30-01-2023 10:22:00 INFO Epoch 1: [10187/10940] ---- BYOL Training Loss = 0.27850931882858276
30-01-2023 10:22:29 INFO Epoch 1: [10198/10940] ---- BYOL Training Loss = 0.31792885065078735
30-01-2023 10:22:58 INFO Epoch 1: [10209/10940] ---- BYOL Training Loss = 0.3288302719593048
30-01-2023 10:24:25 INFO Epoch 1: [10209/10940] ---- BYOL Validation Loss = 0.29509884119033813
30-01-2023 10:24:54 INFO Epoch 1: [10220/10940] ---- BYOL Training Loss = 0.28154510259628296
30-01-2023 10:25:23 INFO Epoch 1: [10231/10940] ---- BYOL Training Loss = 0.2832376956939697
30-01-2023 10:25:51 INFO Epoch 1: [10242/10940] ---- BYOL Training Loss = 0.28748077154159546
30-01-2023 10:26:20 INFO Epoch 1: [10253/10940] ---- BYOL Training Loss = 0.31742241978645325
30-01-2023 10:27:48 INFO Epoch 1: [10253/10940] ---- BYOL Validation Loss = 0.28744134306907654
30-01-2023 10:28:16 INFO Epoch 1: [10264/10940] ---- BYOL Training Loss = 0.32207706570625305
30-01-2023 10:28:44 INFO Epoch 1: [10275/10940] ---- BYOL Training Loss = 0.3266775608062744
30-01-2023 10:29:13 INFO Epoch 1: [10286/10940] ---- BYOL Training Loss = 0.3068820536136627
30-01-2023 10:29:41 INFO Epoch 1: [10297/10940] ---- BYOL Training Loss = 0.2860040068626404
30-01-2023 10:31:09 INFO Epoch 1: [10297/10940] ---- BYOL Validation Loss = 0.2917040288448334
30-01-2023 10:31:38 INFO Epoch 1: [10308/10940] ---- BYOL Training Loss = 0.2611714005470276
30-01-2023 10:32:06 INFO Epoch 1: [10319/10940] ---- BYOL Training Loss = 0.30963030457496643
30-01-2023 10:32:35 INFO Epoch 1: [10330/10940] ---- BYOL Training Loss = 0.3369424343109131
30-01-2023 10:33:04 INFO Epoch 1: [10341/10940] ---- BYOL Training Loss = 0.3105907142162323
30-01-2023 10:34:32 INFO Epoch 1: [10341/10940] ---- BYOL Validation Loss = 0.28435978293418884
30-01-2023 10:35:00 INFO Epoch 1: [10352/10940] ---- BYOL Training Loss = 0.23959913849830627
30-01-2023 10:35:29 INFO Epoch 1: [10363/10940] ---- BYOL Training Loss = 0.2784309685230255
30-01-2023 10:35:57 INFO Epoch 1: [10374/10940] ---- BYOL Training Loss = 0.3432406485080719
30-01-2023 10:36:26 INFO Epoch 1: [10385/10940] ---- BYOL Training Loss = 0.33257055282592773
30-01-2023 10:37:54 INFO Epoch 1: [10385/10940] ---- BYOL Validation Loss = 0.2843250632286072
30-01-2023 10:38:22 INFO Epoch 1: [10396/10940] ---- BYOL Training Loss = 0.3056463897228241
30-01-2023 10:38:51 INFO Epoch 1: [10407/10940] ---- BYOL Training Loss = 0.3085401654243469
30-01-2023 10:39:19 INFO Epoch 1: [10418/10940] ---- BYOL Training Loss = 0.3201060891151428
30-01-2023 10:39:48 INFO Epoch 1: [10429/10940] ---- BYOL Training Loss = 0.3452625870704651
30-01-2023 10:41:16 INFO Epoch 1: [10429/10940] ---- BYOL Validation Loss = 0.2886973023414612
30-01-2023 10:41:44 INFO Epoch 1: [10440/10940] ---- BYOL Training Loss = 0.35849729180336
30-01-2023 10:42:12 INFO Epoch 1: [10451/10940] ---- BYOL Training Loss = 0.3212260603904724
30-01-2023 10:42:41 INFO Epoch 1: [10462/10940] ---- BYOL Training Loss = 0.33721834421157837
30-01-2023 10:43:10 INFO Epoch 1: [10473/10940] ---- BYOL Training Loss = 0.34623950719833374
30-01-2023 10:44:37 INFO Epoch 1: [10473/10940] ---- BYOL Validation Loss = 0.29017797112464905
30-01-2023 10:45:06 INFO Epoch 1: [10484/10940] ---- BYOL Training Loss = 0.2952682077884674
30-01-2023 10:45:34 INFO Epoch 1: [10495/10940] ---- BYOL Training Loss = 0.3333207964897156
30-01-2023 10:46:03 INFO Epoch 1: [10506/10940] ---- BYOL Training Loss = 0.36017340421676636
30-01-2023 10:46:31 INFO Epoch 1: [10517/10940] ---- BYOL Training Loss = 0.3112504482269287
30-01-2023 10:47:59 INFO Epoch 1: [10517/10940] ---- BYOL Validation Loss = 0.2951231598854065
30-01-2023 10:48:28 INFO Epoch 1: [10528/10940] ---- BYOL Training Loss = 0.33128494024276733
30-01-2023 10:48:56 INFO Epoch 1: [10539/10940] ---- BYOL Training Loss = 0.36851248145103455
30-01-2023 10:49:25 INFO Epoch 1: [10550/10940] ---- BYOL Training Loss = 0.37751147150993347
30-01-2023 10:49:54 INFO Epoch 1: [10561/10940] ---- BYOL Training Loss = 0.3179585337638855
30-01-2023 10:51:21 INFO Epoch 1: [10561/10940] ---- BYOL Validation Loss = 0.2966884970664978
30-01-2023 10:51:50 INFO Epoch 1: [10572/10940] ---- BYOL Training Loss = 0.26430848240852356
30-01-2023 10:52:18 INFO Epoch 1: [10583/10940] ---- BYOL Training Loss = 0.3065791130065918
30-01-2023 10:52:47 INFO Epoch 1: [10594/10940] ---- BYOL Training Loss = 0.308138906955719
30-01-2023 10:53:16 INFO Epoch 1: [10605/10940] ---- BYOL Training Loss = 0.29466208815574646
30-01-2023 10:54:43 INFO Epoch 1: [10605/10940] ---- BYOL Validation Loss = 0.2999653220176697
30-01-2023 10:55:12 INFO Epoch 1: [10616/10940] ---- BYOL Training Loss = 0.28696301579475403
30-01-2023 10:55:40 INFO Epoch 1: [10627/10940] ---- BYOL Training Loss = 0.28777316212654114
30-01-2023 10:56:09 INFO Epoch 1: [10638/10940] ---- BYOL Training Loss = 0.32040002942085266
30-01-2023 10:56:37 INFO Epoch 1: [10649/10940] ---- BYOL Training Loss = 0.331102192401886
30-01-2023 10:58:05 INFO Epoch 1: [10649/10940] ---- BYOL Validation Loss = 0.286265105009079
30-01-2023 10:58:34 INFO Epoch 1: [10660/10940] ---- BYOL Training Loss = 0.2756972908973694
30-01-2023 10:59:02 INFO Epoch 1: [10671/10940] ---- BYOL Training Loss = 0.263683557510376
30-01-2023 10:59:31 INFO Epoch 1: [10682/10940] ---- BYOL Training Loss = 0.2609303593635559
30-01-2023 10:59:59 INFO Epoch 1: [10693/10940] ---- BYOL Training Loss = 0.28744781017303467
30-01-2023 11:01:27 INFO Epoch 1: [10693/10940] ---- BYOL Validation Loss = 0.45439624786376953
30-01-2023 11:01:56 INFO Epoch 1: [10704/10940] ---- BYOL Training Loss = 0.3159085214138031
30-01-2023 11:02:24 INFO Epoch 1: [10715/10940] ---- BYOL Training Loss = 0.264350950717926
30-01-2023 11:02:53 INFO Epoch 1: [10726/10940] ---- BYOL Training Loss = 0.22951216995716095
30-01-2023 11:03:21 INFO Epoch 1: [10737/10940] ---- BYOL Training Loss = 0.22029881179332733
30-01-2023 11:04:49 INFO Epoch 1: [10737/10940] ---- BYOL Validation Loss = 0.2806902527809143
30-01-2023 11:05:18 INFO Epoch 1: [10748/10940] ---- BYOL Training Loss = 0.27136343717575073
30-01-2023 11:05:46 INFO Epoch 1: [10759/10940] ---- BYOL Training Loss = 0.32159295678138733
30-01-2023 11:06:15 INFO Epoch 1: [10770/10940] ---- BYOL Training Loss = 0.30519595742225647
30-01-2023 11:06:43 INFO Epoch 1: [10781/10940] ---- BYOL Training Loss = 0.30228906869888306
30-01-2023 11:08:11 INFO Epoch 1: [10781/10940] ---- BYOL Validation Loss = 0.28824666142463684
30-01-2023 11:08:40 INFO Epoch 1: [10792/10940] ---- BYOL Training Loss = 0.29728183150291443
30-01-2023 11:09:09 INFO Epoch 1: [10803/10940] ---- BYOL Training Loss = 0.30249881744384766
30-01-2023 11:09:37 INFO Epoch 1: [10814/10940] ---- BYOL Training Loss = 0.2781558632850647
30-01-2023 11:10:06 INFO Epoch 1: [10825/10940] ---- BYOL Training Loss = 0.2672324776649475
30-01-2023 11:11:34 INFO Epoch 1: [10825/10940] ---- BYOL Validation Loss = 0.27775219082832336
30-01-2023 11:12:02 INFO Epoch 1: [10836/10940] ---- BYOL Training Loss = 0.3111152946949005
30-01-2023 11:12:31 INFO Epoch 1: [10847/10940] ---- BYOL Training Loss = 0.3260221481323242
30-01-2023 11:13:00 INFO Epoch 1: [10858/10940] ---- BYOL Training Loss = 0.34037935733795166
30-01-2023 11:13:29 INFO Epoch 1: [10869/10940] ---- BYOL Training Loss = 0.3466058671474457
30-01-2023 11:14:56 INFO Epoch 1: [10869/10940] ---- BYOL Validation Loss = 0.29059603810310364
30-01-2023 11:15:25 INFO Epoch 1: [10880/10940] ---- BYOL Training Loss = 0.3394376039505005
30-01-2023 11:15:54 INFO Epoch 1: [10891/10940] ---- BYOL Training Loss = 0.27166998386383057
30-01-2023 11:16:22 INFO Epoch 1: [10902/10940] ---- BYOL Training Loss = 0.24375490844249725
30-01-2023 11:16:51 INFO Epoch 1: [10913/10940] ---- BYOL Training Loss = 0.2895423471927643
30-01-2023 11:18:19 INFO Epoch 1: [10913/10940] ---- BYOL Validation Loss = 0.2795465588569641
30-01-2023 11:18:47 INFO Epoch 1: [10924/10940] ---- BYOL Training Loss = 0.32429322600364685
30-01-2023 11:19:16 INFO Epoch 1: [10935/10940] ---- BYOL Training Loss = 0.32771021127700806
30-01-2023 11:19:29 INFO Starting Epoch: 2
30-01-2023 11:19:57 INFO Epoch 2: [12/10940] ---- BYOL Training Loss = 0.27597448229789734
30-01-2023 11:20:25 INFO Epoch 2: [23/10940] ---- BYOL Training Loss = 0.2832837700843811
30-01-2023 11:20:52 INFO Epoch 2: [34/10940] ---- BYOL Training Loss = 0.29294857382774353
30-01-2023 11:21:20 INFO Epoch 2: [45/10940] ---- BYOL Training Loss = 0.27515581250190735
30-01-2023 11:22:47 INFO Epoch 2: [45/10940] ---- BYOL Validation Loss = 0.28917059302330017
30-01-2023 11:23:15 INFO Epoch 2: [56/10940] ---- BYOL Training Loss = 0.24924440681934357
30-01-2023 11:23:43 INFO Epoch 2: [67/10940] ---- BYOL Training Loss = 0.23892371356487274
30-01-2023 11:24:10 INFO Epoch 2: [78/10940] ---- BYOL Training Loss = 0.25559455156326294
30-01-2023 11:24:38 INFO Epoch 2: [89/10940] ---- BYOL Training Loss = 0.2885622978210449
30-01-2023 11:26:05 INFO Epoch 2: [89/10940] ---- BYOL Validation Loss = 0.2939075827598572
30-01-2023 11:26:33 INFO Epoch 2: [100/10940] ---- BYOL Training Loss = 0.3394557535648346
30-01-2023 11:27:01 INFO Epoch 2: [111/10940] ---- BYOL Training Loss = 0.3429105281829834
30-01-2023 11:27:28 INFO Epoch 2: [122/10940] ---- BYOL Training Loss = 0.3146612346172333
30-01-2023 11:27:56 INFO Epoch 2: [133/10940] ---- BYOL Training Loss = 0.2809809446334839
30-01-2023 11:29:24 INFO Epoch 2: [133/10940] ---- BYOL Validation Loss = 0.28686782717704773
30-01-2023 11:29:51 INFO Epoch 2: [144/10940] ---- BYOL Training Loss = 0.2561587393283844
30-01-2023 11:30:19 INFO Epoch 2: [155/10940] ---- BYOL Training Loss = 0.2704772353172302
30-01-2023 11:30:46 INFO Epoch 2: [166/10940] ---- BYOL Training Loss = 0.30331525206565857
30-01-2023 11:31:14 INFO Epoch 2: [177/10940] ---- BYOL Training Loss = 0.3246001899242401
30-01-2023 11:32:42 INFO Epoch 2: [177/10940] ---- BYOL Validation Loss = 0.2910686135292053
30-01-2023 11:33:09 INFO Epoch 2: [188/10940] ---- BYOL Training Loss = 0.3098568618297577
30-01-2023 11:33:37 INFO Epoch 2: [199/10940] ---- BYOL Training Loss = 0.3271792531013489
30-01-2023 11:34:04 INFO Epoch 2: [210/10940] ---- BYOL Training Loss = 0.31198108196258545
30-01-2023 11:34:32 INFO Epoch 2: [221/10940] ---- BYOL Training Loss = 0.29895469546318054
30-01-2023 11:36:00 INFO Epoch 2: [221/10940] ---- BYOL Validation Loss = 0.2887781262397766
30-01-2023 11:36:27 INFO Epoch 2: [232/10940] ---- BYOL Training Loss = 0.29615792632102966
30-01-2023 11:36:55 INFO Epoch 2: [243/10940] ---- BYOL Training Loss = 0.3075992465019226
30-01-2023 11:37:23 INFO Epoch 2: [254/10940] ---- BYOL Training Loss = 0.2834303379058838
30-01-2023 11:37:51 INFO Epoch 2: [265/10940] ---- BYOL Training Loss = 0.28606194257736206
30-01-2023 11:39:18 INFO Epoch 2: [265/10940] ---- BYOL Validation Loss = 0.2955337166786194
30-01-2023 11:39:46 INFO Epoch 2: [276/10940] ---- BYOL Training Loss = 0.3204132914543152
30-01-2023 11:40:14 INFO Epoch 2: [287/10940] ---- BYOL Training Loss = 0.3214521110057831
30-01-2023 11:40:41 INFO Epoch 2: [298/10940] ---- BYOL Training Loss = 0.27020928263664246
30-01-2023 11:41:09 INFO Epoch 2: [309/10940] ---- BYOL Training Loss = 0.2972213625907898
30-01-2023 11:42:37 INFO Epoch 2: [309/10940] ---- BYOL Validation Loss = 0.30120229721069336
30-01-2023 11:43:04 INFO Epoch 2: [320/10940] ---- BYOL Training Loss = 0.3036044239997864
30-01-2023 11:43:32 INFO Epoch 2: [331/10940] ---- BYOL Training Loss = 0.3024289011955261
30-01-2023 11:44:00 INFO Epoch 2: [342/10940] ---- BYOL Training Loss = 0.320237398147583
30-01-2023 11:44:27 INFO Epoch 2: [353/10940] ---- BYOL Training Loss = 0.3140765428543091
30-01-2023 11:45:55 INFO Epoch 2: [353/10940] ---- BYOL Validation Loss = 0.2915167808532715
30-01-2023 11:46:23 INFO Epoch 2: [364/10940] ---- BYOL Training Loss = 0.2852553427219391
30-01-2023 11:46:50 INFO Epoch 2: [375/10940] ---- BYOL Training Loss = 0.27298808097839355
30-01-2023 11:47:18 INFO Epoch 2: [386/10940] ---- BYOL Training Loss = 0.28969258069992065
30-01-2023 11:47:45 INFO Epoch 2: [397/10940] ---- BYOL Training Loss = 0.3220488131046295
30-01-2023 11:49:13 INFO Epoch 2: [397/10940] ---- BYOL Validation Loss = 0.29597240686416626
30-01-2023 11:49:41 INFO Epoch 2: [408/10940] ---- BYOL Training Loss = 0.32072025537490845
30-01-2023 11:50:09 INFO Epoch 2: [419/10940] ---- BYOL Training Loss = 0.32777220010757446
30-01-2023 11:50:36 INFO Epoch 2: [430/10940] ---- BYOL Training Loss = 0.32204529643058777
30-01-2023 11:51:04 INFO Epoch 2: [441/10940] ---- BYOL Training Loss = 0.3065762519836426
30-01-2023 11:52:32 INFO Epoch 2: [441/10940] ---- BYOL Validation Loss = 0.29337286949157715
30-01-2023 11:52:59 INFO Epoch 2: [452/10940] ---- BYOL Training Loss = 0.336935818195343
30-01-2023 11:53:27 INFO Epoch 2: [463/10940] ---- BYOL Training Loss = 0.3281252384185791
30-01-2023 11:53:54 INFO Epoch 2: [474/10940] ---- BYOL Training Loss = 0.2617824375629425
30-01-2023 11:54:22 INFO Epoch 2: [485/10940] ---- BYOL Training Loss = 0.2846757173538208
30-01-2023 11:55:50 INFO Epoch 2: [485/10940] ---- BYOL Validation Loss = 0.28775861859321594
30-01-2023 11:56:17 INFO Epoch 2: [496/10940] ---- BYOL Training Loss = 0.31004002690315247
30-01-2023 11:56:45 INFO Epoch 2: [507/10940] ---- BYOL Training Loss = 0.2774890065193176
30-01-2023 11:57:13 INFO Epoch 2: [518/10940] ---- BYOL Training Loss = 0.28266459703445435
30-01-2023 11:57:40 INFO Epoch 2: [529/10940] ---- BYOL Training Loss = 0.3274005055427551
30-01-2023 11:59:08 INFO Epoch 2: [529/10940] ---- BYOL Validation Loss = 0.28865960240364075
30-01-2023 11:59:36 INFO Epoch 2: [540/10940] ---- BYOL Training Loss = 0.31332528591156006
30-01-2023 12:00:03 INFO Epoch 2: [551/10940] ---- BYOL Training Loss = 0.28119486570358276
30-01-2023 12:00:31 INFO Epoch 2: [562/10940] ---- BYOL Training Loss = 0.26487070322036743
30-01-2023 12:00:58 INFO Epoch 2: [573/10940] ---- BYOL Training Loss = 0.2703877389431
30-01-2023 12:02:26 INFO Epoch 2: [573/10940] ---- BYOL Validation Loss = 0.2860690653324127
30-01-2023 12:02:54 INFO Epoch 2: [584/10940] ---- BYOL Training Loss = 0.2749846577644348
30-01-2023 12:03:21 INFO Epoch 2: [595/10940] ---- BYOL Training Loss = 0.25569018721580505
30-01-2023 12:03:49 INFO Epoch 2: [606/10940] ---- BYOL Training Loss = 0.2733805179595947
30-01-2023 12:04:17 INFO Epoch 2: [617/10940] ---- BYOL Training Loss = 0.29773321747779846
30-01-2023 12:05:45 INFO Epoch 2: [617/10940] ---- BYOL Validation Loss = 0.2850695550441742
30-01-2023 12:06:12 INFO Epoch 2: [628/10940] ---- BYOL Training Loss = 0.2683183550834656
30-01-2023 12:06:40 INFO Epoch 2: [639/10940] ---- BYOL Training Loss = 0.2541954219341278
30-01-2023 12:07:07 INFO Epoch 2: [650/10940] ---- BYOL Training Loss = 0.27042847871780396
30-01-2023 12:07:35 INFO Epoch 2: [661/10940] ---- BYOL Training Loss = 0.26183977723121643
30-01-2023 12:09:02 INFO Epoch 2: [661/10940] ---- BYOL Validation Loss = 0.29584041237831116
30-01-2023 12:09:30 INFO Epoch 2: [672/10940] ---- BYOL Training Loss = 0.2864990234375
30-01-2023 12:09:57 INFO Epoch 2: [683/10940] ---- BYOL Training Loss = 0.3268675208091736
30-01-2023 12:10:25 INFO Epoch 2: [694/10940] ---- BYOL Training Loss = 0.29657071828842163
30-01-2023 12:10:53 INFO Epoch 2: [705/10940] ---- BYOL Training Loss = 0.3445661664009094
30-01-2023 12:12:21 INFO Epoch 2: [705/10940] ---- BYOL Validation Loss = 0.28904882073402405
30-01-2023 12:12:48 INFO Epoch 2: [716/10940] ---- BYOL Training Loss = 0.31886452436447144
30-01-2023 12:13:16 INFO Epoch 2: [727/10940] ---- BYOL Training Loss = 0.2597639262676239
30-01-2023 12:13:43 INFO Epoch 2: [738/10940] ---- BYOL Training Loss = 0.27589234709739685
30-01-2023 12:14:11 INFO Epoch 2: [749/10940] ---- BYOL Training Loss = 0.3199353814125061
30-01-2023 12:15:38 INFO Epoch 2: [749/10940] ---- BYOL Validation Loss = 0.2817871868610382
30-01-2023 12:16:06 INFO Epoch 2: [760/10940] ---- BYOL Training Loss = 0.3205772042274475
30-01-2023 12:16:34 INFO Epoch 2: [771/10940] ---- BYOL Training Loss = 0.31765085458755493
30-01-2023 12:17:01 INFO Epoch 2: [782/10940] ---- BYOL Training Loss = 0.27632060647010803
30-01-2023 12:17:29 INFO Epoch 2: [793/10940] ---- BYOL Training Loss = 0.3050956726074219
30-01-2023 12:18:56 INFO Epoch 2: [793/10940] ---- BYOL Validation Loss = 0.28133049607276917
30-01-2023 12:19:24 INFO Epoch 2: [804/10940] ---- BYOL Training Loss = 0.34625640511512756
30-01-2023 12:19:51 INFO Epoch 2: [815/10940] ---- BYOL Training Loss = 0.31387394666671753
30-01-2023 12:20:19 INFO Epoch 2: [826/10940] ---- BYOL Training Loss = 0.28749117255210876
30-01-2023 12:20:47 INFO Epoch 2: [837/10940] ---- BYOL Training Loss = 0.27563485503196716
30-01-2023 12:22:14 INFO Epoch 2: [837/10940] ---- BYOL Validation Loss = 0.28633996844291687
30-01-2023 12:22:42 INFO Epoch 2: [848/10940] ---- BYOL Training Loss = 0.25959882140159607
30-01-2023 12:23:10 INFO Epoch 2: [859/10940] ---- BYOL Training Loss = 0.28073298931121826
30-01-2023 12:23:37 INFO Epoch 2: [870/10940] ---- BYOL Training Loss = 0.2794063687324524
30-01-2023 12:24:05 INFO Epoch 2: [881/10940] ---- BYOL Training Loss = 0.27986007928848267
30-01-2023 12:25:33 INFO Epoch 2: [881/10940] ---- BYOL Validation Loss = 0.2827453017234802
30-01-2023 12:26:00 INFO Epoch 2: [892/10940] ---- BYOL Training Loss = 0.2945564389228821
30-01-2023 12:26:28 INFO Epoch 2: [903/10940] ---- BYOL Training Loss = 0.314985990524292
30-01-2023 12:26:56 INFO Epoch 2: [914/10940] ---- BYOL Training Loss = 0.3187430799007416
30-01-2023 12:27:23 INFO Epoch 2: [925/10940] ---- BYOL Training Loss = 0.283738911151886
30-01-2023 12:28:51 INFO Epoch 2: [925/10940] ---- BYOL Validation Loss = 0.2846204340457916
30-01-2023 12:29:18 INFO Epoch 2: [936/10940] ---- BYOL Training Loss = 0.2732287049293518
30-01-2023 12:29:46 INFO Epoch 2: [947/10940] ---- BYOL Training Loss = 0.2999586760997772
30-01-2023 12:30:14 INFO Epoch 2: [958/10940] ---- BYOL Training Loss = 0.2862780690193176
30-01-2023 12:30:41 INFO Epoch 2: [969/10940] ---- BYOL Training Loss = 0.267799437046051
30-01-2023 12:32:09 INFO Epoch 2: [969/10940] ---- BYOL Validation Loss = 0.2766614556312561
30-01-2023 12:32:37 INFO Epoch 2: [980/10940] ---- BYOL Training Loss = 0.26163938641548157
30-01-2023 12:33:04 INFO Epoch 2: [991/10940] ---- BYOL Training Loss = 0.30543869733810425
30-01-2023 12:33:32 INFO Epoch 2: [1002/10940] ---- BYOL Training Loss = 0.33627593517303467
30-01-2023 12:33:59 INFO Epoch 2: [1013/10940] ---- BYOL Training Loss = 0.2950313091278076
30-01-2023 12:35:27 INFO Epoch 2: [1013/10940] ---- BYOL Validation Loss = 0.2821994423866272
30-01-2023 12:35:55 INFO Epoch 2: [1024/10940] ---- BYOL Training Loss = 0.2920724153518677
30-01-2023 12:36:22 INFO Epoch 2: [1035/10940] ---- BYOL Training Loss = 0.2924371361732483
30-01-2023 12:36:50 INFO Epoch 2: [1046/10940] ---- BYOL Training Loss = 0.30245882272720337
30-01-2023 12:37:17 INFO Epoch 2: [1057/10940] ---- BYOL Training Loss = 0.30791372060775757
30-01-2023 12:38:45 INFO Epoch 2: [1057/10940] ---- BYOL Validation Loss = 0.28872421383857727
30-01-2023 12:39:13 INFO Epoch 2: [1068/10940] ---- BYOL Training Loss = 0.2863445281982422
30-01-2023 12:39:41 INFO Epoch 2: [1079/10940] ---- BYOL Training Loss = 0.28109776973724365
30-01-2023 12:40:09 INFO Epoch 2: [1090/10940] ---- BYOL Training Loss = 0.31530502438545227
30-01-2023 12:40:36 INFO Epoch 2: [1101/10940] ---- BYOL Training Loss = 0.3302641808986664
30-01-2023 12:42:04 INFO Epoch 2: [1101/10940] ---- BYOL Validation Loss = 0.28696900606155396
30-01-2023 12:42:32 INFO Epoch 2: [1112/10940] ---- BYOL Training Loss = 0.2835847735404968
30-01-2023 12:42:59 INFO Epoch 2: [1123/10940] ---- BYOL Training Loss = 0.26744669675827026
30-01-2023 12:43:27 INFO Epoch 2: [1134/10940] ---- BYOL Training Loss = 0.2599283456802368
30-01-2023 12:43:55 INFO Epoch 2: [1145/10940] ---- BYOL Training Loss = 0.2503431439399719
30-01-2023 12:45:23 INFO Epoch 2: [1145/10940] ---- BYOL Validation Loss = 0.28158897161483765
30-01-2023 12:45:50 INFO Epoch 2: [1156/10940] ---- BYOL Training Loss = 0.29649272561073303
30-01-2023 12:46:18 INFO Epoch 2: [1167/10940] ---- BYOL Training Loss = 0.3186289072036743
30-01-2023 12:46:46 INFO Epoch 2: [1178/10940] ---- BYOL Training Loss = 0.27789944410324097
30-01-2023 12:47:13 INFO Epoch 2: [1189/10940] ---- BYOL Training Loss = 0.23613926768302917
30-01-2023 12:48:41 INFO Epoch 2: [1189/10940] ---- BYOL Validation Loss = 0.2742202579975128
30-01-2023 12:49:09 INFO Epoch 2: [1200/10940] ---- BYOL Training Loss = 0.24269258975982666
30-01-2023 12:49:37 INFO Epoch 2: [1211/10940] ---- BYOL Training Loss = 0.24621538817882538
30-01-2023 12:50:04 INFO Epoch 2: [1222/10940] ---- BYOL Training Loss = 0.3008195459842682
30-01-2023 12:50:32 INFO Epoch 2: [1233/10940] ---- BYOL Training Loss = 0.27416425943374634
30-01-2023 12:52:00 INFO Epoch 2: [1233/10940] ---- BYOL Validation Loss = 0.2725509703159332
30-01-2023 12:52:27 INFO Epoch 2: [1244/10940] ---- BYOL Training Loss = 0.24804861843585968
30-01-2023 12:52:55 INFO Epoch 2: [1255/10940] ---- BYOL Training Loss = 0.3098210096359253
30-01-2023 12:53:23 INFO Epoch 2: [1266/10940] ---- BYOL Training Loss = 0.3052346110343933
30-01-2023 12:53:50 INFO Epoch 2: [1277/10940] ---- BYOL Training Loss = 0.27832597494125366
30-01-2023 12:55:18 INFO Epoch 2: [1277/10940] ---- BYOL Validation Loss = 0.28882136940956116
30-01-2023 12:55:46 INFO Epoch 2: [1288/10940] ---- BYOL Training Loss = 0.2851712107658386
30-01-2023 12:56:13 INFO Epoch 2: [1299/10940] ---- BYOL Training Loss = 0.2738482654094696
30-01-2023 12:56:41 INFO Epoch 2: [1310/10940] ---- BYOL Training Loss = 0.31635600328445435
30-01-2023 12:57:08 INFO Epoch 2: [1321/10940] ---- BYOL Training Loss = 0.27141502499580383
30-01-2023 12:58:36 INFO Epoch 2: [1321/10940] ---- BYOL Validation Loss = 0.2796536684036255
30-01-2023 12:59:04 INFO Epoch 2: [1332/10940] ---- BYOL Training Loss = 0.28435570001602173
30-01-2023 12:59:31 INFO Epoch 2: [1343/10940] ---- BYOL Training Loss = 0.3009641766548157
30-01-2023 12:59:59 INFO Epoch 2: [1354/10940] ---- BYOL Training Loss = 0.27244284749031067
30-01-2023 13:00:27 INFO Epoch 2: [1365/10940] ---- BYOL Training Loss = 0.2935953736305237
30-01-2023 13:01:55 INFO Epoch 2: [1365/10940] ---- BYOL Validation Loss = 0.27932611107826233
30-01-2023 13:02:23 INFO Epoch 2: [1376/10940] ---- BYOL Training Loss = 0.28758612275123596
30-01-2023 13:02:50 INFO Epoch 2: [1387/10940] ---- BYOL Training Loss = 0.2801454961299896
30-01-2023 13:03:18 INFO Epoch 2: [1398/10940] ---- BYOL Training Loss = 0.3071231245994568
30-01-2023 13:03:45 INFO Epoch 2: [1409/10940] ---- BYOL Training Loss = 0.2879382371902466
30-01-2023 13:05:13 INFO Epoch 2: [1409/10940] ---- BYOL Validation Loss = 0.2853865921497345
30-01-2023 13:05:41 INFO Epoch 2: [1420/10940] ---- BYOL Training Loss = 0.28582507371902466
30-01-2023 13:06:08 INFO Epoch 2: [1431/10940] ---- BYOL Training Loss = 0.27690187096595764
30-01-2023 13:06:36 INFO Epoch 2: [1442/10940] ---- BYOL Training Loss = 0.29807594418525696
30-01-2023 13:07:03 INFO Epoch 2: [1453/10940] ---- BYOL Training Loss = 0.28691673278808594
30-01-2023 13:08:31 INFO Epoch 2: [1453/10940] ---- BYOL Validation Loss = 0.28443875908851624
30-01-2023 13:08:59 INFO Epoch 2: [1464/10940] ---- BYOL Training Loss = 0.2819504737854004
30-01-2023 13:09:26 INFO Epoch 2: [1475/10940] ---- BYOL Training Loss = 0.2809205651283264
30-01-2023 13:09:54 INFO Epoch 2: [1486/10940] ---- BYOL Training Loss = 0.28005966544151306
30-01-2023 13:10:22 INFO Epoch 2: [1497/10940] ---- BYOL Training Loss = 0.30411407351493835
30-01-2023 13:11:49 INFO Epoch 2: [1497/10940] ---- BYOL Validation Loss = 0.28884458541870117
30-01-2023 13:12:17 INFO Epoch 2: [1508/10940] ---- BYOL Training Loss = 0.31611496210098267
30-01-2023 13:12:45 INFO Epoch 2: [1519/10940] ---- BYOL Training Loss = 0.32051897048950195
30-01-2023 13:13:12 INFO Epoch 2: [1530/10940] ---- BYOL Training Loss = 0.3070862293243408
30-01-2023 13:13:40 INFO Epoch 2: [1541/10940] ---- BYOL Training Loss = 0.2875922620296478
30-01-2023 13:15:07 INFO Epoch 2: [1541/10940] ---- BYOL Validation Loss = 0.2915087342262268
30-01-2023 13:15:36 INFO Epoch 2: [1552/10940] ---- BYOL Training Loss = 0.33336400985717773
30-01-2023 13:16:03 INFO Epoch 2: [1563/10940] ---- BYOL Training Loss = 0.32042109966278076
30-01-2023 13:16:31 INFO Epoch 2: [1574/10940] ---- BYOL Training Loss = 0.2686958909034729
30-01-2023 13:16:58 INFO Epoch 2: [1585/10940] ---- BYOL Training Loss = 0.27096301317214966
30-01-2023 13:18:26 INFO Epoch 2: [1585/10940] ---- BYOL Validation Loss = 0.2786540389060974
30-01-2023 13:18:54 INFO Epoch 2: [1596/10940] ---- BYOL Training Loss = 0.2583981454372406
30-01-2023 13:19:21 INFO Epoch 2: [1607/10940] ---- BYOL Training Loss = 0.2574862241744995
30-01-2023 13:19:49 INFO Epoch 2: [1618/10940] ---- BYOL Training Loss = 0.28533539175987244
30-01-2023 13:20:17 INFO Epoch 2: [1629/10940] ---- BYOL Training Loss = 0.32420313358306885
30-01-2023 13:21:45 INFO Epoch 2: [1629/10940] ---- BYOL Validation Loss = 0.27342143654823303
30-01-2023 13:22:12 INFO Epoch 2: [1640/10940] ---- BYOL Training Loss = 0.30184823274612427
30-01-2023 13:22:40 INFO Epoch 2: [1651/10940] ---- BYOL Training Loss = 0.265835702419281
30-01-2023 13:23:08 INFO Epoch 2: [1662/10940] ---- BYOL Training Loss = 0.2891388535499573
30-01-2023 13:23:36 INFO Epoch 2: [1673/10940] ---- BYOL Training Loss = 0.2868756651878357
30-01-2023 13:25:03 INFO Epoch 2: [1673/10940] ---- BYOL Validation Loss = 0.2774026393890381
30-01-2023 13:25:31 INFO Epoch 2: [1684/10940] ---- BYOL Training Loss = 0.2935864329338074
30-01-2023 13:25:58 INFO Epoch 2: [1695/10940] ---- BYOL Training Loss = 0.28643837571144104
30-01-2023 13:26:26 INFO Epoch 2: [1706/10940] ---- BYOL Training Loss = 0.2559809982776642
30-01-2023 13:26:54 INFO Epoch 2: [1717/10940] ---- BYOL Training Loss = 0.2920002341270447
30-01-2023 13:28:22 INFO Epoch 2: [1717/10940] ---- BYOL Validation Loss = 0.29077720642089844
30-01-2023 13:28:49 INFO Epoch 2: [1728/10940] ---- BYOL Training Loss = 0.29608356952667236
30-01-2023 13:29:17 INFO Epoch 2: [1739/10940] ---- BYOL Training Loss = 0.2660996615886688
30-01-2023 13:29:45 INFO Epoch 2: [1750/10940] ---- BYOL Training Loss = 0.24181142449378967
30-01-2023 13:30:13 INFO Epoch 2: [1761/10940] ---- BYOL Training Loss = 0.2849462628364563
30-01-2023 13:31:41 INFO Epoch 2: [1761/10940] ---- BYOL Validation Loss = 0.2761380970478058
30-01-2023 13:32:08 INFO Epoch 2: [1772/10940] ---- BYOL Training Loss = 0.302276611328125
30-01-2023 13:32:36 INFO Epoch 2: [1783/10940] ---- BYOL Training Loss = 0.3036632835865021
30-01-2023 13:33:04 INFO Epoch 2: [1794/10940] ---- BYOL Training Loss = 0.30507293343544006
30-01-2023 13:33:31 INFO Epoch 2: [1805/10940] ---- BYOL Training Loss = 0.2723211944103241
30-01-2023 13:34:59 INFO Epoch 2: [1805/10940] ---- BYOL Validation Loss = 0.27313169836997986
30-01-2023 13:35:26 INFO Epoch 2: [1816/10940] ---- BYOL Training Loss = 0.3080332577228546
30-01-2023 13:35:54 INFO Epoch 2: [1827/10940] ---- BYOL Training Loss = 0.28697261214256287
30-01-2023 13:36:23 INFO Epoch 2: [1838/10940] ---- BYOL Training Loss = 0.2585863769054413
30-01-2023 13:36:50 INFO Epoch 2: [1849/10940] ---- BYOL Training Loss = 0.2661746144294739
30-01-2023 13:38:18 INFO Epoch 2: [1849/10940] ---- BYOL Validation Loss = 0.2686813771724701
30-01-2023 13:38:45 INFO Epoch 2: [1860/10940] ---- BYOL Training Loss = 0.25351518392562866
30-01-2023 13:39:13 INFO Epoch 2: [1871/10940] ---- BYOL Training Loss = 0.25843483209609985
30-01-2023 13:39:41 INFO Epoch 2: [1882/10940] ---- BYOL Training Loss = 0.2732577621936798
30-01-2023 13:40:09 INFO Epoch 2: [1893/10940] ---- BYOL Training Loss = 0.2958945631980896
30-01-2023 13:41:36 INFO Epoch 2: [1893/10940] ---- BYOL Validation Loss = 0.272953063249588
30-01-2023 13:42:04 INFO Epoch 2: [1904/10940] ---- BYOL Training Loss = 0.283792108297348
30-01-2023 13:42:32 INFO Epoch 2: [1915/10940] ---- BYOL Training Loss = 0.25724515318870544
30-01-2023 13:42:59 INFO Epoch 2: [1926/10940] ---- BYOL Training Loss = 0.25996285676956177
30-01-2023 13:43:27 INFO Epoch 2: [1937/10940] ---- BYOL Training Loss = 0.30121931433677673
30-01-2023 13:44:55 INFO Epoch 2: [1937/10940] ---- BYOL Validation Loss = 0.280152291059494
30-01-2023 13:45:23 INFO Epoch 2: [1948/10940] ---- BYOL Training Loss = 0.29588231444358826
30-01-2023 13:45:50 INFO Epoch 2: [1959/10940] ---- BYOL Training Loss = 0.2632240951061249
30-01-2023 13:46:18 INFO Epoch 2: [1970/10940] ---- BYOL Training Loss = 0.24943235516548157
30-01-2023 13:46:46 INFO Epoch 2: [1981/10940] ---- BYOL Training Loss = 0.2591134011745453
30-01-2023 13:48:14 INFO Epoch 2: [1981/10940] ---- BYOL Validation Loss = 0.27444812655448914
30-01-2023 13:48:41 INFO Epoch 2: [1992/10940] ---- BYOL Training Loss = 0.2821565866470337
30-01-2023 13:49:09 INFO Epoch 2: [2003/10940] ---- BYOL Training Loss = 0.2522655427455902
30-01-2023 13:49:37 INFO Epoch 2: [2014/10940] ---- BYOL Training Loss = 0.24887216091156006
30-01-2023 13:50:05 INFO Epoch 2: [2025/10940] ---- BYOL Training Loss = 0.2821032404899597
30-01-2023 13:51:33 INFO Epoch 2: [2025/10940] ---- BYOL Validation Loss = 0.2827760577201843
30-01-2023 13:52:01 INFO Epoch 2: [2036/10940] ---- BYOL Training Loss = 0.28821465373039246
30-01-2023 13:52:28 INFO Epoch 2: [2047/10940] ---- BYOL Training Loss = 0.3114855885505676
30-01-2023 13:52:56 INFO Epoch 2: [2058/10940] ---- BYOL Training Loss = 0.32462334632873535
30-01-2023 13:53:24 INFO Epoch 2: [2069/10940] ---- BYOL Training Loss = 0.28954535722732544
30-01-2023 13:54:52 INFO Epoch 2: [2069/10940] ---- BYOL Validation Loss = 0.2641512155532837
30-01-2023 13:55:20 INFO Epoch 2: [2080/10940] ---- BYOL Training Loss = 0.30443117022514343
30-01-2023 13:55:47 INFO Epoch 2: [2091/10940] ---- BYOL Training Loss = 0.2955814301967621
30-01-2023 13:56:15 INFO Epoch 2: [2102/10940] ---- BYOL Training Loss = 0.30391618609428406
30-01-2023 13:56:43 INFO Epoch 2: [2113/10940] ---- BYOL Training Loss = 0.32624945044517517
30-01-2023 13:58:11 INFO Epoch 2: [2113/10940] ---- BYOL Validation Loss = 0.2863914668560028
30-01-2023 13:58:39 INFO Epoch 2: [2124/10940] ---- BYOL Training Loss = 0.3385961651802063
30-01-2023 13:59:06 INFO Epoch 2: [2135/10940] ---- BYOL Training Loss = 0.3053153157234192
30-01-2023 13:59:34 INFO Epoch 2: [2146/10940] ---- BYOL Training Loss = 0.28192806243896484
30-01-2023 14:00:02 INFO Epoch 2: [2157/10940] ---- BYOL Training Loss = 0.30443668365478516
30-01-2023 14:01:29 INFO Epoch 2: [2157/10940] ---- BYOL Validation Loss = 0.28008800745010376
30-01-2023 14:01:58 INFO Epoch 2: [2168/10940] ---- BYOL Training Loss = 0.33353206515312195
30-01-2023 14:02:26 INFO Epoch 2: [2179/10940] ---- BYOL Training Loss = 0.2933982014656067
30-01-2023 14:02:54 INFO Epoch 2: [2190/10940] ---- BYOL Training Loss = 0.25988712906837463
30-01-2023 14:03:22 INFO Epoch 2: [2201/10940] ---- BYOL Training Loss = 0.3118496537208557
30-01-2023 14:04:50 INFO Epoch 2: [2201/10940] ---- BYOL Validation Loss = 0.2710380554199219
30-01-2023 14:05:17 INFO Epoch 2: [2212/10940] ---- BYOL Training Loss = 0.33687397837638855
30-01-2023 14:05:45 INFO Epoch 2: [2223/10940] ---- BYOL Training Loss = 0.3154033124446869
30-01-2023 14:06:13 INFO Epoch 2: [2234/10940] ---- BYOL Training Loss = 0.26530471444129944
30-01-2023 14:06:40 INFO Epoch 2: [2245/10940] ---- BYOL Training Loss = 0.25972601771354675
30-01-2023 14:08:08 INFO Epoch 2: [2245/10940] ---- BYOL Validation Loss = 0.2690031826496124
30-01-2023 14:08:36 INFO Epoch 2: [2256/10940] ---- BYOL Training Loss = 0.2851114869117737
30-01-2023 14:09:03 INFO Epoch 2: [2267/10940] ---- BYOL Training Loss = 0.26678889989852905
30-01-2023 14:09:31 INFO Epoch 2: [2278/10940] ---- BYOL Training Loss = 0.2793654799461365
30-01-2023 14:09:59 INFO Epoch 2: [2289/10940] ---- BYOL Training Loss = 0.27742964029312134
30-01-2023 14:11:27 INFO Epoch 2: [2289/10940] ---- BYOL Validation Loss = 0.26514488458633423
30-01-2023 14:11:54 INFO Epoch 2: [2300/10940] ---- BYOL Training Loss = 0.2655346393585205
30-01-2023 14:12:22 INFO Epoch 2: [2311/10940] ---- BYOL Training Loss = 0.2567524015903473
30-01-2023 14:12:50 INFO Epoch 2: [2322/10940] ---- BYOL Training Loss = 0.2887827754020691
30-01-2023 14:13:18 INFO Epoch 2: [2333/10940] ---- BYOL Training Loss = 0.31201106309890747
30-01-2023 14:14:46 INFO Epoch 2: [2333/10940] ---- BYOL Validation Loss = 0.26977795362472534
30-01-2023 14:15:13 INFO Epoch 2: [2344/10940] ---- BYOL Training Loss = 0.2681918144226074
30-01-2023 14:15:41 INFO Epoch 2: [2355/10940] ---- BYOL Training Loss = 0.2541986405849457
30-01-2023 14:16:09 INFO Epoch 2: [2366/10940] ---- BYOL Training Loss = 0.3051299750804901
30-01-2023 14:16:36 INFO Epoch 2: [2377/10940] ---- BYOL Training Loss = 0.30840763449668884
30-01-2023 14:18:04 INFO Epoch 2: [2377/10940] ---- BYOL Validation Loss = 0.2685887813568115
30-01-2023 14:18:32 INFO Epoch 2: [2388/10940] ---- BYOL Training Loss = 0.27964454889297485
30-01-2023 14:19:00 INFO Epoch 2: [2399/10940] ---- BYOL Training Loss = 0.2847493290901184
30-01-2023 14:19:28 INFO Epoch 2: [2410/10940] ---- BYOL Training Loss = 0.2822922468185425
30-01-2023 14:19:55 INFO Epoch 2: [2421/10940] ---- BYOL Training Loss = 0.27614831924438477
30-01-2023 14:21:23 INFO Epoch 2: [2421/10940] ---- BYOL Validation Loss = 0.27172353863716125
30-01-2023 14:21:51 INFO Epoch 2: [2432/10940] ---- BYOL Training Loss = 0.26081740856170654
30-01-2023 14:22:18 INFO Epoch 2: [2443/10940] ---- BYOL Training Loss = 0.2865564227104187
30-01-2023 14:22:46 INFO Epoch 2: [2454/10940] ---- BYOL Training Loss = 0.31877923011779785
30-01-2023 14:23:14 INFO Epoch 2: [2465/10940] ---- BYOL Training Loss = 0.29371175169944763
30-01-2023 14:24:42 INFO Epoch 2: [2465/10940] ---- BYOL Validation Loss = 0.2629697322845459
30-01-2023 14:25:10 INFO Epoch 2: [2476/10940] ---- BYOL Training Loss = 0.25981980562210083
30-01-2023 14:25:38 INFO Epoch 2: [2487/10940] ---- BYOL Training Loss = 0.2767067849636078
30-01-2023 14:26:05 INFO Epoch 2: [2498/10940] ---- BYOL Training Loss = 0.2775344252586365
30-01-2023 14:26:33 INFO Epoch 2: [2509/10940] ---- BYOL Training Loss = 0.24496769905090332
30-01-2023 14:28:00 INFO Epoch 2: [2509/10940] ---- BYOL Validation Loss = 0.26384639739990234
30-01-2023 14:28:28 INFO Epoch 2: [2520/10940] ---- BYOL Training Loss = 0.22261464595794678
30-01-2023 14:28:56 INFO Epoch 2: [2531/10940] ---- BYOL Training Loss = 0.21318098902702332
30-01-2023 14:29:24 INFO Epoch 2: [2542/10940] ---- BYOL Training Loss = 0.22673086822032928
30-01-2023 14:29:51 INFO Epoch 2: [2553/10940] ---- BYOL Training Loss = 0.25726932287216187
30-01-2023 14:31:19 INFO Epoch 2: [2553/10940] ---- BYOL Validation Loss = 0.26464560627937317
30-01-2023 14:31:47 INFO Epoch 2: [2564/10940] ---- BYOL Training Loss = 0.29256191849708557
30-01-2023 14:32:15 INFO Epoch 2: [2575/10940] ---- BYOL Training Loss = 0.24287155270576477
30-01-2023 14:32:43 INFO Epoch 2: [2586/10940] ---- BYOL Training Loss = 0.23873934149742126
30-01-2023 14:33:10 INFO Epoch 2: [2597/10940] ---- BYOL Training Loss = 0.2567675709724426
30-01-2023 14:34:38 INFO Epoch 2: [2597/10940] ---- BYOL Validation Loss = 0.2730388939380646
30-01-2023 14:35:06 INFO Epoch 2: [2608/10940] ---- BYOL Training Loss = 0.26427987217903137
30-01-2023 14:35:34 INFO Epoch 2: [2619/10940] ---- BYOL Training Loss = 0.2889168858528137
30-01-2023 14:36:01 INFO Epoch 2: [2630/10940] ---- BYOL Training Loss = 0.2722170650959015
30-01-2023 14:36:29 INFO Epoch 2: [2641/10940] ---- BYOL Training Loss = 0.2796439528465271
30-01-2023 14:37:57 INFO Epoch 2: [2641/10940] ---- BYOL Validation Loss = 0.25644606351852417
30-01-2023 14:38:24 INFO Epoch 2: [2652/10940] ---- BYOL Training Loss = 0.2865680158138275
30-01-2023 14:38:52 INFO Epoch 2: [2663/10940] ---- BYOL Training Loss = 0.2755487561225891
30-01-2023 14:39:20 INFO Epoch 2: [2674/10940] ---- BYOL Training Loss = 0.2460993528366089
30-01-2023 14:39:48 INFO Epoch 2: [2685/10940] ---- BYOL Training Loss = 0.2540287971496582
30-01-2023 14:41:15 INFO Epoch 2: [2685/10940] ---- BYOL Validation Loss = 0.26970067620277405
30-01-2023 14:41:43 INFO Epoch 2: [2696/10940] ---- BYOL Training Loss = 0.26558804512023926
30-01-2023 14:42:11 INFO Epoch 2: [2707/10940] ---- BYOL Training Loss = 0.24757952988147736
30-01-2023 14:42:38 INFO Epoch 2: [2718/10940] ---- BYOL Training Loss = 0.29991307854652405
30-01-2023 14:43:06 INFO Epoch 2: [2729/10940] ---- BYOL Training Loss = 0.29061949253082275
30-01-2023 14:44:34 INFO Epoch 2: [2729/10940] ---- BYOL Validation Loss = 0.2690674960613251
30-01-2023 14:45:01 INFO Epoch 2: [2740/10940] ---- BYOL Training Loss = 0.23077502846717834
30-01-2023 14:45:30 INFO Epoch 2: [2751/10940] ---- BYOL Training Loss = 0.26016753911972046
30-01-2023 14:45:57 INFO Epoch 2: [2762/10940] ---- BYOL Training Loss = 0.2687463164329529
30-01-2023 14:46:25 INFO Epoch 2: [2773/10940] ---- BYOL Training Loss = 0.2877616584300995
30-01-2023 14:47:53 INFO Epoch 2: [2773/10940] ---- BYOL Validation Loss = 0.2658332884311676
30-01-2023 14:48:21 INFO Epoch 2: [2784/10940] ---- BYOL Training Loss = 0.29592305421829224
30-01-2023 14:48:48 INFO Epoch 2: [2795/10940] ---- BYOL Training Loss = 0.3102964162826538
30-01-2023 14:49:16 INFO Epoch 2: [2806/10940] ---- BYOL Training Loss = 0.3073636591434479
30-01-2023 14:49:44 INFO Epoch 2: [2817/10940] ---- BYOL Training Loss = 0.2700883746147156
30-01-2023 14:51:11 INFO Epoch 2: [2817/10940] ---- BYOL Validation Loss = 0.27418917417526245
30-01-2023 14:51:40 INFO Epoch 2: [2828/10940] ---- BYOL Training Loss = 0.24102719128131866
30-01-2023 14:52:07 INFO Epoch 2: [2839/10940] ---- BYOL Training Loss = 0.2616848349571228
30-01-2023 14:52:35 INFO Epoch 2: [2850/10940] ---- BYOL Training Loss = 0.26632022857666016
30-01-2023 14:53:03 INFO Epoch 2: [2861/10940] ---- BYOL Training Loss = 0.2986341118812561
30-01-2023 14:54:31 INFO Epoch 2: [2861/10940] ---- BYOL Validation Loss = 0.2717956602573395
30-01-2023 14:54:58 INFO Epoch 2: [2872/10940] ---- BYOL Training Loss = 0.28698790073394775
30-01-2023 14:55:26 INFO Epoch 2: [2883/10940] ---- BYOL Training Loss = 0.264771044254303
30-01-2023 14:55:54 INFO Epoch 2: [2894/10940] ---- BYOL Training Loss = 0.2765047252178192
30-01-2023 14:56:22 INFO Epoch 2: [2905/10940] ---- BYOL Training Loss = 0.30133652687072754
30-01-2023 14:57:49 INFO Epoch 2: [2905/10940] ---- BYOL Validation Loss = 0.27560847997665405
30-01-2023 14:58:17 INFO Epoch 2: [2916/10940] ---- BYOL Training Loss = 0.304909348487854
30-01-2023 14:58:45 INFO Epoch 2: [2927/10940] ---- BYOL Training Loss = 0.2664411664009094
30-01-2023 14:59:13 INFO Epoch 2: [2938/10940] ---- BYOL Training Loss = 0.24595840275287628
30-01-2023 14:59:41 INFO Epoch 2: [2949/10940] ---- BYOL Training Loss = 0.30220165848731995
30-01-2023 15:01:08 INFO Epoch 2: [2949/10940] ---- BYOL Validation Loss = 0.272538423538208
30-01-2023 15:01:36 INFO Epoch 2: [2960/10940] ---- BYOL Training Loss = 0.28117483854293823
30-01-2023 15:02:04 INFO Epoch 2: [2971/10940] ---- BYOL Training Loss = 0.2581086754798889
30-01-2023 15:02:32 INFO Epoch 2: [2982/10940] ---- BYOL Training Loss = 0.25642359256744385
30-01-2023 15:03:00 INFO Epoch 2: [2993/10940] ---- BYOL Training Loss = 0.29708948731422424
30-01-2023 15:04:27 INFO Epoch 2: [2993/10940] ---- BYOL Validation Loss = 0.36398568749427795
30-01-2023 15:04:55 INFO Epoch 2: [3004/10940] ---- BYOL Training Loss = 0.3390095829963684
30-01-2023 15:05:23 INFO Epoch 2: [3015/10940] ---- BYOL Training Loss = 0.30364930629730225
30-01-2023 15:05:51 INFO Epoch 2: [3026/10940] ---- BYOL Training Loss = 0.2879699468612671
30-01-2023 15:06:19 INFO Epoch 2: [3037/10940] ---- BYOL Training Loss = 0.2965618371963501
30-01-2023 15:07:46 INFO Epoch 2: [3037/10940] ---- BYOL Validation Loss = 0.2667798101902008
30-01-2023 15:08:15 INFO Epoch 2: [3048/10940] ---- BYOL Training Loss = 0.31494754552841187
30-01-2023 15:08:42 INFO Epoch 2: [3059/10940] ---- BYOL Training Loss = 0.28292351961135864
30-01-2023 15:09:10 INFO Epoch 2: [3070/10940] ---- BYOL Training Loss = 0.26666292548179626
30-01-2023 15:09:38 INFO Epoch 2: [3081/10940] ---- BYOL Training Loss = 0.24026720225811005
30-01-2023 15:11:06 INFO Epoch 2: [3081/10940] ---- BYOL Validation Loss = 0.2624352276325226
30-01-2023 15:11:34 INFO Epoch 2: [3092/10940] ---- BYOL Training Loss = 0.24051377177238464
30-01-2023 15:12:02 INFO Epoch 2: [3103/10940] ---- BYOL Training Loss = 0.2649560570716858
30-01-2023 15:12:29 INFO Epoch 2: [3114/10940] ---- BYOL Training Loss = 0.2957006096839905
30-01-2023 15:12:57 INFO Epoch 2: [3125/10940] ---- BYOL Training Loss = 0.24713733792304993
30-01-2023 15:14:25 INFO Epoch 2: [3125/10940] ---- BYOL Validation Loss = 0.26244962215423584
30-01-2023 15:14:53 INFO Epoch 2: [3136/10940] ---- BYOL Training Loss = 0.2325078248977661
30-01-2023 15:15:21 INFO Epoch 2: [3147/10940] ---- BYOL Training Loss = 0.27229979634284973
30-01-2023 15:15:49 INFO Epoch 2: [3158/10940] ---- BYOL Training Loss = 0.2745421826839447
30-01-2023 15:16:17 INFO Epoch 2: [3169/10940] ---- BYOL Training Loss = 0.2771039307117462
30-01-2023 15:17:44 INFO Epoch 2: [3169/10940] ---- BYOL Validation Loss = 0.27403008937835693
30-01-2023 15:18:12 INFO Epoch 2: [3180/10940] ---- BYOL Training Loss = 0.33809322118759155
30-01-2023 15:18:40 INFO Epoch 2: [3191/10940] ---- BYOL Training Loss = 0.2703523635864258
30-01-2023 15:19:08 INFO Epoch 2: [3202/10940] ---- BYOL Training Loss = 0.24008715152740479
30-01-2023 15:19:36 INFO Epoch 2: [3213/10940] ---- BYOL Training Loss = 0.2811952829360962
30-01-2023 15:21:04 INFO Epoch 2: [3213/10940] ---- BYOL Validation Loss = 0.2679983675479889
30-01-2023 15:21:31 INFO Epoch 2: [3224/10940] ---- BYOL Training Loss = 0.27692145109176636
30-01-2023 15:21:59 INFO Epoch 2: [3235/10940] ---- BYOL Training Loss = 0.26821279525756836
30-01-2023 15:22:27 INFO Epoch 2: [3246/10940] ---- BYOL Training Loss = 0.2855280637741089
30-01-2023 15:22:55 INFO Epoch 2: [3257/10940] ---- BYOL Training Loss = 0.2766026556491852
30-01-2023 15:24:23 INFO Epoch 2: [3257/10940] ---- BYOL Validation Loss = 0.26192179322242737
30-01-2023 15:24:51 INFO Epoch 2: [3268/10940] ---- BYOL Training Loss = 0.3031449615955353
30-01-2023 15:25:19 INFO Epoch 2: [3279/10940] ---- BYOL Training Loss = 0.2792634963989258
30-01-2023 15:25:47 INFO Epoch 2: [3290/10940] ---- BYOL Training Loss = 0.27694541215896606
30-01-2023 15:26:15 INFO Epoch 2: [3301/10940] ---- BYOL Training Loss = 0.2856143116950989
30-01-2023 15:27:43 INFO Epoch 2: [3301/10940] ---- BYOL Validation Loss = 0.26127296686172485
30-01-2023 15:28:11 INFO Epoch 2: [3312/10940] ---- BYOL Training Loss = 0.2892938554286957
30-01-2023 15:28:39 INFO Epoch 2: [3323/10940] ---- BYOL Training Loss = 0.2631133198738098
30-01-2023 15:29:06 INFO Epoch 2: [3334/10940] ---- BYOL Training Loss = 0.24824826419353485
30-01-2023 15:29:34 INFO Epoch 2: [3345/10940] ---- BYOL Training Loss = 0.24525947868824005
30-01-2023 15:31:02 INFO Epoch 2: [3345/10940] ---- BYOL Validation Loss = 0.26678863167762756
30-01-2023 15:31:30 INFO Epoch 2: [3356/10940] ---- BYOL Training Loss = 0.24579651653766632
30-01-2023 15:31:58 INFO Epoch 2: [3367/10940] ---- BYOL Training Loss = 0.25858020782470703
30-01-2023 15:32:26 INFO Epoch 2: [3378/10940] ---- BYOL Training Loss = 0.2630915939807892
30-01-2023 15:32:53 INFO Epoch 2: [3389/10940] ---- BYOL Training Loss = 0.26221799850463867
30-01-2023 15:34:21 INFO Epoch 2: [3389/10940] ---- BYOL Validation Loss = 0.2553292214870453
30-01-2023 15:34:49 INFO Epoch 2: [3400/10940] ---- BYOL Training Loss = 0.2586933970451355
30-01-2023 15:35:17 INFO Epoch 2: [3411/10940] ---- BYOL Training Loss = 0.2823980450630188
30-01-2023 15:35:45 INFO Epoch 2: [3422/10940] ---- BYOL Training Loss = 0.31037646532058716
30-01-2023 15:36:13 INFO Epoch 2: [3433/10940] ---- BYOL Training Loss = 0.27866584062576294
30-01-2023 15:37:41 INFO Epoch 2: [3433/10940] ---- BYOL Validation Loss = 0.2638644278049469
30-01-2023 15:38:09 INFO Epoch 2: [3444/10940] ---- BYOL Training Loss = 0.2651800513267517
30-01-2023 15:38:37 INFO Epoch 2: [3455/10940] ---- BYOL Training Loss = 0.2589258849620819
30-01-2023 15:39:05 INFO Epoch 2: [3466/10940] ---- BYOL Training Loss = 0.26223644614219666
30-01-2023 15:39:32 INFO Epoch 2: [3477/10940] ---- BYOL Training Loss = 0.2451130896806717
30-01-2023 15:41:00 INFO Epoch 2: [3477/10940] ---- BYOL Validation Loss = 0.2637273371219635
30-01-2023 15:41:28 INFO Epoch 2: [3488/10940] ---- BYOL Training Loss = 0.24360108375549316
30-01-2023 15:41:56 INFO Epoch 2: [3499/10940] ---- BYOL Training Loss = 0.2539219558238983
30-01-2023 15:42:24 INFO Epoch 2: [3510/10940] ---- BYOL Training Loss = 0.26301732659339905
30-01-2023 15:42:52 INFO Epoch 2: [3521/10940] ---- BYOL Training Loss = 0.27907103300094604
30-01-2023 15:44:20 INFO Epoch 2: [3521/10940] ---- BYOL Validation Loss = 0.256721168756485
30-01-2023 15:44:48 INFO Epoch 2: [3532/10940] ---- BYOL Training Loss = 0.2911433279514313
30-01-2023 15:45:16 INFO Epoch 2: [3543/10940] ---- BYOL Training Loss = 0.30529555678367615
30-01-2023 15:45:43 INFO Epoch 2: [3554/10940] ---- BYOL Training Loss = 0.32132837176322937
30-01-2023 15:46:12 INFO Epoch 2: [3565/10940] ---- BYOL Training Loss = 0.31544139981269836
30-01-2023 15:47:39 INFO Epoch 2: [3565/10940] ---- BYOL Validation Loss = 0.25900718569755554
30-01-2023 15:48:07 INFO Epoch 2: [3576/10940] ---- BYOL Training Loss = 0.27999237179756165
30-01-2023 15:48:35 INFO Epoch 2: [3587/10940] ---- BYOL Training Loss = 0.269067645072937
30-01-2023 15:49:03 INFO Epoch 2: [3598/10940] ---- BYOL Training Loss = 0.257595956325531
30-01-2023 15:49:31 INFO Epoch 2: [3609/10940] ---- BYOL Training Loss = 0.24320712685585022
30-01-2023 15:50:59 INFO Epoch 2: [3609/10940] ---- BYOL Validation Loss = 0.25710806250572205
30-01-2023 15:51:27 INFO Epoch 2: [3620/10940] ---- BYOL Training Loss = 0.25557956099510193
30-01-2023 15:51:55 INFO Epoch 2: [3631/10940] ---- BYOL Training Loss = 0.2597002685070038
30-01-2023 15:52:22 INFO Epoch 2: [3642/10940] ---- BYOL Training Loss = 0.2867031693458557
30-01-2023 15:52:50 INFO Epoch 2: [3653/10940] ---- BYOL Training Loss = 0.2695755958557129
30-01-2023 15:54:18 INFO Epoch 2: [3653/10940] ---- BYOL Validation Loss = 0.25663232803344727
30-01-2023 15:54:46 INFO Epoch 2: [3664/10940] ---- BYOL Training Loss = 0.28115516901016235
30-01-2023 15:55:14 INFO Epoch 2: [3675/10940] ---- BYOL Training Loss = 0.2800646126270294
30-01-2023 15:55:42 INFO Epoch 2: [3686/10940] ---- BYOL Training Loss = 0.2572484612464905
30-01-2023 15:56:10 INFO Epoch 2: [3697/10940] ---- BYOL Training Loss = 0.2752031981945038
30-01-2023 15:57:38 INFO Epoch 2: [3697/10940] ---- BYOL Validation Loss = 0.2679464817047119
30-01-2023 15:58:06 INFO Epoch 2: [3708/10940] ---- BYOL Training Loss = 0.2663068175315857
30-01-2023 15:58:34 INFO Epoch 2: [3719/10940] ---- BYOL Training Loss = 0.2924131751060486
30-01-2023 15:59:02 INFO Epoch 2: [3730/10940] ---- BYOL Training Loss = 0.3063949644565582
30-01-2023 15:59:30 INFO Epoch 2: [3741/10940] ---- BYOL Training Loss = 0.30244025588035583
30-01-2023 16:00:57 INFO Epoch 2: [3741/10940] ---- BYOL Validation Loss = 0.2636672258377075
30-01-2023 16:01:25 INFO Epoch 2: [3752/10940] ---- BYOL Training Loss = 0.27761590480804443
30-01-2023 16:01:53 INFO Epoch 2: [3763/10940] ---- BYOL Training Loss = 0.2590840756893158
30-01-2023 16:02:21 INFO Epoch 2: [3774/10940] ---- BYOL Training Loss = 0.24748797714710236
30-01-2023 16:02:49 INFO Epoch 2: [3785/10940] ---- BYOL Training Loss = 0.26864102482795715
30-01-2023 16:04:17 INFO Epoch 2: [3785/10940] ---- BYOL Validation Loss = 0.2598981559276581
30-01-2023 16:04:45 INFO Epoch 2: [3796/10940] ---- BYOL Training Loss = 0.2662028670310974
30-01-2023 16:05:12 INFO Epoch 2: [3807/10940] ---- BYOL Training Loss = 0.2765408754348755
30-01-2023 16:05:40 INFO Epoch 2: [3818/10940] ---- BYOL Training Loss = 0.2987831234931946
30-01-2023 16:06:08 INFO Epoch 2: [3829/10940] ---- BYOL Training Loss = 0.2870200276374817
30-01-2023 16:07:36 INFO Epoch 2: [3829/10940] ---- BYOL Validation Loss = 0.2613960802555084
30-01-2023 16:08:04 INFO Epoch 2: [3840/10940] ---- BYOL Training Loss = 0.2774074673652649
30-01-2023 16:08:32 INFO Epoch 2: [3851/10940] ---- BYOL Training Loss = 0.32519593834877014
30-01-2023 16:09:00 INFO Epoch 2: [3862/10940] ---- BYOL Training Loss = 0.29852956533432007
30-01-2023 16:09:28 INFO Epoch 2: [3873/10940] ---- BYOL Training Loss = 0.2810491919517517
30-01-2023 16:10:55 INFO Epoch 2: [3873/10940] ---- BYOL Validation Loss = 0.2746883034706116
30-01-2023 16:11:23 INFO Epoch 2: [3884/10940] ---- BYOL Training Loss = 0.2553167939186096
30-01-2023 16:11:51 INFO Epoch 2: [3895/10940] ---- BYOL Training Loss = 0.2561921775341034
30-01-2023 16:12:19 INFO Epoch 2: [3906/10940] ---- BYOL Training Loss = 0.2730078101158142
30-01-2023 16:12:47 INFO Epoch 2: [3917/10940] ---- BYOL Training Loss = 0.2752806544303894
30-01-2023 16:14:15 INFO Epoch 2: [3917/10940] ---- BYOL Validation Loss = 0.26184096932411194
30-01-2023 16:14:42 INFO Epoch 2: [3928/10940] ---- BYOL Training Loss = 0.3104180097579956
30-01-2023 16:15:10 INFO Epoch 2: [3939/10940] ---- BYOL Training Loss = 0.28828880190849304
30-01-2023 16:15:38 INFO Epoch 2: [3950/10940] ---- BYOL Training Loss = 0.27553755044937134
30-01-2023 16:16:06 INFO Epoch 2: [3961/10940] ---- BYOL Training Loss = 0.2768092155456543
30-01-2023 16:17:34 INFO Epoch 2: [3961/10940] ---- BYOL Validation Loss = 0.27979785203933716
30-01-2023 16:18:02 INFO Epoch 2: [3972/10940] ---- BYOL Training Loss = 0.3116925060749054
30-01-2023 16:18:30 INFO Epoch 2: [3983/10940] ---- BYOL Training Loss = 0.2826896011829376
30-01-2023 16:18:57 INFO Epoch 2: [3994/10940] ---- BYOL Training Loss = 0.25027602910995483
30-01-2023 16:19:25 INFO Epoch 2: [4005/10940] ---- BYOL Training Loss = 0.2584376931190491
30-01-2023 16:20:53 INFO Epoch 2: [4005/10940] ---- BYOL Validation Loss = 0.2573641836643219
30-01-2023 16:21:21 INFO Epoch 2: [4016/10940] ---- BYOL Training Loss = 0.2611471116542816
30-01-2023 16:21:49 INFO Epoch 2: [4027/10940] ---- BYOL Training Loss = 0.3076976239681244
30-01-2023 16:22:16 INFO Epoch 2: [4038/10940] ---- BYOL Training Loss = 0.3048163056373596
30-01-2023 16:22:45 INFO Epoch 2: [4049/10940] ---- BYOL Training Loss = 0.2455267608165741
30-01-2023 16:24:12 INFO Epoch 2: [4049/10940] ---- BYOL Validation Loss = 0.2723514437675476
30-01-2023 16:24:40 INFO Epoch 2: [4060/10940] ---- BYOL Training Loss = 0.24000123143196106
30-01-2023 16:25:08 INFO Epoch 2: [4071/10940] ---- BYOL Training Loss = 0.24897876381874084
30-01-2023 16:25:36 INFO Epoch 2: [4082/10940] ---- BYOL Training Loss = 0.24385352432727814
30-01-2023 16:26:04 INFO Epoch 2: [4093/10940] ---- BYOL Training Loss = 0.2858784794807434
30-01-2023 16:27:32 INFO Epoch 2: [4093/10940] ---- BYOL Validation Loss = 0.2635440528392792
30-01-2023 16:27:59 INFO Epoch 2: [4104/10940] ---- BYOL Training Loss = 0.2814605236053467
30-01-2023 16:28:27 INFO Epoch 2: [4115/10940] ---- BYOL Training Loss = 0.25128769874572754
30-01-2023 16:28:55 INFO Epoch 2: [4126/10940] ---- BYOL Training Loss = 0.27841830253601074
30-01-2023 16:29:23 INFO Epoch 2: [4137/10940] ---- BYOL Training Loss = 0.269048273563385
30-01-2023 16:30:51 INFO Epoch 2: [4137/10940] ---- BYOL Validation Loss = 0.2560608685016632
30-01-2023 16:31:19 INFO Epoch 2: [4148/10940] ---- BYOL Training Loss = 0.22072701156139374
30-01-2023 16:31:47 INFO Epoch 2: [4159/10940] ---- BYOL Training Loss = 0.24133646488189697
30-01-2023 16:32:14 INFO Epoch 2: [4170/10940] ---- BYOL Training Loss = 0.32574623823165894
30-01-2023 16:32:42 INFO Epoch 2: [4181/10940] ---- BYOL Training Loss = 0.3072862923145294
30-01-2023 16:34:10 INFO Epoch 2: [4181/10940] ---- BYOL Validation Loss = 0.2650727331638336
30-01-2023 16:34:38 INFO Epoch 2: [4192/10940] ---- BYOL Training Loss = 0.27526146173477173
30-01-2023 16:35:06 INFO Epoch 2: [4203/10940] ---- BYOL Training Loss = 0.2689658999443054
30-01-2023 16:35:34 INFO Epoch 2: [4214/10940] ---- BYOL Training Loss = 0.2602953314781189
30-01-2023 16:36:02 INFO Epoch 2: [4225/10940] ---- BYOL Training Loss = 0.23749840259552002
30-01-2023 16:37:29 INFO Epoch 2: [4225/10940] ---- BYOL Validation Loss = 0.24344207346439362
30-01-2023 16:37:57 INFO Epoch 2: [4236/10940] ---- BYOL Training Loss = 0.30171334743499756
30-01-2023 16:38:25 INFO Epoch 2: [4247/10940] ---- BYOL Training Loss = 0.28886646032333374
30-01-2023 16:38:53 INFO Epoch 2: [4258/10940] ---- BYOL Training Loss = 0.24823692440986633
30-01-2023 16:39:21 INFO Epoch 2: [4269/10940] ---- BYOL Training Loss = 0.29158833622932434
30-01-2023 16:40:49 INFO Epoch 2: [4269/10940] ---- BYOL Validation Loss = 0.2666264474391937
30-01-2023 16:41:17 INFO Epoch 2: [4280/10940] ---- BYOL Training Loss = 0.294411838054657
30-01-2023 16:41:44 INFO Epoch 2: [4291/10940] ---- BYOL Training Loss = 0.24702155590057373
30-01-2023 16:42:13 INFO Epoch 2: [4302/10940] ---- BYOL Training Loss = 0.23796603083610535
30-01-2023 16:42:40 INFO Epoch 2: [4313/10940] ---- BYOL Training Loss = 0.24508950114250183
30-01-2023 16:44:08 INFO Epoch 2: [4313/10940] ---- BYOL Validation Loss = 0.24790920317173004
30-01-2023 16:44:36 INFO Epoch 2: [4324/10940] ---- BYOL Training Loss = 0.243942528963089
30-01-2023 16:45:04 INFO Epoch 2: [4335/10940] ---- BYOL Training Loss = 0.24618744850158691
30-01-2023 16:45:32 INFO Epoch 2: [4346/10940] ---- BYOL Training Loss = 0.2491457760334015
30-01-2023 16:45:59 INFO Epoch 2: [4357/10940] ---- BYOL Training Loss = 0.28176718950271606
30-01-2023 16:47:27 INFO Epoch 2: [4357/10940] ---- BYOL Validation Loss = 0.24930743873119354
30-01-2023 16:47:55 INFO Epoch 2: [4368/10940] ---- BYOL Training Loss = 0.27169114351272583
30-01-2023 16:48:23 INFO Epoch 2: [4379/10940] ---- BYOL Training Loss = 0.26348876953125
30-01-2023 16:48:51 INFO Epoch 2: [4390/10940] ---- BYOL Training Loss = 0.2665857970714569
30-01-2023 16:49:19 INFO Epoch 2: [4401/10940] ---- BYOL Training Loss = 0.26670750975608826
30-01-2023 16:50:46 INFO Epoch 2: [4401/10940] ---- BYOL Validation Loss = 0.26014789938926697
30-01-2023 16:51:14 INFO Epoch 2: [4412/10940] ---- BYOL Training Loss = 0.30648285150527954
30-01-2023 16:51:42 INFO Epoch 2: [4423/10940] ---- BYOL Training Loss = 0.2842065691947937
30-01-2023 16:52:10 INFO Epoch 2: [4434/10940] ---- BYOL Training Loss = 0.2538331151008606
30-01-2023 16:52:38 INFO Epoch 2: [4445/10940] ---- BYOL Training Loss = 0.2644585967063904
30-01-2023 16:54:06 INFO Epoch 2: [4445/10940] ---- BYOL Validation Loss = 0.2539093494415283
30-01-2023 16:54:33 INFO Epoch 2: [4456/10940] ---- BYOL Training Loss = 0.2652643322944641
30-01-2023 16:55:01 INFO Epoch 2: [4467/10940] ---- BYOL Training Loss = 0.26454973220825195
30-01-2023 16:55:30 INFO Epoch 2: [4478/10940] ---- BYOL Training Loss = 0.22820989787578583
30-01-2023 16:55:57 INFO Epoch 2: [4489/10940] ---- BYOL Training Loss = 0.26289382576942444
30-01-2023 16:57:25 INFO Epoch 2: [4489/10940] ---- BYOL Validation Loss = 0.26734352111816406
30-01-2023 16:57:53 INFO Epoch 2: [4500/10940] ---- BYOL Training Loss = 0.2997214198112488
30-01-2023 16:58:21 INFO Epoch 2: [4511/10940] ---- BYOL Training Loss = 0.2743898034095764
30-01-2023 16:58:49 INFO Epoch 2: [4522/10940] ---- BYOL Training Loss = 0.25668537616729736
30-01-2023 16:59:17 INFO Epoch 2: [4533/10940] ---- BYOL Training Loss = 0.2588103115558624
30-01-2023 17:00:44 INFO Epoch 2: [4533/10940] ---- BYOL Validation Loss = 0.2529982924461365
30-01-2023 17:01:12 INFO Epoch 2: [4544/10940] ---- BYOL Training Loss = 0.2958579361438751
30-01-2023 17:01:40 INFO Epoch 2: [4555/10940] ---- BYOL Training Loss = 0.32029032707214355
30-01-2023 17:02:08 INFO Epoch 2: [4566/10940] ---- BYOL Training Loss = 0.29718849062919617
30-01-2023 17:02:36 INFO Epoch 2: [4577/10940] ---- BYOL Training Loss = 0.30131402611732483
30-01-2023 17:04:04 INFO Epoch 2: [4577/10940] ---- BYOL Validation Loss = 0.2681771516799927
30-01-2023 17:04:32 INFO Epoch 2: [4588/10940] ---- BYOL Training Loss = 0.26098451018333435
30-01-2023 17:05:00 INFO Epoch 2: [4599/10940] ---- BYOL Training Loss = 0.26856350898742676
30-01-2023 17:05:27 INFO Epoch 2: [4610/10940] ---- BYOL Training Loss = 0.3177441656589508
30-01-2023 17:05:55 INFO Epoch 2: [4621/10940] ---- BYOL Training Loss = 0.31107962131500244
30-01-2023 17:07:23 INFO Epoch 2: [4621/10940] ---- BYOL Validation Loss = 0.2647321820259094
30-01-2023 17:07:51 INFO Epoch 2: [4632/10940] ---- BYOL Training Loss = 0.31346768140792847
30-01-2023 17:08:19 INFO Epoch 2: [4643/10940] ---- BYOL Training Loss = 0.3271788954734802
30-01-2023 17:08:47 INFO Epoch 2: [4654/10940] ---- BYOL Training Loss = 0.3153529465198517
30-01-2023 17:09:15 INFO Epoch 2: [4665/10940] ---- BYOL Training Loss = 0.2838447093963623
30-01-2023 17:10:42 INFO Epoch 2: [4665/10940] ---- BYOL Validation Loss = 0.26570582389831543
30-01-2023 17:11:10 INFO Epoch 2: [4676/10940] ---- BYOL Training Loss = 0.25919458270072937
30-01-2023 17:11:38 INFO Epoch 2: [4687/10940] ---- BYOL Training Loss = 0.27696508169174194
30-01-2023 17:12:06 INFO Epoch 2: [4698/10940] ---- BYOL Training Loss = 0.2764354646205902
30-01-2023 17:12:34 INFO Epoch 2: [4709/10940] ---- BYOL Training Loss = 0.2971903681755066
30-01-2023 17:14:02 INFO Epoch 2: [4709/10940] ---- BYOL Validation Loss = 0.25825226306915283
30-01-2023 17:14:29 INFO Epoch 2: [4720/10940] ---- BYOL Training Loss = 0.3177283704280853
30-01-2023 17:14:58 INFO Epoch 2: [4731/10940] ---- BYOL Training Loss = 0.3007045090198517
30-01-2023 17:15:26 INFO Epoch 2: [4742/10940] ---- BYOL Training Loss = 0.2955598533153534
30-01-2023 17:15:54 INFO Epoch 2: [4753/10940] ---- BYOL Training Loss = 0.27706488966941833
30-01-2023 17:17:22 INFO Epoch 2: [4753/10940] ---- BYOL Validation Loss = 0.23984062671661377
30-01-2023 17:17:50 INFO Epoch 2: [4764/10940] ---- BYOL Training Loss = 0.2642136216163635
30-01-2023 17:18:18 INFO Epoch 2: [4775/10940] ---- BYOL Training Loss = 0.24226656556129456
30-01-2023 17:18:46 INFO Epoch 2: [4786/10940] ---- BYOL Training Loss = 0.24636073410511017
30-01-2023 17:19:14 INFO Epoch 2: [4797/10940] ---- BYOL Training Loss = 0.29746249318122864
30-01-2023 17:20:41 INFO Epoch 2: [4797/10940] ---- BYOL Validation Loss = 0.25253957509994507
30-01-2023 17:21:09 INFO Epoch 2: [4808/10940] ---- BYOL Training Loss = 0.3099200427532196
30-01-2023 17:21:37 INFO Epoch 2: [4819/10940] ---- BYOL Training Loss = 0.3075447380542755
30-01-2023 17:22:05 INFO Epoch 2: [4830/10940] ---- BYOL Training Loss = 0.2972876727581024
30-01-2023 17:22:33 INFO Epoch 2: [4841/10940] ---- BYOL Training Loss = 0.25667843222618103
30-01-2023 17:24:01 INFO Epoch 2: [4841/10940] ---- BYOL Validation Loss = 0.24698124825954437
30-01-2023 17:24:28 INFO Epoch 2: [4852/10940] ---- BYOL Training Loss = 0.24284715950489044
30-01-2023 17:24:56 INFO Epoch 2: [4863/10940] ---- BYOL Training Loss = 0.2433631867170334
30-01-2023 17:25:24 INFO Epoch 2: [4874/10940] ---- BYOL Training Loss = 0.2367955893278122
30-01-2023 17:25:53 INFO Epoch 2: [4885/10940] ---- BYOL Training Loss = 0.3270668387413025
30-01-2023 17:27:20 INFO Epoch 2: [4885/10940] ---- BYOL Validation Loss = 0.27337154746055603
30-01-2023 17:27:48 INFO Epoch 2: [4896/10940] ---- BYOL Training Loss = 0.3554804027080536
30-01-2023 17:28:16 INFO Epoch 2: [4907/10940] ---- BYOL Training Loss = 0.26304560899734497
30-01-2023 17:28:44 INFO Epoch 2: [4918/10940] ---- BYOL Training Loss = 0.2472410649061203
30-01-2023 17:29:12 INFO Epoch 2: [4929/10940] ---- BYOL Training Loss = 0.28284645080566406
30-01-2023 17:30:40 INFO Epoch 2: [4929/10940] ---- BYOL Validation Loss = 0.2506999969482422
30-01-2023 17:31:08 INFO Epoch 2: [4940/10940] ---- BYOL Training Loss = 0.26554638147354126
30-01-2023 17:31:35 INFO Epoch 2: [4951/10940] ---- BYOL Training Loss = 0.29189300537109375
30-01-2023 17:32:03 INFO Epoch 2: [4962/10940] ---- BYOL Training Loss = 0.29070180654525757
30-01-2023 17:32:32 INFO Epoch 2: [4973/10940] ---- BYOL Training Loss = 0.2693813741207123
30-01-2023 17:33:59 INFO Epoch 2: [4973/10940] ---- BYOL Validation Loss = 0.2640400528907776
30-01-2023 17:34:27 INFO Epoch 2: [4984/10940] ---- BYOL Training Loss = 0.31271252036094666
30-01-2023 17:34:55 INFO Epoch 2: [4995/10940] ---- BYOL Training Loss = 0.26696518063545227
30-01-2023 17:35:23 INFO Epoch 2: [5006/10940] ---- BYOL Training Loss = 0.25322848558425903
30-01-2023 17:35:51 INFO Epoch 2: [5017/10940] ---- BYOL Training Loss = 0.2471865862607956
30-01-2023 17:37:18 INFO Epoch 2: [5017/10940] ---- BYOL Validation Loss = 0.2465154379606247
30-01-2023 17:37:47 INFO Epoch 2: [5028/10940] ---- BYOL Training Loss = 0.29434341192245483
30-01-2023 17:38:15 INFO Epoch 2: [5039/10940] ---- BYOL Training Loss = 0.3101532757282257
30-01-2023 17:38:43 INFO Epoch 2: [5050/10940] ---- BYOL Training Loss = 0.2530781328678131
30-01-2023 17:39:11 INFO Epoch 2: [5061/10940] ---- BYOL Training Loss = 0.26061341166496277
30-01-2023 17:40:38 INFO Epoch 2: [5061/10940] ---- BYOL Validation Loss = 0.26574286818504333
30-01-2023 17:41:07 INFO Epoch 2: [5072/10940] ---- BYOL Training Loss = 0.3162402808666229
30-01-2023 17:41:35 INFO Epoch 2: [5083/10940] ---- BYOL Training Loss = 0.3012063205242157
30-01-2023 17:42:03 INFO Epoch 2: [5094/10940] ---- BYOL Training Loss = 0.3075888454914093
30-01-2023 17:42:30 INFO Epoch 2: [5105/10940] ---- BYOL Training Loss = 0.28715795278549194
30-01-2023 17:43:58 INFO Epoch 2: [5105/10940] ---- BYOL Validation Loss = 0.2579006850719452
30-01-2023 17:44:26 INFO Epoch 2: [5116/10940] ---- BYOL Training Loss = 0.2651287615299225
30-01-2023 17:44:54 INFO Epoch 2: [5127/10940] ---- BYOL Training Loss = 0.258584201335907
30-01-2023 17:45:22 INFO Epoch 2: [5138/10940] ---- BYOL Training Loss = 0.27410298585891724
30-01-2023 17:45:50 INFO Epoch 2: [5149/10940] ---- BYOL Training Loss = 0.29760342836380005
30-01-2023 17:47:18 INFO Epoch 2: [5149/10940] ---- BYOL Validation Loss = 0.25636470317840576
30-01-2023 17:47:46 INFO Epoch 2: [5160/10940] ---- BYOL Training Loss = 0.3093939423561096
30-01-2023 17:48:14 INFO Epoch 2: [5171/10940] ---- BYOL Training Loss = 0.30502384901046753
30-01-2023 17:48:42 INFO Epoch 2: [5182/10940] ---- BYOL Training Loss = 0.3113214373588562
30-01-2023 17:49:10 INFO Epoch 2: [5193/10940] ---- BYOL Training Loss = 0.27218887209892273
30-01-2023 17:50:38 INFO Epoch 2: [5193/10940] ---- BYOL Validation Loss = 0.25873440504074097
30-01-2023 17:51:06 INFO Epoch 2: [5204/10940] ---- BYOL Training Loss = 0.2827262878417969
30-01-2023 17:51:34 INFO Epoch 2: [5215/10940] ---- BYOL Training Loss = 0.30295681953430176
30-01-2023 17:52:02 INFO Epoch 2: [5226/10940] ---- BYOL Training Loss = 0.27526676654815674
30-01-2023 17:52:30 INFO Epoch 2: [5237/10940] ---- BYOL Training Loss = 0.23105576634407043
30-01-2023 17:53:58 INFO Epoch 2: [5237/10940] ---- BYOL Validation Loss = 0.23181721568107605
30-01-2023 17:54:26 INFO Epoch 2: [5248/10940] ---- BYOL Training Loss = 0.2320518046617508
30-01-2023 17:54:54 INFO Epoch 2: [5259/10940] ---- BYOL Training Loss = 0.27690768241882324
30-01-2023 17:55:22 INFO Epoch 2: [5270/10940] ---- BYOL Training Loss = 0.2709847688674927
30-01-2023 17:55:50 INFO Epoch 2: [5281/10940] ---- BYOL Training Loss = 0.26529914140701294
30-01-2023 17:57:18 INFO Epoch 2: [5281/10940] ---- BYOL Validation Loss = 0.25380024313926697
30-01-2023 17:57:46 INFO Epoch 2: [5292/10940] ---- BYOL Training Loss = 0.25202038884162903
30-01-2023 17:58:14 INFO Epoch 2: [5303/10940] ---- BYOL Training Loss = 0.26081711053848267
30-01-2023 17:58:42 INFO Epoch 2: [5314/10940] ---- BYOL Training Loss = 0.31071215867996216
30-01-2023 17:59:10 INFO Epoch 2: [5325/10940] ---- BYOL Training Loss = 0.29119789600372314
30-01-2023 18:00:38 INFO Epoch 2: [5325/10940] ---- BYOL Validation Loss = 0.24991974234580994
30-01-2023 18:01:06 INFO Epoch 2: [5336/10940] ---- BYOL Training Loss = 0.2515077590942383
30-01-2023 18:01:34 INFO Epoch 2: [5347/10940] ---- BYOL Training Loss = 0.2782053053379059
30-01-2023 18:02:02 INFO Epoch 2: [5358/10940] ---- BYOL Training Loss = 0.29448285698890686
30-01-2023 18:02:30 INFO Epoch 2: [5369/10940] ---- BYOL Training Loss = 0.2667728662490845
30-01-2023 18:03:58 INFO Epoch 2: [5369/10940] ---- BYOL Validation Loss = 0.2499374896287918
30-01-2023 18:04:26 INFO Epoch 2: [5380/10940] ---- BYOL Training Loss = 0.26072996854782104
30-01-2023 18:04:54 INFO Epoch 2: [5391/10940] ---- BYOL Training Loss = 0.26410922408103943
30-01-2023 18:05:22 INFO Epoch 2: [5402/10940] ---- BYOL Training Loss = 0.2327086627483368
30-01-2023 18:05:50 INFO Epoch 2: [5413/10940] ---- BYOL Training Loss = 0.28525424003601074
30-01-2023 18:07:18 INFO Epoch 2: [5413/10940] ---- BYOL Validation Loss = 0.25574991106987
30-01-2023 18:07:46 INFO Epoch 2: [5424/10940] ---- BYOL Training Loss = 0.3137156069278717
30-01-2023 18:08:15 INFO Epoch 2: [5435/10940] ---- BYOL Training Loss = 0.30508285760879517
30-01-2023 18:08:43 INFO Epoch 2: [5446/10940] ---- BYOL Training Loss = 0.2695079743862152
30-01-2023 18:09:11 INFO Epoch 2: [5457/10940] ---- BYOL Training Loss = 0.2680814862251282
30-01-2023 18:10:39 INFO Epoch 2: [5457/10940] ---- BYOL Validation Loss = 0.2541773319244385
30-01-2023 18:11:07 INFO Epoch 2: [5468/10940] ---- BYOL Training Loss = 0.26279112696647644
30-01-2023 18:11:35 INFO Epoch 2: [5479/10940] ---- BYOL Training Loss = 0.2850617468357086
30-01-2023 18:12:03 INFO Epoch 2: [5490/10940] ---- BYOL Training Loss = 0.28649887442588806
30-01-2023 18:12:31 INFO Epoch 2: [5501/10940] ---- BYOL Training Loss = 0.2689029276371002
30-01-2023 18:13:59 INFO Epoch 2: [5501/10940] ---- BYOL Validation Loss = 0.2594155967235565
30-01-2023 18:14:27 INFO Epoch 2: [5512/10940] ---- BYOL Training Loss = 0.28245097398757935
30-01-2023 18:14:55 INFO Epoch 2: [5523/10940] ---- BYOL Training Loss = 0.280056893825531
30-01-2023 18:15:23 INFO Epoch 2: [5534/10940] ---- BYOL Training Loss = 0.2640112042427063
30-01-2023 18:15:51 INFO Epoch 2: [5545/10940] ---- BYOL Training Loss = 0.29477038979530334
30-01-2023 18:17:19 INFO Epoch 2: [5545/10940] ---- BYOL Validation Loss = 0.2686590552330017
30-01-2023 18:17:47 INFO Epoch 2: [5556/10940] ---- BYOL Training Loss = 0.269542396068573
30-01-2023 18:18:15 INFO Epoch 2: [5567/10940] ---- BYOL Training Loss = 0.28740790486335754
30-01-2023 18:18:43 INFO Epoch 2: [5578/10940] ---- BYOL Training Loss = 0.3112727999687195
30-01-2023 18:19:11 INFO Epoch 2: [5589/10940] ---- BYOL Training Loss = 0.27778324484825134
30-01-2023 18:20:38 INFO Epoch 2: [5589/10940] ---- BYOL Validation Loss = 0.2287720888853073
30-01-2023 18:21:07 INFO Epoch 2: [5600/10940] ---- BYOL Training Loss = 0.23349730670452118
30-01-2023 18:21:35 INFO Epoch 2: [5611/10940] ---- BYOL Training Loss = 0.24778485298156738
30-01-2023 18:22:03 INFO Epoch 2: [5622/10940] ---- BYOL Training Loss = 0.24807290732860565
30-01-2023 18:22:31 INFO Epoch 2: [5633/10940] ---- BYOL Training Loss = 0.2593698501586914
30-01-2023 18:23:58 INFO Epoch 2: [5633/10940] ---- BYOL Validation Loss = 0.23388849198818207
30-01-2023 18:24:27 INFO Epoch 2: [5644/10940] ---- BYOL Training Loss = 0.23170499503612518
30-01-2023 18:24:55 INFO Epoch 2: [5655/10940] ---- BYOL Training Loss = 0.2656360864639282
30-01-2023 18:25:23 INFO Epoch 2: [5666/10940] ---- BYOL Training Loss = 0.2631189227104187
30-01-2023 18:25:51 INFO Epoch 2: [5677/10940] ---- BYOL Training Loss = 0.23202738165855408
30-01-2023 18:27:19 INFO Epoch 2: [5677/10940] ---- BYOL Validation Loss = 0.23759789764881134
30-01-2023 18:27:47 INFO Epoch 2: [5688/10940] ---- BYOL Training Loss = 0.23663869500160217
30-01-2023 18:28:15 INFO Epoch 2: [5699/10940] ---- BYOL Training Loss = 0.29490429162979126
30-01-2023 18:28:43 INFO Epoch 2: [5710/10940] ---- BYOL Training Loss = 0.307155042886734
30-01-2023 18:29:11 INFO Epoch 2: [5721/10940] ---- BYOL Training Loss = 0.2545521855354309
30-01-2023 18:30:39 INFO Epoch 2: [5721/10940] ---- BYOL Validation Loss = 0.2541881799697876
30-01-2023 18:31:07 INFO Epoch 2: [5732/10940] ---- BYOL Training Loss = 0.2613070607185364
30-01-2023 18:31:35 INFO Epoch 2: [5743/10940] ---- BYOL Training Loss = 0.2816191017627716
30-01-2023 18:32:03 INFO Epoch 2: [5754/10940] ---- BYOL Training Loss = 0.28153911232948303
30-01-2023 18:32:31 INFO Epoch 2: [5765/10940] ---- BYOL Training Loss = 0.28082209825515747
30-01-2023 18:33:59 INFO Epoch 2: [5765/10940] ---- BYOL Validation Loss = 0.2519756853580475
30-01-2023 18:34:27 INFO Epoch 2: [5776/10940] ---- BYOL Training Loss = 0.26276618242263794
30-01-2023 18:34:55 INFO Epoch 2: [5787/10940] ---- BYOL Training Loss = 0.2601712942123413
30-01-2023 18:35:23 INFO Epoch 2: [5798/10940] ---- BYOL Training Loss = 0.27964991331100464
30-01-2023 18:35:51 INFO Epoch 2: [5809/10940] ---- BYOL Training Loss = 0.2769030034542084
30-01-2023 18:37:19 INFO Epoch 2: [5809/10940] ---- BYOL Validation Loss = 0.2334231287240982
30-01-2023 18:37:47 INFO Epoch 2: [5820/10940] ---- BYOL Training Loss = 0.3159308135509491
30-01-2023 18:38:15 INFO Epoch 2: [5831/10940] ---- BYOL Training Loss = 0.31711891293525696
30-01-2023 18:38:43 INFO Epoch 2: [5842/10940] ---- BYOL Training Loss = 0.3008003830909729
30-01-2023 18:39:11 INFO Epoch 2: [5853/10940] ---- BYOL Training Loss = 0.2894990146160126
30-01-2023 18:40:39 INFO Epoch 2: [5853/10940] ---- BYOL Validation Loss = 0.23102501034736633
30-01-2023 18:41:07 INFO Epoch 2: [5864/10940] ---- BYOL Training Loss = 0.2912699580192566
30-01-2023 18:41:35 INFO Epoch 2: [5875/10940] ---- BYOL Training Loss = 0.30794763565063477
30-01-2023 18:42:03 INFO Epoch 2: [5886/10940] ---- BYOL Training Loss = 0.30541592836380005
30-01-2023 18:42:31 INFO Epoch 2: [5897/10940] ---- BYOL Training Loss = 0.31329086422920227
30-01-2023 18:43:59 INFO Epoch 2: [5897/10940] ---- BYOL Validation Loss = 0.25726863741874695
30-01-2023 18:44:27 INFO Epoch 2: [5908/10940] ---- BYOL Training Loss = 0.2918545603752136
30-01-2023 18:44:55 INFO Epoch 2: [5919/10940] ---- BYOL Training Loss = 0.2759678363800049
30-01-2023 18:45:23 INFO Epoch 2: [5930/10940] ---- BYOL Training Loss = 0.26405683159828186
30-01-2023 18:45:51 INFO Epoch 2: [5941/10940] ---- BYOL Training Loss = 0.2426554411649704
30-01-2023 18:47:19 INFO Epoch 2: [5941/10940] ---- BYOL Validation Loss = 0.24968907237052917
30-01-2023 18:47:47 INFO Epoch 2: [5952/10940] ---- BYOL Training Loss = 0.26091164350509644
30-01-2023 18:48:15 INFO Epoch 2: [5963/10940] ---- BYOL Training Loss = 0.2847602963447571
30-01-2023 18:48:43 INFO Epoch 2: [5974/10940] ---- BYOL Training Loss = 0.2582738995552063
30-01-2023 18:49:11 INFO Epoch 2: [5985/10940] ---- BYOL Training Loss = 0.2824709713459015
30-01-2023 18:50:39 INFO Epoch 2: [5985/10940] ---- BYOL Validation Loss = 0.26478853821754456
30-01-2023 18:51:07 INFO Epoch 2: [5996/10940] ---- BYOL Training Loss = 0.23399288952350616
30-01-2023 18:51:35 INFO Epoch 2: [6007/10940] ---- BYOL Training Loss = 0.2551354467868805
30-01-2023 18:52:03 INFO Epoch 2: [6018/10940] ---- BYOL Training Loss = 0.2925223708152771
30-01-2023 18:52:32 INFO Epoch 2: [6029/10940] ---- BYOL Training Loss = 0.28106942772865295
30-01-2023 18:53:59 INFO Epoch 2: [6029/10940] ---- BYOL Validation Loss = 0.26623377203941345
30-01-2023 18:54:27 INFO Epoch 2: [6040/10940] ---- BYOL Training Loss = 0.2776026129722595
30-01-2023 18:54:55 INFO Epoch 2: [6051/10940] ---- BYOL Training Loss = 0.28241467475891113
30-01-2023 18:55:23 INFO Epoch 2: [6062/10940] ---- BYOL Training Loss = 0.2619871497154236
30-01-2023 18:55:52 INFO Epoch 2: [6073/10940] ---- BYOL Training Loss = 0.26149982213974
30-01-2023 18:57:19 INFO Epoch 2: [6073/10940] ---- BYOL Validation Loss = 0.24302935600280762
30-01-2023 18:57:47 INFO Epoch 2: [6084/10940] ---- BYOL Training Loss = 0.32384634017944336
30-01-2023 18:58:15 INFO Epoch 2: [6095/10940] ---- BYOL Training Loss = 0.3032994568347931
30-01-2023 18:58:44 INFO Epoch 2: [6106/10940] ---- BYOL Training Loss = 0.2946307957172394
30-01-2023 18:59:12 INFO Epoch 2: [6117/10940] ---- BYOL Training Loss = 0.2512461543083191
30-01-2023 19:00:39 INFO Epoch 2: [6117/10940] ---- BYOL Validation Loss = 0.24569940567016602
30-01-2023 19:01:07 INFO Epoch 2: [6128/10940] ---- BYOL Training Loss = 0.3019580543041229
30-01-2023 19:01:35 INFO Epoch 2: [6139/10940] ---- BYOL Training Loss = 0.29335278272628784
30-01-2023 19:02:04 INFO Epoch 2: [6150/10940] ---- BYOL Training Loss = 0.2783008813858032
30-01-2023 19:02:32 INFO Epoch 2: [6161/10940] ---- BYOL Training Loss = 0.2636810541152954
30-01-2023 19:03:59 INFO Epoch 2: [6161/10940] ---- BYOL Validation Loss = 0.23068544268608093
30-01-2023 19:04:27 INFO Epoch 2: [6172/10940] ---- BYOL Training Loss = 0.2795562148094177
30-01-2023 19:04:55 INFO Epoch 2: [6183/10940] ---- BYOL Training Loss = 0.2723483443260193
30-01-2023 19:05:24 INFO Epoch 2: [6194/10940] ---- BYOL Training Loss = 0.2556614875793457
30-01-2023 19:05:52 INFO Epoch 2: [6205/10940] ---- BYOL Training Loss = 0.29723989963531494
30-01-2023 19:07:19 INFO Epoch 2: [6205/10940] ---- BYOL Validation Loss = 0.2550128102302551
30-01-2023 19:07:47 INFO Epoch 2: [6216/10940] ---- BYOL Training Loss = 0.26909855008125305
30-01-2023 19:08:16 INFO Epoch 2: [6227/10940] ---- BYOL Training Loss = 0.22890686988830566
30-01-2023 19:08:44 INFO Epoch 2: [6238/10940] ---- BYOL Training Loss = 0.2378121167421341
30-01-2023 19:09:12 INFO Epoch 2: [6249/10940] ---- BYOL Training Loss = 0.22275635600090027
30-01-2023 19:10:39 INFO Epoch 2: [6249/10940] ---- BYOL Validation Loss = 0.248230442404747
30-01-2023 19:11:07 INFO Epoch 2: [6260/10940] ---- BYOL Training Loss = 0.24492840468883514
30-01-2023 19:11:36 INFO Epoch 2: [6271/10940] ---- BYOL Training Loss = 0.291813462972641
30-01-2023 19:12:04 INFO Epoch 2: [6282/10940] ---- BYOL Training Loss = 0.290679395198822
30-01-2023 19:12:32 INFO Epoch 2: [6293/10940] ---- BYOL Training Loss = 0.2372332513332367
30-01-2023 19:14:00 INFO Epoch 2: [6293/10940] ---- BYOL Validation Loss = 0.25871792435646057
30-01-2023 19:14:28 INFO Epoch 2: [6304/10940] ---- BYOL Training Loss = 0.2609249949455261
30-01-2023 19:14:56 INFO Epoch 2: [6315/10940] ---- BYOL Training Loss = 0.2723884582519531
30-01-2023 19:15:25 INFO Epoch 2: [6326/10940] ---- BYOL Training Loss = 0.3067966103553772
30-01-2023 19:15:53 INFO Epoch 2: [6337/10940] ---- BYOL Training Loss = 0.2885696589946747
30-01-2023 19:17:20 INFO Epoch 2: [6337/10940] ---- BYOL Validation Loss = 0.2459717094898224
30-01-2023 19:17:49 INFO Epoch 2: [6348/10940] ---- BYOL Training Loss = 0.26966628432273865
30-01-2023 19:18:17 INFO Epoch 2: [6359/10940] ---- BYOL Training Loss = 0.26755043864250183
30-01-2023 19:18:45 INFO Epoch 2: [6370/10940] ---- BYOL Training Loss = 0.25678369402885437
30-01-2023 19:19:13 INFO Epoch 2: [6381/10940] ---- BYOL Training Loss = 0.2296716272830963
30-01-2023 19:20:41 INFO Epoch 2: [6381/10940] ---- BYOL Validation Loss = 0.24605655670166016
30-01-2023 19:21:09 INFO Epoch 2: [6392/10940] ---- BYOL Training Loss = 0.23338787257671356
30-01-2023 19:21:37 INFO Epoch 2: [6403/10940] ---- BYOL Training Loss = 0.28890660405158997
30-01-2023 19:22:05 INFO Epoch 2: [6414/10940] ---- BYOL Training Loss = 0.3536577522754669
30-01-2023 19:22:33 INFO Epoch 2: [6425/10940] ---- BYOL Training Loss = 0.33093497157096863
30-01-2023 19:24:01 INFO Epoch 2: [6425/10940] ---- BYOL Validation Loss = 0.2640918791294098
30-01-2023 19:24:29 INFO Epoch 2: [6436/10940] ---- BYOL Training Loss = 0.30342236161231995
30-01-2023 19:24:57 INFO Epoch 2: [6447/10940] ---- BYOL Training Loss = 0.29436302185058594
30-01-2023 19:25:26 INFO Epoch 2: [6458/10940] ---- BYOL Training Loss = 0.2900637090206146
30-01-2023 19:25:54 INFO Epoch 2: [6469/10940] ---- BYOL Training Loss = 0.2839600741863251
30-01-2023 19:27:21 INFO Epoch 2: [6469/10940] ---- BYOL Validation Loss = 0.2721271216869354
30-01-2023 19:27:50 INFO Epoch 2: [6480/10940] ---- BYOL Training Loss = 0.29440781474113464
30-01-2023 19:28:18 INFO Epoch 2: [6491/10940] ---- BYOL Training Loss = 0.2706950604915619
30-01-2023 19:28:46 INFO Epoch 2: [6502/10940] ---- BYOL Training Loss = 0.27302414178848267
30-01-2023 19:29:14 INFO Epoch 2: [6513/10940] ---- BYOL Training Loss = 0.28644752502441406
30-01-2023 19:30:42 INFO Epoch 2: [6513/10940] ---- BYOL Validation Loss = 0.25792866945266724
30-01-2023 19:31:10 INFO Epoch 2: [6524/10940] ---- BYOL Training Loss = 0.2879154086112976
30-01-2023 19:31:39 INFO Epoch 2: [6535/10940] ---- BYOL Training Loss = 0.2836761474609375
30-01-2023 19:32:07 INFO Epoch 2: [6546/10940] ---- BYOL Training Loss = 0.2542864680290222
30-01-2023 19:32:35 INFO Epoch 2: [6557/10940] ---- BYOL Training Loss = 0.2574724853038788
30-01-2023 19:34:03 INFO Epoch 2: [6557/10940] ---- BYOL Validation Loss = 0.2574554979801178
30-01-2023 19:34:31 INFO Epoch 2: [6568/10940] ---- BYOL Training Loss = 0.31591156125068665
30-01-2023 19:34:59 INFO Epoch 2: [6579/10940] ---- BYOL Training Loss = 0.29863208532333374
30-01-2023 19:35:27 INFO Epoch 2: [6590/10940] ---- BYOL Training Loss = 0.27106887102127075
30-01-2023 19:35:55 INFO Epoch 2: [6601/10940] ---- BYOL Training Loss = 0.280519038438797
30-01-2023 19:37:23 INFO Epoch 2: [6601/10940] ---- BYOL Validation Loss = 0.2488006055355072
30-01-2023 19:37:52 INFO Epoch 2: [6612/10940] ---- BYOL Training Loss = 0.2818368077278137
30-01-2023 19:38:20 INFO Epoch 2: [6623/10940] ---- BYOL Training Loss = 0.2807862460613251
30-01-2023 19:38:48 INFO Epoch 2: [6634/10940] ---- BYOL Training Loss = 0.29739242792129517
30-01-2023 19:39:16 INFO Epoch 2: [6645/10940] ---- BYOL Training Loss = 0.26749542355537415
30-01-2023 19:40:45 INFO Epoch 2: [6645/10940] ---- BYOL Validation Loss = 0.2590023875236511
30-01-2023 19:41:13 INFO Epoch 2: [6656/10940] ---- BYOL Training Loss = 0.28211623430252075
30-01-2023 19:41:41 INFO Epoch 2: [6667/10940] ---- BYOL Training Loss = 0.31146910786628723
30-01-2023 19:42:09 INFO Epoch 2: [6678/10940] ---- BYOL Training Loss = 0.28749480843544006
30-01-2023 19:42:37 INFO Epoch 2: [6689/10940] ---- BYOL Training Loss = 0.28662481904029846
30-01-2023 19:44:05 INFO Epoch 2: [6689/10940] ---- BYOL Validation Loss = 0.259677916765213
30-01-2023 19:44:33 INFO Epoch 2: [6700/10940] ---- BYOL Training Loss = 0.32945793867111206
30-01-2023 19:45:01 INFO Epoch 2: [6711/10940] ---- BYOL Training Loss = 0.3087943196296692
30-01-2023 19:45:30 INFO Epoch 2: [6722/10940] ---- BYOL Training Loss = 0.2311164140701294
30-01-2023 19:45:58 INFO Epoch 2: [6733/10940] ---- BYOL Training Loss = 0.23209774494171143
30-01-2023 19:47:26 INFO Epoch 2: [6733/10940] ---- BYOL Validation Loss = 0.2548854947090149
30-01-2023 19:47:54 INFO Epoch 2: [6744/10940] ---- BYOL Training Loss = 0.2967798411846161
30-01-2023 19:48:22 INFO Epoch 2: [6755/10940] ---- BYOL Training Loss = 0.2942628562450409
30-01-2023 19:48:50 INFO Epoch 2: [6766/10940] ---- BYOL Training Loss = 0.2848460376262665
30-01-2023 19:49:18 INFO Epoch 2: [6777/10940] ---- BYOL Training Loss = 0.27610960602760315
30-01-2023 19:50:46 INFO Epoch 2: [6777/10940] ---- BYOL Validation Loss = 0.232717826962471
30-01-2023 19:51:15 INFO Epoch 2: [6788/10940] ---- BYOL Training Loss = 0.28907063603401184
30-01-2023 19:51:43 INFO Epoch 2: [6799/10940] ---- BYOL Training Loss = 0.29078948497772217
30-01-2023 19:52:11 INFO Epoch 2: [6810/10940] ---- BYOL Training Loss = 0.279291570186615
30-01-2023 19:52:39 INFO Epoch 2: [6821/10940] ---- BYOL Training Loss = 0.2661057710647583
30-01-2023 19:54:07 INFO Epoch 2: [6821/10940] ---- BYOL Validation Loss = 0.24999584257602692
30-01-2023 19:54:35 INFO Epoch 2: [6832/10940] ---- BYOL Training Loss = 0.24411959946155548
30-01-2023 19:55:04 INFO Epoch 2: [6843/10940] ---- BYOL Training Loss = 0.23234805464744568
30-01-2023 19:55:32 INFO Epoch 2: [6854/10940] ---- BYOL Training Loss = 0.2238353043794632
30-01-2023 19:56:00 INFO Epoch 2: [6865/10940] ---- BYOL Training Loss = 0.2745150029659271
30-01-2023 19:57:28 INFO Epoch 2: [6865/10940] ---- BYOL Validation Loss = 0.23561528325080872
30-01-2023 19:57:57 INFO Epoch 2: [6876/10940] ---- BYOL Training Loss = 0.2617257833480835
30-01-2023 19:58:25 INFO Epoch 2: [6887/10940] ---- BYOL Training Loss = 0.20379464328289032
30-01-2023 19:58:53 INFO Epoch 2: [6898/10940] ---- BYOL Training Loss = 0.28212153911590576
30-01-2023 19:59:21 INFO Epoch 2: [6909/10940] ---- BYOL Training Loss = 0.34558144211769104
30-01-2023 20:00:49 INFO Epoch 2: [6909/10940] ---- BYOL Validation Loss = 0.23921050131320953
30-01-2023 20:01:17 INFO Epoch 2: [6920/10940] ---- BYOL Training Loss = 0.2772246301174164
30-01-2023 20:01:45 INFO Epoch 2: [6931/10940] ---- BYOL Training Loss = 0.2504747807979584
30-01-2023 20:02:14 INFO Epoch 2: [6942/10940] ---- BYOL Training Loss = 0.24638071656227112
30-01-2023 20:02:42 INFO Epoch 2: [6953/10940] ---- BYOL Training Loss = 0.24296188354492188
30-01-2023 20:04:10 INFO Epoch 2: [6953/10940] ---- BYOL Validation Loss = 0.2180844396352768
30-01-2023 20:04:38 INFO Epoch 2: [6964/10940] ---- BYOL Training Loss = 0.2972029149532318
30-01-2023 20:05:06 INFO Epoch 2: [6975/10940] ---- BYOL Training Loss = 0.2895617187023163
30-01-2023 20:05:34 INFO Epoch 2: [6986/10940] ---- BYOL Training Loss = 0.2748517394065857
30-01-2023 20:06:02 INFO Epoch 2: [6997/10940] ---- BYOL Training Loss = 0.29657065868377686
30-01-2023 20:07:30 INFO Epoch 2: [6997/10940] ---- BYOL Validation Loss = 0.22498221695423126
30-01-2023 20:07:59 INFO Epoch 2: [7008/10940] ---- BYOL Training Loss = 0.3246893286705017
30-01-2023 20:08:27 INFO Epoch 2: [7019/10940] ---- BYOL Training Loss = 0.3353481888771057
30-01-2023 20:08:55 INFO Epoch 2: [7030/10940] ---- BYOL Training Loss = 0.27784463763237
30-01-2023 20:09:23 INFO Epoch 2: [7041/10940] ---- BYOL Training Loss = 0.2762729823589325
30-01-2023 20:10:51 INFO Epoch 2: [7041/10940] ---- BYOL Validation Loss = 0.2293204516172409
30-01-2023 20:11:19 INFO Epoch 2: [7052/10940] ---- BYOL Training Loss = 0.2746523916721344
30-01-2023 20:11:47 INFO Epoch 2: [7063/10940] ---- BYOL Training Loss = 0.27287063002586365
30-01-2023 20:12:15 INFO Epoch 2: [7074/10940] ---- BYOL Training Loss = 0.2906269431114197
30-01-2023 20:12:44 INFO Epoch 2: [7085/10940] ---- BYOL Training Loss = 0.35236993432044983
30-01-2023 20:14:12 INFO Epoch 2: [7085/10940] ---- BYOL Validation Loss = 0.2887148857116699
30-01-2023 20:14:40 INFO Epoch 2: [7096/10940] ---- BYOL Training Loss = 0.36834245920181274
30-01-2023 20:15:08 INFO Epoch 2: [7107/10940] ---- BYOL Training Loss = 0.3145599961280823
30-01-2023 20:15:36 INFO Epoch 2: [7118/10940] ---- BYOL Training Loss = 0.30863332748413086
30-01-2023 20:16:04 INFO Epoch 2: [7129/10940] ---- BYOL Training Loss = 0.2948286533355713
30-01-2023 20:17:32 INFO Epoch 2: [7129/10940] ---- BYOL Validation Loss = 0.22111940383911133
30-01-2023 20:18:00 INFO Epoch 2: [7140/10940] ---- BYOL Training Loss = 0.3083055019378662
30-01-2023 20:18:29 INFO Epoch 2: [7151/10940] ---- BYOL Training Loss = 0.35126397013664246
30-01-2023 20:18:57 INFO Epoch 2: [7162/10940] ---- BYOL Training Loss = 0.30784234404563904
30-01-2023 20:19:25 INFO Epoch 2: [7173/10940] ---- BYOL Training Loss = 0.23121151328086853
30-01-2023 20:20:53 INFO Epoch 2: [7173/10940] ---- BYOL Validation Loss = 0.18227720260620117
30-01-2023 20:21:21 INFO Epoch 2: [7184/10940] ---- BYOL Training Loss = 0.25392547249794006
30-01-2023 20:21:49 INFO Epoch 2: [7195/10940] ---- BYOL Training Loss = 0.27759867906570435
30-01-2023 20:22:17 INFO Epoch 2: [7206/10940] ---- BYOL Training Loss = 0.24462196230888367
30-01-2023 20:22:46 INFO Epoch 2: [7217/10940] ---- BYOL Training Loss = 0.28174257278442383
30-01-2023 20:24:14 INFO Epoch 2: [7217/10940] ---- BYOL Validation Loss = 0.2472212314605713
30-01-2023 20:24:42 INFO Epoch 2: [7228/10940] ---- BYOL Training Loss = 0.30003243684768677
30-01-2023 20:25:10 INFO Epoch 2: [7239/10940] ---- BYOL Training Loss = 0.2992663085460663
30-01-2023 20:25:39 INFO Epoch 2: [7250/10940] ---- BYOL Training Loss = 0.2586950659751892
30-01-2023 20:26:07 INFO Epoch 2: [7261/10940] ---- BYOL Training Loss = 0.2767496109008789
30-01-2023 20:27:35 INFO Epoch 2: [7261/10940] ---- BYOL Validation Loss = 0.23786583542823792
30-01-2023 20:28:03 INFO Epoch 2: [7272/10940] ---- BYOL Training Loss = 0.28451114892959595
30-01-2023 20:28:31 INFO Epoch 2: [7283/10940] ---- BYOL Training Loss = 0.2947884202003479
30-01-2023 20:28:59 INFO Epoch 2: [7294/10940] ---- BYOL Training Loss = 0.29777318239212036
30-01-2023 20:29:27 INFO Epoch 2: [7305/10940] ---- BYOL Training Loss = 0.338733971118927
30-01-2023 20:30:55 INFO Epoch 2: [7305/10940] ---- BYOL Validation Loss = 0.26427093148231506
30-01-2023 20:31:23 INFO Epoch 2: [7316/10940] ---- BYOL Training Loss = 0.3398287892341614
30-01-2023 20:31:52 INFO Epoch 2: [7327/10940] ---- BYOL Training Loss = 0.3078896403312683
30-01-2023 20:32:20 INFO Epoch 2: [7338/10940] ---- BYOL Training Loss = 0.3008970022201538
30-01-2023 20:32:48 INFO Epoch 2: [7349/10940] ---- BYOL Training Loss = 0.31467515230178833
30-01-2023 20:34:16 INFO Epoch 2: [7349/10940] ---- BYOL Validation Loss = 0.2474862039089203
30-01-2023 20:34:45 INFO Epoch 2: [7360/10940] ---- BYOL Training Loss = 0.33928388357162476
30-01-2023 20:35:13 INFO Epoch 2: [7371/10940] ---- BYOL Training Loss = 0.3109758496284485
30-01-2023 20:35:41 INFO Epoch 2: [7382/10940] ---- BYOL Training Loss = 0.3106652498245239
30-01-2023 20:36:09 INFO Epoch 2: [7393/10940] ---- BYOL Training Loss = 0.28682178258895874
30-01-2023 20:37:37 INFO Epoch 2: [7393/10940] ---- BYOL Validation Loss = 0.2533113658428192
30-01-2023 20:38:06 INFO Epoch 2: [7404/10940] ---- BYOL Training Loss = 0.294228196144104
30-01-2023 20:38:34 INFO Epoch 2: [7415/10940] ---- BYOL Training Loss = 0.37819498777389526
30-01-2023 20:39:02 INFO Epoch 2: [7426/10940] ---- BYOL Training Loss = 0.29029497504234314
30-01-2023 20:39:30 INFO Epoch 2: [7437/10940] ---- BYOL Training Loss = 0.27405160665512085
30-01-2023 20:40:58 INFO Epoch 2: [7437/10940] ---- BYOL Validation Loss = 0.2516542971134186
30-01-2023 20:41:26 INFO Epoch 2: [7448/10940] ---- BYOL Training Loss = 0.28686079382896423
30-01-2023 20:41:55 INFO Epoch 2: [7459/10940] ---- BYOL Training Loss = 0.2854926586151123
30-01-2023 20:42:23 INFO Epoch 2: [7470/10940] ---- BYOL Training Loss = 0.27042534947395325
30-01-2023 20:42:51 INFO Epoch 2: [7481/10940] ---- BYOL Training Loss = 0.289032518863678
30-01-2023 20:44:19 INFO Epoch 2: [7481/10940] ---- BYOL Validation Loss = 0.22857055068016052
30-01-2023 20:44:47 INFO Epoch 2: [7492/10940] ---- BYOL Training Loss = 0.3114718496799469
30-01-2023 20:45:15 INFO Epoch 2: [7503/10940] ---- BYOL Training Loss = 0.33084744215011597
30-01-2023 20:45:44 INFO Epoch 2: [7514/10940] ---- BYOL Training Loss = 0.30461519956588745
30-01-2023 20:46:12 INFO Epoch 2: [7525/10940] ---- BYOL Training Loss = 0.3010871708393097
30-01-2023 20:47:40 INFO Epoch 2: [7525/10940] ---- BYOL Validation Loss = 0.21125951409339905
30-01-2023 20:48:08 INFO Epoch 2: [7536/10940] ---- BYOL Training Loss = 0.3172433376312256
30-01-2023 20:48:37 INFO Epoch 2: [7547/10940] ---- BYOL Training Loss = 0.2796861529350281
30-01-2023 20:49:05 INFO Epoch 2: [7558/10940] ---- BYOL Training Loss = 0.25135093927383423
30-01-2023 20:49:33 INFO Epoch 2: [7569/10940] ---- BYOL Training Loss = 0.2679855525493622
30-01-2023 20:51:01 INFO Epoch 2: [7569/10940] ---- BYOL Validation Loss = 0.20758174359798431
30-01-2023 20:51:29 INFO Epoch 2: [7580/10940] ---- BYOL Training Loss = 0.28755897283554077
30-01-2023 20:51:57 INFO Epoch 2: [7591/10940] ---- BYOL Training Loss = 0.2983205318450928
30-01-2023 20:52:25 INFO Epoch 2: [7602/10940] ---- BYOL Training Loss = 0.2736181616783142
30-01-2023 20:52:54 INFO Epoch 2: [7613/10940] ---- BYOL Training Loss = 0.24001666903495789
30-01-2023 20:54:22 INFO Epoch 2: [7613/10940] ---- BYOL Validation Loss = 0.22065512835979462
30-01-2023 20:54:50 INFO Epoch 2: [7624/10940] ---- BYOL Training Loss = 0.259244441986084
30-01-2023 20:55:18 INFO Epoch 2: [7635/10940] ---- BYOL Training Loss = 0.29019829630851746
30-01-2023 20:55:47 INFO Epoch 2: [7646/10940] ---- BYOL Training Loss = 0.2738359570503235
30-01-2023 20:56:15 INFO Epoch 2: [7657/10940] ---- BYOL Training Loss = 0.2678268551826477
30-01-2023 20:57:43 INFO Epoch 2: [7657/10940] ---- BYOL Validation Loss = 0.24623240530490875
30-01-2023 20:58:11 INFO Epoch 2: [7668/10940] ---- BYOL Training Loss = 0.2638820707798004
30-01-2023 20:58:40 INFO Epoch 2: [7679/10940] ---- BYOL Training Loss = 0.23903898894786835
30-01-2023 20:59:08 INFO Epoch 2: [7690/10940] ---- BYOL Training Loss = 0.2941339612007141
30-01-2023 20:59:36 INFO Epoch 2: [7701/10940] ---- BYOL Training Loss = 0.2988821864128113
30-01-2023 21:01:04 INFO Epoch 2: [7701/10940] ---- BYOL Validation Loss = 0.22490695118904114
30-01-2023 21:01:32 INFO Epoch 2: [7712/10940] ---- BYOL Training Loss = 0.2674051821231842
30-01-2023 21:02:00 INFO Epoch 2: [7723/10940] ---- BYOL Training Loss = 0.26475220918655396
30-01-2023 21:02:29 INFO Epoch 2: [7734/10940] ---- BYOL Training Loss = 0.26540568470954895
30-01-2023 21:02:57 INFO Epoch 2: [7745/10940] ---- BYOL Training Loss = 0.28952980041503906
30-01-2023 21:04:24 INFO Epoch 2: [7745/10940] ---- BYOL Validation Loss = 0.27055686712265015
30-01-2023 21:04:53 INFO Epoch 2: [7756/10940] ---- BYOL Training Loss = 0.3209713101387024
30-01-2023 21:05:21 INFO Epoch 2: [7767/10940] ---- BYOL Training Loss = 0.3359641134738922
30-01-2023 21:05:50 INFO Epoch 2: [7778/10940] ---- BYOL Training Loss = 0.288966566324234
30-01-2023 21:06:18 INFO Epoch 2: [7789/10940] ---- BYOL Training Loss = 0.2808624804019928
30-01-2023 21:07:45 INFO Epoch 2: [7789/10940] ---- BYOL Validation Loss = 0.26229363679885864
30-01-2023 21:08:14 INFO Epoch 2: [7800/10940] ---- BYOL Training Loss = 0.30594050884246826
30-01-2023 21:08:42 INFO Epoch 2: [7811/10940] ---- BYOL Training Loss = 0.2615816593170166
30-01-2023 21:09:10 INFO Epoch 2: [7822/10940] ---- BYOL Training Loss = 0.2796638607978821
30-01-2023 21:09:38 INFO Epoch 2: [7833/10940] ---- BYOL Training Loss = 0.2565748393535614
30-01-2023 21:11:06 INFO Epoch 2: [7833/10940] ---- BYOL Validation Loss = 0.24388685822486877
30-01-2023 21:11:35 INFO Epoch 2: [7844/10940] ---- BYOL Training Loss = 0.3022790849208832
30-01-2023 21:12:03 INFO Epoch 2: [7855/10940] ---- BYOL Training Loss = 0.2989695072174072
30-01-2023 21:12:31 INFO Epoch 2: [7866/10940] ---- BYOL Training Loss = 0.24111106991767883
30-01-2023 21:12:59 INFO Epoch 2: [7877/10940] ---- BYOL Training Loss = 0.24557451903820038
30-01-2023 21:14:27 INFO Epoch 2: [7877/10940] ---- BYOL Validation Loss = 0.24097569286823273
30-01-2023 21:14:55 INFO Epoch 2: [7888/10940] ---- BYOL Training Loss = 0.2462727576494217
30-01-2023 21:15:24 INFO Epoch 2: [7899/10940] ---- BYOL Training Loss = 0.25306469202041626
30-01-2023 21:15:52 INFO Epoch 2: [7910/10940] ---- BYOL Training Loss = 0.25281453132629395
30-01-2023 21:16:20 INFO Epoch 2: [7921/10940] ---- BYOL Training Loss = 0.26210540533065796
30-01-2023 21:17:48 INFO Epoch 2: [7921/10940] ---- BYOL Validation Loss = 0.1957022100687027
30-01-2023 21:18:16 INFO Epoch 2: [7932/10940] ---- BYOL Training Loss = 0.2370544970035553
30-01-2023 21:18:45 INFO Epoch 2: [7943/10940] ---- BYOL Training Loss = 0.23412010073661804
30-01-2023 21:19:13 INFO Epoch 2: [7954/10940] ---- BYOL Training Loss = 0.29425427317619324
30-01-2023 21:19:41 INFO Epoch 2: [7965/10940] ---- BYOL Training Loss = 0.3195713758468628
30-01-2023 21:21:09 INFO Epoch 2: [7965/10940] ---- BYOL Validation Loss = 0.2709038257598877
30-01-2023 21:21:38 INFO Epoch 2: [7976/10940] ---- BYOL Training Loss = 0.26107949018478394
30-01-2023 21:22:06 INFO Epoch 2: [7987/10940] ---- BYOL Training Loss = 0.2547945976257324
30-01-2023 21:22:34 INFO Epoch 2: [7998/10940] ---- BYOL Training Loss = 0.29809361696243286
30-01-2023 21:23:03 INFO Epoch 2: [8009/10940] ---- BYOL Training Loss = 0.315817654132843
30-01-2023 21:24:30 INFO Epoch 2: [8009/10940] ---- BYOL Validation Loss = 0.23019099235534668
30-01-2023 21:24:58 INFO Epoch 2: [8020/10940] ---- BYOL Training Loss = 0.3318932354450226
30-01-2023 21:25:27 INFO Epoch 2: [8031/10940] ---- BYOL Training Loss = 0.2849716544151306
30-01-2023 21:25:56 INFO Epoch 2: [8042/10940] ---- BYOL Training Loss = 0.2643645107746124
30-01-2023 21:26:24 INFO Epoch 2: [8053/10940] ---- BYOL Training Loss = 0.24898898601531982
30-01-2023 21:27:51 INFO Epoch 2: [8053/10940] ---- BYOL Validation Loss = 0.19962814450263977
30-01-2023 21:28:20 INFO Epoch 2: [8064/10940] ---- BYOL Training Loss = 0.24672460556030273
30-01-2023 21:28:49 INFO Epoch 2: [8075/10940] ---- BYOL Training Loss = 0.29394465684890747
30-01-2023 21:29:17 INFO Epoch 2: [8086/10940] ---- BYOL Training Loss = 0.31788647174835205
30-01-2023 21:29:45 INFO Epoch 2: [8097/10940] ---- BYOL Training Loss = 0.257047176361084
30-01-2023 21:31:13 INFO Epoch 2: [8097/10940] ---- BYOL Validation Loss = 0.20587073266506195
30-01-2023 21:31:41 INFO Epoch 2: [8108/10940] ---- BYOL Training Loss = 0.2718721032142639
30-01-2023 21:32:09 INFO Epoch 2: [8119/10940] ---- BYOL Training Loss = 0.27344805002212524
30-01-2023 21:32:37 INFO Epoch 2: [8130/10940] ---- BYOL Training Loss = 0.27985602617263794
30-01-2023 21:33:06 INFO Epoch 2: [8141/10940] ---- BYOL Training Loss = 0.2883017361164093
30-01-2023 21:34:34 INFO Epoch 2: [8141/10940] ---- BYOL Validation Loss = 0.17628438770771027
30-01-2023 21:35:02 INFO Epoch 2: [8152/10940] ---- BYOL Training Loss = 0.28600186109542847
30-01-2023 21:35:31 INFO Epoch 2: [8163/10940] ---- BYOL Training Loss = 0.27161818742752075
30-01-2023 21:35:59 INFO Epoch 2: [8174/10940] ---- BYOL Training Loss = 0.28509002923965454
30-01-2023 21:36:27 INFO Epoch 2: [8185/10940] ---- BYOL Training Loss = 0.28216275572776794
30-01-2023 21:37:55 INFO Epoch 2: [8185/10940] ---- BYOL Validation Loss = 0.21082328259944916
30-01-2023 21:38:23 INFO Epoch 2: [8196/10940] ---- BYOL Training Loss = 0.3028660714626312
30-01-2023 21:38:52 INFO Epoch 2: [8207/10940] ---- BYOL Training Loss = 0.27315545082092285
30-01-2023 21:39:20 INFO Epoch 2: [8218/10940] ---- BYOL Training Loss = 0.22364208102226257
30-01-2023 21:39:48 INFO Epoch 2: [8229/10940] ---- BYOL Training Loss = 0.24087142944335938
30-01-2023 21:41:16 INFO Epoch 2: [8229/10940] ---- BYOL Validation Loss = 0.24496230483055115
30-01-2023 21:41:44 INFO Epoch 2: [8240/10940] ---- BYOL Training Loss = 0.23865878582000732
30-01-2023 21:42:12 INFO Epoch 2: [8251/10940] ---- BYOL Training Loss = 0.2598682940006256
30-01-2023 21:42:41 INFO Epoch 2: [8262/10940] ---- BYOL Training Loss = 0.27687662839889526
30-01-2023 21:43:09 INFO Epoch 2: [8273/10940] ---- BYOL Training Loss = 0.27176743745803833
30-01-2023 21:44:37 INFO Epoch 2: [8273/10940] ---- BYOL Validation Loss = 0.21220269799232483
30-01-2023 21:45:05 INFO Epoch 2: [8284/10940] ---- BYOL Training Loss = 0.27015867829322815
30-01-2023 21:45:34 INFO Epoch 2: [8295/10940] ---- BYOL Training Loss = 0.23981964588165283
30-01-2023 21:46:02 INFO Epoch 2: [8306/10940] ---- BYOL Training Loss = 0.23462846875190735
30-01-2023 21:46:30 INFO Epoch 2: [8317/10940] ---- BYOL Training Loss = 0.25207996368408203
30-01-2023 21:47:58 INFO Epoch 2: [8317/10940] ---- BYOL Validation Loss = 0.22008702158927917
30-01-2023 21:48:27 INFO Epoch 2: [8328/10940] ---- BYOL Training Loss = 0.21284742653369904
30-01-2023 21:48:55 INFO Epoch 2: [8339/10940] ---- BYOL Training Loss = 0.23633944988250732
30-01-2023 21:49:23 INFO Epoch 2: [8350/10940] ---- BYOL Training Loss = 0.2737911641597748
30-01-2023 21:49:52 INFO Epoch 2: [8361/10940] ---- BYOL Training Loss = 0.23494918644428253
30-01-2023 21:51:19 INFO Epoch 2: [8361/10940] ---- BYOL Validation Loss = 0.2151797115802765
30-01-2023 21:51:48 INFO Epoch 2: [8372/10940] ---- BYOL Training Loss = 0.22997155785560608
30-01-2023 21:52:16 INFO Epoch 2: [8383/10940] ---- BYOL Training Loss = 0.2941223084926605
30-01-2023 21:52:44 INFO Epoch 2: [8394/10940] ---- BYOL Training Loss = 0.28794872760772705
30-01-2023 21:53:13 INFO Epoch 2: [8405/10940] ---- BYOL Training Loss = 0.28669461607933044
30-01-2023 21:54:41 INFO Epoch 2: [8405/10940] ---- BYOL Validation Loss = 0.20431511104106903
30-01-2023 21:55:10 INFO Epoch 2: [8416/10940] ---- BYOL Training Loss = 0.3600761294364929
30-01-2023 21:55:38 INFO Epoch 2: [8427/10940] ---- BYOL Training Loss = 0.40068110823631287
30-01-2023 21:56:06 INFO Epoch 2: [8438/10940] ---- BYOL Training Loss = 0.3313371539115906
30-01-2023 21:56:35 INFO Epoch 2: [8449/10940] ---- BYOL Training Loss = 0.3004624843597412
30-01-2023 21:58:02 INFO Epoch 2: [8449/10940] ---- BYOL Validation Loss = 0.25043267011642456
30-01-2023 21:58:31 INFO Epoch 2: [8460/10940] ---- BYOL Training Loss = 0.2876676917076111
30-01-2023 21:58:59 INFO Epoch 2: [8471/10940] ---- BYOL Training Loss = 0.2690877318382263
30-01-2023 21:59:27 INFO Epoch 2: [8482/10940] ---- BYOL Training Loss = 0.3172938823699951
30-01-2023 21:59:56 INFO Epoch 2: [8493/10940] ---- BYOL Training Loss = 0.3075559735298157
30-01-2023 22:01:24 INFO Epoch 2: [8493/10940] ---- BYOL Validation Loss = 0.24661707878112793
30-01-2023 22:01:52 INFO Epoch 2: [8504/10940] ---- BYOL Training Loss = 0.26694199442863464
30-01-2023 22:02:20 INFO Epoch 2: [8515/10940] ---- BYOL Training Loss = 0.2742137312889099
30-01-2023 22:02:49 INFO Epoch 2: [8526/10940] ---- BYOL Training Loss = 0.2799816131591797
30-01-2023 22:03:17 INFO Epoch 2: [8537/10940] ---- BYOL Training Loss = 0.30598458647727966
30-01-2023 22:04:45 INFO Epoch 2: [8537/10940] ---- BYOL Validation Loss = 0.1949571818113327
30-01-2023 22:05:13 INFO Epoch 2: [8548/10940] ---- BYOL Training Loss = 0.25342726707458496
30-01-2023 22:05:42 INFO Epoch 2: [8559/10940] ---- BYOL Training Loss = 0.25544828176498413
30-01-2023 22:06:10 INFO Epoch 2: [8570/10940] ---- BYOL Training Loss = 0.25562989711761475
30-01-2023 22:06:38 INFO Epoch 2: [8581/10940] ---- BYOL Training Loss = 0.23328132927417755
30-01-2023 22:08:06 INFO Epoch 2: [8581/10940] ---- BYOL Validation Loss = 0.20427489280700684
30-01-2023 22:08:34 INFO Epoch 2: [8592/10940] ---- BYOL Training Loss = 0.2314547747373581
30-01-2023 22:09:03 INFO Epoch 2: [8603/10940] ---- BYOL Training Loss = 0.25502052903175354
30-01-2023 22:09:31 INFO Epoch 2: [8614/10940] ---- BYOL Training Loss = 0.2817230224609375
30-01-2023 22:09:59 INFO Epoch 2: [8625/10940] ---- BYOL Training Loss = 0.3024119734764099
30-01-2023 22:11:27 INFO Epoch 2: [8625/10940] ---- BYOL Validation Loss = 0.24395442008972168
30-01-2023 22:11:55 INFO Epoch 2: [8636/10940] ---- BYOL Training Loss = 0.2967032790184021
30-01-2023 22:12:24 INFO Epoch 2: [8647/10940] ---- BYOL Training Loss = 0.2744888961315155
30-01-2023 22:12:52 INFO Epoch 2: [8658/10940] ---- BYOL Training Loss = 0.27999910712242126
30-01-2023 22:13:20 INFO Epoch 2: [8669/10940] ---- BYOL Training Loss = 0.24792571365833282
30-01-2023 22:14:48 INFO Epoch 2: [8669/10940] ---- BYOL Validation Loss = 0.20329013466835022
30-01-2023 22:15:16 INFO Epoch 2: [8680/10940] ---- BYOL Training Loss = 0.2589333653450012
30-01-2023 22:15:44 INFO Epoch 2: [8691/10940] ---- BYOL Training Loss = 0.2669336199760437
30-01-2023 22:16:13 INFO Epoch 2: [8702/10940] ---- BYOL Training Loss = 0.2515830397605896
30-01-2023 22:16:41 INFO Epoch 2: [8713/10940] ---- BYOL Training Loss = 0.2611226737499237
30-01-2023 22:18:09 INFO Epoch 2: [8713/10940] ---- BYOL Validation Loss = 0.23578773438930511
30-01-2023 22:18:37 INFO Epoch 2: [8724/10940] ---- BYOL Training Loss = 0.24475114047527313
30-01-2023 22:19:06 INFO Epoch 2: [8735/10940] ---- BYOL Training Loss = 0.24797213077545166
30-01-2023 22:19:34 INFO Epoch 2: [8746/10940] ---- BYOL Training Loss = 0.26538020372390747
30-01-2023 22:20:03 INFO Epoch 2: [8757/10940] ---- BYOL Training Loss = 0.2452140599489212
30-01-2023 22:21:31 INFO Epoch 2: [8757/10940] ---- BYOL Validation Loss = 0.22598709166049957
30-01-2023 22:21:59 INFO Epoch 2: [8768/10940] ---- BYOL Training Loss = 0.2620253562927246
30-01-2023 22:22:27 INFO Epoch 2: [8779/10940] ---- BYOL Training Loss = 0.3061875104904175
30-01-2023 22:22:56 INFO Epoch 2: [8790/10940] ---- BYOL Training Loss = 0.3357678949832916
30-01-2023 22:23:24 INFO Epoch 2: [8801/10940] ---- BYOL Training Loss = 0.3290404677391052
30-01-2023 22:24:52 INFO Epoch 2: [8801/10940] ---- BYOL Validation Loss = 0.18452830612659454
30-01-2023 22:25:20 INFO Epoch 2: [8812/10940] ---- BYOL Training Loss = 0.24575722217559814
30-01-2023 22:25:49 INFO Epoch 2: [8823/10940] ---- BYOL Training Loss = 0.2527897357940674
30-01-2023 22:26:17 INFO Epoch 2: [8834/10940] ---- BYOL Training Loss = 0.24389071762561798
30-01-2023 22:26:46 INFO Epoch 2: [8845/10940] ---- BYOL Training Loss = 0.21157066524028778
30-01-2023 22:28:13 INFO Epoch 2: [8845/10940] ---- BYOL Validation Loss = 0.20671941339969635
30-01-2023 22:28:42 INFO Epoch 2: [8856/10940] ---- BYOL Training Loss = 0.23014184832572937
30-01-2023 22:29:10 INFO Epoch 2: [8867/10940] ---- BYOL Training Loss = 0.2727307677268982
30-01-2023 22:29:38 INFO Epoch 2: [8878/10940] ---- BYOL Training Loss = 0.2932489514350891
30-01-2023 22:30:07 INFO Epoch 2: [8889/10940] ---- BYOL Training Loss = 0.3033745288848877
30-01-2023 22:31:35 INFO Epoch 2: [8889/10940] ---- BYOL Validation Loss = 0.25473013520240784
30-01-2023 22:32:04 INFO Epoch 2: [8900/10940] ---- BYOL Training Loss = 0.2947724759578705
30-01-2023 22:32:32 INFO Epoch 2: [8911/10940] ---- BYOL Training Loss = 0.2786748707294464
30-01-2023 22:33:00 INFO Epoch 2: [8922/10940] ---- BYOL Training Loss = 0.28717532753944397
30-01-2023 22:33:29 INFO Epoch 2: [8933/10940] ---- BYOL Training Loss = 0.2756972908973694
30-01-2023 22:34:56 INFO Epoch 2: [8933/10940] ---- BYOL Validation Loss = 0.22393007576465607
30-01-2023 22:35:25 INFO Epoch 2: [8944/10940] ---- BYOL Training Loss = 0.2766597270965576
30-01-2023 22:35:54 INFO Epoch 2: [8955/10940] ---- BYOL Training Loss = 0.35162097215652466
30-01-2023 22:36:22 INFO Epoch 2: [8966/10940] ---- BYOL Training Loss = 0.3428598642349243
30-01-2023 22:36:50 INFO Epoch 2: [8977/10940] ---- BYOL Training Loss = 0.26863276958465576
30-01-2023 22:38:18 INFO Epoch 2: [8977/10940] ---- BYOL Validation Loss = 0.2325722873210907
30-01-2023 22:38:47 INFO Epoch 2: [8988/10940] ---- BYOL Training Loss = 0.250688374042511
30-01-2023 22:39:15 INFO Epoch 2: [8999/10940] ---- BYOL Training Loss = 0.25015872716903687
30-01-2023 22:39:43 INFO Epoch 2: [9010/10940] ---- BYOL Training Loss = 0.25911352038383484
30-01-2023 22:40:12 INFO Epoch 2: [9021/10940] ---- BYOL Training Loss = 0.28890278935432434
30-01-2023 22:41:40 INFO Epoch 2: [9021/10940] ---- BYOL Validation Loss = 0.2170781046152115
30-01-2023 22:42:08 INFO Epoch 2: [9032/10940] ---- BYOL Training Loss = 0.33947837352752686
30-01-2023 22:42:37 INFO Epoch 2: [9043/10940] ---- BYOL Training Loss = 0.365083783864975
30-01-2023 22:43:05 INFO Epoch 2: [9054/10940] ---- BYOL Training Loss = 0.31203004717826843
30-01-2023 22:43:33 INFO Epoch 2: [9065/10940] ---- BYOL Training Loss = 0.2831578850746155
30-01-2023 22:45:01 INFO Epoch 2: [9065/10940] ---- BYOL Validation Loss = 0.25585323572158813
30-01-2023 22:45:29 INFO Epoch 2: [9076/10940] ---- BYOL Training Loss = 0.2406356781721115
30-01-2023 22:45:58 INFO Epoch 2: [9087/10940] ---- BYOL Training Loss = 0.21421992778778076
30-01-2023 22:46:26 INFO Epoch 2: [9098/10940] ---- BYOL Training Loss = 0.2454686462879181
30-01-2023 22:46:54 INFO Epoch 2: [9109/10940] ---- BYOL Training Loss = 0.3077246844768524
30-01-2023 22:48:22 INFO Epoch 2: [9109/10940] ---- BYOL Validation Loss = 0.2231988161802292
30-01-2023 22:48:50 INFO Epoch 2: [9120/10940] ---- BYOL Training Loss = 0.30722078680992126
30-01-2023 22:49:19 INFO Epoch 2: [9131/10940] ---- BYOL Training Loss = 0.26667895913124084
30-01-2023 22:49:47 INFO Epoch 2: [9142/10940] ---- BYOL Training Loss = 0.26628097891807556
30-01-2023 22:50:16 INFO Epoch 2: [9153/10940] ---- BYOL Training Loss = 0.2523375451564789
30-01-2023 22:51:43 INFO Epoch 2: [9153/10940] ---- BYOL Validation Loss = 0.22773385047912598
30-01-2023 22:52:12 INFO Epoch 2: [9164/10940] ---- BYOL Training Loss = 0.2656623125076294
30-01-2023 22:52:40 INFO Epoch 2: [9175/10940] ---- BYOL Training Loss = 0.2825503945350647
30-01-2023 22:53:08 INFO Epoch 2: [9186/10940] ---- BYOL Training Loss = 0.31591469049453735
30-01-2023 22:53:37 INFO Epoch 2: [9197/10940] ---- BYOL Training Loss = 0.234532430768013
30-01-2023 22:55:05 INFO Epoch 2: [9197/10940] ---- BYOL Validation Loss = 0.21235322952270508
30-01-2023 22:55:33 INFO Epoch 2: [9208/10940] ---- BYOL Training Loss = 0.2639317512512207
30-01-2023 22:56:02 INFO Epoch 2: [9219/10940] ---- BYOL Training Loss = 0.2926831841468811
30-01-2023 22:56:30 INFO Epoch 2: [9230/10940] ---- BYOL Training Loss = 0.28725236654281616
30-01-2023 22:56:59 INFO Epoch 2: [9241/10940] ---- BYOL Training Loss = 0.2679142951965332
30-01-2023 22:58:26 INFO Epoch 2: [9241/10940] ---- BYOL Validation Loss = 0.23603127896785736
30-01-2023 22:58:55 INFO Epoch 2: [9252/10940] ---- BYOL Training Loss = 0.3157144784927368
30-01-2023 22:59:23 INFO Epoch 2: [9263/10940] ---- BYOL Training Loss = 0.3200526237487793
30-01-2023 22:59:52 INFO Epoch 2: [9274/10940] ---- BYOL Training Loss = 0.27268078923225403
30-01-2023 23:00:20 INFO Epoch 2: [9285/10940] ---- BYOL Training Loss = 0.22376716136932373
30-01-2023 23:01:48 INFO Epoch 2: [9285/10940] ---- BYOL Validation Loss = 0.20719017088413239
30-01-2023 23:02:17 INFO Epoch 2: [9296/10940] ---- BYOL Training Loss = 0.21455681324005127
30-01-2023 23:02:45 INFO Epoch 2: [9307/10940] ---- BYOL Training Loss = 0.26407676935195923
30-01-2023 23:03:13 INFO Epoch 2: [9318/10940] ---- BYOL Training Loss = 0.27783438563346863
30-01-2023 23:03:42 INFO Epoch 2: [9329/10940] ---- BYOL Training Loss = 0.22889967262744904
30-01-2023 23:05:10 INFO Epoch 2: [9329/10940] ---- BYOL Validation Loss = 0.2329881191253662
30-01-2023 23:05:38 INFO Epoch 2: [9340/10940] ---- BYOL Training Loss = 0.2866174876689911
30-01-2023 23:06:06 INFO Epoch 2: [9351/10940] ---- BYOL Training Loss = 0.26307326555252075
30-01-2023 23:06:35 INFO Epoch 2: [9362/10940] ---- BYOL Training Loss = 0.28150680661201477
30-01-2023 23:07:03 INFO Epoch 2: [9373/10940] ---- BYOL Training Loss = 0.2408423125743866
30-01-2023 23:08:31 INFO Epoch 2: [9373/10940] ---- BYOL Validation Loss = 0.19716490805149078
30-01-2023 23:09:00 INFO Epoch 2: [9384/10940] ---- BYOL Training Loss = 0.2449958622455597
30-01-2023 23:09:28 INFO Epoch 2: [9395/10940] ---- BYOL Training Loss = 0.23480920493602753
30-01-2023 23:09:56 INFO Epoch 2: [9406/10940] ---- BYOL Training Loss = 0.2380083054304123
30-01-2023 23:10:25 INFO Epoch 2: [9417/10940] ---- BYOL Training Loss = 0.23869943618774414
30-01-2023 23:11:53 INFO Epoch 2: [9417/10940] ---- BYOL Validation Loss = 0.1979726254940033
30-01-2023 23:12:21 INFO Epoch 2: [9428/10940] ---- BYOL Training Loss = 0.1958337128162384
30-01-2023 23:12:50 INFO Epoch 2: [9439/10940] ---- BYOL Training Loss = 0.213359996676445
30-01-2023 23:13:18 INFO Epoch 2: [9450/10940] ---- BYOL Training Loss = 0.2599276304244995
30-01-2023 23:13:47 INFO Epoch 2: [9461/10940] ---- BYOL Training Loss = 0.2401859313249588
30-01-2023 23:15:15 INFO Epoch 2: [9461/10940] ---- BYOL Validation Loss = 0.20319914817810059
30-01-2023 23:15:43 INFO Epoch 2: [9472/10940] ---- BYOL Training Loss = 0.23362299799919128
30-01-2023 23:16:11 INFO Epoch 2: [9483/10940] ---- BYOL Training Loss = 0.2469397485256195
30-01-2023 23:16:40 INFO Epoch 2: [9494/10940] ---- BYOL Training Loss = 0.2420680820941925
30-01-2023 23:17:08 INFO Epoch 2: [9505/10940] ---- BYOL Training Loss = 0.24815508723258972
30-01-2023 23:18:36 INFO Epoch 2: [9505/10940] ---- BYOL Validation Loss = 0.22166334092617035
30-01-2023 23:19:05 INFO Epoch 2: [9516/10940] ---- BYOL Training Loss = 0.2934894561767578
30-01-2023 23:19:33 INFO Epoch 2: [9527/10940] ---- BYOL Training Loss = 0.26949256658554077
30-01-2023 23:20:01 INFO Epoch 2: [9538/10940] ---- BYOL Training Loss = 0.2407018393278122
30-01-2023 23:20:30 INFO Epoch 2: [9549/10940] ---- BYOL Training Loss = 0.26934900879859924
30-01-2023 23:21:57 INFO Epoch 2: [9549/10940] ---- BYOL Validation Loss = 0.24174468219280243
30-01-2023 23:22:26 INFO Epoch 2: [9560/10940] ---- BYOL Training Loss = 0.2609679400920868
30-01-2023 23:22:55 INFO Epoch 2: [9571/10940] ---- BYOL Training Loss = 0.28820717334747314
30-01-2023 23:23:23 INFO Epoch 2: [9582/10940] ---- BYOL Training Loss = 0.27512234449386597
30-01-2023 23:23:52 INFO Epoch 2: [9593/10940] ---- BYOL Training Loss = 0.2435002624988556
30-01-2023 23:25:20 INFO Epoch 2: [9593/10940] ---- BYOL Validation Loss = 0.21926555037498474
30-01-2023 23:25:48 INFO Epoch 2: [9604/10940] ---- BYOL Training Loss = 0.2306208312511444
30-01-2023 23:26:17 INFO Epoch 2: [9615/10940] ---- BYOL Training Loss = 0.2817624509334564
30-01-2023 23:26:45 INFO Epoch 2: [9626/10940] ---- BYOL Training Loss = 0.3444945216178894
30-01-2023 23:27:14 INFO Epoch 2: [9637/10940] ---- BYOL Training Loss = 0.29694345593452454
30-01-2023 23:28:42 INFO Epoch 2: [9637/10940] ---- BYOL Validation Loss = 0.22537708282470703
30-01-2023 23:29:10 INFO Epoch 2: [9648/10940] ---- BYOL Training Loss = 0.2697378993034363
30-01-2023 23:29:39 INFO Epoch 2: [9659/10940] ---- BYOL Training Loss = 0.26347047090530396
30-01-2023 23:30:07 INFO Epoch 2: [9670/10940] ---- BYOL Training Loss = 0.25344914197921753
30-01-2023 23:30:36 INFO Epoch 2: [9681/10940] ---- BYOL Training Loss = 0.2661842107772827
30-01-2023 23:32:03 INFO Epoch 2: [9681/10940] ---- BYOL Validation Loss = 0.20820696651935577
30-01-2023 23:32:32 INFO Epoch 2: [9692/10940] ---- BYOL Training Loss = 0.28863295912742615
30-01-2023 23:33:01 INFO Epoch 2: [9703/10940] ---- BYOL Training Loss = 0.2903277575969696
30-01-2023 23:33:29 INFO Epoch 2: [9714/10940] ---- BYOL Training Loss = 0.30759674310684204
30-01-2023 23:33:58 INFO Epoch 2: [9725/10940] ---- BYOL Training Loss = 0.25967806577682495
30-01-2023 23:35:25 INFO Epoch 2: [9725/10940] ---- BYOL Validation Loss = 0.21053221821784973
30-01-2023 23:35:54 INFO Epoch 2: [9736/10940] ---- BYOL Training Loss = 0.2252664864063263
30-01-2023 23:36:22 INFO Epoch 2: [9747/10940] ---- BYOL Training Loss = 0.2610117793083191
30-01-2023 23:36:51 INFO Epoch 2: [9758/10940] ---- BYOL Training Loss = 0.2975718379020691
30-01-2023 23:37:19 INFO Epoch 2: [9769/10940] ---- BYOL Training Loss = 0.28786900639533997
30-01-2023 23:38:47 INFO Epoch 2: [9769/10940] ---- BYOL Validation Loss = 0.24144330620765686
30-01-2023 23:39:16 INFO Epoch 2: [9780/10940] ---- BYOL Training Loss = 0.23348179459571838
30-01-2023 23:39:44 INFO Epoch 2: [9791/10940] ---- BYOL Training Loss = 0.23854298889636993
30-01-2023 23:40:13 INFO Epoch 2: [9802/10940] ---- BYOL Training Loss = 0.27754098176956177
30-01-2023 23:40:41 INFO Epoch 2: [9813/10940] ---- BYOL Training Loss = 0.24768328666687012
30-01-2023 23:42:09 INFO Epoch 2: [9813/10940] ---- BYOL Validation Loss = 0.22556696832180023
30-01-2023 23:42:37 INFO Epoch 2: [9824/10940] ---- BYOL Training Loss = 0.2462770640850067
30-01-2023 23:43:06 INFO Epoch 2: [9835/10940] ---- BYOL Training Loss = 0.25718531012535095
30-01-2023 23:43:34 INFO Epoch 2: [9846/10940] ---- BYOL Training Loss = 0.2692197263240814
30-01-2023 23:44:03 INFO Epoch 2: [9857/10940] ---- BYOL Training Loss = 0.26605066657066345
30-01-2023 23:45:31 INFO Epoch 2: [9857/10940] ---- BYOL Validation Loss = 0.24513676762580872
30-01-2023 23:45:59 INFO Epoch 2: [9868/10940] ---- BYOL Training Loss = 0.28135359287261963
30-01-2023 23:46:28 INFO Epoch 2: [9879/10940] ---- BYOL Training Loss = 0.2870602607727051
30-01-2023 23:46:56 INFO Epoch 2: [9890/10940] ---- BYOL Training Loss = 0.27364861965179443
30-01-2023 23:47:25 INFO Epoch 2: [9901/10940] ---- BYOL Training Loss = 0.3079472482204437
30-01-2023 23:48:52 INFO Epoch 2: [9901/10940] ---- BYOL Validation Loss = 0.2140314280986786
30-01-2023 23:49:21 INFO Epoch 2: [9912/10940] ---- BYOL Training Loss = 0.25221413373947144
30-01-2023 23:49:49 INFO Epoch 2: [9923/10940] ---- BYOL Training Loss = 0.2467098981142044
30-01-2023 23:50:18 INFO Epoch 2: [9934/10940] ---- BYOL Training Loss = 0.22969011962413788
30-01-2023 23:50:46 INFO Epoch 2: [9945/10940] ---- BYOL Training Loss = 0.2360239326953888
30-01-2023 23:52:14 INFO Epoch 2: [9945/10940] ---- BYOL Validation Loss = 0.22929878532886505
30-01-2023 23:52:43 INFO Epoch 2: [9956/10940] ---- BYOL Training Loss = 0.30590540170669556
30-01-2023 23:53:11 INFO Epoch 2: [9967/10940] ---- BYOL Training Loss = 0.27268946170806885
30-01-2023 23:53:40 INFO Epoch 2: [9978/10940] ---- BYOL Training Loss = 0.28864094614982605
30-01-2023 23:54:08 INFO Epoch 2: [9989/10940] ---- BYOL Training Loss = 0.2418060600757599
30-01-2023 23:55:36 INFO Epoch 2: [9989/10940] ---- BYOL Validation Loss = 0.26386794447898865
30-01-2023 23:56:04 INFO Epoch 2: [10000/10940] ---- BYOL Training Loss = 0.2735978960990906
30-01-2023 23:56:33 INFO Epoch 2: [10011/10940] ---- BYOL Training Loss = 0.27666062116622925
30-01-2023 23:57:01 INFO Epoch 2: [10022/10940] ---- BYOL Training Loss = 0.2905498147010803
30-01-2023 23:57:30 INFO Epoch 2: [10033/10940] ---- BYOL Training Loss = 0.27873921394348145
30-01-2023 23:58:58 INFO Epoch 2: [10033/10940] ---- BYOL Validation Loss = 0.16708870232105255
30-01-2023 23:59:26 INFO Epoch 2: [10044/10940] ---- BYOL Training Loss = 0.24530450999736786
30-01-2023 23:59:54 INFO Epoch 2: [10055/10940] ---- BYOL Training Loss = 0.25245246291160583
31-01-2023 00:00:24 INFO Epoch 2: [10066/10940] ---- BYOL Training Loss = 0.2558629810810089
31-01-2023 00:00:52 INFO Epoch 2: [10077/10940] ---- BYOL Training Loss = 0.2383621633052826
31-01-2023 00:02:20 INFO Epoch 2: [10077/10940] ---- BYOL Validation Loss = 0.24426372349262238
31-01-2023 00:02:49 INFO Epoch 2: [10088/10940] ---- BYOL Training Loss = 0.22017686069011688
31-01-2023 00:03:17 INFO Epoch 2: [10099/10940] ---- BYOL Training Loss = 0.2442593276500702
31-01-2023 00:03:46 INFO Epoch 2: [10110/10940] ---- BYOL Training Loss = 0.2808965742588043
31-01-2023 00:04:14 INFO Epoch 2: [10121/10940] ---- BYOL Training Loss = 0.2793673872947693
31-01-2023 00:05:42 INFO Epoch 2: [10121/10940] ---- BYOL Validation Loss = 0.180245503783226
31-01-2023 00:06:11 INFO Epoch 2: [10132/10940] ---- BYOL Training Loss = 0.28682979941368103
31-01-2023 00:06:39 INFO Epoch 2: [10143/10940] ---- BYOL Training Loss = 0.3334921598434448
31-01-2023 00:07:08 INFO Epoch 2: [10154/10940] ---- BYOL Training Loss = 0.30409136414527893
31-01-2023 00:07:36 INFO Epoch 2: [10165/10940] ---- BYOL Training Loss = 0.34869787096977234
31-01-2023 00:09:04 INFO Epoch 2: [10165/10940] ---- BYOL Validation Loss = 0.2343408316373825
31-01-2023 00:09:33 INFO Epoch 2: [10176/10940] ---- BYOL Training Loss = 0.3458375334739685
31-01-2023 00:10:01 INFO Epoch 2: [10187/10940] ---- BYOL Training Loss = 0.2844121754169464
31-01-2023 00:10:30 INFO Epoch 2: [10198/10940] ---- BYOL Training Loss = 0.28452613949775696
31-01-2023 00:10:59 INFO Epoch 2: [10209/10940] ---- BYOL Training Loss = 0.24947524070739746
31-01-2023 00:12:26 INFO Epoch 2: [10209/10940] ---- BYOL Validation Loss = 0.20218899846076965
31-01-2023 00:12:55 INFO Epoch 2: [10220/10940] ---- BYOL Training Loss = 0.21148523688316345
31-01-2023 00:13:24 INFO Epoch 2: [10231/10940] ---- BYOL Training Loss = 0.23151513934135437
31-01-2023 00:13:52 INFO Epoch 2: [10242/10940] ---- BYOL Training Loss = 0.22464247047901154
31-01-2023 00:14:21 INFO Epoch 2: [10253/10940] ---- BYOL Training Loss = 0.22553303837776184
31-01-2023 00:15:49 INFO Epoch 2: [10253/10940] ---- BYOL Validation Loss = 0.2079860121011734
31-01-2023 00:16:17 INFO Epoch 2: [10264/10940] ---- BYOL Training Loss = 0.270285040140152
31-01-2023 00:16:45 INFO Epoch 2: [10275/10940] ---- BYOL Training Loss = 0.27043282985687256
31-01-2023 00:17:14 INFO Epoch 2: [10286/10940] ---- BYOL Training Loss = 0.22946500778198242
31-01-2023 00:17:42 INFO Epoch 2: [10297/10940] ---- BYOL Training Loss = 0.2189866602420807
31-01-2023 00:19:10 INFO Epoch 2: [10297/10940] ---- BYOL Validation Loss = 0.24335439503192902
31-01-2023 00:19:39 INFO Epoch 2: [10308/10940] ---- BYOL Training Loss = 0.27115598320961
31-01-2023 00:20:07 INFO Epoch 2: [10319/10940] ---- BYOL Training Loss = 0.27369651198387146
31-01-2023 00:20:36 INFO Epoch 2: [10330/10940] ---- BYOL Training Loss = 0.2652093768119812
31-01-2023 00:21:04 INFO Epoch 2: [10341/10940] ---- BYOL Training Loss = 0.263009250164032
31-01-2023 00:22:32 INFO Epoch 2: [10341/10940] ---- BYOL Validation Loss = 0.24259765446186066
31-01-2023 00:23:00 INFO Epoch 2: [10352/10940] ---- BYOL Training Loss = 0.26782113313674927
31-01-2023 00:23:29 INFO Epoch 2: [10363/10940] ---- BYOL Training Loss = 0.2890722453594208
31-01-2023 00:23:57 INFO Epoch 2: [10374/10940] ---- BYOL Training Loss = 0.27420446276664734
31-01-2023 00:24:26 INFO Epoch 2: [10385/10940] ---- BYOL Training Loss = 0.28065556287765503
31-01-2023 00:25:54 INFO Epoch 2: [10385/10940] ---- BYOL Validation Loss = 0.2295427769422531
31-01-2023 00:26:22 INFO Epoch 2: [10396/10940] ---- BYOL Training Loss = 0.25647562742233276
31-01-2023 00:26:51 INFO Epoch 2: [10407/10940] ---- BYOL Training Loss = 0.26073575019836426
31-01-2023 00:27:19 INFO Epoch 2: [10418/10940] ---- BYOL Training Loss = 0.22487971186637878
31-01-2023 00:27:48 INFO Epoch 2: [10429/10940] ---- BYOL Training Loss = 0.23960213363170624
31-01-2023 00:29:15 INFO Epoch 2: [10429/10940] ---- BYOL Validation Loss = 0.1813398152589798
31-01-2023 00:29:44 INFO Epoch 2: [10440/10940] ---- BYOL Training Loss = 0.26245492696762085
31-01-2023 00:30:13 INFO Epoch 2: [10451/10940] ---- BYOL Training Loss = 0.22313335537910461
31-01-2023 00:30:41 INFO Epoch 2: [10462/10940] ---- BYOL Training Loss = 0.22811312973499298
31-01-2023 00:31:10 INFO Epoch 2: [10473/10940] ---- BYOL Training Loss = 0.24436664581298828
31-01-2023 00:32:37 INFO Epoch 2: [10473/10940] ---- BYOL Validation Loss = 0.22764775156974792
31-01-2023 00:33:06 INFO Epoch 2: [10484/10940] ---- BYOL Training Loss = 0.27573901414871216
31-01-2023 00:33:35 INFO Epoch 2: [10495/10940] ---- BYOL Training Loss = 0.2770638167858124
31-01-2023 00:34:04 INFO Epoch 2: [10506/10940] ---- BYOL Training Loss = 0.24951234459877014
31-01-2023 00:34:32 INFO Epoch 2: [10517/10940] ---- BYOL Training Loss = 0.2462642937898636
31-01-2023 00:35:59 INFO Epoch 2: [10517/10940] ---- BYOL Validation Loss = 0.2031489759683609
31-01-2023 00:36:28 INFO Epoch 2: [10528/10940] ---- BYOL Training Loss = 0.23754426836967468
31-01-2023 00:36:57 INFO Epoch 2: [10539/10940] ---- BYOL Training Loss = 0.23974525928497314
31-01-2023 00:37:25 INFO Epoch 2: [10550/10940] ---- BYOL Training Loss = 0.24594374001026154
31-01-2023 00:37:54 INFO Epoch 2: [10561/10940] ---- BYOL Training Loss = 0.25068366527557373
31-01-2023 00:39:22 INFO Epoch 2: [10561/10940] ---- BYOL Validation Loss = 0.19746039807796478
31-01-2023 00:39:50 INFO Epoch 2: [10572/10940] ---- BYOL Training Loss = 0.20731210708618164
31-01-2023 00:40:19 INFO Epoch 2: [10583/10940] ---- BYOL Training Loss = 0.23205482959747314
31-01-2023 00:40:47 INFO Epoch 2: [10594/10940] ---- BYOL Training Loss = 0.27609413862228394
31-01-2023 00:41:16 INFO Epoch 2: [10605/10940] ---- BYOL Training Loss = 0.2631792724132538
31-01-2023 00:42:44 INFO Epoch 2: [10605/10940] ---- BYOL Validation Loss = 0.23308910429477692
31-01-2023 00:43:12 INFO Epoch 2: [10616/10940] ---- BYOL Training Loss = 0.2318800389766693
31-01-2023 00:43:41 INFO Epoch 2: [10627/10940] ---- BYOL Training Loss = 0.23042860627174377
31-01-2023 00:44:09 INFO Epoch 2: [10638/10940] ---- BYOL Training Loss = 0.28016120195388794
31-01-2023 00:44:38 INFO Epoch 2: [10649/10940] ---- BYOL Training Loss = 0.257894903421402
31-01-2023 00:46:06 INFO Epoch 2: [10649/10940] ---- BYOL Validation Loss = 0.17583730816841125
31-01-2023 00:46:34 INFO Epoch 2: [10660/10940] ---- BYOL Training Loss = 0.22508876025676727
31-01-2023 00:47:03 INFO Epoch 2: [10671/10940] ---- BYOL Training Loss = 0.2729116678237915
31-01-2023 00:47:32 INFO Epoch 2: [10682/10940] ---- BYOL Training Loss = 0.2845316231250763
31-01-2023 00:48:00 INFO Epoch 2: [10693/10940] ---- BYOL Training Loss = 0.2596985697746277
31-01-2023 00:49:28 INFO Epoch 2: [10693/10940] ---- BYOL Validation Loss = 0.225701242685318
31-01-2023 00:49:56 INFO Epoch 2: [10704/10940] ---- BYOL Training Loss = 0.2577911615371704
31-01-2023 00:50:25 INFO Epoch 2: [10715/10940] ---- BYOL Training Loss = 0.25415584444999695
31-01-2023 00:50:54 INFO Epoch 2: [10726/10940] ---- BYOL Training Loss = 0.2573488652706146
31-01-2023 00:51:23 INFO Epoch 2: [10737/10940] ---- BYOL Training Loss = 0.22524218261241913
31-01-2023 00:52:50 INFO Epoch 2: [10737/10940] ---- BYOL Validation Loss = 0.2135784924030304
31-01-2023 00:53:19 INFO Epoch 2: [10748/10940] ---- BYOL Training Loss = 0.240324929356575
31-01-2023 00:53:47 INFO Epoch 2: [10759/10940] ---- BYOL Training Loss = 0.3070574104785919
31-01-2023 00:54:16 INFO Epoch 2: [10770/10940] ---- BYOL Training Loss = 0.2725580036640167
31-01-2023 00:54:45 INFO Epoch 2: [10781/10940] ---- BYOL Training Loss = 0.2239803969860077
31-01-2023 00:56:12 INFO Epoch 2: [10781/10940] ---- BYOL Validation Loss = 0.16691668331623077
31-01-2023 00:56:41 INFO Epoch 2: [10792/10940] ---- BYOL Training Loss = 0.26026999950408936
31-01-2023 00:57:09 INFO Epoch 2: [10803/10940] ---- BYOL Training Loss = 0.2554480731487274
31-01-2023 00:57:38 INFO Epoch 2: [10814/10940] ---- BYOL Training Loss = 0.2277943193912506
31-01-2023 00:58:07 INFO Epoch 2: [10825/10940] ---- BYOL Training Loss = 0.22377853095531464
31-01-2023 00:59:34 INFO Epoch 2: [10825/10940] ---- BYOL Validation Loss = 0.21988143026828766
31-01-2023 01:00:03 INFO Epoch 2: [10836/10940] ---- BYOL Training Loss = 0.27218711376190186
31-01-2023 01:00:32 INFO Epoch 2: [10847/10940] ---- BYOL Training Loss = 0.27824273705482483
31-01-2023 01:01:00 INFO Epoch 2: [10858/10940] ---- BYOL Training Loss = 0.24180614948272705
31-01-2023 01:01:29 INFO Epoch 2: [10869/10940] ---- BYOL Training Loss = 0.27619391679763794
31-01-2023 01:02:57 INFO Epoch 2: [10869/10940] ---- BYOL Validation Loss = 0.22771689295768738
31-01-2023 01:03:25 INFO Epoch 2: [10880/10940] ---- BYOL Training Loss = 0.2606140971183777
31-01-2023 01:03:54 INFO Epoch 2: [10891/10940] ---- BYOL Training Loss = 0.2426082193851471
31-01-2023 01:04:22 INFO Epoch 2: [10902/10940] ---- BYOL Training Loss = 0.2596737742424011
31-01-2023 01:04:51 INFO Epoch 2: [10913/10940] ---- BYOL Training Loss = 0.3237910866737366
31-01-2023 01:06:18 INFO Epoch 2: [10913/10940] ---- BYOL Validation Loss = 0.2515498101711273
31-01-2023 01:06:47 INFO Epoch 2: [10924/10940] ---- BYOL Training Loss = 0.30623266100883484
31-01-2023 01:07:16 INFO Epoch 2: [10935/10940] ---- BYOL Training Loss = 0.2713232934474945
31-01-2023 01:07:29 INFO Starting Epoch: 3
31-01-2023 01:07:57 INFO Epoch 3: [12/10940] ---- BYOL Training Loss = 0.22926582396030426
31-01-2023 01:08:25 INFO Epoch 3: [23/10940] ---- BYOL Training Loss = 0.22086632251739502
31-01-2023 01:08:53 INFO Epoch 3: [34/10940] ---- BYOL Training Loss = 0.22210188210010529
31-01-2023 01:09:20 INFO Epoch 3: [45/10940] ---- BYOL Training Loss = 0.2216755598783493
31-01-2023 01:10:48 INFO Epoch 3: [45/10940] ---- BYOL Validation Loss = 0.22681845724582672
31-01-2023 01:11:15 INFO Epoch 3: [56/10940] ---- BYOL Training Loss = 0.22415423393249512
31-01-2023 01:11:43 INFO Epoch 3: [67/10940] ---- BYOL Training Loss = 0.2014012634754181
31-01-2023 01:12:10 INFO Epoch 3: [78/10940] ---- BYOL Training Loss = 0.23596517741680145
31-01-2023 01:12:38 INFO Epoch 3: [89/10940] ---- BYOL Training Loss = 0.2825622856616974
31-01-2023 01:14:05 INFO Epoch 3: [89/10940] ---- BYOL Validation Loss = 0.21595993638038635
31-01-2023 01:14:33 INFO Epoch 3: [100/10940] ---- BYOL Training Loss = 0.20865146815776825
31-01-2023 01:15:00 INFO Epoch 3: [111/10940] ---- BYOL Training Loss = 0.2255294770002365
31-01-2023 01:15:28 INFO Epoch 3: [122/10940] ---- BYOL Training Loss = 0.23734807968139648
31-01-2023 01:15:55 INFO Epoch 3: [133/10940] ---- BYOL Training Loss = 0.2514987587928772
31-01-2023 01:17:23 INFO Epoch 3: [133/10940] ---- BYOL Validation Loss = 0.19992341101169586
31-01-2023 01:17:51 INFO Epoch 3: [144/10940] ---- BYOL Training Loss = 0.2333430051803589
31-01-2023 01:18:18 INFO Epoch 3: [155/10940] ---- BYOL Training Loss = 0.2580743432044983
31-01-2023 01:18:46 INFO Epoch 3: [166/10940] ---- BYOL Training Loss = 0.2608809471130371
31-01-2023 01:19:13 INFO Epoch 3: [177/10940] ---- BYOL Training Loss = 0.2333303987979889
31-01-2023 01:20:41 INFO Epoch 3: [177/10940] ---- BYOL Validation Loss = 0.22645613551139832
31-01-2023 01:21:08 INFO Epoch 3: [188/10940] ---- BYOL Training Loss = 0.2434350699186325
31-01-2023 01:21:36 INFO Epoch 3: [199/10940] ---- BYOL Training Loss = 0.2735426425933838
31-01-2023 01:22:03 INFO Epoch 3: [210/10940] ---- BYOL Training Loss = 0.2897412180900574
31-01-2023 01:22:31 INFO Epoch 3: [221/10940] ---- BYOL Training Loss = 0.2625396251678467
31-01-2023 01:23:58 INFO Epoch 3: [221/10940] ---- BYOL Validation Loss = 0.24892078340053558
31-01-2023 01:24:26 INFO Epoch 3: [232/10940] ---- BYOL Training Loss = 0.2408522665500641
31-01-2023 01:24:53 INFO Epoch 3: [243/10940] ---- BYOL Training Loss = 0.2394794225692749
31-01-2023 01:25:21 INFO Epoch 3: [254/10940] ---- BYOL Training Loss = 0.2579236626625061
31-01-2023 01:25:48 INFO Epoch 3: [265/10940] ---- BYOL Training Loss = 0.24789714813232422
31-01-2023 01:27:16 INFO Epoch 3: [265/10940] ---- BYOL Validation Loss = 0.1710173785686493
31-01-2023 01:27:44 INFO Epoch 3: [276/10940] ---- BYOL Training Loss = 0.24108192324638367
31-01-2023 01:28:12 INFO Epoch 3: [287/10940] ---- BYOL Training Loss = 0.2576805651187897
31-01-2023 01:28:39 INFO Epoch 3: [298/10940] ---- BYOL Training Loss = 0.2298932820558548
31-01-2023 01:29:06 INFO Epoch 3: [309/10940] ---- BYOL Training Loss = 0.19930677115917206
31-01-2023 01:30:34 INFO Epoch 3: [309/10940] ---- BYOL Validation Loss = 0.18102744221687317
31-01-2023 01:31:02 INFO Epoch 3: [320/10940] ---- BYOL Training Loss = 0.19794532656669617
31-01-2023 01:31:29 INFO Epoch 3: [331/10940] ---- BYOL Training Loss = 0.2585600018501282
31-01-2023 01:31:57 INFO Epoch 3: [342/10940] ---- BYOL Training Loss = 0.275311142206192
31-01-2023 01:32:25 INFO Epoch 3: [353/10940] ---- BYOL Training Loss = 0.19302956759929657
31-01-2023 01:33:52 INFO Epoch 3: [353/10940] ---- BYOL Validation Loss = 0.19131764769554138
31-01-2023 01:34:20 INFO Epoch 3: [364/10940] ---- BYOL Training Loss = 0.1916693150997162
31-01-2023 01:34:48 INFO Epoch 3: [375/10940] ---- BYOL Training Loss = 0.2156178057193756
31-01-2023 01:35:15 INFO Epoch 3: [386/10940] ---- BYOL Training Loss = 0.2559658885002136
31-01-2023 01:35:43 INFO Epoch 3: [397/10940] ---- BYOL Training Loss = 0.24868683516979218
31-01-2023 01:37:10 INFO Epoch 3: [397/10940] ---- BYOL Validation Loss = 0.18304945528507233
31-01-2023 01:37:38 INFO Epoch 3: [408/10940] ---- BYOL Training Loss = 0.2334841787815094
31-01-2023 01:38:06 INFO Epoch 3: [419/10940] ---- BYOL Training Loss = 0.24416296184062958
31-01-2023 01:38:34 INFO Epoch 3: [430/10940] ---- BYOL Training Loss = 0.29995647072792053
31-01-2023 01:39:01 INFO Epoch 3: [441/10940] ---- BYOL Training Loss = 0.3267550468444824
31-01-2023 01:40:29 INFO Epoch 3: [441/10940] ---- BYOL Validation Loss = 0.2325732707977295
31-01-2023 01:40:56 INFO Epoch 3: [452/10940] ---- BYOL Training Loss = 0.25601425766944885
31-01-2023 01:41:24 INFO Epoch 3: [463/10940] ---- BYOL Training Loss = 0.22374483942985535
31-01-2023 01:41:51 INFO Epoch 3: [474/10940] ---- BYOL Training Loss = 0.2662651240825653
31-01-2023 01:42:19 INFO Epoch 3: [485/10940] ---- BYOL Training Loss = 0.24806499481201172
31-01-2023 01:43:46 INFO Epoch 3: [485/10940] ---- BYOL Validation Loss = 0.23494219779968262
31-01-2023 01:44:14 INFO Epoch 3: [496/10940] ---- BYOL Training Loss = 0.2294456511735916
31-01-2023 01:44:42 INFO Epoch 3: [507/10940] ---- BYOL Training Loss = 0.2539990544319153
31-01-2023 01:45:10 INFO Epoch 3: [518/10940] ---- BYOL Training Loss = 0.2871158719062805
31-01-2023 01:45:38 INFO Epoch 3: [529/10940] ---- BYOL Training Loss = 0.28050872683525085
31-01-2023 01:47:05 INFO Epoch 3: [529/10940] ---- BYOL Validation Loss = 0.20689484477043152
31-01-2023 01:47:33 INFO Epoch 3: [540/10940] ---- BYOL Training Loss = 0.2376284897327423
31-01-2023 01:48:01 INFO Epoch 3: [551/10940] ---- BYOL Training Loss = 0.18845078349113464
31-01-2023 01:48:28 INFO Epoch 3: [562/10940] ---- BYOL Training Loss = 0.18945786356925964
31-01-2023 01:48:56 INFO Epoch 3: [573/10940] ---- BYOL Training Loss = 0.23442582786083221
31-01-2023 01:50:23 INFO Epoch 3: [573/10940] ---- BYOL Validation Loss = 0.15323366224765778
31-01-2023 01:50:51 INFO Epoch 3: [584/10940] ---- BYOL Training Loss = 0.2526238262653351
31-01-2023 01:51:18 INFO Epoch 3: [595/10940] ---- BYOL Training Loss = 0.2613103985786438
31-01-2023 01:51:46 INFO Epoch 3: [606/10940] ---- BYOL Training Loss = 0.2425047606229782
31-01-2023 01:52:13 INFO Epoch 3: [617/10940] ---- BYOL Training Loss = 0.2389570027589798
31-01-2023 01:53:41 INFO Epoch 3: [617/10940] ---- BYOL Validation Loss = 0.2245863527059555
31-01-2023 01:54:09 INFO Epoch 3: [628/10940] ---- BYOL Training Loss = 0.2115175724029541
31-01-2023 01:54:36 INFO Epoch 3: [639/10940] ---- BYOL Training Loss = 0.19309411942958832
31-01-2023 01:55:04 INFO Epoch 3: [650/10940] ---- BYOL Training Loss = 0.23367340862751007
31-01-2023 01:55:31 INFO Epoch 3: [661/10940] ---- BYOL Training Loss = 0.278795063495636
31-01-2023 01:56:59 INFO Epoch 3: [661/10940] ---- BYOL Validation Loss = 0.2402794361114502
31-01-2023 01:57:27 INFO Epoch 3: [672/10940] ---- BYOL Training Loss = 0.252541720867157
31-01-2023 01:57:55 INFO Epoch 3: [683/10940] ---- BYOL Training Loss = 0.27628815174102783
31-01-2023 01:58:22 INFO Epoch 3: [694/10940] ---- BYOL Training Loss = 0.2986987829208374
31-01-2023 01:58:49 INFO Epoch 3: [705/10940] ---- BYOL Training Loss = 0.28949883580207825
31-01-2023 02:00:17 INFO Epoch 3: [705/10940] ---- BYOL Validation Loss = 0.16737087070941925
31-01-2023 02:00:45 INFO Epoch 3: [716/10940] ---- BYOL Training Loss = 0.27255895733833313
31-01-2023 02:01:12 INFO Epoch 3: [727/10940] ---- BYOL Training Loss = 0.2529776096343994
31-01-2023 02:01:40 INFO Epoch 3: [738/10940] ---- BYOL Training Loss = 0.26584190130233765
31-01-2023 02:02:07 INFO Epoch 3: [749/10940] ---- BYOL Training Loss = 0.2689588665962219
31-01-2023 02:03:35 INFO Epoch 3: [749/10940] ---- BYOL Validation Loss = 0.24556688964366913
31-01-2023 02:04:02 INFO Epoch 3: [760/10940] ---- BYOL Training Loss = 0.2617906928062439
31-01-2023 02:04:30 INFO Epoch 3: [771/10940] ---- BYOL Training Loss = 0.28657835721969604
31-01-2023 02:04:58 INFO Epoch 3: [782/10940] ---- BYOL Training Loss = 0.2748049795627594
31-01-2023 02:05:25 INFO Epoch 3: [793/10940] ---- BYOL Training Loss = 0.23216482996940613
31-01-2023 02:06:53 INFO Epoch 3: [793/10940] ---- BYOL Validation Loss = 0.18763117492198944
31-01-2023 02:07:21 INFO Epoch 3: [804/10940] ---- BYOL Training Loss = 0.20279189944267273
31-01-2023 02:07:48 INFO Epoch 3: [815/10940] ---- BYOL Training Loss = 0.17964079976081848
31-01-2023 02:08:16 INFO Epoch 3: [826/10940] ---- BYOL Training Loss = 0.1558251529932022
31-01-2023 02:08:43 INFO Epoch 3: [837/10940] ---- BYOL Training Loss = 0.21492083370685577
31-01-2023 02:10:11 INFO Epoch 3: [837/10940] ---- BYOL Validation Loss = 0.21495597064495087
31-01-2023 02:10:39 INFO Epoch 3: [848/10940] ---- BYOL Training Loss = 0.22515776753425598
31-01-2023 02:11:06 INFO Epoch 3: [859/10940] ---- BYOL Training Loss = 0.21490749716758728
31-01-2023 02:11:34 INFO Epoch 3: [870/10940] ---- BYOL Training Loss = 0.23111310601234436
31-01-2023 02:12:02 INFO Epoch 3: [881/10940] ---- BYOL Training Loss = 0.26133468747138977
31-01-2023 02:13:29 INFO Epoch 3: [881/10940] ---- BYOL Validation Loss = 0.17772133648395538
31-01-2023 02:13:57 INFO Epoch 3: [892/10940] ---- BYOL Training Loss = 0.28084373474121094
31-01-2023 02:14:24 INFO Epoch 3: [903/10940] ---- BYOL Training Loss = 0.2515375018119812
31-01-2023 02:14:52 INFO Epoch 3: [914/10940] ---- BYOL Training Loss = 0.25498542189598083
31-01-2023 02:15:20 INFO Epoch 3: [925/10940] ---- BYOL Training Loss = 0.2564379572868347
31-01-2023 02:16:47 INFO Epoch 3: [925/10940] ---- BYOL Validation Loss = 0.2241487205028534
31-01-2023 02:17:15 INFO Epoch 3: [936/10940] ---- BYOL Training Loss = 0.25738948583602905
31-01-2023 02:17:43 INFO Epoch 3: [947/10940] ---- BYOL Training Loss = 0.2761140465736389
31-01-2023 02:18:10 INFO Epoch 3: [958/10940] ---- BYOL Training Loss = 0.2868834435939789
31-01-2023 02:18:38 INFO Epoch 3: [969/10940] ---- BYOL Training Loss = 0.29621177911758423
31-01-2023 02:20:06 INFO Epoch 3: [969/10940] ---- BYOL Validation Loss = 0.2191389948129654
31-01-2023 02:20:33 INFO Epoch 3: [980/10940] ---- BYOL Training Loss = 0.2749917209148407
31-01-2023 02:21:01 INFO Epoch 3: [991/10940] ---- BYOL Training Loss = 0.275552898645401
31-01-2023 02:21:28 INFO Epoch 3: [1002/10940] ---- BYOL Training Loss = 0.23442773520946503
31-01-2023 02:21:56 INFO Epoch 3: [1013/10940] ---- BYOL Training Loss = 0.22325102984905243
31-01-2023 02:23:23 INFO Epoch 3: [1013/10940] ---- BYOL Validation Loss = 0.1921243816614151
31-01-2023 02:23:51 INFO Epoch 3: [1024/10940] ---- BYOL Training Loss = 0.1934531182050705
31-01-2023 02:24:19 INFO Epoch 3: [1035/10940] ---- BYOL Training Loss = 0.25159603357315063
31-01-2023 02:24:46 INFO Epoch 3: [1046/10940] ---- BYOL Training Loss = 0.29191210865974426
31-01-2023 02:25:14 INFO Epoch 3: [1057/10940] ---- BYOL Training Loss = 0.27982887625694275
31-01-2023 02:26:41 INFO Epoch 3: [1057/10940] ---- BYOL Validation Loss = 0.23248042166233063
31-01-2023 02:27:09 INFO Epoch 3: [1068/10940] ---- BYOL Training Loss = 0.22832968831062317
31-01-2023 02:27:37 INFO Epoch 3: [1079/10940] ---- BYOL Training Loss = 0.25191783905029297
31-01-2023 02:28:04 INFO Epoch 3: [1090/10940] ---- BYOL Training Loss = 0.2509731948375702
31-01-2023 02:28:32 INFO Epoch 3: [1101/10940] ---- BYOL Training Loss = 0.21081817150115967
31-01-2023 02:30:00 INFO Epoch 3: [1101/10940] ---- BYOL Validation Loss = 0.2211925983428955
31-01-2023 02:30:28 INFO Epoch 3: [1112/10940] ---- BYOL Training Loss = 0.22505220770835876
31-01-2023 02:30:55 INFO Epoch 3: [1123/10940] ---- BYOL Training Loss = 0.28414812684059143
31-01-2023 02:31:23 INFO Epoch 3: [1134/10940] ---- BYOL Training Loss = 0.294436514377594
31-01-2023 02:31:50 INFO Epoch 3: [1145/10940] ---- BYOL Training Loss = 0.3358317017555237
31-01-2023 02:33:18 INFO Epoch 3: [1145/10940] ---- BYOL Validation Loss = 0.21211454272270203
31-01-2023 02:33:46 INFO Epoch 3: [1156/10940] ---- BYOL Training Loss = 0.32841232419013977
31-01-2023 02:34:13 INFO Epoch 3: [1167/10940] ---- BYOL Training Loss = 0.33189675211906433
31-01-2023 02:34:41 INFO Epoch 3: [1178/10940] ---- BYOL Training Loss = 0.2698417603969574
31-01-2023 02:35:09 INFO Epoch 3: [1189/10940] ---- BYOL Training Loss = 0.265460729598999
31-01-2023 02:36:37 INFO Epoch 3: [1189/10940] ---- BYOL Validation Loss = 0.19132526218891144
31-01-2023 02:37:04 INFO Epoch 3: [1200/10940] ---- BYOL Training Loss = 0.22929735481739044
31-01-2023 02:37:32 INFO Epoch 3: [1211/10940] ---- BYOL Training Loss = 0.2360568791627884
31-01-2023 02:38:00 INFO Epoch 3: [1222/10940] ---- BYOL Training Loss = 0.30710965394973755
31-01-2023 02:38:27 INFO Epoch 3: [1233/10940] ---- BYOL Training Loss = 0.33018848299980164
31-01-2023 02:39:55 INFO Epoch 3: [1233/10940] ---- BYOL Validation Loss = 0.15873797237873077
31-01-2023 02:40:23 INFO Epoch 3: [1244/10940] ---- BYOL Training Loss = 0.23767518997192383
31-01-2023 02:40:50 INFO Epoch 3: [1255/10940] ---- BYOL Training Loss = 0.2476254254579544
31-01-2023 02:41:18 INFO Epoch 3: [1266/10940] ---- BYOL Training Loss = 0.24225449562072754
31-01-2023 02:41:46 INFO Epoch 3: [1277/10940] ---- BYOL Training Loss = 0.26959028840065
31-01-2023 02:43:13 INFO Epoch 3: [1277/10940] ---- BYOL Validation Loss = 0.22832782566547394
31-01-2023 02:43:41 INFO Epoch 3: [1288/10940] ---- BYOL Training Loss = 0.2643370032310486
31-01-2023 02:44:09 INFO Epoch 3: [1299/10940] ---- BYOL Training Loss = 0.23614713549613953
31-01-2023 02:44:36 INFO Epoch 3: [1310/10940] ---- BYOL Training Loss = 0.2753191590309143
31-01-2023 02:45:04 INFO Epoch 3: [1321/10940] ---- BYOL Training Loss = 0.2330750674009323
31-01-2023 02:46:32 INFO Epoch 3: [1321/10940] ---- BYOL Validation Loss = 0.19947831332683563
31-01-2023 02:46:59 INFO Epoch 3: [1332/10940] ---- BYOL Training Loss = 0.222367525100708
31-01-2023 02:47:27 INFO Epoch 3: [1343/10940] ---- BYOL Training Loss = 0.19138269126415253
31-01-2023 02:47:55 INFO Epoch 3: [1354/10940] ---- BYOL Training Loss = 0.20272207260131836
31-01-2023 02:48:23 INFO Epoch 3: [1365/10940] ---- BYOL Training Loss = 0.20794017612934113
31-01-2023 02:49:50 INFO Epoch 3: [1365/10940] ---- BYOL Validation Loss = 0.17313185334205627
31-01-2023 02:50:18 INFO Epoch 3: [1376/10940] ---- BYOL Training Loss = 0.19619081914424896
31-01-2023 02:50:46 INFO Epoch 3: [1387/10940] ---- BYOL Training Loss = 0.22652609646320343
31-01-2023 02:51:13 INFO Epoch 3: [1398/10940] ---- BYOL Training Loss = 0.23772351443767548
31-01-2023 02:51:41 INFO Epoch 3: [1409/10940] ---- BYOL Training Loss = 0.2568861246109009
31-01-2023 02:53:09 INFO Epoch 3: [1409/10940] ---- BYOL Validation Loss = 0.15669621527194977
31-01-2023 02:53:37 INFO Epoch 3: [1420/10940] ---- BYOL Training Loss = 0.25947532057762146
31-01-2023 02:54:04 INFO Epoch 3: [1431/10940] ---- BYOL Training Loss = 0.251001238822937
31-01-2023 02:54:32 INFO Epoch 3: [1442/10940] ---- BYOL Training Loss = 0.250385582447052
31-01-2023 02:54:59 INFO Epoch 3: [1453/10940] ---- BYOL Training Loss = 0.2592669129371643
31-01-2023 02:56:27 INFO Epoch 3: [1453/10940] ---- BYOL Validation Loss = 0.23247599601745605
31-01-2023 02:56:55 INFO Epoch 3: [1464/10940] ---- BYOL Training Loss = 0.24946793913841248
31-01-2023 02:57:22 INFO Epoch 3: [1475/10940] ---- BYOL Training Loss = 0.22883489727973938
31-01-2023 02:57:50 INFO Epoch 3: [1486/10940] ---- BYOL Training Loss = 0.22078219056129456
31-01-2023 02:58:18 INFO Epoch 3: [1497/10940] ---- BYOL Training Loss = 0.20204803347587585
31-01-2023 02:59:45 INFO Epoch 3: [1497/10940] ---- BYOL Validation Loss = 0.22026407718658447
31-01-2023 03:00:13 INFO Epoch 3: [1508/10940] ---- BYOL Training Loss = 0.256006121635437
31-01-2023 03:00:41 INFO Epoch 3: [1519/10940] ---- BYOL Training Loss = 0.29678767919540405
31-01-2023 03:01:08 INFO Epoch 3: [1530/10940] ---- BYOL Training Loss = 0.28630170226097107
31-01-2023 03:01:36 INFO Epoch 3: [1541/10940] ---- BYOL Training Loss = 0.23230063915252686
31-01-2023 03:03:04 INFO Epoch 3: [1541/10940] ---- BYOL Validation Loss = 0.21128833293914795
31-01-2023 03:03:32 INFO Epoch 3: [1552/10940] ---- BYOL Training Loss = 0.21571986377239227
31-01-2023 03:03:59 INFO Epoch 3: [1563/10940] ---- BYOL Training Loss = 0.24938654899597168
31-01-2023 03:04:27 INFO Epoch 3: [1574/10940] ---- BYOL Training Loss = 0.2778208553791046
31-01-2023 03:04:55 INFO Epoch 3: [1585/10940] ---- BYOL Training Loss = 0.2454548180103302
31-01-2023 03:06:22 INFO Epoch 3: [1585/10940] ---- BYOL Validation Loss = 0.17283964157104492
31-01-2023 03:06:50 INFO Epoch 3: [1596/10940] ---- BYOL Training Loss = 0.23256616294384003
31-01-2023 03:07:17 INFO Epoch 3: [1607/10940] ---- BYOL Training Loss = 0.26166659593582153
31-01-2023 03:07:45 INFO Epoch 3: [1618/10940] ---- BYOL Training Loss = 0.255331814289093
31-01-2023 03:08:12 INFO Epoch 3: [1629/10940] ---- BYOL Training Loss = 0.21107277274131775
31-01-2023 03:09:40 INFO Epoch 3: [1629/10940] ---- BYOL Validation Loss = 0.1750616580247879
31-01-2023 03:10:08 INFO Epoch 3: [1640/10940] ---- BYOL Training Loss = 0.24951867759227753
31-01-2023 03:10:36 INFO Epoch 3: [1651/10940] ---- BYOL Training Loss = 0.23725995421409607
31-01-2023 03:11:03 INFO Epoch 3: [1662/10940] ---- BYOL Training Loss = 0.24406559765338898
31-01-2023 03:11:31 INFO Epoch 3: [1673/10940] ---- BYOL Training Loss = 0.2600395083427429
31-01-2023 03:12:58 INFO Epoch 3: [1673/10940] ---- BYOL Validation Loss = 0.18868455290794373
31-01-2023 03:13:26 INFO Epoch 3: [1684/10940] ---- BYOL Training Loss = 0.22135598957538605
31-01-2023 03:13:54 INFO Epoch 3: [1695/10940] ---- BYOL Training Loss = 0.25465551018714905
31-01-2023 03:14:22 INFO Epoch 3: [1706/10940] ---- BYOL Training Loss = 0.2566100060939789
31-01-2023 03:14:49 INFO Epoch 3: [1717/10940] ---- BYOL Training Loss = 0.27666717767715454
31-01-2023 03:16:17 INFO Epoch 3: [1717/10940] ---- BYOL Validation Loss = 0.19727538526058197
31-01-2023 03:16:44 INFO Epoch 3: [1728/10940] ---- BYOL Training Loss = 0.30828145146369934
31-01-2023 03:17:12 INFO Epoch 3: [1739/10940] ---- BYOL Training Loss = 0.28373584151268005
31-01-2023 03:17:40 INFO Epoch 3: [1750/10940] ---- BYOL Training Loss = 0.1997600495815277
31-01-2023 03:18:08 INFO Epoch 3: [1761/10940] ---- BYOL Training Loss = 0.2167847901582718
31-01-2023 03:19:35 INFO Epoch 3: [1761/10940] ---- BYOL Validation Loss = 0.16160795092582703
31-01-2023 03:20:03 INFO Epoch 3: [1772/10940] ---- BYOL Training Loss = 0.23088626563549042
31-01-2023 03:20:31 INFO Epoch 3: [1783/10940] ---- BYOL Training Loss = 0.2878530025482178
31-01-2023 03:20:58 INFO Epoch 3: [1794/10940] ---- BYOL Training Loss = 0.28717583417892456
31-01-2023 03:21:26 INFO Epoch 3: [1805/10940] ---- BYOL Training Loss = 0.25393930077552795
31-01-2023 03:22:54 INFO Epoch 3: [1805/10940] ---- BYOL Validation Loss = 0.19175061583518982
31-01-2023 03:23:21 INFO Epoch 3: [1816/10940] ---- BYOL Training Loss = 0.2326260358095169
31-01-2023 03:23:49 INFO Epoch 3: [1827/10940] ---- BYOL Training Loss = 0.19868405163288116
31-01-2023 03:24:17 INFO Epoch 3: [1838/10940] ---- BYOL Training Loss = 0.24232812225818634
31-01-2023 03:24:44 INFO Epoch 3: [1849/10940] ---- BYOL Training Loss = 0.2919772267341614
31-01-2023 03:26:12 INFO Epoch 3: [1849/10940] ---- BYOL Validation Loss = 0.21769431233406067
31-01-2023 03:26:40 INFO Epoch 3: [1860/10940] ---- BYOL Training Loss = 0.2687518298625946
31-01-2023 03:27:08 INFO Epoch 3: [1871/10940] ---- BYOL Training Loss = 0.3346118927001953
31-01-2023 03:27:35 INFO Epoch 3: [1882/10940] ---- BYOL Training Loss = 0.28345787525177
31-01-2023 03:28:03 INFO Epoch 3: [1893/10940] ---- BYOL Training Loss = 0.2488904446363449
31-01-2023 03:29:31 INFO Epoch 3: [1893/10940] ---- BYOL Validation Loss = 0.2105250060558319
31-01-2023 03:29:58 INFO Epoch 3: [1904/10940] ---- BYOL Training Loss = 0.22281627357006073
31-01-2023 03:30:27 INFO Epoch 3: [1915/10940] ---- BYOL Training Loss = 0.22532279789447784
31-01-2023 03:30:54 INFO Epoch 3: [1926/10940] ---- BYOL Training Loss = 0.21555617451667786
31-01-2023 03:31:22 INFO Epoch 3: [1937/10940] ---- BYOL Training Loss = 0.20278039574623108
31-01-2023 03:32:49 INFO Epoch 3: [1937/10940] ---- BYOL Validation Loss = 0.1893240213394165
31-01-2023 03:33:17 INFO Epoch 3: [1948/10940] ---- BYOL Training Loss = 0.22121140360832214
31-01-2023 03:33:45 INFO Epoch 3: [1959/10940] ---- BYOL Training Loss = 0.25615572929382324
31-01-2023 03:34:13 INFO Epoch 3: [1970/10940] ---- BYOL Training Loss = 0.2604142129421234
31-01-2023 03:34:40 INFO Epoch 3: [1981/10940] ---- BYOL Training Loss = 0.24727892875671387
31-01-2023 03:36:08 INFO Epoch 3: [1981/10940] ---- BYOL Validation Loss = 0.1909770965576172
31-01-2023 03:36:36 INFO Epoch 3: [1992/10940] ---- BYOL Training Loss = 0.3255409896373749
31-01-2023 03:37:03 INFO Epoch 3: [2003/10940] ---- BYOL Training Loss = 0.2687048614025116
31-01-2023 03:37:31 INFO Epoch 3: [2014/10940] ---- BYOL Training Loss = 0.22962665557861328
31-01-2023 03:37:59 INFO Epoch 3: [2025/10940] ---- BYOL Training Loss = 0.24146458506584167
31-01-2023 03:39:26 INFO Epoch 3: [2025/10940] ---- BYOL Validation Loss = 0.1617983728647232
31-01-2023 03:39:54 INFO Epoch 3: [2036/10940] ---- BYOL Training Loss = 0.2199246883392334
31-01-2023 03:40:22 INFO Epoch 3: [2047/10940] ---- BYOL Training Loss = 0.2469266951084137
31-01-2023 03:40:49 INFO Epoch 3: [2058/10940] ---- BYOL Training Loss = 0.322138249874115
31-01-2023 03:41:17 INFO Epoch 3: [2069/10940] ---- BYOL Training Loss = 0.270244836807251
31-01-2023 03:42:45 INFO Epoch 3: [2069/10940] ---- BYOL Validation Loss = 0.21444280445575714
31-01-2023 03:43:13 INFO Epoch 3: [2080/10940] ---- BYOL Training Loss = 0.27333569526672363
31-01-2023 03:43:40 INFO Epoch 3: [2091/10940] ---- BYOL Training Loss = 0.2749176621437073
31-01-2023 03:44:08 INFO Epoch 3: [2102/10940] ---- BYOL Training Loss = 0.23028762638568878
31-01-2023 03:44:36 INFO Epoch 3: [2113/10940] ---- BYOL Training Loss = 0.1809651106595993
31-01-2023 03:46:03 INFO Epoch 3: [2113/10940] ---- BYOL Validation Loss = 0.18544019758701324
31-01-2023 03:46:31 INFO Epoch 3: [2124/10940] ---- BYOL Training Loss = 0.2074999362230301
31-01-2023 03:46:58 INFO Epoch 3: [2135/10940] ---- BYOL Training Loss = 0.2620941698551178
31-01-2023 03:47:26 INFO Epoch 3: [2146/10940] ---- BYOL Training Loss = 0.26839399337768555
31-01-2023 03:47:54 INFO Epoch 3: [2157/10940] ---- BYOL Training Loss = 0.27133601903915405
31-01-2023 03:49:21 INFO Epoch 3: [2157/10940] ---- BYOL Validation Loss = 0.16715125739574432
31-01-2023 03:49:49 INFO Epoch 3: [2168/10940] ---- BYOL Training Loss = 0.2215356081724167
31-01-2023 03:50:17 INFO Epoch 3: [2179/10940] ---- BYOL Training Loss = 0.26718640327453613
31-01-2023 03:50:45 INFO Epoch 3: [2190/10940] ---- BYOL Training Loss = 0.23790840804576874
31-01-2023 03:51:13 INFO Epoch 3: [2201/10940] ---- BYOL Training Loss = 0.24150128662586212
31-01-2023 03:52:40 INFO Epoch 3: [2201/10940] ---- BYOL Validation Loss = 0.21395066380500793
31-01-2023 03:53:08 INFO Epoch 3: [2212/10940] ---- BYOL Training Loss = 0.2620878219604492
31-01-2023 03:53:36 INFO Epoch 3: [2223/10940] ---- BYOL Training Loss = 0.3027244210243225
31-01-2023 03:54:04 INFO Epoch 3: [2234/10940] ---- BYOL Training Loss = 0.35172009468078613
31-01-2023 03:54:31 INFO Epoch 3: [2245/10940] ---- BYOL Training Loss = 0.2759684920310974
31-01-2023 03:55:59 INFO Epoch 3: [2245/10940] ---- BYOL Validation Loss = 0.23721548914909363
31-01-2023 03:56:26 INFO Epoch 3: [2256/10940] ---- BYOL Training Loss = 0.2755224108695984
31-01-2023 03:56:54 INFO Epoch 3: [2267/10940] ---- BYOL Training Loss = 0.26946955919265747
31-01-2023 03:57:22 INFO Epoch 3: [2278/10940] ---- BYOL Training Loss = 0.25033801794052124
31-01-2023 03:57:50 INFO Epoch 3: [2289/10940] ---- BYOL Training Loss = 0.24822941422462463
31-01-2023 03:59:17 INFO Epoch 3: [2289/10940] ---- BYOL Validation Loss = 0.22502252459526062
31-01-2023 03:59:45 INFO Epoch 3: [2300/10940] ---- BYOL Training Loss = 0.3084249496459961
31-01-2023 04:00:13 INFO Epoch 3: [2311/10940] ---- BYOL Training Loss = 0.26635926961898804
31-01-2023 04:00:41 INFO Epoch 3: [2322/10940] ---- BYOL Training Loss = 0.23503239452838898
31-01-2023 04:01:08 INFO Epoch 3: [2333/10940] ---- BYOL Training Loss = 0.26041215658187866
31-01-2023 04:02:36 INFO Epoch 3: [2333/10940] ---- BYOL Validation Loss = 0.2397812157869339
31-01-2023 04:03:03 INFO Epoch 3: [2344/10940] ---- BYOL Training Loss = 0.2880484163761139
31-01-2023 04:03:31 INFO Epoch 3: [2355/10940] ---- BYOL Training Loss = 0.32762017846107483
31-01-2023 04:03:59 INFO Epoch 3: [2366/10940] ---- BYOL Training Loss = 0.320436954498291
31-01-2023 04:04:26 INFO Epoch 3: [2377/10940] ---- BYOL Training Loss = 0.253039687871933
31-01-2023 04:05:54 INFO Epoch 3: [2377/10940] ---- BYOL Validation Loss = 0.17576013505458832
31-01-2023 04:06:22 INFO Epoch 3: [2388/10940] ---- BYOL Training Loss = 0.2341986894607544
31-01-2023 04:06:49 INFO Epoch 3: [2399/10940] ---- BYOL Training Loss = 0.2374185025691986
31-01-2023 04:07:17 INFO Epoch 3: [2410/10940] ---- BYOL Training Loss = 0.21817927062511444
31-01-2023 04:07:45 INFO Epoch 3: [2421/10940] ---- BYOL Training Loss = 0.2940812408924103
31-01-2023 04:09:12 INFO Epoch 3: [2421/10940] ---- BYOL Validation Loss = 0.23470020294189453
31-01-2023 04:09:40 INFO Epoch 3: [2432/10940] ---- BYOL Training Loss = 0.3317238390445709
31-01-2023 04:10:08 INFO Epoch 3: [2443/10940] ---- BYOL Training Loss = 0.26190346479415894
31-01-2023 04:10:36 INFO Epoch 3: [2454/10940] ---- BYOL Training Loss = 0.24815639853477478
31-01-2023 04:11:04 INFO Epoch 3: [2465/10940] ---- BYOL Training Loss = 0.26727741956710815
31-01-2023 04:12:31 INFO Epoch 3: [2465/10940] ---- BYOL Validation Loss = 0.20180417597293854
31-01-2023 04:12:59 INFO Epoch 3: [2476/10940] ---- BYOL Training Loss = 0.20261318981647491
31-01-2023 04:13:27 INFO Epoch 3: [2487/10940] ---- BYOL Training Loss = 0.2371862232685089
31-01-2023 04:13:54 INFO Epoch 3: [2498/10940] ---- BYOL Training Loss = 0.2952622175216675
31-01-2023 04:14:22 INFO Epoch 3: [2509/10940] ---- BYOL Training Loss = 0.23748064041137695
31-01-2023 04:15:49 INFO Epoch 3: [2509/10940] ---- BYOL Validation Loss = 0.2197437435388565
31-01-2023 04:16:17 INFO Epoch 3: [2520/10940] ---- BYOL Training Loss = 0.2262984961271286
31-01-2023 04:16:45 INFO Epoch 3: [2531/10940] ---- BYOL Training Loss = 0.23897013068199158
31-01-2023 04:17:12 INFO Epoch 3: [2542/10940] ---- BYOL Training Loss = 0.233712837100029
31-01-2023 04:17:40 INFO Epoch 3: [2553/10940] ---- BYOL Training Loss = 0.21332678198814392
31-01-2023 04:19:07 INFO Epoch 3: [2553/10940] ---- BYOL Validation Loss = 0.19855014979839325
31-01-2023 04:19:35 INFO Epoch 3: [2564/10940] ---- BYOL Training Loss = 0.1944449543952942
31-01-2023 04:20:03 INFO Epoch 3: [2575/10940] ---- BYOL Training Loss = 0.23057100176811218
31-01-2023 04:20:31 INFO Epoch 3: [2586/10940] ---- BYOL Training Loss = 0.23094525933265686
31-01-2023 04:20:59 INFO Epoch 3: [2597/10940] ---- BYOL Training Loss = 0.25872355699539185
31-01-2023 04:22:26 INFO Epoch 3: [2597/10940] ---- BYOL Validation Loss = 0.2072959989309311
31-01-2023 04:22:54 INFO Epoch 3: [2608/10940] ---- BYOL Training Loss = 0.2524290680885315
31-01-2023 04:23:22 INFO Epoch 3: [2619/10940] ---- BYOL Training Loss = 0.24190740287303925
31-01-2023 04:23:49 INFO Epoch 3: [2630/10940] ---- BYOL Training Loss = 0.2841206192970276
31-01-2023 04:24:17 INFO Epoch 3: [2641/10940] ---- BYOL Training Loss = 0.3025009036064148
31-01-2023 04:25:44 INFO Epoch 3: [2641/10940] ---- BYOL Validation Loss = 0.22421357035636902
31-01-2023 04:26:12 INFO Epoch 3: [2652/10940] ---- BYOL Training Loss = 0.23515932261943817
31-01-2023 04:26:40 INFO Epoch 3: [2663/10940] ---- BYOL Training Loss = 0.2221967726945877
31-01-2023 04:27:08 INFO Epoch 3: [2674/10940] ---- BYOL Training Loss = 0.23988835513591766
31-01-2023 04:27:35 INFO Epoch 3: [2685/10940] ---- BYOL Training Loss = 0.21685346961021423
31-01-2023 04:29:03 INFO Epoch 3: [2685/10940] ---- BYOL Validation Loss = 0.1468755155801773
31-01-2023 04:29:30 INFO Epoch 3: [2696/10940] ---- BYOL Training Loss = 0.24333925545215607
31-01-2023 04:29:58 INFO Epoch 3: [2707/10940] ---- BYOL Training Loss = 0.23688741028308868
31-01-2023 04:30:26 INFO Epoch 3: [2718/10940] ---- BYOL Training Loss = 0.23788976669311523
31-01-2023 04:30:54 INFO Epoch 3: [2729/10940] ---- BYOL Training Loss = 0.22995540499687195
31-01-2023 04:32:21 INFO Epoch 3: [2729/10940] ---- BYOL Validation Loss = 0.230428546667099
31-01-2023 04:32:49 INFO Epoch 3: [2740/10940] ---- BYOL Training Loss = 0.1900002509355545
31-01-2023 04:33:17 INFO Epoch 3: [2751/10940] ---- BYOL Training Loss = 0.21758201718330383
31-01-2023 04:33:45 INFO Epoch 3: [2762/10940] ---- BYOL Training Loss = 0.24641168117523193
31-01-2023 04:34:12 INFO Epoch 3: [2773/10940] ---- BYOL Training Loss = 0.24007180333137512
31-01-2023 04:35:40 INFO Epoch 3: [2773/10940] ---- BYOL Validation Loss = 0.19443045556545258
31-01-2023 04:36:08 INFO Epoch 3: [2784/10940] ---- BYOL Training Loss = 0.2982853949069977
31-01-2023 04:36:36 INFO Epoch 3: [2795/10940] ---- BYOL Training Loss = 0.2943543791770935
31-01-2023 04:37:03 INFO Epoch 3: [2806/10940] ---- BYOL Training Loss = 0.2561621367931366
31-01-2023 04:37:31 INFO Epoch 3: [2817/10940] ---- BYOL Training Loss = 0.27973729372024536
31-01-2023 04:38:58 INFO Epoch 3: [2817/10940] ---- BYOL Validation Loss = 0.21967943012714386
31-01-2023 04:39:27 INFO Epoch 3: [2828/10940] ---- BYOL Training Loss = 0.2759113907814026
31-01-2023 04:39:54 INFO Epoch 3: [2839/10940] ---- BYOL Training Loss = 0.23498694598674774
31-01-2023 04:40:22 INFO Epoch 3: [2850/10940] ---- BYOL Training Loss = 0.21045896410942078
31-01-2023 04:40:50 INFO Epoch 3: [2861/10940] ---- BYOL Training Loss = 0.24017691612243652
31-01-2023 04:42:17 INFO Epoch 3: [2861/10940] ---- BYOL Validation Loss = 0.20071281492710114
31-01-2023 04:42:45 INFO Epoch 3: [2872/10940] ---- BYOL Training Loss = 0.23112916946411133
31-01-2023 04:43:13 INFO Epoch 3: [2883/10940] ---- BYOL Training Loss = 0.2780887484550476
31-01-2023 04:43:41 INFO Epoch 3: [2894/10940] ---- BYOL Training Loss = 0.29270139336586
31-01-2023 04:44:08 INFO Epoch 3: [2905/10940] ---- BYOL Training Loss = 0.20538130402565002
31-01-2023 04:45:36 INFO Epoch 3: [2905/10940] ---- BYOL Validation Loss = 0.17795634269714355
31-01-2023 04:46:04 INFO Epoch 3: [2916/10940] ---- BYOL Training Loss = 0.21959738433361053
31-01-2023 04:46:32 INFO Epoch 3: [2927/10940] ---- BYOL Training Loss = 0.23429854214191437
31-01-2023 04:47:00 INFO Epoch 3: [2938/10940] ---- BYOL Training Loss = 0.2474232017993927
31-01-2023 04:47:28 INFO Epoch 3: [2949/10940] ---- BYOL Training Loss = 0.27744656801223755
31-01-2023 04:48:55 INFO Epoch 3: [2949/10940] ---- BYOL Validation Loss = 0.22199861705303192
31-01-2023 04:49:23 INFO Epoch 3: [2960/10940] ---- BYOL Training Loss = 0.29507675766944885
31-01-2023 04:49:51 INFO Epoch 3: [2971/10940] ---- BYOL Training Loss = 0.2611849904060364
31-01-2023 04:50:19 INFO Epoch 3: [2982/10940] ---- BYOL Training Loss = 0.2821201682090759
31-01-2023 04:50:47 INFO Epoch 3: [2993/10940] ---- BYOL Training Loss = 0.2749793231487274
31-01-2023 04:52:14 INFO Epoch 3: [2993/10940] ---- BYOL Validation Loss = 0.18904916942119598
31-01-2023 04:52:42 INFO Epoch 3: [3004/10940] ---- BYOL Training Loss = 0.27048417925834656
31-01-2023 04:53:10 INFO Epoch 3: [3015/10940] ---- BYOL Training Loss = 0.22101211547851562
31-01-2023 04:53:38 INFO Epoch 3: [3026/10940] ---- BYOL Training Loss = 0.20425057411193848
31-01-2023 04:54:06 INFO Epoch 3: [3037/10940] ---- BYOL Training Loss = 0.20074832439422607
31-01-2023 04:55:33 INFO Epoch 3: [3037/10940] ---- BYOL Validation Loss = 0.17617200314998627
31-01-2023 04:56:01 INFO Epoch 3: [3048/10940] ---- BYOL Training Loss = 0.20493777096271515
31-01-2023 04:56:29 INFO Epoch 3: [3059/10940] ---- BYOL Training Loss = 0.23875980079174042
31-01-2023 04:56:57 INFO Epoch 3: [3070/10940] ---- BYOL Training Loss = 0.2619793713092804
31-01-2023 04:57:24 INFO Epoch 3: [3081/10940] ---- BYOL Training Loss = 0.2726747393608093
31-01-2023 04:58:52 INFO Epoch 3: [3081/10940] ---- BYOL Validation Loss = 0.2280987948179245
31-01-2023 04:59:20 INFO Epoch 3: [3092/10940] ---- BYOL Training Loss = 0.22722482681274414
31-01-2023 04:59:47 INFO Epoch 3: [3103/10940] ---- BYOL Training Loss = 0.23939915001392365
31-01-2023 05:00:15 INFO Epoch 3: [3114/10940] ---- BYOL Training Loss = 0.22154200077056885
31-01-2023 05:00:43 INFO Epoch 3: [3125/10940] ---- BYOL Training Loss = 0.26947346329689026
31-01-2023 05:02:11 INFO Epoch 3: [3125/10940] ---- BYOL Validation Loss = 0.2422361671924591
31-01-2023 05:02:38 INFO Epoch 3: [3136/10940] ---- BYOL Training Loss = 0.30544644594192505
31-01-2023 05:03:07 INFO Epoch 3: [3147/10940] ---- BYOL Training Loss = 0.27935436367988586
31-01-2023 05:03:35 INFO Epoch 3: [3158/10940] ---- BYOL Training Loss = 0.25409629940986633
31-01-2023 05:04:02 INFO Epoch 3: [3169/10940] ---- BYOL Training Loss = 0.28417500853538513
31-01-2023 05:05:30 INFO Epoch 3: [3169/10940] ---- BYOL Validation Loss = 0.2538926303386688
31-01-2023 05:05:57 INFO Epoch 3: [3180/10940] ---- BYOL Training Loss = 0.30259284377098083
31-01-2023 05:06:25 INFO Epoch 3: [3191/10940] ---- BYOL Training Loss = 0.32107749581336975
31-01-2023 05:06:53 INFO Epoch 3: [3202/10940] ---- BYOL Training Loss = 0.29875099658966064
31-01-2023 05:07:21 INFO Epoch 3: [3213/10940] ---- BYOL Training Loss = 0.26541656255722046
31-01-2023 05:08:49 INFO Epoch 3: [3213/10940] ---- BYOL Validation Loss = 0.235650435090065
31-01-2023 05:09:16 INFO Epoch 3: [3224/10940] ---- BYOL Training Loss = 0.30725687742233276
31-01-2023 05:09:44 INFO Epoch 3: [3235/10940] ---- BYOL Training Loss = 0.2929053008556366
31-01-2023 05:10:13 INFO Epoch 3: [3246/10940] ---- BYOL Training Loss = 0.23498287796974182
31-01-2023 05:10:41 INFO Epoch 3: [3257/10940] ---- BYOL Training Loss = 0.24180379509925842
31-01-2023 05:12:08 INFO Epoch 3: [3257/10940] ---- BYOL Validation Loss = 0.23265454173088074
31-01-2023 05:12:36 INFO Epoch 3: [3268/10940] ---- BYOL Training Loss = 0.2683619558811188
31-01-2023 05:13:04 INFO Epoch 3: [3279/10940] ---- BYOL Training Loss = 0.241135835647583
31-01-2023 05:13:32 INFO Epoch 3: [3290/10940] ---- BYOL Training Loss = 0.2198658436536789
31-01-2023 05:13:59 INFO Epoch 3: [3301/10940] ---- BYOL Training Loss = 0.2598472833633423
31-01-2023 05:15:27 INFO Epoch 3: [3301/10940] ---- BYOL Validation Loss = 0.17872190475463867
31-01-2023 05:15:55 INFO Epoch 3: [3312/10940] ---- BYOL Training Loss = 0.2498817890882492
31-01-2023 05:16:22 INFO Epoch 3: [3323/10940] ---- BYOL Training Loss = 0.22884707152843475
31-01-2023 05:16:50 INFO Epoch 3: [3334/10940] ---- BYOL Training Loss = 0.24294450879096985
31-01-2023 05:17:18 INFO Epoch 3: [3345/10940] ---- BYOL Training Loss = 0.22176241874694824
31-01-2023 05:18:46 INFO Epoch 3: [3345/10940] ---- BYOL Validation Loss = 0.21291586756706238
31-01-2023 05:19:15 INFO Epoch 3: [3356/10940] ---- BYOL Training Loss = 0.2507077157497406
31-01-2023 05:19:43 INFO Epoch 3: [3367/10940] ---- BYOL Training Loss = 0.2495281994342804
31-01-2023 05:20:11 INFO Epoch 3: [3378/10940] ---- BYOL Training Loss = 0.24297603964805603
31-01-2023 05:20:39 INFO Epoch 3: [3389/10940] ---- BYOL Training Loss = 0.2322637140750885
31-01-2023 05:22:06 INFO Epoch 3: [3389/10940] ---- BYOL Validation Loss = 0.20928312838077545
31-01-2023 05:22:35 INFO Epoch 3: [3400/10940] ---- BYOL Training Loss = 0.2805028557777405
31-01-2023 05:23:02 INFO Epoch 3: [3411/10940] ---- BYOL Training Loss = 0.277313768863678
31-01-2023 05:23:30 INFO Epoch 3: [3422/10940] ---- BYOL Training Loss = 0.19974899291992188
31-01-2023 05:23:58 INFO Epoch 3: [3433/10940] ---- BYOL Training Loss = 0.2251674234867096
31-01-2023 05:25:26 INFO Epoch 3: [3433/10940] ---- BYOL Validation Loss = 0.17126737534999847
31-01-2023 05:25:54 INFO Epoch 3: [3444/10940] ---- BYOL Training Loss = 0.2560127377510071
31-01-2023 05:26:21 INFO Epoch 3: [3455/10940] ---- BYOL Training Loss = 0.25954675674438477
31-01-2023 05:26:49 INFO Epoch 3: [3466/10940] ---- BYOL Training Loss = 0.2863307297229767
31-01-2023 05:27:18 INFO Epoch 3: [3477/10940] ---- BYOL Training Loss = 0.23341146111488342
31-01-2023 05:28:45 INFO Epoch 3: [3477/10940] ---- BYOL Validation Loss = 0.17787699401378632
31-01-2023 05:29:13 INFO Epoch 3: [3488/10940] ---- BYOL Training Loss = 0.2640365958213806
31-01-2023 05:29:41 INFO Epoch 3: [3499/10940] ---- BYOL Training Loss = 0.24011468887329102
31-01-2023 05:30:09 INFO Epoch 3: [3510/10940] ---- BYOL Training Loss = 0.2572055459022522
31-01-2023 05:30:37 INFO Epoch 3: [3521/10940] ---- BYOL Training Loss = 0.2091076821088791
slurmstepd-landonia21: error: *** JOB 1507995 ON landonia21 CANCELLED AT 2023-01-31T05:31:14 DUE TO TIME LIMIT ***
