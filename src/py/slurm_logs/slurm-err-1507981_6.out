29-01-2023 21:46:10 INFO Running main & importing modules...
29-01-2023 21:46:28 INFO Parsed arguments: Namespace(batch_size=32, byol_ema_tau=0.95, debug=False, encoder='resnet18', encoder_layer_idx=-2, epochs=5, experiment_name='b-presnet18-e5-b32-t0_95-p64', input='/disk/scratch_big/s1908368/data', log_interval=1000, lr=0.001, output='/disk/scratch_big/s1908368/output', patch_size=64, pretrain_encoder=True, seed=23, simclr_tau=0.99, train_proportion=0.98, use_byol=True)
29-01-2023 21:46:28 INFO File at /disk/scratch_big/s1908368/data/patch_train_dataset_64.pk: False
29-01-2023 21:46:28 INFO File at /disk/scratch_big/s1908368/data/patch_val_dataset_64.pk: False
29-01-2023 21:46:28 INFO Directories found: ['1', '10', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '6', '7', '8', '9', 'patch_dataset.pk']
29-01-2023 21:46:28 INFO Files in first directory: ['82877952.png', '82877949.png', '82877955.png']
29-01-2023 21:46:28 INFO Fetching patches from folder: 43
29-01-2023 21:46:33 INFO Fetching patches from folder: 57
29-01-2023 21:46:36 INFO Fetching patches from folder: 32
29-01-2023 21:46:44 INFO Fetching patches from folder: 53
29-01-2023 21:46:48 INFO Fetching patches from folder: 51
29-01-2023 21:46:52 INFO Fetching patches from folder: 44
29-01-2023 21:46:56 INFO Fetching patches from folder: 39
29-01-2023 21:47:03 INFO Fetching patches from folder: 34
29-01-2023 21:47:10 INFO Fetching patches from folder: 55
29-01-2023 21:47:14 INFO Fetching patches from folder: 8
29-01-2023 21:47:21 INFO Fetching patches from folder: 2
29-01-2023 21:47:27 INFO Fetching patches from folder: 12
29-01-2023 21:47:30 INFO Fetching patches from folder: 36
29-01-2023 21:47:37 INFO Fetching patches from folder: 56
29-01-2023 21:47:40 INFO Fetching patches from folder: 21
29-01-2023 21:47:46 INFO Fetching patches from folder: 13
29-01-2023 21:47:52 INFO Fetching patches from folder: 26
29-01-2023 21:48:02 INFO Fetching patches from folder: 24
29-01-2023 21:48:12 INFO Fetching patches from folder: 10
29-01-2023 21:48:19 INFO Fetching patches from folder: 40
29-01-2023 21:48:24 INFO Fetching patches from folder: 48
29-01-2023 21:48:26 INFO Fetching patches from folder: 6
29-01-2023 21:48:31 INFO Fetching patches from folder: 22
29-01-2023 21:48:38 INFO Fetching patches from folder: 1
29-01-2023 21:48:46 INFO Fetching patches from folder: 49
29-01-2023 21:48:48 INFO Fetching patches from folder: 15
29-01-2023 21:48:56 INFO Fetching patches from folder: 7
29-01-2023 21:49:03 INFO Fetching patches from folder: 20
29-01-2023 21:49:06 INFO Fetching patches from folder: 33
29-01-2023 21:49:14 INFO Fetching patches from folder: 19
29-01-2023 21:49:21 INFO Fetching patches from folder: 41
29-01-2023 21:49:25 INFO Fetching patches from folder: 46
29-01-2023 21:49:29 INFO Fetching patches from folder: 35
29-01-2023 21:49:36 INFO Fetching patches from folder: 5
29-01-2023 21:49:42 INFO Fetching patches from folder: 38
29-01-2023 21:49:49 INFO Fetching patches from folder: 23
29-01-2023 21:49:59 INFO Fetching patches from folder: 42
29-01-2023 21:50:03 INFO Fetching patches from folder: 50
29-01-2023 21:50:06 INFO Fetching patches from folder: 16
29-01-2023 21:50:15 INFO Fetching patches from folder: 54
29-01-2023 21:50:19 INFO Fetching patches from folder: 9
29-01-2023 21:50:27 INFO Fetching patches from folder: 37
29-01-2023 21:50:33 INFO Fetching patches from folder: 30
29-01-2023 21:50:41 INFO Fetching patches from folder: 4
29-01-2023 21:50:47 INFO Fetching patches from folder: 3
29-01-2023 21:50:53 INFO Fetching patches from folder: 17
29-01-2023 21:51:02 INFO Fetching patches from folder: 18
29-01-2023 21:51:11 INFO Fetching patches from folder: 29
29-01-2023 21:51:19 INFO Fetching patches from folder: 14
29-01-2023 21:51:26 INFO Fetching patches from folder: 25
29-01-2023 21:51:36 INFO Fetching patches from folder: 52
29-01-2023 21:51:39 INFO Fetching patches from folder: 47
29-01-2023 21:51:43 INFO Fetching patches from folder: 45
29-01-2023 21:51:47 INFO Fetching patches from folder: 31
29-01-2023 21:51:55 INFO Generated 357207 positive pairs, after removing 264063 positive pairs.
29-01-2023 21:52:46 INFO Generated training dataset with 350062 samples.
29-01-2023 21:52:46 INFO Generated validation dataset with 7145 samples.
29-01-2023 21:52:47 INFO Using encoder resnet18 with pretrained weights = True
29-01-2023 21:52:48 INFO Using BYOL with tau = 0.95, with encoder layer index = -2
29-01-2023 21:52:48 INFO Using device: cuda
29-01-2023 21:52:58 INFO Starting Epoch: 1
29-01-2023 21:53:18 INFO Epoch 1: [12/10940] ---- BYOL Training Loss = 2.156696081161499
29-01-2023 21:53:36 INFO Epoch 1: [23/10940] ---- BYOL Training Loss = 1.7426977157592773
29-01-2023 21:53:53 INFO Epoch 1: [34/10940] ---- BYOL Training Loss = 1.4041359424591064
29-01-2023 21:54:11 INFO Epoch 1: [45/10940] ---- BYOL Training Loss = 1.1930601596832275
29-01-2023 21:55:03 INFO Epoch 1: [45/10940] ---- BYOL Validation Loss = 0.999230682849884
29-01-2023 21:55:21 INFO Epoch 1: [56/10940] ---- BYOL Training Loss = 0.993902325630188
29-01-2023 21:55:38 INFO Epoch 1: [67/10940] ---- BYOL Training Loss = 0.9309528470039368
29-01-2023 21:55:56 INFO Epoch 1: [78/10940] ---- BYOL Training Loss = 0.8524287343025208
29-01-2023 21:56:14 INFO Epoch 1: [89/10940] ---- BYOL Training Loss = 0.7506226897239685
29-01-2023 21:57:06 INFO Epoch 1: [89/10940] ---- BYOL Validation Loss = 0.7345499396324158
29-01-2023 21:57:24 INFO Epoch 1: [100/10940] ---- BYOL Training Loss = 0.7338720560073853
29-01-2023 21:57:42 INFO Epoch 1: [111/10940] ---- BYOL Training Loss = 0.6947660446166992
29-01-2023 21:57:59 INFO Epoch 1: [122/10940] ---- BYOL Training Loss = 0.6320633888244629
29-01-2023 21:58:17 INFO Epoch 1: [133/10940] ---- BYOL Training Loss = 0.6568551063537598
29-01-2023 21:59:09 INFO Epoch 1: [133/10940] ---- BYOL Validation Loss = 0.6287921071052551
29-01-2023 21:59:27 INFO Epoch 1: [144/10940] ---- BYOL Training Loss = 0.6645592451095581
29-01-2023 21:59:45 INFO Epoch 1: [155/10940] ---- BYOL Training Loss = 0.6170622110366821
29-01-2023 22:00:02 INFO Epoch 1: [166/10940] ---- BYOL Training Loss = 0.5980782508850098
29-01-2023 22:00:20 INFO Epoch 1: [177/10940] ---- BYOL Training Loss = 0.6479474306106567
29-01-2023 22:01:12 INFO Epoch 1: [177/10940] ---- BYOL Validation Loss = 0.6234702467918396
29-01-2023 22:01:30 INFO Epoch 1: [188/10940] ---- BYOL Training Loss = 0.6275902390480042
29-01-2023 22:01:48 INFO Epoch 1: [199/10940] ---- BYOL Training Loss = 0.5859786868095398
29-01-2023 22:02:05 INFO Epoch 1: [210/10940] ---- BYOL Training Loss = 0.5005460977554321
29-01-2023 22:02:23 INFO Epoch 1: [221/10940] ---- BYOL Training Loss = 0.46181201934814453
29-01-2023 22:03:15 INFO Epoch 1: [221/10940] ---- BYOL Validation Loss = 0.4773992896080017
29-01-2023 22:03:33 INFO Epoch 1: [232/10940] ---- BYOL Training Loss = 0.5448082685470581
29-01-2023 22:03:51 INFO Epoch 1: [243/10940] ---- BYOL Training Loss = 0.49580755829811096
29-01-2023 22:04:09 INFO Epoch 1: [254/10940] ---- BYOL Training Loss = 0.504790723323822
29-01-2023 22:04:26 INFO Epoch 1: [265/10940] ---- BYOL Training Loss = 0.5564818382263184
29-01-2023 22:05:18 INFO Epoch 1: [265/10940] ---- BYOL Validation Loss = 0.4996916651725769
29-01-2023 22:05:36 INFO Epoch 1: [276/10940] ---- BYOL Training Loss = 0.5364413261413574
29-01-2023 22:05:54 INFO Epoch 1: [287/10940] ---- BYOL Training Loss = 0.45871686935424805
29-01-2023 22:06:12 INFO Epoch 1: [298/10940] ---- BYOL Training Loss = 0.4651796817779541
29-01-2023 22:06:29 INFO Epoch 1: [309/10940] ---- BYOL Training Loss = 0.49243831634521484
29-01-2023 22:07:21 INFO Epoch 1: [309/10940] ---- BYOL Validation Loss = 0.4929111897945404
29-01-2023 22:07:39 INFO Epoch 1: [320/10940] ---- BYOL Training Loss = 0.5077387094497681
29-01-2023 22:07:57 INFO Epoch 1: [331/10940] ---- BYOL Training Loss = 0.5290854573249817
29-01-2023 22:08:15 INFO Epoch 1: [342/10940] ---- BYOL Training Loss = 0.5654093027114868
29-01-2023 22:08:32 INFO Epoch 1: [353/10940] ---- BYOL Training Loss = 0.5541082620620728
29-01-2023 22:09:25 INFO Epoch 1: [353/10940] ---- BYOL Validation Loss = 0.470735102891922
29-01-2023 22:09:42 INFO Epoch 1: [364/10940] ---- BYOL Training Loss = 0.563494086265564
29-01-2023 22:10:00 INFO Epoch 1: [375/10940] ---- BYOL Training Loss = 0.5080347657203674
29-01-2023 22:10:18 INFO Epoch 1: [386/10940] ---- BYOL Training Loss = 0.522104799747467
29-01-2023 22:10:36 INFO Epoch 1: [397/10940] ---- BYOL Training Loss = 0.5245141386985779
29-01-2023 22:11:28 INFO Epoch 1: [397/10940] ---- BYOL Validation Loss = 0.4626348912715912
29-01-2023 22:11:45 INFO Epoch 1: [408/10940] ---- BYOL Training Loss = 0.4587097764015198
29-01-2023 22:12:03 INFO Epoch 1: [419/10940] ---- BYOL Training Loss = 0.49505457282066345
29-01-2023 22:12:21 INFO Epoch 1: [430/10940] ---- BYOL Training Loss = 0.4923884868621826
29-01-2023 22:12:39 INFO Epoch 1: [441/10940] ---- BYOL Training Loss = 0.3856751024723053
29-01-2023 22:13:31 INFO Epoch 1: [441/10940] ---- BYOL Validation Loss = 0.44120869040489197
29-01-2023 22:13:49 INFO Epoch 1: [452/10940] ---- BYOL Training Loss = 0.4368153512477875
29-01-2023 22:14:06 INFO Epoch 1: [463/10940] ---- BYOL Training Loss = 0.48361554741859436
29-01-2023 22:14:24 INFO Epoch 1: [474/10940] ---- BYOL Training Loss = 0.501014769077301
29-01-2023 22:14:42 INFO Epoch 1: [485/10940] ---- BYOL Training Loss = 0.4075589179992676
29-01-2023 22:15:34 INFO Epoch 1: [485/10940] ---- BYOL Validation Loss = 0.4199216961860657
29-01-2023 22:15:52 INFO Epoch 1: [496/10940] ---- BYOL Training Loss = 0.4124223291873932
29-01-2023 22:16:10 INFO Epoch 1: [507/10940] ---- BYOL Training Loss = 0.47099870443344116
29-01-2023 22:16:28 INFO Epoch 1: [518/10940] ---- BYOL Training Loss = 0.4286137521266937
29-01-2023 22:16:46 INFO Epoch 1: [529/10940] ---- BYOL Training Loss = 0.41440510749816895
29-01-2023 22:17:38 INFO Epoch 1: [529/10940] ---- BYOL Validation Loss = 0.43235817551612854
29-01-2023 22:17:55 INFO Epoch 1: [540/10940] ---- BYOL Training Loss = 0.44448867440223694
29-01-2023 22:18:13 INFO Epoch 1: [551/10940] ---- BYOL Training Loss = 0.45383119583129883
29-01-2023 22:18:31 INFO Epoch 1: [562/10940] ---- BYOL Training Loss = 0.4203585088253021
29-01-2023 22:18:49 INFO Epoch 1: [573/10940] ---- BYOL Training Loss = 0.4167678952217102
29-01-2023 22:19:41 INFO Epoch 1: [573/10940] ---- BYOL Validation Loss = 0.3963410556316376
29-01-2023 22:19:59 INFO Epoch 1: [584/10940] ---- BYOL Training Loss = 0.40973907709121704
29-01-2023 22:20:17 INFO Epoch 1: [595/10940] ---- BYOL Training Loss = 0.44224968552589417
29-01-2023 22:20:35 INFO Epoch 1: [606/10940] ---- BYOL Training Loss = 0.4721546769142151
29-01-2023 22:20:52 INFO Epoch 1: [617/10940] ---- BYOL Training Loss = 0.4802115857601166
29-01-2023 22:21:45 INFO Epoch 1: [617/10940] ---- BYOL Validation Loss = 0.41343197226524353
29-01-2023 22:22:02 INFO Epoch 1: [628/10940] ---- BYOL Training Loss = 0.41889458894729614
29-01-2023 22:22:20 INFO Epoch 1: [639/10940] ---- BYOL Training Loss = 0.4654316008090973
29-01-2023 22:22:38 INFO Epoch 1: [650/10940] ---- BYOL Training Loss = 0.490396112203598
29-01-2023 22:22:56 INFO Epoch 1: [661/10940] ---- BYOL Training Loss = 0.4830094277858734
29-01-2023 22:23:48 INFO Epoch 1: [661/10940] ---- BYOL Validation Loss = 0.4170878231525421
29-01-2023 22:24:06 INFO Epoch 1: [672/10940] ---- BYOL Training Loss = 0.48763784766197205
29-01-2023 22:24:24 INFO Epoch 1: [683/10940] ---- BYOL Training Loss = 0.4681166112422943
29-01-2023 22:24:42 INFO Epoch 1: [694/10940] ---- BYOL Training Loss = 0.4501599669456482
29-01-2023 22:25:00 INFO Epoch 1: [705/10940] ---- BYOL Training Loss = 0.4773505628108978
29-01-2023 22:25:52 INFO Epoch 1: [705/10940] ---- BYOL Validation Loss = 0.38939687609672546
29-01-2023 22:26:10 INFO Epoch 1: [716/10940] ---- BYOL Training Loss = 0.43416324257850647
29-01-2023 22:26:28 INFO Epoch 1: [727/10940] ---- BYOL Training Loss = 0.4446372389793396
29-01-2023 22:26:45 INFO Epoch 1: [738/10940] ---- BYOL Training Loss = 0.5094948410987854
29-01-2023 22:27:03 INFO Epoch 1: [749/10940] ---- BYOL Training Loss = 0.47058558464050293
29-01-2023 22:27:55 INFO Epoch 1: [749/10940] ---- BYOL Validation Loss = 0.4079788029193878
29-01-2023 22:28:13 INFO Epoch 1: [760/10940] ---- BYOL Training Loss = 0.43053048849105835
29-01-2023 22:28:31 INFO Epoch 1: [771/10940] ---- BYOL Training Loss = 0.4138547480106354
29-01-2023 22:28:49 INFO Epoch 1: [782/10940] ---- BYOL Training Loss = 0.42595869302749634
29-01-2023 22:29:07 INFO Epoch 1: [793/10940] ---- BYOL Training Loss = 0.345200777053833
29-01-2023 22:29:59 INFO Epoch 1: [793/10940] ---- BYOL Validation Loss = 0.3865898549556732
29-01-2023 22:30:16 INFO Epoch 1: [804/10940] ---- BYOL Training Loss = 0.4059392511844635
29-01-2023 22:30:34 INFO Epoch 1: [815/10940] ---- BYOL Training Loss = 0.4837839603424072
29-01-2023 22:30:52 INFO Epoch 1: [826/10940] ---- BYOL Training Loss = 0.4388126730918884
29-01-2023 22:31:10 INFO Epoch 1: [837/10940] ---- BYOL Training Loss = 0.3939359486103058
29-01-2023 22:32:02 INFO Epoch 1: [837/10940] ---- BYOL Validation Loss = 0.41053083539009094
29-01-2023 22:32:20 INFO Epoch 1: [848/10940] ---- BYOL Training Loss = 0.45288795232772827
29-01-2023 22:32:37 INFO Epoch 1: [859/10940] ---- BYOL Training Loss = 0.4607406258583069
29-01-2023 22:32:55 INFO Epoch 1: [870/10940] ---- BYOL Training Loss = 0.40518492460250854
29-01-2023 22:33:13 INFO Epoch 1: [881/10940] ---- BYOL Training Loss = 0.41626086831092834
29-01-2023 22:34:05 INFO Epoch 1: [881/10940] ---- BYOL Validation Loss = 0.38564613461494446
29-01-2023 22:34:23 INFO Epoch 1: [892/10940] ---- BYOL Training Loss = 0.4358334541320801
29-01-2023 22:34:41 INFO Epoch 1: [903/10940] ---- BYOL Training Loss = 0.3837745785713196
29-01-2023 22:34:59 INFO Epoch 1: [914/10940] ---- BYOL Training Loss = 0.37844204902648926
29-01-2023 22:35:17 INFO Epoch 1: [925/10940] ---- BYOL Training Loss = 0.40835699439048767
29-01-2023 22:36:09 INFO Epoch 1: [925/10940] ---- BYOL Validation Loss = 0.37038636207580566
29-01-2023 22:36:26 INFO Epoch 1: [936/10940] ---- BYOL Training Loss = 0.40951189398765564
29-01-2023 22:36:44 INFO Epoch 1: [947/10940] ---- BYOL Training Loss = 0.38715559244155884
29-01-2023 22:37:02 INFO Epoch 1: [958/10940] ---- BYOL Training Loss = 0.41294336318969727
29-01-2023 22:37:20 INFO Epoch 1: [969/10940] ---- BYOL Training Loss = 0.41879597306251526
29-01-2023 22:38:12 INFO Epoch 1: [969/10940] ---- BYOL Validation Loss = 0.38786789774894714
29-01-2023 22:38:30 INFO Epoch 1: [980/10940] ---- BYOL Training Loss = 0.4143097996711731
29-01-2023 22:38:48 INFO Epoch 1: [991/10940] ---- BYOL Training Loss = 0.4169135093688965
29-01-2023 22:39:06 INFO Epoch 1: [1002/10940] ---- BYOL Training Loss = 0.3548690974712372
29-01-2023 22:39:24 INFO Epoch 1: [1013/10940] ---- BYOL Training Loss = 0.3378477096557617
29-01-2023 22:40:16 INFO Epoch 1: [1013/10940] ---- BYOL Validation Loss = 0.3704531490802765
29-01-2023 22:40:34 INFO Epoch 1: [1024/10940] ---- BYOL Training Loss = 0.3307415246963501
29-01-2023 22:40:52 INFO Epoch 1: [1035/10940] ---- BYOL Training Loss = 0.3893732726573944
29-01-2023 22:41:09 INFO Epoch 1: [1046/10940] ---- BYOL Training Loss = 0.40097060799598694
29-01-2023 22:41:28 INFO Epoch 1: [1057/10940] ---- BYOL Training Loss = 0.38992828130722046
29-01-2023 22:42:20 INFO Epoch 1: [1057/10940] ---- BYOL Validation Loss = 0.3784429728984833
29-01-2023 22:42:37 INFO Epoch 1: [1068/10940] ---- BYOL Training Loss = 0.37904638051986694
29-01-2023 22:42:55 INFO Epoch 1: [1079/10940] ---- BYOL Training Loss = 0.3676116466522217
29-01-2023 22:43:13 INFO Epoch 1: [1090/10940] ---- BYOL Training Loss = 0.36855223774909973
29-01-2023 22:43:31 INFO Epoch 1: [1101/10940] ---- BYOL Training Loss = 0.36103183031082153
29-01-2023 22:44:23 INFO Epoch 1: [1101/10940] ---- BYOL Validation Loss = 0.36485448479652405
29-01-2023 22:44:41 INFO Epoch 1: [1112/10940] ---- BYOL Training Loss = 0.4305834174156189
29-01-2023 22:44:59 INFO Epoch 1: [1123/10940] ---- BYOL Training Loss = 0.4209154546260834
29-01-2023 22:45:17 INFO Epoch 1: [1134/10940] ---- BYOL Training Loss = 0.38933032751083374
29-01-2023 22:45:35 INFO Epoch 1: [1145/10940] ---- BYOL Training Loss = 0.4168516993522644
29-01-2023 22:46:27 INFO Epoch 1: [1145/10940] ---- BYOL Validation Loss = 0.37464138865470886
29-01-2023 22:46:44 INFO Epoch 1: [1156/10940] ---- BYOL Training Loss = 0.3609512150287628
29-01-2023 22:47:02 INFO Epoch 1: [1167/10940] ---- BYOL Training Loss = 0.3943919241428375
29-01-2023 22:47:20 INFO Epoch 1: [1178/10940] ---- BYOL Training Loss = 0.40306463837623596
29-01-2023 22:47:38 INFO Epoch 1: [1189/10940] ---- BYOL Training Loss = 0.35948246717453003
29-01-2023 22:48:30 INFO Epoch 1: [1189/10940] ---- BYOL Validation Loss = 0.36318063735961914
29-01-2023 22:48:48 INFO Epoch 1: [1200/10940] ---- BYOL Training Loss = 0.3351989686489105
29-01-2023 22:49:06 INFO Epoch 1: [1211/10940] ---- BYOL Training Loss = 0.3933129906654358
29-01-2023 22:49:24 INFO Epoch 1: [1222/10940] ---- BYOL Training Loss = 0.41500911116600037
29-01-2023 22:49:42 INFO Epoch 1: [1233/10940] ---- BYOL Training Loss = 0.3814084529876709
29-01-2023 22:50:34 INFO Epoch 1: [1233/10940] ---- BYOL Validation Loss = 0.3626730144023895
29-01-2023 22:50:51 INFO Epoch 1: [1244/10940] ---- BYOL Training Loss = 0.3365495800971985
29-01-2023 22:51:09 INFO Epoch 1: [1255/10940] ---- BYOL Training Loss = 0.2913621962070465
29-01-2023 22:51:27 INFO Epoch 1: [1266/10940] ---- BYOL Training Loss = 0.32571932673454285
29-01-2023 22:51:45 INFO Epoch 1: [1277/10940] ---- BYOL Training Loss = 0.35874122381210327
29-01-2023 22:52:37 INFO Epoch 1: [1277/10940] ---- BYOL Validation Loss = 0.37561002373695374
29-01-2023 22:52:55 INFO Epoch 1: [1288/10940] ---- BYOL Training Loss = 0.34483855962753296
29-01-2023 22:53:13 INFO Epoch 1: [1299/10940] ---- BYOL Training Loss = 0.3445059657096863
29-01-2023 22:53:31 INFO Epoch 1: [1310/10940] ---- BYOL Training Loss = 0.371951162815094
29-01-2023 22:53:49 INFO Epoch 1: [1321/10940] ---- BYOL Training Loss = 0.40718722343444824
29-01-2023 22:54:41 INFO Epoch 1: [1321/10940] ---- BYOL Validation Loss = 0.36653003096580505
29-01-2023 22:54:58 INFO Epoch 1: [1332/10940] ---- BYOL Training Loss = 0.3415970206260681
29-01-2023 22:55:16 INFO Epoch 1: [1343/10940] ---- BYOL Training Loss = 0.3098509907722473
29-01-2023 22:55:35 INFO Epoch 1: [1354/10940] ---- BYOL Training Loss = 0.3497914671897888
29-01-2023 22:55:53 INFO Epoch 1: [1365/10940] ---- BYOL Training Loss = 0.35858291387557983
29-01-2023 22:56:45 INFO Epoch 1: [1365/10940] ---- BYOL Validation Loss = 0.3696041405200958
29-01-2023 22:57:02 INFO Epoch 1: [1376/10940] ---- BYOL Training Loss = 0.3575398921966553
29-01-2023 22:57:20 INFO Epoch 1: [1387/10940] ---- BYOL Training Loss = 0.37014859914779663
29-01-2023 22:57:38 INFO Epoch 1: [1398/10940] ---- BYOL Training Loss = 0.41747674345970154
29-01-2023 22:57:56 INFO Epoch 1: [1409/10940] ---- BYOL Training Loss = 0.39330917596817017
29-01-2023 22:58:48 INFO Epoch 1: [1409/10940] ---- BYOL Validation Loss = 0.36261889338493347
29-01-2023 22:59:06 INFO Epoch 1: [1420/10940] ---- BYOL Training Loss = 0.40706929564476013
29-01-2023 22:59:24 INFO Epoch 1: [1431/10940] ---- BYOL Training Loss = 0.3685011565685272
29-01-2023 22:59:42 INFO Epoch 1: [1442/10940] ---- BYOL Training Loss = 0.35059112310409546
29-01-2023 23:00:00 INFO Epoch 1: [1453/10940] ---- BYOL Training Loss = 0.3650490641593933
29-01-2023 23:00:52 INFO Epoch 1: [1453/10940] ---- BYOL Validation Loss = 0.3615589141845703
29-01-2023 23:01:09 INFO Epoch 1: [1464/10940] ---- BYOL Training Loss = 0.3858950436115265
29-01-2023 23:01:27 INFO Epoch 1: [1475/10940] ---- BYOL Training Loss = 0.3649373948574066
29-01-2023 23:01:45 INFO Epoch 1: [1486/10940] ---- BYOL Training Loss = 0.3743785619735718
29-01-2023 23:02:03 INFO Epoch 1: [1497/10940] ---- BYOL Training Loss = 0.3881303668022156
29-01-2023 23:02:56 INFO Epoch 1: [1497/10940] ---- BYOL Validation Loss = 0.3627701699733734
29-01-2023 23:03:13 INFO Epoch 1: [1508/10940] ---- BYOL Training Loss = 0.3560589849948883
29-01-2023 23:03:31 INFO Epoch 1: [1519/10940] ---- BYOL Training Loss = 0.39576685428619385
29-01-2023 23:03:49 INFO Epoch 1: [1530/10940] ---- BYOL Training Loss = 0.38313621282577515
29-01-2023 23:04:07 INFO Epoch 1: [1541/10940] ---- BYOL Training Loss = 0.3447411060333252
29-01-2023 23:04:59 INFO Epoch 1: [1541/10940] ---- BYOL Validation Loss = 0.36093470454216003
29-01-2023 23:05:17 INFO Epoch 1: [1552/10940] ---- BYOL Training Loss = 0.3847402036190033
29-01-2023 23:05:35 INFO Epoch 1: [1563/10940] ---- BYOL Training Loss = 0.39480316638946533
29-01-2023 23:05:53 INFO Epoch 1: [1574/10940] ---- BYOL Training Loss = 0.38100093603134155
29-01-2023 23:06:11 INFO Epoch 1: [1585/10940] ---- BYOL Training Loss = 0.3964579403400421
29-01-2023 23:07:03 INFO Epoch 1: [1585/10940] ---- BYOL Validation Loss = 0.35131531953811646
29-01-2023 23:07:21 INFO Epoch 1: [1596/10940] ---- BYOL Training Loss = 0.3673289120197296
29-01-2023 23:07:39 INFO Epoch 1: [1607/10940] ---- BYOL Training Loss = 0.38894373178482056
29-01-2023 23:07:57 INFO Epoch 1: [1618/10940] ---- BYOL Training Loss = 0.40938958525657654
29-01-2023 23:08:15 INFO Epoch 1: [1629/10940] ---- BYOL Training Loss = 0.4007539749145508
29-01-2023 23:09:07 INFO Epoch 1: [1629/10940] ---- BYOL Validation Loss = 0.36036452651023865
29-01-2023 23:09:24 INFO Epoch 1: [1640/10940] ---- BYOL Training Loss = 0.3742736876010895
29-01-2023 23:09:42 INFO Epoch 1: [1651/10940] ---- BYOL Training Loss = 0.33129066228866577
29-01-2023 23:10:00 INFO Epoch 1: [1662/10940] ---- BYOL Training Loss = 0.29256471991539
29-01-2023 23:10:18 INFO Epoch 1: [1673/10940] ---- BYOL Training Loss = 0.365203320980072
29-01-2023 23:11:11 INFO Epoch 1: [1673/10940] ---- BYOL Validation Loss = 0.35874423384666443
29-01-2023 23:11:28 INFO Epoch 1: [1684/10940] ---- BYOL Training Loss = 0.41081494092941284
29-01-2023 23:11:46 INFO Epoch 1: [1695/10940] ---- BYOL Training Loss = 0.37401461601257324
29-01-2023 23:12:04 INFO Epoch 1: [1706/10940] ---- BYOL Training Loss = 0.3447851836681366
29-01-2023 23:12:22 INFO Epoch 1: [1717/10940] ---- BYOL Training Loss = 0.3336791396141052
29-01-2023 23:13:14 INFO Epoch 1: [1717/10940] ---- BYOL Validation Loss = 0.34516552090644836
29-01-2023 23:13:32 INFO Epoch 1: [1728/10940] ---- BYOL Training Loss = 0.36526256799697876
29-01-2023 23:13:50 INFO Epoch 1: [1739/10940] ---- BYOL Training Loss = 0.3570139408111572
29-01-2023 23:14:08 INFO Epoch 1: [1750/10940] ---- BYOL Training Loss = 0.3366784453392029
29-01-2023 23:14:26 INFO Epoch 1: [1761/10940] ---- BYOL Training Loss = 0.33054691553115845
29-01-2023 23:15:18 INFO Epoch 1: [1761/10940] ---- BYOL Validation Loss = 0.34739670157432556
29-01-2023 23:15:35 INFO Epoch 1: [1772/10940] ---- BYOL Training Loss = 0.3389463424682617
29-01-2023 23:15:53 INFO Epoch 1: [1783/10940] ---- BYOL Training Loss = 0.3219534456729889
29-01-2023 23:16:12 INFO Epoch 1: [1794/10940] ---- BYOL Training Loss = 0.35876214504241943
29-01-2023 23:16:30 INFO Epoch 1: [1805/10940] ---- BYOL Training Loss = 0.42229628562927246
29-01-2023 23:17:22 INFO Epoch 1: [1805/10940] ---- BYOL Validation Loss = 0.34748077392578125
29-01-2023 23:17:40 INFO Epoch 1: [1816/10940] ---- BYOL Training Loss = 0.3891505002975464
29-01-2023 23:17:58 INFO Epoch 1: [1827/10940] ---- BYOL Training Loss = 0.3461928367614746
29-01-2023 23:18:16 INFO Epoch 1: [1838/10940] ---- BYOL Training Loss = 0.3894360065460205
29-01-2023 23:18:34 INFO Epoch 1: [1849/10940] ---- BYOL Training Loss = 0.38743168115615845
29-01-2023 23:19:26 INFO Epoch 1: [1849/10940] ---- BYOL Validation Loss = 0.34859490394592285
29-01-2023 23:19:44 INFO Epoch 1: [1860/10940] ---- BYOL Training Loss = 0.3756639361381531
29-01-2023 23:20:02 INFO Epoch 1: [1871/10940] ---- BYOL Training Loss = 0.4623583257198334
29-01-2023 23:20:20 INFO Epoch 1: [1882/10940] ---- BYOL Training Loss = 0.3750421106815338
29-01-2023 23:20:38 INFO Epoch 1: [1893/10940] ---- BYOL Training Loss = 0.3394961655139923
29-01-2023 23:21:30 INFO Epoch 1: [1893/10940] ---- BYOL Validation Loss = 0.3629014194011688
29-01-2023 23:21:47 INFO Epoch 1: [1904/10940] ---- BYOL Training Loss = 0.4017952084541321
29-01-2023 23:22:05 INFO Epoch 1: [1915/10940] ---- BYOL Training Loss = 0.3908385634422302
29-01-2023 23:22:23 INFO Epoch 1: [1926/10940] ---- BYOL Training Loss = 0.3741878569126129
29-01-2023 23:22:41 INFO Epoch 1: [1937/10940] ---- BYOL Training Loss = 0.35153889656066895
29-01-2023 23:23:33 INFO Epoch 1: [1937/10940] ---- BYOL Validation Loss = 0.34373709559440613
29-01-2023 23:23:51 INFO Epoch 1: [1948/10940] ---- BYOL Training Loss = 0.37585821747779846
29-01-2023 23:24:09 INFO Epoch 1: [1959/10940] ---- BYOL Training Loss = 0.35111287236213684
29-01-2023 23:24:27 INFO Epoch 1: [1970/10940] ---- BYOL Training Loss = 0.33581286668777466
29-01-2023 23:24:46 INFO Epoch 1: [1981/10940] ---- BYOL Training Loss = 0.3432690501213074
29-01-2023 23:25:38 INFO Epoch 1: [1981/10940] ---- BYOL Validation Loss = 0.33856672048568726
29-01-2023 23:25:55 INFO Epoch 1: [1992/10940] ---- BYOL Training Loss = 0.3045058250427246
29-01-2023 23:26:13 INFO Epoch 1: [2003/10940] ---- BYOL Training Loss = 0.3342081904411316
29-01-2023 23:26:31 INFO Epoch 1: [2014/10940] ---- BYOL Training Loss = 0.31606370210647583
29-01-2023 23:26:49 INFO Epoch 1: [2025/10940] ---- BYOL Training Loss = 0.32815831899642944
29-01-2023 23:27:41 INFO Epoch 1: [2025/10940] ---- BYOL Validation Loss = 0.34498342871665955
29-01-2023 23:27:59 INFO Epoch 1: [2036/10940] ---- BYOL Training Loss = 0.3137827217578888
29-01-2023 23:28:17 INFO Epoch 1: [2047/10940] ---- BYOL Training Loss = 0.2935972511768341
29-01-2023 23:28:35 INFO Epoch 1: [2058/10940] ---- BYOL Training Loss = 0.3193822503089905
29-01-2023 23:28:53 INFO Epoch 1: [2069/10940] ---- BYOL Training Loss = 0.29724588990211487
29-01-2023 23:29:45 INFO Epoch 1: [2069/10940] ---- BYOL Validation Loss = 0.3431830406188965
29-01-2023 23:30:03 INFO Epoch 1: [2080/10940] ---- BYOL Training Loss = 0.2745376229286194
29-01-2023 23:30:21 INFO Epoch 1: [2091/10940] ---- BYOL Training Loss = 0.343265175819397
29-01-2023 23:30:39 INFO Epoch 1: [2102/10940] ---- BYOL Training Loss = 0.33001959323883057
29-01-2023 23:30:57 INFO Epoch 1: [2113/10940] ---- BYOL Training Loss = 0.3661728501319885
29-01-2023 23:31:49 INFO Epoch 1: [2113/10940] ---- BYOL Validation Loss = 0.35893338918685913
29-01-2023 23:32:07 INFO Epoch 1: [2124/10940] ---- BYOL Training Loss = 0.4403817653656006
29-01-2023 23:32:25 INFO Epoch 1: [2135/10940] ---- BYOL Training Loss = 0.3871377110481262
29-01-2023 23:32:43 INFO Epoch 1: [2146/10940] ---- BYOL Training Loss = 0.39985111355781555
29-01-2023 23:33:01 INFO Epoch 1: [2157/10940] ---- BYOL Training Loss = 0.36645692586898804
29-01-2023 23:33:53 INFO Epoch 1: [2157/10940] ---- BYOL Validation Loss = 0.34390705823898315
29-01-2023 23:34:11 INFO Epoch 1: [2168/10940] ---- BYOL Training Loss = 0.3233589231967926
29-01-2023 23:34:29 INFO Epoch 1: [2179/10940] ---- BYOL Training Loss = 0.36587005853652954
29-01-2023 23:34:47 INFO Epoch 1: [2190/10940] ---- BYOL Training Loss = 0.3379196226596832
29-01-2023 23:35:05 INFO Epoch 1: [2201/10940] ---- BYOL Training Loss = 0.3182419538497925
29-01-2023 23:35:57 INFO Epoch 1: [2201/10940] ---- BYOL Validation Loss = 0.33525797724723816
29-01-2023 23:36:15 INFO Epoch 1: [2212/10940] ---- BYOL Training Loss = 0.38049057126045227
29-01-2023 23:36:33 INFO Epoch 1: [2223/10940] ---- BYOL Training Loss = 0.37491631507873535
29-01-2023 23:36:51 INFO Epoch 1: [2234/10940] ---- BYOL Training Loss = 0.32431262731552124
29-01-2023 23:37:09 INFO Epoch 1: [2245/10940] ---- BYOL Training Loss = 0.3679348826408386
29-01-2023 23:38:01 INFO Epoch 1: [2245/10940] ---- BYOL Validation Loss = 0.3316647410392761
29-01-2023 23:38:19 INFO Epoch 1: [2256/10940] ---- BYOL Training Loss = 0.3319142460823059
29-01-2023 23:38:37 INFO Epoch 1: [2267/10940] ---- BYOL Training Loss = 0.37234172224998474
29-01-2023 23:38:55 INFO Epoch 1: [2278/10940] ---- BYOL Training Loss = 0.3666025996208191
29-01-2023 23:39:13 INFO Epoch 1: [2289/10940] ---- BYOL Training Loss = 0.2937648296356201
29-01-2023 23:40:05 INFO Epoch 1: [2289/10940] ---- BYOL Validation Loss = 0.32414284348487854
29-01-2023 23:40:23 INFO Epoch 1: [2300/10940] ---- BYOL Training Loss = 0.3574100136756897
29-01-2023 23:40:41 INFO Epoch 1: [2311/10940] ---- BYOL Training Loss = 0.3741081953048706
29-01-2023 23:40:59 INFO Epoch 1: [2322/10940] ---- BYOL Training Loss = 0.31683364510536194
29-01-2023 23:41:17 INFO Epoch 1: [2333/10940] ---- BYOL Training Loss = 0.3399520516395569
29-01-2023 23:42:09 INFO Epoch 1: [2333/10940] ---- BYOL Validation Loss = 0.3229374885559082
29-01-2023 23:42:27 INFO Epoch 1: [2344/10940] ---- BYOL Training Loss = 0.3071505129337311
29-01-2023 23:42:45 INFO Epoch 1: [2355/10940] ---- BYOL Training Loss = 0.2744371294975281
29-01-2023 23:43:03 INFO Epoch 1: [2366/10940] ---- BYOL Training Loss = 0.29127639532089233
29-01-2023 23:43:21 INFO Epoch 1: [2377/10940] ---- BYOL Training Loss = 0.3313734531402588
29-01-2023 23:44:13 INFO Epoch 1: [2377/10940] ---- BYOL Validation Loss = 0.3372977375984192
29-01-2023 23:44:31 INFO Epoch 1: [2388/10940] ---- BYOL Training Loss = 0.32067522406578064
29-01-2023 23:44:49 INFO Epoch 1: [2399/10940] ---- BYOL Training Loss = 0.27502086758613586
29-01-2023 23:45:07 INFO Epoch 1: [2410/10940] ---- BYOL Training Loss = 0.2710620164871216
29-01-2023 23:45:25 INFO Epoch 1: [2421/10940] ---- BYOL Training Loss = 0.2912374436855316
29-01-2023 23:46:17 INFO Epoch 1: [2421/10940] ---- BYOL Validation Loss = 0.33689436316490173
29-01-2023 23:46:35 INFO Epoch 1: [2432/10940] ---- BYOL Training Loss = 0.31422993540763855
29-01-2023 23:46:53 INFO Epoch 1: [2443/10940] ---- BYOL Training Loss = 0.3464902341365814
29-01-2023 23:47:11 INFO Epoch 1: [2454/10940] ---- BYOL Training Loss = 0.3429321050643921
29-01-2023 23:47:29 INFO Epoch 1: [2465/10940] ---- BYOL Training Loss = 0.3900722861289978
29-01-2023 23:48:20 INFO Epoch 1: [2465/10940] ---- BYOL Validation Loss = 0.33812108635902405
29-01-2023 23:48:38 INFO Epoch 1: [2476/10940] ---- BYOL Training Loss = 0.3637179136276245
29-01-2023 23:48:57 INFO Epoch 1: [2487/10940] ---- BYOL Training Loss = 0.34821608662605286
29-01-2023 23:49:15 INFO Epoch 1: [2498/10940] ---- BYOL Training Loss = 0.3946019411087036
29-01-2023 23:49:33 INFO Epoch 1: [2509/10940] ---- BYOL Training Loss = 0.36343714594841003
29-01-2023 23:50:25 INFO Epoch 1: [2509/10940] ---- BYOL Validation Loss = 0.3350713551044464
29-01-2023 23:50:42 INFO Epoch 1: [2520/10940] ---- BYOL Training Loss = 0.31787198781967163
29-01-2023 23:51:00 INFO Epoch 1: [2531/10940] ---- BYOL Training Loss = 0.39148229360580444
29-01-2023 23:51:18 INFO Epoch 1: [2542/10940] ---- BYOL Training Loss = 0.4402386546134949
29-01-2023 23:51:36 INFO Epoch 1: [2553/10940] ---- BYOL Training Loss = 0.39075207710266113
29-01-2023 23:52:28 INFO Epoch 1: [2553/10940] ---- BYOL Validation Loss = 0.3472413420677185
29-01-2023 23:52:46 INFO Epoch 1: [2564/10940] ---- BYOL Training Loss = 0.34106361865997314
29-01-2023 23:53:04 INFO Epoch 1: [2575/10940] ---- BYOL Training Loss = 0.3529866337776184
29-01-2023 23:53:22 INFO Epoch 1: [2586/10940] ---- BYOL Training Loss = 0.3528214991092682
29-01-2023 23:53:41 INFO Epoch 1: [2597/10940] ---- BYOL Training Loss = 0.30081087350845337
29-01-2023 23:54:32 INFO Epoch 1: [2597/10940] ---- BYOL Validation Loss = 0.3260677456855774
29-01-2023 23:54:50 INFO Epoch 1: [2608/10940] ---- BYOL Training Loss = 0.30751070380210876
29-01-2023 23:55:08 INFO Epoch 1: [2619/10940] ---- BYOL Training Loss = 0.3610207438468933
29-01-2023 23:55:26 INFO Epoch 1: [2630/10940] ---- BYOL Training Loss = 0.35944709181785583
29-01-2023 23:55:44 INFO Epoch 1: [2641/10940] ---- BYOL Training Loss = 0.3506292998790741
29-01-2023 23:56:36 INFO Epoch 1: [2641/10940] ---- BYOL Validation Loss = 0.334600031375885
29-01-2023 23:56:54 INFO Epoch 1: [2652/10940] ---- BYOL Training Loss = 0.34923434257507324
29-01-2023 23:57:12 INFO Epoch 1: [2663/10940] ---- BYOL Training Loss = 0.36362117528915405
29-01-2023 23:57:30 INFO Epoch 1: [2674/10940] ---- BYOL Training Loss = 0.36435362696647644
29-01-2023 23:57:48 INFO Epoch 1: [2685/10940] ---- BYOL Training Loss = 0.3600916266441345
29-01-2023 23:58:40 INFO Epoch 1: [2685/10940] ---- BYOL Validation Loss = 0.3334634602069855
29-01-2023 23:58:58 INFO Epoch 1: [2696/10940] ---- BYOL Training Loss = 0.3682669401168823
29-01-2023 23:59:16 INFO Epoch 1: [2707/10940] ---- BYOL Training Loss = 0.3729258179664612
29-01-2023 23:59:34 INFO Epoch 1: [2718/10940] ---- BYOL Training Loss = 0.36838218569755554
29-01-2023 23:59:52 INFO Epoch 1: [2729/10940] ---- BYOL Training Loss = 0.34322771430015564
30-01-2023 00:00:44 INFO Epoch 1: [2729/10940] ---- BYOL Validation Loss = 0.3221255838871002
30-01-2023 00:01:02 INFO Epoch 1: [2740/10940] ---- BYOL Training Loss = 0.3075793385505676
30-01-2023 00:01:20 INFO Epoch 1: [2751/10940] ---- BYOL Training Loss = 0.27008578181266785
30-01-2023 00:01:38 INFO Epoch 1: [2762/10940] ---- BYOL Training Loss = 0.2960541844367981
30-01-2023 00:01:56 INFO Epoch 1: [2773/10940] ---- BYOL Training Loss = 0.30812206864356995
30-01-2023 00:02:48 INFO Epoch 1: [2773/10940] ---- BYOL Validation Loss = 0.32989221811294556
30-01-2023 00:03:05 INFO Epoch 1: [2784/10940] ---- BYOL Training Loss = 0.34766262769699097
30-01-2023 00:03:24 INFO Epoch 1: [2795/10940] ---- BYOL Training Loss = 0.37315428256988525
30-01-2023 00:03:42 INFO Epoch 1: [2806/10940] ---- BYOL Training Loss = 0.3927394151687622
30-01-2023 00:04:00 INFO Epoch 1: [2817/10940] ---- BYOL Training Loss = 0.35584360361099243
30-01-2023 00:04:52 INFO Epoch 1: [2817/10940] ---- BYOL Validation Loss = 0.31635332107543945
30-01-2023 00:05:10 INFO Epoch 1: [2828/10940] ---- BYOL Training Loss = 0.3371029794216156
30-01-2023 00:05:28 INFO Epoch 1: [2839/10940] ---- BYOL Training Loss = 0.34385886788368225
30-01-2023 00:05:46 INFO Epoch 1: [2850/10940] ---- BYOL Training Loss = 0.3836952745914459
30-01-2023 00:06:04 INFO Epoch 1: [2861/10940] ---- BYOL Training Loss = 0.36713287234306335
30-01-2023 00:06:56 INFO Epoch 1: [2861/10940] ---- BYOL Validation Loss = 0.3234325349330902
30-01-2023 00:07:13 INFO Epoch 1: [2872/10940] ---- BYOL Training Loss = 0.35431426763534546
30-01-2023 00:07:31 INFO Epoch 1: [2883/10940] ---- BYOL Training Loss = 0.33486032485961914
30-01-2023 00:07:50 INFO Epoch 1: [2894/10940] ---- BYOL Training Loss = 0.33732789754867554
30-01-2023 00:08:08 INFO Epoch 1: [2905/10940] ---- BYOL Training Loss = 0.36646685004234314
30-01-2023 00:09:00 INFO Epoch 1: [2905/10940] ---- BYOL Validation Loss = 0.32989391684532166
30-01-2023 00:09:17 INFO Epoch 1: [2916/10940] ---- BYOL Training Loss = 0.35350918769836426
30-01-2023 00:09:36 INFO Epoch 1: [2927/10940] ---- BYOL Training Loss = 0.3471662104129791
30-01-2023 00:09:54 INFO Epoch 1: [2938/10940] ---- BYOL Training Loss = 0.36091741919517517
30-01-2023 00:10:12 INFO Epoch 1: [2949/10940] ---- BYOL Training Loss = 0.3438705801963806
30-01-2023 00:11:04 INFO Epoch 1: [2949/10940] ---- BYOL Validation Loss = 0.32528671622276306
30-01-2023 00:11:21 INFO Epoch 1: [2960/10940] ---- BYOL Training Loss = 0.32546165585517883
30-01-2023 00:11:39 INFO Epoch 1: [2971/10940] ---- BYOL Training Loss = 0.3067324459552765
30-01-2023 00:11:57 INFO Epoch 1: [2982/10940] ---- BYOL Training Loss = 0.29277849197387695
30-01-2023 00:12:16 INFO Epoch 1: [2993/10940] ---- BYOL Training Loss = 0.31321054697036743
30-01-2023 00:13:08 INFO Epoch 1: [2993/10940] ---- BYOL Validation Loss = 0.3236410319805145
30-01-2023 00:13:26 INFO Epoch 1: [3004/10940] ---- BYOL Training Loss = 0.3449212908744812
30-01-2023 00:13:44 INFO Epoch 1: [3015/10940] ---- BYOL Training Loss = 0.35891401767730713
30-01-2023 00:14:02 INFO Epoch 1: [3026/10940] ---- BYOL Training Loss = 0.34524548053741455
30-01-2023 00:14:20 INFO Epoch 1: [3037/10940] ---- BYOL Training Loss = 0.34012195467948914
30-01-2023 00:15:12 INFO Epoch 1: [3037/10940] ---- BYOL Validation Loss = 0.31572696566581726
30-01-2023 00:15:29 INFO Epoch 1: [3048/10940] ---- BYOL Training Loss = 0.36183422803878784
30-01-2023 00:15:47 INFO Epoch 1: [3059/10940] ---- BYOL Training Loss = 0.32501643896102905
30-01-2023 00:16:06 INFO Epoch 1: [3070/10940] ---- BYOL Training Loss = 0.293678879737854
30-01-2023 00:16:24 INFO Epoch 1: [3081/10940] ---- BYOL Training Loss = 0.32110437750816345
30-01-2023 00:17:16 INFO Epoch 1: [3081/10940] ---- BYOL Validation Loss = 0.31807994842529297
30-01-2023 00:17:34 INFO Epoch 1: [3092/10940] ---- BYOL Training Loss = 0.27610522508621216
30-01-2023 00:17:52 INFO Epoch 1: [3103/10940] ---- BYOL Training Loss = 0.34344708919525146
30-01-2023 00:18:10 INFO Epoch 1: [3114/10940] ---- BYOL Training Loss = 0.40107959508895874
30-01-2023 00:18:28 INFO Epoch 1: [3125/10940] ---- BYOL Training Loss = 0.3280079960823059
30-01-2023 00:19:20 INFO Epoch 1: [3125/10940] ---- BYOL Validation Loss = 0.3248705565929413
30-01-2023 00:19:38 INFO Epoch 1: [3136/10940] ---- BYOL Training Loss = 0.31349968910217285
30-01-2023 00:19:56 INFO Epoch 1: [3147/10940] ---- BYOL Training Loss = 0.2649109363555908
30-01-2023 00:20:14 INFO Epoch 1: [3158/10940] ---- BYOL Training Loss = 0.3041391968727112
30-01-2023 00:20:32 INFO Epoch 1: [3169/10940] ---- BYOL Training Loss = 0.34296515583992004
30-01-2023 00:21:24 INFO Epoch 1: [3169/10940] ---- BYOL Validation Loss = 0.32091230154037476
30-01-2023 00:21:42 INFO Epoch 1: [3180/10940] ---- BYOL Training Loss = 0.3227623403072357
30-01-2023 00:22:00 INFO Epoch 1: [3191/10940] ---- BYOL Training Loss = 0.3658605217933655
30-01-2023 00:22:18 INFO Epoch 1: [3202/10940] ---- BYOL Training Loss = 0.3708668053150177
30-01-2023 00:22:36 INFO Epoch 1: [3213/10940] ---- BYOL Training Loss = 0.35223981738090515
30-01-2023 00:23:28 INFO Epoch 1: [3213/10940] ---- BYOL Validation Loss = 0.3171687424182892
30-01-2023 00:23:46 INFO Epoch 1: [3224/10940] ---- BYOL Training Loss = 0.2928297817707062
30-01-2023 00:24:04 INFO Epoch 1: [3235/10940] ---- BYOL Training Loss = 0.30940788984298706
30-01-2023 00:24:22 INFO Epoch 1: [3246/10940] ---- BYOL Training Loss = 0.3864976465702057
30-01-2023 00:24:40 INFO Epoch 1: [3257/10940] ---- BYOL Training Loss = 0.3911587595939636
30-01-2023 00:25:32 INFO Epoch 1: [3257/10940] ---- BYOL Validation Loss = 0.31856462359428406
30-01-2023 00:25:50 INFO Epoch 1: [3268/10940] ---- BYOL Training Loss = 0.32830455899238586
30-01-2023 00:26:08 INFO Epoch 1: [3279/10940] ---- BYOL Training Loss = 0.3386651575565338
30-01-2023 00:26:26 INFO Epoch 1: [3290/10940] ---- BYOL Training Loss = 0.27615851163864136
30-01-2023 00:26:44 INFO Epoch 1: [3301/10940] ---- BYOL Training Loss = 0.2824796438217163
30-01-2023 00:27:36 INFO Epoch 1: [3301/10940] ---- BYOL Validation Loss = 0.3141315281391144
30-01-2023 00:27:54 INFO Epoch 1: [3312/10940] ---- BYOL Training Loss = 0.2962563931941986
30-01-2023 00:28:12 INFO Epoch 1: [3323/10940] ---- BYOL Training Loss = 0.31566691398620605
30-01-2023 00:28:30 INFO Epoch 1: [3334/10940] ---- BYOL Training Loss = 0.3554249703884125
30-01-2023 00:28:48 INFO Epoch 1: [3345/10940] ---- BYOL Training Loss = 0.31531548500061035
30-01-2023 00:29:40 INFO Epoch 1: [3345/10940] ---- BYOL Validation Loss = 0.3095416724681854
30-01-2023 00:29:58 INFO Epoch 1: [3356/10940] ---- BYOL Training Loss = 0.2848430275917053
30-01-2023 00:30:16 INFO Epoch 1: [3367/10940] ---- BYOL Training Loss = 0.27822673320770264
30-01-2023 00:30:34 INFO Epoch 1: [3378/10940] ---- BYOL Training Loss = 0.3176674246788025
30-01-2023 00:30:52 INFO Epoch 1: [3389/10940] ---- BYOL Training Loss = 0.3259334862232208
30-01-2023 00:31:44 INFO Epoch 1: [3389/10940] ---- BYOL Validation Loss = 0.32219934463500977
30-01-2023 00:32:02 INFO Epoch 1: [3400/10940] ---- BYOL Training Loss = 0.3551377058029175
30-01-2023 00:32:20 INFO Epoch 1: [3411/10940] ---- BYOL Training Loss = 0.36922115087509155
30-01-2023 00:32:38 INFO Epoch 1: [3422/10940] ---- BYOL Training Loss = 0.3137068748474121
30-01-2023 00:32:56 INFO Epoch 1: [3433/10940] ---- BYOL Training Loss = 0.2832626700401306
30-01-2023 00:33:48 INFO Epoch 1: [3433/10940] ---- BYOL Validation Loss = 0.3204008638858795
30-01-2023 00:34:06 INFO Epoch 1: [3444/10940] ---- BYOL Training Loss = 0.33651870489120483
30-01-2023 00:34:24 INFO Epoch 1: [3455/10940] ---- BYOL Training Loss = 0.3148934543132782
30-01-2023 00:34:42 INFO Epoch 1: [3466/10940] ---- BYOL Training Loss = 0.3606078624725342
30-01-2023 00:35:01 INFO Epoch 1: [3477/10940] ---- BYOL Training Loss = 0.35866841673851013
30-01-2023 00:35:53 INFO Epoch 1: [3477/10940] ---- BYOL Validation Loss = 0.31741848587989807
30-01-2023 00:36:10 INFO Epoch 1: [3488/10940] ---- BYOL Training Loss = 0.3221682012081146
30-01-2023 00:36:28 INFO Epoch 1: [3499/10940] ---- BYOL Training Loss = 0.31036919355392456
30-01-2023 00:36:46 INFO Epoch 1: [3510/10940] ---- BYOL Training Loss = 0.365612268447876
30-01-2023 00:37:05 INFO Epoch 1: [3521/10940] ---- BYOL Training Loss = 0.3704617917537689
30-01-2023 00:37:56 INFO Epoch 1: [3521/10940] ---- BYOL Validation Loss = 0.3089923858642578
30-01-2023 00:38:14 INFO Epoch 1: [3532/10940] ---- BYOL Training Loss = 0.347378671169281
30-01-2023 00:38:33 INFO Epoch 1: [3543/10940] ---- BYOL Training Loss = 0.3260853886604309
30-01-2023 00:38:51 INFO Epoch 1: [3554/10940] ---- BYOL Training Loss = 0.32707497477531433
30-01-2023 00:39:09 INFO Epoch 1: [3565/10940] ---- BYOL Training Loss = 0.3213233947753906
30-01-2023 00:40:01 INFO Epoch 1: [3565/10940] ---- BYOL Validation Loss = 0.31048092246055603
30-01-2023 00:40:19 INFO Epoch 1: [3576/10940] ---- BYOL Training Loss = 0.2951810956001282
30-01-2023 00:40:37 INFO Epoch 1: [3587/10940] ---- BYOL Training Loss = 0.30108803510665894
30-01-2023 00:40:55 INFO Epoch 1: [3598/10940] ---- BYOL Training Loss = 0.30246803164482117
30-01-2023 00:41:13 INFO Epoch 1: [3609/10940] ---- BYOL Training Loss = 0.3425297439098358
30-01-2023 00:42:05 INFO Epoch 1: [3609/10940] ---- BYOL Validation Loss = 0.31146249175071716
30-01-2023 00:42:23 INFO Epoch 1: [3620/10940] ---- BYOL Training Loss = 0.3622519075870514
30-01-2023 00:42:41 INFO Epoch 1: [3631/10940] ---- BYOL Training Loss = 0.3371874690055847
30-01-2023 00:42:59 INFO Epoch 1: [3642/10940] ---- BYOL Training Loss = 0.3392864763736725
30-01-2023 00:43:17 INFO Epoch 1: [3653/10940] ---- BYOL Training Loss = 0.3217109143733978
30-01-2023 00:44:09 INFO Epoch 1: [3653/10940] ---- BYOL Validation Loss = 0.32466527819633484
30-01-2023 00:44:27 INFO Epoch 1: [3664/10940] ---- BYOL Training Loss = 0.3482525646686554
30-01-2023 00:44:45 INFO Epoch 1: [3675/10940] ---- BYOL Training Loss = 0.35303035378456116
30-01-2023 00:45:04 INFO Epoch 1: [3686/10940] ---- BYOL Training Loss = 0.33684876561164856
30-01-2023 00:45:22 INFO Epoch 1: [3697/10940] ---- BYOL Training Loss = 0.3115309178829193
30-01-2023 00:46:14 INFO Epoch 1: [3697/10940] ---- BYOL Validation Loss = 0.3163759410381317
30-01-2023 00:46:31 INFO Epoch 1: [3708/10940] ---- BYOL Training Loss = 0.26525047421455383
30-01-2023 00:46:49 INFO Epoch 1: [3719/10940] ---- BYOL Training Loss = 0.32511964440345764
30-01-2023 00:47:08 INFO Epoch 1: [3730/10940] ---- BYOL Training Loss = 0.3491373062133789
30-01-2023 00:47:26 INFO Epoch 1: [3741/10940] ---- BYOL Training Loss = 0.35513490438461304
30-01-2023 00:48:18 INFO Epoch 1: [3741/10940] ---- BYOL Validation Loss = 0.3158505856990814
30-01-2023 00:48:36 INFO Epoch 1: [3752/10940] ---- BYOL Training Loss = 0.3221457600593567
30-01-2023 00:48:54 INFO Epoch 1: [3763/10940] ---- BYOL Training Loss = 0.3452446460723877
30-01-2023 00:49:12 INFO Epoch 1: [3774/10940] ---- BYOL Training Loss = 0.3572259545326233
30-01-2023 00:49:30 INFO Epoch 1: [3785/10940] ---- BYOL Training Loss = 0.3823546767234802
30-01-2023 00:50:22 INFO Epoch 1: [3785/10940] ---- BYOL Validation Loss = 0.3249301016330719
30-01-2023 00:50:40 INFO Epoch 1: [3796/10940] ---- BYOL Training Loss = 0.4008609354496002
30-01-2023 00:50:58 INFO Epoch 1: [3807/10940] ---- BYOL Training Loss = 0.3413875699043274
30-01-2023 00:51:16 INFO Epoch 1: [3818/10940] ---- BYOL Training Loss = 0.31497302651405334
30-01-2023 00:51:35 INFO Epoch 1: [3829/10940] ---- BYOL Training Loss = 0.2879837155342102
30-01-2023 00:52:27 INFO Epoch 1: [3829/10940] ---- BYOL Validation Loss = 0.3162647783756256
30-01-2023 00:52:44 INFO Epoch 1: [3840/10940] ---- BYOL Training Loss = 0.31238609552383423
30-01-2023 00:53:02 INFO Epoch 1: [3851/10940] ---- BYOL Training Loss = 0.3186630606651306
30-01-2023 00:53:21 INFO Epoch 1: [3862/10940] ---- BYOL Training Loss = 0.3579869270324707
30-01-2023 00:53:39 INFO Epoch 1: [3873/10940] ---- BYOL Training Loss = 0.34791100025177
30-01-2023 00:54:31 INFO Epoch 1: [3873/10940] ---- BYOL Validation Loss = 0.33259662985801697
30-01-2023 00:54:48 INFO Epoch 1: [3884/10940] ---- BYOL Training Loss = 0.31434640288352966
30-01-2023 00:55:07 INFO Epoch 1: [3895/10940] ---- BYOL Training Loss = 0.31185632944107056
30-01-2023 00:55:25 INFO Epoch 1: [3906/10940] ---- BYOL Training Loss = 0.3564260005950928
30-01-2023 00:55:44 INFO Epoch 1: [3917/10940] ---- BYOL Training Loss = 0.3727501928806305
30-01-2023 00:56:35 INFO Epoch 1: [3917/10940] ---- BYOL Validation Loss = 0.3330543339252472
30-01-2023 00:56:53 INFO Epoch 1: [3928/10940] ---- BYOL Training Loss = 0.38257986307144165
30-01-2023 00:57:11 INFO Epoch 1: [3939/10940] ---- BYOL Training Loss = 0.38546425104141235
30-01-2023 00:57:30 INFO Epoch 1: [3950/10940] ---- BYOL Training Loss = 0.34171074628829956
30-01-2023 00:57:48 INFO Epoch 1: [3961/10940] ---- BYOL Training Loss = 0.33635765314102173
30-01-2023 00:58:40 INFO Epoch 1: [3961/10940] ---- BYOL Validation Loss = 0.32442399859428406
30-01-2023 00:58:58 INFO Epoch 1: [3972/10940] ---- BYOL Training Loss = 0.3162000775337219
30-01-2023 00:59:16 INFO Epoch 1: [3983/10940] ---- BYOL Training Loss = 0.3280560374259949
30-01-2023 00:59:34 INFO Epoch 1: [3994/10940] ---- BYOL Training Loss = 0.3370538651943207
30-01-2023 00:59:52 INFO Epoch 1: [4005/10940] ---- BYOL Training Loss = 0.29756325483322144
30-01-2023 01:00:44 INFO Epoch 1: [4005/10940] ---- BYOL Validation Loss = 0.31721433997154236
30-01-2023 01:01:02 INFO Epoch 1: [4016/10940] ---- BYOL Training Loss = 0.3422888517379761
30-01-2023 01:01:21 INFO Epoch 1: [4027/10940] ---- BYOL Training Loss = 0.35387733578681946
30-01-2023 01:01:39 INFO Epoch 1: [4038/10940] ---- BYOL Training Loss = 0.33341366052627563
30-01-2023 01:01:57 INFO Epoch 1: [4049/10940] ---- BYOL Training Loss = 0.35652437806129456
30-01-2023 01:02:49 INFO Epoch 1: [4049/10940] ---- BYOL Validation Loss = 0.30972805619239807
30-01-2023 01:03:07 INFO Epoch 1: [4060/10940] ---- BYOL Training Loss = 0.34188029170036316
30-01-2023 01:03:25 INFO Epoch 1: [4071/10940] ---- BYOL Training Loss = 0.35013920068740845
30-01-2023 01:03:43 INFO Epoch 1: [4082/10940] ---- BYOL Training Loss = 0.3468608260154724
30-01-2023 01:04:02 INFO Epoch 1: [4093/10940] ---- BYOL Training Loss = 0.34108009934425354
30-01-2023 01:04:53 INFO Epoch 1: [4093/10940] ---- BYOL Validation Loss = 0.31690216064453125
30-01-2023 01:05:11 INFO Epoch 1: [4104/10940] ---- BYOL Training Loss = 0.3524077236652374
30-01-2023 01:05:29 INFO Epoch 1: [4115/10940] ---- BYOL Training Loss = 0.3637222647666931
30-01-2023 01:05:47 INFO Epoch 1: [4126/10940] ---- BYOL Training Loss = 0.36668461561203003
30-01-2023 01:06:06 INFO Epoch 1: [4137/10940] ---- BYOL Training Loss = 0.3441295027732849
30-01-2023 01:06:57 INFO Epoch 1: [4137/10940] ---- BYOL Validation Loss = 0.3279484212398529
30-01-2023 01:07:16 INFO Epoch 1: [4148/10940] ---- BYOL Training Loss = 0.3071720600128174
30-01-2023 01:07:34 INFO Epoch 1: [4159/10940] ---- BYOL Training Loss = 0.28239625692367554
30-01-2023 01:07:52 INFO Epoch 1: [4170/10940] ---- BYOL Training Loss = 0.35445117950439453
30-01-2023 01:08:11 INFO Epoch 1: [4181/10940] ---- BYOL Training Loss = 0.3959747552871704
30-01-2023 01:09:02 INFO Epoch 1: [4181/10940] ---- BYOL Validation Loss = 0.3184099793434143
30-01-2023 01:09:20 INFO Epoch 1: [4192/10940] ---- BYOL Training Loss = 0.3771241009235382
30-01-2023 01:09:38 INFO Epoch 1: [4203/10940] ---- BYOL Training Loss = 0.33623427152633667
30-01-2023 01:09:57 INFO Epoch 1: [4214/10940] ---- BYOL Training Loss = 0.316372811794281
30-01-2023 01:10:15 INFO Epoch 1: [4225/10940] ---- BYOL Training Loss = 0.2903234362602234
30-01-2023 01:11:07 INFO Epoch 1: [4225/10940] ---- BYOL Validation Loss = 0.3034277856349945
30-01-2023 01:11:25 INFO Epoch 1: [4236/10940] ---- BYOL Training Loss = 0.3033196032047272
30-01-2023 01:11:43 INFO Epoch 1: [4247/10940] ---- BYOL Training Loss = 0.34905022382736206
30-01-2023 01:12:01 INFO Epoch 1: [4258/10940] ---- BYOL Training Loss = 0.35112228989601135
30-01-2023 01:12:20 INFO Epoch 1: [4269/10940] ---- BYOL Training Loss = 0.35324928164482117
30-01-2023 01:13:12 INFO Epoch 1: [4269/10940] ---- BYOL Validation Loss = 0.30969667434692383
30-01-2023 01:13:29 INFO Epoch 1: [4280/10940] ---- BYOL Training Loss = 0.343601793050766
30-01-2023 01:13:48 INFO Epoch 1: [4291/10940] ---- BYOL Training Loss = 0.33064842224121094
30-01-2023 01:14:06 INFO Epoch 1: [4302/10940] ---- BYOL Training Loss = 0.3759164810180664
30-01-2023 01:14:24 INFO Epoch 1: [4313/10940] ---- BYOL Training Loss = 0.33820489048957825
30-01-2023 01:15:16 INFO Epoch 1: [4313/10940] ---- BYOL Validation Loss = 0.3102339208126068
30-01-2023 01:15:34 INFO Epoch 1: [4324/10940] ---- BYOL Training Loss = 0.2791213095188141
30-01-2023 01:15:52 INFO Epoch 1: [4335/10940] ---- BYOL Training Loss = 0.3027302622795105
30-01-2023 01:16:11 INFO Epoch 1: [4346/10940] ---- BYOL Training Loss = 0.3386308550834656
30-01-2023 01:16:29 INFO Epoch 1: [4357/10940] ---- BYOL Training Loss = 0.32680100202560425
30-01-2023 01:17:21 INFO Epoch 1: [4357/10940] ---- BYOL Validation Loss = 0.30916157364845276
30-01-2023 01:17:38 INFO Epoch 1: [4368/10940] ---- BYOL Training Loss = 0.351126104593277
30-01-2023 01:17:57 INFO Epoch 1: [4379/10940] ---- BYOL Training Loss = 0.3031485676765442
30-01-2023 01:18:15 INFO Epoch 1: [4390/10940] ---- BYOL Training Loss = 0.29723674058914185
30-01-2023 01:18:33 INFO Epoch 1: [4401/10940] ---- BYOL Training Loss = 0.33209681510925293
30-01-2023 01:19:25 INFO Epoch 1: [4401/10940] ---- BYOL Validation Loss = 0.3187764286994934
30-01-2023 01:19:43 INFO Epoch 1: [4412/10940] ---- BYOL Training Loss = 0.3052167594432831
30-01-2023 01:20:01 INFO Epoch 1: [4423/10940] ---- BYOL Training Loss = 0.2984188497066498
30-01-2023 01:20:20 INFO Epoch 1: [4434/10940] ---- BYOL Training Loss = 0.2910281717777252
30-01-2023 01:20:38 INFO Epoch 1: [4445/10940] ---- BYOL Training Loss = 0.3000536859035492
30-01-2023 01:21:30 INFO Epoch 1: [4445/10940] ---- BYOL Validation Loss = 0.3072589337825775
30-01-2023 01:21:48 INFO Epoch 1: [4456/10940] ---- BYOL Training Loss = 0.3030011057853699
30-01-2023 01:22:06 INFO Epoch 1: [4467/10940] ---- BYOL Training Loss = 0.31536418199539185
30-01-2023 01:22:24 INFO Epoch 1: [4478/10940] ---- BYOL Training Loss = 0.32199400663375854
30-01-2023 01:22:43 INFO Epoch 1: [4489/10940] ---- BYOL Training Loss = 0.32032614946365356
30-01-2023 01:23:34 INFO Epoch 1: [4489/10940] ---- BYOL Validation Loss = 0.3033352792263031
30-01-2023 01:23:52 INFO Epoch 1: [4500/10940] ---- BYOL Training Loss = 0.3479313552379608
30-01-2023 01:24:11 INFO Epoch 1: [4511/10940] ---- BYOL Training Loss = 0.32749325037002563
30-01-2023 01:24:29 INFO Epoch 1: [4522/10940] ---- BYOL Training Loss = 0.3174059987068176
30-01-2023 01:24:47 INFO Epoch 1: [4533/10940] ---- BYOL Training Loss = 0.3703319728374481
30-01-2023 01:25:39 INFO Epoch 1: [4533/10940] ---- BYOL Validation Loss = 0.3066735863685608
30-01-2023 01:25:57 INFO Epoch 1: [4544/10940] ---- BYOL Training Loss = 0.345306932926178
30-01-2023 01:26:15 INFO Epoch 1: [4555/10940] ---- BYOL Training Loss = 0.2935192286968231
30-01-2023 01:26:34 INFO Epoch 1: [4566/10940] ---- BYOL Training Loss = 0.2715601325035095
30-01-2023 01:26:52 INFO Epoch 1: [4577/10940] ---- BYOL Training Loss = 0.3353256285190582
30-01-2023 01:27:44 INFO Epoch 1: [4577/10940] ---- BYOL Validation Loss = 0.31995806097984314
30-01-2023 01:28:01 INFO Epoch 1: [4588/10940] ---- BYOL Training Loss = 0.40126028656959534
30-01-2023 01:28:20 INFO Epoch 1: [4599/10940] ---- BYOL Training Loss = 0.3360878527164459
30-01-2023 01:28:38 INFO Epoch 1: [4610/10940] ---- BYOL Training Loss = 0.31921881437301636
30-01-2023 01:28:56 INFO Epoch 1: [4621/10940] ---- BYOL Training Loss = 0.3023093342781067
30-01-2023 01:29:48 INFO Epoch 1: [4621/10940] ---- BYOL Validation Loss = 0.301693856716156
30-01-2023 01:30:06 INFO Epoch 1: [4632/10940] ---- BYOL Training Loss = 0.2945030927658081
30-01-2023 01:30:24 INFO Epoch 1: [4643/10940] ---- BYOL Training Loss = 0.30933138728141785
30-01-2023 01:30:42 INFO Epoch 1: [4654/10940] ---- BYOL Training Loss = 0.31283992528915405
30-01-2023 01:31:01 INFO Epoch 1: [4665/10940] ---- BYOL Training Loss = 0.2675805389881134
30-01-2023 01:31:52 INFO Epoch 1: [4665/10940] ---- BYOL Validation Loss = 0.30065950751304626
30-01-2023 01:32:11 INFO Epoch 1: [4676/10940] ---- BYOL Training Loss = 0.29696211218833923
30-01-2023 01:32:29 INFO Epoch 1: [4687/10940] ---- BYOL Training Loss = 0.3420208990573883
30-01-2023 01:32:47 INFO Epoch 1: [4698/10940] ---- BYOL Training Loss = 0.3514708876609802
30-01-2023 01:33:05 INFO Epoch 1: [4709/10940] ---- BYOL Training Loss = 0.3712283968925476
30-01-2023 01:33:57 INFO Epoch 1: [4709/10940] ---- BYOL Validation Loss = 0.30915775895118713
30-01-2023 01:34:15 INFO Epoch 1: [4720/10940] ---- BYOL Training Loss = 0.3212055265903473
30-01-2023 01:34:34 INFO Epoch 1: [4731/10940] ---- BYOL Training Loss = 0.3156658709049225
30-01-2023 01:34:52 INFO Epoch 1: [4742/10940] ---- BYOL Training Loss = 0.32624778151512146
30-01-2023 01:35:10 INFO Epoch 1: [4753/10940] ---- BYOL Training Loss = 0.35109275579452515
30-01-2023 01:36:02 INFO Epoch 1: [4753/10940] ---- BYOL Validation Loss = 0.31575724482536316
30-01-2023 01:36:20 INFO Epoch 1: [4764/10940] ---- BYOL Training Loss = 0.3628178536891937
30-01-2023 01:36:38 INFO Epoch 1: [4775/10940] ---- BYOL Training Loss = 0.264883428812027
30-01-2023 01:36:57 INFO Epoch 1: [4786/10940] ---- BYOL Training Loss = 0.332689106464386
30-01-2023 01:37:15 INFO Epoch 1: [4797/10940] ---- BYOL Training Loss = 0.36030805110931396
30-01-2023 01:38:07 INFO Epoch 1: [4797/10940] ---- BYOL Validation Loss = 0.30923542380332947
30-01-2023 01:38:25 INFO Epoch 1: [4808/10940] ---- BYOL Training Loss = 0.32866835594177246
30-01-2023 01:38:43 INFO Epoch 1: [4819/10940] ---- BYOL Training Loss = 0.3383658528327942
30-01-2023 01:39:01 INFO Epoch 1: [4830/10940] ---- BYOL Training Loss = 0.33101770281791687
30-01-2023 01:39:20 INFO Epoch 1: [4841/10940] ---- BYOL Training Loss = 0.3424862325191498
30-01-2023 01:40:11 INFO Epoch 1: [4841/10940] ---- BYOL Validation Loss = 0.3159022033214569
30-01-2023 01:40:29 INFO Epoch 1: [4852/10940] ---- BYOL Training Loss = 0.35592353343963623
30-01-2023 01:40:47 INFO Epoch 1: [4863/10940] ---- BYOL Training Loss = 0.320483535528183
30-01-2023 01:41:06 INFO Epoch 1: [4874/10940] ---- BYOL Training Loss = 0.2990688681602478
30-01-2023 01:41:24 INFO Epoch 1: [4885/10940] ---- BYOL Training Loss = 0.30166497826576233
30-01-2023 01:42:16 INFO Epoch 1: [4885/10940] ---- BYOL Validation Loss = 0.3114818036556244
30-01-2023 01:42:34 INFO Epoch 1: [4896/10940] ---- BYOL Training Loss = 0.32433024048805237
30-01-2023 01:42:52 INFO Epoch 1: [4907/10940] ---- BYOL Training Loss = 0.3399287760257721
30-01-2023 01:43:11 INFO Epoch 1: [4918/10940] ---- BYOL Training Loss = 0.3150181472301483
30-01-2023 01:43:29 INFO Epoch 1: [4929/10940] ---- BYOL Training Loss = 0.3166421055793762
30-01-2023 01:44:20 INFO Epoch 1: [4929/10940] ---- BYOL Validation Loss = 0.3238781988620758
30-01-2023 01:44:39 INFO Epoch 1: [4940/10940] ---- BYOL Training Loss = 0.32516250014305115
30-01-2023 01:44:57 INFO Epoch 1: [4951/10940] ---- BYOL Training Loss = 0.345805823802948
30-01-2023 01:45:15 INFO Epoch 1: [4962/10940] ---- BYOL Training Loss = 0.36842823028564453
30-01-2023 01:45:34 INFO Epoch 1: [4973/10940] ---- BYOL Training Loss = 0.31954818964004517
30-01-2023 01:46:25 INFO Epoch 1: [4973/10940] ---- BYOL Validation Loss = 0.31324419379234314
30-01-2023 01:46:43 INFO Epoch 1: [4984/10940] ---- BYOL Training Loss = 0.2605328857898712
30-01-2023 01:47:02 INFO Epoch 1: [4995/10940] ---- BYOL Training Loss = 0.2737954556941986
30-01-2023 01:47:20 INFO Epoch 1: [5006/10940] ---- BYOL Training Loss = 0.3324818015098572
30-01-2023 01:47:38 INFO Epoch 1: [5017/10940] ---- BYOL Training Loss = 0.3373646140098572
30-01-2023 01:48:30 INFO Epoch 1: [5017/10940] ---- BYOL Validation Loss = 0.3181762397289276
30-01-2023 01:48:48 INFO Epoch 1: [5028/10940] ---- BYOL Training Loss = 0.3464926779270172
30-01-2023 01:49:07 INFO Epoch 1: [5039/10940] ---- BYOL Training Loss = 0.37133556604385376
30-01-2023 01:49:25 INFO Epoch 1: [5050/10940] ---- BYOL Training Loss = 0.34916821122169495
30-01-2023 01:49:43 INFO Epoch 1: [5061/10940] ---- BYOL Training Loss = 0.331949383020401
30-01-2023 01:50:35 INFO Epoch 1: [5061/10940] ---- BYOL Validation Loss = 0.30800601840019226
30-01-2023 01:50:53 INFO Epoch 1: [5072/10940] ---- BYOL Training Loss = 0.28963717818260193
30-01-2023 01:51:11 INFO Epoch 1: [5083/10940] ---- BYOL Training Loss = 0.27011051774024963
30-01-2023 01:51:30 INFO Epoch 1: [5094/10940] ---- BYOL Training Loss = 0.32522815465927124
30-01-2023 01:51:48 INFO Epoch 1: [5105/10940] ---- BYOL Training Loss = 0.3377761244773865
30-01-2023 01:52:40 INFO Epoch 1: [5105/10940] ---- BYOL Validation Loss = 0.3016189932823181
30-01-2023 01:52:58 INFO Epoch 1: [5116/10940] ---- BYOL Training Loss = 0.3087500035762787
30-01-2023 01:53:16 INFO Epoch 1: [5127/10940] ---- BYOL Training Loss = 0.26479169726371765
30-01-2023 01:53:35 INFO Epoch 1: [5138/10940] ---- BYOL Training Loss = 0.2821803689002991
30-01-2023 01:53:53 INFO Epoch 1: [5149/10940] ---- BYOL Training Loss = 0.2827562987804413
30-01-2023 01:54:45 INFO Epoch 1: [5149/10940] ---- BYOL Validation Loss = 0.3045906722545624
30-01-2023 01:55:03 INFO Epoch 1: [5160/10940] ---- BYOL Training Loss = 0.285142719745636
30-01-2023 01:55:21 INFO Epoch 1: [5171/10940] ---- BYOL Training Loss = 0.32290467619895935
30-01-2023 01:55:39 INFO Epoch 1: [5182/10940] ---- BYOL Training Loss = 0.31353288888931274
30-01-2023 01:55:58 INFO Epoch 1: [5193/10940] ---- BYOL Training Loss = 0.29965344071388245
30-01-2023 01:56:49 INFO Epoch 1: [5193/10940] ---- BYOL Validation Loss = 0.3009607791900635
30-01-2023 01:57:07 INFO Epoch 1: [5204/10940] ---- BYOL Training Loss = 0.32038262486457825
30-01-2023 01:57:26 INFO Epoch 1: [5215/10940] ---- BYOL Training Loss = 0.3634989857673645
30-01-2023 01:57:44 INFO Epoch 1: [5226/10940] ---- BYOL Training Loss = 0.33767637610435486
30-01-2023 01:58:03 INFO Epoch 1: [5237/10940] ---- BYOL Training Loss = 0.3100336492061615
30-01-2023 01:58:54 INFO Epoch 1: [5237/10940] ---- BYOL Validation Loss = 0.30162009596824646
30-01-2023 01:59:12 INFO Epoch 1: [5248/10940] ---- BYOL Training Loss = 0.3402443826198578
30-01-2023 01:59:31 INFO Epoch 1: [5259/10940] ---- BYOL Training Loss = 0.2945544123649597
30-01-2023 01:59:49 INFO Epoch 1: [5270/10940] ---- BYOL Training Loss = 0.3270012140274048
30-01-2023 02:00:07 INFO Epoch 1: [5281/10940] ---- BYOL Training Loss = 0.34104543924331665
30-01-2023 02:00:59 INFO Epoch 1: [5281/10940] ---- BYOL Validation Loss = 0.29633596539497375
30-01-2023 02:01:17 INFO Epoch 1: [5292/10940] ---- BYOL Training Loss = 0.36431679129600525
30-01-2023 02:01:36 INFO Epoch 1: [5303/10940] ---- BYOL Training Loss = 0.3709995448589325
30-01-2023 02:01:54 INFO Epoch 1: [5314/10940] ---- BYOL Training Loss = 0.3204198479652405
30-01-2023 02:02:12 INFO Epoch 1: [5325/10940] ---- BYOL Training Loss = 0.3131226599216461
30-01-2023 02:03:04 INFO Epoch 1: [5325/10940] ---- BYOL Validation Loss = 0.2979612648487091
30-01-2023 02:03:22 INFO Epoch 1: [5336/10940] ---- BYOL Training Loss = 0.31401029229164124
30-01-2023 02:03:40 INFO Epoch 1: [5347/10940] ---- BYOL Training Loss = 0.3108425736427307
30-01-2023 02:03:59 INFO Epoch 1: [5358/10940] ---- BYOL Training Loss = 0.29941076040267944
30-01-2023 02:04:17 INFO Epoch 1: [5369/10940] ---- BYOL Training Loss = 0.3044414818286896
30-01-2023 02:05:09 INFO Epoch 1: [5369/10940] ---- BYOL Validation Loss = 0.3027711808681488
30-01-2023 02:05:27 INFO Epoch 1: [5380/10940] ---- BYOL Training Loss = 0.29425525665283203
30-01-2023 02:05:45 INFO Epoch 1: [5391/10940] ---- BYOL Training Loss = 0.2893383502960205
30-01-2023 02:06:04 INFO Epoch 1: [5402/10940] ---- BYOL Training Loss = 0.2884787917137146
30-01-2023 02:06:22 INFO Epoch 1: [5413/10940] ---- BYOL Training Loss = 0.2695409059524536
30-01-2023 02:07:14 INFO Epoch 1: [5413/10940] ---- BYOL Validation Loss = 0.28858691453933716
30-01-2023 02:07:32 INFO Epoch 1: [5424/10940] ---- BYOL Training Loss = 0.27116674184799194
30-01-2023 02:07:50 INFO Epoch 1: [5435/10940] ---- BYOL Training Loss = 0.27490049600601196
30-01-2023 02:08:09 INFO Epoch 1: [5446/10940] ---- BYOL Training Loss = 0.2886120676994324
30-01-2023 02:08:27 INFO Epoch 1: [5457/10940] ---- BYOL Training Loss = 0.2970605790615082
30-01-2023 02:09:19 INFO Epoch 1: [5457/10940] ---- BYOL Validation Loss = 0.2892548441886902
30-01-2023 02:09:37 INFO Epoch 1: [5468/10940] ---- BYOL Training Loss = 0.31948742270469666
30-01-2023 02:09:55 INFO Epoch 1: [5479/10940] ---- BYOL Training Loss = 0.3370882570743561
30-01-2023 02:10:14 INFO Epoch 1: [5490/10940] ---- BYOL Training Loss = 0.370039701461792
30-01-2023 02:10:32 INFO Epoch 1: [5501/10940] ---- BYOL Training Loss = 0.3007945418357849
30-01-2023 02:11:24 INFO Epoch 1: [5501/10940] ---- BYOL Validation Loss = 0.2993497848510742
30-01-2023 02:11:42 INFO Epoch 1: [5512/10940] ---- BYOL Training Loss = 0.302733838558197
30-01-2023 02:12:00 INFO Epoch 1: [5523/10940] ---- BYOL Training Loss = 0.34687888622283936
30-01-2023 02:12:18 INFO Epoch 1: [5534/10940] ---- BYOL Training Loss = 0.31698358058929443
30-01-2023 02:12:37 INFO Epoch 1: [5545/10940] ---- BYOL Training Loss = 0.29932188987731934
30-01-2023 02:13:29 INFO Epoch 1: [5545/10940] ---- BYOL Validation Loss = 0.29956844449043274
30-01-2023 02:13:47 INFO Epoch 1: [5556/10940] ---- BYOL Training Loss = 0.3227713406085968
30-01-2023 02:14:05 INFO Epoch 1: [5567/10940] ---- BYOL Training Loss = 0.32955998182296753
30-01-2023 02:14:24 INFO Epoch 1: [5578/10940] ---- BYOL Training Loss = 0.2811473309993744
30-01-2023 02:14:42 INFO Epoch 1: [5589/10940] ---- BYOL Training Loss = 0.27250245213508606
30-01-2023 02:15:34 INFO Epoch 1: [5589/10940] ---- BYOL Validation Loss = 0.2996363639831543
30-01-2023 02:15:52 INFO Epoch 1: [5600/10940] ---- BYOL Training Loss = 0.31784290075302124
30-01-2023 02:16:10 INFO Epoch 1: [5611/10940] ---- BYOL Training Loss = 0.316996693611145
30-01-2023 02:16:29 INFO Epoch 1: [5622/10940] ---- BYOL Training Loss = 0.296994149684906
30-01-2023 02:16:47 INFO Epoch 1: [5633/10940] ---- BYOL Training Loss = 0.3198320269584656
30-01-2023 02:17:39 INFO Epoch 1: [5633/10940] ---- BYOL Validation Loss = 0.2969949543476105
30-01-2023 02:17:57 INFO Epoch 1: [5644/10940] ---- BYOL Training Loss = 0.35949912667274475
30-01-2023 02:18:15 INFO Epoch 1: [5655/10940] ---- BYOL Training Loss = 0.3589031398296356
30-01-2023 02:18:34 INFO Epoch 1: [5666/10940] ---- BYOL Training Loss = 0.31809788942337036
30-01-2023 02:18:52 INFO Epoch 1: [5677/10940] ---- BYOL Training Loss = 0.3293015956878662
30-01-2023 02:19:44 INFO Epoch 1: [5677/10940] ---- BYOL Validation Loss = 0.3138527572154999
30-01-2023 02:20:02 INFO Epoch 1: [5688/10940] ---- BYOL Training Loss = 0.3248618245124817
30-01-2023 02:20:20 INFO Epoch 1: [5699/10940] ---- BYOL Training Loss = 0.3833209276199341
30-01-2023 02:20:38 INFO Epoch 1: [5710/10940] ---- BYOL Training Loss = 0.3926258385181427
30-01-2023 02:20:57 INFO Epoch 1: [5721/10940] ---- BYOL Training Loss = 0.30653712153434753
30-01-2023 02:21:49 INFO Epoch 1: [5721/10940] ---- BYOL Validation Loss = 0.2973325848579407
30-01-2023 02:22:06 INFO Epoch 1: [5732/10940] ---- BYOL Training Loss = 0.26708200573921204
30-01-2023 02:22:25 INFO Epoch 1: [5743/10940] ---- BYOL Training Loss = 0.2477480173110962
30-01-2023 02:22:44 INFO Epoch 1: [5754/10940] ---- BYOL Training Loss = 0.26208460330963135
30-01-2023 02:23:02 INFO Epoch 1: [5765/10940] ---- BYOL Training Loss = 0.30353331565856934
30-01-2023 02:23:54 INFO Epoch 1: [5765/10940] ---- BYOL Validation Loss = 0.30317744612693787
30-01-2023 02:24:12 INFO Epoch 1: [5776/10940] ---- BYOL Training Loss = 0.31633490324020386
30-01-2023 02:24:30 INFO Epoch 1: [5787/10940] ---- BYOL Training Loss = 0.314777135848999
30-01-2023 02:24:49 INFO Epoch 1: [5798/10940] ---- BYOL Training Loss = 0.3261375427246094
30-01-2023 02:25:07 INFO Epoch 1: [5809/10940] ---- BYOL Training Loss = 0.2702053189277649
30-01-2023 02:25:59 INFO Epoch 1: [5809/10940] ---- BYOL Validation Loss = 0.292013019323349
30-01-2023 02:26:17 INFO Epoch 1: [5820/10940] ---- BYOL Training Loss = 0.2786049246788025
30-01-2023 02:26:35 INFO Epoch 1: [5831/10940] ---- BYOL Training Loss = 0.31512540578842163
30-01-2023 02:26:54 INFO Epoch 1: [5842/10940] ---- BYOL Training Loss = 0.2984035909175873
30-01-2023 02:27:12 INFO Epoch 1: [5853/10940] ---- BYOL Training Loss = 0.30054283142089844
30-01-2023 02:28:04 INFO Epoch 1: [5853/10940] ---- BYOL Validation Loss = 0.30597254633903503
30-01-2023 02:28:22 INFO Epoch 1: [5864/10940] ---- BYOL Training Loss = 0.3144323229789734
30-01-2023 02:28:40 INFO Epoch 1: [5875/10940] ---- BYOL Training Loss = 0.3394862413406372
30-01-2023 02:28:59 INFO Epoch 1: [5886/10940] ---- BYOL Training Loss = 0.310833215713501
30-01-2023 02:29:17 INFO Epoch 1: [5897/10940] ---- BYOL Training Loss = 0.29808372259140015
30-01-2023 02:30:09 INFO Epoch 1: [5897/10940] ---- BYOL Validation Loss = 0.2958490252494812
30-01-2023 02:30:27 INFO Epoch 1: [5908/10940] ---- BYOL Training Loss = 0.3056843876838684
30-01-2023 02:30:45 INFO Epoch 1: [5919/10940] ---- BYOL Training Loss = 0.3009834885597229
30-01-2023 02:31:04 INFO Epoch 1: [5930/10940] ---- BYOL Training Loss = 0.3229811191558838
30-01-2023 02:31:22 INFO Epoch 1: [5941/10940] ---- BYOL Training Loss = 0.33141085505485535
30-01-2023 02:32:14 INFO Epoch 1: [5941/10940] ---- BYOL Validation Loss = 0.30248767137527466
30-01-2023 02:32:32 INFO Epoch 1: [5952/10940] ---- BYOL Training Loss = 0.310234397649765
30-01-2023 02:32:50 INFO Epoch 1: [5963/10940] ---- BYOL Training Loss = 0.29414206743240356
30-01-2023 02:33:09 INFO Epoch 1: [5974/10940] ---- BYOL Training Loss = 0.32833850383758545
30-01-2023 02:33:27 INFO Epoch 1: [5985/10940] ---- BYOL Training Loss = 0.27906742691993713
30-01-2023 02:34:19 INFO Epoch 1: [5985/10940] ---- BYOL Validation Loss = 0.307355135679245
30-01-2023 02:34:37 INFO Epoch 1: [5996/10940] ---- BYOL Training Loss = 0.28593406081199646
30-01-2023 02:34:56 INFO Epoch 1: [6007/10940] ---- BYOL Training Loss = 0.3412378430366516
30-01-2023 02:35:14 INFO Epoch 1: [6018/10940] ---- BYOL Training Loss = 0.33478087186813354
30-01-2023 02:35:33 INFO Epoch 1: [6029/10940] ---- BYOL Training Loss = 0.29551881551742554
30-01-2023 02:36:24 INFO Epoch 1: [6029/10940] ---- BYOL Validation Loss = 0.3055569529533386
30-01-2023 02:36:42 INFO Epoch 1: [6040/10940] ---- BYOL Training Loss = 0.280589759349823
30-01-2023 02:37:01 INFO Epoch 1: [6051/10940] ---- BYOL Training Loss = 0.2860080301761627
30-01-2023 02:37:20 INFO Epoch 1: [6062/10940] ---- BYOL Training Loss = 0.3172953724861145
30-01-2023 02:37:38 INFO Epoch 1: [6073/10940] ---- BYOL Training Loss = 0.31844204664230347
30-01-2023 02:38:30 INFO Epoch 1: [6073/10940] ---- BYOL Validation Loss = 0.30525174736976624
30-01-2023 02:38:48 INFO Epoch 1: [6084/10940] ---- BYOL Training Loss = 0.3169097900390625
30-01-2023 02:39:06 INFO Epoch 1: [6095/10940] ---- BYOL Training Loss = 0.3210352063179016
30-01-2023 02:39:25 INFO Epoch 1: [6106/10940] ---- BYOL Training Loss = 0.3177524507045746
30-01-2023 02:39:43 INFO Epoch 1: [6117/10940] ---- BYOL Training Loss = 0.33111947774887085
30-01-2023 02:40:35 INFO Epoch 1: [6117/10940] ---- BYOL Validation Loss = 0.310719758272171
30-01-2023 02:40:53 INFO Epoch 1: [6128/10940] ---- BYOL Training Loss = 0.31086429953575134
30-01-2023 02:41:11 INFO Epoch 1: [6139/10940] ---- BYOL Training Loss = 0.3422642648220062
30-01-2023 02:41:30 INFO Epoch 1: [6150/10940] ---- BYOL Training Loss = 0.3753679394721985
30-01-2023 02:41:48 INFO Epoch 1: [6161/10940] ---- BYOL Training Loss = 0.34572944045066833
30-01-2023 02:42:40 INFO Epoch 1: [6161/10940] ---- BYOL Validation Loss = 0.2950598895549774
30-01-2023 02:42:58 INFO Epoch 1: [6172/10940] ---- BYOL Training Loss = 0.3186716139316559
30-01-2023 02:43:17 INFO Epoch 1: [6183/10940] ---- BYOL Training Loss = 0.2924498915672302
30-01-2023 02:43:35 INFO Epoch 1: [6194/10940] ---- BYOL Training Loss = 0.28942394256591797
30-01-2023 02:43:54 INFO Epoch 1: [6205/10940] ---- BYOL Training Loss = 0.29282310605049133
30-01-2023 02:44:46 INFO Epoch 1: [6205/10940] ---- BYOL Validation Loss = 0.3053470253944397
30-01-2023 02:45:04 INFO Epoch 1: [6216/10940] ---- BYOL Training Loss = 0.35655102133750916
30-01-2023 02:45:22 INFO Epoch 1: [6227/10940] ---- BYOL Training Loss = 0.3381279408931732
30-01-2023 02:45:41 INFO Epoch 1: [6238/10940] ---- BYOL Training Loss = 0.3096791207790375
30-01-2023 02:45:59 INFO Epoch 1: [6249/10940] ---- BYOL Training Loss = 0.3136747479438782
30-01-2023 02:46:51 INFO Epoch 1: [6249/10940] ---- BYOL Validation Loss = 0.31162315607070923
30-01-2023 02:47:09 INFO Epoch 1: [6260/10940] ---- BYOL Training Loss = 0.31309956312179565
30-01-2023 02:47:28 INFO Epoch 1: [6271/10940] ---- BYOL Training Loss = 0.3053697645664215
30-01-2023 02:47:46 INFO Epoch 1: [6282/10940] ---- BYOL Training Loss = 0.33543136715888977
30-01-2023 02:48:05 INFO Epoch 1: [6293/10940] ---- BYOL Training Loss = 0.33616429567337036
30-01-2023 02:48:56 INFO Epoch 1: [6293/10940] ---- BYOL Validation Loss = 0.30301743745803833
30-01-2023 02:49:14 INFO Epoch 1: [6304/10940] ---- BYOL Training Loss = 0.3236004114151001
30-01-2023 02:49:33 INFO Epoch 1: [6315/10940] ---- BYOL Training Loss = 0.3604816496372223
30-01-2023 02:49:52 INFO Epoch 1: [6326/10940] ---- BYOL Training Loss = 0.3441356420516968
30-01-2023 02:50:10 INFO Epoch 1: [6337/10940] ---- BYOL Training Loss = 0.3353303074836731
30-01-2023 02:51:02 INFO Epoch 1: [6337/10940] ---- BYOL Validation Loss = 0.29898834228515625
30-01-2023 02:51:20 INFO Epoch 1: [6348/10940] ---- BYOL Training Loss = 0.3196626603603363
30-01-2023 02:51:38 INFO Epoch 1: [6359/10940] ---- BYOL Training Loss = 0.32613593339920044
30-01-2023 02:51:57 INFO Epoch 1: [6370/10940] ---- BYOL Training Loss = 0.33299851417541504
30-01-2023 02:52:15 INFO Epoch 1: [6381/10940] ---- BYOL Training Loss = 0.27725425362586975
30-01-2023 02:53:07 INFO Epoch 1: [6381/10940] ---- BYOL Validation Loss = 0.29925695061683655
30-01-2023 02:53:25 INFO Epoch 1: [6392/10940] ---- BYOL Training Loss = 0.3004339635372162
30-01-2023 02:53:44 INFO Epoch 1: [6403/10940] ---- BYOL Training Loss = 0.3683732748031616
30-01-2023 02:54:02 INFO Epoch 1: [6414/10940] ---- BYOL Training Loss = 0.3241056799888611
30-01-2023 02:54:21 INFO Epoch 1: [6425/10940] ---- BYOL Training Loss = 0.3127235174179077
30-01-2023 02:55:12 INFO Epoch 1: [6425/10940] ---- BYOL Validation Loss = 0.3050563633441925
30-01-2023 02:55:31 INFO Epoch 1: [6436/10940] ---- BYOL Training Loss = 0.351004034280777
30-01-2023 02:55:49 INFO Epoch 1: [6447/10940] ---- BYOL Training Loss = 0.35757511854171753
30-01-2023 02:56:07 INFO Epoch 1: [6458/10940] ---- BYOL Training Loss = 0.3120909035205841
30-01-2023 02:56:26 INFO Epoch 1: [6469/10940] ---- BYOL Training Loss = 0.2744143307209015
30-01-2023 02:57:18 INFO Epoch 1: [6469/10940] ---- BYOL Validation Loss = 0.3100484013557434
30-01-2023 02:57:36 INFO Epoch 1: [6480/10940] ---- BYOL Training Loss = 0.26973065733909607
30-01-2023 02:57:55 INFO Epoch 1: [6491/10940] ---- BYOL Training Loss = 0.28634020686149597
30-01-2023 02:58:13 INFO Epoch 1: [6502/10940] ---- BYOL Training Loss = 0.32307079434394836
30-01-2023 02:58:32 INFO Epoch 1: [6513/10940] ---- BYOL Training Loss = 0.35435134172439575
30-01-2023 02:59:24 INFO Epoch 1: [6513/10940] ---- BYOL Validation Loss = 0.30135712027549744
30-01-2023 02:59:42 INFO Epoch 1: [6524/10940] ---- BYOL Training Loss = 0.3200633227825165
30-01-2023 03:00:00 INFO Epoch 1: [6535/10940] ---- BYOL Training Loss = 0.26123619079589844
30-01-2023 03:00:19 INFO Epoch 1: [6546/10940] ---- BYOL Training Loss = 0.31007906794548035
30-01-2023 03:00:37 INFO Epoch 1: [6557/10940] ---- BYOL Training Loss = 0.3109528720378876
30-01-2023 03:01:29 INFO Epoch 1: [6557/10940] ---- BYOL Validation Loss = 0.2905188202857971
30-01-2023 03:01:47 INFO Epoch 1: [6568/10940] ---- BYOL Training Loss = 0.30801892280578613
30-01-2023 03:02:06 INFO Epoch 1: [6579/10940] ---- BYOL Training Loss = 0.3539281487464905
30-01-2023 03:02:24 INFO Epoch 1: [6590/10940] ---- BYOL Training Loss = 0.3430789113044739
30-01-2023 03:02:43 INFO Epoch 1: [6601/10940] ---- BYOL Training Loss = 0.3111930787563324
30-01-2023 03:03:35 INFO Epoch 1: [6601/10940] ---- BYOL Validation Loss = 0.3001403510570526
30-01-2023 03:03:53 INFO Epoch 1: [6612/10940] ---- BYOL Training Loss = 0.31450381875038147
30-01-2023 03:04:11 INFO Epoch 1: [6623/10940] ---- BYOL Training Loss = 0.29010316729545593
30-01-2023 03:04:30 INFO Epoch 1: [6634/10940] ---- BYOL Training Loss = 0.2937725782394409
30-01-2023 03:04:48 INFO Epoch 1: [6645/10940] ---- BYOL Training Loss = 0.3336165249347687
30-01-2023 03:05:40 INFO Epoch 1: [6645/10940] ---- BYOL Validation Loss = 0.3018490970134735
30-01-2023 03:05:58 INFO Epoch 1: [6656/10940] ---- BYOL Training Loss = 0.3602423071861267
30-01-2023 03:06:17 INFO Epoch 1: [6667/10940] ---- BYOL Training Loss = 0.3722885549068451
30-01-2023 03:06:35 INFO Epoch 1: [6678/10940] ---- BYOL Training Loss = 0.36354413628578186
30-01-2023 03:06:54 INFO Epoch 1: [6689/10940] ---- BYOL Training Loss = 0.33472734689712524
30-01-2023 03:07:46 INFO Epoch 1: [6689/10940] ---- BYOL Validation Loss = 0.3196123540401459
30-01-2023 03:08:04 INFO Epoch 1: [6700/10940] ---- BYOL Training Loss = 0.2922876179218292
30-01-2023 03:08:22 INFO Epoch 1: [6711/10940] ---- BYOL Training Loss = 0.28398802876472473
30-01-2023 03:08:41 INFO Epoch 1: [6722/10940] ---- BYOL Training Loss = 0.2789914011955261
30-01-2023 03:08:59 INFO Epoch 1: [6733/10940] ---- BYOL Training Loss = 0.2940877377986908
30-01-2023 03:09:51 INFO Epoch 1: [6733/10940] ---- BYOL Validation Loss = 0.2966940701007843
30-01-2023 03:10:09 INFO Epoch 1: [6744/10940] ---- BYOL Training Loss = 0.37256160378456116
30-01-2023 03:10:28 INFO Epoch 1: [6755/10940] ---- BYOL Training Loss = 0.378431111574173
30-01-2023 03:10:46 INFO Epoch 1: [6766/10940] ---- BYOL Training Loss = 0.3158647418022156
30-01-2023 03:11:05 INFO Epoch 1: [6777/10940] ---- BYOL Training Loss = 0.30179911851882935
30-01-2023 03:11:56 INFO Epoch 1: [6777/10940] ---- BYOL Validation Loss = 0.2951816916465759
30-01-2023 03:12:15 INFO Epoch 1: [6788/10940] ---- BYOL Training Loss = 0.28472915291786194
30-01-2023 03:12:33 INFO Epoch 1: [6799/10940] ---- BYOL Training Loss = 0.2821836471557617
30-01-2023 03:12:52 INFO Epoch 1: [6810/10940] ---- BYOL Training Loss = 0.2726295292377472
30-01-2023 03:13:10 INFO Epoch 1: [6821/10940] ---- BYOL Training Loss = 0.25619834661483765
30-01-2023 03:14:02 INFO Epoch 1: [6821/10940] ---- BYOL Validation Loss = 0.29564428329467773
30-01-2023 03:14:20 INFO Epoch 1: [6832/10940] ---- BYOL Training Loss = 0.3026890754699707
30-01-2023 03:14:39 INFO Epoch 1: [6843/10940] ---- BYOL Training Loss = 0.3055828809738159
30-01-2023 03:14:58 INFO Epoch 1: [6854/10940] ---- BYOL Training Loss = 0.2753593325614929
30-01-2023 03:15:16 INFO Epoch 1: [6865/10940] ---- BYOL Training Loss = 0.29190072417259216
30-01-2023 03:16:08 INFO Epoch 1: [6865/10940] ---- BYOL Validation Loss = 0.30624595284461975
30-01-2023 03:16:26 INFO Epoch 1: [6876/10940] ---- BYOL Training Loss = 0.29478996992111206
30-01-2023 03:16:45 INFO Epoch 1: [6887/10940] ---- BYOL Training Loss = 0.3079829216003418
30-01-2023 03:17:03 INFO Epoch 1: [6898/10940] ---- BYOL Training Loss = 0.2992902994155884
30-01-2023 03:17:22 INFO Epoch 1: [6909/10940] ---- BYOL Training Loss = 0.3406578600406647
30-01-2023 03:18:13 INFO Epoch 1: [6909/10940] ---- BYOL Validation Loss = 0.3133316934108734
30-01-2023 03:18:32 INFO Epoch 1: [6920/10940] ---- BYOL Training Loss = 0.3866642117500305
30-01-2023 03:18:50 INFO Epoch 1: [6931/10940] ---- BYOL Training Loss = 0.33914700150489807
30-01-2023 03:19:09 INFO Epoch 1: [6942/10940] ---- BYOL Training Loss = 0.2876873016357422
30-01-2023 03:19:27 INFO Epoch 1: [6953/10940] ---- BYOL Training Loss = 0.3428727090358734
30-01-2023 03:20:19 INFO Epoch 1: [6953/10940] ---- BYOL Validation Loss = 0.30620887875556946
30-01-2023 03:20:38 INFO Epoch 1: [6964/10940] ---- BYOL Training Loss = 0.3493615388870239
30-01-2023 03:20:56 INFO Epoch 1: [6975/10940] ---- BYOL Training Loss = 0.32935747504234314
30-01-2023 03:21:14 INFO Epoch 1: [6986/10940] ---- BYOL Training Loss = 0.3177061080932617
30-01-2023 03:21:33 INFO Epoch 1: [6997/10940] ---- BYOL Training Loss = 0.2852528691291809
30-01-2023 03:22:25 INFO Epoch 1: [6997/10940] ---- BYOL Validation Loss = 0.3027200698852539
30-01-2023 03:22:43 INFO Epoch 1: [7008/10940] ---- BYOL Training Loss = 0.3206198811531067
30-01-2023 03:23:01 INFO Epoch 1: [7019/10940] ---- BYOL Training Loss = 0.3767624497413635
30-01-2023 03:23:20 INFO Epoch 1: [7030/10940] ---- BYOL Training Loss = 0.34244418144226074
30-01-2023 03:23:39 INFO Epoch 1: [7041/10940] ---- BYOL Training Loss = 0.33320197463035583
30-01-2023 03:24:30 INFO Epoch 1: [7041/10940] ---- BYOL Validation Loss = 0.30313703417778015
30-01-2023 03:24:48 INFO Epoch 1: [7052/10940] ---- BYOL Training Loss = 0.2878313362598419
30-01-2023 03:25:07 INFO Epoch 1: [7063/10940] ---- BYOL Training Loss = 0.2607577443122864
30-01-2023 03:25:26 INFO Epoch 1: [7074/10940] ---- BYOL Training Loss = 0.2991023361682892
30-01-2023 03:25:44 INFO Epoch 1: [7085/10940] ---- BYOL Training Loss = 0.35154959559440613
30-01-2023 03:26:36 INFO Epoch 1: [7085/10940] ---- BYOL Validation Loss = 0.302863746881485
30-01-2023 03:26:54 INFO Epoch 1: [7096/10940] ---- BYOL Training Loss = 0.29395538568496704
30-01-2023 03:27:13 INFO Epoch 1: [7107/10940] ---- BYOL Training Loss = 0.27365103363990784
30-01-2023 03:27:31 INFO Epoch 1: [7118/10940] ---- BYOL Training Loss = 0.29572415351867676
30-01-2023 03:27:50 INFO Epoch 1: [7129/10940] ---- BYOL Training Loss = 0.30459803342819214
30-01-2023 03:28:42 INFO Epoch 1: [7129/10940] ---- BYOL Validation Loss = 0.30866122245788574
30-01-2023 03:29:00 INFO Epoch 1: [7140/10940] ---- BYOL Training Loss = 0.33645427227020264
30-01-2023 03:29:18 INFO Epoch 1: [7151/10940] ---- BYOL Training Loss = 0.3275105357170105
30-01-2023 03:29:37 INFO Epoch 1: [7162/10940] ---- BYOL Training Loss = 0.327648788690567
30-01-2023 03:29:55 INFO Epoch 1: [7173/10940] ---- BYOL Training Loss = 0.34408247470855713
30-01-2023 03:30:47 INFO Epoch 1: [7173/10940] ---- BYOL Validation Loss = 0.3127928674221039
30-01-2023 03:31:06 INFO Epoch 1: [7184/10940] ---- BYOL Training Loss = 0.35174378752708435
30-01-2023 03:31:24 INFO Epoch 1: [7195/10940] ---- BYOL Training Loss = 0.3439871668815613
30-01-2023 03:31:43 INFO Epoch 1: [7206/10940] ---- BYOL Training Loss = 0.3688240349292755
30-01-2023 03:32:01 INFO Epoch 1: [7217/10940] ---- BYOL Training Loss = 0.35195741057395935
30-01-2023 03:32:53 INFO Epoch 1: [7217/10940] ---- BYOL Validation Loss = 0.31034448742866516
30-01-2023 03:33:11 INFO Epoch 1: [7228/10940] ---- BYOL Training Loss = 0.3778223693370819
30-01-2023 03:33:30 INFO Epoch 1: [7239/10940] ---- BYOL Training Loss = 0.36636868119239807
30-01-2023 03:33:49 INFO Epoch 1: [7250/10940] ---- BYOL Training Loss = 0.36709514260292053
30-01-2023 03:34:07 INFO Epoch 1: [7261/10940] ---- BYOL Training Loss = 0.37751156091690063
30-01-2023 03:34:59 INFO Epoch 1: [7261/10940] ---- BYOL Validation Loss = 0.31945520639419556
30-01-2023 03:35:17 INFO Epoch 1: [7272/10940] ---- BYOL Training Loss = 0.387229859828949
30-01-2023 03:35:35 INFO Epoch 1: [7283/10940] ---- BYOL Training Loss = 0.3498222529888153
30-01-2023 03:35:54 INFO Epoch 1: [7294/10940] ---- BYOL Training Loss = 0.334673672914505
30-01-2023 03:36:13 INFO Epoch 1: [7305/10940] ---- BYOL Training Loss = 0.32630157470703125
30-01-2023 03:37:05 INFO Epoch 1: [7305/10940] ---- BYOL Validation Loss = 0.31808096170425415
30-01-2023 03:37:23 INFO Epoch 1: [7316/10940] ---- BYOL Training Loss = 0.37068110704421997
30-01-2023 03:37:42 INFO Epoch 1: [7327/10940] ---- BYOL Training Loss = 0.3422836661338806
30-01-2023 03:38:00 INFO Epoch 1: [7338/10940] ---- BYOL Training Loss = 0.3223678469657898
30-01-2023 03:38:19 INFO Epoch 1: [7349/10940] ---- BYOL Training Loss = 0.32769668102264404
30-01-2023 03:39:11 INFO Epoch 1: [7349/10940] ---- BYOL Validation Loss = 0.3141973912715912
30-01-2023 03:39:29 INFO Epoch 1: [7360/10940] ---- BYOL Training Loss = 0.3421465754508972
30-01-2023 03:39:47 INFO Epoch 1: [7371/10940] ---- BYOL Training Loss = 0.34581512212753296
30-01-2023 03:40:06 INFO Epoch 1: [7382/10940] ---- BYOL Training Loss = 0.34720930457115173
30-01-2023 03:40:24 INFO Epoch 1: [7393/10940] ---- BYOL Training Loss = 0.3237670063972473
30-01-2023 03:41:16 INFO Epoch 1: [7393/10940] ---- BYOL Validation Loss = 0.3104580342769623
30-01-2023 03:41:34 INFO Epoch 1: [7404/10940] ---- BYOL Training Loss = 0.34043508768081665
30-01-2023 03:41:53 INFO Epoch 1: [7415/10940] ---- BYOL Training Loss = 0.301297664642334
30-01-2023 03:42:12 INFO Epoch 1: [7426/10940] ---- BYOL Training Loss = 0.328982412815094
30-01-2023 03:42:30 INFO Epoch 1: [7437/10940] ---- BYOL Training Loss = 0.3107132315635681
30-01-2023 03:43:22 INFO Epoch 1: [7437/10940] ---- BYOL Validation Loss = 0.3240680694580078
30-01-2023 03:43:40 INFO Epoch 1: [7448/10940] ---- BYOL Training Loss = 0.3122127652168274
30-01-2023 03:43:59 INFO Epoch 1: [7459/10940] ---- BYOL Training Loss = 0.3624543249607086
30-01-2023 03:44:17 INFO Epoch 1: [7470/10940] ---- BYOL Training Loss = 0.370699942111969
30-01-2023 03:44:36 INFO Epoch 1: [7481/10940] ---- BYOL Training Loss = 0.3680882751941681
30-01-2023 03:45:28 INFO Epoch 1: [7481/10940] ---- BYOL Validation Loss = 0.3225545883178711
30-01-2023 03:45:46 INFO Epoch 1: [7492/10940] ---- BYOL Training Loss = 0.3567630648612976
30-01-2023 03:46:05 INFO Epoch 1: [7503/10940] ---- BYOL Training Loss = 0.32037559151649475
30-01-2023 03:46:23 INFO Epoch 1: [7514/10940] ---- BYOL Training Loss = 0.33249393105506897
30-01-2023 03:46:42 INFO Epoch 1: [7525/10940] ---- BYOL Training Loss = 0.34755080938339233
30-01-2023 03:47:34 INFO Epoch 1: [7525/10940] ---- BYOL Validation Loss = 0.31466642022132874
30-01-2023 03:47:52 INFO Epoch 1: [7536/10940] ---- BYOL Training Loss = 0.3510877192020416
30-01-2023 03:48:10 INFO Epoch 1: [7547/10940] ---- BYOL Training Loss = 0.33944958448410034
30-01-2023 03:48:29 INFO Epoch 1: [7558/10940] ---- BYOL Training Loss = 0.27421489357948303
30-01-2023 03:48:48 INFO Epoch 1: [7569/10940] ---- BYOL Training Loss = 0.32186028361320496
30-01-2023 03:49:40 INFO Epoch 1: [7569/10940] ---- BYOL Validation Loss = 0.3282645046710968
30-01-2023 03:49:58 INFO Epoch 1: [7580/10940] ---- BYOL Training Loss = 0.32725977897644043
30-01-2023 03:50:17 INFO Epoch 1: [7591/10940] ---- BYOL Training Loss = 0.2943337559700012
30-01-2023 03:50:35 INFO Epoch 1: [7602/10940] ---- BYOL Training Loss = 0.3062094748020172
30-01-2023 03:50:54 INFO Epoch 1: [7613/10940] ---- BYOL Training Loss = 0.2618696093559265
30-01-2023 03:51:45 INFO Epoch 1: [7613/10940] ---- BYOL Validation Loss = 0.3095483183860779
30-01-2023 03:52:04 INFO Epoch 1: [7624/10940] ---- BYOL Training Loss = 0.3083339333534241
30-01-2023 03:52:22 INFO Epoch 1: [7635/10940] ---- BYOL Training Loss = 0.3608070909976959
30-01-2023 03:52:41 INFO Epoch 1: [7646/10940] ---- BYOL Training Loss = 0.3299756944179535
30-01-2023 03:53:00 INFO Epoch 1: [7657/10940] ---- BYOL Training Loss = 0.31474852561950684
30-01-2023 03:53:52 INFO Epoch 1: [7657/10940] ---- BYOL Validation Loss = 0.3206901550292969
30-01-2023 03:54:10 INFO Epoch 1: [7668/10940] ---- BYOL Training Loss = 0.3360843062400818
30-01-2023 03:54:28 INFO Epoch 1: [7679/10940] ---- BYOL Training Loss = 0.3405265808105469
30-01-2023 03:54:47 INFO Epoch 1: [7690/10940] ---- BYOL Training Loss = 0.3243558406829834
30-01-2023 03:55:06 INFO Epoch 1: [7701/10940] ---- BYOL Training Loss = 0.33057016134262085
30-01-2023 03:55:57 INFO Epoch 1: [7701/10940] ---- BYOL Validation Loss = 0.3171386122703552
30-01-2023 03:56:16 INFO Epoch 1: [7712/10940] ---- BYOL Training Loss = 0.36096441745758057
30-01-2023 03:56:34 INFO Epoch 1: [7723/10940] ---- BYOL Training Loss = 0.35747799277305603
30-01-2023 03:56:53 INFO Epoch 1: [7734/10940] ---- BYOL Training Loss = 0.2612949311733246
30-01-2023 03:57:11 INFO Epoch 1: [7745/10940] ---- BYOL Training Loss = 0.2504432201385498
30-01-2023 03:58:03 INFO Epoch 1: [7745/10940] ---- BYOL Validation Loss = 0.31213584542274475
30-01-2023 03:58:22 INFO Epoch 1: [7756/10940] ---- BYOL Training Loss = 0.29317107796669006
30-01-2023 03:58:40 INFO Epoch 1: [7767/10940] ---- BYOL Training Loss = 0.301567941904068
30-01-2023 03:58:59 INFO Epoch 1: [7778/10940] ---- BYOL Training Loss = 0.3209381103515625
30-01-2023 03:59:18 INFO Epoch 1: [7789/10940] ---- BYOL Training Loss = 0.38080117106437683
30-01-2023 04:00:09 INFO Epoch 1: [7789/10940] ---- BYOL Validation Loss = 0.3232591450214386
30-01-2023 04:00:27 INFO Epoch 1: [7800/10940] ---- BYOL Training Loss = 0.35252878069877625
30-01-2023 04:00:46 INFO Epoch 1: [7811/10940] ---- BYOL Training Loss = 0.33916911482810974
30-01-2023 04:01:05 INFO Epoch 1: [7822/10940] ---- BYOL Training Loss = 0.32480287551879883
30-01-2023 04:01:23 INFO Epoch 1: [7833/10940] ---- BYOL Training Loss = 0.31405049562454224
30-01-2023 04:02:15 INFO Epoch 1: [7833/10940] ---- BYOL Validation Loss = 0.31406736373901367
30-01-2023 04:02:33 INFO Epoch 1: [7844/10940] ---- BYOL Training Loss = 0.34784457087516785
30-01-2023 04:02:52 INFO Epoch 1: [7855/10940] ---- BYOL Training Loss = 0.32558122277259827
30-01-2023 04:03:11 INFO Epoch 1: [7866/10940] ---- BYOL Training Loss = 0.3217751085758209
30-01-2023 04:03:29 INFO Epoch 1: [7877/10940] ---- BYOL Training Loss = 0.3127318024635315
30-01-2023 04:04:21 INFO Epoch 1: [7877/10940] ---- BYOL Validation Loss = 0.31377920508384705
30-01-2023 04:04:39 INFO Epoch 1: [7888/10940] ---- BYOL Training Loss = 0.2977484464645386
30-01-2023 04:04:58 INFO Epoch 1: [7899/10940] ---- BYOL Training Loss = 0.37262362241744995
30-01-2023 04:05:16 INFO Epoch 1: [7910/10940] ---- BYOL Training Loss = 0.37031883001327515
30-01-2023 04:05:35 INFO Epoch 1: [7921/10940] ---- BYOL Training Loss = 0.3301066756248474
30-01-2023 04:06:27 INFO Epoch 1: [7921/10940] ---- BYOL Validation Loss = 0.31072622537612915
30-01-2023 04:06:45 INFO Epoch 1: [7932/10940] ---- BYOL Training Loss = 0.3540775179862976
30-01-2023 04:07:04 INFO Epoch 1: [7943/10940] ---- BYOL Training Loss = 0.30598413944244385
30-01-2023 04:07:23 INFO Epoch 1: [7954/10940] ---- BYOL Training Loss = 0.2886250913143158
30-01-2023 04:07:41 INFO Epoch 1: [7965/10940] ---- BYOL Training Loss = 0.3039931654930115
30-01-2023 04:08:33 INFO Epoch 1: [7965/10940] ---- BYOL Validation Loss = 0.31520572304725647
30-01-2023 04:08:51 INFO Epoch 1: [7976/10940] ---- BYOL Training Loss = 0.30636391043663025
30-01-2023 04:09:10 INFO Epoch 1: [7987/10940] ---- BYOL Training Loss = 0.34888529777526855
30-01-2023 04:09:28 INFO Epoch 1: [7998/10940] ---- BYOL Training Loss = 0.34982815384864807
30-01-2023 04:09:47 INFO Epoch 1: [8009/10940] ---- BYOL Training Loss = 0.3373417556285858
30-01-2023 04:10:39 INFO Epoch 1: [8009/10940] ---- BYOL Validation Loss = 0.30939292907714844
30-01-2023 04:10:57 INFO Epoch 1: [8020/10940] ---- BYOL Training Loss = 0.3150717616081238
30-01-2023 04:11:16 INFO Epoch 1: [8031/10940] ---- BYOL Training Loss = 0.3006139397621155
30-01-2023 04:11:35 INFO Epoch 1: [8042/10940] ---- BYOL Training Loss = 0.2946776747703552
30-01-2023 04:11:53 INFO Epoch 1: [8053/10940] ---- BYOL Training Loss = 0.3160298764705658
30-01-2023 04:12:45 INFO Epoch 1: [8053/10940] ---- BYOL Validation Loss = 0.30705568194389343
30-01-2023 04:13:03 INFO Epoch 1: [8064/10940] ---- BYOL Training Loss = 0.3013555705547333
30-01-2023 04:13:22 INFO Epoch 1: [8075/10940] ---- BYOL Training Loss = 0.29639482498168945
30-01-2023 04:13:41 INFO Epoch 1: [8086/10940] ---- BYOL Training Loss = 0.2631818354129791
30-01-2023 04:13:59 INFO Epoch 1: [8097/10940] ---- BYOL Training Loss = 0.2759193778038025
30-01-2023 04:14:51 INFO Epoch 1: [8097/10940] ---- BYOL Validation Loss = 0.30777135491371155
30-01-2023 04:15:09 INFO Epoch 1: [8108/10940] ---- BYOL Training Loss = 0.3735445439815521
30-01-2023 04:15:28 INFO Epoch 1: [8119/10940] ---- BYOL Training Loss = 0.3420674204826355
30-01-2023 04:15:46 INFO Epoch 1: [8130/10940] ---- BYOL Training Loss = 0.312353253364563
30-01-2023 04:16:05 INFO Epoch 1: [8141/10940] ---- BYOL Training Loss = 0.3268558382987976
30-01-2023 04:16:57 INFO Epoch 1: [8141/10940] ---- BYOL Validation Loss = 0.3077267110347748
30-01-2023 04:17:16 INFO Epoch 1: [8152/10940] ---- BYOL Training Loss = 0.3285282254219055
30-01-2023 04:17:34 INFO Epoch 1: [8163/10940] ---- BYOL Training Loss = 0.3651432991027832
30-01-2023 04:17:53 INFO Epoch 1: [8174/10940] ---- BYOL Training Loss = 0.32404714822769165
30-01-2023 04:18:12 INFO Epoch 1: [8185/10940] ---- BYOL Training Loss = 0.32458892464637756
30-01-2023 04:19:04 INFO Epoch 1: [8185/10940] ---- BYOL Validation Loss = 0.3103730380535126
30-01-2023 04:19:22 INFO Epoch 1: [8196/10940] ---- BYOL Training Loss = 0.32857027649879456
30-01-2023 04:19:41 INFO Epoch 1: [8207/10940] ---- BYOL Training Loss = 0.3411269783973694
30-01-2023 04:19:59 INFO Epoch 1: [8218/10940] ---- BYOL Training Loss = 0.30136987566947937
30-01-2023 04:20:18 INFO Epoch 1: [8229/10940] ---- BYOL Training Loss = 0.28255534172058105
30-01-2023 04:21:10 INFO Epoch 1: [8229/10940] ---- BYOL Validation Loss = 0.31377026438713074
30-01-2023 04:21:28 INFO Epoch 1: [8240/10940] ---- BYOL Training Loss = 0.2930402159690857
30-01-2023 04:21:47 INFO Epoch 1: [8251/10940] ---- BYOL Training Loss = 0.28645962476730347
30-01-2023 04:22:06 INFO Epoch 1: [8262/10940] ---- BYOL Training Loss = 0.35524463653564453
30-01-2023 04:22:25 INFO Epoch 1: [8273/10940] ---- BYOL Training Loss = 0.3725801110267639
30-01-2023 04:23:17 INFO Epoch 1: [8273/10940] ---- BYOL Validation Loss = 0.307856023311615
30-01-2023 04:23:35 INFO Epoch 1: [8284/10940] ---- BYOL Training Loss = 0.32762542366981506
30-01-2023 04:23:54 INFO Epoch 1: [8295/10940] ---- BYOL Training Loss = 0.2857302725315094
30-01-2023 04:24:12 INFO Epoch 1: [8306/10940] ---- BYOL Training Loss = 0.33132404088974
30-01-2023 04:24:31 INFO Epoch 1: [8317/10940] ---- BYOL Training Loss = 0.3371172845363617
30-01-2023 04:25:23 INFO Epoch 1: [8317/10940] ---- BYOL Validation Loss = 0.3050970137119293
30-01-2023 04:25:41 INFO Epoch 1: [8328/10940] ---- BYOL Training Loss = 0.3141910135746002
30-01-2023 04:26:00 INFO Epoch 1: [8339/10940] ---- BYOL Training Loss = 0.32646602392196655
30-01-2023 04:26:18 INFO Epoch 1: [8350/10940] ---- BYOL Training Loss = 0.3930284380912781
30-01-2023 04:26:37 INFO Epoch 1: [8361/10940] ---- BYOL Training Loss = 0.3305087685585022
30-01-2023 04:27:29 INFO Epoch 1: [8361/10940] ---- BYOL Validation Loss = 0.3043474853038788
30-01-2023 04:27:47 INFO Epoch 1: [8372/10940] ---- BYOL Training Loss = 0.30110782384872437
30-01-2023 04:28:06 INFO Epoch 1: [8383/10940] ---- BYOL Training Loss = 0.33473101258277893
30-01-2023 04:28:25 INFO Epoch 1: [8394/10940] ---- BYOL Training Loss = 0.32484596967697144
30-01-2023 04:28:43 INFO Epoch 1: [8405/10940] ---- BYOL Training Loss = 0.34830576181411743
30-01-2023 04:29:35 INFO Epoch 1: [8405/10940] ---- BYOL Validation Loss = 0.30253103375434875
30-01-2023 04:29:53 INFO Epoch 1: [8416/10940] ---- BYOL Training Loss = 0.3295687735080719
30-01-2023 04:30:12 INFO Epoch 1: [8427/10940] ---- BYOL Training Loss = 0.3254527151584625
30-01-2023 04:30:30 INFO Epoch 1: [8438/10940] ---- BYOL Training Loss = 0.32199379801750183
30-01-2023 04:30:49 INFO Epoch 1: [8449/10940] ---- BYOL Training Loss = 0.35308513045310974
30-01-2023 04:31:41 INFO Epoch 1: [8449/10940] ---- BYOL Validation Loss = 0.3020014762878418
30-01-2023 04:31:59 INFO Epoch 1: [8460/10940] ---- BYOL Training Loss = 0.35486310720443726
30-01-2023 04:32:18 INFO Epoch 1: [8471/10940] ---- BYOL Training Loss = 0.33344537019729614
30-01-2023 04:32:37 INFO Epoch 1: [8482/10940] ---- BYOL Training Loss = 0.35157203674316406
30-01-2023 04:32:55 INFO Epoch 1: [8493/10940] ---- BYOL Training Loss = 0.32424792647361755
30-01-2023 04:33:47 INFO Epoch 1: [8493/10940] ---- BYOL Validation Loss = 0.30713382363319397
30-01-2023 04:34:05 INFO Epoch 1: [8504/10940] ---- BYOL Training Loss = 0.3048033118247986
30-01-2023 04:34:24 INFO Epoch 1: [8515/10940] ---- BYOL Training Loss = 0.326185405254364
30-01-2023 04:34:43 INFO Epoch 1: [8526/10940] ---- BYOL Training Loss = 0.36729881167411804
30-01-2023 04:35:02 INFO Epoch 1: [8537/10940] ---- BYOL Training Loss = 0.3508216440677643
30-01-2023 04:35:53 INFO Epoch 1: [8537/10940] ---- BYOL Validation Loss = 0.29416269063949585
30-01-2023 04:36:12 INFO Epoch 1: [8548/10940] ---- BYOL Training Loss = 0.3494488298892975
30-01-2023 04:36:30 INFO Epoch 1: [8559/10940] ---- BYOL Training Loss = 0.3382638096809387
30-01-2023 04:36:49 INFO Epoch 1: [8570/10940] ---- BYOL Training Loss = 0.29487138986587524
30-01-2023 04:37:08 INFO Epoch 1: [8581/10940] ---- BYOL Training Loss = 0.28259509801864624
30-01-2023 04:37:59 INFO Epoch 1: [8581/10940] ---- BYOL Validation Loss = 0.296211302280426
30-01-2023 04:38:18 INFO Epoch 1: [8592/10940] ---- BYOL Training Loss = 0.2912076711654663
30-01-2023 04:38:37 INFO Epoch 1: [8603/10940] ---- BYOL Training Loss = 0.26585039496421814
30-01-2023 04:38:55 INFO Epoch 1: [8614/10940] ---- BYOL Training Loss = 0.3151973783969879
30-01-2023 04:39:14 INFO Epoch 1: [8625/10940] ---- BYOL Training Loss = 0.3721226155757904
30-01-2023 04:40:06 INFO Epoch 1: [8625/10940] ---- BYOL Validation Loss = 0.31651902198791504
30-01-2023 04:40:24 INFO Epoch 1: [8636/10940] ---- BYOL Training Loss = 0.3343889117240906
30-01-2023 04:40:43 INFO Epoch 1: [8647/10940] ---- BYOL Training Loss = 0.3077903091907501
30-01-2023 04:41:02 INFO Epoch 1: [8658/10940] ---- BYOL Training Loss = 0.3138992190361023
30-01-2023 04:41:20 INFO Epoch 1: [8669/10940] ---- BYOL Training Loss = 0.3523297905921936
30-01-2023 04:42:12 INFO Epoch 1: [8669/10940] ---- BYOL Validation Loss = 0.2970292866230011
30-01-2023 04:42:30 INFO Epoch 1: [8680/10940] ---- BYOL Training Loss = 0.3759894371032715
30-01-2023 04:42:49 INFO Epoch 1: [8691/10940] ---- BYOL Training Loss = 0.3615477383136749
30-01-2023 04:43:08 INFO Epoch 1: [8702/10940] ---- BYOL Training Loss = 0.37306973338127136
30-01-2023 04:43:27 INFO Epoch 1: [8713/10940] ---- BYOL Training Loss = 0.34949737787246704
30-01-2023 04:44:18 INFO Epoch 1: [8713/10940] ---- BYOL Validation Loss = 0.29551658034324646
30-01-2023 04:44:37 INFO Epoch 1: [8724/10940] ---- BYOL Training Loss = 0.3223735988140106
30-01-2023 04:44:55 INFO Epoch 1: [8735/10940] ---- BYOL Training Loss = 0.3098786473274231
30-01-2023 04:45:14 INFO Epoch 1: [8746/10940] ---- BYOL Training Loss = 0.2638114392757416
30-01-2023 04:45:33 INFO Epoch 1: [8757/10940] ---- BYOL Training Loss = 0.28158921003341675
30-01-2023 04:46:25 INFO Epoch 1: [8757/10940] ---- BYOL Validation Loss = 0.302139550447464
30-01-2023 04:46:43 INFO Epoch 1: [8768/10940] ---- BYOL Training Loss = 0.33865514397621155
30-01-2023 04:47:02 INFO Epoch 1: [8779/10940] ---- BYOL Training Loss = 0.3632862865924835
30-01-2023 04:47:21 INFO Epoch 1: [8790/10940] ---- BYOL Training Loss = 0.3587210774421692
30-01-2023 04:47:40 INFO Epoch 1: [8801/10940] ---- BYOL Training Loss = 0.31479912996292114
30-01-2023 04:48:31 INFO Epoch 1: [8801/10940] ---- BYOL Validation Loss = 0.30051371455192566
30-01-2023 04:48:50 INFO Epoch 1: [8812/10940] ---- BYOL Training Loss = 0.31235378980636597
30-01-2023 04:49:08 INFO Epoch 1: [8823/10940] ---- BYOL Training Loss = 0.32983654737472534
30-01-2023 04:49:28 INFO Epoch 1: [8834/10940] ---- BYOL Training Loss = 0.35898423194885254
30-01-2023 04:49:46 INFO Epoch 1: [8845/10940] ---- BYOL Training Loss = 0.33919984102249146
30-01-2023 04:50:38 INFO Epoch 1: [8845/10940] ---- BYOL Validation Loss = 0.2976412773132324
30-01-2023 04:50:56 INFO Epoch 1: [8856/10940] ---- BYOL Training Loss = 0.3264194428920746
30-01-2023 04:51:15 INFO Epoch 1: [8867/10940] ---- BYOL Training Loss = 0.30465736985206604
30-01-2023 04:51:34 INFO Epoch 1: [8878/10940] ---- BYOL Training Loss = 0.33065852522850037
30-01-2023 04:51:53 INFO Epoch 1: [8889/10940] ---- BYOL Training Loss = 0.3464702069759369
30-01-2023 04:52:45 INFO Epoch 1: [8889/10940] ---- BYOL Validation Loss = 0.3018333315849304
30-01-2023 04:53:03 INFO Epoch 1: [8900/10940] ---- BYOL Training Loss = 0.3387548625469208
30-01-2023 04:53:22 INFO Epoch 1: [8911/10940] ---- BYOL Training Loss = 0.29739144444465637
30-01-2023 04:53:41 INFO Epoch 1: [8922/10940] ---- BYOL Training Loss = 0.2862071394920349
30-01-2023 04:53:59 INFO Epoch 1: [8933/10940] ---- BYOL Training Loss = 0.2874387502670288
30-01-2023 04:54:51 INFO Epoch 1: [8933/10940] ---- BYOL Validation Loss = 0.29261547327041626
30-01-2023 04:55:10 INFO Epoch 1: [8944/10940] ---- BYOL Training Loss = 0.3101583421230316
30-01-2023 04:55:28 INFO Epoch 1: [8955/10940] ---- BYOL Training Loss = 0.2870330512523651
30-01-2023 04:55:47 INFO Epoch 1: [8966/10940] ---- BYOL Training Loss = 0.3285958766937256
30-01-2023 04:56:06 INFO Epoch 1: [8977/10940] ---- BYOL Training Loss = 0.32825329899787903
30-01-2023 04:56:58 INFO Epoch 1: [8977/10940] ---- BYOL Validation Loss = 0.2868446707725525
30-01-2023 04:57:16 INFO Epoch 1: [8988/10940] ---- BYOL Training Loss = 0.3063676953315735
30-01-2023 04:57:35 INFO Epoch 1: [8999/10940] ---- BYOL Training Loss = 0.27048856019973755
30-01-2023 04:57:53 INFO Epoch 1: [9010/10940] ---- BYOL Training Loss = 0.24731457233428955
30-01-2023 04:58:12 INFO Epoch 1: [9021/10940] ---- BYOL Training Loss = 0.28411999344825745
30-01-2023 04:59:04 INFO Epoch 1: [9021/10940] ---- BYOL Validation Loss = 0.2933747172355652
30-01-2023 04:59:23 INFO Epoch 1: [9032/10940] ---- BYOL Training Loss = 0.3183864951133728
30-01-2023 04:59:41 INFO Epoch 1: [9043/10940] ---- BYOL Training Loss = 0.2979472577571869
30-01-2023 05:00:00 INFO Epoch 1: [9054/10940] ---- BYOL Training Loss = 0.273397833108902
30-01-2023 05:00:19 INFO Epoch 1: [9065/10940] ---- BYOL Training Loss = 0.25532466173171997
30-01-2023 05:01:10 INFO Epoch 1: [9065/10940] ---- BYOL Validation Loss = 0.29201430082321167
30-01-2023 05:01:29 INFO Epoch 1: [9076/10940] ---- BYOL Training Loss = 0.28571397066116333
30-01-2023 05:01:48 INFO Epoch 1: [9087/10940] ---- BYOL Training Loss = 0.3536618947982788
30-01-2023 05:02:06 INFO Epoch 1: [9098/10940] ---- BYOL Training Loss = 0.3373735547065735
30-01-2023 05:02:25 INFO Epoch 1: [9109/10940] ---- BYOL Training Loss = 0.30582329630851746
30-01-2023 05:03:17 INFO Epoch 1: [9109/10940] ---- BYOL Validation Loss = 0.2893196940422058
30-01-2023 05:03:35 INFO Epoch 1: [9120/10940] ---- BYOL Training Loss = 0.28689199686050415
30-01-2023 05:03:54 INFO Epoch 1: [9131/10940] ---- BYOL Training Loss = 0.2903740108013153
30-01-2023 05:04:13 INFO Epoch 1: [9142/10940] ---- BYOL Training Loss = 0.2937176525592804
30-01-2023 05:04:32 INFO Epoch 1: [9153/10940] ---- BYOL Training Loss = 0.29436278343200684
30-01-2023 05:05:23 INFO Epoch 1: [9153/10940] ---- BYOL Validation Loss = 0.28920820355415344
30-01-2023 05:05:42 INFO Epoch 1: [9164/10940] ---- BYOL Training Loss = 0.3450701832771301
30-01-2023 05:06:01 INFO Epoch 1: [9175/10940] ---- BYOL Training Loss = 0.343830406665802
30-01-2023 05:06:19 INFO Epoch 1: [9186/10940] ---- BYOL Training Loss = 0.317920446395874
30-01-2023 05:06:38 INFO Epoch 1: [9197/10940] ---- BYOL Training Loss = 0.32701772451400757
30-01-2023 05:07:30 INFO Epoch 1: [9197/10940] ---- BYOL Validation Loss = 0.3054525554180145
30-01-2023 05:07:48 INFO Epoch 1: [9208/10940] ---- BYOL Training Loss = 0.302918016910553
30-01-2023 05:08:07 INFO Epoch 1: [9219/10940] ---- BYOL Training Loss = 0.26972058415412903
30-01-2023 05:08:26 INFO Epoch 1: [9230/10940] ---- BYOL Training Loss = 0.31101366877555847
30-01-2023 05:08:45 INFO Epoch 1: [9241/10940] ---- BYOL Training Loss = 0.3207044005393982
30-01-2023 05:09:36 INFO Epoch 1: [9241/10940] ---- BYOL Validation Loss = 0.29415297508239746
30-01-2023 05:09:55 INFO Epoch 1: [9252/10940] ---- BYOL Training Loss = 0.31270429491996765
30-01-2023 05:10:14 INFO Epoch 1: [9263/10940] ---- BYOL Training Loss = 0.36419156193733215
30-01-2023 05:10:32 INFO Epoch 1: [9274/10940] ---- BYOL Training Loss = 0.3420674204826355
30-01-2023 05:10:51 INFO Epoch 1: [9285/10940] ---- BYOL Training Loss = 0.319732666015625
30-01-2023 05:11:43 INFO Epoch 1: [9285/10940] ---- BYOL Validation Loss = 0.29854530096054077
30-01-2023 05:12:02 INFO Epoch 1: [9296/10940] ---- BYOL Training Loss = 0.28996261954307556
30-01-2023 05:12:20 INFO Epoch 1: [9307/10940] ---- BYOL Training Loss = 0.27294543385505676
30-01-2023 05:12:39 INFO Epoch 1: [9318/10940] ---- BYOL Training Loss = 0.2805030643939972
30-01-2023 05:12:58 INFO Epoch 1: [9329/10940] ---- BYOL Training Loss = 0.2778930068016052
30-01-2023 05:13:50 INFO Epoch 1: [9329/10940] ---- BYOL Validation Loss = 0.28926315903663635
30-01-2023 05:14:08 INFO Epoch 1: [9340/10940] ---- BYOL Training Loss = 0.2800101637840271
30-01-2023 05:14:27 INFO Epoch 1: [9351/10940] ---- BYOL Training Loss = 0.301594078540802
30-01-2023 05:14:46 INFO Epoch 1: [9362/10940] ---- BYOL Training Loss = 0.30994245409965515
30-01-2023 05:15:05 INFO Epoch 1: [9373/10940] ---- BYOL Training Loss = 0.30064818263053894
30-01-2023 05:15:57 INFO Epoch 1: [9373/10940] ---- BYOL Validation Loss = 0.2961045205593109
30-01-2023 05:16:15 INFO Epoch 1: [9384/10940] ---- BYOL Training Loss = 0.3109159767627716
30-01-2023 05:16:34 INFO Epoch 1: [9395/10940] ---- BYOL Training Loss = 0.2963877320289612
30-01-2023 05:16:52 INFO Epoch 1: [9406/10940] ---- BYOL Training Loss = 0.2812601923942566
30-01-2023 05:17:11 INFO Epoch 1: [9417/10940] ---- BYOL Training Loss = 0.2982417941093445
30-01-2023 05:18:03 INFO Epoch 1: [9417/10940] ---- BYOL Validation Loss = 0.30150291323661804
30-01-2023 05:18:22 INFO Epoch 1: [9428/10940] ---- BYOL Training Loss = 0.3268732726573944
30-01-2023 05:18:40 INFO Epoch 1: [9439/10940] ---- BYOL Training Loss = 0.3220144808292389
30-01-2023 05:18:59 INFO Epoch 1: [9450/10940] ---- BYOL Training Loss = 0.30309921503067017
30-01-2023 05:19:18 INFO Epoch 1: [9461/10940] ---- BYOL Training Loss = 0.3049839437007904
30-01-2023 05:20:10 INFO Epoch 1: [9461/10940] ---- BYOL Validation Loss = 0.29400381445884705
30-01-2023 05:20:28 INFO Epoch 1: [9472/10940] ---- BYOL Training Loss = 0.2811468243598938
30-01-2023 05:20:47 INFO Epoch 1: [9483/10940] ---- BYOL Training Loss = 0.2979596257209778
30-01-2023 05:21:06 INFO Epoch 1: [9494/10940] ---- BYOL Training Loss = 0.30635303258895874
30-01-2023 05:21:25 INFO Epoch 1: [9505/10940] ---- BYOL Training Loss = 0.31280189752578735
30-01-2023 05:22:17 INFO Epoch 1: [9505/10940] ---- BYOL Validation Loss = 0.29793643951416016
30-01-2023 05:22:35 INFO Epoch 1: [9516/10940] ---- BYOL Training Loss = 0.2838807702064514
30-01-2023 05:22:54 INFO Epoch 1: [9527/10940] ---- BYOL Training Loss = 0.2631382942199707
30-01-2023 05:23:13 INFO Epoch 1: [9538/10940] ---- BYOL Training Loss = 0.2589055597782135
30-01-2023 05:23:32 INFO Epoch 1: [9549/10940] ---- BYOL Training Loss = 0.2732255160808563
30-01-2023 05:24:24 INFO Epoch 1: [9549/10940] ---- BYOL Validation Loss = 0.29544082283973694
30-01-2023 05:24:42 INFO Epoch 1: [9560/10940] ---- BYOL Training Loss = 0.31725987792015076
30-01-2023 05:25:01 INFO Epoch 1: [9571/10940] ---- BYOL Training Loss = 0.32006531953811646
30-01-2023 05:25:20 INFO Epoch 1: [9582/10940] ---- BYOL Training Loss = 0.3308066129684448
30-01-2023 05:25:39 INFO Epoch 1: [9593/10940] ---- BYOL Training Loss = 0.3088943064212799
30-01-2023 05:26:31 INFO Epoch 1: [9593/10940] ---- BYOL Validation Loss = 0.296835333108902
30-01-2023 05:26:49 INFO Epoch 1: [9604/10940] ---- BYOL Training Loss = 0.29165416955947876
30-01-2023 05:27:08 INFO Epoch 1: [9615/10940] ---- BYOL Training Loss = 0.2907096743583679
30-01-2023 05:27:27 INFO Epoch 1: [9626/10940] ---- BYOL Training Loss = 0.28076067566871643
30-01-2023 05:27:46 INFO Epoch 1: [9637/10940] ---- BYOL Training Loss = 0.26794499158859253
30-01-2023 05:28:38 INFO Epoch 1: [9637/10940] ---- BYOL Validation Loss = 0.2995387017726898
30-01-2023 05:28:56 INFO Epoch 1: [9648/10940] ---- BYOL Training Loss = 0.2946729362010956
30-01-2023 05:29:15 INFO Epoch 1: [9659/10940] ---- BYOL Training Loss = 0.29581502079963684
30-01-2023 05:29:34 INFO Epoch 1: [9670/10940] ---- BYOL Training Loss = 0.29611843824386597
30-01-2023 05:29:52 INFO Epoch 1: [9681/10940] ---- BYOL Training Loss = 0.3066628575325012
30-01-2023 05:30:44 INFO Epoch 1: [9681/10940] ---- BYOL Validation Loss = 0.3020842969417572
30-01-2023 05:31:03 INFO Epoch 1: [9692/10940] ---- BYOL Training Loss = 0.32946649193763733
30-01-2023 05:31:22 INFO Epoch 1: [9703/10940] ---- BYOL Training Loss = 0.30296579003334045
30-01-2023 05:31:40 INFO Epoch 1: [9714/10940] ---- BYOL Training Loss = 0.34387245774269104
30-01-2023 05:31:59 INFO Epoch 1: [9725/10940] ---- BYOL Training Loss = 0.37244492769241333
30-01-2023 05:32:51 INFO Epoch 1: [9725/10940] ---- BYOL Validation Loss = 0.3023882508277893
30-01-2023 05:33:09 INFO Epoch 1: [9736/10940] ---- BYOL Training Loss = 0.38410550355911255
30-01-2023 05:33:28 INFO Epoch 1: [9747/10940] ---- BYOL Training Loss = 0.34162428975105286
30-01-2023 05:33:47 INFO Epoch 1: [9758/10940] ---- BYOL Training Loss = 0.26763007044792175
30-01-2023 05:34:06 INFO Epoch 1: [9769/10940] ---- BYOL Training Loss = 0.26669198274612427
30-01-2023 05:34:58 INFO Epoch 1: [9769/10940] ---- BYOL Validation Loss = 0.2901487350463867
30-01-2023 05:35:16 INFO Epoch 1: [9780/10940] ---- BYOL Training Loss = 0.33729249238967896
30-01-2023 05:35:35 INFO Epoch 1: [9791/10940] ---- BYOL Training Loss = 0.30400967597961426
30-01-2023 05:35:54 INFO Epoch 1: [9802/10940] ---- BYOL Training Loss = 0.32231324911117554
30-01-2023 05:36:13 INFO Epoch 1: [9813/10940] ---- BYOL Training Loss = 0.3015815317630768
30-01-2023 05:37:05 INFO Epoch 1: [9813/10940] ---- BYOL Validation Loss = 0.29548951983451843
30-01-2023 05:37:23 INFO Epoch 1: [9824/10940] ---- BYOL Training Loss = 0.2899717390537262
30-01-2023 05:37:42 INFO Epoch 1: [9835/10940] ---- BYOL Training Loss = 0.3351137340068817
30-01-2023 05:38:01 INFO Epoch 1: [9846/10940] ---- BYOL Training Loss = 0.3205958902835846
30-01-2023 05:38:20 INFO Epoch 1: [9857/10940] ---- BYOL Training Loss = 0.25247883796691895
30-01-2023 05:39:11 INFO Epoch 1: [9857/10940] ---- BYOL Validation Loss = 0.297982782125473
30-01-2023 05:39:30 INFO Epoch 1: [9868/10940] ---- BYOL Training Loss = 0.2558594346046448
30-01-2023 05:39:49 INFO Epoch 1: [9879/10940] ---- BYOL Training Loss = 0.29105013608932495
30-01-2023 05:40:07 INFO Epoch 1: [9890/10940] ---- BYOL Training Loss = 0.3197726607322693
30-01-2023 05:40:27 INFO Epoch 1: [9901/10940] ---- BYOL Training Loss = 0.3515368103981018
30-01-2023 05:41:18 INFO Epoch 1: [9901/10940] ---- BYOL Validation Loss = 0.2974497973918915
30-01-2023 05:41:37 INFO Epoch 1: [9912/10940] ---- BYOL Training Loss = 0.33766990900039673
30-01-2023 05:41:56 INFO Epoch 1: [9923/10940] ---- BYOL Training Loss = 0.31130972504615784
30-01-2023 05:42:15 INFO Epoch 1: [9934/10940] ---- BYOL Training Loss = 0.2565361261367798
30-01-2023 05:42:33 INFO Epoch 1: [9945/10940] ---- BYOL Training Loss = 0.27295154333114624
30-01-2023 05:43:25 INFO Epoch 1: [9945/10940] ---- BYOL Validation Loss = 0.2980714440345764
30-01-2023 05:43:44 INFO Epoch 1: [9956/10940] ---- BYOL Training Loss = 0.3067869246006012
30-01-2023 05:44:03 INFO Epoch 1: [9967/10940] ---- BYOL Training Loss = 0.3278920650482178
30-01-2023 05:44:22 INFO Epoch 1: [9978/10940] ---- BYOL Training Loss = 0.3294743001461029
30-01-2023 05:44:40 INFO Epoch 1: [9989/10940] ---- BYOL Training Loss = 0.344279021024704
30-01-2023 05:45:32 INFO Epoch 1: [9989/10940] ---- BYOL Validation Loss = 0.290209025144577
30-01-2023 05:45:51 INFO Epoch 1: [10000/10940] ---- BYOL Training Loss = 0.33641576766967773
30-01-2023 05:46:10 INFO Epoch 1: [10011/10940] ---- BYOL Training Loss = 0.2831413149833679
30-01-2023 05:46:28 INFO Epoch 1: [10022/10940] ---- BYOL Training Loss = 0.3038112223148346
30-01-2023 05:46:47 INFO Epoch 1: [10033/10940] ---- BYOL Training Loss = 0.30317625403404236
30-01-2023 05:47:39 INFO Epoch 1: [10033/10940] ---- BYOL Validation Loss = 0.3005620539188385
30-01-2023 05:47:58 INFO Epoch 1: [10044/10940] ---- BYOL Training Loss = 0.2866767942905426
30-01-2023 05:48:17 INFO Epoch 1: [10055/10940] ---- BYOL Training Loss = 0.28099098801612854
30-01-2023 05:48:35 INFO Epoch 1: [10066/10940] ---- BYOL Training Loss = 0.30948036909103394
30-01-2023 05:48:54 INFO Epoch 1: [10077/10940] ---- BYOL Training Loss = 0.3295270800590515
30-01-2023 05:49:46 INFO Epoch 1: [10077/10940] ---- BYOL Validation Loss = 0.28878098726272583
30-01-2023 05:50:05 INFO Epoch 1: [10088/10940] ---- BYOL Training Loss = 0.32785794138908386
30-01-2023 05:50:23 INFO Epoch 1: [10099/10940] ---- BYOL Training Loss = 0.37030285596847534
30-01-2023 05:50:42 INFO Epoch 1: [10110/10940] ---- BYOL Training Loss = 0.33437487483024597
30-01-2023 05:51:01 INFO Epoch 1: [10121/10940] ---- BYOL Training Loss = 0.29275426268577576
30-01-2023 05:51:53 INFO Epoch 1: [10121/10940] ---- BYOL Validation Loss = 0.3056216835975647
30-01-2023 05:52:11 INFO Epoch 1: [10132/10940] ---- BYOL Training Loss = 0.319674551486969
30-01-2023 05:52:30 INFO Epoch 1: [10143/10940] ---- BYOL Training Loss = 0.2858654856681824
30-01-2023 05:52:49 INFO Epoch 1: [10154/10940] ---- BYOL Training Loss = 0.256033718585968
30-01-2023 05:53:08 INFO Epoch 1: [10165/10940] ---- BYOL Training Loss = 0.2852933406829834
30-01-2023 05:54:00 INFO Epoch 1: [10165/10940] ---- BYOL Validation Loss = 0.2995419502258301
30-01-2023 05:54:18 INFO Epoch 1: [10176/10940] ---- BYOL Training Loss = 0.32589489221572876
30-01-2023 05:54:37 INFO Epoch 1: [10187/10940] ---- BYOL Training Loss = 0.2724214196205139
30-01-2023 05:54:56 INFO Epoch 1: [10198/10940] ---- BYOL Training Loss = 0.2741168439388275
30-01-2023 05:55:15 INFO Epoch 1: [10209/10940] ---- BYOL Training Loss = 0.35255515575408936
30-01-2023 05:56:07 INFO Epoch 1: [10209/10940] ---- BYOL Validation Loss = 0.3035409450531006
30-01-2023 05:56:25 INFO Epoch 1: [10220/10940] ---- BYOL Training Loss = 0.369743287563324
30-01-2023 05:56:44 INFO Epoch 1: [10231/10940] ---- BYOL Training Loss = 0.3458159863948822
30-01-2023 05:57:03 INFO Epoch 1: [10242/10940] ---- BYOL Training Loss = 0.3120559751987457
30-01-2023 05:57:22 INFO Epoch 1: [10253/10940] ---- BYOL Training Loss = 0.31113988161087036
30-01-2023 05:58:14 INFO Epoch 1: [10253/10940] ---- BYOL Validation Loss = 0.2888414263725281
30-01-2023 05:58:32 INFO Epoch 1: [10264/10940] ---- BYOL Training Loss = 0.32812947034835815
30-01-2023 05:58:51 INFO Epoch 1: [10275/10940] ---- BYOL Training Loss = 0.2986471354961395
30-01-2023 05:59:10 INFO Epoch 1: [10286/10940] ---- BYOL Training Loss = 0.31247657537460327
30-01-2023 05:59:29 INFO Epoch 1: [10297/10940] ---- BYOL Training Loss = 0.3309813439846039
30-01-2023 06:00:21 INFO Epoch 1: [10297/10940] ---- BYOL Validation Loss = 0.30282968282699585
30-01-2023 06:00:39 INFO Epoch 1: [10308/10940] ---- BYOL Training Loss = 0.36158671975135803
30-01-2023 06:00:58 INFO Epoch 1: [10319/10940] ---- BYOL Training Loss = 0.3380551338195801
30-01-2023 06:01:17 INFO Epoch 1: [10330/10940] ---- BYOL Training Loss = 0.32569900155067444
30-01-2023 06:01:36 INFO Epoch 1: [10341/10940] ---- BYOL Training Loss = 0.29488930106163025
30-01-2023 06:02:28 INFO Epoch 1: [10341/10940] ---- BYOL Validation Loss = 0.2919684946537018
30-01-2023 06:02:46 INFO Epoch 1: [10352/10940] ---- BYOL Training Loss = 0.2881760001182556
30-01-2023 06:03:05 INFO Epoch 1: [10363/10940] ---- BYOL Training Loss = 0.307406485080719
30-01-2023 06:03:24 INFO Epoch 1: [10374/10940] ---- BYOL Training Loss = 0.2888915538787842
30-01-2023 06:03:43 INFO Epoch 1: [10385/10940] ---- BYOL Training Loss = 0.2762893736362457
30-01-2023 06:04:35 INFO Epoch 1: [10385/10940] ---- BYOL Validation Loss = 0.290410578250885
30-01-2023 06:04:53 INFO Epoch 1: [10396/10940] ---- BYOL Training Loss = 0.26308757066726685
30-01-2023 06:05:12 INFO Epoch 1: [10407/10940] ---- BYOL Training Loss = 0.27881571650505066
30-01-2023 06:05:31 INFO Epoch 1: [10418/10940] ---- BYOL Training Loss = 0.2822445333003998
30-01-2023 06:05:49 INFO Epoch 1: [10429/10940] ---- BYOL Training Loss = 0.30974143743515015
30-01-2023 06:06:41 INFO Epoch 1: [10429/10940] ---- BYOL Validation Loss = 0.29319262504577637
30-01-2023 06:07:00 INFO Epoch 1: [10440/10940] ---- BYOL Training Loss = 0.3450029492378235
30-01-2023 06:07:19 INFO Epoch 1: [10451/10940] ---- BYOL Training Loss = 0.30606430768966675
30-01-2023 06:07:38 INFO Epoch 1: [10462/10940] ---- BYOL Training Loss = 0.32236504554748535
30-01-2023 06:07:57 INFO Epoch 1: [10473/10940] ---- BYOL Training Loss = 0.3595244586467743
30-01-2023 06:08:48 INFO Epoch 1: [10473/10940] ---- BYOL Validation Loss = 0.29351821541786194
30-01-2023 06:09:07 INFO Epoch 1: [10484/10940] ---- BYOL Training Loss = 0.3229462802410126
30-01-2023 06:09:26 INFO Epoch 1: [10495/10940] ---- BYOL Training Loss = 0.3023144602775574
30-01-2023 06:09:45 INFO Epoch 1: [10506/10940] ---- BYOL Training Loss = 0.319511353969574
30-01-2023 06:10:04 INFO Epoch 1: [10517/10940] ---- BYOL Training Loss = 0.279313862323761
30-01-2023 06:10:56 INFO Epoch 1: [10517/10940] ---- BYOL Validation Loss = 0.286977618932724
30-01-2023 06:11:14 INFO Epoch 1: [10528/10940] ---- BYOL Training Loss = 0.2890569269657135
30-01-2023 06:11:33 INFO Epoch 1: [10539/10940] ---- BYOL Training Loss = 0.3116214871406555
30-01-2023 06:11:52 INFO Epoch 1: [10550/10940] ---- BYOL Training Loss = 0.3282240331172943
30-01-2023 06:12:11 INFO Epoch 1: [10561/10940] ---- BYOL Training Loss = 0.2901409864425659
30-01-2023 06:13:03 INFO Epoch 1: [10561/10940] ---- BYOL Validation Loss = 0.2863507866859436
30-01-2023 06:13:21 INFO Epoch 1: [10572/10940] ---- BYOL Training Loss = 0.29863739013671875
30-01-2023 06:13:40 INFO Epoch 1: [10583/10940] ---- BYOL Training Loss = 0.32481327652931213
30-01-2023 06:13:59 INFO Epoch 1: [10594/10940] ---- BYOL Training Loss = 0.284942090511322
30-01-2023 06:14:18 INFO Epoch 1: [10605/10940] ---- BYOL Training Loss = 0.290018767118454
30-01-2023 06:15:10 INFO Epoch 1: [10605/10940] ---- BYOL Validation Loss = 0.2917945683002472
30-01-2023 06:15:29 INFO Epoch 1: [10616/10940] ---- BYOL Training Loss = 0.32944661378860474
30-01-2023 06:15:47 INFO Epoch 1: [10627/10940] ---- BYOL Training Loss = 0.34121519327163696
30-01-2023 06:16:06 INFO Epoch 1: [10638/10940] ---- BYOL Training Loss = 0.3468852639198303
30-01-2023 06:16:25 INFO Epoch 1: [10649/10940] ---- BYOL Training Loss = 0.34116700291633606
30-01-2023 06:17:17 INFO Epoch 1: [10649/10940] ---- BYOL Validation Loss = 0.2839449942111969
30-01-2023 06:17:36 INFO Epoch 1: [10660/10940] ---- BYOL Training Loss = 0.3264014720916748
30-01-2023 06:17:55 INFO Epoch 1: [10671/10940] ---- BYOL Training Loss = 0.32974523305892944
30-01-2023 06:18:14 INFO Epoch 1: [10682/10940] ---- BYOL Training Loss = 0.33199992775917053
30-01-2023 06:18:33 INFO Epoch 1: [10693/10940] ---- BYOL Training Loss = 0.31197085976600647
30-01-2023 06:19:25 INFO Epoch 1: [10693/10940] ---- BYOL Validation Loss = 0.2823045551776886
30-01-2023 06:19:43 INFO Epoch 1: [10704/10940] ---- BYOL Training Loss = 0.30405497550964355
30-01-2023 06:20:02 INFO Epoch 1: [10715/10940] ---- BYOL Training Loss = 0.3094288408756256
30-01-2023 06:20:21 INFO Epoch 1: [10726/10940] ---- BYOL Training Loss = 0.2865294814109802
30-01-2023 06:20:40 INFO Epoch 1: [10737/10940] ---- BYOL Training Loss = 0.28498709201812744
30-01-2023 06:21:32 INFO Epoch 1: [10737/10940] ---- BYOL Validation Loss = 0.2748117744922638
30-01-2023 06:21:50 INFO Epoch 1: [10748/10940] ---- BYOL Training Loss = 0.3235149383544922
30-01-2023 06:22:09 INFO Epoch 1: [10759/10940] ---- BYOL Training Loss = 0.29202792048454285
30-01-2023 06:22:28 INFO Epoch 1: [10770/10940] ---- BYOL Training Loss = 0.29734334349632263
30-01-2023 06:22:47 INFO Epoch 1: [10781/10940] ---- BYOL Training Loss = 0.31173524260520935
30-01-2023 06:23:39 INFO Epoch 1: [10781/10940] ---- BYOL Validation Loss = 0.2880173623561859
30-01-2023 06:23:57 INFO Epoch 1: [10792/10940] ---- BYOL Training Loss = 0.30668705701828003
30-01-2023 06:24:16 INFO Epoch 1: [10803/10940] ---- BYOL Training Loss = 0.2923125624656677
30-01-2023 06:24:35 INFO Epoch 1: [10814/10940] ---- BYOL Training Loss = 0.3096374273300171
30-01-2023 06:24:54 INFO Epoch 1: [10825/10940] ---- BYOL Training Loss = 0.27506616711616516
30-01-2023 06:25:46 INFO Epoch 1: [10825/10940] ---- BYOL Validation Loss = 0.28544190526008606
30-01-2023 06:26:04 INFO Epoch 1: [10836/10940] ---- BYOL Training Loss = 0.25330087542533875
30-01-2023 06:26:23 INFO Epoch 1: [10847/10940] ---- BYOL Training Loss = 0.296519011259079
30-01-2023 06:26:42 INFO Epoch 1: [10858/10940] ---- BYOL Training Loss = 0.3200995624065399
30-01-2023 06:27:01 INFO Epoch 1: [10869/10940] ---- BYOL Training Loss = 0.3030795454978943
30-01-2023 06:27:53 INFO Epoch 1: [10869/10940] ---- BYOL Validation Loss = 0.28859466314315796
30-01-2023 06:28:12 INFO Epoch 1: [10880/10940] ---- BYOL Training Loss = 0.31806468963623047
30-01-2023 06:28:31 INFO Epoch 1: [10891/10940] ---- BYOL Training Loss = 0.2803034782409668
30-01-2023 06:28:50 INFO Epoch 1: [10902/10940] ---- BYOL Training Loss = 0.30095773935317993
30-01-2023 06:29:09 INFO Epoch 1: [10913/10940] ---- BYOL Training Loss = 0.31550630927085876
30-01-2023 06:30:00 INFO Epoch 1: [10913/10940] ---- BYOL Validation Loss = 0.2878754436969757
30-01-2023 06:30:19 INFO Epoch 1: [10924/10940] ---- BYOL Training Loss = 0.3074183166027069
30-01-2023 06:30:38 INFO Epoch 1: [10935/10940] ---- BYOL Training Loss = 0.30916744470596313
30-01-2023 06:30:47 INFO Starting Epoch: 2
30-01-2023 06:31:06 INFO Epoch 2: [12/10940] ---- BYOL Training Loss = 0.2758454382419586
30-01-2023 06:31:24 INFO Epoch 2: [23/10940] ---- BYOL Training Loss = 0.3063763976097107
30-01-2023 06:31:42 INFO Epoch 2: [34/10940] ---- BYOL Training Loss = 0.30514150857925415
30-01-2023 06:31:59 INFO Epoch 2: [45/10940] ---- BYOL Training Loss = 0.2704077363014221
30-01-2023 06:32:51 INFO Epoch 2: [45/10940] ---- BYOL Validation Loss = 0.27934375405311584
30-01-2023 06:33:09 INFO Epoch 2: [56/10940] ---- BYOL Training Loss = 0.3036091923713684
30-01-2023 06:33:27 INFO Epoch 2: [67/10940] ---- BYOL Training Loss = 0.2950607240200043
30-01-2023 06:33:45 INFO Epoch 2: [78/10940] ---- BYOL Training Loss = 0.28805989027023315
30-01-2023 06:34:02 INFO Epoch 2: [89/10940] ---- BYOL Training Loss = 0.31190919876098633
30-01-2023 06:34:54 INFO Epoch 2: [89/10940] ---- BYOL Validation Loss = 0.2916050851345062
30-01-2023 06:35:12 INFO Epoch 2: [100/10940] ---- BYOL Training Loss = 0.26853233575820923
30-01-2023 06:35:30 INFO Epoch 2: [111/10940] ---- BYOL Training Loss = 0.3155260384082794
30-01-2023 06:35:47 INFO Epoch 2: [122/10940] ---- BYOL Training Loss = 0.2954261004924774
30-01-2023 06:36:05 INFO Epoch 2: [133/10940] ---- BYOL Training Loss = 0.2894659638404846
30-01-2023 06:36:57 INFO Epoch 2: [133/10940] ---- BYOL Validation Loss = 0.28746750950813293
30-01-2023 06:37:15 INFO Epoch 2: [144/10940] ---- BYOL Training Loss = 0.26475900411605835
30-01-2023 06:37:33 INFO Epoch 2: [155/10940] ---- BYOL Training Loss = 0.24853000044822693
30-01-2023 06:37:51 INFO Epoch 2: [166/10940] ---- BYOL Training Loss = 0.2489899843931198
30-01-2023 06:38:08 INFO Epoch 2: [177/10940] ---- BYOL Training Loss = 0.2593042254447937
30-01-2023 06:39:00 INFO Epoch 2: [177/10940] ---- BYOL Validation Loss = 0.27863210439682007
30-01-2023 06:39:18 INFO Epoch 2: [188/10940] ---- BYOL Training Loss = 0.2715318500995636
30-01-2023 06:39:36 INFO Epoch 2: [199/10940] ---- BYOL Training Loss = 0.2645815908908844
30-01-2023 06:39:54 INFO Epoch 2: [210/10940] ---- BYOL Training Loss = 0.2887656092643738
30-01-2023 06:40:11 INFO Epoch 2: [221/10940] ---- BYOL Training Loss = 0.32120487093925476
30-01-2023 06:41:03 INFO Epoch 2: [221/10940] ---- BYOL Validation Loss = 0.28410083055496216
30-01-2023 06:41:21 INFO Epoch 2: [232/10940] ---- BYOL Training Loss = 0.3061072826385498
30-01-2023 06:41:39 INFO Epoch 2: [243/10940] ---- BYOL Training Loss = 0.28249305486679077
30-01-2023 06:41:57 INFO Epoch 2: [254/10940] ---- BYOL Training Loss = 0.27908164262771606
30-01-2023 06:42:14 INFO Epoch 2: [265/10940] ---- BYOL Training Loss = 0.26399171352386475
30-01-2023 06:43:06 INFO Epoch 2: [265/10940] ---- BYOL Validation Loss = 0.28564566373825073
30-01-2023 06:43:24 INFO Epoch 2: [276/10940] ---- BYOL Training Loss = 0.2854005694389343
30-01-2023 06:43:42 INFO Epoch 2: [287/10940] ---- BYOL Training Loss = 0.2890545427799225
30-01-2023 06:44:00 INFO Epoch 2: [298/10940] ---- BYOL Training Loss = 0.313770055770874
30-01-2023 06:44:17 INFO Epoch 2: [309/10940] ---- BYOL Training Loss = 0.30807924270629883
30-01-2023 06:45:09 INFO Epoch 2: [309/10940] ---- BYOL Validation Loss = 0.2888079285621643
30-01-2023 06:45:27 INFO Epoch 2: [320/10940] ---- BYOL Training Loss = 0.29470887780189514
30-01-2023 06:45:45 INFO Epoch 2: [331/10940] ---- BYOL Training Loss = 0.2665984630584717
30-01-2023 06:46:03 INFO Epoch 2: [342/10940] ---- BYOL Training Loss = 0.279157817363739
30-01-2023 06:46:21 INFO Epoch 2: [353/10940] ---- BYOL Training Loss = 0.3364512622356415
30-01-2023 06:47:12 INFO Epoch 2: [353/10940] ---- BYOL Validation Loss = 0.28068968653678894
30-01-2023 06:47:30 INFO Epoch 2: [364/10940] ---- BYOL Training Loss = 0.35849007964134216
30-01-2023 06:47:48 INFO Epoch 2: [375/10940] ---- BYOL Training Loss = 0.2850930690765381
30-01-2023 06:48:06 INFO Epoch 2: [386/10940] ---- BYOL Training Loss = 0.2870446741580963
30-01-2023 06:48:24 INFO Epoch 2: [397/10940] ---- BYOL Training Loss = 0.3010484576225281
30-01-2023 06:49:15 INFO Epoch 2: [397/10940] ---- BYOL Validation Loss = 0.2769045829772949
30-01-2023 06:49:33 INFO Epoch 2: [408/10940] ---- BYOL Training Loss = 0.30389970541000366
30-01-2023 06:49:51 INFO Epoch 2: [419/10940] ---- BYOL Training Loss = 0.28038397431373596
30-01-2023 06:50:09 INFO Epoch 2: [430/10940] ---- BYOL Training Loss = 0.2752952575683594
30-01-2023 06:50:26 INFO Epoch 2: [441/10940] ---- BYOL Training Loss = 0.27724435925483704
30-01-2023 06:51:18 INFO Epoch 2: [441/10940] ---- BYOL Validation Loss = 0.2768923044204712
30-01-2023 06:51:36 INFO Epoch 2: [452/10940] ---- BYOL Training Loss = 0.26520928740501404
30-01-2023 06:51:54 INFO Epoch 2: [463/10940] ---- BYOL Training Loss = 0.26974156498908997
30-01-2023 06:52:12 INFO Epoch 2: [474/10940] ---- BYOL Training Loss = 0.2802996039390564
30-01-2023 06:52:29 INFO Epoch 2: [485/10940] ---- BYOL Training Loss = 0.3056599497795105
30-01-2023 06:53:21 INFO Epoch 2: [485/10940] ---- BYOL Validation Loss = 0.274020254611969
30-01-2023 06:53:39 INFO Epoch 2: [496/10940] ---- BYOL Training Loss = 0.3103078305721283
30-01-2023 06:53:57 INFO Epoch 2: [507/10940] ---- BYOL Training Loss = 0.294467031955719
30-01-2023 06:54:14 INFO Epoch 2: [518/10940] ---- BYOL Training Loss = 0.2625660300254822
30-01-2023 06:54:32 INFO Epoch 2: [529/10940] ---- BYOL Training Loss = 0.24835006892681122
30-01-2023 06:55:24 INFO Epoch 2: [529/10940] ---- BYOL Validation Loss = 0.2739408314228058
30-01-2023 06:55:42 INFO Epoch 2: [540/10940] ---- BYOL Training Loss = 0.25021037459373474
30-01-2023 06:56:00 INFO Epoch 2: [551/10940] ---- BYOL Training Loss = 0.25712257623672485
30-01-2023 06:56:17 INFO Epoch 2: [562/10940] ---- BYOL Training Loss = 0.280961811542511
30-01-2023 06:56:35 INFO Epoch 2: [573/10940] ---- BYOL Training Loss = 0.27244600653648376
30-01-2023 06:57:27 INFO Epoch 2: [573/10940] ---- BYOL Validation Loss = 0.27766185998916626
30-01-2023 06:57:45 INFO Epoch 2: [584/10940] ---- BYOL Training Loss = 0.30078667402267456
30-01-2023 06:58:03 INFO Epoch 2: [595/10940] ---- BYOL Training Loss = 0.28472989797592163
30-01-2023 06:58:21 INFO Epoch 2: [606/10940] ---- BYOL Training Loss = 0.27170753479003906
30-01-2023 06:58:39 INFO Epoch 2: [617/10940] ---- BYOL Training Loss = 0.28120213747024536
30-01-2023 06:59:31 INFO Epoch 2: [617/10940] ---- BYOL Validation Loss = 0.2788398563861847
30-01-2023 06:59:48 INFO Epoch 2: [628/10940] ---- BYOL Training Loss = 0.2447982132434845
30-01-2023 07:00:06 INFO Epoch 2: [639/10940] ---- BYOL Training Loss = 0.2618982791900635
30-01-2023 07:00:24 INFO Epoch 2: [650/10940] ---- BYOL Training Loss = 0.3046123683452606
30-01-2023 07:00:42 INFO Epoch 2: [661/10940] ---- BYOL Training Loss = 0.29849499464035034
30-01-2023 07:01:34 INFO Epoch 2: [661/10940] ---- BYOL Validation Loss = 0.27416878938674927
30-01-2023 07:01:51 INFO Epoch 2: [672/10940] ---- BYOL Training Loss = 0.2746519148349762
30-01-2023 07:02:09 INFO Epoch 2: [683/10940] ---- BYOL Training Loss = 0.2346286028623581
30-01-2023 07:02:27 INFO Epoch 2: [694/10940] ---- BYOL Training Loss = 0.23970003426074982
30-01-2023 07:02:45 INFO Epoch 2: [705/10940] ---- BYOL Training Loss = 0.31335657835006714
30-01-2023 07:03:37 INFO Epoch 2: [705/10940] ---- BYOL Validation Loss = 0.28437212109565735
30-01-2023 07:03:54 INFO Epoch 2: [716/10940] ---- BYOL Training Loss = 0.31277304887771606
30-01-2023 07:04:12 INFO Epoch 2: [727/10940] ---- BYOL Training Loss = 0.280897319316864
30-01-2023 07:04:30 INFO Epoch 2: [738/10940] ---- BYOL Training Loss = 0.2838495373725891
30-01-2023 07:04:48 INFO Epoch 2: [749/10940] ---- BYOL Training Loss = 0.2738632261753082
30-01-2023 07:05:40 INFO Epoch 2: [749/10940] ---- BYOL Validation Loss = 0.2809799015522003
30-01-2023 07:05:58 INFO Epoch 2: [760/10940] ---- BYOL Training Loss = 0.2702523171901703
30-01-2023 07:06:16 INFO Epoch 2: [771/10940] ---- BYOL Training Loss = 0.3036901354789734
30-01-2023 07:06:34 INFO Epoch 2: [782/10940] ---- BYOL Training Loss = 0.28097161650657654
30-01-2023 07:06:52 INFO Epoch 2: [793/10940] ---- BYOL Training Loss = 0.28328877687454224
30-01-2023 07:07:43 INFO Epoch 2: [793/10940] ---- BYOL Validation Loss = 0.28169283270835876
30-01-2023 07:08:01 INFO Epoch 2: [804/10940] ---- BYOL Training Loss = 0.29408934712409973
30-01-2023 07:08:19 INFO Epoch 2: [815/10940] ---- BYOL Training Loss = 0.3169020116329193
30-01-2023 07:08:37 INFO Epoch 2: [826/10940] ---- BYOL Training Loss = 0.28253620862960815
30-01-2023 07:08:54 INFO Epoch 2: [837/10940] ---- BYOL Training Loss = 0.2673107087612152
30-01-2023 07:09:46 INFO Epoch 2: [837/10940] ---- BYOL Validation Loss = 0.2805020213127136
30-01-2023 07:10:04 INFO Epoch 2: [848/10940] ---- BYOL Training Loss = 0.271869957447052
30-01-2023 07:10:22 INFO Epoch 2: [859/10940] ---- BYOL Training Loss = 0.2683643400669098
30-01-2023 07:10:40 INFO Epoch 2: [870/10940] ---- BYOL Training Loss = 0.2849929928779602
30-01-2023 07:10:58 INFO Epoch 2: [881/10940] ---- BYOL Training Loss = 0.29490119218826294
30-01-2023 07:11:50 INFO Epoch 2: [881/10940] ---- BYOL Validation Loss = 0.2784513831138611
30-01-2023 07:12:07 INFO Epoch 2: [892/10940] ---- BYOL Training Loss = 0.296065092086792
30-01-2023 07:12:25 INFO Epoch 2: [903/10940] ---- BYOL Training Loss = 0.28106027841567993
30-01-2023 07:12:43 INFO Epoch 2: [914/10940] ---- BYOL Training Loss = 0.30546480417251587
30-01-2023 07:13:01 INFO Epoch 2: [925/10940] ---- BYOL Training Loss = 0.3274500072002411
30-01-2023 07:13:53 INFO Epoch 2: [925/10940] ---- BYOL Validation Loss = 0.2864449620246887
30-01-2023 07:14:10 INFO Epoch 2: [936/10940] ---- BYOL Training Loss = 0.3103184103965759
30-01-2023 07:14:28 INFO Epoch 2: [947/10940] ---- BYOL Training Loss = 0.26727598905563354
30-01-2023 07:14:46 INFO Epoch 2: [958/10940] ---- BYOL Training Loss = 0.28446558117866516
30-01-2023 07:15:04 INFO Epoch 2: [969/10940] ---- BYOL Training Loss = 0.300703227519989
30-01-2023 07:15:56 INFO Epoch 2: [969/10940] ---- BYOL Validation Loss = 0.28336697816848755
30-01-2023 07:16:14 INFO Epoch 2: [980/10940] ---- BYOL Training Loss = 0.28331390023231506
30-01-2023 07:16:32 INFO Epoch 2: [991/10940] ---- BYOL Training Loss = 0.31279927492141724
30-01-2023 07:16:50 INFO Epoch 2: [1002/10940] ---- BYOL Training Loss = 0.3312987983226776
30-01-2023 07:17:07 INFO Epoch 2: [1013/10940] ---- BYOL Training Loss = 0.3140830993652344
30-01-2023 07:17:59 INFO Epoch 2: [1013/10940] ---- BYOL Validation Loss = 0.28839176893234253
30-01-2023 07:18:17 INFO Epoch 2: [1024/10940] ---- BYOL Training Loss = 0.3418383300304413
30-01-2023 07:18:35 INFO Epoch 2: [1035/10940] ---- BYOL Training Loss = 0.30120623111724854
30-01-2023 07:18:53 INFO Epoch 2: [1046/10940] ---- BYOL Training Loss = 0.2600197196006775
30-01-2023 07:19:11 INFO Epoch 2: [1057/10940] ---- BYOL Training Loss = 0.3043281137943268
30-01-2023 07:20:03 INFO Epoch 2: [1057/10940] ---- BYOL Validation Loss = 0.2804207503795624
30-01-2023 07:20:20 INFO Epoch 2: [1068/10940] ---- BYOL Training Loss = 0.31726473569869995
30-01-2023 07:20:38 INFO Epoch 2: [1079/10940] ---- BYOL Training Loss = 0.2765887379646301
30-01-2023 07:20:56 INFO Epoch 2: [1090/10940] ---- BYOL Training Loss = 0.2579149901866913
30-01-2023 07:21:14 INFO Epoch 2: [1101/10940] ---- BYOL Training Loss = 0.2742174565792084
30-01-2023 07:22:06 INFO Epoch 2: [1101/10940] ---- BYOL Validation Loss = 0.2741663157939911
30-01-2023 07:22:24 INFO Epoch 2: [1112/10940] ---- BYOL Training Loss = 0.26509156823158264
30-01-2023 07:22:42 INFO Epoch 2: [1123/10940] ---- BYOL Training Loss = 0.2724928557872772
30-01-2023 07:23:00 INFO Epoch 2: [1134/10940] ---- BYOL Training Loss = 0.2976455092430115
30-01-2023 07:23:18 INFO Epoch 2: [1145/10940] ---- BYOL Training Loss = 0.2850913405418396
30-01-2023 07:24:10 INFO Epoch 2: [1145/10940] ---- BYOL Validation Loss = 0.2878805696964264
30-01-2023 07:24:27 INFO Epoch 2: [1156/10940] ---- BYOL Training Loss = 0.2786053419113159
30-01-2023 07:24:45 INFO Epoch 2: [1167/10940] ---- BYOL Training Loss = 0.2699485421180725
30-01-2023 07:25:03 INFO Epoch 2: [1178/10940] ---- BYOL Training Loss = 0.294878751039505
30-01-2023 07:25:21 INFO Epoch 2: [1189/10940] ---- BYOL Training Loss = 0.2956959009170532
30-01-2023 07:26:13 INFO Epoch 2: [1189/10940] ---- BYOL Validation Loss = 0.2666141390800476
30-01-2023 07:26:31 INFO Epoch 2: [1200/10940] ---- BYOL Training Loss = 0.26551032066345215
30-01-2023 07:26:49 INFO Epoch 2: [1211/10940] ---- BYOL Training Loss = 0.28184717893600464
30-01-2023 07:27:06 INFO Epoch 2: [1222/10940] ---- BYOL Training Loss = 0.3164385259151459
30-01-2023 07:27:24 INFO Epoch 2: [1233/10940] ---- BYOL Training Loss = 0.28695768117904663
30-01-2023 07:28:16 INFO Epoch 2: [1233/10940] ---- BYOL Validation Loss = 0.2776162922382355
30-01-2023 07:28:34 INFO Epoch 2: [1244/10940] ---- BYOL Training Loss = 0.2878369092941284
30-01-2023 07:28:52 INFO Epoch 2: [1255/10940] ---- BYOL Training Loss = 0.3007250428199768
30-01-2023 07:29:10 INFO Epoch 2: [1266/10940] ---- BYOL Training Loss = 0.2912254333496094
30-01-2023 07:29:28 INFO Epoch 2: [1277/10940] ---- BYOL Training Loss = 0.2799200117588043
30-01-2023 07:30:19 INFO Epoch 2: [1277/10940] ---- BYOL Validation Loss = 0.2736201286315918
30-01-2023 07:30:37 INFO Epoch 2: [1288/10940] ---- BYOL Training Loss = 0.2530971169471741
30-01-2023 07:30:55 INFO Epoch 2: [1299/10940] ---- BYOL Training Loss = 0.276771605014801
30-01-2023 07:31:13 INFO Epoch 2: [1310/10940] ---- BYOL Training Loss = 0.2909236550331116
30-01-2023 07:31:31 INFO Epoch 2: [1321/10940] ---- BYOL Training Loss = 0.30128076672554016
30-01-2023 07:32:23 INFO Epoch 2: [1321/10940] ---- BYOL Validation Loss = 0.2773358225822449
30-01-2023 07:32:40 INFO Epoch 2: [1332/10940] ---- BYOL Training Loss = 0.2978009581565857
30-01-2023 07:32:58 INFO Epoch 2: [1343/10940] ---- BYOL Training Loss = 0.28895673155784607
30-01-2023 07:33:16 INFO Epoch 2: [1354/10940] ---- BYOL Training Loss = 0.31145158410072327
30-01-2023 07:33:35 INFO Epoch 2: [1365/10940] ---- BYOL Training Loss = 0.33439958095550537
30-01-2023 07:34:26 INFO Epoch 2: [1365/10940] ---- BYOL Validation Loss = 0.2913293242454529
30-01-2023 07:34:44 INFO Epoch 2: [1376/10940] ---- BYOL Training Loss = 0.32037079334259033
30-01-2023 07:35:02 INFO Epoch 2: [1387/10940] ---- BYOL Training Loss = 0.28899282217025757
30-01-2023 07:35:20 INFO Epoch 2: [1398/10940] ---- BYOL Training Loss = 0.2654063403606415
30-01-2023 07:35:38 INFO Epoch 2: [1409/10940] ---- BYOL Training Loss = 0.2643255889415741
30-01-2023 07:36:30 INFO Epoch 2: [1409/10940] ---- BYOL Validation Loss = 0.28342655301094055
30-01-2023 07:36:48 INFO Epoch 2: [1420/10940] ---- BYOL Training Loss = 0.2908931374549866
30-01-2023 07:37:06 INFO Epoch 2: [1431/10940] ---- BYOL Training Loss = 0.327486515045166
30-01-2023 07:37:23 INFO Epoch 2: [1442/10940] ---- BYOL Training Loss = 0.3102056086063385
30-01-2023 07:37:42 INFO Epoch 2: [1453/10940] ---- BYOL Training Loss = 0.268693745136261
30-01-2023 07:38:33 INFO Epoch 2: [1453/10940] ---- BYOL Validation Loss = 0.2719866633415222
30-01-2023 07:38:51 INFO Epoch 2: [1464/10940] ---- BYOL Training Loss = 0.24480672180652618
30-01-2023 07:39:09 INFO Epoch 2: [1475/10940] ---- BYOL Training Loss = 0.2705571949481964
30-01-2023 07:39:27 INFO Epoch 2: [1486/10940] ---- BYOL Training Loss = 0.2971566617488861
30-01-2023 07:39:45 INFO Epoch 2: [1497/10940] ---- BYOL Training Loss = 0.27544668316841125
30-01-2023 07:40:37 INFO Epoch 2: [1497/10940] ---- BYOL Validation Loss = 0.28099608421325684
30-01-2023 07:40:54 INFO Epoch 2: [1508/10940] ---- BYOL Training Loss = 0.24332325160503387
30-01-2023 07:41:12 INFO Epoch 2: [1519/10940] ---- BYOL Training Loss = 0.24910549819469452
30-01-2023 07:41:30 INFO Epoch 2: [1530/10940] ---- BYOL Training Loss = 0.2878102660179138
30-01-2023 07:41:48 INFO Epoch 2: [1541/10940] ---- BYOL Training Loss = 0.30741241574287415
30-01-2023 07:42:40 INFO Epoch 2: [1541/10940] ---- BYOL Validation Loss = 0.2866847813129425
30-01-2023 07:42:58 INFO Epoch 2: [1552/10940] ---- BYOL Training Loss = 0.27906420826911926
30-01-2023 07:43:16 INFO Epoch 2: [1563/10940] ---- BYOL Training Loss = 0.23210163414478302
30-01-2023 07:43:34 INFO Epoch 2: [1574/10940] ---- BYOL Training Loss = 0.2614704668521881
30-01-2023 07:43:52 INFO Epoch 2: [1585/10940] ---- BYOL Training Loss = 0.2538328766822815
30-01-2023 07:44:44 INFO Epoch 2: [1585/10940] ---- BYOL Validation Loss = 0.27483558654785156
30-01-2023 07:45:01 INFO Epoch 2: [1596/10940] ---- BYOL Training Loss = 0.26370495557785034
30-01-2023 07:45:19 INFO Epoch 2: [1607/10940] ---- BYOL Training Loss = 0.30739980936050415
30-01-2023 07:45:37 INFO Epoch 2: [1618/10940] ---- BYOL Training Loss = 0.2775038778781891
30-01-2023 07:45:55 INFO Epoch 2: [1629/10940] ---- BYOL Training Loss = 0.24624812602996826
30-01-2023 07:46:47 INFO Epoch 2: [1629/10940] ---- BYOL Validation Loss = 0.2714328467845917
30-01-2023 07:47:05 INFO Epoch 2: [1640/10940] ---- BYOL Training Loss = 0.2381150722503662
30-01-2023 07:47:23 INFO Epoch 2: [1651/10940] ---- BYOL Training Loss = 0.2714259922504425
30-01-2023 07:47:41 INFO Epoch 2: [1662/10940] ---- BYOL Training Loss = 0.3207300007343292
30-01-2023 07:47:59 INFO Epoch 2: [1673/10940] ---- BYOL Training Loss = 0.2954995930194855
30-01-2023 07:48:51 INFO Epoch 2: [1673/10940] ---- BYOL Validation Loss = 0.2778059244155884
30-01-2023 07:49:08 INFO Epoch 2: [1684/10940] ---- BYOL Training Loss = 0.26219844818115234
30-01-2023 07:49:26 INFO Epoch 2: [1695/10940] ---- BYOL Training Loss = 0.26750028133392334
30-01-2023 07:49:44 INFO Epoch 2: [1706/10940] ---- BYOL Training Loss = 0.30941200256347656
30-01-2023 07:50:02 INFO Epoch 2: [1717/10940] ---- BYOL Training Loss = 0.30671265721321106
30-01-2023 07:50:54 INFO Epoch 2: [1717/10940] ---- BYOL Validation Loss = 0.2732582688331604
30-01-2023 07:51:12 INFO Epoch 2: [1728/10940] ---- BYOL Training Loss = 0.26796892285346985
30-01-2023 07:51:29 INFO Epoch 2: [1739/10940] ---- BYOL Training Loss = 0.26057106256484985
30-01-2023 07:51:47 INFO Epoch 2: [1750/10940] ---- BYOL Training Loss = 0.26317495107650757
30-01-2023 07:52:05 INFO Epoch 2: [1761/10940] ---- BYOL Training Loss = 0.26240840554237366
30-01-2023 07:52:57 INFO Epoch 2: [1761/10940] ---- BYOL Validation Loss = 0.27382057905197144
30-01-2023 07:53:15 INFO Epoch 2: [1772/10940] ---- BYOL Training Loss = 0.2788761556148529
30-01-2023 07:53:33 INFO Epoch 2: [1783/10940] ---- BYOL Training Loss = 0.30292314291000366
30-01-2023 07:53:51 INFO Epoch 2: [1794/10940] ---- BYOL Training Loss = 0.2846837043762207
30-01-2023 07:54:09 INFO Epoch 2: [1805/10940] ---- BYOL Training Loss = 0.297343373298645
30-01-2023 07:55:01 INFO Epoch 2: [1805/10940] ---- BYOL Validation Loss = 0.27095869183540344
30-01-2023 07:55:19 INFO Epoch 2: [1816/10940] ---- BYOL Training Loss = 0.3482901453971863
30-01-2023 07:55:37 INFO Epoch 2: [1827/10940] ---- BYOL Training Loss = 0.27625077962875366
30-01-2023 07:55:55 INFO Epoch 2: [1838/10940] ---- BYOL Training Loss = 0.26400572061538696
30-01-2023 07:56:13 INFO Epoch 2: [1849/10940] ---- BYOL Training Loss = 0.2851567268371582
30-01-2023 07:57:04 INFO Epoch 2: [1849/10940] ---- BYOL Validation Loss = 0.2749297618865967
30-01-2023 07:57:22 INFO Epoch 2: [1860/10940] ---- BYOL Training Loss = 0.2983146011829376
30-01-2023 07:57:40 INFO Epoch 2: [1871/10940] ---- BYOL Training Loss = 0.2744508981704712
30-01-2023 07:57:58 INFO Epoch 2: [1882/10940] ---- BYOL Training Loss = 0.25614210963249207
30-01-2023 07:58:16 INFO Epoch 2: [1893/10940] ---- BYOL Training Loss = 0.28831949830055237
30-01-2023 07:59:08 INFO Epoch 2: [1893/10940] ---- BYOL Validation Loss = 0.2704571485519409
30-01-2023 07:59:25 INFO Epoch 2: [1904/10940] ---- BYOL Training Loss = 0.275340735912323
30-01-2023 07:59:44 INFO Epoch 2: [1915/10940] ---- BYOL Training Loss = 0.32393142580986023
30-01-2023 08:00:02 INFO Epoch 2: [1926/10940] ---- BYOL Training Loss = 0.34140029549598694
30-01-2023 08:00:20 INFO Epoch 2: [1937/10940] ---- BYOL Training Loss = 0.3163405656814575
30-01-2023 08:01:12 INFO Epoch 2: [1937/10940] ---- BYOL Validation Loss = 0.2794046700000763
30-01-2023 08:01:29 INFO Epoch 2: [1948/10940] ---- BYOL Training Loss = 0.3394504189491272
30-01-2023 08:01:47 INFO Epoch 2: [1959/10940] ---- BYOL Training Loss = 0.3117179572582245
30-01-2023 08:02:05 INFO Epoch 2: [1970/10940] ---- BYOL Training Loss = 0.30708029866218567
30-01-2023 08:02:23 INFO Epoch 2: [1981/10940] ---- BYOL Training Loss = 0.3164578974246979
30-01-2023 08:03:15 INFO Epoch 2: [1981/10940] ---- BYOL Validation Loss = 0.28056034445762634
30-01-2023 08:03:33 INFO Epoch 2: [1992/10940] ---- BYOL Training Loss = 0.30929240584373474
30-01-2023 08:03:51 INFO Epoch 2: [2003/10940] ---- BYOL Training Loss = 0.31068170070648193
30-01-2023 08:04:09 INFO Epoch 2: [2014/10940] ---- BYOL Training Loss = 0.3079497814178467
30-01-2023 08:04:27 INFO Epoch 2: [2025/10940] ---- BYOL Training Loss = 0.32956117391586304
30-01-2023 08:05:19 INFO Epoch 2: [2025/10940] ---- BYOL Validation Loss = 0.28153571486473083
30-01-2023 08:05:36 INFO Epoch 2: [2036/10940] ---- BYOL Training Loss = 0.3052079677581787
30-01-2023 08:05:54 INFO Epoch 2: [2047/10940] ---- BYOL Training Loss = 0.3274427056312561
30-01-2023 08:06:12 INFO Epoch 2: [2058/10940] ---- BYOL Training Loss = 0.3227459490299225
30-01-2023 08:06:30 INFO Epoch 2: [2069/10940] ---- BYOL Training Loss = 0.29684633016586304
30-01-2023 08:07:22 INFO Epoch 2: [2069/10940] ---- BYOL Validation Loss = 0.2808015048503876
30-01-2023 08:07:40 INFO Epoch 2: [2080/10940] ---- BYOL Training Loss = 0.2834102511405945
30-01-2023 08:07:58 INFO Epoch 2: [2091/10940] ---- BYOL Training Loss = 0.25069841742515564
30-01-2023 08:08:16 INFO Epoch 2: [2102/10940] ---- BYOL Training Loss = 0.2761636972427368
30-01-2023 08:08:34 INFO Epoch 2: [2113/10940] ---- BYOL Training Loss = 0.26335588097572327
30-01-2023 08:09:26 INFO Epoch 2: [2113/10940] ---- BYOL Validation Loss = 0.2699255645275116
30-01-2023 08:09:44 INFO Epoch 2: [2124/10940] ---- BYOL Training Loss = 0.28479498624801636
30-01-2023 08:10:02 INFO Epoch 2: [2135/10940] ---- BYOL Training Loss = 0.29320207238197327
30-01-2023 08:10:20 INFO Epoch 2: [2146/10940] ---- BYOL Training Loss = 0.260846346616745
30-01-2023 08:10:38 INFO Epoch 2: [2157/10940] ---- BYOL Training Loss = 0.2795369625091553
30-01-2023 08:11:30 INFO Epoch 2: [2157/10940] ---- BYOL Validation Loss = 0.2884085476398468
30-01-2023 08:11:47 INFO Epoch 2: [2168/10940] ---- BYOL Training Loss = 0.29447758197784424
30-01-2023 08:12:05 INFO Epoch 2: [2179/10940] ---- BYOL Training Loss = 0.2963736951351166
30-01-2023 08:12:23 INFO Epoch 2: [2190/10940] ---- BYOL Training Loss = 0.30835816264152527
30-01-2023 08:12:41 INFO Epoch 2: [2201/10940] ---- BYOL Training Loss = 0.29269829392433167
30-01-2023 08:13:33 INFO Epoch 2: [2201/10940] ---- BYOL Validation Loss = 0.2815128564834595
30-01-2023 08:13:51 INFO Epoch 2: [2212/10940] ---- BYOL Training Loss = 0.25372761487960815
30-01-2023 08:14:09 INFO Epoch 2: [2223/10940] ---- BYOL Training Loss = 0.24952563643455505
30-01-2023 08:14:27 INFO Epoch 2: [2234/10940] ---- BYOL Training Loss = 0.28038182854652405
30-01-2023 08:14:45 INFO Epoch 2: [2245/10940] ---- BYOL Training Loss = 0.2508907914161682
30-01-2023 08:15:37 INFO Epoch 2: [2245/10940] ---- BYOL Validation Loss = 0.281159371137619
30-01-2023 08:15:55 INFO Epoch 2: [2256/10940] ---- BYOL Training Loss = 0.2877329885959625
30-01-2023 08:16:13 INFO Epoch 2: [2267/10940] ---- BYOL Training Loss = 0.2911660373210907
30-01-2023 08:16:31 INFO Epoch 2: [2278/10940] ---- BYOL Training Loss = 0.2818843722343445
30-01-2023 08:16:49 INFO Epoch 2: [2289/10940] ---- BYOL Training Loss = 0.2977848947048187
30-01-2023 08:17:41 INFO Epoch 2: [2289/10940] ---- BYOL Validation Loss = 0.2848055958747864
30-01-2023 08:17:59 INFO Epoch 2: [2300/10940] ---- BYOL Training Loss = 0.275420218706131
30-01-2023 08:18:17 INFO Epoch 2: [2311/10940] ---- BYOL Training Loss = 0.300708144903183
30-01-2023 08:18:35 INFO Epoch 2: [2322/10940] ---- BYOL Training Loss = 0.28243541717529297
30-01-2023 08:18:53 INFO Epoch 2: [2333/10940] ---- BYOL Training Loss = 0.2714653015136719
30-01-2023 08:19:45 INFO Epoch 2: [2333/10940] ---- BYOL Validation Loss = 0.267380952835083
30-01-2023 08:20:02 INFO Epoch 2: [2344/10940] ---- BYOL Training Loss = 0.2592483162879944
30-01-2023 08:20:21 INFO Epoch 2: [2355/10940] ---- BYOL Training Loss = 0.2392866611480713
30-01-2023 08:20:39 INFO Epoch 2: [2366/10940] ---- BYOL Training Loss = 0.25264352560043335
30-01-2023 08:20:57 INFO Epoch 2: [2377/10940] ---- BYOL Training Loss = 0.28161942958831787
30-01-2023 08:21:49 INFO Epoch 2: [2377/10940] ---- BYOL Validation Loss = 0.26214316487312317
30-01-2023 08:22:07 INFO Epoch 2: [2388/10940] ---- BYOL Training Loss = 0.3171374201774597
30-01-2023 08:22:25 INFO Epoch 2: [2399/10940] ---- BYOL Training Loss = 0.3379345238208771
30-01-2023 08:22:43 INFO Epoch 2: [2410/10940] ---- BYOL Training Loss = 0.2813127338886261
30-01-2023 08:23:01 INFO Epoch 2: [2421/10940] ---- BYOL Training Loss = 0.24652743339538574
30-01-2023 08:23:53 INFO Epoch 2: [2421/10940] ---- BYOL Validation Loss = 0.2702445387840271
30-01-2023 08:24:10 INFO Epoch 2: [2432/10940] ---- BYOL Training Loss = 0.2812553644180298
30-01-2023 08:24:28 INFO Epoch 2: [2443/10940] ---- BYOL Training Loss = 0.3122880160808563
30-01-2023 08:24:46 INFO Epoch 2: [2454/10940] ---- BYOL Training Loss = 0.2901933789253235
30-01-2023 08:25:04 INFO Epoch 2: [2465/10940] ---- BYOL Training Loss = 0.2883084714412689
30-01-2023 08:25:56 INFO Epoch 2: [2465/10940] ---- BYOL Validation Loss = 0.26603251695632935
30-01-2023 08:26:14 INFO Epoch 2: [2476/10940] ---- BYOL Training Loss = 0.2756718695163727
30-01-2023 08:26:33 INFO Epoch 2: [2487/10940] ---- BYOL Training Loss = 0.27986499667167664
30-01-2023 08:26:51 INFO Epoch 2: [2498/10940] ---- BYOL Training Loss = 0.24636635184288025
30-01-2023 08:27:09 INFO Epoch 2: [2509/10940] ---- BYOL Training Loss = 0.2945849299430847
30-01-2023 08:28:00 INFO Epoch 2: [2509/10940] ---- BYOL Validation Loss = 0.27391260862350464
30-01-2023 08:28:18 INFO Epoch 2: [2520/10940] ---- BYOL Training Loss = 0.32354581356048584
30-01-2023 08:28:36 INFO Epoch 2: [2531/10940] ---- BYOL Training Loss = 0.2397107630968094
30-01-2023 08:28:54 INFO Epoch 2: [2542/10940] ---- BYOL Training Loss = 0.25981956720352173
30-01-2023 08:29:12 INFO Epoch 2: [2553/10940] ---- BYOL Training Loss = 0.26657092571258545
30-01-2023 08:30:04 INFO Epoch 2: [2553/10940] ---- BYOL Validation Loss = 0.26879534125328064
30-01-2023 08:30:22 INFO Epoch 2: [2564/10940] ---- BYOL Training Loss = 0.2463192194700241
30-01-2023 08:30:40 INFO Epoch 2: [2575/10940] ---- BYOL Training Loss = 0.2699369490146637
30-01-2023 08:30:58 INFO Epoch 2: [2586/10940] ---- BYOL Training Loss = 0.30609130859375
30-01-2023 08:31:16 INFO Epoch 2: [2597/10940] ---- BYOL Training Loss = 0.28572267293930054
30-01-2023 08:32:08 INFO Epoch 2: [2597/10940] ---- BYOL Validation Loss = 0.264687716960907
30-01-2023 08:32:26 INFO Epoch 2: [2608/10940] ---- BYOL Training Loss = 0.3019842207431793
30-01-2023 08:32:44 INFO Epoch 2: [2619/10940] ---- BYOL Training Loss = 0.3099840581417084
30-01-2023 08:33:02 INFO Epoch 2: [2630/10940] ---- BYOL Training Loss = 0.28696209192276
30-01-2023 08:33:20 INFO Epoch 2: [2641/10940] ---- BYOL Training Loss = 0.2858586609363556
30-01-2023 08:34:12 INFO Epoch 2: [2641/10940] ---- BYOL Validation Loss = 0.2749064862728119
30-01-2023 08:34:30 INFO Epoch 2: [2652/10940] ---- BYOL Training Loss = 0.26877331733703613
30-01-2023 08:34:48 INFO Epoch 2: [2663/10940] ---- BYOL Training Loss = 0.28600233793258667
30-01-2023 08:35:06 INFO Epoch 2: [2674/10940] ---- BYOL Training Loss = 0.29305902123451233
30-01-2023 08:35:24 INFO Epoch 2: [2685/10940] ---- BYOL Training Loss = 0.31893011927604675
30-01-2023 08:36:16 INFO Epoch 2: [2685/10940] ---- BYOL Validation Loss = 0.27469655871391296
30-01-2023 08:36:33 INFO Epoch 2: [2696/10940] ---- BYOL Training Loss = 0.31087613105773926
30-01-2023 08:36:51 INFO Epoch 2: [2707/10940] ---- BYOL Training Loss = 0.29294055700302124
30-01-2023 08:37:10 INFO Epoch 2: [2718/10940] ---- BYOL Training Loss = 0.2757543921470642
30-01-2023 08:37:28 INFO Epoch 2: [2729/10940] ---- BYOL Training Loss = 0.26813265681266785
30-01-2023 08:38:20 INFO Epoch 2: [2729/10940] ---- BYOL Validation Loss = 0.2644443213939667
30-01-2023 08:38:37 INFO Epoch 2: [2740/10940] ---- BYOL Training Loss = 0.29164427518844604
30-01-2023 08:38:56 INFO Epoch 2: [2751/10940] ---- BYOL Training Loss = 0.25982341170310974
30-01-2023 08:39:14 INFO Epoch 2: [2762/10940] ---- BYOL Training Loss = 0.26863187551498413
30-01-2023 08:39:32 INFO Epoch 2: [2773/10940] ---- BYOL Training Loss = 0.32940182089805603
30-01-2023 08:40:24 INFO Epoch 2: [2773/10940] ---- BYOL Validation Loss = 0.2850636839866638
30-01-2023 08:40:41 INFO Epoch 2: [2784/10940] ---- BYOL Training Loss = 0.2936699092388153
30-01-2023 08:40:59 INFO Epoch 2: [2795/10940] ---- BYOL Training Loss = 0.23139269649982452
30-01-2023 08:41:18 INFO Epoch 2: [2806/10940] ---- BYOL Training Loss = 0.23827366530895233
30-01-2023 08:41:36 INFO Epoch 2: [2817/10940] ---- BYOL Training Loss = 0.28628650307655334
30-01-2023 08:42:28 INFO Epoch 2: [2817/10940] ---- BYOL Validation Loss = 0.27140507102012634
30-01-2023 08:42:46 INFO Epoch 2: [2828/10940] ---- BYOL Training Loss = 0.29890602827072144
30-01-2023 08:43:04 INFO Epoch 2: [2839/10940] ---- BYOL Training Loss = 0.31633460521698
30-01-2023 08:43:22 INFO Epoch 2: [2850/10940] ---- BYOL Training Loss = 0.334689199924469
30-01-2023 08:43:40 INFO Epoch 2: [2861/10940] ---- BYOL Training Loss = 0.29599982500076294
30-01-2023 08:44:32 INFO Epoch 2: [2861/10940] ---- BYOL Validation Loss = 0.26538997888565063
30-01-2023 08:44:49 INFO Epoch 2: [2872/10940] ---- BYOL Training Loss = 0.25107836723327637
30-01-2023 08:45:07 INFO Epoch 2: [2883/10940] ---- BYOL Training Loss = 0.2840421795845032
30-01-2023 08:45:26 INFO Epoch 2: [2894/10940] ---- BYOL Training Loss = 0.2966582179069519
30-01-2023 08:45:44 INFO Epoch 2: [2905/10940] ---- BYOL Training Loss = 0.2645285725593567
30-01-2023 08:46:36 INFO Epoch 2: [2905/10940] ---- BYOL Validation Loss = 0.25755053758621216
30-01-2023 08:46:54 INFO Epoch 2: [2916/10940] ---- BYOL Training Loss = 0.24636885523796082
30-01-2023 08:47:12 INFO Epoch 2: [2927/10940] ---- BYOL Training Loss = 0.2673869729042053
30-01-2023 08:47:30 INFO Epoch 2: [2938/10940] ---- BYOL Training Loss = 0.2953266501426697
30-01-2023 08:47:48 INFO Epoch 2: [2949/10940] ---- BYOL Training Loss = 0.28389498591423035
30-01-2023 08:48:40 INFO Epoch 2: [2949/10940] ---- BYOL Validation Loss = 0.2525767683982849
30-01-2023 08:48:57 INFO Epoch 2: [2960/10940] ---- BYOL Training Loss = 0.2647680640220642
30-01-2023 08:49:15 INFO Epoch 2: [2971/10940] ---- BYOL Training Loss = 0.23664216697216034
30-01-2023 08:49:34 INFO Epoch 2: [2982/10940] ---- BYOL Training Loss = 0.2822020947933197
30-01-2023 08:49:52 INFO Epoch 2: [2993/10940] ---- BYOL Training Loss = 0.32469436526298523
30-01-2023 08:50:44 INFO Epoch 2: [2993/10940] ---- BYOL Validation Loss = 0.26280802488327026
30-01-2023 08:51:01 INFO Epoch 2: [3004/10940] ---- BYOL Training Loss = 0.29227322340011597
30-01-2023 08:51:20 INFO Epoch 2: [3015/10940] ---- BYOL Training Loss = 0.31610745191574097
30-01-2023 08:51:38 INFO Epoch 2: [3026/10940] ---- BYOL Training Loss = 0.3283274173736572
30-01-2023 08:51:56 INFO Epoch 2: [3037/10940] ---- BYOL Training Loss = 0.31088787317276
30-01-2023 08:52:48 INFO Epoch 2: [3037/10940] ---- BYOL Validation Loss = 0.2638299763202667
30-01-2023 08:53:05 INFO Epoch 2: [3048/10940] ---- BYOL Training Loss = 0.31836169958114624
30-01-2023 08:53:23 INFO Epoch 2: [3059/10940] ---- BYOL Training Loss = 0.28453153371810913
30-01-2023 08:53:42 INFO Epoch 2: [3070/10940] ---- BYOL Training Loss = 0.2904345393180847
30-01-2023 08:54:00 INFO Epoch 2: [3081/10940] ---- BYOL Training Loss = 0.3128092885017395
30-01-2023 08:54:52 INFO Epoch 2: [3081/10940] ---- BYOL Validation Loss = 0.2558443546295166
30-01-2023 08:55:10 INFO Epoch 2: [3092/10940] ---- BYOL Training Loss = 0.2989494204521179
30-01-2023 08:55:28 INFO Epoch 2: [3103/10940] ---- BYOL Training Loss = 0.23887479305267334
30-01-2023 08:55:46 INFO Epoch 2: [3114/10940] ---- BYOL Training Loss = 0.2495776116847992
30-01-2023 08:56:04 INFO Epoch 2: [3125/10940] ---- BYOL Training Loss = 0.28703469038009644
30-01-2023 08:56:56 INFO Epoch 2: [3125/10940] ---- BYOL Validation Loss = 0.2619779109954834
30-01-2023 08:57:14 INFO Epoch 2: [3136/10940] ---- BYOL Training Loss = 0.28549474477767944
30-01-2023 08:57:32 INFO Epoch 2: [3147/10940] ---- BYOL Training Loss = 0.29681429266929626
30-01-2023 08:57:50 INFO Epoch 2: [3158/10940] ---- BYOL Training Loss = 0.29654622077941895
30-01-2023 08:58:09 INFO Epoch 2: [3169/10940] ---- BYOL Training Loss = 0.2739294767379761
30-01-2023 08:59:01 INFO Epoch 2: [3169/10940] ---- BYOL Validation Loss = 0.26065126061439514
30-01-2023 08:59:18 INFO Epoch 2: [3180/10940] ---- BYOL Training Loss = 0.26458990573883057
30-01-2023 08:59:37 INFO Epoch 2: [3191/10940] ---- BYOL Training Loss = 0.3038675785064697
30-01-2023 08:59:55 INFO Epoch 2: [3202/10940] ---- BYOL Training Loss = 0.28485268354415894
30-01-2023 09:00:13 INFO Epoch 2: [3213/10940] ---- BYOL Training Loss = 0.2586464285850525
30-01-2023 09:01:05 INFO Epoch 2: [3213/10940] ---- BYOL Validation Loss = 0.25819844007492065
30-01-2023 09:01:22 INFO Epoch 2: [3224/10940] ---- BYOL Training Loss = 0.2694648802280426
30-01-2023 09:01:41 INFO Epoch 2: [3235/10940] ---- BYOL Training Loss = 0.3201071619987488
30-01-2023 09:01:59 INFO Epoch 2: [3246/10940] ---- BYOL Training Loss = 0.3141195774078369
30-01-2023 09:02:17 INFO Epoch 2: [3257/10940] ---- BYOL Training Loss = 0.2542881965637207
30-01-2023 09:03:09 INFO Epoch 2: [3257/10940] ---- BYOL Validation Loss = 0.25742489099502563
30-01-2023 09:03:27 INFO Epoch 2: [3268/10940] ---- BYOL Training Loss = 0.22589604556560516
30-01-2023 09:03:45 INFO Epoch 2: [3279/10940] ---- BYOL Training Loss = 0.25237777829170227
30-01-2023 09:04:03 INFO Epoch 2: [3290/10940] ---- BYOL Training Loss = 0.2565649151802063
30-01-2023 09:04:21 INFO Epoch 2: [3301/10940] ---- BYOL Training Loss = 0.27368706464767456
30-01-2023 09:05:13 INFO Epoch 2: [3301/10940] ---- BYOL Validation Loss = 0.2540387511253357
30-01-2023 09:05:31 INFO Epoch 2: [3312/10940] ---- BYOL Training Loss = 0.25490790605545044
30-01-2023 09:05:49 INFO Epoch 2: [3323/10940] ---- BYOL Training Loss = 0.28406697511672974
30-01-2023 09:06:07 INFO Epoch 2: [3334/10940] ---- BYOL Training Loss = 0.29743319749832153
30-01-2023 09:06:26 INFO Epoch 2: [3345/10940] ---- BYOL Training Loss = 0.31297940015792847
30-01-2023 09:07:17 INFO Epoch 2: [3345/10940] ---- BYOL Validation Loss = 0.28085389733314514
30-01-2023 09:07:35 INFO Epoch 2: [3356/10940] ---- BYOL Training Loss = 0.2910378575325012
30-01-2023 09:07:53 INFO Epoch 2: [3367/10940] ---- BYOL Training Loss = 0.24506297707557678
30-01-2023 09:08:11 INFO Epoch 2: [3378/10940] ---- BYOL Training Loss = 0.260775625705719
30-01-2023 09:08:30 INFO Epoch 2: [3389/10940] ---- BYOL Training Loss = 0.2557518482208252
30-01-2023 09:09:22 INFO Epoch 2: [3389/10940] ---- BYOL Validation Loss = 0.25334566831588745
30-01-2023 09:09:40 INFO Epoch 2: [3400/10940] ---- BYOL Training Loss = 0.25010520219802856
30-01-2023 09:09:58 INFO Epoch 2: [3411/10940] ---- BYOL Training Loss = 0.24138030409812927
30-01-2023 09:10:16 INFO Epoch 2: [3422/10940] ---- BYOL Training Loss = 0.2530394494533539
30-01-2023 09:10:34 INFO Epoch 2: [3433/10940] ---- BYOL Training Loss = 0.2519788444042206
30-01-2023 09:11:26 INFO Epoch 2: [3433/10940] ---- BYOL Validation Loss = 0.24216918647289276
30-01-2023 09:11:44 INFO Epoch 2: [3444/10940] ---- BYOL Training Loss = 0.253966748714447
30-01-2023 09:12:02 INFO Epoch 2: [3455/10940] ---- BYOL Training Loss = 0.2688289284706116
30-01-2023 09:12:20 INFO Epoch 2: [3466/10940] ---- BYOL Training Loss = 0.26771461963653564
30-01-2023 09:12:39 INFO Epoch 2: [3477/10940] ---- BYOL Training Loss = 0.21774189174175262
30-01-2023 09:13:30 INFO Epoch 2: [3477/10940] ---- BYOL Validation Loss = 0.25652411580085754
30-01-2023 09:13:48 INFO Epoch 2: [3488/10940] ---- BYOL Training Loss = 0.25027841329574585
30-01-2023 09:14:06 INFO Epoch 2: [3499/10940] ---- BYOL Training Loss = 0.2691153287887573
30-01-2023 09:14:24 INFO Epoch 2: [3510/10940] ---- BYOL Training Loss = 0.2786937355995178
30-01-2023 09:14:42 INFO Epoch 2: [3521/10940] ---- BYOL Training Loss = 0.2755979597568512
30-01-2023 09:15:34 INFO Epoch 2: [3521/10940] ---- BYOL Validation Loss = 0.25696322321891785
30-01-2023 09:15:52 INFO Epoch 2: [3532/10940] ---- BYOL Training Loss = 0.29159992933273315
30-01-2023 09:16:10 INFO Epoch 2: [3543/10940] ---- BYOL Training Loss = 0.3068467676639557
30-01-2023 09:16:29 INFO Epoch 2: [3554/10940] ---- BYOL Training Loss = 0.27720198035240173
30-01-2023 09:16:47 INFO Epoch 2: [3565/10940] ---- BYOL Training Loss = 0.28728020191192627
30-01-2023 09:17:39 INFO Epoch 2: [3565/10940] ---- BYOL Validation Loss = 0.26648518443107605
30-01-2023 09:17:56 INFO Epoch 2: [3576/10940] ---- BYOL Training Loss = 0.2719569504261017
30-01-2023 09:18:14 INFO Epoch 2: [3587/10940] ---- BYOL Training Loss = 0.24756495654582977
30-01-2023 09:18:33 INFO Epoch 2: [3598/10940] ---- BYOL Training Loss = 0.25153008103370667
30-01-2023 09:18:51 INFO Epoch 2: [3609/10940] ---- BYOL Training Loss = 0.25279733538627625
30-01-2023 09:19:43 INFO Epoch 2: [3609/10940] ---- BYOL Validation Loss = 0.2481393665075302
30-01-2023 09:20:01 INFO Epoch 2: [3620/10940] ---- BYOL Training Loss = 0.23161597549915314
30-01-2023 09:20:19 INFO Epoch 2: [3631/10940] ---- BYOL Training Loss = 0.26766902208328247
30-01-2023 09:20:37 INFO Epoch 2: [3642/10940] ---- BYOL Training Loss = 0.3223007321357727
30-01-2023 09:20:55 INFO Epoch 2: [3653/10940] ---- BYOL Training Loss = 0.33163920044898987
30-01-2023 09:21:47 INFO Epoch 2: [3653/10940] ---- BYOL Validation Loss = 0.2620117962360382
30-01-2023 09:22:05 INFO Epoch 2: [3664/10940] ---- BYOL Training Loss = 0.28011554479599
30-01-2023 09:22:23 INFO Epoch 2: [3675/10940] ---- BYOL Training Loss = 0.26898136734962463
30-01-2023 09:22:41 INFO Epoch 2: [3686/10940] ---- BYOL Training Loss = 0.27042585611343384
30-01-2023 09:23:00 INFO Epoch 2: [3697/10940] ---- BYOL Training Loss = 0.27528420090675354
30-01-2023 09:23:51 INFO Epoch 2: [3697/10940] ---- BYOL Validation Loss = 0.2569204568862915
30-01-2023 09:24:09 INFO Epoch 2: [3708/10940] ---- BYOL Training Loss = 0.3195428252220154
30-01-2023 09:24:27 INFO Epoch 2: [3719/10940] ---- BYOL Training Loss = 0.2659042477607727
30-01-2023 09:24:45 INFO Epoch 2: [3730/10940] ---- BYOL Training Loss = 0.24656431376934052
30-01-2023 09:25:04 INFO Epoch 2: [3741/10940] ---- BYOL Training Loss = 0.29190048575401306
30-01-2023 09:25:55 INFO Epoch 2: [3741/10940] ---- BYOL Validation Loss = 0.2619730830192566
30-01-2023 09:26:13 INFO Epoch 2: [3752/10940] ---- BYOL Training Loss = 0.32004526257514954
30-01-2023 09:26:31 INFO Epoch 2: [3763/10940] ---- BYOL Training Loss = 0.28837108612060547
30-01-2023 09:26:50 INFO Epoch 2: [3774/10940] ---- BYOL Training Loss = 0.2363142967224121
30-01-2023 09:27:08 INFO Epoch 2: [3785/10940] ---- BYOL Training Loss = 0.24517981708049774
30-01-2023 09:28:00 INFO Epoch 2: [3785/10940] ---- BYOL Validation Loss = 0.2423141896724701
30-01-2023 09:28:18 INFO Epoch 2: [3796/10940] ---- BYOL Training Loss = 0.29210349917411804
30-01-2023 09:28:36 INFO Epoch 2: [3807/10940] ---- BYOL Training Loss = 0.2779284119606018
30-01-2023 09:28:54 INFO Epoch 2: [3818/10940] ---- BYOL Training Loss = 0.2544199228286743
30-01-2023 09:29:12 INFO Epoch 2: [3829/10940] ---- BYOL Training Loss = 0.31512266397476196
30-01-2023 09:30:04 INFO Epoch 2: [3829/10940] ---- BYOL Validation Loss = 0.24846355617046356
30-01-2023 09:30:22 INFO Epoch 2: [3840/10940] ---- BYOL Training Loss = 0.3115842938423157
30-01-2023 09:30:40 INFO Epoch 2: [3851/10940] ---- BYOL Training Loss = 0.263039231300354
30-01-2023 09:30:58 INFO Epoch 2: [3862/10940] ---- BYOL Training Loss = 0.2402460277080536
30-01-2023 09:31:17 INFO Epoch 2: [3873/10940] ---- BYOL Training Loss = 0.2670533061027527
30-01-2023 09:32:08 INFO Epoch 2: [3873/10940] ---- BYOL Validation Loss = 0.252456396818161
30-01-2023 09:32:26 INFO Epoch 2: [3884/10940] ---- BYOL Training Loss = 0.2903238534927368
30-01-2023 09:32:44 INFO Epoch 2: [3895/10940] ---- BYOL Training Loss = 0.28731101751327515
30-01-2023 09:33:03 INFO Epoch 2: [3906/10940] ---- BYOL Training Loss = 0.26477521657943726
30-01-2023 09:33:21 INFO Epoch 2: [3917/10940] ---- BYOL Training Loss = 0.24926109611988068
30-01-2023 09:34:13 INFO Epoch 2: [3917/10940] ---- BYOL Validation Loss = 0.2555212080478668
30-01-2023 09:34:31 INFO Epoch 2: [3928/10940] ---- BYOL Training Loss = 0.26099327206611633
30-01-2023 09:34:49 INFO Epoch 2: [3939/10940] ---- BYOL Training Loss = 0.28399771451950073
30-01-2023 09:35:07 INFO Epoch 2: [3950/10940] ---- BYOL Training Loss = 0.29707175493240356
30-01-2023 09:35:25 INFO Epoch 2: [3961/10940] ---- BYOL Training Loss = 0.3166724443435669
30-01-2023 09:36:17 INFO Epoch 2: [3961/10940] ---- BYOL Validation Loss = 0.2625143826007843
30-01-2023 09:36:35 INFO Epoch 2: [3972/10940] ---- BYOL Training Loss = 0.30660566687583923
30-01-2023 09:36:53 INFO Epoch 2: [3983/10940] ---- BYOL Training Loss = 0.24951693415641785
30-01-2023 09:37:12 INFO Epoch 2: [3994/10940] ---- BYOL Training Loss = 0.23516353964805603
30-01-2023 09:37:30 INFO Epoch 2: [4005/10940] ---- BYOL Training Loss = 0.23693832755088806
30-01-2023 09:38:22 INFO Epoch 2: [4005/10940] ---- BYOL Validation Loss = 0.25531667470932007
30-01-2023 09:38:40 INFO Epoch 2: [4016/10940] ---- BYOL Training Loss = 0.25837334990501404
30-01-2023 09:38:58 INFO Epoch 2: [4027/10940] ---- BYOL Training Loss = 0.24668388068675995
30-01-2023 09:39:16 INFO Epoch 2: [4038/10940] ---- BYOL Training Loss = 0.25357532501220703
30-01-2023 09:39:35 INFO Epoch 2: [4049/10940] ---- BYOL Training Loss = 0.2848373353481293
30-01-2023 09:40:26 INFO Epoch 2: [4049/10940] ---- BYOL Validation Loss = 0.2587919533252716
30-01-2023 09:40:44 INFO Epoch 2: [4060/10940] ---- BYOL Training Loss = 0.26932448148727417
30-01-2023 09:41:03 INFO Epoch 2: [4071/10940] ---- BYOL Training Loss = 0.2438824623823166
30-01-2023 09:41:21 INFO Epoch 2: [4082/10940] ---- BYOL Training Loss = 0.2680288553237915
30-01-2023 09:41:39 INFO Epoch 2: [4093/10940] ---- BYOL Training Loss = 0.2569687068462372
30-01-2023 09:42:31 INFO Epoch 2: [4093/10940] ---- BYOL Validation Loss = 0.2620120942592621
30-01-2023 09:42:49 INFO Epoch 2: [4104/10940] ---- BYOL Training Loss = 0.27054673433303833
30-01-2023 09:43:07 INFO Epoch 2: [4115/10940] ---- BYOL Training Loss = 0.2821953594684601
30-01-2023 09:43:26 INFO Epoch 2: [4126/10940] ---- BYOL Training Loss = 0.2392934262752533
30-01-2023 09:43:44 INFO Epoch 2: [4137/10940] ---- BYOL Training Loss = 0.2285657376050949
30-01-2023 09:44:36 INFO Epoch 2: [4137/10940] ---- BYOL Validation Loss = 0.2483709156513214
30-01-2023 09:44:53 INFO Epoch 2: [4148/10940] ---- BYOL Training Loss = 0.23597022891044617
30-01-2023 09:45:12 INFO Epoch 2: [4159/10940] ---- BYOL Training Loss = 0.26516032218933105
30-01-2023 09:45:30 INFO Epoch 2: [4170/10940] ---- BYOL Training Loss = 0.28697431087493896
30-01-2023 09:45:49 INFO Epoch 2: [4181/10940] ---- BYOL Training Loss = 0.2793702781200409
30-01-2023 09:46:40 INFO Epoch 2: [4181/10940] ---- BYOL Validation Loss = 0.2536509037017822
30-01-2023 09:46:58 INFO Epoch 2: [4192/10940] ---- BYOL Training Loss = 0.29756611585617065
30-01-2023 09:47:17 INFO Epoch 2: [4203/10940] ---- BYOL Training Loss = 0.29359227418899536
30-01-2023 09:47:35 INFO Epoch 2: [4214/10940] ---- BYOL Training Loss = 0.27126026153564453
30-01-2023 09:47:53 INFO Epoch 2: [4225/10940] ---- BYOL Training Loss = 0.2215333729982376
30-01-2023 09:48:45 INFO Epoch 2: [4225/10940] ---- BYOL Validation Loss = 0.25396084785461426
30-01-2023 09:49:03 INFO Epoch 2: [4236/10940] ---- BYOL Training Loss = 0.23455321788787842
30-01-2023 09:49:21 INFO Epoch 2: [4247/10940] ---- BYOL Training Loss = 0.2755855619907379
30-01-2023 09:49:40 INFO Epoch 2: [4258/10940] ---- BYOL Training Loss = 0.2962706685066223
30-01-2023 09:49:58 INFO Epoch 2: [4269/10940] ---- BYOL Training Loss = 0.2885463237762451
30-01-2023 09:50:50 INFO Epoch 2: [4269/10940] ---- BYOL Validation Loss = 0.25881195068359375
30-01-2023 09:51:08 INFO Epoch 2: [4280/10940] ---- BYOL Training Loss = 0.2625303268432617
30-01-2023 09:51:26 INFO Epoch 2: [4291/10940] ---- BYOL Training Loss = 0.3125831186771393
30-01-2023 09:51:45 INFO Epoch 2: [4302/10940] ---- BYOL Training Loss = 0.290686696767807
30-01-2023 09:52:03 INFO Epoch 2: [4313/10940] ---- BYOL Training Loss = 0.2836810350418091
30-01-2023 09:52:55 INFO Epoch 2: [4313/10940] ---- BYOL Validation Loss = 0.24976202845573425
30-01-2023 09:53:13 INFO Epoch 2: [4324/10940] ---- BYOL Training Loss = 0.27182358503341675
30-01-2023 09:53:31 INFO Epoch 2: [4335/10940] ---- BYOL Training Loss = 0.27955928444862366
30-01-2023 09:53:49 INFO Epoch 2: [4346/10940] ---- BYOL Training Loss = 0.26691824197769165
30-01-2023 09:54:08 INFO Epoch 2: [4357/10940] ---- BYOL Training Loss = 0.2785319983959198
30-01-2023 09:54:59 INFO Epoch 2: [4357/10940] ---- BYOL Validation Loss = 0.2607002556324005
30-01-2023 09:55:17 INFO Epoch 2: [4368/10940] ---- BYOL Training Loss = 0.32378286123275757
30-01-2023 09:55:36 INFO Epoch 2: [4379/10940] ---- BYOL Training Loss = 0.2879868149757385
30-01-2023 09:55:54 INFO Epoch 2: [4390/10940] ---- BYOL Training Loss = 0.31548088788986206
30-01-2023 09:56:13 INFO Epoch 2: [4401/10940] ---- BYOL Training Loss = 0.2832285463809967
30-01-2023 09:57:04 INFO Epoch 2: [4401/10940] ---- BYOL Validation Loss = 0.25331059098243713
30-01-2023 09:57:22 INFO Epoch 2: [4412/10940] ---- BYOL Training Loss = 0.27268901467323303
30-01-2023 09:57:41 INFO Epoch 2: [4423/10940] ---- BYOL Training Loss = 0.322044312953949
30-01-2023 09:57:59 INFO Epoch 2: [4434/10940] ---- BYOL Training Loss = 0.35461658239364624
30-01-2023 09:58:17 INFO Epoch 2: [4445/10940] ---- BYOL Training Loss = 0.32845133543014526
30-01-2023 09:59:09 INFO Epoch 2: [4445/10940] ---- BYOL Validation Loss = 0.26828956604003906
30-01-2023 09:59:27 INFO Epoch 2: [4456/10940] ---- BYOL Training Loss = 0.3156989812850952
30-01-2023 09:59:45 INFO Epoch 2: [4467/10940] ---- BYOL Training Loss = 0.3517511785030365
30-01-2023 10:00:04 INFO Epoch 2: [4478/10940] ---- BYOL Training Loss = 0.28713488578796387
30-01-2023 10:00:22 INFO Epoch 2: [4489/10940] ---- BYOL Training Loss = 0.2523910701274872
30-01-2023 10:01:14 INFO Epoch 2: [4489/10940] ---- BYOL Validation Loss = 0.25706395506858826
30-01-2023 10:01:32 INFO Epoch 2: [4500/10940] ---- BYOL Training Loss = 0.2850326597690582
30-01-2023 10:01:50 INFO Epoch 2: [4511/10940] ---- BYOL Training Loss = 0.31720203161239624
30-01-2023 10:02:08 INFO Epoch 2: [4522/10940] ---- BYOL Training Loss = 0.29437536001205444
30-01-2023 10:02:27 INFO Epoch 2: [4533/10940] ---- BYOL Training Loss = 0.25716274976730347
30-01-2023 10:03:18 INFO Epoch 2: [4533/10940] ---- BYOL Validation Loss = 0.25922703742980957
30-01-2023 10:03:36 INFO Epoch 2: [4544/10940] ---- BYOL Training Loss = 0.28007349371910095
30-01-2023 10:03:54 INFO Epoch 2: [4555/10940] ---- BYOL Training Loss = 0.293643057346344
30-01-2023 10:04:13 INFO Epoch 2: [4566/10940] ---- BYOL Training Loss = 0.33147966861724854
30-01-2023 10:04:31 INFO Epoch 2: [4577/10940] ---- BYOL Training Loss = 0.3545958399772644
30-01-2023 10:05:23 INFO Epoch 2: [4577/10940] ---- BYOL Validation Loss = 0.250589519739151
30-01-2023 10:05:41 INFO Epoch 2: [4588/10940] ---- BYOL Training Loss = 0.2847815752029419
30-01-2023 10:05:59 INFO Epoch 2: [4599/10940] ---- BYOL Training Loss = 0.28332287073135376
30-01-2023 10:06:17 INFO Epoch 2: [4610/10940] ---- BYOL Training Loss = 0.2750837206840515
30-01-2023 10:06:36 INFO Epoch 2: [4621/10940] ---- BYOL Training Loss = 0.28624457120895386
30-01-2023 10:07:27 INFO Epoch 2: [4621/10940] ---- BYOL Validation Loss = 0.2565755546092987
30-01-2023 10:07:46 INFO Epoch 2: [4632/10940] ---- BYOL Training Loss = 0.29598578810691833
30-01-2023 10:08:04 INFO Epoch 2: [4643/10940] ---- BYOL Training Loss = 0.2702363133430481
30-01-2023 10:08:22 INFO Epoch 2: [4654/10940] ---- BYOL Training Loss = 0.28638407588005066
30-01-2023 10:08:40 INFO Epoch 2: [4665/10940] ---- BYOL Training Loss = 0.3034726083278656
30-01-2023 10:09:32 INFO Epoch 2: [4665/10940] ---- BYOL Validation Loss = 0.2648428678512573
30-01-2023 10:09:50 INFO Epoch 2: [4676/10940] ---- BYOL Training Loss = 0.25761210918426514
30-01-2023 10:10:09 INFO Epoch 2: [4687/10940] ---- BYOL Training Loss = 0.24513304233551025
30-01-2023 10:10:27 INFO Epoch 2: [4698/10940] ---- BYOL Training Loss = 0.27416935563087463
30-01-2023 10:10:45 INFO Epoch 2: [4709/10940] ---- BYOL Training Loss = 0.295265257358551
30-01-2023 10:11:37 INFO Epoch 2: [4709/10940] ---- BYOL Validation Loss = 0.26377424597740173
30-01-2023 10:11:55 INFO Epoch 2: [4720/10940] ---- BYOL Training Loss = 0.3074377179145813
30-01-2023 10:12:13 INFO Epoch 2: [4731/10940] ---- BYOL Training Loss = 0.27689114212989807
30-01-2023 10:12:32 INFO Epoch 2: [4742/10940] ---- BYOL Training Loss = 0.24860581755638123
30-01-2023 10:12:50 INFO Epoch 2: [4753/10940] ---- BYOL Training Loss = 0.26306506991386414
30-01-2023 10:13:42 INFO Epoch 2: [4753/10940] ---- BYOL Validation Loss = 0.25785693526268005
30-01-2023 10:14:00 INFO Epoch 2: [4764/10940] ---- BYOL Training Loss = 0.27354323863983154
30-01-2023 10:14:18 INFO Epoch 2: [4775/10940] ---- BYOL Training Loss = 0.29703623056411743
30-01-2023 10:14:36 INFO Epoch 2: [4786/10940] ---- BYOL Training Loss = 0.3075698912143707
30-01-2023 10:14:55 INFO Epoch 2: [4797/10940] ---- BYOL Training Loss = 0.3501308560371399
30-01-2023 10:15:47 INFO Epoch 2: [4797/10940] ---- BYOL Validation Loss = 0.2624622881412506
30-01-2023 10:16:05 INFO Epoch 2: [4808/10940] ---- BYOL Training Loss = 0.33708980679512024
30-01-2023 10:16:23 INFO Epoch 2: [4819/10940] ---- BYOL Training Loss = 0.2673717141151428
30-01-2023 10:16:41 INFO Epoch 2: [4830/10940] ---- BYOL Training Loss = 0.2726970911026001
30-01-2023 10:17:00 INFO Epoch 2: [4841/10940] ---- BYOL Training Loss = 0.25071853399276733
30-01-2023 10:17:51 INFO Epoch 2: [4841/10940] ---- BYOL Validation Loss = 0.26295796036720276
30-01-2023 10:18:10 INFO Epoch 2: [4852/10940] ---- BYOL Training Loss = 0.2632485032081604
30-01-2023 10:18:28 INFO Epoch 2: [4863/10940] ---- BYOL Training Loss = 0.2883221507072449
30-01-2023 10:18:46 INFO Epoch 2: [4874/10940] ---- BYOL Training Loss = 0.2754978537559509
30-01-2023 10:19:05 INFO Epoch 2: [4885/10940] ---- BYOL Training Loss = 0.2878836989402771
30-01-2023 10:19:57 INFO Epoch 2: [4885/10940] ---- BYOL Validation Loss = 0.2690538465976715
30-01-2023 10:20:15 INFO Epoch 2: [4896/10940] ---- BYOL Training Loss = 0.29155150055885315
30-01-2023 10:20:33 INFO Epoch 2: [4907/10940] ---- BYOL Training Loss = 0.26029327511787415
30-01-2023 10:20:52 INFO Epoch 2: [4918/10940] ---- BYOL Training Loss = 0.2747878432273865
30-01-2023 10:21:10 INFO Epoch 2: [4929/10940] ---- BYOL Training Loss = 0.28335103392601013
30-01-2023 10:22:02 INFO Epoch 2: [4929/10940] ---- BYOL Validation Loss = 0.25757667422294617
30-01-2023 10:22:20 INFO Epoch 2: [4940/10940] ---- BYOL Training Loss = 0.31883901357650757
30-01-2023 10:22:39 INFO Epoch 2: [4951/10940] ---- BYOL Training Loss = 0.3310336470603943
30-01-2023 10:22:57 INFO Epoch 2: [4962/10940] ---- BYOL Training Loss = 0.3168272376060486
30-01-2023 10:23:15 INFO Epoch 2: [4973/10940] ---- BYOL Training Loss = 0.29422277212142944
30-01-2023 10:24:07 INFO Epoch 2: [4973/10940] ---- BYOL Validation Loss = 0.2660554349422455
30-01-2023 10:24:25 INFO Epoch 2: [4984/10940] ---- BYOL Training Loss = 0.29422205686569214
30-01-2023 10:24:43 INFO Epoch 2: [4995/10940] ---- BYOL Training Loss = 0.2807023525238037
30-01-2023 10:25:02 INFO Epoch 2: [5006/10940] ---- BYOL Training Loss = 0.24524232745170593
30-01-2023 10:25:20 INFO Epoch 2: [5017/10940] ---- BYOL Training Loss = 0.2520321309566498
30-01-2023 10:26:12 INFO Epoch 2: [5017/10940] ---- BYOL Validation Loss = 0.26417165994644165
30-01-2023 10:26:30 INFO Epoch 2: [5028/10940] ---- BYOL Training Loss = 0.2560120224952698
30-01-2023 10:26:48 INFO Epoch 2: [5039/10940] ---- BYOL Training Loss = 0.2687012255191803
30-01-2023 10:27:07 INFO Epoch 2: [5050/10940] ---- BYOL Training Loss = 0.2608601450920105
30-01-2023 10:27:25 INFO Epoch 2: [5061/10940] ---- BYOL Training Loss = 0.28093940019607544
30-01-2023 10:28:17 INFO Epoch 2: [5061/10940] ---- BYOL Validation Loss = 0.2482849508523941
30-01-2023 10:28:35 INFO Epoch 2: [5072/10940] ---- BYOL Training Loss = 0.2969704568386078
30-01-2023 10:28:53 INFO Epoch 2: [5083/10940] ---- BYOL Training Loss = 0.3001089096069336
30-01-2023 10:29:11 INFO Epoch 2: [5094/10940] ---- BYOL Training Loss = 0.2809322476387024
30-01-2023 10:29:30 INFO Epoch 2: [5105/10940] ---- BYOL Training Loss = 0.3175387382507324
30-01-2023 10:30:22 INFO Epoch 2: [5105/10940] ---- BYOL Validation Loss = 0.2455941140651703
30-01-2023 10:30:40 INFO Epoch 2: [5116/10940] ---- BYOL Training Loss = 0.27287212014198303
30-01-2023 10:30:58 INFO Epoch 2: [5127/10940] ---- BYOL Training Loss = 0.26466283202171326
30-01-2023 10:31:16 INFO Epoch 2: [5138/10940] ---- BYOL Training Loss = 0.2661482095718384
30-01-2023 10:31:35 INFO Epoch 2: [5149/10940] ---- BYOL Training Loss = 0.28125953674316406
30-01-2023 10:32:26 INFO Epoch 2: [5149/10940] ---- BYOL Validation Loss = 0.25444456934928894
30-01-2023 10:32:45 INFO Epoch 2: [5160/10940] ---- BYOL Training Loss = 0.3058386445045471
30-01-2023 10:33:03 INFO Epoch 2: [5171/10940] ---- BYOL Training Loss = 0.28515052795410156
30-01-2023 10:33:21 INFO Epoch 2: [5182/10940] ---- BYOL Training Loss = 0.2927792966365814
30-01-2023 10:33:39 INFO Epoch 2: [5193/10940] ---- BYOL Training Loss = 0.33861109614372253
30-01-2023 10:34:31 INFO Epoch 2: [5193/10940] ---- BYOL Validation Loss = 0.26874345541000366
30-01-2023 10:34:50 INFO Epoch 2: [5204/10940] ---- BYOL Training Loss = 0.29216331243515015
30-01-2023 10:35:08 INFO Epoch 2: [5215/10940] ---- BYOL Training Loss = 0.2574276924133301
30-01-2023 10:35:26 INFO Epoch 2: [5226/10940] ---- BYOL Training Loss = 0.24330992996692657
30-01-2023 10:35:44 INFO Epoch 2: [5237/10940] ---- BYOL Training Loss = 0.30208197236061096
30-01-2023 10:36:36 INFO Epoch 2: [5237/10940] ---- BYOL Validation Loss = 0.24479056894779205
30-01-2023 10:36:54 INFO Epoch 2: [5248/10940] ---- BYOL Training Loss = 0.31522291898727417
30-01-2023 10:37:13 INFO Epoch 2: [5259/10940] ---- BYOL Training Loss = 0.27355632185935974
30-01-2023 10:37:31 INFO Epoch 2: [5270/10940] ---- BYOL Training Loss = 0.2902253270149231
30-01-2023 10:37:49 INFO Epoch 2: [5281/10940] ---- BYOL Training Loss = 0.2865837514400482
30-01-2023 10:38:41 INFO Epoch 2: [5281/10940] ---- BYOL Validation Loss = 0.24650637805461884
30-01-2023 10:38:59 INFO Epoch 2: [5292/10940] ---- BYOL Training Loss = 0.2741515040397644
30-01-2023 10:39:18 INFO Epoch 2: [5303/10940] ---- BYOL Training Loss = 0.282848060131073
30-01-2023 10:39:36 INFO Epoch 2: [5314/10940] ---- BYOL Training Loss = 0.3158782124519348
30-01-2023 10:39:54 INFO Epoch 2: [5325/10940] ---- BYOL Training Loss = 0.3221058249473572
30-01-2023 10:40:46 INFO Epoch 2: [5325/10940] ---- BYOL Validation Loss = 0.2580956816673279
30-01-2023 10:41:04 INFO Epoch 2: [5336/10940] ---- BYOL Training Loss = 0.28451672196388245
30-01-2023 10:41:22 INFO Epoch 2: [5347/10940] ---- BYOL Training Loss = 0.2577071785926819
30-01-2023 10:41:41 INFO Epoch 2: [5358/10940] ---- BYOL Training Loss = 0.27755993604660034
30-01-2023 10:41:59 INFO Epoch 2: [5369/10940] ---- BYOL Training Loss = 0.30494970083236694
30-01-2023 10:42:51 INFO Epoch 2: [5369/10940] ---- BYOL Validation Loss = 0.24956248700618744
30-01-2023 10:43:09 INFO Epoch 2: [5380/10940] ---- BYOL Training Loss = 0.2783333361148834
30-01-2023 10:43:27 INFO Epoch 2: [5391/10940] ---- BYOL Training Loss = 0.25027939677238464
30-01-2023 10:43:46 INFO Epoch 2: [5402/10940] ---- BYOL Training Loss = 0.2905427813529968
30-01-2023 10:44:04 INFO Epoch 2: [5413/10940] ---- BYOL Training Loss = 0.32847821712493896
30-01-2023 10:44:56 INFO Epoch 2: [5413/10940] ---- BYOL Validation Loss = 0.24711954593658447
30-01-2023 10:45:14 INFO Epoch 2: [5424/10940] ---- BYOL Training Loss = 0.3443275988101959
30-01-2023 10:45:32 INFO Epoch 2: [5435/10940] ---- BYOL Training Loss = 0.3364766240119934
30-01-2023 10:45:51 INFO Epoch 2: [5446/10940] ---- BYOL Training Loss = 0.27980801463127136
30-01-2023 10:46:09 INFO Epoch 2: [5457/10940] ---- BYOL Training Loss = 0.2696954607963562
30-01-2023 10:47:01 INFO Epoch 2: [5457/10940] ---- BYOL Validation Loss = 0.2535509169101715
30-01-2023 10:47:19 INFO Epoch 2: [5468/10940] ---- BYOL Training Loss = 0.26746127009391785
30-01-2023 10:47:37 INFO Epoch 2: [5479/10940] ---- BYOL Training Loss = 0.2593889832496643
30-01-2023 10:47:56 INFO Epoch 2: [5490/10940] ---- BYOL Training Loss = 0.25507569313049316
30-01-2023 10:48:14 INFO Epoch 2: [5501/10940] ---- BYOL Training Loss = 0.258301317691803
30-01-2023 10:49:06 INFO Epoch 2: [5501/10940] ---- BYOL Validation Loss = 0.24773728847503662
30-01-2023 10:49:24 INFO Epoch 2: [5512/10940] ---- BYOL Training Loss = 0.26347827911376953
30-01-2023 10:49:42 INFO Epoch 2: [5523/10940] ---- BYOL Training Loss = 0.24655704200267792
30-01-2023 10:50:01 INFO Epoch 2: [5534/10940] ---- BYOL Training Loss = 0.26508060097694397
30-01-2023 10:50:19 INFO Epoch 2: [5545/10940] ---- BYOL Training Loss = 0.2874448597431183
30-01-2023 10:51:11 INFO Epoch 2: [5545/10940] ---- BYOL Validation Loss = 0.2536429762840271
30-01-2023 10:51:29 INFO Epoch 2: [5556/10940] ---- BYOL Training Loss = 0.2538663148880005
30-01-2023 10:51:48 INFO Epoch 2: [5567/10940] ---- BYOL Training Loss = 0.26809850335121155
30-01-2023 10:52:06 INFO Epoch 2: [5578/10940] ---- BYOL Training Loss = 0.258772611618042
30-01-2023 10:52:24 INFO Epoch 2: [5589/10940] ---- BYOL Training Loss = 0.24473151564598083
30-01-2023 10:53:16 INFO Epoch 2: [5589/10940] ---- BYOL Validation Loss = 0.250998318195343
30-01-2023 10:53:34 INFO Epoch 2: [5600/10940] ---- BYOL Training Loss = 0.3020300269126892
30-01-2023 10:53:53 INFO Epoch 2: [5611/10940] ---- BYOL Training Loss = 0.3185252249240875
30-01-2023 10:54:11 INFO Epoch 2: [5622/10940] ---- BYOL Training Loss = 0.26915961503982544
30-01-2023 10:54:30 INFO Epoch 2: [5633/10940] ---- BYOL Training Loss = 0.26894882321357727
30-01-2023 10:55:21 INFO Epoch 2: [5633/10940] ---- BYOL Validation Loss = 0.2706642150878906
30-01-2023 10:55:39 INFO Epoch 2: [5644/10940] ---- BYOL Training Loss = 0.258596271276474
30-01-2023 10:55:57 INFO Epoch 2: [5655/10940] ---- BYOL Training Loss = 0.3217991292476654
30-01-2023 10:56:16 INFO Epoch 2: [5666/10940] ---- BYOL Training Loss = 0.32076960802078247
30-01-2023 10:56:35 INFO Epoch 2: [5677/10940] ---- BYOL Training Loss = 0.2364671230316162
30-01-2023 10:57:26 INFO Epoch 2: [5677/10940] ---- BYOL Validation Loss = 0.266036719083786
30-01-2023 10:57:44 INFO Epoch 2: [5688/10940] ---- BYOL Training Loss = 0.2514675557613373
30-01-2023 10:58:03 INFO Epoch 2: [5699/10940] ---- BYOL Training Loss = 0.28545868396759033
30-01-2023 10:58:21 INFO Epoch 2: [5710/10940] ---- BYOL Training Loss = 0.2783345878124237
30-01-2023 10:58:40 INFO Epoch 2: [5721/10940] ---- BYOL Training Loss = 0.2844429314136505
30-01-2023 10:59:32 INFO Epoch 2: [5721/10940] ---- BYOL Validation Loss = 0.2752215266227722
30-01-2023 10:59:49 INFO Epoch 2: [5732/10940] ---- BYOL Training Loss = 0.2974216341972351
30-01-2023 11:00:08 INFO Epoch 2: [5743/10940] ---- BYOL Training Loss = 0.2976914346218109
30-01-2023 11:00:26 INFO Epoch 2: [5754/10940] ---- BYOL Training Loss = 0.28374332189559937
30-01-2023 11:00:45 INFO Epoch 2: [5765/10940] ---- BYOL Training Loss = 0.2642652690410614
30-01-2023 11:01:37 INFO Epoch 2: [5765/10940] ---- BYOL Validation Loss = 0.2541212737560272
30-01-2023 11:01:55 INFO Epoch 2: [5776/10940] ---- BYOL Training Loss = 0.24430644512176514
30-01-2023 11:02:13 INFO Epoch 2: [5787/10940] ---- BYOL Training Loss = 0.2589040994644165
30-01-2023 11:02:31 INFO Epoch 2: [5798/10940] ---- BYOL Training Loss = 0.28611260652542114
30-01-2023 11:02:50 INFO Epoch 2: [5809/10940] ---- BYOL Training Loss = 0.2987045645713806
30-01-2023 11:03:42 INFO Epoch 2: [5809/10940] ---- BYOL Validation Loss = 0.3362830579280853
30-01-2023 11:04:00 INFO Epoch 2: [5820/10940] ---- BYOL Training Loss = 0.2695457935333252
30-01-2023 11:04:18 INFO Epoch 2: [5831/10940] ---- BYOL Training Loss = 0.26074451208114624
30-01-2023 11:04:37 INFO Epoch 2: [5842/10940] ---- BYOL Training Loss = 0.2624424695968628
30-01-2023 11:04:55 INFO Epoch 2: [5853/10940] ---- BYOL Training Loss = 0.28475379943847656
30-01-2023 11:05:47 INFO Epoch 2: [5853/10940] ---- BYOL Validation Loss = 0.24086971580982208
30-01-2023 11:06:05 INFO Epoch 2: [5864/10940] ---- BYOL Training Loss = 0.2743229269981384
30-01-2023 11:06:23 INFO Epoch 2: [5875/10940] ---- BYOL Training Loss = 0.27936482429504395
30-01-2023 11:06:42 INFO Epoch 2: [5886/10940] ---- BYOL Training Loss = 0.3191985785961151
30-01-2023 11:07:00 INFO Epoch 2: [5897/10940] ---- BYOL Training Loss = 0.2896275818347931
30-01-2023 11:07:52 INFO Epoch 2: [5897/10940] ---- BYOL Validation Loss = 0.24330566823482513
30-01-2023 11:08:10 INFO Epoch 2: [5908/10940] ---- BYOL Training Loss = 0.27880844473838806
30-01-2023 11:08:29 INFO Epoch 2: [5919/10940] ---- BYOL Training Loss = 0.3347485363483429
30-01-2023 11:08:47 INFO Epoch 2: [5930/10940] ---- BYOL Training Loss = 0.34067848324775696
30-01-2023 11:09:06 INFO Epoch 2: [5941/10940] ---- BYOL Training Loss = 0.2803947329521179
30-01-2023 11:09:57 INFO Epoch 2: [5941/10940] ---- BYOL Validation Loss = 0.24978110194206238
30-01-2023 11:10:15 INFO Epoch 2: [5952/10940] ---- BYOL Training Loss = 0.2567054033279419
30-01-2023 11:10:34 INFO Epoch 2: [5963/10940] ---- BYOL Training Loss = 0.2907852530479431
30-01-2023 11:10:52 INFO Epoch 2: [5974/10940] ---- BYOL Training Loss = 0.3030291795730591
30-01-2023 11:11:11 INFO Epoch 2: [5985/10940] ---- BYOL Training Loss = 0.3178170919418335
30-01-2023 11:12:03 INFO Epoch 2: [5985/10940] ---- BYOL Validation Loss = 0.24367468059062958
30-01-2023 11:12:21 INFO Epoch 2: [5996/10940] ---- BYOL Training Loss = 0.3129100501537323
30-01-2023 11:12:39 INFO Epoch 2: [6007/10940] ---- BYOL Training Loss = 0.30451878905296326
30-01-2023 11:12:57 INFO Epoch 2: [6018/10940] ---- BYOL Training Loss = 0.2628462314605713
30-01-2023 11:13:16 INFO Epoch 2: [6029/10940] ---- BYOL Training Loss = 0.25864559412002563
30-01-2023 11:14:08 INFO Epoch 2: [6029/10940] ---- BYOL Validation Loss = 0.25735583901405334
30-01-2023 11:14:26 INFO Epoch 2: [6040/10940] ---- BYOL Training Loss = 0.26833575963974
30-01-2023 11:14:44 INFO Epoch 2: [6051/10940] ---- BYOL Training Loss = 0.26041948795318604
30-01-2023 11:15:03 INFO Epoch 2: [6062/10940] ---- BYOL Training Loss = 0.3002984821796417
30-01-2023 11:15:21 INFO Epoch 2: [6073/10940] ---- BYOL Training Loss = 0.28701645135879517
30-01-2023 11:16:13 INFO Epoch 2: [6073/10940] ---- BYOL Validation Loss = 0.23631535470485687
30-01-2023 11:16:31 INFO Epoch 2: [6084/10940] ---- BYOL Training Loss = 0.2618306577205658
30-01-2023 11:16:50 INFO Epoch 2: [6095/10940] ---- BYOL Training Loss = 0.2644088864326477
30-01-2023 11:17:08 INFO Epoch 2: [6106/10940] ---- BYOL Training Loss = 0.2854113280773163
30-01-2023 11:17:27 INFO Epoch 2: [6117/10940] ---- BYOL Training Loss = 0.30078864097595215
30-01-2023 11:18:18 INFO Epoch 2: [6117/10940] ---- BYOL Validation Loss = 0.24730409681797028
30-01-2023 11:18:36 INFO Epoch 2: [6128/10940] ---- BYOL Training Loss = 0.3307376205921173
30-01-2023 11:18:55 INFO Epoch 2: [6139/10940] ---- BYOL Training Loss = 0.34802430868148804
30-01-2023 11:19:14 INFO Epoch 2: [6150/10940] ---- BYOL Training Loss = 0.3132857382297516
30-01-2023 11:19:32 INFO Epoch 2: [6161/10940] ---- BYOL Training Loss = 0.3539944887161255
30-01-2023 11:20:24 INFO Epoch 2: [6161/10940] ---- BYOL Validation Loss = 0.24890075623989105
30-01-2023 11:20:42 INFO Epoch 2: [6172/10940] ---- BYOL Training Loss = 0.30605632066726685
30-01-2023 11:21:00 INFO Epoch 2: [6183/10940] ---- BYOL Training Loss = 0.2560606896877289
30-01-2023 11:21:19 INFO Epoch 2: [6194/10940] ---- BYOL Training Loss = 0.2347053587436676
30-01-2023 11:21:37 INFO Epoch 2: [6205/10940] ---- BYOL Training Loss = 0.23739905655384064
30-01-2023 11:22:29 INFO Epoch 2: [6205/10940] ---- BYOL Validation Loss = 0.2423027902841568
30-01-2023 11:22:47 INFO Epoch 2: [6216/10940] ---- BYOL Training Loss = 0.23709292709827423
30-01-2023 11:23:06 INFO Epoch 2: [6227/10940] ---- BYOL Training Loss = 0.28706875443458557
30-01-2023 11:23:24 INFO Epoch 2: [6238/10940] ---- BYOL Training Loss = 0.30216115713119507
30-01-2023 11:23:43 INFO Epoch 2: [6249/10940] ---- BYOL Training Loss = 0.2862563729286194
30-01-2023 11:24:35 INFO Epoch 2: [6249/10940] ---- BYOL Validation Loss = 0.24793744087219238
30-01-2023 11:24:53 INFO Epoch 2: [6260/10940] ---- BYOL Training Loss = 0.3120841681957245
30-01-2023 11:25:11 INFO Epoch 2: [6271/10940] ---- BYOL Training Loss = 0.25042980909347534
30-01-2023 11:25:30 INFO Epoch 2: [6282/10940] ---- BYOL Training Loss = 0.2542870044708252
30-01-2023 11:25:48 INFO Epoch 2: [6293/10940] ---- BYOL Training Loss = 0.2754378914833069
30-01-2023 11:26:40 INFO Epoch 2: [6293/10940] ---- BYOL Validation Loss = 0.23992109298706055
30-01-2023 11:26:58 INFO Epoch 2: [6304/10940] ---- BYOL Training Loss = 0.2798565626144409
30-01-2023 11:27:17 INFO Epoch 2: [6315/10940] ---- BYOL Training Loss = 0.32686540484428406
30-01-2023 11:27:35 INFO Epoch 2: [6326/10940] ---- BYOL Training Loss = 0.312247097492218
30-01-2023 11:27:54 INFO Epoch 2: [6337/10940] ---- BYOL Training Loss = 0.2906683087348938
30-01-2023 11:28:45 INFO Epoch 2: [6337/10940] ---- BYOL Validation Loss = 0.22445178031921387
30-01-2023 11:29:03 INFO Epoch 2: [6348/10940] ---- BYOL Training Loss = 0.3118588924407959
30-01-2023 11:29:22 INFO Epoch 2: [6359/10940] ---- BYOL Training Loss = 0.28288328647613525
30-01-2023 11:29:41 INFO Epoch 2: [6370/10940] ---- BYOL Training Loss = 0.2523093521595001
30-01-2023 11:29:59 INFO Epoch 2: [6381/10940] ---- BYOL Training Loss = 0.2664946913719177
30-01-2023 11:30:51 INFO Epoch 2: [6381/10940] ---- BYOL Validation Loss = 0.24544112384319305
30-01-2023 11:31:09 INFO Epoch 2: [6392/10940] ---- BYOL Training Loss = 0.26150304079055786
30-01-2023 11:31:28 INFO Epoch 2: [6403/10940] ---- BYOL Training Loss = 0.25917190313339233
30-01-2023 11:31:46 INFO Epoch 2: [6414/10940] ---- BYOL Training Loss = 0.23980705440044403
30-01-2023 11:32:04 INFO Epoch 2: [6425/10940] ---- BYOL Training Loss = 0.29140904545783997
30-01-2023 11:32:56 INFO Epoch 2: [6425/10940] ---- BYOL Validation Loss = 0.2515932023525238
30-01-2023 11:33:15 INFO Epoch 2: [6436/10940] ---- BYOL Training Loss = 0.29402655363082886
30-01-2023 11:33:33 INFO Epoch 2: [6447/10940] ---- BYOL Training Loss = 0.2590082287788391
30-01-2023 11:33:51 INFO Epoch 2: [6458/10940] ---- BYOL Training Loss = 0.27201905846595764
30-01-2023 11:34:10 INFO Epoch 2: [6469/10940] ---- BYOL Training Loss = 0.29967963695526123
30-01-2023 11:35:02 INFO Epoch 2: [6469/10940] ---- BYOL Validation Loss = 0.248736172914505
30-01-2023 11:35:20 INFO Epoch 2: [6480/10940] ---- BYOL Training Loss = 0.32962867617607117
30-01-2023 11:35:38 INFO Epoch 2: [6491/10940] ---- BYOL Training Loss = 0.3201797604560852
30-01-2023 11:35:57 INFO Epoch 2: [6502/10940] ---- BYOL Training Loss = 0.31649914383888245
30-01-2023 11:36:16 INFO Epoch 2: [6513/10940] ---- BYOL Training Loss = 0.3247033953666687
30-01-2023 11:37:08 INFO Epoch 2: [6513/10940] ---- BYOL Validation Loss = 0.2666488587856293
30-01-2023 11:37:26 INFO Epoch 2: [6524/10940] ---- BYOL Training Loss = 0.31238430738449097
30-01-2023 11:37:44 INFO Epoch 2: [6535/10940] ---- BYOL Training Loss = 0.3213142454624176
30-01-2023 11:38:03 INFO Epoch 2: [6546/10940] ---- BYOL Training Loss = 0.3006278872489929
30-01-2023 11:38:21 INFO Epoch 2: [6557/10940] ---- BYOL Training Loss = 0.2538546025753021
30-01-2023 11:39:13 INFO Epoch 2: [6557/10940] ---- BYOL Validation Loss = 0.2577717900276184
30-01-2023 11:39:31 INFO Epoch 2: [6568/10940] ---- BYOL Training Loss = 0.29217976331710815
30-01-2023 11:39:50 INFO Epoch 2: [6579/10940] ---- BYOL Training Loss = 0.30842822790145874
30-01-2023 11:40:08 INFO Epoch 2: [6590/10940] ---- BYOL Training Loss = 0.2997846007347107
30-01-2023 11:40:27 INFO Epoch 2: [6601/10940] ---- BYOL Training Loss = 0.29245901107788086
30-01-2023 11:41:19 INFO Epoch 2: [6601/10940] ---- BYOL Validation Loss = 0.24321159720420837
30-01-2023 11:41:37 INFO Epoch 2: [6612/10940] ---- BYOL Training Loss = 0.2989925742149353
30-01-2023 11:41:55 INFO Epoch 2: [6623/10940] ---- BYOL Training Loss = 0.3233228921890259
30-01-2023 11:42:14 INFO Epoch 2: [6634/10940] ---- BYOL Training Loss = 0.32237735390663147
30-01-2023 11:42:32 INFO Epoch 2: [6645/10940] ---- BYOL Training Loss = 0.2806737422943115
30-01-2023 11:43:24 INFO Epoch 2: [6645/10940] ---- BYOL Validation Loss = 0.24296888709068298
30-01-2023 11:43:43 INFO Epoch 2: [6656/10940] ---- BYOL Training Loss = 0.2778168022632599
30-01-2023 11:44:01 INFO Epoch 2: [6667/10940] ---- BYOL Training Loss = 0.2657288610935211
30-01-2023 11:44:19 INFO Epoch 2: [6678/10940] ---- BYOL Training Loss = 0.30746519565582275
30-01-2023 11:44:38 INFO Epoch 2: [6689/10940] ---- BYOL Training Loss = 0.3415232002735138
30-01-2023 11:45:30 INFO Epoch 2: [6689/10940] ---- BYOL Validation Loss = 0.27198526263237
30-01-2023 11:45:48 INFO Epoch 2: [6700/10940] ---- BYOL Training Loss = 0.30620190501213074
30-01-2023 11:46:07 INFO Epoch 2: [6711/10940] ---- BYOL Training Loss = 0.28228095173835754
30-01-2023 11:46:25 INFO Epoch 2: [6722/10940] ---- BYOL Training Loss = 0.2902929186820984
30-01-2023 11:46:44 INFO Epoch 2: [6733/10940] ---- BYOL Training Loss = 0.27005869150161743
30-01-2023 11:47:36 INFO Epoch 2: [6733/10940] ---- BYOL Validation Loss = 0.25257816910743713
30-01-2023 11:47:54 INFO Epoch 2: [6744/10940] ---- BYOL Training Loss = 0.27815455198287964
30-01-2023 11:48:12 INFO Epoch 2: [6755/10940] ---- BYOL Training Loss = 0.2417246401309967
30-01-2023 11:48:30 INFO Epoch 2: [6766/10940] ---- BYOL Training Loss = 0.22893674671649933
30-01-2023 11:48:49 INFO Epoch 2: [6777/10940] ---- BYOL Training Loss = 0.2674137055873871
30-01-2023 11:49:41 INFO Epoch 2: [6777/10940] ---- BYOL Validation Loss = 0.2539516091346741
30-01-2023 11:49:59 INFO Epoch 2: [6788/10940] ---- BYOL Training Loss = 0.23988065123558044
30-01-2023 11:50:18 INFO Epoch 2: [6799/10940] ---- BYOL Training Loss = 0.27849507331848145
30-01-2023 11:50:36 INFO Epoch 2: [6810/10940] ---- BYOL Training Loss = 0.3249935209751129
30-01-2023 11:50:55 INFO Epoch 2: [6821/10940] ---- BYOL Training Loss = 0.31481242179870605
30-01-2023 11:51:47 INFO Epoch 2: [6821/10940] ---- BYOL Validation Loss = 0.25301751494407654
30-01-2023 11:52:05 INFO Epoch 2: [6832/10940] ---- BYOL Training Loss = 0.30120280385017395
30-01-2023 11:52:23 INFO Epoch 2: [6843/10940] ---- BYOL Training Loss = 0.3147277235984802
30-01-2023 11:52:42 INFO Epoch 2: [6854/10940] ---- BYOL Training Loss = 0.29583945870399475
30-01-2023 11:53:00 INFO Epoch 2: [6865/10940] ---- BYOL Training Loss = 0.2592771053314209
30-01-2023 11:53:52 INFO Epoch 2: [6865/10940] ---- BYOL Validation Loss = 0.2537132799625397
30-01-2023 11:54:10 INFO Epoch 2: [6876/10940] ---- BYOL Training Loss = 0.2751634120941162
30-01-2023 11:54:29 INFO Epoch 2: [6887/10940] ---- BYOL Training Loss = 0.2812526822090149
30-01-2023 11:54:48 INFO Epoch 2: [6898/10940] ---- BYOL Training Loss = 0.26532259583473206
30-01-2023 11:55:06 INFO Epoch 2: [6909/10940] ---- BYOL Training Loss = 0.257192999124527
30-01-2023 11:55:58 INFO Epoch 2: [6909/10940] ---- BYOL Validation Loss = 0.24396993219852448
30-01-2023 11:56:16 INFO Epoch 2: [6920/10940] ---- BYOL Training Loss = 0.2762860357761383
30-01-2023 11:56:35 INFO Epoch 2: [6931/10940] ---- BYOL Training Loss = 0.25602227449417114
30-01-2023 11:56:53 INFO Epoch 2: [6942/10940] ---- BYOL Training Loss = 0.2694454491138458
30-01-2023 11:57:12 INFO Epoch 2: [6953/10940] ---- BYOL Training Loss = 0.29091498255729675
30-01-2023 11:58:04 INFO Epoch 2: [6953/10940] ---- BYOL Validation Loss = 0.238338440656662
30-01-2023 11:58:22 INFO Epoch 2: [6964/10940] ---- BYOL Training Loss = 0.2965568006038666
30-01-2023 11:58:40 INFO Epoch 2: [6975/10940] ---- BYOL Training Loss = 0.29792696237564087
30-01-2023 11:58:59 INFO Epoch 2: [6986/10940] ---- BYOL Training Loss = 0.3050810396671295
30-01-2023 11:59:17 INFO Epoch 2: [6997/10940] ---- BYOL Training Loss = 0.3030926585197449
30-01-2023 12:00:09 INFO Epoch 2: [6997/10940] ---- BYOL Validation Loss = 0.24235662817955017
30-01-2023 12:00:27 INFO Epoch 2: [7008/10940] ---- BYOL Training Loss = 0.2600589394569397
30-01-2023 12:00:46 INFO Epoch 2: [7019/10940] ---- BYOL Training Loss = 0.26078617572784424
30-01-2023 12:01:05 INFO Epoch 2: [7030/10940] ---- BYOL Training Loss = 0.28785979747772217
30-01-2023 12:01:23 INFO Epoch 2: [7041/10940] ---- BYOL Training Loss = 0.2550109028816223
30-01-2023 12:02:15 INFO Epoch 2: [7041/10940] ---- BYOL Validation Loss = 0.22951190173625946
30-01-2023 12:02:33 INFO Epoch 2: [7052/10940] ---- BYOL Training Loss = 0.29439836740493774
30-01-2023 12:02:52 INFO Epoch 2: [7063/10940] ---- BYOL Training Loss = 0.305340439081192
30-01-2023 12:03:10 INFO Epoch 2: [7074/10940] ---- BYOL Training Loss = 0.2575378119945526
30-01-2023 12:03:28 INFO Epoch 2: [7085/10940] ---- BYOL Training Loss = 0.26073235273361206
30-01-2023 12:04:20 INFO Epoch 2: [7085/10940] ---- BYOL Validation Loss = 0.23711110651493073
30-01-2023 12:04:39 INFO Epoch 2: [7096/10940] ---- BYOL Training Loss = 0.316240519285202
30-01-2023 12:04:57 INFO Epoch 2: [7107/10940] ---- BYOL Training Loss = 0.3051033616065979
30-01-2023 12:05:16 INFO Epoch 2: [7118/10940] ---- BYOL Training Loss = 0.32584595680236816
30-01-2023 12:05:34 INFO Epoch 2: [7129/10940] ---- BYOL Training Loss = 0.3225153982639313
30-01-2023 12:06:26 INFO Epoch 2: [7129/10940] ---- BYOL Validation Loss = 0.25225186347961426
30-01-2023 12:06:44 INFO Epoch 2: [7140/10940] ---- BYOL Training Loss = 0.27659496665000916
30-01-2023 12:07:03 INFO Epoch 2: [7151/10940] ---- BYOL Training Loss = 0.2815890312194824
30-01-2023 12:07:21 INFO Epoch 2: [7162/10940] ---- BYOL Training Loss = 0.28487998247146606
30-01-2023 12:07:40 INFO Epoch 2: [7173/10940] ---- BYOL Training Loss = 0.26219442486763
30-01-2023 12:08:32 INFO Epoch 2: [7173/10940] ---- BYOL Validation Loss = 0.2372630089521408
30-01-2023 12:08:50 INFO Epoch 2: [7184/10940] ---- BYOL Training Loss = 0.2378147840499878
30-01-2023 12:09:09 INFO Epoch 2: [7195/10940] ---- BYOL Training Loss = 0.24785761535167694
30-01-2023 12:09:28 INFO Epoch 2: [7206/10940] ---- BYOL Training Loss = 0.3149580955505371
30-01-2023 12:09:46 INFO Epoch 2: [7217/10940] ---- BYOL Training Loss = 0.3162536323070526
30-01-2023 12:10:38 INFO Epoch 2: [7217/10940] ---- BYOL Validation Loss = 0.2615823447704315
30-01-2023 12:10:56 INFO Epoch 2: [7228/10940] ---- BYOL Training Loss = 0.32539597153663635
30-01-2023 12:11:15 INFO Epoch 2: [7239/10940] ---- BYOL Training Loss = 0.3544074594974518
30-01-2023 12:11:34 INFO Epoch 2: [7250/10940] ---- BYOL Training Loss = 0.3306897282600403
30-01-2023 12:11:52 INFO Epoch 2: [7261/10940] ---- BYOL Training Loss = 0.2710646688938141
30-01-2023 12:12:44 INFO Epoch 2: [7261/10940] ---- BYOL Validation Loss = 0.2503909468650818
30-01-2023 12:13:02 INFO Epoch 2: [7272/10940] ---- BYOL Training Loss = 0.24112096428871155
30-01-2023 12:13:21 INFO Epoch 2: [7283/10940] ---- BYOL Training Loss = 0.2834712862968445
30-01-2023 12:13:39 INFO Epoch 2: [7294/10940] ---- BYOL Training Loss = 0.26791197061538696
30-01-2023 12:13:58 INFO Epoch 2: [7305/10940] ---- BYOL Training Loss = 0.23061203956604004
30-01-2023 12:14:50 INFO Epoch 2: [7305/10940] ---- BYOL Validation Loss = 0.24132023751735687
30-01-2023 12:15:08 INFO Epoch 2: [7316/10940] ---- BYOL Training Loss = 0.2650464177131653
30-01-2023 12:15:27 INFO Epoch 2: [7327/10940] ---- BYOL Training Loss = 0.3262947201728821
30-01-2023 12:15:45 INFO Epoch 2: [7338/10940] ---- BYOL Training Loss = 0.3047904074192047
30-01-2023 12:16:04 INFO Epoch 2: [7349/10940] ---- BYOL Training Loss = 0.2962362468242645
30-01-2023 12:16:56 INFO Epoch 2: [7349/10940] ---- BYOL Validation Loss = 0.26393067836761475
30-01-2023 12:17:14 INFO Epoch 2: [7360/10940] ---- BYOL Training Loss = 0.32400548458099365
30-01-2023 12:17:32 INFO Epoch 2: [7371/10940] ---- BYOL Training Loss = 0.29206186532974243
30-01-2023 12:17:51 INFO Epoch 2: [7382/10940] ---- BYOL Training Loss = 0.2648307681083679
30-01-2023 12:18:10 INFO Epoch 2: [7393/10940] ---- BYOL Training Loss = 0.27543848752975464
30-01-2023 12:19:02 INFO Epoch 2: [7393/10940] ---- BYOL Validation Loss = 0.24869439005851746
30-01-2023 12:19:20 INFO Epoch 2: [7404/10940] ---- BYOL Training Loss = 0.23325958847999573
30-01-2023 12:19:39 INFO Epoch 2: [7415/10940] ---- BYOL Training Loss = 0.2629600763320923
30-01-2023 12:19:57 INFO Epoch 2: [7426/10940] ---- BYOL Training Loss = 0.2761208415031433
30-01-2023 12:20:15 INFO Epoch 2: [7437/10940] ---- BYOL Training Loss = 0.25108617544174194
30-01-2023 12:21:07 INFO Epoch 2: [7437/10940] ---- BYOL Validation Loss = 0.25864097476005554
30-01-2023 12:21:26 INFO Epoch 2: [7448/10940] ---- BYOL Training Loss = 0.2971631586551666
30-01-2023 12:21:44 INFO Epoch 2: [7459/10940] ---- BYOL Training Loss = 0.28534021973609924
30-01-2023 12:22:03 INFO Epoch 2: [7470/10940] ---- BYOL Training Loss = 0.22683286666870117
30-01-2023 12:22:22 INFO Epoch 2: [7481/10940] ---- BYOL Training Loss = 0.2802336812019348
30-01-2023 12:23:14 INFO Epoch 2: [7481/10940] ---- BYOL Validation Loss = 0.23948927223682404
30-01-2023 12:23:32 INFO Epoch 2: [7492/10940] ---- BYOL Training Loss = 0.3041093349456787
30-01-2023 12:23:50 INFO Epoch 2: [7503/10940] ---- BYOL Training Loss = 0.2832905650138855
30-01-2023 12:24:09 INFO Epoch 2: [7514/10940] ---- BYOL Training Loss = 0.2727988362312317
30-01-2023 12:24:28 INFO Epoch 2: [7525/10940] ---- BYOL Training Loss = 0.26080721616744995
30-01-2023 12:25:20 INFO Epoch 2: [7525/10940] ---- BYOL Validation Loss = 0.21155643463134766
30-01-2023 12:25:38 INFO Epoch 2: [7536/10940] ---- BYOL Training Loss = 0.36143144965171814
30-01-2023 12:25:56 INFO Epoch 2: [7547/10940] ---- BYOL Training Loss = 0.3545267879962921
30-01-2023 12:26:15 INFO Epoch 2: [7558/10940] ---- BYOL Training Loss = 0.2715149223804474
30-01-2023 12:26:34 INFO Epoch 2: [7569/10940] ---- BYOL Training Loss = 0.3212025761604309
30-01-2023 12:27:26 INFO Epoch 2: [7569/10940] ---- BYOL Validation Loss = 0.24750123918056488
30-01-2023 12:27:44 INFO Epoch 2: [7580/10940] ---- BYOL Training Loss = 0.30428147315979004
30-01-2023 12:28:03 INFO Epoch 2: [7591/10940] ---- BYOL Training Loss = 0.2981341481208801
30-01-2023 12:28:21 INFO Epoch 2: [7602/10940] ---- BYOL Training Loss = 0.2894531786441803
30-01-2023 12:28:39 INFO Epoch 2: [7613/10940] ---- BYOL Training Loss = 0.2847469449043274
30-01-2023 12:29:31 INFO Epoch 2: [7613/10940] ---- BYOL Validation Loss = 0.25038203597068787
30-01-2023 12:29:50 INFO Epoch 2: [7624/10940] ---- BYOL Training Loss = 0.2691720128059387
30-01-2023 12:30:08 INFO Epoch 2: [7635/10940] ---- BYOL Training Loss = 0.2480403184890747
30-01-2023 12:30:27 INFO Epoch 2: [7646/10940] ---- BYOL Training Loss = 0.2589515745639801
30-01-2023 12:30:46 INFO Epoch 2: [7657/10940] ---- BYOL Training Loss = 0.27188223600387573
30-01-2023 12:31:38 INFO Epoch 2: [7657/10940] ---- BYOL Validation Loss = 0.24770571291446686
30-01-2023 12:31:56 INFO Epoch 2: [7668/10940] ---- BYOL Training Loss = 0.32350531220436096
30-01-2023 12:32:14 INFO Epoch 2: [7679/10940] ---- BYOL Training Loss = 0.3960191309452057
30-01-2023 12:32:33 INFO Epoch 2: [7690/10940] ---- BYOL Training Loss = 0.28027060627937317
30-01-2023 12:32:52 INFO Epoch 2: [7701/10940] ---- BYOL Training Loss = 0.27235180139541626
30-01-2023 12:33:44 INFO Epoch 2: [7701/10940] ---- BYOL Validation Loss = 0.2559710144996643
30-01-2023 12:34:02 INFO Epoch 2: [7712/10940] ---- BYOL Training Loss = 0.30709388852119446
30-01-2023 12:34:21 INFO Epoch 2: [7723/10940] ---- BYOL Training Loss = 0.31002601981163025
30-01-2023 12:34:39 INFO Epoch 2: [7734/10940] ---- BYOL Training Loss = 0.3004298210144043
30-01-2023 12:34:58 INFO Epoch 2: [7745/10940] ---- BYOL Training Loss = 0.2579740881919861
30-01-2023 12:35:50 INFO Epoch 2: [7745/10940] ---- BYOL Validation Loss = 0.23802627623081207
30-01-2023 12:36:08 INFO Epoch 2: [7756/10940] ---- BYOL Training Loss = 0.2382739782333374
30-01-2023 12:36:27 INFO Epoch 2: [7767/10940] ---- BYOL Training Loss = 0.23599345982074738
30-01-2023 12:36:45 INFO Epoch 2: [7778/10940] ---- BYOL Training Loss = 0.26326215267181396
30-01-2023 12:37:04 INFO Epoch 2: [7789/10940] ---- BYOL Training Loss = 0.2692219913005829
30-01-2023 12:37:56 INFO Epoch 2: [7789/10940] ---- BYOL Validation Loss = 0.22344180941581726
30-01-2023 12:38:14 INFO Epoch 2: [7800/10940] ---- BYOL Training Loss = 0.26623111963272095
30-01-2023 12:38:33 INFO Epoch 2: [7811/10940] ---- BYOL Training Loss = 0.31068235635757446
30-01-2023 12:38:52 INFO Epoch 2: [7822/10940] ---- BYOL Training Loss = 0.3061477541923523
30-01-2023 12:39:11 INFO Epoch 2: [7833/10940] ---- BYOL Training Loss = 0.2899834215641022
30-01-2023 12:40:03 INFO Epoch 2: [7833/10940] ---- BYOL Validation Loss = 0.26357680559158325
30-01-2023 12:40:21 INFO Epoch 2: [7844/10940] ---- BYOL Training Loss = 0.3262585997581482
30-01-2023 12:40:40 INFO Epoch 2: [7855/10940] ---- BYOL Training Loss = 0.2648823857307434
30-01-2023 12:40:58 INFO Epoch 2: [7866/10940] ---- BYOL Training Loss = 0.2468237578868866
30-01-2023 12:41:17 INFO Epoch 2: [7877/10940] ---- BYOL Training Loss = 0.29029667377471924
30-01-2023 12:42:09 INFO Epoch 2: [7877/10940] ---- BYOL Validation Loss = 0.2255515307188034
30-01-2023 12:42:27 INFO Epoch 2: [7888/10940] ---- BYOL Training Loss = 0.2829410135746002
30-01-2023 12:42:46 INFO Epoch 2: [7899/10940] ---- BYOL Training Loss = 0.2854655683040619
30-01-2023 12:43:05 INFO Epoch 2: [7910/10940] ---- BYOL Training Loss = 0.2603326439857483
30-01-2023 12:43:23 INFO Epoch 2: [7921/10940] ---- BYOL Training Loss = 0.27866727113723755
30-01-2023 12:44:15 INFO Epoch 2: [7921/10940] ---- BYOL Validation Loss = 0.24764886498451233
30-01-2023 12:44:33 INFO Epoch 2: [7932/10940] ---- BYOL Training Loss = 0.2737258970737457
30-01-2023 12:44:52 INFO Epoch 2: [7943/10940] ---- BYOL Training Loss = 0.2582649290561676
30-01-2023 12:45:11 INFO Epoch 2: [7954/10940] ---- BYOL Training Loss = 0.2574300169944763
30-01-2023 12:45:29 INFO Epoch 2: [7965/10940] ---- BYOL Training Loss = 0.26218658685684204
30-01-2023 12:46:21 INFO Epoch 2: [7965/10940] ---- BYOL Validation Loss = 0.23527398705482483
30-01-2023 12:46:40 INFO Epoch 2: [7976/10940] ---- BYOL Training Loss = 0.29685938358306885
30-01-2023 12:46:59 INFO Epoch 2: [7987/10940] ---- BYOL Training Loss = 0.2789745628833771
30-01-2023 12:47:17 INFO Epoch 2: [7998/10940] ---- BYOL Training Loss = 0.23955824971199036
30-01-2023 12:47:36 INFO Epoch 2: [8009/10940] ---- BYOL Training Loss = 0.22908596694469452
30-01-2023 12:48:28 INFO Epoch 2: [8009/10940] ---- BYOL Validation Loss = 0.24415574967861176
30-01-2023 12:48:46 INFO Epoch 2: [8020/10940] ---- BYOL Training Loss = 0.25359994173049927
30-01-2023 12:49:05 INFO Epoch 2: [8031/10940] ---- BYOL Training Loss = 0.25003582239151
30-01-2023 12:49:24 INFO Epoch 2: [8042/10940] ---- BYOL Training Loss = 0.2308885157108307
30-01-2023 12:49:42 INFO Epoch 2: [8053/10940] ---- BYOL Training Loss = 0.26720520853996277
30-01-2023 12:50:34 INFO Epoch 2: [8053/10940] ---- BYOL Validation Loss = 0.2488785833120346
30-01-2023 12:50:52 INFO Epoch 2: [8064/10940] ---- BYOL Training Loss = 0.26585084199905396
30-01-2023 12:51:11 INFO Epoch 2: [8075/10940] ---- BYOL Training Loss = 0.23456183075904846
30-01-2023 12:51:30 INFO Epoch 2: [8086/10940] ---- BYOL Training Loss = 0.25037604570388794
30-01-2023 12:51:49 INFO Epoch 2: [8097/10940] ---- BYOL Training Loss = 0.2426079958677292
30-01-2023 12:52:41 INFO Epoch 2: [8097/10940] ---- BYOL Validation Loss = 0.22706292569637299
30-01-2023 12:52:59 INFO Epoch 2: [8108/10940] ---- BYOL Training Loss = 0.257917582988739
30-01-2023 12:53:17 INFO Epoch 2: [8119/10940] ---- BYOL Training Loss = 0.26104697585105896
30-01-2023 12:53:36 INFO Epoch 2: [8130/10940] ---- BYOL Training Loss = 0.2567698359489441
30-01-2023 12:53:55 INFO Epoch 2: [8141/10940] ---- BYOL Training Loss = 0.26060935854911804
30-01-2023 12:54:47 INFO Epoch 2: [8141/10940] ---- BYOL Validation Loss = 0.2393459975719452
30-01-2023 12:55:05 INFO Epoch 2: [8152/10940] ---- BYOL Training Loss = 0.2625561058521271
30-01-2023 12:55:24 INFO Epoch 2: [8163/10940] ---- BYOL Training Loss = 0.2510802745819092
30-01-2023 12:55:43 INFO Epoch 2: [8174/10940] ---- BYOL Training Loss = 0.2778720557689667
30-01-2023 12:56:01 INFO Epoch 2: [8185/10940] ---- BYOL Training Loss = 0.2751859724521637
30-01-2023 12:56:53 INFO Epoch 2: [8185/10940] ---- BYOL Validation Loss = 0.22880731523036957
30-01-2023 12:57:12 INFO Epoch 2: [8196/10940] ---- BYOL Training Loss = 0.26025599241256714
30-01-2023 12:57:30 INFO Epoch 2: [8207/10940] ---- BYOL Training Loss = 0.23289430141448975
30-01-2023 12:57:49 INFO Epoch 2: [8218/10940] ---- BYOL Training Loss = 0.24474398791790009
30-01-2023 12:58:08 INFO Epoch 2: [8229/10940] ---- BYOL Training Loss = 0.27028852701187134
30-01-2023 12:59:00 INFO Epoch 2: [8229/10940] ---- BYOL Validation Loss = 0.2084914743900299
30-01-2023 12:59:18 INFO Epoch 2: [8240/10940] ---- BYOL Training Loss = 0.2793932557106018
30-01-2023 12:59:36 INFO Epoch 2: [8251/10940] ---- BYOL Training Loss = 0.2913772463798523
30-01-2023 12:59:55 INFO Epoch 2: [8262/10940] ---- BYOL Training Loss = 0.28074443340301514
30-01-2023 13:00:14 INFO Epoch 2: [8273/10940] ---- BYOL Training Loss = 0.28583213686943054
30-01-2023 13:01:06 INFO Epoch 2: [8273/10940] ---- BYOL Validation Loss = 0.24674606323242188
30-01-2023 13:01:24 INFO Epoch 2: [8284/10940] ---- BYOL Training Loss = 0.27979928255081177
30-01-2023 13:01:43 INFO Epoch 2: [8295/10940] ---- BYOL Training Loss = 0.2533268630504608
30-01-2023 13:02:01 INFO Epoch 2: [8306/10940] ---- BYOL Training Loss = 0.2717600464820862
30-01-2023 13:02:20 INFO Epoch 2: [8317/10940] ---- BYOL Training Loss = 0.2822907567024231
30-01-2023 13:03:12 INFO Epoch 2: [8317/10940] ---- BYOL Validation Loss = 0.24372455477714539
30-01-2023 13:03:30 INFO Epoch 2: [8328/10940] ---- BYOL Training Loss = 0.25873762369155884
30-01-2023 13:03:49 INFO Epoch 2: [8339/10940] ---- BYOL Training Loss = 0.2637345790863037
30-01-2023 13:04:07 INFO Epoch 2: [8350/10940] ---- BYOL Training Loss = 0.2725326120853424
30-01-2023 13:04:26 INFO Epoch 2: [8361/10940] ---- BYOL Training Loss = 0.2697552740573883
30-01-2023 13:05:18 INFO Epoch 2: [8361/10940] ---- BYOL Validation Loss = 0.19717267155647278
30-01-2023 13:05:37 INFO Epoch 2: [8372/10940] ---- BYOL Training Loss = 0.26985079050064087
30-01-2023 13:05:55 INFO Epoch 2: [8383/10940] ---- BYOL Training Loss = 0.2957353889942169
30-01-2023 13:06:14 INFO Epoch 2: [8394/10940] ---- BYOL Training Loss = 0.29246971011161804
30-01-2023 13:06:32 INFO Epoch 2: [8405/10940] ---- BYOL Training Loss = 0.3200025260448456
30-01-2023 13:07:24 INFO Epoch 2: [8405/10940] ---- BYOL Validation Loss = 0.24666425585746765
30-01-2023 13:07:43 INFO Epoch 2: [8416/10940] ---- BYOL Training Loss = 0.32504770159721375
30-01-2023 13:08:02 INFO Epoch 2: [8427/10940] ---- BYOL Training Loss = 0.3462074100971222
30-01-2023 13:08:20 INFO Epoch 2: [8438/10940] ---- BYOL Training Loss = 0.3034372925758362
30-01-2023 13:08:39 INFO Epoch 2: [8449/10940] ---- BYOL Training Loss = 0.2980613708496094
30-01-2023 13:09:31 INFO Epoch 2: [8449/10940] ---- BYOL Validation Loss = 0.20764894783496857
30-01-2023 13:09:49 INFO Epoch 2: [8460/10940] ---- BYOL Training Loss = 0.2635868787765503
30-01-2023 13:10:08 INFO Epoch 2: [8471/10940] ---- BYOL Training Loss = 0.24581202864646912
30-01-2023 13:10:27 INFO Epoch 2: [8482/10940] ---- BYOL Training Loss = 0.24414865672588348
30-01-2023 13:10:46 INFO Epoch 2: [8493/10940] ---- BYOL Training Loss = 0.3220352530479431
30-01-2023 13:11:38 INFO Epoch 2: [8493/10940] ---- BYOL Validation Loss = 0.2062934786081314
30-01-2023 13:11:56 INFO Epoch 2: [8504/10940] ---- BYOL Training Loss = 0.3370541036128998
30-01-2023 13:12:15 INFO Epoch 2: [8515/10940] ---- BYOL Training Loss = 0.30621710419654846
30-01-2023 13:12:33 INFO Epoch 2: [8526/10940] ---- BYOL Training Loss = 0.2968525290489197
30-01-2023 13:12:52 INFO Epoch 2: [8537/10940] ---- BYOL Training Loss = 0.2621552348136902
30-01-2023 13:13:44 INFO Epoch 2: [8537/10940] ---- BYOL Validation Loss = 0.2091747373342514
30-01-2023 13:14:02 INFO Epoch 2: [8548/10940] ---- BYOL Training Loss = 0.24496746063232422
30-01-2023 13:14:21 INFO Epoch 2: [8559/10940] ---- BYOL Training Loss = 0.2597199082374573
30-01-2023 13:14:40 INFO Epoch 2: [8570/10940] ---- BYOL Training Loss = 0.3132123351097107
30-01-2023 13:14:58 INFO Epoch 2: [8581/10940] ---- BYOL Training Loss = 0.3460462987422943
30-01-2023 13:15:50 INFO Epoch 2: [8581/10940] ---- BYOL Validation Loss = 0.2329515665769577
30-01-2023 13:16:09 INFO Epoch 2: [8592/10940] ---- BYOL Training Loss = 0.32832881808280945
30-01-2023 13:16:27 INFO Epoch 2: [8603/10940] ---- BYOL Training Loss = 0.29971230030059814
30-01-2023 13:16:46 INFO Epoch 2: [8614/10940] ---- BYOL Training Loss = 0.28219881653785706
30-01-2023 13:17:05 INFO Epoch 2: [8625/10940] ---- BYOL Training Loss = 0.249388188123703
30-01-2023 13:17:57 INFO Epoch 2: [8625/10940] ---- BYOL Validation Loss = 0.23354217410087585
30-01-2023 13:18:15 INFO Epoch 2: [8636/10940] ---- BYOL Training Loss = 0.2693677842617035
30-01-2023 13:18:34 INFO Epoch 2: [8647/10940] ---- BYOL Training Loss = 0.2501276135444641
30-01-2023 13:18:52 INFO Epoch 2: [8658/10940] ---- BYOL Training Loss = 0.23443612456321716
30-01-2023 13:19:11 INFO Epoch 2: [8669/10940] ---- BYOL Training Loss = 0.2505052387714386
30-01-2023 13:20:03 INFO Epoch 2: [8669/10940] ---- BYOL Validation Loss = 0.25357237458229065
30-01-2023 13:20:22 INFO Epoch 2: [8680/10940] ---- BYOL Training Loss = 0.24039120972156525
30-01-2023 13:20:41 INFO Epoch 2: [8691/10940] ---- BYOL Training Loss = 0.2632422149181366
30-01-2023 13:20:59 INFO Epoch 2: [8702/10940] ---- BYOL Training Loss = 0.25150176882743835
30-01-2023 13:21:18 INFO Epoch 2: [8713/10940] ---- BYOL Training Loss = 0.25982171297073364
30-01-2023 13:22:10 INFO Epoch 2: [8713/10940] ---- BYOL Validation Loss = 0.22878286242485046
30-01-2023 13:22:28 INFO Epoch 2: [8724/10940] ---- BYOL Training Loss = 0.2914378046989441
30-01-2023 13:22:47 INFO Epoch 2: [8735/10940] ---- BYOL Training Loss = 0.2834102511405945
30-01-2023 13:23:06 INFO Epoch 2: [8746/10940] ---- BYOL Training Loss = 0.287015438079834
30-01-2023 13:23:25 INFO Epoch 2: [8757/10940] ---- BYOL Training Loss = 0.32952672243118286
30-01-2023 13:24:17 INFO Epoch 2: [8757/10940] ---- BYOL Validation Loss = 0.24651221930980682
30-01-2023 13:24:35 INFO Epoch 2: [8768/10940] ---- BYOL Training Loss = 0.2801564931869507
30-01-2023 13:24:54 INFO Epoch 2: [8779/10940] ---- BYOL Training Loss = 0.2839601933956146
30-01-2023 13:25:12 INFO Epoch 2: [8790/10940] ---- BYOL Training Loss = 0.2856276035308838
30-01-2023 13:25:31 INFO Epoch 2: [8801/10940] ---- BYOL Training Loss = 0.2947161793708801
30-01-2023 13:26:23 INFO Epoch 2: [8801/10940] ---- BYOL Validation Loss = 0.22187747061252594
30-01-2023 13:26:42 INFO Epoch 2: [8812/10940] ---- BYOL Training Loss = 0.3234547972679138
30-01-2023 13:27:00 INFO Epoch 2: [8823/10940] ---- BYOL Training Loss = 0.279859334230423
30-01-2023 13:27:19 INFO Epoch 2: [8834/10940] ---- BYOL Training Loss = 0.23659729957580566
30-01-2023 13:27:38 INFO Epoch 2: [8845/10940] ---- BYOL Training Loss = 0.2326236516237259
30-01-2023 13:28:30 INFO Epoch 2: [8845/10940] ---- BYOL Validation Loss = 0.20331020653247833
30-01-2023 13:28:48 INFO Epoch 2: [8856/10940] ---- BYOL Training Loss = 0.27022722363471985
30-01-2023 13:29:07 INFO Epoch 2: [8867/10940] ---- BYOL Training Loss = 0.2604069411754608
30-01-2023 13:29:26 INFO Epoch 2: [8878/10940] ---- BYOL Training Loss = 0.27286747097969055
30-01-2023 13:29:45 INFO Epoch 2: [8889/10940] ---- BYOL Training Loss = 0.2733807861804962
30-01-2023 13:30:37 INFO Epoch 2: [8889/10940] ---- BYOL Validation Loss = 0.2262173742055893
30-01-2023 13:30:55 INFO Epoch 2: [8900/10940] ---- BYOL Training Loss = 0.3305636942386627
30-01-2023 13:31:13 INFO Epoch 2: [8911/10940] ---- BYOL Training Loss = 0.30229079723358154
30-01-2023 13:31:32 INFO Epoch 2: [8922/10940] ---- BYOL Training Loss = 0.247807115316391
30-01-2023 13:31:51 INFO Epoch 2: [8933/10940] ---- BYOL Training Loss = 0.3087049126625061
30-01-2023 13:32:43 INFO Epoch 2: [8933/10940] ---- BYOL Validation Loss = 0.21792259812355042
30-01-2023 13:33:02 INFO Epoch 2: [8944/10940] ---- BYOL Training Loss = 0.34504595398902893
30-01-2023 13:33:20 INFO Epoch 2: [8955/10940] ---- BYOL Training Loss = 0.31060990691185
30-01-2023 13:33:39 INFO Epoch 2: [8966/10940] ---- BYOL Training Loss = 0.32883420586586
30-01-2023 13:33:58 INFO Epoch 2: [8977/10940] ---- BYOL Training Loss = 0.31843215227127075
30-01-2023 13:34:50 INFO Epoch 2: [8977/10940] ---- BYOL Validation Loss = 0.23868320882320404
30-01-2023 13:35:08 INFO Epoch 2: [8988/10940] ---- BYOL Training Loss = 0.29590123891830444
30-01-2023 13:35:27 INFO Epoch 2: [8999/10940] ---- BYOL Training Loss = 0.2550966143608093
30-01-2023 13:35:46 INFO Epoch 2: [9010/10940] ---- BYOL Training Loss = 0.24618574976921082
30-01-2023 13:36:04 INFO Epoch 2: [9021/10940] ---- BYOL Training Loss = 0.20939263701438904
30-01-2023 13:36:56 INFO Epoch 2: [9021/10940] ---- BYOL Validation Loss = 0.22651556134223938
30-01-2023 13:37:15 INFO Epoch 2: [9032/10940] ---- BYOL Training Loss = 0.2614479660987854
30-01-2023 13:37:34 INFO Epoch 2: [9043/10940] ---- BYOL Training Loss = 0.3026984930038452
30-01-2023 13:37:52 INFO Epoch 2: [9054/10940] ---- BYOL Training Loss = 0.2583697736263275
30-01-2023 13:38:11 INFO Epoch 2: [9065/10940] ---- BYOL Training Loss = 0.2560315430164337
30-01-2023 13:39:03 INFO Epoch 2: [9065/10940] ---- BYOL Validation Loss = 0.23045554757118225
30-01-2023 13:39:22 INFO Epoch 2: [9076/10940] ---- BYOL Training Loss = 0.2738950848579407
30-01-2023 13:39:40 INFO Epoch 2: [9087/10940] ---- BYOL Training Loss = 0.2650265693664551
30-01-2023 13:39:59 INFO Epoch 2: [9098/10940] ---- BYOL Training Loss = 0.24401304125785828
30-01-2023 13:40:18 INFO Epoch 2: [9109/10940] ---- BYOL Training Loss = 0.2421453297138214
30-01-2023 13:41:10 INFO Epoch 2: [9109/10940] ---- BYOL Validation Loss = 0.22445079684257507
30-01-2023 13:41:29 INFO Epoch 2: [9120/10940] ---- BYOL Training Loss = 0.2734837234020233
30-01-2023 13:41:47 INFO Epoch 2: [9131/10940] ---- BYOL Training Loss = 0.2843171954154968
30-01-2023 13:42:06 INFO Epoch 2: [9142/10940] ---- BYOL Training Loss = 0.2823595702648163
30-01-2023 13:42:25 INFO Epoch 2: [9153/10940] ---- BYOL Training Loss = 0.2516947388648987
30-01-2023 13:43:17 INFO Epoch 2: [9153/10940] ---- BYOL Validation Loss = 0.21380604803562164
30-01-2023 13:43:35 INFO Epoch 2: [9164/10940] ---- BYOL Training Loss = 0.256760835647583
30-01-2023 13:43:54 INFO Epoch 2: [9175/10940] ---- BYOL Training Loss = 0.2564534544944763
30-01-2023 13:44:13 INFO Epoch 2: [9186/10940] ---- BYOL Training Loss = 0.23419710993766785
30-01-2023 13:44:31 INFO Epoch 2: [9197/10940] ---- BYOL Training Loss = 0.23351597785949707
30-01-2023 13:45:23 INFO Epoch 2: [9197/10940] ---- BYOL Validation Loss = 0.22542791068553925
30-01-2023 13:45:42 INFO Epoch 2: [9208/10940] ---- BYOL Training Loss = 0.2408733069896698
30-01-2023 13:46:01 INFO Epoch 2: [9219/10940] ---- BYOL Training Loss = 0.2883847951889038
30-01-2023 13:46:20 INFO Epoch 2: [9230/10940] ---- BYOL Training Loss = 0.304629385471344
30-01-2023 13:46:38 INFO Epoch 2: [9241/10940] ---- BYOL Training Loss = 0.3046911358833313
30-01-2023 13:47:30 INFO Epoch 2: [9241/10940] ---- BYOL Validation Loss = 0.24530379474163055
30-01-2023 13:47:49 INFO Epoch 2: [9252/10940] ---- BYOL Training Loss = 0.28177303075790405
30-01-2023 13:48:08 INFO Epoch 2: [9263/10940] ---- BYOL Training Loss = 0.26274964213371277
30-01-2023 13:48:26 INFO Epoch 2: [9274/10940] ---- BYOL Training Loss = 0.2814878821372986
30-01-2023 13:48:45 INFO Epoch 2: [9285/10940] ---- BYOL Training Loss = 0.262044221162796
30-01-2023 13:49:37 INFO Epoch 2: [9285/10940] ---- BYOL Validation Loss = 0.23709742724895477
30-01-2023 13:49:56 INFO Epoch 2: [9296/10940] ---- BYOL Training Loss = 0.24467162787914276
30-01-2023 13:50:14 INFO Epoch 2: [9307/10940] ---- BYOL Training Loss = 0.26843923330307007
30-01-2023 13:50:33 INFO Epoch 2: [9318/10940] ---- BYOL Training Loss = 0.294752299785614
30-01-2023 13:50:52 INFO Epoch 2: [9329/10940] ---- BYOL Training Loss = 0.27543824911117554
30-01-2023 13:51:44 INFO Epoch 2: [9329/10940] ---- BYOL Validation Loss = 0.22889630496501923
30-01-2023 13:52:03 INFO Epoch 2: [9340/10940] ---- BYOL Training Loss = 0.23094746470451355
30-01-2023 13:52:21 INFO Epoch 2: [9351/10940] ---- BYOL Training Loss = 0.281460165977478
30-01-2023 13:52:40 INFO Epoch 2: [9362/10940] ---- BYOL Training Loss = 0.2981939911842346
30-01-2023 13:52:59 INFO Epoch 2: [9373/10940] ---- BYOL Training Loss = 0.24869148433208466
30-01-2023 13:53:51 INFO Epoch 2: [9373/10940] ---- BYOL Validation Loss = 0.21284492313861847
30-01-2023 13:54:09 INFO Epoch 2: [9384/10940] ---- BYOL Training Loss = 0.2284688949584961
30-01-2023 13:54:28 INFO Epoch 2: [9395/10940] ---- BYOL Training Loss = 0.25808972120285034
30-01-2023 13:54:47 INFO Epoch 2: [9406/10940] ---- BYOL Training Loss = 0.259277880191803
30-01-2023 13:55:05 INFO Epoch 2: [9417/10940] ---- BYOL Training Loss = 0.25538456439971924
30-01-2023 13:55:57 INFO Epoch 2: [9417/10940] ---- BYOL Validation Loss = 0.20300480723381042
30-01-2023 13:56:16 INFO Epoch 2: [9428/10940] ---- BYOL Training Loss = 0.31048810482025146
30-01-2023 13:56:35 INFO Epoch 2: [9439/10940] ---- BYOL Training Loss = 0.2872892916202545
30-01-2023 13:56:54 INFO Epoch 2: [9450/10940] ---- BYOL Training Loss = 0.2189973145723343
30-01-2023 13:57:12 INFO Epoch 2: [9461/10940] ---- BYOL Training Loss = 0.23070690035820007
30-01-2023 13:58:04 INFO Epoch 2: [9461/10940] ---- BYOL Validation Loss = 0.23533396422863007
30-01-2023 13:58:23 INFO Epoch 2: [9472/10940] ---- BYOL Training Loss = 0.3019024729728699
30-01-2023 13:58:42 INFO Epoch 2: [9483/10940] ---- BYOL Training Loss = 0.32360535860061646
30-01-2023 13:59:00 INFO Epoch 2: [9494/10940] ---- BYOL Training Loss = 0.3096398413181305
30-01-2023 13:59:19 INFO Epoch 2: [9505/10940] ---- BYOL Training Loss = 0.28092214465141296
30-01-2023 14:00:11 INFO Epoch 2: [9505/10940] ---- BYOL Validation Loss = 0.21597354114055634
30-01-2023 14:00:30 INFO Epoch 2: [9516/10940] ---- BYOL Training Loss = 0.23599286377429962
30-01-2023 14:00:49 INFO Epoch 2: [9527/10940] ---- BYOL Training Loss = 0.20895802974700928
30-01-2023 14:01:07 INFO Epoch 2: [9538/10940] ---- BYOL Training Loss = 0.26776769757270813
30-01-2023 14:01:26 INFO Epoch 2: [9549/10940] ---- BYOL Training Loss = 0.26375913619995117
30-01-2023 14:02:18 INFO Epoch 2: [9549/10940] ---- BYOL Validation Loss = 0.2277487963438034
30-01-2023 14:02:37 INFO Epoch 2: [9560/10940] ---- BYOL Training Loss = 0.24618878960609436
30-01-2023 14:02:56 INFO Epoch 2: [9571/10940] ---- BYOL Training Loss = 0.2728934586048126
30-01-2023 14:03:14 INFO Epoch 2: [9582/10940] ---- BYOL Training Loss = 0.2544773519039154
30-01-2023 14:03:33 INFO Epoch 2: [9593/10940] ---- BYOL Training Loss = 0.24615855515003204
30-01-2023 14:04:25 INFO Epoch 2: [9593/10940] ---- BYOL Validation Loss = 0.21997003257274628
30-01-2023 14:04:44 INFO Epoch 2: [9604/10940] ---- BYOL Training Loss = 0.2645363211631775
30-01-2023 14:05:03 INFO Epoch 2: [9615/10940] ---- BYOL Training Loss = 0.26428958773612976
30-01-2023 14:05:21 INFO Epoch 2: [9626/10940] ---- BYOL Training Loss = 0.341347873210907
30-01-2023 14:05:40 INFO Epoch 2: [9637/10940] ---- BYOL Training Loss = 0.34472694993019104
30-01-2023 14:06:32 INFO Epoch 2: [9637/10940] ---- BYOL Validation Loss = 0.16994330286979675
30-01-2023 14:06:51 INFO Epoch 2: [9648/10940] ---- BYOL Training Loss = 0.3123399615287781
30-01-2023 14:07:09 INFO Epoch 2: [9659/10940] ---- BYOL Training Loss = 0.274516761302948
30-01-2023 14:07:28 INFO Epoch 2: [9670/10940] ---- BYOL Training Loss = 0.26119670271873474
30-01-2023 14:07:47 INFO Epoch 2: [9681/10940] ---- BYOL Training Loss = 0.2722164988517761
30-01-2023 14:08:39 INFO Epoch 2: [9681/10940] ---- BYOL Validation Loss = 0.18841072916984558
30-01-2023 14:08:58 INFO Epoch 2: [9692/10940] ---- BYOL Training Loss = 0.2770252823829651
30-01-2023 14:09:17 INFO Epoch 2: [9703/10940] ---- BYOL Training Loss = 0.36477383971214294
30-01-2023 14:09:36 INFO Epoch 2: [9714/10940] ---- BYOL Training Loss = 0.4323441982269287
30-01-2023 14:09:54 INFO Epoch 2: [9725/10940] ---- BYOL Training Loss = 0.3264954090118408
30-01-2023 14:10:46 INFO Epoch 2: [9725/10940] ---- BYOL Validation Loss = 0.2457645982503891
30-01-2023 14:11:05 INFO Epoch 2: [9736/10940] ---- BYOL Training Loss = 0.26060324907302856
30-01-2023 14:11:24 INFO Epoch 2: [9747/10940] ---- BYOL Training Loss = 0.28149813413619995
30-01-2023 14:11:43 INFO Epoch 2: [9758/10940] ---- BYOL Training Loss = 0.2698245942592621
30-01-2023 14:12:02 INFO Epoch 2: [9769/10940] ---- BYOL Training Loss = 0.28043699264526367
30-01-2023 14:12:54 INFO Epoch 2: [9769/10940] ---- BYOL Validation Loss = 0.23084446787834167
30-01-2023 14:13:12 INFO Epoch 2: [9780/10940] ---- BYOL Training Loss = 0.25524407625198364
30-01-2023 14:13:32 INFO Epoch 2: [9791/10940] ---- BYOL Training Loss = 0.25071239471435547
30-01-2023 14:13:50 INFO Epoch 2: [9802/10940] ---- BYOL Training Loss = 0.2615618109703064
30-01-2023 14:14:09 INFO Epoch 2: [9813/10940] ---- BYOL Training Loss = 0.2792690098285675
30-01-2023 14:15:01 INFO Epoch 2: [9813/10940] ---- BYOL Validation Loss = 0.24874816834926605
30-01-2023 14:15:20 INFO Epoch 2: [9824/10940] ---- BYOL Training Loss = 0.33602023124694824
30-01-2023 14:15:39 INFO Epoch 2: [9835/10940] ---- BYOL Training Loss = 0.35601335763931274
30-01-2023 14:15:58 INFO Epoch 2: [9846/10940] ---- BYOL Training Loss = 0.37201571464538574
30-01-2023 14:16:16 INFO Epoch 2: [9857/10940] ---- BYOL Training Loss = 0.3660393953323364
30-01-2023 14:17:08 INFO Epoch 2: [9857/10940] ---- BYOL Validation Loss = 0.27069875597953796
30-01-2023 14:17:27 INFO Epoch 2: [9868/10940] ---- BYOL Training Loss = 0.2904869019985199
30-01-2023 14:17:46 INFO Epoch 2: [9879/10940] ---- BYOL Training Loss = 0.2739410996437073
30-01-2023 14:18:05 INFO Epoch 2: [9890/10940] ---- BYOL Training Loss = 0.29974716901779175
30-01-2023 14:18:24 INFO Epoch 2: [9901/10940] ---- BYOL Training Loss = 0.2718120217323303
30-01-2023 14:19:16 INFO Epoch 2: [9901/10940] ---- BYOL Validation Loss = 0.2139696627855301
30-01-2023 14:19:34 INFO Epoch 2: [9912/10940] ---- BYOL Training Loss = 0.287839412689209
30-01-2023 14:19:53 INFO Epoch 2: [9923/10940] ---- BYOL Training Loss = 0.22735626995563507
30-01-2023 14:20:12 INFO Epoch 2: [9934/10940] ---- BYOL Training Loss = 0.2147352397441864
30-01-2023 14:20:31 INFO Epoch 2: [9945/10940] ---- BYOL Training Loss = 0.2728082537651062
30-01-2023 14:21:23 INFO Epoch 2: [9945/10940] ---- BYOL Validation Loss = 0.22039495408535004
30-01-2023 14:21:41 INFO Epoch 2: [9956/10940] ---- BYOL Training Loss = 0.2284337729215622
30-01-2023 14:22:00 INFO Epoch 2: [9967/10940] ---- BYOL Training Loss = 0.2693465054035187
30-01-2023 14:22:19 INFO Epoch 2: [9978/10940] ---- BYOL Training Loss = 0.2665841281414032
30-01-2023 14:22:38 INFO Epoch 2: [9989/10940] ---- BYOL Training Loss = 0.2419106662273407
30-01-2023 14:23:30 INFO Epoch 2: [9989/10940] ---- BYOL Validation Loss = 0.22325529158115387
30-01-2023 14:23:48 INFO Epoch 2: [10000/10940] ---- BYOL Training Loss = 0.29486387968063354
30-01-2023 14:24:07 INFO Epoch 2: [10011/10940] ---- BYOL Training Loss = 0.2812848687171936
30-01-2023 14:24:26 INFO Epoch 2: [10022/10940] ---- BYOL Training Loss = 0.23603984713554382
30-01-2023 14:24:45 INFO Epoch 2: [10033/10940] ---- BYOL Training Loss = 0.353518545627594
30-01-2023 14:25:37 INFO Epoch 2: [10033/10940] ---- BYOL Validation Loss = 0.2321883887052536
30-01-2023 14:25:55 INFO Epoch 2: [10044/10940] ---- BYOL Training Loss = 0.4411605894565582
30-01-2023 14:26:14 INFO Epoch 2: [10055/10940] ---- BYOL Training Loss = 0.3263372778892517
30-01-2023 14:26:33 INFO Epoch 2: [10066/10940] ---- BYOL Training Loss = 0.27220281958580017
30-01-2023 14:26:52 INFO Epoch 2: [10077/10940] ---- BYOL Training Loss = 0.2849242687225342
30-01-2023 14:27:44 INFO Epoch 2: [10077/10940] ---- BYOL Validation Loss = 0.24241520464420319
30-01-2023 14:28:03 INFO Epoch 2: [10088/10940] ---- BYOL Training Loss = 0.2738063633441925
30-01-2023 14:28:21 INFO Epoch 2: [10099/10940] ---- BYOL Training Loss = 0.25515487790107727
30-01-2023 14:28:40 INFO Epoch 2: [10110/10940] ---- BYOL Training Loss = 0.2389637678861618
30-01-2023 14:28:59 INFO Epoch 2: [10121/10940] ---- BYOL Training Loss = 0.232609823346138
30-01-2023 14:29:51 INFO Epoch 2: [10121/10940] ---- BYOL Validation Loss = 0.20082814991474152
30-01-2023 14:30:10 INFO Epoch 2: [10132/10940] ---- BYOL Training Loss = 0.2765060067176819
30-01-2023 14:30:29 INFO Epoch 2: [10143/10940] ---- BYOL Training Loss = 0.23264022171497345
30-01-2023 14:30:48 INFO Epoch 2: [10154/10940] ---- BYOL Training Loss = 0.2616271376609802
30-01-2023 14:31:06 INFO Epoch 2: [10165/10940] ---- BYOL Training Loss = 0.3270493149757385
30-01-2023 14:31:58 INFO Epoch 2: [10165/10940] ---- BYOL Validation Loss = 0.2148900330066681
30-01-2023 14:32:17 INFO Epoch 2: [10176/10940] ---- BYOL Training Loss = 0.30949586629867554
30-01-2023 14:32:36 INFO Epoch 2: [10187/10940] ---- BYOL Training Loss = 0.2558393180370331
30-01-2023 14:32:55 INFO Epoch 2: [10198/10940] ---- BYOL Training Loss = 0.2602807879447937
30-01-2023 14:33:14 INFO Epoch 2: [10209/10940] ---- BYOL Training Loss = 0.21140316128730774
30-01-2023 14:34:06 INFO Epoch 2: [10209/10940] ---- BYOL Validation Loss = 0.18089626729488373
30-01-2023 14:34:24 INFO Epoch 2: [10220/10940] ---- BYOL Training Loss = 0.24287860095500946
30-01-2023 14:34:43 INFO Epoch 2: [10231/10940] ---- BYOL Training Loss = 0.2892529368400574
30-01-2023 14:35:02 INFO Epoch 2: [10242/10940] ---- BYOL Training Loss = 0.3006454408168793
30-01-2023 14:35:21 INFO Epoch 2: [10253/10940] ---- BYOL Training Loss = 0.3185930848121643
30-01-2023 14:36:13 INFO Epoch 2: [10253/10940] ---- BYOL Validation Loss = 0.22541935741901398
30-01-2023 14:36:32 INFO Epoch 2: [10264/10940] ---- BYOL Training Loss = 0.31471043825149536
30-01-2023 14:36:50 INFO Epoch 2: [10275/10940] ---- BYOL Training Loss = 0.2950577139854431
30-01-2023 14:37:09 INFO Epoch 2: [10286/10940] ---- BYOL Training Loss = 0.36197179555892944
30-01-2023 14:37:28 INFO Epoch 2: [10297/10940] ---- BYOL Training Loss = 0.33272722363471985
30-01-2023 14:38:20 INFO Epoch 2: [10297/10940] ---- BYOL Validation Loss = 0.2184976190328598
30-01-2023 14:38:39 INFO Epoch 2: [10308/10940] ---- BYOL Training Loss = 0.28921160101890564
30-01-2023 14:38:58 INFO Epoch 2: [10319/10940] ---- BYOL Training Loss = 0.29843637347221375
30-01-2023 14:39:17 INFO Epoch 2: [10330/10940] ---- BYOL Training Loss = 0.24777844548225403
30-01-2023 14:39:35 INFO Epoch 2: [10341/10940] ---- BYOL Training Loss = 0.2776631712913513
30-01-2023 14:40:27 INFO Epoch 2: [10341/10940] ---- BYOL Validation Loss = 0.241289883852005
30-01-2023 14:40:46 INFO Epoch 2: [10352/10940] ---- BYOL Training Loss = 0.25187692046165466
30-01-2023 14:41:05 INFO Epoch 2: [10363/10940] ---- BYOL Training Loss = 0.2553369402885437
30-01-2023 14:41:24 INFO Epoch 2: [10374/10940] ---- BYOL Training Loss = 0.2924785912036896
30-01-2023 14:41:43 INFO Epoch 2: [10385/10940] ---- BYOL Training Loss = 0.27528029680252075
30-01-2023 14:42:35 INFO Epoch 2: [10385/10940] ---- BYOL Validation Loss = 0.21194982528686523
30-01-2023 14:42:53 INFO Epoch 2: [10396/10940] ---- BYOL Training Loss = 0.3072494566440582
30-01-2023 14:43:12 INFO Epoch 2: [10407/10940] ---- BYOL Training Loss = 0.3143811523914337
30-01-2023 14:43:31 INFO Epoch 2: [10418/10940] ---- BYOL Training Loss = 0.32767587900161743
30-01-2023 14:43:50 INFO Epoch 2: [10429/10940] ---- BYOL Training Loss = 0.3368043899536133
30-01-2023 14:44:42 INFO Epoch 2: [10429/10940] ---- BYOL Validation Loss = 0.23259098827838898
30-01-2023 14:45:00 INFO Epoch 2: [10440/10940] ---- BYOL Training Loss = 0.24757561087608337
30-01-2023 14:45:20 INFO Epoch 2: [10451/10940] ---- BYOL Training Loss = 0.2477354109287262
30-01-2023 14:45:38 INFO Epoch 2: [10462/10940] ---- BYOL Training Loss = 0.36040905117988586
30-01-2023 14:45:57 INFO Epoch 2: [10473/10940] ---- BYOL Training Loss = 0.32541483640670776
30-01-2023 14:46:49 INFO Epoch 2: [10473/10940] ---- BYOL Validation Loss = 0.2243698388338089
30-01-2023 14:47:08 INFO Epoch 2: [10484/10940] ---- BYOL Training Loss = 0.2419634312391281
30-01-2023 14:47:27 INFO Epoch 2: [10495/10940] ---- BYOL Training Loss = 0.3280973434448242
30-01-2023 14:47:46 INFO Epoch 2: [10506/10940] ---- BYOL Training Loss = 0.4233667850494385
30-01-2023 14:48:04 INFO Epoch 2: [10517/10940] ---- BYOL Training Loss = 0.3342116177082062
30-01-2023 14:48:56 INFO Epoch 2: [10517/10940] ---- BYOL Validation Loss = 0.26748421788215637
30-01-2023 14:49:15 INFO Epoch 2: [10528/10940] ---- BYOL Training Loss = 0.3735632002353668
30-01-2023 14:49:34 INFO Epoch 2: [10539/10940] ---- BYOL Training Loss = 0.3603733479976654
30-01-2023 14:49:53 INFO Epoch 2: [10550/10940] ---- BYOL Training Loss = 0.3615754246711731
30-01-2023 14:50:11 INFO Epoch 2: [10561/10940] ---- BYOL Training Loss = 0.3950946629047394
30-01-2023 14:51:03 INFO Epoch 2: [10561/10940] ---- BYOL Validation Loss = 0.2908349633216858
30-01-2023 14:51:22 INFO Epoch 2: [10572/10940] ---- BYOL Training Loss = 0.339225172996521
30-01-2023 14:51:41 INFO Epoch 2: [10583/10940] ---- BYOL Training Loss = 0.3056055009365082
30-01-2023 14:52:00 INFO Epoch 2: [10594/10940] ---- BYOL Training Loss = 0.30588841438293457
30-01-2023 14:52:19 INFO Epoch 2: [10605/10940] ---- BYOL Training Loss = 0.31181278824806213
30-01-2023 14:53:10 INFO Epoch 2: [10605/10940] ---- BYOL Validation Loss = 0.26998427510261536
30-01-2023 14:53:29 INFO Epoch 2: [10616/10940] ---- BYOL Training Loss = 0.35089877247810364
30-01-2023 14:53:48 INFO Epoch 2: [10627/10940] ---- BYOL Training Loss = 0.3663546144962311
30-01-2023 14:54:07 INFO Epoch 2: [10638/10940] ---- BYOL Training Loss = 0.3150565028190613
30-01-2023 14:54:26 INFO Epoch 2: [10649/10940] ---- BYOL Training Loss = 0.31836843490600586
30-01-2023 14:55:18 INFO Epoch 2: [10649/10940] ---- BYOL Validation Loss = 0.24621941149234772
30-01-2023 14:55:36 INFO Epoch 2: [10660/10940] ---- BYOL Training Loss = 0.3021402955055237
30-01-2023 14:55:55 INFO Epoch 2: [10671/10940] ---- BYOL Training Loss = 0.28790122270584106
30-01-2023 14:56:14 INFO Epoch 2: [10682/10940] ---- BYOL Training Loss = 0.305622398853302
30-01-2023 14:56:33 INFO Epoch 2: [10693/10940] ---- BYOL Training Loss = 0.34185922145843506
30-01-2023 14:57:25 INFO Epoch 2: [10693/10940] ---- BYOL Validation Loss = 0.29441824555397034
30-01-2023 14:57:43 INFO Epoch 2: [10704/10940] ---- BYOL Training Loss = 0.3244229853153229
30-01-2023 14:58:02 INFO Epoch 2: [10715/10940] ---- BYOL Training Loss = 0.23490551114082336
30-01-2023 14:58:21 INFO Epoch 2: [10726/10940] ---- BYOL Training Loss = 0.3057008981704712
30-01-2023 14:58:40 INFO Epoch 2: [10737/10940] ---- BYOL Training Loss = 0.3198501765727997
30-01-2023 14:59:32 INFO Epoch 2: [10737/10940] ---- BYOL Validation Loss = 0.2395845353603363
30-01-2023 14:59:50 INFO Epoch 2: [10748/10940] ---- BYOL Training Loss = 0.33215364813804626
30-01-2023 15:00:09 INFO Epoch 2: [10759/10940] ---- BYOL Training Loss = 0.3131257891654968
30-01-2023 15:00:28 INFO Epoch 2: [10770/10940] ---- BYOL Training Loss = 0.23931412398815155
30-01-2023 15:00:47 INFO Epoch 2: [10781/10940] ---- BYOL Training Loss = 0.3056718707084656
30-01-2023 15:01:39 INFO Epoch 2: [10781/10940] ---- BYOL Validation Loss = 0.2548641860485077
30-01-2023 15:01:57 INFO Epoch 2: [10792/10940] ---- BYOL Training Loss = 0.2980337142944336
30-01-2023 15:02:16 INFO Epoch 2: [10803/10940] ---- BYOL Training Loss = 0.26905709505081177
30-01-2023 15:02:35 INFO Epoch 2: [10814/10940] ---- BYOL Training Loss = 0.25370725989341736
30-01-2023 15:02:54 INFO Epoch 2: [10825/10940] ---- BYOL Training Loss = 0.29020777344703674
30-01-2023 15:03:46 INFO Epoch 2: [10825/10940] ---- BYOL Validation Loss = 0.26197224855422974
30-01-2023 15:04:05 INFO Epoch 2: [10836/10940] ---- BYOL Training Loss = 0.32944488525390625
30-01-2023 15:04:24 INFO Epoch 2: [10847/10940] ---- BYOL Training Loss = 0.30568987131118774
30-01-2023 15:04:43 INFO Epoch 2: [10858/10940] ---- BYOL Training Loss = 0.3234766721725464
30-01-2023 15:05:01 INFO Epoch 2: [10869/10940] ---- BYOL Training Loss = 0.2879948019981384
30-01-2023 15:05:53 INFO Epoch 2: [10869/10940] ---- BYOL Validation Loss = 0.23652979731559753
30-01-2023 15:06:12 INFO Epoch 2: [10880/10940] ---- BYOL Training Loss = 0.26992297172546387
30-01-2023 15:06:31 INFO Epoch 2: [10891/10940] ---- BYOL Training Loss = 0.2811945080757141
30-01-2023 15:06:49 INFO Epoch 2: [10902/10940] ---- BYOL Training Loss = 0.2831730246543884
30-01-2023 15:07:09 INFO Epoch 2: [10913/10940] ---- BYOL Training Loss = 0.26248180866241455
30-01-2023 15:08:01 INFO Epoch 2: [10913/10940] ---- BYOL Validation Loss = 0.2120593637228012
30-01-2023 15:08:19 INFO Epoch 2: [10924/10940] ---- BYOL Training Loss = 0.27594661712646484
30-01-2023 15:08:38 INFO Epoch 2: [10935/10940] ---- BYOL Training Loss = 0.2623772919178009
30-01-2023 15:08:47 INFO Starting Epoch: 3
30-01-2023 15:09:05 INFO Epoch 3: [12/10940] ---- BYOL Training Loss = 0.40187397599220276
30-01-2023 15:09:23 INFO Epoch 3: [23/10940] ---- BYOL Training Loss = 0.3915441930294037
30-01-2023 15:09:41 INFO Epoch 3: [34/10940] ---- BYOL Training Loss = 0.2970048189163208
30-01-2023 15:09:59 INFO Epoch 3: [45/10940] ---- BYOL Training Loss = 0.2991974353790283
30-01-2023 15:10:51 INFO Epoch 3: [45/10940] ---- BYOL Validation Loss = 0.24317587912082672
30-01-2023 15:11:08 INFO Epoch 3: [56/10940] ---- BYOL Training Loss = 0.29775217175483704
30-01-2023 15:11:26 INFO Epoch 3: [67/10940] ---- BYOL Training Loss = 0.20396831631660461
30-01-2023 15:11:44 INFO Epoch 3: [78/10940] ---- BYOL Training Loss = 0.23924751579761505
30-01-2023 15:12:02 INFO Epoch 3: [89/10940] ---- BYOL Training Loss = 0.25744590163230896
30-01-2023 15:12:54 INFO Epoch 3: [89/10940] ---- BYOL Validation Loss = 0.21094772219657898
30-01-2023 15:13:11 INFO Epoch 3: [100/10940] ---- BYOL Training Loss = 0.23650231957435608
30-01-2023 15:13:29 INFO Epoch 3: [111/10940] ---- BYOL Training Loss = 0.26183223724365234
30-01-2023 15:13:48 INFO Epoch 3: [122/10940] ---- BYOL Training Loss = 0.3042270839214325
30-01-2023 15:14:05 INFO Epoch 3: [133/10940] ---- BYOL Training Loss = 0.2929159998893738
30-01-2023 15:14:57 INFO Epoch 3: [133/10940] ---- BYOL Validation Loss = 0.23945252597332
30-01-2023 15:15:15 INFO Epoch 3: [144/10940] ---- BYOL Training Loss = 0.23289473354816437
30-01-2023 15:15:33 INFO Epoch 3: [155/10940] ---- BYOL Training Loss = 0.2255411446094513
30-01-2023 15:15:50 INFO Epoch 3: [166/10940] ---- BYOL Training Loss = 0.25106027722358704
30-01-2023 15:16:08 INFO Epoch 3: [177/10940] ---- BYOL Training Loss = 0.32221803069114685
30-01-2023 15:17:00 INFO Epoch 3: [177/10940] ---- BYOL Validation Loss = 0.2122623175382614
30-01-2023 15:17:18 INFO Epoch 3: [188/10940] ---- BYOL Training Loss = 0.34295985102653503
30-01-2023 15:17:35 INFO Epoch 3: [199/10940] ---- BYOL Training Loss = 0.24033550918102264
30-01-2023 15:17:53 INFO Epoch 3: [210/10940] ---- BYOL Training Loss = 0.23561716079711914
30-01-2023 15:18:11 INFO Epoch 3: [221/10940] ---- BYOL Training Loss = 0.22726604342460632
30-01-2023 15:19:03 INFO Epoch 3: [221/10940] ---- BYOL Validation Loss = 0.21378454566001892
30-01-2023 15:19:20 INFO Epoch 3: [232/10940] ---- BYOL Training Loss = 0.24165017902851105
30-01-2023 15:19:38 INFO Epoch 3: [243/10940] ---- BYOL Training Loss = 0.25269046425819397
30-01-2023 15:19:56 INFO Epoch 3: [254/10940] ---- BYOL Training Loss = 0.27303504943847656
30-01-2023 15:20:14 INFO Epoch 3: [265/10940] ---- BYOL Training Loss = 0.2617065906524658
30-01-2023 15:21:06 INFO Epoch 3: [265/10940] ---- BYOL Validation Loss = 0.207487553358078
30-01-2023 15:21:23 INFO Epoch 3: [276/10940] ---- BYOL Training Loss = 0.1905926913022995
30-01-2023 15:21:41 INFO Epoch 3: [287/10940] ---- BYOL Training Loss = 0.217616006731987
30-01-2023 15:21:59 INFO Epoch 3: [298/10940] ---- BYOL Training Loss = 0.31998151540756226
30-01-2023 15:22:17 INFO Epoch 3: [309/10940] ---- BYOL Training Loss = 0.26721030473709106
30-01-2023 15:23:09 INFO Epoch 3: [309/10940] ---- BYOL Validation Loss = 0.24515976011753082
30-01-2023 15:23:26 INFO Epoch 3: [320/10940] ---- BYOL Training Loss = 0.22526900470256805
30-01-2023 15:23:44 INFO Epoch 3: [331/10940] ---- BYOL Training Loss = 0.24096226692199707
30-01-2023 15:24:02 INFO Epoch 3: [342/10940] ---- BYOL Training Loss = 0.2570105493068695
30-01-2023 15:24:20 INFO Epoch 3: [353/10940] ---- BYOL Training Loss = 0.24670195579528809
30-01-2023 15:25:12 INFO Epoch 3: [353/10940] ---- BYOL Validation Loss = 0.23356859385967255
30-01-2023 15:25:29 INFO Epoch 3: [364/10940] ---- BYOL Training Loss = 0.21521484851837158
30-01-2023 15:25:47 INFO Epoch 3: [375/10940] ---- BYOL Training Loss = 0.24833834171295166
30-01-2023 15:26:05 INFO Epoch 3: [386/10940] ---- BYOL Training Loss = 0.24864864349365234
30-01-2023 15:26:23 INFO Epoch 3: [397/10940] ---- BYOL Training Loss = 0.2238367795944214
30-01-2023 15:27:15 INFO Epoch 3: [397/10940] ---- BYOL Validation Loss = 0.17277681827545166
30-01-2023 15:27:32 INFO Epoch 3: [408/10940] ---- BYOL Training Loss = 0.2341504991054535
30-01-2023 15:27:50 INFO Epoch 3: [419/10940] ---- BYOL Training Loss = 0.25012120604515076
30-01-2023 15:28:08 INFO Epoch 3: [430/10940] ---- BYOL Training Loss = 0.22716891765594482
30-01-2023 15:28:26 INFO Epoch 3: [441/10940] ---- BYOL Training Loss = 0.22706814110279083
30-01-2023 15:29:18 INFO Epoch 3: [441/10940] ---- BYOL Validation Loss = 0.20569753646850586
30-01-2023 15:29:35 INFO Epoch 3: [452/10940] ---- BYOL Training Loss = 0.27924618124961853
30-01-2023 15:29:53 INFO Epoch 3: [463/10940] ---- BYOL Training Loss = 0.3136107623577118
30-01-2023 15:30:11 INFO Epoch 3: [474/10940] ---- BYOL Training Loss = 0.31276577711105347
30-01-2023 15:30:29 INFO Epoch 3: [485/10940] ---- BYOL Training Loss = 0.24044279754161835
30-01-2023 15:31:21 INFO Epoch 3: [485/10940] ---- BYOL Validation Loss = 0.20261608064174652
30-01-2023 15:31:38 INFO Epoch 3: [496/10940] ---- BYOL Training Loss = 0.2534773647785187
30-01-2023 15:31:56 INFO Epoch 3: [507/10940] ---- BYOL Training Loss = 0.2946317195892334
30-01-2023 15:32:14 INFO Epoch 3: [518/10940] ---- BYOL Training Loss = 0.2506248354911804
30-01-2023 15:32:32 INFO Epoch 3: [529/10940] ---- BYOL Training Loss = 0.33115237951278687
30-01-2023 15:33:24 INFO Epoch 3: [529/10940] ---- BYOL Validation Loss = 0.2224414050579071
30-01-2023 15:33:41 INFO Epoch 3: [540/10940] ---- BYOL Training Loss = 0.4153596758842468
30-01-2023 15:33:59 INFO Epoch 3: [551/10940] ---- BYOL Training Loss = 0.3743975758552551
30-01-2023 15:34:17 INFO Epoch 3: [562/10940] ---- BYOL Training Loss = 0.25874191522598267
30-01-2023 15:34:35 INFO Epoch 3: [573/10940] ---- BYOL Training Loss = 0.2654092311859131
30-01-2023 15:35:27 INFO Epoch 3: [573/10940] ---- BYOL Validation Loss = 0.21014010906219482
30-01-2023 15:35:44 INFO Epoch 3: [584/10940] ---- BYOL Training Loss = 0.34552839398384094
30-01-2023 15:36:02 INFO Epoch 3: [595/10940] ---- BYOL Training Loss = 0.3139275014400482
30-01-2023 15:36:20 INFO Epoch 3: [606/10940] ---- BYOL Training Loss = 0.2940508723258972
30-01-2023 15:36:38 INFO Epoch 3: [617/10940] ---- BYOL Training Loss = 0.25153976678848267
30-01-2023 15:37:30 INFO Epoch 3: [617/10940] ---- BYOL Validation Loss = 0.2031218707561493
30-01-2023 15:37:47 INFO Epoch 3: [628/10940] ---- BYOL Training Loss = 0.2718867063522339
30-01-2023 15:38:05 INFO Epoch 3: [639/10940] ---- BYOL Training Loss = 0.2813001275062561
30-01-2023 15:38:23 INFO Epoch 3: [650/10940] ---- BYOL Training Loss = 0.2229735404253006
30-01-2023 15:38:41 INFO Epoch 3: [661/10940] ---- BYOL Training Loss = 0.2421519011259079
30-01-2023 15:39:33 INFO Epoch 3: [661/10940] ---- BYOL Validation Loss = 0.17734786868095398
30-01-2023 15:39:50 INFO Epoch 3: [672/10940] ---- BYOL Training Loss = 0.28074130415916443
30-01-2023 15:40:08 INFO Epoch 3: [683/10940] ---- BYOL Training Loss = 0.3132253885269165
30-01-2023 15:40:26 INFO Epoch 3: [694/10940] ---- BYOL Training Loss = 0.2914464473724365
30-01-2023 15:40:44 INFO Epoch 3: [705/10940] ---- BYOL Training Loss = 0.31063002347946167
30-01-2023 15:41:36 INFO Epoch 3: [705/10940] ---- BYOL Validation Loss = 0.22763705253601074
30-01-2023 15:41:53 INFO Epoch 3: [716/10940] ---- BYOL Training Loss = 0.31598615646362305
30-01-2023 15:42:11 INFO Epoch 3: [727/10940] ---- BYOL Training Loss = 0.2792089879512787
30-01-2023 15:42:29 INFO Epoch 3: [738/10940] ---- BYOL Training Loss = 0.2838600277900696
30-01-2023 15:42:47 INFO Epoch 3: [749/10940] ---- BYOL Training Loss = 0.2432391345500946
30-01-2023 15:43:39 INFO Epoch 3: [749/10940] ---- BYOL Validation Loss = 0.23668122291564941
30-01-2023 15:43:57 INFO Epoch 3: [760/10940] ---- BYOL Training Loss = 0.2127993106842041
30-01-2023 15:44:15 INFO Epoch 3: [771/10940] ---- BYOL Training Loss = 0.20865626633167267
30-01-2023 15:44:33 INFO Epoch 3: [782/10940] ---- BYOL Training Loss = 0.2744583189487457
30-01-2023 15:44:50 INFO Epoch 3: [793/10940] ---- BYOL Training Loss = 0.3638022541999817
30-01-2023 15:45:42 INFO Epoch 3: [793/10940] ---- BYOL Validation Loss = 0.1864662915468216
30-01-2023 15:46:00 INFO Epoch 3: [804/10940] ---- BYOL Training Loss = 0.3830229341983795
30-01-2023 15:46:18 INFO Epoch 3: [815/10940] ---- BYOL Training Loss = 0.336376816034317
30-01-2023 15:46:36 INFO Epoch 3: [826/10940] ---- BYOL Training Loss = 0.2588811218738556
30-01-2023 15:46:54 INFO Epoch 3: [837/10940] ---- BYOL Training Loss = 0.2432229071855545
30-01-2023 15:47:46 INFO Epoch 3: [837/10940] ---- BYOL Validation Loss = 0.1796778291463852
30-01-2023 15:48:03 INFO Epoch 3: [848/10940] ---- BYOL Training Loss = 0.22239749133586884
30-01-2023 15:48:21 INFO Epoch 3: [859/10940] ---- BYOL Training Loss = 0.24518640339374542
30-01-2023 15:48:39 INFO Epoch 3: [870/10940] ---- BYOL Training Loss = 0.23534278571605682
30-01-2023 15:48:57 INFO Epoch 3: [881/10940] ---- BYOL Training Loss = 0.20509867370128632
30-01-2023 15:49:49 INFO Epoch 3: [881/10940] ---- BYOL Validation Loss = 0.21339496970176697
30-01-2023 15:50:06 INFO Epoch 3: [892/10940] ---- BYOL Training Loss = 0.24992766976356506
30-01-2023 15:50:24 INFO Epoch 3: [903/10940] ---- BYOL Training Loss = 0.3110713064670563
30-01-2023 15:50:42 INFO Epoch 3: [914/10940] ---- BYOL Training Loss = 0.28051334619522095
30-01-2023 15:51:00 INFO Epoch 3: [925/10940] ---- BYOL Training Loss = 0.26604562997817993
30-01-2023 15:51:52 INFO Epoch 3: [925/10940] ---- BYOL Validation Loss = 0.20734919607639313
30-01-2023 15:52:10 INFO Epoch 3: [936/10940] ---- BYOL Training Loss = 0.2556177079677582
30-01-2023 15:52:28 INFO Epoch 3: [947/10940] ---- BYOL Training Loss = 0.22383585572242737
30-01-2023 15:52:45 INFO Epoch 3: [958/10940] ---- BYOL Training Loss = 0.25226259231567383
30-01-2023 15:53:03 INFO Epoch 3: [969/10940] ---- BYOL Training Loss = 0.276371031999588
30-01-2023 15:53:55 INFO Epoch 3: [969/10940] ---- BYOL Validation Loss = 0.18158316612243652
30-01-2023 15:54:13 INFO Epoch 3: [980/10940] ---- BYOL Training Loss = 0.25750309228897095
30-01-2023 15:54:31 INFO Epoch 3: [991/10940] ---- BYOL Training Loss = 0.27708354592323303
30-01-2023 15:54:49 INFO Epoch 3: [1002/10940] ---- BYOL Training Loss = 0.2811703681945801
30-01-2023 15:55:07 INFO Epoch 3: [1013/10940] ---- BYOL Training Loss = 0.23564183712005615
30-01-2023 15:55:58 INFO Epoch 3: [1013/10940] ---- BYOL Validation Loss = 0.20891572535037994
30-01-2023 15:56:16 INFO Epoch 3: [1024/10940] ---- BYOL Training Loss = 0.2537994980812073
30-01-2023 15:56:34 INFO Epoch 3: [1035/10940] ---- BYOL Training Loss = 0.2744906544685364
30-01-2023 15:56:52 INFO Epoch 3: [1046/10940] ---- BYOL Training Loss = 0.2614456117153168
30-01-2023 15:57:10 INFO Epoch 3: [1057/10940] ---- BYOL Training Loss = 0.2693932056427002
30-01-2023 15:58:02 INFO Epoch 3: [1057/10940] ---- BYOL Validation Loss = 0.1909022182226181
30-01-2023 15:58:19 INFO Epoch 3: [1068/10940] ---- BYOL Training Loss = 0.2574857771396637
30-01-2023 15:58:37 INFO Epoch 3: [1079/10940] ---- BYOL Training Loss = 0.25705984234809875
30-01-2023 15:58:55 INFO Epoch 3: [1090/10940] ---- BYOL Training Loss = 0.1965811550617218
30-01-2023 15:59:13 INFO Epoch 3: [1101/10940] ---- BYOL Training Loss = 0.2039995938539505
30-01-2023 16:00:05 INFO Epoch 3: [1101/10940] ---- BYOL Validation Loss = 0.1639835089445114
30-01-2023 16:00:22 INFO Epoch 3: [1112/10940] ---- BYOL Training Loss = 0.2287633866071701
30-01-2023 16:00:40 INFO Epoch 3: [1123/10940] ---- BYOL Training Loss = 0.19809593260288239
30-01-2023 16:00:58 INFO Epoch 3: [1134/10940] ---- BYOL Training Loss = 0.17293474078178406
30-01-2023 16:01:16 INFO Epoch 3: [1145/10940] ---- BYOL Training Loss = 0.20734544098377228
30-01-2023 16:02:08 INFO Epoch 3: [1145/10940] ---- BYOL Validation Loss = 0.18115825951099396
30-01-2023 16:02:26 INFO Epoch 3: [1156/10940] ---- BYOL Training Loss = 0.18373975157737732
30-01-2023 16:02:44 INFO Epoch 3: [1167/10940] ---- BYOL Training Loss = 0.24005047976970673
30-01-2023 16:03:02 INFO Epoch 3: [1178/10940] ---- BYOL Training Loss = 0.2812747359275818
30-01-2023 16:03:20 INFO Epoch 3: [1189/10940] ---- BYOL Training Loss = 0.26261478662490845
30-01-2023 16:04:12 INFO Epoch 3: [1189/10940] ---- BYOL Validation Loss = 0.21988312900066376
30-01-2023 16:04:29 INFO Epoch 3: [1200/10940] ---- BYOL Training Loss = 0.27490973472595215
30-01-2023 16:04:47 INFO Epoch 3: [1211/10940] ---- BYOL Training Loss = 0.35402435064315796
30-01-2023 16:05:05 INFO Epoch 3: [1222/10940] ---- BYOL Training Loss = 0.45697227120399475
30-01-2023 16:05:23 INFO Epoch 3: [1233/10940] ---- BYOL Training Loss = 0.33959174156188965
30-01-2023 16:06:15 INFO Epoch 3: [1233/10940] ---- BYOL Validation Loss = 0.22015337646007538
30-01-2023 16:06:33 INFO Epoch 3: [1244/10940] ---- BYOL Training Loss = 0.28463977575302124
30-01-2023 16:06:51 INFO Epoch 3: [1255/10940] ---- BYOL Training Loss = 0.24748539924621582
30-01-2023 16:07:09 INFO Epoch 3: [1266/10940] ---- BYOL Training Loss = 0.24719969928264618
30-01-2023 16:07:27 INFO Epoch 3: [1277/10940] ---- BYOL Training Loss = 0.2489347904920578
30-01-2023 16:08:19 INFO Epoch 3: [1277/10940] ---- BYOL Validation Loss = 0.21302779018878937
30-01-2023 16:08:36 INFO Epoch 3: [1288/10940] ---- BYOL Training Loss = 0.23241393268108368
30-01-2023 16:08:54 INFO Epoch 3: [1299/10940] ---- BYOL Training Loss = 0.22799786925315857
30-01-2023 16:09:12 INFO Epoch 3: [1310/10940] ---- BYOL Training Loss = 0.290122926235199
30-01-2023 16:09:30 INFO Epoch 3: [1321/10940] ---- BYOL Training Loss = 0.35709938406944275
30-01-2023 16:10:22 INFO Epoch 3: [1321/10940] ---- BYOL Validation Loss = 0.1795044094324112
30-01-2023 16:10:40 INFO Epoch 3: [1332/10940] ---- BYOL Training Loss = 0.27373945713043213
30-01-2023 16:10:57 INFO Epoch 3: [1343/10940] ---- BYOL Training Loss = 0.22830896079540253
30-01-2023 16:11:15 INFO Epoch 3: [1354/10940] ---- BYOL Training Loss = 0.29835206270217896
30-01-2023 16:11:33 INFO Epoch 3: [1365/10940] ---- BYOL Training Loss = 0.32926544547080994
30-01-2023 16:12:25 INFO Epoch 3: [1365/10940] ---- BYOL Validation Loss = 0.23070785403251648
30-01-2023 16:12:43 INFO Epoch 3: [1376/10940] ---- BYOL Training Loss = 0.33045491576194763
30-01-2023 16:13:01 INFO Epoch 3: [1387/10940] ---- BYOL Training Loss = 0.32108622789382935
30-01-2023 16:13:19 INFO Epoch 3: [1398/10940] ---- BYOL Training Loss = 0.2108050286769867
30-01-2023 16:13:37 INFO Epoch 3: [1409/10940] ---- BYOL Training Loss = 0.23920698463916779
30-01-2023 16:14:29 INFO Epoch 3: [1409/10940] ---- BYOL Validation Loss = 0.1580677330493927
30-01-2023 16:14:46 INFO Epoch 3: [1420/10940] ---- BYOL Training Loss = 0.27059414982795715
30-01-2023 16:15:04 INFO Epoch 3: [1431/10940] ---- BYOL Training Loss = 0.2680600583553314
30-01-2023 16:15:23 INFO Epoch 3: [1442/10940] ---- BYOL Training Loss = 0.30136775970458984
30-01-2023 16:15:41 INFO Epoch 3: [1453/10940] ---- BYOL Training Loss = 0.2820401191711426
30-01-2023 16:16:33 INFO Epoch 3: [1453/10940] ---- BYOL Validation Loss = 0.2189691960811615
30-01-2023 16:16:50 INFO Epoch 3: [1464/10940] ---- BYOL Training Loss = 0.23534801602363586
30-01-2023 16:17:08 INFO Epoch 3: [1475/10940] ---- BYOL Training Loss = 0.24020691215991974
30-01-2023 16:17:26 INFO Epoch 3: [1486/10940] ---- BYOL Training Loss = 0.22161999344825745
30-01-2023 16:17:44 INFO Epoch 3: [1497/10940] ---- BYOL Training Loss = 0.22947824001312256
30-01-2023 16:18:36 INFO Epoch 3: [1497/10940] ---- BYOL Validation Loss = 0.19774611294269562
30-01-2023 16:18:54 INFO Epoch 3: [1508/10940] ---- BYOL Training Loss = 0.263186514377594
30-01-2023 16:19:12 INFO Epoch 3: [1519/10940] ---- BYOL Training Loss = 0.2727016806602478
30-01-2023 16:19:30 INFO Epoch 3: [1530/10940] ---- BYOL Training Loss = 0.27999815344810486
30-01-2023 16:19:48 INFO Epoch 3: [1541/10940] ---- BYOL Training Loss = 0.24045304954051971
30-01-2023 16:20:40 INFO Epoch 3: [1541/10940] ---- BYOL Validation Loss = 0.20911936461925507
30-01-2023 16:20:57 INFO Epoch 3: [1552/10940] ---- BYOL Training Loss = 0.2655344605445862
30-01-2023 16:21:15 INFO Epoch 3: [1563/10940] ---- BYOL Training Loss = 0.31837597489356995
30-01-2023 16:21:33 INFO Epoch 3: [1574/10940] ---- BYOL Training Loss = 0.27119219303131104
30-01-2023 16:21:51 INFO Epoch 3: [1585/10940] ---- BYOL Training Loss = 0.27166467905044556
30-01-2023 16:22:43 INFO Epoch 3: [1585/10940] ---- BYOL Validation Loss = 0.2219030112028122
30-01-2023 16:23:01 INFO Epoch 3: [1596/10940] ---- BYOL Training Loss = 0.2353302538394928
30-01-2023 16:23:19 INFO Epoch 3: [1607/10940] ---- BYOL Training Loss = 0.21483436226844788
30-01-2023 16:23:37 INFO Epoch 3: [1618/10940] ---- BYOL Training Loss = 0.2293480634689331
30-01-2023 16:23:55 INFO Epoch 3: [1629/10940] ---- BYOL Training Loss = 0.2879822850227356
30-01-2023 16:24:47 INFO Epoch 3: [1629/10940] ---- BYOL Validation Loss = 0.22440411150455475
30-01-2023 16:25:04 INFO Epoch 3: [1640/10940] ---- BYOL Training Loss = 0.2586873471736908
30-01-2023 16:25:22 INFO Epoch 3: [1651/10940] ---- BYOL Training Loss = 0.17929360270500183
30-01-2023 16:25:41 INFO Epoch 3: [1662/10940] ---- BYOL Training Loss = 0.22157344222068787
30-01-2023 16:25:59 INFO Epoch 3: [1673/10940] ---- BYOL Training Loss = 0.22288544476032257
30-01-2023 16:26:50 INFO Epoch 3: [1673/10940] ---- BYOL Validation Loss = 0.2149389237165451
30-01-2023 16:27:08 INFO Epoch 3: [1684/10940] ---- BYOL Training Loss = 0.28015241026878357
30-01-2023 16:27:26 INFO Epoch 3: [1695/10940] ---- BYOL Training Loss = 0.2886018455028534
30-01-2023 16:27:44 INFO Epoch 3: [1706/10940] ---- BYOL Training Loss = 0.2496984899044037
30-01-2023 16:28:02 INFO Epoch 3: [1717/10940] ---- BYOL Training Loss = 0.2321699857711792
30-01-2023 16:28:54 INFO Epoch 3: [1717/10940] ---- BYOL Validation Loss = 0.22457249462604523
30-01-2023 16:29:12 INFO Epoch 3: [1728/10940] ---- BYOL Training Loss = 0.24099743366241455
30-01-2023 16:29:30 INFO Epoch 3: [1739/10940] ---- BYOL Training Loss = 0.2334839105606079
30-01-2023 16:29:48 INFO Epoch 3: [1750/10940] ---- BYOL Training Loss = 0.23920464515686035
30-01-2023 16:30:05 INFO Epoch 3: [1761/10940] ---- BYOL Training Loss = 0.26238811016082764
30-01-2023 16:30:57 INFO Epoch 3: [1761/10940] ---- BYOL Validation Loss = 0.2109774649143219
30-01-2023 16:31:15 INFO Epoch 3: [1772/10940] ---- BYOL Training Loss = 0.23540493845939636
30-01-2023 16:31:33 INFO Epoch 3: [1783/10940] ---- BYOL Training Loss = 0.18808844685554504
30-01-2023 16:31:51 INFO Epoch 3: [1794/10940] ---- BYOL Training Loss = 0.24584154784679413
30-01-2023 16:32:09 INFO Epoch 3: [1805/10940] ---- BYOL Training Loss = 0.22034724056720734
30-01-2023 16:33:01 INFO Epoch 3: [1805/10940] ---- BYOL Validation Loss = 0.18362614512443542
30-01-2023 16:33:19 INFO Epoch 3: [1816/10940] ---- BYOL Training Loss = 0.19515471160411835
30-01-2023 16:33:36 INFO Epoch 3: [1827/10940] ---- BYOL Training Loss = 0.3281816840171814
30-01-2023 16:33:55 INFO Epoch 3: [1838/10940] ---- BYOL Training Loss = 0.36410653591156006
30-01-2023 16:34:13 INFO Epoch 3: [1849/10940] ---- BYOL Training Loss = 0.31160643696784973
30-01-2023 16:35:05 INFO Epoch 3: [1849/10940] ---- BYOL Validation Loss = 0.22323299944400787
30-01-2023 16:35:23 INFO Epoch 3: [1860/10940] ---- BYOL Training Loss = 0.24280421435832977
30-01-2023 16:35:41 INFO Epoch 3: [1871/10940] ---- BYOL Training Loss = 0.2464388608932495
30-01-2023 16:35:59 INFO Epoch 3: [1882/10940] ---- BYOL Training Loss = 0.30015429854393005
30-01-2023 16:36:17 INFO Epoch 3: [1893/10940] ---- BYOL Training Loss = 0.2759517431259155
30-01-2023 16:37:08 INFO Epoch 3: [1893/10940] ---- BYOL Validation Loss = 0.21173028647899628
30-01-2023 16:37:26 INFO Epoch 3: [1904/10940] ---- BYOL Training Loss = 0.2912856638431549
30-01-2023 16:37:44 INFO Epoch 3: [1915/10940] ---- BYOL Training Loss = 0.25388169288635254
30-01-2023 16:38:02 INFO Epoch 3: [1926/10940] ---- BYOL Training Loss = 0.22834455966949463
30-01-2023 16:38:20 INFO Epoch 3: [1937/10940] ---- BYOL Training Loss = 0.23110385239124298
30-01-2023 16:39:12 INFO Epoch 3: [1937/10940] ---- BYOL Validation Loss = 0.19498947262763977
30-01-2023 16:39:30 INFO Epoch 3: [1948/10940] ---- BYOL Training Loss = 0.3128106892108917
30-01-2023 16:39:48 INFO Epoch 3: [1959/10940] ---- BYOL Training Loss = 0.3229394555091858
30-01-2023 16:40:06 INFO Epoch 3: [1970/10940] ---- BYOL Training Loss = 0.22776857018470764
30-01-2023 16:40:24 INFO Epoch 3: [1981/10940] ---- BYOL Training Loss = 0.25354892015457153
30-01-2023 16:41:15 INFO Epoch 3: [1981/10940] ---- BYOL Validation Loss = 0.18976140022277832
30-01-2023 16:41:33 INFO Epoch 3: [1992/10940] ---- BYOL Training Loss = 0.270840585231781
30-01-2023 16:41:51 INFO Epoch 3: [2003/10940] ---- BYOL Training Loss = 0.25410276651382446
30-01-2023 16:42:09 INFO Epoch 3: [2014/10940] ---- BYOL Training Loss = 0.2737883925437927
30-01-2023 16:42:27 INFO Epoch 3: [2025/10940] ---- BYOL Training Loss = 0.29121434688568115
30-01-2023 16:43:19 INFO Epoch 3: [2025/10940] ---- BYOL Validation Loss = 0.21200326085090637
30-01-2023 16:43:37 INFO Epoch 3: [2036/10940] ---- BYOL Training Loss = 0.228357195854187
30-01-2023 16:43:55 INFO Epoch 3: [2047/10940] ---- BYOL Training Loss = 0.24996189773082733
30-01-2023 16:44:13 INFO Epoch 3: [2058/10940] ---- BYOL Training Loss = 0.2957659661769867
30-01-2023 16:44:32 INFO Epoch 3: [2069/10940] ---- BYOL Training Loss = 0.2330351620912552
30-01-2023 16:45:23 INFO Epoch 3: [2069/10940] ---- BYOL Validation Loss = 0.2160167694091797
30-01-2023 16:45:41 INFO Epoch 3: [2080/10940] ---- BYOL Training Loss = 0.21601466834545135
30-01-2023 16:45:59 INFO Epoch 3: [2091/10940] ---- BYOL Training Loss = 0.28498560190200806
30-01-2023 16:46:17 INFO Epoch 3: [2102/10940] ---- BYOL Training Loss = 0.29287800192832947
30-01-2023 16:46:35 INFO Epoch 3: [2113/10940] ---- BYOL Training Loss = 0.28370749950408936
30-01-2023 16:47:27 INFO Epoch 3: [2113/10940] ---- BYOL Validation Loss = 0.22925160825252533
30-01-2023 16:47:45 INFO Epoch 3: [2124/10940] ---- BYOL Training Loss = 0.26882633566856384
30-01-2023 16:48:03 INFO Epoch 3: [2135/10940] ---- BYOL Training Loss = 0.244233176112175
30-01-2023 16:48:21 INFO Epoch 3: [2146/10940] ---- BYOL Training Loss = 0.24191050231456757
30-01-2023 16:48:39 INFO Epoch 3: [2157/10940] ---- BYOL Training Loss = 0.21084313094615936
30-01-2023 16:49:31 INFO Epoch 3: [2157/10940] ---- BYOL Validation Loss = 0.1995176374912262
30-01-2023 16:49:48 INFO Epoch 3: [2168/10940] ---- BYOL Training Loss = 0.22279421985149384
30-01-2023 16:50:06 INFO Epoch 3: [2179/10940] ---- BYOL Training Loss = 0.22757622599601746
30-01-2023 16:50:25 INFO Epoch 3: [2190/10940] ---- BYOL Training Loss = 0.25520431995391846
30-01-2023 16:50:43 INFO Epoch 3: [2201/10940] ---- BYOL Training Loss = 0.2525990605354309
30-01-2023 16:51:35 INFO Epoch 3: [2201/10940] ---- BYOL Validation Loss = 0.18172645568847656
30-01-2023 16:51:52 INFO Epoch 3: [2212/10940] ---- BYOL Training Loss = 0.2288685142993927
30-01-2023 16:52:10 INFO Epoch 3: [2223/10940] ---- BYOL Training Loss = 0.20241758227348328
30-01-2023 16:52:29 INFO Epoch 3: [2234/10940] ---- BYOL Training Loss = 0.23355773091316223
30-01-2023 16:52:47 INFO Epoch 3: [2245/10940] ---- BYOL Training Loss = 0.2390531748533249
30-01-2023 16:53:38 INFO Epoch 3: [2245/10940] ---- BYOL Validation Loss = 0.19836831092834473
30-01-2023 16:53:56 INFO Epoch 3: [2256/10940] ---- BYOL Training Loss = 0.2447177618741989
30-01-2023 16:54:14 INFO Epoch 3: [2267/10940] ---- BYOL Training Loss = 0.2860635221004486
30-01-2023 16:54:32 INFO Epoch 3: [2278/10940] ---- BYOL Training Loss = 0.339389830827713
30-01-2023 16:54:50 INFO Epoch 3: [2289/10940] ---- BYOL Training Loss = 0.30654099583625793
30-01-2023 16:55:42 INFO Epoch 3: [2289/10940] ---- BYOL Validation Loss = 0.21929931640625
30-01-2023 16:55:59 INFO Epoch 3: [2300/10940] ---- BYOL Training Loss = 0.26719051599502563
30-01-2023 16:56:17 INFO Epoch 3: [2311/10940] ---- BYOL Training Loss = 0.24967047572135925
30-01-2023 16:56:36 INFO Epoch 3: [2322/10940] ---- BYOL Training Loss = 0.2607616186141968
30-01-2023 16:56:54 INFO Epoch 3: [2333/10940] ---- BYOL Training Loss = 0.27807632088661194
30-01-2023 16:57:46 INFO Epoch 3: [2333/10940] ---- BYOL Validation Loss = 0.21203479170799255
30-01-2023 16:58:03 INFO Epoch 3: [2344/10940] ---- BYOL Training Loss = 0.25202134251594543
30-01-2023 16:58:21 INFO Epoch 3: [2355/10940] ---- BYOL Training Loss = 0.20230619609355927
30-01-2023 16:58:39 INFO Epoch 3: [2366/10940] ---- BYOL Training Loss = 0.2131984531879425
30-01-2023 16:58:57 INFO Epoch 3: [2377/10940] ---- BYOL Training Loss = 0.2417309731245041
30-01-2023 16:59:49 INFO Epoch 3: [2377/10940] ---- BYOL Validation Loss = 0.18806923925876617
30-01-2023 17:00:07 INFO Epoch 3: [2388/10940] ---- BYOL Training Loss = 0.2454405277967453
30-01-2023 17:00:25 INFO Epoch 3: [2399/10940] ---- BYOL Training Loss = 0.17990617454051971
30-01-2023 17:00:43 INFO Epoch 3: [2410/10940] ---- BYOL Training Loss = 0.17961259186267853
30-01-2023 17:01:01 INFO Epoch 3: [2421/10940] ---- BYOL Training Loss = 0.2123728096485138
30-01-2023 17:01:53 INFO Epoch 3: [2421/10940] ---- BYOL Validation Loss = 0.1639244556427002
30-01-2023 17:02:11 INFO Epoch 3: [2432/10940] ---- BYOL Training Loss = 0.2239602506160736
30-01-2023 17:02:29 INFO Epoch 3: [2443/10940] ---- BYOL Training Loss = 0.24617533385753632
30-01-2023 17:02:47 INFO Epoch 3: [2454/10940] ---- BYOL Training Loss = 0.2178700715303421
30-01-2023 17:03:05 INFO Epoch 3: [2465/10940] ---- BYOL Training Loss = 0.22174453735351562
30-01-2023 17:03:57 INFO Epoch 3: [2465/10940] ---- BYOL Validation Loss = 0.18904149532318115
30-01-2023 17:04:14 INFO Epoch 3: [2476/10940] ---- BYOL Training Loss = 0.329828143119812
30-01-2023 17:04:32 INFO Epoch 3: [2487/10940] ---- BYOL Training Loss = 0.29225319623947144
30-01-2023 17:04:50 INFO Epoch 3: [2498/10940] ---- BYOL Training Loss = 0.25807127356529236
30-01-2023 17:05:09 INFO Epoch 3: [2509/10940] ---- BYOL Training Loss = 0.23906807601451874
30-01-2023 17:06:00 INFO Epoch 3: [2509/10940] ---- BYOL Validation Loss = 0.15934821963310242
30-01-2023 17:06:18 INFO Epoch 3: [2520/10940] ---- BYOL Training Loss = 0.21698732674121857
30-01-2023 17:06:36 INFO Epoch 3: [2531/10940] ---- BYOL Training Loss = 0.2732434868812561
30-01-2023 17:06:54 INFO Epoch 3: [2542/10940] ---- BYOL Training Loss = 0.2972213923931122
30-01-2023 17:07:12 INFO Epoch 3: [2553/10940] ---- BYOL Training Loss = 0.22981083393096924
30-01-2023 17:08:04 INFO Epoch 3: [2553/10940] ---- BYOL Validation Loss = 0.17781461775302887
30-01-2023 17:08:22 INFO Epoch 3: [2564/10940] ---- BYOL Training Loss = 0.24234795570373535
30-01-2023 17:08:40 INFO Epoch 3: [2575/10940] ---- BYOL Training Loss = 0.2577472925186157
30-01-2023 17:08:58 INFO Epoch 3: [2586/10940] ---- BYOL Training Loss = 0.254810094833374
30-01-2023 17:09:16 INFO Epoch 3: [2597/10940] ---- BYOL Training Loss = 0.26923617720603943
30-01-2023 17:10:08 INFO Epoch 3: [2597/10940] ---- BYOL Validation Loss = 0.2245735377073288
30-01-2023 17:10:26 INFO Epoch 3: [2608/10940] ---- BYOL Training Loss = 0.230404332280159
30-01-2023 17:10:44 INFO Epoch 3: [2619/10940] ---- BYOL Training Loss = 0.24487507343292236
30-01-2023 17:11:02 INFO Epoch 3: [2630/10940] ---- BYOL Training Loss = 0.27670934796333313
30-01-2023 17:11:20 INFO Epoch 3: [2641/10940] ---- BYOL Training Loss = 0.2253858745098114
30-01-2023 17:12:12 INFO Epoch 3: [2641/10940] ---- BYOL Validation Loss = 0.2114591896533966
30-01-2023 17:12:30 INFO Epoch 3: [2652/10940] ---- BYOL Training Loss = 0.26121586561203003
30-01-2023 17:12:48 INFO Epoch 3: [2663/10940] ---- BYOL Training Loss = 0.26219409704208374
30-01-2023 17:13:06 INFO Epoch 3: [2674/10940] ---- BYOL Training Loss = 0.2284541130065918
30-01-2023 17:13:24 INFO Epoch 3: [2685/10940] ---- BYOL Training Loss = 0.21578416228294373
30-01-2023 17:14:16 INFO Epoch 3: [2685/10940] ---- BYOL Validation Loss = 0.15799081325531006
30-01-2023 17:14:34 INFO Epoch 3: [2696/10940] ---- BYOL Training Loss = 0.21767573058605194
30-01-2023 17:14:52 INFO Epoch 3: [2707/10940] ---- BYOL Training Loss = 0.22347982227802277
30-01-2023 17:15:10 INFO Epoch 3: [2718/10940] ---- BYOL Training Loss = 0.18785688281059265
30-01-2023 17:15:28 INFO Epoch 3: [2729/10940] ---- BYOL Training Loss = 0.18611958622932434
30-01-2023 17:16:20 INFO Epoch 3: [2729/10940] ---- BYOL Validation Loss = 0.14916838705539703
30-01-2023 17:16:37 INFO Epoch 3: [2740/10940] ---- BYOL Training Loss = 0.17460593581199646
30-01-2023 17:16:55 INFO Epoch 3: [2751/10940] ---- BYOL Training Loss = 0.1958572119474411
30-01-2023 17:17:13 INFO Epoch 3: [2762/10940] ---- BYOL Training Loss = 0.2351820021867752
30-01-2023 17:17:32 INFO Epoch 3: [2773/10940] ---- BYOL Training Loss = 0.26401880383491516
30-01-2023 17:18:23 INFO Epoch 3: [2773/10940] ---- BYOL Validation Loss = 0.1636972874403
30-01-2023 17:18:41 INFO Epoch 3: [2784/10940] ---- BYOL Training Loss = 0.269754022359848
30-01-2023 17:19:00 INFO Epoch 3: [2795/10940] ---- BYOL Training Loss = 0.23046597838401794
30-01-2023 17:19:18 INFO Epoch 3: [2806/10940] ---- BYOL Training Loss = 0.23150892555713654
30-01-2023 17:19:36 INFO Epoch 3: [2817/10940] ---- BYOL Training Loss = 0.21989615261554718
30-01-2023 17:20:27 INFO Epoch 3: [2817/10940] ---- BYOL Validation Loss = 0.17276088893413544
30-01-2023 17:20:45 INFO Epoch 3: [2828/10940] ---- BYOL Training Loss = 0.2571926712989807
30-01-2023 17:21:03 INFO Epoch 3: [2839/10940] ---- BYOL Training Loss = 0.3039732575416565
30-01-2023 17:21:21 INFO Epoch 3: [2850/10940] ---- BYOL Training Loss = 0.3243701159954071
30-01-2023 17:21:39 INFO Epoch 3: [2861/10940] ---- BYOL Training Loss = 0.2105286419391632
30-01-2023 17:22:31 INFO Epoch 3: [2861/10940] ---- BYOL Validation Loss = 0.16071884334087372
30-01-2023 17:22:49 INFO Epoch 3: [2872/10940] ---- BYOL Training Loss = 0.1783471554517746
30-01-2023 17:23:07 INFO Epoch 3: [2883/10940] ---- BYOL Training Loss = 0.19904766976833344
30-01-2023 17:23:26 INFO Epoch 3: [2894/10940] ---- BYOL Training Loss = 0.31806784868240356
30-01-2023 17:23:44 INFO Epoch 3: [2905/10940] ---- BYOL Training Loss = 0.3244718015193939
30-01-2023 17:24:36 INFO Epoch 3: [2905/10940] ---- BYOL Validation Loss = 0.1394803524017334
30-01-2023 17:24:53 INFO Epoch 3: [2916/10940] ---- BYOL Training Loss = 0.27377694845199585
30-01-2023 17:25:11 INFO Epoch 3: [2927/10940] ---- BYOL Training Loss = 0.2795064449310303
30-01-2023 17:25:29 INFO Epoch 3: [2938/10940] ---- BYOL Training Loss = 0.22533032298088074
30-01-2023 17:25:48 INFO Epoch 3: [2949/10940] ---- BYOL Training Loss = 0.2697727084159851
30-01-2023 17:26:39 INFO Epoch 3: [2949/10940] ---- BYOL Validation Loss = 0.171836718916893
30-01-2023 17:26:57 INFO Epoch 3: [2960/10940] ---- BYOL Training Loss = 0.2812264859676361
30-01-2023 17:27:16 INFO Epoch 3: [2971/10940] ---- BYOL Training Loss = 0.3129308223724365
30-01-2023 17:27:34 INFO Epoch 3: [2982/10940] ---- BYOL Training Loss = 0.2793720066547394
30-01-2023 17:27:52 INFO Epoch 3: [2993/10940] ---- BYOL Training Loss = 0.2562384307384491
30-01-2023 17:28:44 INFO Epoch 3: [2993/10940] ---- BYOL Validation Loss = 0.17115746438503265
30-01-2023 17:29:01 INFO Epoch 3: [3004/10940] ---- BYOL Training Loss = 0.22480878233909607
30-01-2023 17:29:19 INFO Epoch 3: [3015/10940] ---- BYOL Training Loss = 0.22841140627861023
30-01-2023 17:29:37 INFO Epoch 3: [3026/10940] ---- BYOL Training Loss = 0.23458914458751678
30-01-2023 17:29:55 INFO Epoch 3: [3037/10940] ---- BYOL Training Loss = 0.2133127748966217
30-01-2023 17:30:47 INFO Epoch 3: [3037/10940] ---- BYOL Validation Loss = 0.16641120612621307
30-01-2023 17:31:05 INFO Epoch 3: [3048/10940] ---- BYOL Training Loss = 0.2778405547142029
30-01-2023 17:31:23 INFO Epoch 3: [3059/10940] ---- BYOL Training Loss = 0.3094974160194397
30-01-2023 17:31:42 INFO Epoch 3: [3070/10940] ---- BYOL Training Loss = 0.2674797475337982
30-01-2023 17:32:00 INFO Epoch 3: [3081/10940] ---- BYOL Training Loss = 0.2487335205078125
30-01-2023 17:32:52 INFO Epoch 3: [3081/10940] ---- BYOL Validation Loss = 0.11453002691268921
30-01-2023 17:33:09 INFO Epoch 3: [3092/10940] ---- BYOL Training Loss = 0.25956007838249207
30-01-2023 17:33:27 INFO Epoch 3: [3103/10940] ---- BYOL Training Loss = 0.38275688886642456
30-01-2023 17:33:45 INFO Epoch 3: [3114/10940] ---- BYOL Training Loss = 0.3812514841556549
30-01-2023 17:34:03 INFO Epoch 3: [3125/10940] ---- BYOL Training Loss = 0.3309418857097626
30-01-2023 17:34:55 INFO Epoch 3: [3125/10940] ---- BYOL Validation Loss = 0.19729021191596985
30-01-2023 17:35:13 INFO Epoch 3: [3136/10940] ---- BYOL Training Loss = 0.3560985028743744
30-01-2023 17:35:31 INFO Epoch 3: [3147/10940] ---- BYOL Training Loss = 0.31421059370040894
30-01-2023 17:35:50 INFO Epoch 3: [3158/10940] ---- BYOL Training Loss = 0.2518116533756256
30-01-2023 17:36:08 INFO Epoch 3: [3169/10940] ---- BYOL Training Loss = 0.23944632709026337
30-01-2023 17:36:59 INFO Epoch 3: [3169/10940] ---- BYOL Validation Loss = 0.20077931880950928
30-01-2023 17:37:17 INFO Epoch 3: [3180/10940] ---- BYOL Training Loss = 0.30194419622421265
30-01-2023 17:37:35 INFO Epoch 3: [3191/10940] ---- BYOL Training Loss = 0.31615859270095825
30-01-2023 17:37:53 INFO Epoch 3: [3202/10940] ---- BYOL Training Loss = 0.24663767218589783
30-01-2023 17:38:12 INFO Epoch 3: [3213/10940] ---- BYOL Training Loss = 0.22395670413970947
30-01-2023 17:39:03 INFO Epoch 3: [3213/10940] ---- BYOL Validation Loss = 0.18645919859409332
30-01-2023 17:39:21 INFO Epoch 3: [3224/10940] ---- BYOL Training Loss = 0.19147519767284393
30-01-2023 17:39:40 INFO Epoch 3: [3235/10940] ---- BYOL Training Loss = 0.21625180542469025
30-01-2023 17:39:58 INFO Epoch 3: [3246/10940] ---- BYOL Training Loss = 0.2555411458015442
30-01-2023 17:40:16 INFO Epoch 3: [3257/10940] ---- BYOL Training Loss = 0.2925712466239929
30-01-2023 17:41:08 INFO Epoch 3: [3257/10940] ---- BYOL Validation Loss = 0.16951990127563477
30-01-2023 17:41:25 INFO Epoch 3: [3268/10940] ---- BYOL Training Loss = 0.26111334562301636
30-01-2023 17:41:43 INFO Epoch 3: [3279/10940] ---- BYOL Training Loss = 0.4806672930717468
30-01-2023 17:42:02 INFO Epoch 3: [3290/10940] ---- BYOL Training Loss = 0.5093854665756226
30-01-2023 17:42:20 INFO Epoch 3: [3301/10940] ---- BYOL Training Loss = 0.32374173402786255
30-01-2023 17:43:12 INFO Epoch 3: [3301/10940] ---- BYOL Validation Loss = 0.14364443719387054
30-01-2023 17:43:30 INFO Epoch 3: [3312/10940] ---- BYOL Training Loss = 0.2412487268447876
30-01-2023 17:43:48 INFO Epoch 3: [3323/10940] ---- BYOL Training Loss = 0.2513396441936493
30-01-2023 17:44:06 INFO Epoch 3: [3334/10940] ---- BYOL Training Loss = 0.28218382596969604
30-01-2023 17:44:24 INFO Epoch 3: [3345/10940] ---- BYOL Training Loss = 0.24108333885669708
30-01-2023 17:45:16 INFO Epoch 3: [3345/10940] ---- BYOL Validation Loss = 0.12638691067695618
30-01-2023 17:45:34 INFO Epoch 3: [3356/10940] ---- BYOL Training Loss = 0.18459737300872803
30-01-2023 17:45:52 INFO Epoch 3: [3367/10940] ---- BYOL Training Loss = 0.22509625554084778
30-01-2023 17:46:10 INFO Epoch 3: [3378/10940] ---- BYOL Training Loss = 0.2203223705291748
30-01-2023 17:46:28 INFO Epoch 3: [3389/10940] ---- BYOL Training Loss = 0.19898703694343567
30-01-2023 17:47:20 INFO Epoch 3: [3389/10940] ---- BYOL Validation Loss = 0.1678876131772995
30-01-2023 17:47:38 INFO Epoch 3: [3400/10940] ---- BYOL Training Loss = 0.31199365854263306
30-01-2023 17:47:56 INFO Epoch 3: [3411/10940] ---- BYOL Training Loss = 0.2890271544456482
30-01-2023 17:48:14 INFO Epoch 3: [3422/10940] ---- BYOL Training Loss = 0.26444822549819946
30-01-2023 17:48:32 INFO Epoch 3: [3433/10940] ---- BYOL Training Loss = 0.256683886051178
30-01-2023 17:49:24 INFO Epoch 3: [3433/10940] ---- BYOL Validation Loss = 0.17909274995326996
30-01-2023 17:49:42 INFO Epoch 3: [3444/10940] ---- BYOL Training Loss = 0.25203874707221985
30-01-2023 17:50:01 INFO Epoch 3: [3455/10940] ---- BYOL Training Loss = 0.3335900902748108
30-01-2023 17:50:19 INFO Epoch 3: [3466/10940] ---- BYOL Training Loss = 0.3268609642982483
30-01-2023 17:50:37 INFO Epoch 3: [3477/10940] ---- BYOL Training Loss = 0.26943865418434143
30-01-2023 17:51:29 INFO Epoch 3: [3477/10940] ---- BYOL Validation Loss = 0.16955454647541046
30-01-2023 17:51:47 INFO Epoch 3: [3488/10940] ---- BYOL Training Loss = 0.27183547616004944
30-01-2023 17:52:05 INFO Epoch 3: [3499/10940] ---- BYOL Training Loss = 0.2514362037181854
30-01-2023 17:52:23 INFO Epoch 3: [3510/10940] ---- BYOL Training Loss = 0.2531997263431549
30-01-2023 17:52:41 INFO Epoch 3: [3521/10940] ---- BYOL Training Loss = 0.2468550205230713
30-01-2023 17:53:33 INFO Epoch 3: [3521/10940] ---- BYOL Validation Loss = 0.19185127317905426
30-01-2023 17:53:51 INFO Epoch 3: [3532/10940] ---- BYOL Training Loss = 0.2584988474845886
30-01-2023 17:54:09 INFO Epoch 3: [3543/10940] ---- BYOL Training Loss = 0.17965051531791687
30-01-2023 17:54:27 INFO Epoch 3: [3554/10940] ---- BYOL Training Loss = 0.1911132037639618
30-01-2023 17:54:45 INFO Epoch 3: [3565/10940] ---- BYOL Training Loss = 0.2283974438905716
30-01-2023 17:55:37 INFO Epoch 3: [3565/10940] ---- BYOL Validation Loss = 0.18208105862140656
30-01-2023 17:55:55 INFO Epoch 3: [3576/10940] ---- BYOL Training Loss = 0.2553698420524597
30-01-2023 17:56:13 INFO Epoch 3: [3587/10940] ---- BYOL Training Loss = 0.2868073582649231
30-01-2023 17:56:31 INFO Epoch 3: [3598/10940] ---- BYOL Training Loss = 0.2438928186893463
30-01-2023 17:56:50 INFO Epoch 3: [3609/10940] ---- BYOL Training Loss = 0.19187863171100616
30-01-2023 17:57:42 INFO Epoch 3: [3609/10940] ---- BYOL Validation Loss = 0.1616652011871338
30-01-2023 17:57:59 INFO Epoch 3: [3620/10940] ---- BYOL Training Loss = 0.2510179281234741
30-01-2023 17:58:18 INFO Epoch 3: [3631/10940] ---- BYOL Training Loss = 0.2477942407131195
30-01-2023 17:58:36 INFO Epoch 3: [3642/10940] ---- BYOL Training Loss = 0.31179124116897583
30-01-2023 17:58:54 INFO Epoch 3: [3653/10940] ---- BYOL Training Loss = 0.2848135232925415
30-01-2023 17:59:46 INFO Epoch 3: [3653/10940] ---- BYOL Validation Loss = 0.1972067505121231
30-01-2023 18:00:04 INFO Epoch 3: [3664/10940] ---- BYOL Training Loss = 0.23950591683387756
30-01-2023 18:00:22 INFO Epoch 3: [3675/10940] ---- BYOL Training Loss = 0.254960834980011
30-01-2023 18:00:40 INFO Epoch 3: [3686/10940] ---- BYOL Training Loss = 0.26236554980278015
30-01-2023 18:00:59 INFO Epoch 3: [3697/10940] ---- BYOL Training Loss = 0.2920052707195282
30-01-2023 18:01:50 INFO Epoch 3: [3697/10940] ---- BYOL Validation Loss = 0.2158094346523285
30-01-2023 18:02:08 INFO Epoch 3: [3708/10940] ---- BYOL Training Loss = 0.32667064666748047
30-01-2023 18:02:26 INFO Epoch 3: [3719/10940] ---- BYOL Training Loss = 0.2777016758918762
30-01-2023 18:02:44 INFO Epoch 3: [3730/10940] ---- BYOL Training Loss = 0.21657617390155792
30-01-2023 18:03:03 INFO Epoch 3: [3741/10940] ---- BYOL Training Loss = 0.26498275995254517
30-01-2023 18:03:55 INFO Epoch 3: [3741/10940] ---- BYOL Validation Loss = 0.20961427688598633
30-01-2023 18:04:13 INFO Epoch 3: [3752/10940] ---- BYOL Training Loss = 0.20007213950157166
30-01-2023 18:04:31 INFO Epoch 3: [3763/10940] ---- BYOL Training Loss = 0.26542288064956665
30-01-2023 18:04:49 INFO Epoch 3: [3774/10940] ---- BYOL Training Loss = 0.2554067075252533
30-01-2023 18:05:07 INFO Epoch 3: [3785/10940] ---- BYOL Training Loss = 0.28027844429016113
30-01-2023 18:05:59 INFO Epoch 3: [3785/10940] ---- BYOL Validation Loss = 0.12094379961490631
30-01-2023 18:06:17 INFO Epoch 3: [3796/10940] ---- BYOL Training Loss = 0.3257071375846863
30-01-2023 18:06:35 INFO Epoch 3: [3807/10940] ---- BYOL Training Loss = 0.331766277551651
30-01-2023 18:06:54 INFO Epoch 3: [3818/10940] ---- BYOL Training Loss = 0.326854944229126
30-01-2023 18:07:12 INFO Epoch 3: [3829/10940] ---- BYOL Training Loss = 0.28956758975982666
30-01-2023 18:08:04 INFO Epoch 3: [3829/10940] ---- BYOL Validation Loss = 0.20325298607349396
30-01-2023 18:08:22 INFO Epoch 3: [3840/10940] ---- BYOL Training Loss = 0.2611934542655945
30-01-2023 18:08:40 INFO Epoch 3: [3851/10940] ---- BYOL Training Loss = 0.2499805986881256
30-01-2023 18:08:58 INFO Epoch 3: [3862/10940] ---- BYOL Training Loss = 0.22642309963703156
30-01-2023 18:09:16 INFO Epoch 3: [3873/10940] ---- BYOL Training Loss = 0.2913646697998047
30-01-2023 18:10:08 INFO Epoch 3: [3873/10940] ---- BYOL Validation Loss = 0.1443207561969757
30-01-2023 18:10:26 INFO Epoch 3: [3884/10940] ---- BYOL Training Loss = 0.28874656558036804
30-01-2023 18:10:45 INFO Epoch 3: [3895/10940] ---- BYOL Training Loss = 0.22276678681373596
30-01-2023 18:11:03 INFO Epoch 3: [3906/10940] ---- BYOL Training Loss = 0.19735439121723175
30-01-2023 18:11:21 INFO Epoch 3: [3917/10940] ---- BYOL Training Loss = 0.23555774986743927
30-01-2023 18:12:13 INFO Epoch 3: [3917/10940] ---- BYOL Validation Loss = 0.10941318422555923
30-01-2023 18:12:31 INFO Epoch 3: [3928/10940] ---- BYOL Training Loss = 0.24057741463184357
30-01-2023 18:12:49 INFO Epoch 3: [3939/10940] ---- BYOL Training Loss = 0.3004988133907318
30-01-2023 18:13:08 INFO Epoch 3: [3950/10940] ---- BYOL Training Loss = 0.30739930272102356
30-01-2023 18:13:26 INFO Epoch 3: [3961/10940] ---- BYOL Training Loss = 0.2361847460269928
30-01-2023 18:14:18 INFO Epoch 3: [3961/10940] ---- BYOL Validation Loss = 0.17003750801086426
30-01-2023 18:14:36 INFO Epoch 3: [3972/10940] ---- BYOL Training Loss = 0.21439985930919647
30-01-2023 18:14:54 INFO Epoch 3: [3983/10940] ---- BYOL Training Loss = 0.2550695836544037
30-01-2023 18:15:12 INFO Epoch 3: [3994/10940] ---- BYOL Training Loss = 0.2395951747894287
30-01-2023 18:15:30 INFO Epoch 3: [4005/10940] ---- BYOL Training Loss = 0.22331702709197998
30-01-2023 18:16:22 INFO Epoch 3: [4005/10940] ---- BYOL Validation Loss = 0.09203212708234787
30-01-2023 18:16:40 INFO Epoch 3: [4016/10940] ---- BYOL Training Loss = 0.22199709713459015
30-01-2023 18:16:58 INFO Epoch 3: [4027/10940] ---- BYOL Training Loss = 0.19806377589702606
30-01-2023 18:17:17 INFO Epoch 3: [4038/10940] ---- BYOL Training Loss = 0.19863475859165192
30-01-2023 18:17:35 INFO Epoch 3: [4049/10940] ---- BYOL Training Loss = 0.22113578021526337
30-01-2023 18:18:27 INFO Epoch 3: [4049/10940] ---- BYOL Validation Loss = 0.10364300012588501
30-01-2023 18:18:44 INFO Epoch 3: [4060/10940] ---- BYOL Training Loss = 0.20031051337718964
30-01-2023 18:19:03 INFO Epoch 3: [4071/10940] ---- BYOL Training Loss = 0.19829869270324707
30-01-2023 18:19:21 INFO Epoch 3: [4082/10940] ---- BYOL Training Loss = 0.17183917760849
30-01-2023 18:19:39 INFO Epoch 3: [4093/10940] ---- BYOL Training Loss = 0.18869450688362122
30-01-2023 18:20:31 INFO Epoch 3: [4093/10940] ---- BYOL Validation Loss = 0.09596701711416245
30-01-2023 18:20:49 INFO Epoch 3: [4104/10940] ---- BYOL Training Loss = 0.20068247616291046
30-01-2023 18:21:07 INFO Epoch 3: [4115/10940] ---- BYOL Training Loss = 0.1895483434200287
30-01-2023 18:21:25 INFO Epoch 3: [4126/10940] ---- BYOL Training Loss = 0.24960367381572723
30-01-2023 18:21:44 INFO Epoch 3: [4137/10940] ---- BYOL Training Loss = 0.20341643691062927
30-01-2023 18:22:36 INFO Epoch 3: [4137/10940] ---- BYOL Validation Loss = 0.15954217314720154
30-01-2023 18:22:54 INFO Epoch 3: [4148/10940] ---- BYOL Training Loss = 0.3013782501220703
30-01-2023 18:23:12 INFO Epoch 3: [4159/10940] ---- BYOL Training Loss = 0.3794832229614258
30-01-2023 18:23:30 INFO Epoch 3: [4170/10940] ---- BYOL Training Loss = 0.3395901620388031
30-01-2023 18:23:48 INFO Epoch 3: [4181/10940] ---- BYOL Training Loss = 0.32917457818984985
30-01-2023 18:24:40 INFO Epoch 3: [4181/10940] ---- BYOL Validation Loss = 0.1518906205892563
30-01-2023 18:24:58 INFO Epoch 3: [4192/10940] ---- BYOL Training Loss = 0.262503445148468
30-01-2023 18:25:17 INFO Epoch 3: [4203/10940] ---- BYOL Training Loss = 0.2338705062866211
30-01-2023 18:25:35 INFO Epoch 3: [4214/10940] ---- BYOL Training Loss = 0.2759610414505005
30-01-2023 18:25:53 INFO Epoch 3: [4225/10940] ---- BYOL Training Loss = 0.3434804081916809
30-01-2023 18:26:45 INFO Epoch 3: [4225/10940] ---- BYOL Validation Loss = 0.096831314265728
30-01-2023 18:27:03 INFO Epoch 3: [4236/10940] ---- BYOL Training Loss = 0.4214935302734375
30-01-2023 18:27:21 INFO Epoch 3: [4247/10940] ---- BYOL Training Loss = 0.2658022940158844
30-01-2023 18:27:39 INFO Epoch 3: [4258/10940] ---- BYOL Training Loss = 0.29940494894981384
30-01-2023 18:27:58 INFO Epoch 3: [4269/10940] ---- BYOL Training Loss = 0.33672529458999634
30-01-2023 18:28:50 INFO Epoch 3: [4269/10940] ---- BYOL Validation Loss = 0.16706477105617523
30-01-2023 18:29:08 INFO Epoch 3: [4280/10940] ---- BYOL Training Loss = 0.25469303131103516
30-01-2023 18:29:26 INFO Epoch 3: [4291/10940] ---- BYOL Training Loss = 0.22297906875610352
30-01-2023 18:29:44 INFO Epoch 3: [4302/10940] ---- BYOL Training Loss = 0.24459496140480042
30-01-2023 18:30:02 INFO Epoch 3: [4313/10940] ---- BYOL Training Loss = 0.3319666385650635
30-01-2023 18:30:54 INFO Epoch 3: [4313/10940] ---- BYOL Validation Loss = 0.22609925270080566
30-01-2023 18:31:12 INFO Epoch 3: [4324/10940] ---- BYOL Training Loss = 0.45559757947921753
30-01-2023 18:31:30 INFO Epoch 3: [4335/10940] ---- BYOL Training Loss = 0.3926313817501068
30-01-2023 18:31:49 INFO Epoch 3: [4346/10940] ---- BYOL Training Loss = 0.23941859602928162
30-01-2023 18:32:07 INFO Epoch 3: [4357/10940] ---- BYOL Training Loss = 0.3866119086742401
30-01-2023 18:32:59 INFO Epoch 3: [4357/10940] ---- BYOL Validation Loss = 0.18031466007232666
30-01-2023 18:33:16 INFO Epoch 3: [4368/10940] ---- BYOL Training Loss = 0.33760401606559753
30-01-2023 18:33:35 INFO Epoch 3: [4379/10940] ---- BYOL Training Loss = 0.21669089794158936
30-01-2023 18:33:53 INFO Epoch 3: [4390/10940] ---- BYOL Training Loss = 0.20266631245613098
30-01-2023 18:34:12 INFO Epoch 3: [4401/10940] ---- BYOL Training Loss = 0.2510683536529541
30-01-2023 18:35:03 INFO Epoch 3: [4401/10940] ---- BYOL Validation Loss = 0.2299489825963974
30-01-2023 18:35:21 INFO Epoch 3: [4412/10940] ---- BYOL Training Loss = 0.3368833363056183
30-01-2023 18:35:39 INFO Epoch 3: [4423/10940] ---- BYOL Training Loss = 0.31866222620010376
30-01-2023 18:35:58 INFO Epoch 3: [4434/10940] ---- BYOL Training Loss = 0.22157171368598938
30-01-2023 18:36:16 INFO Epoch 3: [4445/10940] ---- BYOL Training Loss = 0.19731537997722626
30-01-2023 18:37:08 INFO Epoch 3: [4445/10940] ---- BYOL Validation Loss = 0.18597163259983063
30-01-2023 18:37:26 INFO Epoch 3: [4456/10940] ---- BYOL Training Loss = 0.25500744581222534
30-01-2023 18:37:44 INFO Epoch 3: [4467/10940] ---- BYOL Training Loss = 0.2891382575035095
30-01-2023 18:38:02 INFO Epoch 3: [4478/10940] ---- BYOL Training Loss = 0.24202831089496613
30-01-2023 18:38:21 INFO Epoch 3: [4489/10940] ---- BYOL Training Loss = 0.27523961663246155
30-01-2023 18:39:12 INFO Epoch 3: [4489/10940] ---- BYOL Validation Loss = 0.16711831092834473
30-01-2023 18:39:30 INFO Epoch 3: [4500/10940] ---- BYOL Training Loss = 0.285535603761673
30-01-2023 18:39:49 INFO Epoch 3: [4511/10940] ---- BYOL Training Loss = 0.253810316324234
30-01-2023 18:40:07 INFO Epoch 3: [4522/10940] ---- BYOL Training Loss = 0.28159189224243164
30-01-2023 18:40:25 INFO Epoch 3: [4533/10940] ---- BYOL Training Loss = 0.27825888991355896
30-01-2023 18:41:17 INFO Epoch 3: [4533/10940] ---- BYOL Validation Loss = 0.2305452823638916
30-01-2023 18:41:35 INFO Epoch 3: [4544/10940] ---- BYOL Training Loss = 0.32341891527175903
30-01-2023 18:41:53 INFO Epoch 3: [4555/10940] ---- BYOL Training Loss = 0.30917876958847046
30-01-2023 18:42:12 INFO Epoch 3: [4566/10940] ---- BYOL Training Loss = 0.23420432209968567
30-01-2023 18:42:30 INFO Epoch 3: [4577/10940] ---- BYOL Training Loss = 0.26689842343330383
30-01-2023 18:43:22 INFO Epoch 3: [4577/10940] ---- BYOL Validation Loss = 0.18241849541664124
30-01-2023 18:43:40 INFO Epoch 3: [4588/10940] ---- BYOL Training Loss = 0.1991705596446991
30-01-2023 18:43:58 INFO Epoch 3: [4599/10940] ---- BYOL Training Loss = 0.19919615983963013
30-01-2023 18:44:17 INFO Epoch 3: [4610/10940] ---- BYOL Training Loss = 0.2983998954296112
30-01-2023 18:44:35 INFO Epoch 3: [4621/10940] ---- BYOL Training Loss = 0.30075591802597046
30-01-2023 18:45:27 INFO Epoch 3: [4621/10940] ---- BYOL Validation Loss = 0.19229038059711456
30-01-2023 18:45:45 INFO Epoch 3: [4632/10940] ---- BYOL Training Loss = 0.2562815248966217
30-01-2023 18:46:03 INFO Epoch 3: [4643/10940] ---- BYOL Training Loss = 0.3122017979621887
30-01-2023 18:46:21 INFO Epoch 3: [4654/10940] ---- BYOL Training Loss = 0.28205108642578125
30-01-2023 18:46:40 INFO Epoch 3: [4665/10940] ---- BYOL Training Loss = 0.23291628062725067
30-01-2023 18:47:31 INFO Epoch 3: [4665/10940] ---- BYOL Validation Loss = 0.21625635027885437
30-01-2023 18:47:49 INFO Epoch 3: [4676/10940] ---- BYOL Training Loss = 0.20181488990783691
30-01-2023 18:48:08 INFO Epoch 3: [4687/10940] ---- BYOL Training Loss = 0.2379758656024933
30-01-2023 18:48:26 INFO Epoch 3: [4698/10940] ---- BYOL Training Loss = 0.3190559446811676
30-01-2023 18:48:44 INFO Epoch 3: [4709/10940] ---- BYOL Training Loss = 0.2487226277589798
30-01-2023 18:49:36 INFO Epoch 3: [4709/10940] ---- BYOL Validation Loss = 0.15120908617973328
30-01-2023 18:49:54 INFO Epoch 3: [4720/10940] ---- BYOL Training Loss = 0.300739586353302
30-01-2023 18:50:12 INFO Epoch 3: [4731/10940] ---- BYOL Training Loss = 0.3305985927581787
30-01-2023 18:50:31 INFO Epoch 3: [4742/10940] ---- BYOL Training Loss = 0.2260085642337799
30-01-2023 18:50:49 INFO Epoch 3: [4753/10940] ---- BYOL Training Loss = 0.1825154721736908
30-01-2023 18:51:41 INFO Epoch 3: [4753/10940] ---- BYOL Validation Loss = 0.19558191299438477
30-01-2023 18:51:59 INFO Epoch 3: [4764/10940] ---- BYOL Training Loss = 0.2648523151874542
30-01-2023 18:52:17 INFO Epoch 3: [4775/10940] ---- BYOL Training Loss = 0.2687224745750427
30-01-2023 18:52:36 INFO Epoch 3: [4786/10940] ---- BYOL Training Loss = 0.1909588873386383
30-01-2023 18:52:54 INFO Epoch 3: [4797/10940] ---- BYOL Training Loss = 0.2662496864795685
30-01-2023 18:53:46 INFO Epoch 3: [4797/10940] ---- BYOL Validation Loss = 0.1684464067220688
30-01-2023 18:54:04 INFO Epoch 3: [4808/10940] ---- BYOL Training Loss = 0.36122527718544006
30-01-2023 18:54:22 INFO Epoch 3: [4819/10940] ---- BYOL Training Loss = 0.31779417395591736
30-01-2023 18:54:40 INFO Epoch 3: [4830/10940] ---- BYOL Training Loss = 0.26974400877952576
30-01-2023 18:54:59 INFO Epoch 3: [4841/10940] ---- BYOL Training Loss = 0.19967599213123322
30-01-2023 18:55:51 INFO Epoch 3: [4841/10940] ---- BYOL Validation Loss = 0.19266022741794586
30-01-2023 18:56:08 INFO Epoch 3: [4852/10940] ---- BYOL Training Loss = 0.19930708408355713
30-01-2023 18:56:27 INFO Epoch 3: [4863/10940] ---- BYOL Training Loss = 0.22174286842346191
30-01-2023 18:56:45 INFO Epoch 3: [4874/10940] ---- BYOL Training Loss = 0.20518286526203156
30-01-2023 18:57:03 INFO Epoch 3: [4885/10940] ---- BYOL Training Loss = 0.2889597713947296
30-01-2023 18:57:55 INFO Epoch 3: [4885/10940] ---- BYOL Validation Loss = 0.16625897586345673
30-01-2023 18:58:13 INFO Epoch 3: [4896/10940] ---- BYOL Training Loss = 0.3066839575767517
30-01-2023 18:58:32 INFO Epoch 3: [4907/10940] ---- BYOL Training Loss = 0.23572519421577454
30-01-2023 18:58:50 INFO Epoch 3: [4918/10940] ---- BYOL Training Loss = 0.21076428890228271
30-01-2023 18:59:08 INFO Epoch 3: [4929/10940] ---- BYOL Training Loss = 0.2359086275100708
30-01-2023 19:00:00 INFO Epoch 3: [4929/10940] ---- BYOL Validation Loss = 0.17050130665302277
30-01-2023 19:00:18 INFO Epoch 3: [4940/10940] ---- BYOL Training Loss = 0.24564507603645325
30-01-2023 19:00:36 INFO Epoch 3: [4951/10940] ---- BYOL Training Loss = 0.3011435568332672
30-01-2023 19:00:55 INFO Epoch 3: [4962/10940] ---- BYOL Training Loss = 0.29580575227737427
30-01-2023 19:01:13 INFO Epoch 3: [4973/10940] ---- BYOL Training Loss = 0.18956926465034485
30-01-2023 19:02:05 INFO Epoch 3: [4973/10940] ---- BYOL Validation Loss = 0.14108988642692566
30-01-2023 19:02:23 INFO Epoch 3: [4984/10940] ---- BYOL Training Loss = 0.21699437499046326
30-01-2023 19:02:41 INFO Epoch 3: [4995/10940] ---- BYOL Training Loss = 0.20604462921619415
30-01-2023 19:03:00 INFO Epoch 3: [5006/10940] ---- BYOL Training Loss = 0.2282470464706421
30-01-2023 19:03:18 INFO Epoch 3: [5017/10940] ---- BYOL Training Loss = 0.31634020805358887
30-01-2023 19:04:10 INFO Epoch 3: [5017/10940] ---- BYOL Validation Loss = 0.14368759095668793
30-01-2023 19:04:28 INFO Epoch 3: [5028/10940] ---- BYOL Training Loss = 0.2245214879512787
30-01-2023 19:04:46 INFO Epoch 3: [5039/10940] ---- BYOL Training Loss = 0.3010079264640808
30-01-2023 19:05:05 INFO Epoch 3: [5050/10940] ---- BYOL Training Loss = 0.3362022042274475
30-01-2023 19:05:23 INFO Epoch 3: [5061/10940] ---- BYOL Training Loss = 0.2383609116077423
30-01-2023 19:06:15 INFO Epoch 3: [5061/10940] ---- BYOL Validation Loss = 0.14264287054538727
30-01-2023 19:06:33 INFO Epoch 3: [5072/10940] ---- BYOL Training Loss = 0.20532500743865967
30-01-2023 19:06:51 INFO Epoch 3: [5083/10940] ---- BYOL Training Loss = 0.289662629365921
30-01-2023 19:07:10 INFO Epoch 3: [5094/10940] ---- BYOL Training Loss = 0.3146178126335144
30-01-2023 19:07:28 INFO Epoch 3: [5105/10940] ---- BYOL Training Loss = 0.3233264982700348
30-01-2023 19:08:20 INFO Epoch 3: [5105/10940] ---- BYOL Validation Loss = 0.1945294439792633
30-01-2023 19:08:38 INFO Epoch 3: [5116/10940] ---- BYOL Training Loss = 0.3155166506767273
30-01-2023 19:08:56 INFO Epoch 3: [5127/10940] ---- BYOL Training Loss = 0.24897649884223938
30-01-2023 19:09:15 INFO Epoch 3: [5138/10940] ---- BYOL Training Loss = 0.18145017325878143
30-01-2023 19:09:33 INFO Epoch 3: [5149/10940] ---- BYOL Training Loss = 0.17670045793056488
30-01-2023 19:10:25 INFO Epoch 3: [5149/10940] ---- BYOL Validation Loss = 0.14222471415996552
30-01-2023 19:10:43 INFO Epoch 3: [5160/10940] ---- BYOL Training Loss = 0.2662762403488159
30-01-2023 19:11:01 INFO Epoch 3: [5171/10940] ---- BYOL Training Loss = 0.2588283121585846
30-01-2023 19:11:20 INFO Epoch 3: [5182/10940] ---- BYOL Training Loss = 0.1870223879814148
30-01-2023 19:11:38 INFO Epoch 3: [5193/10940] ---- BYOL Training Loss = 0.2288798838853836
30-01-2023 19:12:30 INFO Epoch 3: [5193/10940] ---- BYOL Validation Loss = 0.16072988510131836
30-01-2023 19:12:48 INFO Epoch 3: [5204/10940] ---- BYOL Training Loss = 0.22754375636577606
30-01-2023 19:13:06 INFO Epoch 3: [5215/10940] ---- BYOL Training Loss = 0.197749525308609
30-01-2023 19:13:25 INFO Epoch 3: [5226/10940] ---- BYOL Training Loss = 0.24201259016990662
30-01-2023 19:13:43 INFO Epoch 3: [5237/10940] ---- BYOL Training Loss = 0.2588041126728058
30-01-2023 19:14:35 INFO Epoch 3: [5237/10940] ---- BYOL Validation Loss = 0.1209573745727539
30-01-2023 19:14:53 INFO Epoch 3: [5248/10940] ---- BYOL Training Loss = 0.23664891719818115
30-01-2023 19:15:11 INFO Epoch 3: [5259/10940] ---- BYOL Training Loss = 0.23115620017051697
30-01-2023 19:15:30 INFO Epoch 3: [5270/10940] ---- BYOL Training Loss = 0.2606923580169678
30-01-2023 19:15:48 INFO Epoch 3: [5281/10940] ---- BYOL Training Loss = 0.20616655051708221
30-01-2023 19:16:40 INFO Epoch 3: [5281/10940] ---- BYOL Validation Loss = 0.15163768827915192
30-01-2023 19:16:58 INFO Epoch 3: [5292/10940] ---- BYOL Training Loss = 0.2388732135295868
30-01-2023 19:17:16 INFO Epoch 3: [5303/10940] ---- BYOL Training Loss = 0.2371729612350464
30-01-2023 19:17:35 INFO Epoch 3: [5314/10940] ---- BYOL Training Loss = 0.2135755568742752
30-01-2023 19:17:53 INFO Epoch 3: [5325/10940] ---- BYOL Training Loss = 0.23090973496437073
30-01-2023 19:18:45 INFO Epoch 3: [5325/10940] ---- BYOL Validation Loss = 0.10862462222576141
30-01-2023 19:19:03 INFO Epoch 3: [5336/10940] ---- BYOL Training Loss = 0.2981676459312439
30-01-2023 19:19:21 INFO Epoch 3: [5347/10940] ---- BYOL Training Loss = 0.3046896457672119
30-01-2023 19:19:40 INFO Epoch 3: [5358/10940] ---- BYOL Training Loss = 0.22209124267101288
30-01-2023 19:19:58 INFO Epoch 3: [5369/10940] ---- BYOL Training Loss = 0.24225525557994843
30-01-2023 19:20:50 INFO Epoch 3: [5369/10940] ---- BYOL Validation Loss = 0.15764440596103668
30-01-2023 19:21:08 INFO Epoch 3: [5380/10940] ---- BYOL Training Loss = 0.3347266912460327
30-01-2023 19:21:26 INFO Epoch 3: [5391/10940] ---- BYOL Training Loss = 0.35970041155815125
30-01-2023 19:21:45 INFO Epoch 3: [5402/10940] ---- BYOL Training Loss = 0.2855589985847473
30-01-2023 19:22:03 INFO Epoch 3: [5413/10940] ---- BYOL Training Loss = 0.26789480447769165
30-01-2023 19:22:55 INFO Epoch 3: [5413/10940] ---- BYOL Validation Loss = 0.16894829273223877
30-01-2023 19:23:13 INFO Epoch 3: [5424/10940] ---- BYOL Training Loss = 0.30465221405029297
30-01-2023 19:23:31 INFO Epoch 3: [5435/10940] ---- BYOL Training Loss = 0.26301059126853943
30-01-2023 19:23:50 INFO Epoch 3: [5446/10940] ---- BYOL Training Loss = 0.26203468441963196
30-01-2023 19:24:08 INFO Epoch 3: [5457/10940] ---- BYOL Training Loss = 0.2606777846813202
30-01-2023 19:25:00 INFO Epoch 3: [5457/10940] ---- BYOL Validation Loss = 0.1966487616300583
30-01-2023 19:25:18 INFO Epoch 3: [5468/10940] ---- BYOL Training Loss = 0.2204645574092865
30-01-2023 19:25:36 INFO Epoch 3: [5479/10940] ---- BYOL Training Loss = 0.21859169006347656
30-01-2023 19:25:55 INFO Epoch 3: [5490/10940] ---- BYOL Training Loss = 0.20223411917686462
30-01-2023 19:26:13 INFO Epoch 3: [5501/10940] ---- BYOL Training Loss = 0.19796893000602722
30-01-2023 19:27:05 INFO Epoch 3: [5501/10940] ---- BYOL Validation Loss = 0.16365782916545868
30-01-2023 19:27:23 INFO Epoch 3: [5512/10940] ---- BYOL Training Loss = 0.20757336914539337
30-01-2023 19:27:41 INFO Epoch 3: [5523/10940] ---- BYOL Training Loss = 0.2200971096754074
30-01-2023 19:28:00 INFO Epoch 3: [5534/10940] ---- BYOL Training Loss = 0.24919016659259796
30-01-2023 19:28:19 INFO Epoch 3: [5545/10940] ---- BYOL Training Loss = 0.2229260504245758
30-01-2023 19:29:10 INFO Epoch 3: [5545/10940] ---- BYOL Validation Loss = 0.14366039633750916
30-01-2023 19:29:28 INFO Epoch 3: [5556/10940] ---- BYOL Training Loss = 0.24810698628425598
30-01-2023 19:29:47 INFO Epoch 3: [5567/10940] ---- BYOL Training Loss = 0.2647573947906494
30-01-2023 19:30:05 INFO Epoch 3: [5578/10940] ---- BYOL Training Loss = 0.2074776142835617
30-01-2023 19:30:24 INFO Epoch 3: [5589/10940] ---- BYOL Training Loss = 0.2706497311592102
30-01-2023 19:31:16 INFO Epoch 3: [5589/10940] ---- BYOL Validation Loss = 0.15099576115608215
30-01-2023 19:31:34 INFO Epoch 3: [5600/10940] ---- BYOL Training Loss = 0.239688903093338
30-01-2023 19:31:52 INFO Epoch 3: [5611/10940] ---- BYOL Training Loss = 0.18578386306762695
30-01-2023 19:32:10 INFO Epoch 3: [5622/10940] ---- BYOL Training Loss = 0.22603726387023926
30-01-2023 19:32:29 INFO Epoch 3: [5633/10940] ---- BYOL Training Loss = 0.23662085831165314
30-01-2023 19:33:21 INFO Epoch 3: [5633/10940] ---- BYOL Validation Loss = 0.10811686515808105
30-01-2023 19:33:39 INFO Epoch 3: [5644/10940] ---- BYOL Training Loss = 0.17047199606895447
30-01-2023 19:33:57 INFO Epoch 3: [5655/10940] ---- BYOL Training Loss = 0.17323347926139832
30-01-2023 19:34:16 INFO Epoch 3: [5666/10940] ---- BYOL Training Loss = 0.1682141274213791
30-01-2023 19:34:34 INFO Epoch 3: [5677/10940] ---- BYOL Training Loss = 0.18780365586280823
30-01-2023 19:35:26 INFO Epoch 3: [5677/10940] ---- BYOL Validation Loss = 0.14890940487384796
30-01-2023 19:35:44 INFO Epoch 3: [5688/10940] ---- BYOL Training Loss = 0.2321510761976242
30-01-2023 19:36:02 INFO Epoch 3: [5699/10940] ---- BYOL Training Loss = 0.25542372465133667
30-01-2023 19:36:21 INFO Epoch 3: [5710/10940] ---- BYOL Training Loss = 0.29233211278915405
30-01-2023 19:36:39 INFO Epoch 3: [5721/10940] ---- BYOL Training Loss = 0.27677711844444275
30-01-2023 19:37:31 INFO Epoch 3: [5721/10940] ---- BYOL Validation Loss = 0.1362214982509613
30-01-2023 19:37:49 INFO Epoch 3: [5732/10940] ---- BYOL Training Loss = 0.3414032757282257
30-01-2023 19:38:08 INFO Epoch 3: [5743/10940] ---- BYOL Training Loss = 0.36192578077316284
30-01-2023 19:38:26 INFO Epoch 3: [5754/10940] ---- BYOL Training Loss = 0.29328012466430664
30-01-2023 19:38:45 INFO Epoch 3: [5765/10940] ---- BYOL Training Loss = 0.28469061851501465
30-01-2023 19:39:37 INFO Epoch 3: [5765/10940] ---- BYOL Validation Loss = 0.19046881794929504
30-01-2023 19:39:55 INFO Epoch 3: [5776/10940] ---- BYOL Training Loss = 0.21033839881420135
30-01-2023 19:40:13 INFO Epoch 3: [5787/10940] ---- BYOL Training Loss = 0.20991507172584534
30-01-2023 19:40:31 INFO Epoch 3: [5798/10940] ---- BYOL Training Loss = 0.21743139624595642
30-01-2023 19:40:50 INFO Epoch 3: [5809/10940] ---- BYOL Training Loss = 0.22322368621826172
30-01-2023 19:41:42 INFO Epoch 3: [5809/10940] ---- BYOL Validation Loss = 0.13200004398822784
30-01-2023 19:42:00 INFO Epoch 3: [5820/10940] ---- BYOL Training Loss = 0.21696047484874725
30-01-2023 19:42:19 INFO Epoch 3: [5831/10940] ---- BYOL Training Loss = 0.1834280788898468
30-01-2023 19:42:37 INFO Epoch 3: [5842/10940] ---- BYOL Training Loss = 0.19053754210472107
30-01-2023 19:42:56 INFO Epoch 3: [5853/10940] ---- BYOL Training Loss = 0.23997540771961212
30-01-2023 19:43:48 INFO Epoch 3: [5853/10940] ---- BYOL Validation Loss = 0.19908510148525238
30-01-2023 19:44:06 INFO Epoch 3: [5864/10940] ---- BYOL Training Loss = 0.2037474364042282
30-01-2023 19:44:24 INFO Epoch 3: [5875/10940] ---- BYOL Training Loss = 0.1779009848833084
30-01-2023 19:44:43 INFO Epoch 3: [5886/10940] ---- BYOL Training Loss = 0.22161206603050232
30-01-2023 19:45:01 INFO Epoch 3: [5897/10940] ---- BYOL Training Loss = 0.23841901123523712
30-01-2023 19:45:53 INFO Epoch 3: [5897/10940] ---- BYOL Validation Loss = 0.17365658283233643
30-01-2023 19:46:11 INFO Epoch 3: [5908/10940] ---- BYOL Training Loss = 0.25511008501052856
30-01-2023 19:46:30 INFO Epoch 3: [5919/10940] ---- BYOL Training Loss = 0.2814376950263977
30-01-2023 19:46:48 INFO Epoch 3: [5930/10940] ---- BYOL Training Loss = 0.2593596577644348
30-01-2023 19:47:07 INFO Epoch 3: [5941/10940] ---- BYOL Training Loss = 0.18695634603500366
30-01-2023 19:47:59 INFO Epoch 3: [5941/10940] ---- BYOL Validation Loss = 0.12382511794567108
30-01-2023 19:48:17 INFO Epoch 3: [5952/10940] ---- BYOL Training Loss = 0.2034677267074585
30-01-2023 19:48:35 INFO Epoch 3: [5963/10940] ---- BYOL Training Loss = 0.20408639311790466
30-01-2023 19:48:54 INFO Epoch 3: [5974/10940] ---- BYOL Training Loss = 0.27348217368125916
30-01-2023 19:49:12 INFO Epoch 3: [5985/10940] ---- BYOL Training Loss = 0.35875505208969116
30-01-2023 19:50:04 INFO Epoch 3: [5985/10940] ---- BYOL Validation Loss = 0.17007377743721008
30-01-2023 19:50:22 INFO Epoch 3: [5996/10940] ---- BYOL Training Loss = 0.2446838617324829
30-01-2023 19:50:41 INFO Epoch 3: [6007/10940] ---- BYOL Training Loss = 0.24521932005882263
30-01-2023 19:50:59 INFO Epoch 3: [6018/10940] ---- BYOL Training Loss = 0.23201067745685577
30-01-2023 19:51:18 INFO Epoch 3: [6029/10940] ---- BYOL Training Loss = 0.18805594742298126
30-01-2023 19:52:10 INFO Epoch 3: [6029/10940] ---- BYOL Validation Loss = 0.12568844854831696
30-01-2023 19:52:28 INFO Epoch 3: [6040/10940] ---- BYOL Training Loss = 0.19506916403770447
30-01-2023 19:52:46 INFO Epoch 3: [6051/10940] ---- BYOL Training Loss = 0.16994930803775787
30-01-2023 19:53:05 INFO Epoch 3: [6062/10940] ---- BYOL Training Loss = 0.16595718264579773
30-01-2023 19:53:23 INFO Epoch 3: [6073/10940] ---- BYOL Training Loss = 0.30598559975624084
30-01-2023 19:54:15 INFO Epoch 3: [6073/10940] ---- BYOL Validation Loss = 0.11405616253614426
30-01-2023 19:54:33 INFO Epoch 3: [6084/10940] ---- BYOL Training Loss = 0.2736821174621582
30-01-2023 19:54:52 INFO Epoch 3: [6095/10940] ---- BYOL Training Loss = 0.20167949795722961
30-01-2023 19:55:10 INFO Epoch 3: [6106/10940] ---- BYOL Training Loss = 0.22651851177215576
30-01-2023 19:55:29 INFO Epoch 3: [6117/10940] ---- BYOL Training Loss = 0.18070463836193085
30-01-2023 19:56:21 INFO Epoch 3: [6117/10940] ---- BYOL Validation Loss = 0.12104471772909164
30-01-2023 19:56:39 INFO Epoch 3: [6128/10940] ---- BYOL Training Loss = 0.16390350461006165
30-01-2023 19:56:57 INFO Epoch 3: [6139/10940] ---- BYOL Training Loss = 0.3141997456550598
30-01-2023 19:57:16 INFO Epoch 3: [6150/10940] ---- BYOL Training Loss = 0.3771986663341522
30-01-2023 19:57:34 INFO Epoch 3: [6161/10940] ---- BYOL Training Loss = 0.2787059247493744
30-01-2023 19:58:26 INFO Epoch 3: [6161/10940] ---- BYOL Validation Loss = 0.1571936309337616
30-01-2023 19:58:44 INFO Epoch 3: [6172/10940] ---- BYOL Training Loss = 0.3179837465286255
30-01-2023 19:59:02 INFO Epoch 3: [6183/10940] ---- BYOL Training Loss = 0.2760065793991089
30-01-2023 19:59:21 INFO Epoch 3: [6194/10940] ---- BYOL Training Loss = 0.27126964926719666
30-01-2023 19:59:40 INFO Epoch 3: [6205/10940] ---- BYOL Training Loss = 0.35586684942245483
30-01-2023 20:00:32 INFO Epoch 3: [6205/10940] ---- BYOL Validation Loss = 0.18823078274726868
30-01-2023 20:00:50 INFO Epoch 3: [6216/10940] ---- BYOL Training Loss = 0.27107617259025574
30-01-2023 20:01:08 INFO Epoch 3: [6227/10940] ---- BYOL Training Loss = 0.2116488218307495
30-01-2023 20:01:27 INFO Epoch 3: [6238/10940] ---- BYOL Training Loss = 0.276116281747818
30-01-2023 20:01:45 INFO Epoch 3: [6249/10940] ---- BYOL Training Loss = 0.25654295086860657
30-01-2023 20:02:37 INFO Epoch 3: [6249/10940] ---- BYOL Validation Loss = 0.14003346860408783
30-01-2023 20:02:55 INFO Epoch 3: [6260/10940] ---- BYOL Training Loss = 0.2584679126739502
30-01-2023 20:03:14 INFO Epoch 3: [6271/10940] ---- BYOL Training Loss = 0.21124091744422913
30-01-2023 20:03:32 INFO Epoch 3: [6282/10940] ---- BYOL Training Loss = 0.1752798855304718
30-01-2023 20:03:51 INFO Epoch 3: [6293/10940] ---- BYOL Training Loss = 0.17830519378185272
30-01-2023 20:04:43 INFO Epoch 3: [6293/10940] ---- BYOL Validation Loss = 0.07820524275302887
30-01-2023 20:05:01 INFO Epoch 3: [6304/10940] ---- BYOL Training Loss = 0.1708155870437622
30-01-2023 20:05:20 INFO Epoch 3: [6315/10940] ---- BYOL Training Loss = 0.19189265370368958
30-01-2023 20:05:38 INFO Epoch 3: [6326/10940] ---- BYOL Training Loss = 0.22302846610546112
30-01-2023 20:05:57 INFO Epoch 3: [6337/10940] ---- BYOL Training Loss = 0.2388562709093094
30-01-2023 20:06:49 INFO Epoch 3: [6337/10940] ---- BYOL Validation Loss = 0.13608936965465546
30-01-2023 20:07:07 INFO Epoch 3: [6348/10940] ---- BYOL Training Loss = 0.22006568312644958
30-01-2023 20:07:25 INFO Epoch 3: [6359/10940] ---- BYOL Training Loss = 0.28944602608680725
30-01-2023 20:07:44 INFO Epoch 3: [6370/10940] ---- BYOL Training Loss = 0.2315458059310913
30-01-2023 20:08:02 INFO Epoch 3: [6381/10940] ---- BYOL Training Loss = 0.3319200873374939
30-01-2023 20:08:54 INFO Epoch 3: [6381/10940] ---- BYOL Validation Loss = 0.09565985202789307
30-01-2023 20:09:13 INFO Epoch 3: [6392/10940] ---- BYOL Training Loss = 0.3001179099082947
30-01-2023 20:09:31 INFO Epoch 3: [6403/10940] ---- BYOL Training Loss = 0.22114363312721252
30-01-2023 20:09:50 INFO Epoch 3: [6414/10940] ---- BYOL Training Loss = 0.21084973216056824
30-01-2023 20:10:08 INFO Epoch 3: [6425/10940] ---- BYOL Training Loss = 0.21603381633758545
30-01-2023 20:11:00 INFO Epoch 3: [6425/10940] ---- BYOL Validation Loss = 0.1528344452381134
30-01-2023 20:11:18 INFO Epoch 3: [6436/10940] ---- BYOL Training Loss = 0.23483124375343323
30-01-2023 20:11:37 INFO Epoch 3: [6447/10940] ---- BYOL Training Loss = 0.21358919143676758
30-01-2023 20:11:56 INFO Epoch 3: [6458/10940] ---- BYOL Training Loss = 0.20435731112957
30-01-2023 20:12:14 INFO Epoch 3: [6469/10940] ---- BYOL Training Loss = 0.1872381716966629
30-01-2023 20:13:06 INFO Epoch 3: [6469/10940] ---- BYOL Validation Loss = 0.12574255466461182
30-01-2023 20:13:24 INFO Epoch 3: [6480/10940] ---- BYOL Training Loss = 0.18154175579547882
30-01-2023 20:13:43 INFO Epoch 3: [6491/10940] ---- BYOL Training Loss = 0.2261536568403244
30-01-2023 20:14:01 INFO Epoch 3: [6502/10940] ---- BYOL Training Loss = 0.2774592936038971
30-01-2023 20:14:20 INFO Epoch 3: [6513/10940] ---- BYOL Training Loss = 0.2778252959251404
30-01-2023 20:15:12 INFO Epoch 3: [6513/10940] ---- BYOL Validation Loss = 0.16032631695270538
30-01-2023 20:15:30 INFO Epoch 3: [6524/10940] ---- BYOL Training Loss = 0.24766671657562256
30-01-2023 20:15:48 INFO Epoch 3: [6535/10940] ---- BYOL Training Loss = 0.20259301364421844
30-01-2023 20:16:07 INFO Epoch 3: [6546/10940] ---- BYOL Training Loss = 0.1831948310136795
30-01-2023 20:16:25 INFO Epoch 3: [6557/10940] ---- BYOL Training Loss = 0.21550431847572327
30-01-2023 20:17:17 INFO Epoch 3: [6557/10940] ---- BYOL Validation Loss = 0.168828085064888
30-01-2023 20:17:35 INFO Epoch 3: [6568/10940] ---- BYOL Training Loss = 0.22706742584705353
30-01-2023 20:17:54 INFO Epoch 3: [6579/10940] ---- BYOL Training Loss = 0.13875427842140198
30-01-2023 20:18:13 INFO Epoch 3: [6590/10940] ---- BYOL Training Loss = 0.14889158308506012
30-01-2023 20:18:31 INFO Epoch 3: [6601/10940] ---- BYOL Training Loss = 0.2936815321445465
30-01-2023 20:19:23 INFO Epoch 3: [6601/10940] ---- BYOL Validation Loss = 0.1633659452199936
30-01-2023 20:19:42 INFO Epoch 3: [6612/10940] ---- BYOL Training Loss = 0.3429694175720215
30-01-2023 20:20:00 INFO Epoch 3: [6623/10940] ---- BYOL Training Loss = 0.261836975812912
30-01-2023 20:20:18 INFO Epoch 3: [6634/10940] ---- BYOL Training Loss = 0.1929313987493515
30-01-2023 20:20:37 INFO Epoch 3: [6645/10940] ---- BYOL Training Loss = 0.25307929515838623
30-01-2023 20:21:29 INFO Epoch 3: [6645/10940] ---- BYOL Validation Loss = 0.1149083748459816
30-01-2023 20:21:47 INFO Epoch 3: [6656/10940] ---- BYOL Training Loss = 0.19312943518161774
30-01-2023 20:22:06 INFO Epoch 3: [6667/10940] ---- BYOL Training Loss = 0.178794264793396
30-01-2023 20:22:24 INFO Epoch 3: [6678/10940] ---- BYOL Training Loss = 0.19862507283687592
30-01-2023 20:22:43 INFO Epoch 3: [6689/10940] ---- BYOL Training Loss = 0.21136954426765442
30-01-2023 20:23:35 INFO Epoch 3: [6689/10940] ---- BYOL Validation Loss = 0.08819340914487839
30-01-2023 20:23:53 INFO Epoch 3: [6700/10940] ---- BYOL Training Loss = 0.18808817863464355
30-01-2023 20:24:12 INFO Epoch 3: [6711/10940] ---- BYOL Training Loss = 0.23474374413490295
30-01-2023 20:24:30 INFO Epoch 3: [6722/10940] ---- BYOL Training Loss = 0.24638128280639648
30-01-2023 20:24:49 INFO Epoch 3: [6733/10940] ---- BYOL Training Loss = 0.24702425301074982
30-01-2023 20:25:41 INFO Epoch 3: [6733/10940] ---- BYOL Validation Loss = 0.10861102491617203
30-01-2023 20:25:59 INFO Epoch 3: [6744/10940] ---- BYOL Training Loss = 0.2153407335281372
30-01-2023 20:26:17 INFO Epoch 3: [6755/10940] ---- BYOL Training Loss = 0.3127624988555908
30-01-2023 20:26:36 INFO Epoch 3: [6766/10940] ---- BYOL Training Loss = 0.37304767966270447
30-01-2023 20:26:55 INFO Epoch 3: [6777/10940] ---- BYOL Training Loss = 0.3452078104019165
30-01-2023 20:27:47 INFO Epoch 3: [6777/10940] ---- BYOL Validation Loss = 0.14762534201145172
30-01-2023 20:28:05 INFO Epoch 3: [6788/10940] ---- BYOL Training Loss = 0.332234650850296
30-01-2023 20:28:24 INFO Epoch 3: [6799/10940] ---- BYOL Training Loss = 0.2614819407463074
30-01-2023 20:28:42 INFO Epoch 3: [6810/10940] ---- BYOL Training Loss = 0.2263505905866623
30-01-2023 20:29:00 INFO Epoch 3: [6821/10940] ---- BYOL Training Loss = 0.1956840604543686
30-01-2023 20:29:52 INFO Epoch 3: [6821/10940] ---- BYOL Validation Loss = 0.13973145186901093
30-01-2023 20:30:10 INFO Epoch 3: [6832/10940] ---- BYOL Training Loss = 0.19960397481918335
30-01-2023 20:30:29 INFO Epoch 3: [6843/10940] ---- BYOL Training Loss = 0.19753247499465942
30-01-2023 20:30:48 INFO Epoch 3: [6854/10940] ---- BYOL Training Loss = 0.16233253479003906
30-01-2023 20:31:06 INFO Epoch 3: [6865/10940] ---- BYOL Training Loss = 0.22310154139995575
30-01-2023 20:31:58 INFO Epoch 3: [6865/10940] ---- BYOL Validation Loss = 0.15226860344409943
30-01-2023 20:32:17 INFO Epoch 3: [6876/10940] ---- BYOL Training Loss = 0.2809606194496155
30-01-2023 20:32:35 INFO Epoch 3: [6887/10940] ---- BYOL Training Loss = 0.2862490117549896
30-01-2023 20:32:54 INFO Epoch 3: [6898/10940] ---- BYOL Training Loss = 0.28896790742874146
30-01-2023 20:33:12 INFO Epoch 3: [6909/10940] ---- BYOL Training Loss = 0.18941497802734375
30-01-2023 20:34:04 INFO Epoch 3: [6909/10940] ---- BYOL Validation Loss = 0.15166714787483215
30-01-2023 20:34:22 INFO Epoch 3: [6920/10940] ---- BYOL Training Loss = 0.18607822060585022
30-01-2023 20:34:41 INFO Epoch 3: [6931/10940] ---- BYOL Training Loss = 0.18731848895549774
30-01-2023 20:34:59 INFO Epoch 3: [6942/10940] ---- BYOL Training Loss = 0.19514670968055725
30-01-2023 20:35:18 INFO Epoch 3: [6953/10940] ---- BYOL Training Loss = 0.23178008198738098
30-01-2023 20:36:10 INFO Epoch 3: [6953/10940] ---- BYOL Validation Loss = 0.1335693746805191
30-01-2023 20:36:28 INFO Epoch 3: [6964/10940] ---- BYOL Training Loss = 0.22837305068969727
30-01-2023 20:36:47 INFO Epoch 3: [6975/10940] ---- BYOL Training Loss = 0.20223355293273926
30-01-2023 20:37:05 INFO Epoch 3: [6986/10940] ---- BYOL Training Loss = 0.18791595101356506
30-01-2023 20:37:24 INFO Epoch 3: [6997/10940] ---- BYOL Training Loss = 0.19646291434764862
30-01-2023 20:38:16 INFO Epoch 3: [6997/10940] ---- BYOL Validation Loss = 0.16397105157375336
30-01-2023 20:38:34 INFO Epoch 3: [7008/10940] ---- BYOL Training Loss = 0.1632848083972931
30-01-2023 20:38:53 INFO Epoch 3: [7019/10940] ---- BYOL Training Loss = 0.21609501540660858
30-01-2023 20:39:11 INFO Epoch 3: [7030/10940] ---- BYOL Training Loss = 0.21256637573242188
30-01-2023 20:39:30 INFO Epoch 3: [7041/10940] ---- BYOL Training Loss = 0.24382932484149933
30-01-2023 20:40:22 INFO Epoch 3: [7041/10940] ---- BYOL Validation Loss = 0.20262496173381805
30-01-2023 20:40:40 INFO Epoch 3: [7052/10940] ---- BYOL Training Loss = 0.2784910798072815
30-01-2023 20:40:59 INFO Epoch 3: [7063/10940] ---- BYOL Training Loss = 0.2515372931957245
30-01-2023 20:41:17 INFO Epoch 3: [7074/10940] ---- BYOL Training Loss = 0.23346011340618134
30-01-2023 20:41:36 INFO Epoch 3: [7085/10940] ---- BYOL Training Loss = 0.20937295258045197
30-01-2023 20:42:28 INFO Epoch 3: [7085/10940] ---- BYOL Validation Loss = 0.14187894761562347
30-01-2023 20:42:46 INFO Epoch 3: [7096/10940] ---- BYOL Training Loss = 0.23422713577747345
30-01-2023 20:43:05 INFO Epoch 3: [7107/10940] ---- BYOL Training Loss = 0.23086538910865784
30-01-2023 20:43:23 INFO Epoch 3: [7118/10940] ---- BYOL Training Loss = 0.22460031509399414
30-01-2023 20:43:42 INFO Epoch 3: [7129/10940] ---- BYOL Training Loss = 0.25517597794532776
30-01-2023 20:44:34 INFO Epoch 3: [7129/10940] ---- BYOL Validation Loss = 0.1768472045660019
30-01-2023 20:44:52 INFO Epoch 3: [7140/10940] ---- BYOL Training Loss = 0.239353746175766
30-01-2023 20:45:10 INFO Epoch 3: [7151/10940] ---- BYOL Training Loss = 0.19453951716423035
30-01-2023 20:45:29 INFO Epoch 3: [7162/10940] ---- BYOL Training Loss = 0.18904291093349457
30-01-2023 20:45:48 INFO Epoch 3: [7173/10940] ---- BYOL Training Loss = 0.23532915115356445
30-01-2023 20:46:40 INFO Epoch 3: [7173/10940] ---- BYOL Validation Loss = 0.1841278374195099
30-01-2023 20:46:58 INFO Epoch 3: [7184/10940] ---- BYOL Training Loss = 0.24861030280590057
30-01-2023 20:47:17 INFO Epoch 3: [7195/10940] ---- BYOL Training Loss = 0.19571161270141602
30-01-2023 20:47:35 INFO Epoch 3: [7206/10940] ---- BYOL Training Loss = 0.21617011725902557
30-01-2023 20:47:54 INFO Epoch 3: [7217/10940] ---- BYOL Training Loss = 0.2902820110321045
30-01-2023 20:48:46 INFO Epoch 3: [7217/10940] ---- BYOL Validation Loss = 0.11063481867313385
30-01-2023 20:49:04 INFO Epoch 3: [7228/10940] ---- BYOL Training Loss = 0.21858887374401093
30-01-2023 20:49:23 INFO Epoch 3: [7239/10940] ---- BYOL Training Loss = 0.22726663947105408
30-01-2023 20:49:41 INFO Epoch 3: [7250/10940] ---- BYOL Training Loss = 0.2655388116836548
30-01-2023 20:50:00 INFO Epoch 3: [7261/10940] ---- BYOL Training Loss = 0.18682000041007996
30-01-2023 20:50:52 INFO Epoch 3: [7261/10940] ---- BYOL Validation Loss = 0.10646320134401321
30-01-2023 20:51:10 INFO Epoch 3: [7272/10940] ---- BYOL Training Loss = 0.14048375189304352
30-01-2023 20:51:29 INFO Epoch 3: [7283/10940] ---- BYOL Training Loss = 0.19430720806121826
30-01-2023 20:51:47 INFO Epoch 3: [7294/10940] ---- BYOL Training Loss = 0.22218024730682373
30-01-2023 20:52:06 INFO Epoch 3: [7305/10940] ---- BYOL Training Loss = 0.2132742702960968
30-01-2023 20:52:58 INFO Epoch 3: [7305/10940] ---- BYOL Validation Loss = 0.10646826773881912
30-01-2023 20:53:16 INFO Epoch 3: [7316/10940] ---- BYOL Training Loss = 0.26047009229660034
30-01-2023 20:53:34 INFO Epoch 3: [7327/10940] ---- BYOL Training Loss = 0.18734413385391235
30-01-2023 20:53:53 INFO Epoch 3: [7338/10940] ---- BYOL Training Loss = 0.21820183098316193
30-01-2023 20:54:12 INFO Epoch 3: [7349/10940] ---- BYOL Training Loss = 0.25902706384658813
30-01-2023 20:55:04 INFO Epoch 3: [7349/10940] ---- BYOL Validation Loss = 0.16387467086315155
30-01-2023 20:55:22 INFO Epoch 3: [7360/10940] ---- BYOL Training Loss = 0.2459878921508789
30-01-2023 20:55:41 INFO Epoch 3: [7371/10940] ---- BYOL Training Loss = 0.221323162317276
30-01-2023 20:55:59 INFO Epoch 3: [7382/10940] ---- BYOL Training Loss = 0.23858126997947693
30-01-2023 20:56:18 INFO Epoch 3: [7393/10940] ---- BYOL Training Loss = 0.31827253103256226
30-01-2023 20:57:10 INFO Epoch 3: [7393/10940] ---- BYOL Validation Loss = 0.17401061952114105
30-01-2023 20:57:28 INFO Epoch 3: [7404/10940] ---- BYOL Training Loss = 0.29149478673934937
30-01-2023 20:57:47 INFO Epoch 3: [7415/10940] ---- BYOL Training Loss = 0.25645336508750916
30-01-2023 20:58:05 INFO Epoch 3: [7426/10940] ---- BYOL Training Loss = 0.2082400619983673
30-01-2023 20:58:24 INFO Epoch 3: [7437/10940] ---- BYOL Training Loss = 0.22042682766914368
30-01-2023 20:59:16 INFO Epoch 3: [7437/10940] ---- BYOL Validation Loss = 0.15699028968811035
30-01-2023 20:59:34 INFO Epoch 3: [7448/10940] ---- BYOL Training Loss = 0.19445838034152985
30-01-2023 20:59:52 INFO Epoch 3: [7459/10940] ---- BYOL Training Loss = 0.1948968470096588
30-01-2023 21:00:11 INFO Epoch 3: [7470/10940] ---- BYOL Training Loss = 0.23725061118602753
30-01-2023 21:00:30 INFO Epoch 3: [7481/10940] ---- BYOL Training Loss = 0.2461777627468109
30-01-2023 21:01:22 INFO Epoch 3: [7481/10940] ---- BYOL Validation Loss = 0.1665154993534088
30-01-2023 21:01:40 INFO Epoch 3: [7492/10940] ---- BYOL Training Loss = 0.20972688496112823
30-01-2023 21:01:59 INFO Epoch 3: [7503/10940] ---- BYOL Training Loss = 0.15391595661640167
30-01-2023 21:02:17 INFO Epoch 3: [7514/10940] ---- BYOL Training Loss = 0.18895795941352844
30-01-2023 21:02:36 INFO Epoch 3: [7525/10940] ---- BYOL Training Loss = 0.2285400927066803
30-01-2023 21:03:28 INFO Epoch 3: [7525/10940] ---- BYOL Validation Loss = 0.1306094378232956
30-01-2023 21:03:46 INFO Epoch 3: [7536/10940] ---- BYOL Training Loss = 0.21915790438652039
30-01-2023 21:04:05 INFO Epoch 3: [7547/10940] ---- BYOL Training Loss = 0.25687697529792786
30-01-2023 21:04:23 INFO Epoch 3: [7558/10940] ---- BYOL Training Loss = 0.23265507817268372
30-01-2023 21:04:42 INFO Epoch 3: [7569/10940] ---- BYOL Training Loss = 0.2043246030807495
30-01-2023 21:05:34 INFO Epoch 3: [7569/10940] ---- BYOL Validation Loss = 0.12272406369447708
30-01-2023 21:05:52 INFO Epoch 3: [7580/10940] ---- BYOL Training Loss = 0.19501693546772003
30-01-2023 21:06:11 INFO Epoch 3: [7591/10940] ---- BYOL Training Loss = 0.22321514785289764
30-01-2023 21:06:29 INFO Epoch 3: [7602/10940] ---- BYOL Training Loss = 0.20081667602062225
30-01-2023 21:06:48 INFO Epoch 3: [7613/10940] ---- BYOL Training Loss = 0.21894919872283936
30-01-2023 21:07:40 INFO Epoch 3: [7613/10940] ---- BYOL Validation Loss = 0.1563710868358612
30-01-2023 21:07:59 INFO Epoch 3: [7624/10940] ---- BYOL Training Loss = 0.20606482028961182
30-01-2023 21:08:17 INFO Epoch 3: [7635/10940] ---- BYOL Training Loss = 0.21031348407268524
30-01-2023 21:08:36 INFO Epoch 3: [7646/10940] ---- BYOL Training Loss = 0.23347286880016327
30-01-2023 21:08:55 INFO Epoch 3: [7657/10940] ---- BYOL Training Loss = 0.22885391116142273
30-01-2023 21:09:47 INFO Epoch 3: [7657/10940] ---- BYOL Validation Loss = 0.14119277894496918
30-01-2023 21:10:05 INFO Epoch 3: [7668/10940] ---- BYOL Training Loss = 0.20926329493522644
30-01-2023 21:10:24 INFO Epoch 3: [7679/10940] ---- BYOL Training Loss = 0.1764770746231079
30-01-2023 21:10:42 INFO Epoch 3: [7690/10940] ---- BYOL Training Loss = 0.14732326567173004
30-01-2023 21:11:01 INFO Epoch 3: [7701/10940] ---- BYOL Training Loss = 0.18464042246341705
30-01-2023 21:11:53 INFO Epoch 3: [7701/10940] ---- BYOL Validation Loss = 0.1611885130405426
30-01-2023 21:12:11 INFO Epoch 3: [7712/10940] ---- BYOL Training Loss = 0.1636112928390503
30-01-2023 21:12:30 INFO Epoch 3: [7723/10940] ---- BYOL Training Loss = 0.1650324910879135
30-01-2023 21:12:48 INFO Epoch 3: [7734/10940] ---- BYOL Training Loss = 0.19833120703697205
30-01-2023 21:13:07 INFO Epoch 3: [7745/10940] ---- BYOL Training Loss = 0.20265011489391327
30-01-2023 21:13:59 INFO Epoch 3: [7745/10940] ---- BYOL Validation Loss = 0.08961080014705658
30-01-2023 21:14:18 INFO Epoch 3: [7756/10940] ---- BYOL Training Loss = 0.2468620240688324
30-01-2023 21:14:36 INFO Epoch 3: [7767/10940] ---- BYOL Training Loss = 0.25599849224090576
30-01-2023 21:14:55 INFO Epoch 3: [7778/10940] ---- BYOL Training Loss = 0.17677173018455505
30-01-2023 21:15:14 INFO Epoch 3: [7789/10940] ---- BYOL Training Loss = 0.18362954258918762
30-01-2023 21:16:06 INFO Epoch 3: [7789/10940] ---- BYOL Validation Loss = 0.14496980607509613
30-01-2023 21:16:24 INFO Epoch 3: [7800/10940] ---- BYOL Training Loss = 0.23586437106132507
30-01-2023 21:16:43 INFO Epoch 3: [7811/10940] ---- BYOL Training Loss = 0.28557461500167847
30-01-2023 21:17:01 INFO Epoch 3: [7822/10940] ---- BYOL Training Loss = 0.20629504323005676
30-01-2023 21:17:20 INFO Epoch 3: [7833/10940] ---- BYOL Training Loss = 0.20798444747924805
30-01-2023 21:18:12 INFO Epoch 3: [7833/10940] ---- BYOL Validation Loss = 0.17943431437015533
30-01-2023 21:18:30 INFO Epoch 3: [7844/10940] ---- BYOL Training Loss = 0.2243538796901703
30-01-2023 21:18:49 INFO Epoch 3: [7855/10940] ---- BYOL Training Loss = 0.22547833621501923
30-01-2023 21:19:07 INFO Epoch 3: [7866/10940] ---- BYOL Training Loss = 0.21793469786643982
30-01-2023 21:19:26 INFO Epoch 3: [7877/10940] ---- BYOL Training Loss = 0.1954665333032608
30-01-2023 21:20:18 INFO Epoch 3: [7877/10940] ---- BYOL Validation Loss = 0.15254424512386322
30-01-2023 21:20:36 INFO Epoch 3: [7888/10940] ---- BYOL Training Loss = 0.1946442723274231
30-01-2023 21:20:55 INFO Epoch 3: [7899/10940] ---- BYOL Training Loss = 0.20011647045612335
30-01-2023 21:21:14 INFO Epoch 3: [7910/10940] ---- BYOL Training Loss = 0.17309395968914032
30-01-2023 21:21:32 INFO Epoch 3: [7921/10940] ---- BYOL Training Loss = 0.18548724055290222
30-01-2023 21:22:24 INFO Epoch 3: [7921/10940] ---- BYOL Validation Loss = 0.17239955067634583
30-01-2023 21:22:42 INFO Epoch 3: [7932/10940] ---- BYOL Training Loss = 0.20062747597694397
30-01-2023 21:23:01 INFO Epoch 3: [7943/10940] ---- BYOL Training Loss = 0.19659040868282318
30-01-2023 21:23:20 INFO Epoch 3: [7954/10940] ---- BYOL Training Loss = 0.2189343273639679
30-01-2023 21:23:39 INFO Epoch 3: [7965/10940] ---- BYOL Training Loss = 0.2547994554042816
30-01-2023 21:24:31 INFO Epoch 3: [7965/10940] ---- BYOL Validation Loss = 0.1613648384809494
30-01-2023 21:24:49 INFO Epoch 3: [7976/10940] ---- BYOL Training Loss = 0.2340594232082367
30-01-2023 21:25:07 INFO Epoch 3: [7987/10940] ---- BYOL Training Loss = 0.25685515999794006
30-01-2023 21:25:26 INFO Epoch 3: [7998/10940] ---- BYOL Training Loss = 0.27180030941963196
30-01-2023 21:25:45 INFO Epoch 3: [8009/10940] ---- BYOL Training Loss = 0.18615704774856567
30-01-2023 21:26:37 INFO Epoch 3: [8009/10940] ---- BYOL Validation Loss = 0.14395630359649658
30-01-2023 21:26:55 INFO Epoch 3: [8020/10940] ---- BYOL Training Loss = 0.21315982937812805
30-01-2023 21:27:14 INFO Epoch 3: [8031/10940] ---- BYOL Training Loss = 0.225701242685318
30-01-2023 21:27:33 INFO Epoch 3: [8042/10940] ---- BYOL Training Loss = 0.20784816145896912
30-01-2023 21:27:51 INFO Epoch 3: [8053/10940] ---- BYOL Training Loss = 0.21252663433551788
30-01-2023 21:28:43 INFO Epoch 3: [8053/10940] ---- BYOL Validation Loss = 0.11154407262802124
30-01-2023 21:29:02 INFO Epoch 3: [8064/10940] ---- BYOL Training Loss = 0.20016340911388397
30-01-2023 21:29:20 INFO Epoch 3: [8075/10940] ---- BYOL Training Loss = 0.21141085028648376
30-01-2023 21:29:39 INFO Epoch 3: [8086/10940] ---- BYOL Training Loss = 0.2396073043346405
30-01-2023 21:29:58 INFO Epoch 3: [8097/10940] ---- BYOL Training Loss = 0.25266021490097046
30-01-2023 21:30:50 INFO Epoch 3: [8097/10940] ---- BYOL Validation Loss = 0.14761005342006683
30-01-2023 21:31:08 INFO Epoch 3: [8108/10940] ---- BYOL Training Loss = 0.2160748988389969
30-01-2023 21:31:27 INFO Epoch 3: [8119/10940] ---- BYOL Training Loss = 0.22063632309436798
30-01-2023 21:31:45 INFO Epoch 3: [8130/10940] ---- BYOL Training Loss = 0.26946574449539185
30-01-2023 21:32:04 INFO Epoch 3: [8141/10940] ---- BYOL Training Loss = 0.2888471186161041
30-01-2023 21:32:56 INFO Epoch 3: [8141/10940] ---- BYOL Validation Loss = 0.191815584897995
30-01-2023 21:33:14 INFO Epoch 3: [8152/10940] ---- BYOL Training Loss = 0.2559419274330139
30-01-2023 21:33:33 INFO Epoch 3: [8163/10940] ---- BYOL Training Loss = 0.23351451754570007
30-01-2023 21:33:52 INFO Epoch 3: [8174/10940] ---- BYOL Training Loss = 0.2009241133928299
30-01-2023 21:34:10 INFO Epoch 3: [8185/10940] ---- BYOL Training Loss = 0.17294509708881378
30-01-2023 21:35:02 INFO Epoch 3: [8185/10940] ---- BYOL Validation Loss = 0.17263305187225342
30-01-2023 21:35:21 INFO Epoch 3: [8196/10940] ---- BYOL Training Loss = 0.18274810910224915
30-01-2023 21:35:40 INFO Epoch 3: [8207/10940] ---- BYOL Training Loss = 0.21342149376869202
30-01-2023 21:35:58 INFO Epoch 3: [8218/10940] ---- BYOL Training Loss = 0.20748372375965118
30-01-2023 21:36:17 INFO Epoch 3: [8229/10940] ---- BYOL Training Loss = 0.22156588733196259
30-01-2023 21:37:09 INFO Epoch 3: [8229/10940] ---- BYOL Validation Loss = 0.16786162555217743
30-01-2023 21:37:27 INFO Epoch 3: [8240/10940] ---- BYOL Training Loss = 0.2255840301513672
30-01-2023 21:37:46 INFO Epoch 3: [8251/10940] ---- BYOL Training Loss = 0.1859082132577896
30-01-2023 21:38:05 INFO Epoch 3: [8262/10940] ---- BYOL Training Loss = 0.202579066157341
30-01-2023 21:38:24 INFO Epoch 3: [8273/10940] ---- BYOL Training Loss = 0.22732727229595184
30-01-2023 21:39:16 INFO Epoch 3: [8273/10940] ---- BYOL Validation Loss = 0.18369413912296295
30-01-2023 21:39:34 INFO Epoch 3: [8284/10940] ---- BYOL Training Loss = 0.2178603857755661
30-01-2023 21:39:53 INFO Epoch 3: [8295/10940] ---- BYOL Training Loss = 0.23169641196727753
30-01-2023 21:40:11 INFO Epoch 3: [8306/10940] ---- BYOL Training Loss = 0.1739533245563507
30-01-2023 21:40:30 INFO Epoch 3: [8317/10940] ---- BYOL Training Loss = 0.18622608482837677
30-01-2023 21:41:22 INFO Epoch 3: [8317/10940] ---- BYOL Validation Loss = 0.14910390973091125
30-01-2023 21:41:41 INFO Epoch 3: [8328/10940] ---- BYOL Training Loss = 0.20581433176994324
30-01-2023 21:41:59 INFO Epoch 3: [8339/10940] ---- BYOL Training Loss = 0.22043125331401825
30-01-2023 21:42:18 INFO Epoch 3: [8350/10940] ---- BYOL Training Loss = 0.22749634087085724
30-01-2023 21:42:37 INFO Epoch 3: [8361/10940] ---- BYOL Training Loss = 0.2523285746574402
30-01-2023 21:43:29 INFO Epoch 3: [8361/10940] ---- BYOL Validation Loss = 0.1676499992609024
30-01-2023 21:43:47 INFO Epoch 3: [8372/10940] ---- BYOL Training Loss = 0.2487705647945404
30-01-2023 21:44:06 INFO Epoch 3: [8383/10940] ---- BYOL Training Loss = 0.30986276268959045
30-01-2023 21:44:25 INFO Epoch 3: [8394/10940] ---- BYOL Training Loss = 0.33021318912506104
30-01-2023 21:44:43 INFO Epoch 3: [8405/10940] ---- BYOL Training Loss = 0.24145551025867462
30-01-2023 21:45:35 INFO Epoch 3: [8405/10940] ---- BYOL Validation Loss = 0.14080658555030823
30-01-2023 21:45:54 INFO Epoch 3: [8416/10940] ---- BYOL Training Loss = 0.2171134650707245
30-01-2023 21:46:12 INFO Epoch 3: [8427/10940] ---- BYOL Training Loss = 0.1877264529466629
30-01-2023 21:46:31 INFO Epoch 3: [8438/10940] ---- BYOL Training Loss = 0.2000475823879242
30-01-2023 21:46:50 INFO Epoch 3: [8449/10940] ---- BYOL Training Loss = 0.18879477679729462
30-01-2023 21:47:42 INFO Epoch 3: [8449/10940] ---- BYOL Validation Loss = 0.1797822266817093
30-01-2023 21:48:00 INFO Epoch 3: [8460/10940] ---- BYOL Training Loss = 0.24921543896198273
30-01-2023 21:48:19 INFO Epoch 3: [8471/10940] ---- BYOL Training Loss = 0.21987219154834747
30-01-2023 21:48:38 INFO Epoch 3: [8482/10940] ---- BYOL Training Loss = 0.19343365728855133
30-01-2023 21:48:56 INFO Epoch 3: [8493/10940] ---- BYOL Training Loss = 0.20132282376289368
30-01-2023 21:49:48 INFO Epoch 3: [8493/10940] ---- BYOL Validation Loss = 0.1479870229959488
30-01-2023 21:50:07 INFO Epoch 3: [8504/10940] ---- BYOL Training Loss = 0.19416406750679016
30-01-2023 21:50:26 INFO Epoch 3: [8515/10940] ---- BYOL Training Loss = 0.17888642847537994
30-01-2023 21:50:44 INFO Epoch 3: [8526/10940] ---- BYOL Training Loss = 0.1667586863040924
30-01-2023 21:51:03 INFO Epoch 3: [8537/10940] ---- BYOL Training Loss = 0.17581215500831604
30-01-2023 21:51:55 INFO Epoch 3: [8537/10940] ---- BYOL Validation Loss = 0.11940424144268036
30-01-2023 21:52:13 INFO Epoch 3: [8548/10940] ---- BYOL Training Loss = 0.17101792991161346
30-01-2023 21:52:32 INFO Epoch 3: [8559/10940] ---- BYOL Training Loss = 0.21053609251976013
30-01-2023 21:52:51 INFO Epoch 3: [8570/10940] ---- BYOL Training Loss = 0.20456281304359436
30-01-2023 21:53:10 INFO Epoch 3: [8581/10940] ---- BYOL Training Loss = 0.21415022015571594
30-01-2023 21:54:02 INFO Epoch 3: [8581/10940] ---- BYOL Validation Loss = 0.16463729739189148
30-01-2023 21:54:20 INFO Epoch 3: [8592/10940] ---- BYOL Training Loss = 0.23229733109474182
30-01-2023 21:54:39 INFO Epoch 3: [8603/10940] ---- BYOL Training Loss = 0.23149287700653076
30-01-2023 21:54:57 INFO Epoch 3: [8614/10940] ---- BYOL Training Loss = 0.22366297245025635
30-01-2023 21:55:16 INFO Epoch 3: [8625/10940] ---- BYOL Training Loss = 0.2167152613401413
30-01-2023 21:56:08 INFO Epoch 3: [8625/10940] ---- BYOL Validation Loss = 0.15656958520412445
30-01-2023 21:56:26 INFO Epoch 3: [8636/10940] ---- BYOL Training Loss = 0.1843430995941162
30-01-2023 21:56:45 INFO Epoch 3: [8647/10940] ---- BYOL Training Loss = 0.2234164923429489
30-01-2023 21:57:04 INFO Epoch 3: [8658/10940] ---- BYOL Training Loss = 0.245759055018425
30-01-2023 21:57:23 INFO Epoch 3: [8669/10940] ---- BYOL Training Loss = 0.24750390648841858
30-01-2023 21:58:15 INFO Epoch 3: [8669/10940] ---- BYOL Validation Loss = 0.1932603418827057
30-01-2023 21:58:33 INFO Epoch 3: [8680/10940] ---- BYOL Training Loss = 0.2529495358467102
30-01-2023 21:58:52 INFO Epoch 3: [8691/10940] ---- BYOL Training Loss = 0.20754344761371613
30-01-2023 21:59:11 INFO Epoch 3: [8702/10940] ---- BYOL Training Loss = 0.18726912140846252
30-01-2023 21:59:30 INFO Epoch 3: [8713/10940] ---- BYOL Training Loss = 0.19434815645217896
30-01-2023 22:00:21 INFO Epoch 3: [8713/10940] ---- BYOL Validation Loss = 0.17376886308193207
30-01-2023 22:00:39 INFO Epoch 3: [8724/10940] ---- BYOL Training Loss = 0.16633842885494232
30-01-2023 22:00:58 INFO Epoch 3: [8735/10940] ---- BYOL Training Loss = 0.17261822521686554
30-01-2023 22:01:17 INFO Epoch 3: [8746/10940] ---- BYOL Training Loss = 0.2161388099193573
30-01-2023 22:01:36 INFO Epoch 3: [8757/10940] ---- BYOL Training Loss = 0.18239596486091614
30-01-2023 22:02:27 INFO Epoch 3: [8757/10940] ---- BYOL Validation Loss = 0.1105378195643425
30-01-2023 22:02:46 INFO Epoch 3: [8768/10940] ---- BYOL Training Loss = 0.19021400809288025
30-01-2023 22:03:05 INFO Epoch 3: [8779/10940] ---- BYOL Training Loss = 0.20783087611198425
30-01-2023 22:03:23 INFO Epoch 3: [8790/10940] ---- BYOL Training Loss = 0.1870066374540329
30-01-2023 22:03:42 INFO Epoch 3: [8801/10940] ---- BYOL Training Loss = 0.19927053153514862
30-01-2023 22:04:34 INFO Epoch 3: [8801/10940] ---- BYOL Validation Loss = 0.10521173477172852
30-01-2023 22:04:52 INFO Epoch 3: [8812/10940] ---- BYOL Training Loss = 0.18436366319656372
30-01-2023 22:05:11 INFO Epoch 3: [8823/10940] ---- BYOL Training Loss = 0.15606367588043213
30-01-2023 22:05:30 INFO Epoch 3: [8834/10940] ---- BYOL Training Loss = 0.18681129813194275
30-01-2023 22:05:48 INFO Epoch 3: [8845/10940] ---- BYOL Training Loss = 0.2667272686958313
30-01-2023 22:06:40 INFO Epoch 3: [8845/10940] ---- BYOL Validation Loss = 0.14058589935302734
30-01-2023 22:06:59 INFO Epoch 3: [8856/10940] ---- BYOL Training Loss = 0.2890907824039459
30-01-2023 22:07:17 INFO Epoch 3: [8867/10940] ---- BYOL Training Loss = 0.2714678645133972
30-01-2023 22:07:36 INFO Epoch 3: [8878/10940] ---- BYOL Training Loss = 0.2910252809524536
30-01-2023 22:07:55 INFO Epoch 3: [8889/10940] ---- BYOL Training Loss = 0.2901732921600342
30-01-2023 22:08:47 INFO Epoch 3: [8889/10940] ---- BYOL Validation Loss = 0.15737174451351166
30-01-2023 22:09:05 INFO Epoch 3: [8900/10940] ---- BYOL Training Loss = 0.24073059856891632
30-01-2023 22:09:24 INFO Epoch 3: [8911/10940] ---- BYOL Training Loss = 0.1988736093044281
30-01-2023 22:09:42 INFO Epoch 3: [8922/10940] ---- BYOL Training Loss = 0.20464888215065002
30-01-2023 22:10:01 INFO Epoch 3: [8933/10940] ---- BYOL Training Loss = 0.2163524627685547
30-01-2023 22:10:53 INFO Epoch 3: [8933/10940] ---- BYOL Validation Loss = 0.12366025894880295
30-01-2023 22:11:11 INFO Epoch 3: [8944/10940] ---- BYOL Training Loss = 0.18776443600654602
30-01-2023 22:11:30 INFO Epoch 3: [8955/10940] ---- BYOL Training Loss = 0.20498546957969666
30-01-2023 22:11:49 INFO Epoch 3: [8966/10940] ---- BYOL Training Loss = 0.25210458040237427
30-01-2023 22:12:08 INFO Epoch 3: [8977/10940] ---- BYOL Training Loss = 0.2660348117351532
30-01-2023 22:12:59 INFO Epoch 3: [8977/10940] ---- BYOL Validation Loss = 0.16937629878520966
30-01-2023 22:13:18 INFO Epoch 3: [8988/10940] ---- BYOL Training Loss = 0.2720099091529846
30-01-2023 22:13:36 INFO Epoch 3: [8999/10940] ---- BYOL Training Loss = 0.23532554507255554
30-01-2023 22:13:55 INFO Epoch 3: [9010/10940] ---- BYOL Training Loss = 0.18910793960094452
30-01-2023 22:14:14 INFO Epoch 3: [9021/10940] ---- BYOL Training Loss = 0.22092774510383606
30-01-2023 22:15:06 INFO Epoch 3: [9021/10940] ---- BYOL Validation Loss = 0.17052514851093292
30-01-2023 22:15:24 INFO Epoch 3: [9032/10940] ---- BYOL Training Loss = 0.22308723628520966
30-01-2023 22:15:43 INFO Epoch 3: [9043/10940] ---- BYOL Training Loss = 0.2302946299314499
30-01-2023 22:16:01 INFO Epoch 3: [9054/10940] ---- BYOL Training Loss = 0.20432837307453156
30-01-2023 22:16:20 INFO Epoch 3: [9065/10940] ---- BYOL Training Loss = 0.19062629342079163
30-01-2023 22:17:12 INFO Epoch 3: [9065/10940] ---- BYOL Validation Loss = 0.202405646443367
30-01-2023 22:17:31 INFO Epoch 3: [9076/10940] ---- BYOL Training Loss = 0.27155935764312744
30-01-2023 22:17:49 INFO Epoch 3: [9087/10940] ---- BYOL Training Loss = 0.21770703792572021
30-01-2023 22:18:08 INFO Epoch 3: [9098/10940] ---- BYOL Training Loss = 0.20151391625404358
30-01-2023 22:18:27 INFO Epoch 3: [9109/10940] ---- BYOL Training Loss = 0.1647435873746872
30-01-2023 22:19:18 INFO Epoch 3: [9109/10940] ---- BYOL Validation Loss = 0.13517120480537415
30-01-2023 22:19:37 INFO Epoch 3: [9120/10940] ---- BYOL Training Loss = 0.18305093050003052
30-01-2023 22:19:56 INFO Epoch 3: [9131/10940] ---- BYOL Training Loss = 0.23759011924266815
30-01-2023 22:20:15 INFO Epoch 3: [9142/10940] ---- BYOL Training Loss = 0.19545605778694153
30-01-2023 22:20:33 INFO Epoch 3: [9153/10940] ---- BYOL Training Loss = 0.18233121931552887
30-01-2023 22:21:25 INFO Epoch 3: [9153/10940] ---- BYOL Validation Loss = 0.13851341605186462
30-01-2023 22:21:43 INFO Epoch 3: [9164/10940] ---- BYOL Training Loss = 0.1963280886411667
30-01-2023 22:22:02 INFO Epoch 3: [9175/10940] ---- BYOL Training Loss = 0.19139182567596436
30-01-2023 22:22:21 INFO Epoch 3: [9186/10940] ---- BYOL Training Loss = 0.23457828164100647
30-01-2023 22:22:40 INFO Epoch 3: [9197/10940] ---- BYOL Training Loss = 0.2543516755104065
30-01-2023 22:23:32 INFO Epoch 3: [9197/10940] ---- BYOL Validation Loss = 0.15704594552516937
30-01-2023 22:23:50 INFO Epoch 3: [9208/10940] ---- BYOL Training Loss = 0.18045088648796082
30-01-2023 22:24:09 INFO Epoch 3: [9219/10940] ---- BYOL Training Loss = 0.21221943199634552
30-01-2023 22:24:28 INFO Epoch 3: [9230/10940] ---- BYOL Training Loss = 0.19049043953418732
30-01-2023 22:24:47 INFO Epoch 3: [9241/10940] ---- BYOL Training Loss = 0.1952786147594452
30-01-2023 22:25:38 INFO Epoch 3: [9241/10940] ---- BYOL Validation Loss = 0.13440468907356262
30-01-2023 22:25:57 INFO Epoch 3: [9252/10940] ---- BYOL Training Loss = 0.2015933096408844
30-01-2023 22:26:16 INFO Epoch 3: [9263/10940] ---- BYOL Training Loss = 0.2192157506942749
30-01-2023 22:26:34 INFO Epoch 3: [9274/10940] ---- BYOL Training Loss = 0.18339478969573975
30-01-2023 22:26:53 INFO Epoch 3: [9285/10940] ---- BYOL Training Loss = 0.13485300540924072
30-01-2023 22:27:45 INFO Epoch 3: [9285/10940] ---- BYOL Validation Loss = 0.11979474872350693
30-01-2023 22:28:03 INFO Epoch 3: [9296/10940] ---- BYOL Training Loss = 0.13789844512939453
30-01-2023 22:28:22 INFO Epoch 3: [9307/10940] ---- BYOL Training Loss = 0.1935156285762787
30-01-2023 22:28:41 INFO Epoch 3: [9318/10940] ---- BYOL Training Loss = 0.20594212412834167
30-01-2023 22:29:00 INFO Epoch 3: [9329/10940] ---- BYOL Training Loss = 0.18006590008735657
30-01-2023 22:29:52 INFO Epoch 3: [9329/10940] ---- BYOL Validation Loss = 0.14792943000793457
30-01-2023 22:30:10 INFO Epoch 3: [9340/10940] ---- BYOL Training Loss = 0.16291210055351257
30-01-2023 22:30:29 INFO Epoch 3: [9351/10940] ---- BYOL Training Loss = 0.2587520480155945
30-01-2023 22:30:48 INFO Epoch 3: [9362/10940] ---- BYOL Training Loss = 0.31856876611709595
30-01-2023 22:31:07 INFO Epoch 3: [9373/10940] ---- BYOL Training Loss = 0.23548908531665802
30-01-2023 22:31:58 INFO Epoch 3: [9373/10940] ---- BYOL Validation Loss = 0.14756999909877777
30-01-2023 22:32:17 INFO Epoch 3: [9384/10940] ---- BYOL Training Loss = 0.15108224749565125
30-01-2023 22:32:36 INFO Epoch 3: [9395/10940] ---- BYOL Training Loss = 0.333812952041626
30-01-2023 22:32:54 INFO Epoch 3: [9406/10940] ---- BYOL Training Loss = 0.3325578272342682
30-01-2023 22:33:13 INFO Epoch 3: [9417/10940] ---- BYOL Training Loss = 0.19142593443393707
30-01-2023 22:34:05 INFO Epoch 3: [9417/10940] ---- BYOL Validation Loss = 0.10313583165407181
30-01-2023 22:34:24 INFO Epoch 3: [9428/10940] ---- BYOL Training Loss = 0.18669773638248444
30-01-2023 22:34:42 INFO Epoch 3: [9439/10940] ---- BYOL Training Loss = 0.18085011839866638
30-01-2023 22:35:01 INFO Epoch 3: [9450/10940] ---- BYOL Training Loss = 0.206716850399971
30-01-2023 22:35:20 INFO Epoch 3: [9461/10940] ---- BYOL Training Loss = 0.232020765542984
30-01-2023 22:36:12 INFO Epoch 3: [9461/10940] ---- BYOL Validation Loss = 0.10313086211681366
30-01-2023 22:36:30 INFO Epoch 3: [9472/10940] ---- BYOL Training Loss = 0.24104242026805878
30-01-2023 22:36:49 INFO Epoch 3: [9483/10940] ---- BYOL Training Loss = 0.22179722785949707
30-01-2023 22:37:08 INFO Epoch 3: [9494/10940] ---- BYOL Training Loss = 0.20450210571289062
30-01-2023 22:37:27 INFO Epoch 3: [9505/10940] ---- BYOL Training Loss = 0.2182859480381012
30-01-2023 22:38:19 INFO Epoch 3: [9505/10940] ---- BYOL Validation Loss = 0.14730562269687653
30-01-2023 22:38:37 INFO Epoch 3: [9516/10940] ---- BYOL Training Loss = 0.18807537853717804
30-01-2023 22:38:56 INFO Epoch 3: [9527/10940] ---- BYOL Training Loss = 0.1976369023323059
30-01-2023 22:39:15 INFO Epoch 3: [9538/10940] ---- BYOL Training Loss = 0.21515341103076935
30-01-2023 22:39:33 INFO Epoch 3: [9549/10940] ---- BYOL Training Loss = 0.21616864204406738
30-01-2023 22:40:25 INFO Epoch 3: [9549/10940] ---- BYOL Validation Loss = 0.1777331829071045
30-01-2023 22:40:44 INFO Epoch 3: [9560/10940] ---- BYOL Training Loss = 0.24309220910072327
30-01-2023 22:41:03 INFO Epoch 3: [9571/10940] ---- BYOL Training Loss = 0.22866840660572052
30-01-2023 22:41:21 INFO Epoch 3: [9582/10940] ---- BYOL Training Loss = 0.21025016903877258
30-01-2023 22:41:40 INFO Epoch 3: [9593/10940] ---- BYOL Training Loss = 0.19758057594299316
30-01-2023 22:42:32 INFO Epoch 3: [9593/10940] ---- BYOL Validation Loss = 0.1406569629907608
30-01-2023 22:42:50 INFO Epoch 3: [9604/10940] ---- BYOL Training Loss = 0.16643300652503967
30-01-2023 22:43:10 INFO Epoch 3: [9615/10940] ---- BYOL Training Loss = 0.1460687816143036
30-01-2023 22:43:28 INFO Epoch 3: [9626/10940] ---- BYOL Training Loss = 0.15205226838588715
30-01-2023 22:43:47 INFO Epoch 3: [9637/10940] ---- BYOL Training Loss = 0.18840596079826355
30-01-2023 22:44:39 INFO Epoch 3: [9637/10940] ---- BYOL Validation Loss = 0.14420688152313232
30-01-2023 22:44:58 INFO Epoch 3: [9648/10940] ---- BYOL Training Loss = 0.20942501723766327
30-01-2023 22:45:16 INFO Epoch 3: [9659/10940] ---- BYOL Training Loss = 0.17130081355571747
30-01-2023 22:45:35 INFO Epoch 3: [9670/10940] ---- BYOL Training Loss = 0.20007050037384033
30-01-2023 22:45:54 INFO Epoch 3: [9681/10940] ---- BYOL Training Loss = 0.22278837859630585
30-01-2023 22:46:46 INFO Epoch 3: [9681/10940] ---- BYOL Validation Loss = 0.10777442902326584
30-01-2023 22:47:05 INFO Epoch 3: [9692/10940] ---- BYOL Training Loss = 0.20070524513721466
30-01-2023 22:47:23 INFO Epoch 3: [9703/10940] ---- BYOL Training Loss = 0.21652352809906006
30-01-2023 22:47:42 INFO Epoch 3: [9714/10940] ---- BYOL Training Loss = 0.21899613738059998
30-01-2023 22:48:01 INFO Epoch 3: [9725/10940] ---- BYOL Training Loss = 0.21952763199806213
30-01-2023 22:48:53 INFO Epoch 3: [9725/10940] ---- BYOL Validation Loss = 0.11290327459573746
30-01-2023 22:49:11 INFO Epoch 3: [9736/10940] ---- BYOL Training Loss = 0.21776580810546875
30-01-2023 22:49:30 INFO Epoch 3: [9747/10940] ---- BYOL Training Loss = 0.19681885838508606
30-01-2023 22:49:49 INFO Epoch 3: [9758/10940] ---- BYOL Training Loss = 0.22230593860149384
30-01-2023 22:50:08 INFO Epoch 3: [9769/10940] ---- BYOL Training Loss = 0.2597644627094269
30-01-2023 22:51:00 INFO Epoch 3: [9769/10940] ---- BYOL Validation Loss = 0.12571261823177338
30-01-2023 22:51:18 INFO Epoch 3: [9780/10940] ---- BYOL Training Loss = 0.24116583168506622
30-01-2023 22:51:37 INFO Epoch 3: [9791/10940] ---- BYOL Training Loss = 0.2354745864868164
30-01-2023 22:51:56 INFO Epoch 3: [9802/10940] ---- BYOL Training Loss = 0.21056024730205536
30-01-2023 22:52:15 INFO Epoch 3: [9813/10940] ---- BYOL Training Loss = 0.18437476456165314
30-01-2023 22:53:07 INFO Epoch 3: [9813/10940] ---- BYOL Validation Loss = 0.10713917762041092
30-01-2023 22:53:25 INFO Epoch 3: [9824/10940] ---- BYOL Training Loss = 0.17096315324306488
30-01-2023 22:53:44 INFO Epoch 3: [9835/10940] ---- BYOL Training Loss = 0.23051539063453674
30-01-2023 22:54:03 INFO Epoch 3: [9846/10940] ---- BYOL Training Loss = 0.2214169055223465
30-01-2023 22:54:22 INFO Epoch 3: [9857/10940] ---- BYOL Training Loss = 0.18862324953079224
30-01-2023 22:55:14 INFO Epoch 3: [9857/10940] ---- BYOL Validation Loss = 0.10223884135484695
30-01-2023 22:55:32 INFO Epoch 3: [9868/10940] ---- BYOL Training Loss = 0.2037612944841385
30-01-2023 22:55:51 INFO Epoch 3: [9879/10940] ---- BYOL Training Loss = 0.2343340367078781
30-01-2023 22:56:10 INFO Epoch 3: [9890/10940] ---- BYOL Training Loss = 0.171357661485672
30-01-2023 22:56:29 INFO Epoch 3: [9901/10940] ---- BYOL Training Loss = 0.17636215686798096
30-01-2023 22:57:21 INFO Epoch 3: [9901/10940] ---- BYOL Validation Loss = 0.08900157362222672
30-01-2023 22:57:39 INFO Epoch 3: [9912/10940] ---- BYOL Training Loss = 0.20363938808441162
30-01-2023 22:57:58 INFO Epoch 3: [9923/10940] ---- BYOL Training Loss = 0.19782069325447083
30-01-2023 22:58:17 INFO Epoch 3: [9934/10940] ---- BYOL Training Loss = 0.19280222058296204
30-01-2023 22:58:36 INFO Epoch 3: [9945/10940] ---- BYOL Training Loss = 0.1722026765346527
30-01-2023 22:59:28 INFO Epoch 3: [9945/10940] ---- BYOL Validation Loss = 0.11576244980096817
30-01-2023 22:59:47 INFO Epoch 3: [9956/10940] ---- BYOL Training Loss = 0.18284623324871063
30-01-2023 23:00:05 INFO Epoch 3: [9967/10940] ---- BYOL Training Loss = 0.16081169247627258
30-01-2023 23:00:24 INFO Epoch 3: [9978/10940] ---- BYOL Training Loss = 0.22467908263206482
30-01-2023 23:00:43 INFO Epoch 3: [9989/10940] ---- BYOL Training Loss = 0.24192628264427185
30-01-2023 23:01:35 INFO Epoch 3: [9989/10940] ---- BYOL Validation Loss = 0.1294049769639969
30-01-2023 23:01:54 INFO Epoch 3: [10000/10940] ---- BYOL Training Loss = 0.23779752850532532
30-01-2023 23:02:13 INFO Epoch 3: [10011/10940] ---- BYOL Training Loss = 0.22547674179077148
30-01-2023 23:02:31 INFO Epoch 3: [10022/10940] ---- BYOL Training Loss = 0.2622981667518616
30-01-2023 23:02:51 INFO Epoch 3: [10033/10940] ---- BYOL Training Loss = 0.2586176097393036
30-01-2023 23:03:42 INFO Epoch 3: [10033/10940] ---- BYOL Validation Loss = 0.08059811592102051
30-01-2023 23:04:01 INFO Epoch 3: [10044/10940] ---- BYOL Training Loss = 0.19355717301368713
30-01-2023 23:04:19 INFO Epoch 3: [10055/10940] ---- BYOL Training Loss = 0.2421099841594696
30-01-2023 23:04:39 INFO Epoch 3: [10066/10940] ---- BYOL Training Loss = 0.2830967307090759
30-01-2023 23:04:57 INFO Epoch 3: [10077/10940] ---- BYOL Training Loss = 0.25466135144233704
30-01-2023 23:05:49 INFO Epoch 3: [10077/10940] ---- BYOL Validation Loss = 0.09137061983346939
30-01-2023 23:06:08 INFO Epoch 3: [10088/10940] ---- BYOL Training Loss = 0.1864505410194397
30-01-2023 23:06:27 INFO Epoch 3: [10099/10940] ---- BYOL Training Loss = 0.18099793791770935
30-01-2023 23:06:46 INFO Epoch 3: [10110/10940] ---- BYOL Training Loss = 0.18572162091732025
30-01-2023 23:07:04 INFO Epoch 3: [10121/10940] ---- BYOL Training Loss = 0.2183280736207962
30-01-2023 23:07:56 INFO Epoch 3: [10121/10940] ---- BYOL Validation Loss = 0.12526793777942657
30-01-2023 23:08:15 INFO Epoch 3: [10132/10940] ---- BYOL Training Loss = 0.2591228187084198
30-01-2023 23:08:34 INFO Epoch 3: [10143/10940] ---- BYOL Training Loss = 0.19222058355808258
30-01-2023 23:08:52 INFO Epoch 3: [10154/10940] ---- BYOL Training Loss = 0.20176628232002258
30-01-2023 23:09:12 INFO Epoch 3: [10165/10940] ---- BYOL Training Loss = 0.18883506953716278
30-01-2023 23:10:03 INFO Epoch 3: [10165/10940] ---- BYOL Validation Loss = 0.11681850999593735
30-01-2023 23:10:22 INFO Epoch 3: [10176/10940] ---- BYOL Training Loss = 0.2228119671344757
30-01-2023 23:10:41 INFO Epoch 3: [10187/10940] ---- BYOL Training Loss = 0.20892584323883057
30-01-2023 23:11:00 INFO Epoch 3: [10198/10940] ---- BYOL Training Loss = 0.20953500270843506
30-01-2023 23:11:19 INFO Epoch 3: [10209/10940] ---- BYOL Training Loss = 0.1917046755552292
30-01-2023 23:12:11 INFO Epoch 3: [10209/10940] ---- BYOL Validation Loss = 0.10652423650026321
30-01-2023 23:12:29 INFO Epoch 3: [10220/10940] ---- BYOL Training Loss = 0.19573666155338287
30-01-2023 23:12:48 INFO Epoch 3: [10231/10940] ---- BYOL Training Loss = 0.20522108674049377
30-01-2023 23:13:07 INFO Epoch 3: [10242/10940] ---- BYOL Training Loss = 0.1818879097700119
30-01-2023 23:13:26 INFO Epoch 3: [10253/10940] ---- BYOL Training Loss = 0.2509724497795105
30-01-2023 23:14:18 INFO Epoch 3: [10253/10940] ---- BYOL Validation Loss = 0.11672942340373993
30-01-2023 23:14:36 INFO Epoch 3: [10264/10940] ---- BYOL Training Loss = 0.2273956835269928
30-01-2023 23:14:55 INFO Epoch 3: [10275/10940] ---- BYOL Training Loss = 0.17209061980247498
30-01-2023 23:15:14 INFO Epoch 3: [10286/10940] ---- BYOL Training Loss = 0.16967615485191345
30-01-2023 23:15:33 INFO Epoch 3: [10297/10940] ---- BYOL Training Loss = 0.18924829363822937
30-01-2023 23:16:25 INFO Epoch 3: [10297/10940] ---- BYOL Validation Loss = 0.10625048726797104
30-01-2023 23:16:44 INFO Epoch 3: [10308/10940] ---- BYOL Training Loss = 0.23352515697479248
30-01-2023 23:17:02 INFO Epoch 3: [10319/10940] ---- BYOL Training Loss = 0.1900085210800171
30-01-2023 23:17:22 INFO Epoch 3: [10330/10940] ---- BYOL Training Loss = 0.15598218142986298
30-01-2023 23:17:40 INFO Epoch 3: [10341/10940] ---- BYOL Training Loss = 0.19687357544898987
30-01-2023 23:18:32 INFO Epoch 3: [10341/10940] ---- BYOL Validation Loss = 0.12493842095136642
30-01-2023 23:18:50 INFO Epoch 3: [10352/10940] ---- BYOL Training Loss = 0.23882217705249786
30-01-2023 23:19:10 INFO Epoch 3: [10363/10940] ---- BYOL Training Loss = 0.20388071238994598
30-01-2023 23:19:28 INFO Epoch 3: [10374/10940] ---- BYOL Training Loss = 0.2047853171825409
30-01-2023 23:19:47 INFO Epoch 3: [10385/10940] ---- BYOL Training Loss = 0.19783872365951538
30-01-2023 23:20:39 INFO Epoch 3: [10385/10940] ---- BYOL Validation Loss = 0.13791336119174957
30-01-2023 23:20:58 INFO Epoch 3: [10396/10940] ---- BYOL Training Loss = 0.14434917271137238
30-01-2023 23:21:16 INFO Epoch 3: [10407/10940] ---- BYOL Training Loss = 0.17528630793094635
30-01-2023 23:21:36 INFO Epoch 3: [10418/10940] ---- BYOL Training Loss = 0.23492248356342316
30-01-2023 23:21:54 INFO Epoch 3: [10429/10940] ---- BYOL Training Loss = 0.2154427468776703
30-01-2023 23:22:46 INFO Epoch 3: [10429/10940] ---- BYOL Validation Loss = 0.1469351202249527
30-01-2023 23:23:05 INFO Epoch 3: [10440/10940] ---- BYOL Training Loss = 0.2150859832763672
30-01-2023 23:23:24 INFO Epoch 3: [10451/10940] ---- BYOL Training Loss = 0.21199508011341095
30-01-2023 23:23:43 INFO Epoch 3: [10462/10940] ---- BYOL Training Loss = 0.19509552419185638
30-01-2023 23:24:02 INFO Epoch 3: [10473/10940] ---- BYOL Training Loss = 0.2167506217956543
30-01-2023 23:24:53 INFO Epoch 3: [10473/10940] ---- BYOL Validation Loss = 0.08689731359481812
30-01-2023 23:25:12 INFO Epoch 3: [10484/10940] ---- BYOL Training Loss = 0.18190298974514008
30-01-2023 23:25:31 INFO Epoch 3: [10495/10940] ---- BYOL Training Loss = 0.23092356324195862
30-01-2023 23:25:50 INFO Epoch 3: [10506/10940] ---- BYOL Training Loss = 0.20550385117530823
30-01-2023 23:26:09 INFO Epoch 3: [10517/10940] ---- BYOL Training Loss = 0.19358694553375244
30-01-2023 23:27:01 INFO Epoch 3: [10517/10940] ---- BYOL Validation Loss = 0.09932737052440643
30-01-2023 23:27:20 INFO Epoch 3: [10528/10940] ---- BYOL Training Loss = 0.19119606912136078
30-01-2023 23:27:38 INFO Epoch 3: [10539/10940] ---- BYOL Training Loss = 0.1992012858390808
30-01-2023 23:27:57 INFO Epoch 3: [10550/10940] ---- BYOL Training Loss = 0.19400957226753235
30-01-2023 23:28:16 INFO Epoch 3: [10561/10940] ---- BYOL Training Loss = 0.16220425069332123
30-01-2023 23:29:08 INFO Epoch 3: [10561/10940] ---- BYOL Validation Loss = 0.10004036873579025
30-01-2023 23:29:26 INFO Epoch 3: [10572/10940] ---- BYOL Training Loss = 0.24559596180915833
30-01-2023 23:29:45 INFO Epoch 3: [10583/10940] ---- BYOL Training Loss = 0.2532314658164978
30-01-2023 23:30:04 INFO Epoch 3: [10594/10940] ---- BYOL Training Loss = 0.21475975215435028
30-01-2023 23:30:23 INFO Epoch 3: [10605/10940] ---- BYOL Training Loss = 0.21373435854911804
30-01-2023 23:31:15 INFO Epoch 3: [10605/10940] ---- BYOL Validation Loss = 0.11181851476430893
30-01-2023 23:31:34 INFO Epoch 3: [10616/10940] ---- BYOL Training Loss = 0.24382245540618896
30-01-2023 23:31:53 INFO Epoch 3: [10627/10940] ---- BYOL Training Loss = 0.2216854989528656
30-01-2023 23:32:12 INFO Epoch 3: [10638/10940] ---- BYOL Training Loss = 0.1826995462179184
30-01-2023 23:32:30 INFO Epoch 3: [10649/10940] ---- BYOL Training Loss = 0.18878088891506195
30-01-2023 23:33:22 INFO Epoch 3: [10649/10940] ---- BYOL Validation Loss = 0.10991328209638596
30-01-2023 23:33:41 INFO Epoch 3: [10660/10940] ---- BYOL Training Loss = 0.17594221234321594
30-01-2023 23:34:00 INFO Epoch 3: [10671/10940] ---- BYOL Training Loss = 0.15182730555534363
30-01-2023 23:34:19 INFO Epoch 3: [10682/10940] ---- BYOL Training Loss = 0.2427615225315094
30-01-2023 23:34:37 INFO Epoch 3: [10693/10940] ---- BYOL Training Loss = 0.19711799919605255
30-01-2023 23:35:29 INFO Epoch 3: [10693/10940] ---- BYOL Validation Loss = 0.09254379570484161
30-01-2023 23:35:48 INFO Epoch 3: [10704/10940] ---- BYOL Training Loss = 0.2572311758995056
30-01-2023 23:36:07 INFO Epoch 3: [10715/10940] ---- BYOL Training Loss = 0.2563644051551819
30-01-2023 23:36:26 INFO Epoch 3: [10726/10940] ---- BYOL Training Loss = 0.26674386858940125
30-01-2023 23:36:45 INFO Epoch 3: [10737/10940] ---- BYOL Training Loss = 0.2890779674053192
30-01-2023 23:37:37 INFO Epoch 3: [10737/10940] ---- BYOL Validation Loss = 0.14004096388816833
30-01-2023 23:37:55 INFO Epoch 3: [10748/10940] ---- BYOL Training Loss = 0.22635230422019958
30-01-2023 23:38:14 INFO Epoch 3: [10759/10940] ---- BYOL Training Loss = 0.19325195252895355
30-01-2023 23:38:33 INFO Epoch 3: [10770/10940] ---- BYOL Training Loss = 0.23970532417297363
30-01-2023 23:38:52 INFO Epoch 3: [10781/10940] ---- BYOL Training Loss = 0.21914193034172058
30-01-2023 23:39:44 INFO Epoch 3: [10781/10940] ---- BYOL Validation Loss = 0.1337033063173294
30-01-2023 23:40:03 INFO Epoch 3: [10792/10940] ---- BYOL Training Loss = 0.17996041476726532
30-01-2023 23:40:21 INFO Epoch 3: [10803/10940] ---- BYOL Training Loss = 0.18129868805408478
30-01-2023 23:40:40 INFO Epoch 3: [10814/10940] ---- BYOL Training Loss = 0.19724012911319733
30-01-2023 23:40:59 INFO Epoch 3: [10825/10940] ---- BYOL Training Loss = 0.16974805295467377
30-01-2023 23:41:51 INFO Epoch 3: [10825/10940] ---- BYOL Validation Loss = 0.12202741205692291
30-01-2023 23:42:10 INFO Epoch 3: [10836/10940] ---- BYOL Training Loss = 0.17797598242759705
30-01-2023 23:42:29 INFO Epoch 3: [10847/10940] ---- BYOL Training Loss = 0.17866751551628113
30-01-2023 23:42:48 INFO Epoch 3: [10858/10940] ---- BYOL Training Loss = 0.19526110589504242
30-01-2023 23:43:07 INFO Epoch 3: [10869/10940] ---- BYOL Training Loss = 0.1757877767086029
30-01-2023 23:43:59 INFO Epoch 3: [10869/10940] ---- BYOL Validation Loss = 0.1377590447664261
30-01-2023 23:44:17 INFO Epoch 3: [10880/10940] ---- BYOL Training Loss = 0.28225940465927124
30-01-2023 23:44:36 INFO Epoch 3: [10891/10940] ---- BYOL Training Loss = 0.2999579906463623
30-01-2023 23:44:55 INFO Epoch 3: [10902/10940] ---- BYOL Training Loss = 0.21496453881263733
30-01-2023 23:45:14 INFO Epoch 3: [10913/10940] ---- BYOL Training Loss = 0.1764688640832901
30-01-2023 23:46:06 INFO Epoch 3: [10913/10940] ---- BYOL Validation Loss = 0.14628443121910095
30-01-2023 23:46:24 INFO Epoch 3: [10924/10940] ---- BYOL Training Loss = 0.20986099541187286
30-01-2023 23:46:43 INFO Epoch 3: [10935/10940] ---- BYOL Training Loss = 0.20233671367168427
30-01-2023 23:46:52 INFO Starting Epoch: 4
30-01-2023 23:47:11 INFO Epoch 4: [12/10940] ---- BYOL Training Loss = 0.15390585362911224
30-01-2023 23:47:29 INFO Epoch 4: [23/10940] ---- BYOL Training Loss = 0.17636366188526154
30-01-2023 23:47:47 INFO Epoch 4: [34/10940] ---- BYOL Training Loss = 0.18648996949195862
30-01-2023 23:48:04 INFO Epoch 4: [45/10940] ---- BYOL Training Loss = 0.24891920387744904
30-01-2023 23:48:56 INFO Epoch 4: [45/10940] ---- BYOL Validation Loss = 0.14466966688632965
30-01-2023 23:49:14 INFO Epoch 4: [56/10940] ---- BYOL Training Loss = 0.22252655029296875
30-01-2023 23:49:32 INFO Epoch 4: [67/10940] ---- BYOL Training Loss = 0.16107147932052612
30-01-2023 23:49:50 INFO Epoch 4: [78/10940] ---- BYOL Training Loss = 0.16863442957401276
30-01-2023 23:50:08 INFO Epoch 4: [89/10940] ---- BYOL Training Loss = 0.17749805748462677
30-01-2023 23:51:00 INFO Epoch 4: [89/10940] ---- BYOL Validation Loss = 0.13799242675304413
30-01-2023 23:51:17 INFO Epoch 4: [100/10940] ---- BYOL Training Loss = 0.2192138135433197
30-01-2023 23:51:35 INFO Epoch 4: [111/10940] ---- BYOL Training Loss = 0.22156593203544617
30-01-2023 23:51:53 INFO Epoch 4: [122/10940] ---- BYOL Training Loss = 0.19741661846637726
30-01-2023 23:52:11 INFO Epoch 4: [133/10940] ---- BYOL Training Loss = 0.17987433075904846
30-01-2023 23:53:02 INFO Epoch 4: [133/10940] ---- BYOL Validation Loss = 0.12757624685764313
30-01-2023 23:53:20 INFO Epoch 4: [144/10940] ---- BYOL Training Loss = 0.25277644395828247
30-01-2023 23:53:38 INFO Epoch 4: [155/10940] ---- BYOL Training Loss = 0.22475416958332062
30-01-2023 23:53:56 INFO Epoch 4: [166/10940] ---- BYOL Training Loss = 0.17926904559135437
30-01-2023 23:54:14 INFO Epoch 4: [177/10940] ---- BYOL Training Loss = 0.19037210941314697
30-01-2023 23:55:05 INFO Epoch 4: [177/10940] ---- BYOL Validation Loss = 0.13838927447795868
30-01-2023 23:55:23 INFO Epoch 4: [188/10940] ---- BYOL Training Loss = 0.19647638499736786
30-01-2023 23:55:41 INFO Epoch 4: [199/10940] ---- BYOL Training Loss = 0.21324364840984344
30-01-2023 23:55:59 INFO Epoch 4: [210/10940] ---- BYOL Training Loss = 0.20648816227912903
30-01-2023 23:56:17 INFO Epoch 4: [221/10940] ---- BYOL Training Loss = 0.2228246033191681
30-01-2023 23:57:09 INFO Epoch 4: [221/10940] ---- BYOL Validation Loss = 0.12931863963603973
30-01-2023 23:57:26 INFO Epoch 4: [232/10940] ---- BYOL Training Loss = 0.3194301724433899
30-01-2023 23:57:44 INFO Epoch 4: [243/10940] ---- BYOL Training Loss = 0.25289788842201233
30-01-2023 23:58:02 INFO Epoch 4: [254/10940] ---- BYOL Training Loss = 0.17511653900146484
30-01-2023 23:58:20 INFO Epoch 4: [265/10940] ---- BYOL Training Loss = 0.1986934393644333
30-01-2023 23:59:12 INFO Epoch 4: [265/10940] ---- BYOL Validation Loss = 0.14037401974201202
30-01-2023 23:59:29 INFO Epoch 4: [276/10940] ---- BYOL Training Loss = 0.18632128834724426
30-01-2023 23:59:47 INFO Epoch 4: [287/10940] ---- BYOL Training Loss = 0.16638819873332977
31-01-2023 00:00:05 INFO Epoch 4: [298/10940] ---- BYOL Training Loss = 0.14889799058437347
slurmstepd-landonia23: error: slurm_get_node_energy: Connection refused
slurmstepd-landonia23: error: _get_joules_task: can't get info from slurmd
31-01-2023 00:00:23 INFO Epoch 4: [309/10940] ---- BYOL Training Loss = 0.17277783155441284
31-01-2023 00:01:15 INFO Epoch 4: [309/10940] ---- BYOL Validation Loss = 0.12376513332128525
31-01-2023 00:01:32 INFO Epoch 4: [320/10940] ---- BYOL Training Loss = 0.223589688539505
31-01-2023 00:01:50 INFO Epoch 4: [331/10940] ---- BYOL Training Loss = 0.22308564186096191
31-01-2023 00:02:08 INFO Epoch 4: [342/10940] ---- BYOL Training Loss = 0.2329300194978714
31-01-2023 00:02:26 INFO Epoch 4: [353/10940] ---- BYOL Training Loss = 0.18781891465187073
31-01-2023 00:03:18 INFO Epoch 4: [353/10940] ---- BYOL Validation Loss = 0.0815204530954361
31-01-2023 00:03:35 INFO Epoch 4: [364/10940] ---- BYOL Training Loss = 0.2134791612625122
31-01-2023 00:03:53 INFO Epoch 4: [375/10940] ---- BYOL Training Loss = 0.1909172683954239
31-01-2023 00:04:11 INFO Epoch 4: [386/10940] ---- BYOL Training Loss = 0.19294412434101105
31-01-2023 00:04:29 INFO Epoch 4: [397/10940] ---- BYOL Training Loss = 0.25871944427490234
31-01-2023 00:05:21 INFO Epoch 4: [397/10940] ---- BYOL Validation Loss = 0.16519084572792053
31-01-2023 00:05:39 INFO Epoch 4: [408/10940] ---- BYOL Training Loss = 0.2061961442232132
31-01-2023 00:05:57 INFO Epoch 4: [419/10940] ---- BYOL Training Loss = 0.2003839910030365
31-01-2023 00:06:15 INFO Epoch 4: [430/10940] ---- BYOL Training Loss = 0.1763181984424591
31-01-2023 00:06:33 INFO Epoch 4: [441/10940] ---- BYOL Training Loss = 0.15515875816345215
31-01-2023 00:07:25 INFO Epoch 4: [441/10940] ---- BYOL Validation Loss = 0.10785424709320068
31-01-2023 00:07:42 INFO Epoch 4: [452/10940] ---- BYOL Training Loss = 0.1761661171913147
31-01-2023 00:08:00 INFO Epoch 4: [463/10940] ---- BYOL Training Loss = 0.17515605688095093
31-01-2023 00:08:18 INFO Epoch 4: [474/10940] ---- BYOL Training Loss = 0.1519327461719513
31-01-2023 00:08:36 INFO Epoch 4: [485/10940] ---- BYOL Training Loss = 0.18097133934497833
31-01-2023 00:09:28 INFO Epoch 4: [485/10940] ---- BYOL Validation Loss = 0.1661573201417923
31-01-2023 00:09:45 INFO Epoch 4: [496/10940] ---- BYOL Training Loss = 0.22895927727222443
31-01-2023 00:10:03 INFO Epoch 4: [507/10940] ---- BYOL Training Loss = 0.1853841096162796
31-01-2023 00:10:21 INFO Epoch 4: [518/10940] ---- BYOL Training Loss = 0.21012592315673828
31-01-2023 00:10:39 INFO Epoch 4: [529/10940] ---- BYOL Training Loss = 0.19655469059944153
31-01-2023 00:11:31 INFO Epoch 4: [529/10940] ---- BYOL Validation Loss = 0.13625338673591614
31-01-2023 00:11:48 INFO Epoch 4: [540/10940] ---- BYOL Training Loss = 0.22941496968269348
31-01-2023 00:12:06 INFO Epoch 4: [551/10940] ---- BYOL Training Loss = 0.2277822196483612
31-01-2023 00:12:24 INFO Epoch 4: [562/10940] ---- BYOL Training Loss = 0.15423919260501862
31-01-2023 00:12:42 INFO Epoch 4: [573/10940] ---- BYOL Training Loss = 0.1744268834590912
31-01-2023 00:13:34 INFO Epoch 4: [573/10940] ---- BYOL Validation Loss = 0.15748392045497894
31-01-2023 00:13:52 INFO Epoch 4: [584/10940] ---- BYOL Training Loss = 0.20977365970611572
31-01-2023 00:14:09 INFO Epoch 4: [595/10940] ---- BYOL Training Loss = 0.208835169672966
31-01-2023 00:14:27 INFO Epoch 4: [606/10940] ---- BYOL Training Loss = 0.2136727124452591
31-01-2023 00:14:45 INFO Epoch 4: [617/10940] ---- BYOL Training Loss = 0.21046197414398193
31-01-2023 00:15:37 INFO Epoch 4: [617/10940] ---- BYOL Validation Loss = 0.12471391260623932
31-01-2023 00:15:55 INFO Epoch 4: [628/10940] ---- BYOL Training Loss = 0.1788443922996521
31-01-2023 00:16:13 INFO Epoch 4: [639/10940] ---- BYOL Training Loss = 0.17450319230556488
31-01-2023 00:16:31 INFO Epoch 4: [650/10940] ---- BYOL Training Loss = 0.14375928044319153
31-01-2023 00:16:49 INFO Epoch 4: [661/10940] ---- BYOL Training Loss = 0.15445852279663086
31-01-2023 00:17:41 INFO Epoch 4: [661/10940] ---- BYOL Validation Loss = 0.1175568625330925
31-01-2023 00:17:58 INFO Epoch 4: [672/10940] ---- BYOL Training Loss = 0.2090892791748047
31-01-2023 00:18:16 INFO Epoch 4: [683/10940] ---- BYOL Training Loss = 0.191278874874115
31-01-2023 00:18:34 INFO Epoch 4: [694/10940] ---- BYOL Training Loss = 0.16822712123394012
31-01-2023 00:18:52 INFO Epoch 4: [705/10940] ---- BYOL Training Loss = 0.17676374316215515
31-01-2023 00:19:44 INFO Epoch 4: [705/10940] ---- BYOL Validation Loss = 0.12393692880868912
31-01-2023 00:20:02 INFO Epoch 4: [716/10940] ---- BYOL Training Loss = 0.197362020611763
31-01-2023 00:20:20 INFO Epoch 4: [727/10940] ---- BYOL Training Loss = 0.19875648617744446
31-01-2023 00:20:38 INFO Epoch 4: [738/10940] ---- BYOL Training Loss = 0.16567294299602509
31-01-2023 00:20:56 INFO Epoch 4: [749/10940] ---- BYOL Training Loss = 0.13203445076942444
31-01-2023 00:21:48 INFO Epoch 4: [749/10940] ---- BYOL Validation Loss = 0.12093407660722733
31-01-2023 00:22:05 INFO Epoch 4: [760/10940] ---- BYOL Training Loss = 0.1533082276582718
31-01-2023 00:22:23 INFO Epoch 4: [771/10940] ---- BYOL Training Loss = 0.21469871699810028
31-01-2023 00:22:41 INFO Epoch 4: [782/10940] ---- BYOL Training Loss = 0.2000066041946411
31-01-2023 00:22:59 INFO Epoch 4: [793/10940] ---- BYOL Training Loss = 0.21313278377056122
31-01-2023 00:23:51 INFO Epoch 4: [793/10940] ---- BYOL Validation Loss = 0.15270812809467316
31-01-2023 00:24:08 INFO Epoch 4: [804/10940] ---- BYOL Training Loss = 0.16107869148254395
31-01-2023 00:24:26 INFO Epoch 4: [815/10940] ---- BYOL Training Loss = 0.17358025908470154
31-01-2023 00:24:45 INFO Epoch 4: [826/10940] ---- BYOL Training Loss = 0.19043411314487457
31-01-2023 00:25:02 INFO Epoch 4: [837/10940] ---- BYOL Training Loss = 0.18963834643363953
31-01-2023 00:25:54 INFO Epoch 4: [837/10940] ---- BYOL Validation Loss = 0.1635744273662567
31-01-2023 00:26:12 INFO Epoch 4: [848/10940] ---- BYOL Training Loss = 0.1738215982913971
31-01-2023 00:26:30 INFO Epoch 4: [859/10940] ---- BYOL Training Loss = 0.1797437220811844
31-01-2023 00:26:48 INFO Epoch 4: [870/10940] ---- BYOL Training Loss = 0.2245628386735916
31-01-2023 00:27:06 INFO Epoch 4: [881/10940] ---- BYOL Training Loss = 0.207065612077713
31-01-2023 00:27:58 INFO Epoch 4: [881/10940] ---- BYOL Validation Loss = 0.1522681713104248
31-01-2023 00:28:16 INFO Epoch 4: [892/10940] ---- BYOL Training Loss = 0.19132979214191437
31-01-2023 00:28:33 INFO Epoch 4: [903/10940] ---- BYOL Training Loss = 0.18054233491420746
31-01-2023 00:28:51 INFO Epoch 4: [914/10940] ---- BYOL Training Loss = 0.16098934412002563
31-01-2023 00:29:09 INFO Epoch 4: [925/10940] ---- BYOL Training Loss = 0.15465477108955383
31-01-2023 00:30:01 INFO Epoch 4: [925/10940] ---- BYOL Validation Loss = 0.16365180909633636
31-01-2023 00:30:19 INFO Epoch 4: [936/10940] ---- BYOL Training Loss = 0.18667663633823395
31-01-2023 00:30:37 INFO Epoch 4: [947/10940] ---- BYOL Training Loss = 0.1869601309299469
31-01-2023 00:30:55 INFO Epoch 4: [958/10940] ---- BYOL Training Loss = 0.189710795879364
31-01-2023 00:31:13 INFO Epoch 4: [969/10940] ---- BYOL Training Loss = 0.18611322343349457
31-01-2023 00:32:05 INFO Epoch 4: [969/10940] ---- BYOL Validation Loss = 0.11877745389938354
31-01-2023 00:32:22 INFO Epoch 4: [980/10940] ---- BYOL Training Loss = 0.1359104961156845
31-01-2023 00:32:40 INFO Epoch 4: [991/10940] ---- BYOL Training Loss = 0.16077543795108795
31-01-2023 00:32:58 INFO Epoch 4: [1002/10940] ---- BYOL Training Loss = 0.18117912113666534
31-01-2023 00:33:16 INFO Epoch 4: [1013/10940] ---- BYOL Training Loss = 0.16151683032512665
31-01-2023 00:34:08 INFO Epoch 4: [1013/10940] ---- BYOL Validation Loss = 0.12920840084552765
31-01-2023 00:34:26 INFO Epoch 4: [1024/10940] ---- BYOL Training Loss = 0.14259305596351624
31-01-2023 00:34:44 INFO Epoch 4: [1035/10940] ---- BYOL Training Loss = 0.2649663984775543
31-01-2023 00:35:02 INFO Epoch 4: [1046/10940] ---- BYOL Training Loss = 0.2582206726074219
31-01-2023 00:35:20 INFO Epoch 4: [1057/10940] ---- BYOL Training Loss = 0.16023612022399902
31-01-2023 00:36:12 INFO Epoch 4: [1057/10940] ---- BYOL Validation Loss = 0.12879955768585205
31-01-2023 00:36:29 INFO Epoch 4: [1068/10940] ---- BYOL Training Loss = 0.1759694218635559
31-01-2023 00:36:47 INFO Epoch 4: [1079/10940] ---- BYOL Training Loss = 0.19419290125370026
31-01-2023 00:37:05 INFO Epoch 4: [1090/10940] ---- BYOL Training Loss = 0.19722644984722137
31-01-2023 00:37:23 INFO Epoch 4: [1101/10940] ---- BYOL Training Loss = 0.21077874302864075
31-01-2023 00:38:15 INFO Epoch 4: [1101/10940] ---- BYOL Validation Loss = 0.15740887820720673
31-01-2023 00:38:33 INFO Epoch 4: [1112/10940] ---- BYOL Training Loss = 0.2065782994031906
31-01-2023 00:38:50 INFO Epoch 4: [1123/10940] ---- BYOL Training Loss = 0.1976020783185959
31-01-2023 00:39:08 INFO Epoch 4: [1134/10940] ---- BYOL Training Loss = 0.18551985919475555
31-01-2023 00:39:26 INFO Epoch 4: [1145/10940] ---- BYOL Training Loss = 0.22268648445606232
31-01-2023 00:40:18 INFO Epoch 4: [1145/10940] ---- BYOL Validation Loss = 0.1544090211391449
31-01-2023 00:40:36 INFO Epoch 4: [1156/10940] ---- BYOL Training Loss = 0.23767559230327606
31-01-2023 00:40:54 INFO Epoch 4: [1167/10940] ---- BYOL Training Loss = 0.15078361332416534
31-01-2023 00:41:12 INFO Epoch 4: [1178/10940] ---- BYOL Training Loss = 0.1990785449743271
31-01-2023 00:41:30 INFO Epoch 4: [1189/10940] ---- BYOL Training Loss = 0.22100456058979034
31-01-2023 00:42:22 INFO Epoch 4: [1189/10940] ---- BYOL Validation Loss = 0.1162947341799736
31-01-2023 00:42:40 INFO Epoch 4: [1200/10940] ---- BYOL Training Loss = 0.20944175124168396
31-01-2023 00:42:58 INFO Epoch 4: [1211/10940] ---- BYOL Training Loss = 0.1959720402956009
31-01-2023 00:43:16 INFO Epoch 4: [1222/10940] ---- BYOL Training Loss = 0.17488519847393036
31-01-2023 00:43:34 INFO Epoch 4: [1233/10940] ---- BYOL Training Loss = 0.15940943360328674
31-01-2023 00:44:26 INFO Epoch 4: [1233/10940] ---- BYOL Validation Loss = 0.1253683716058731
31-01-2023 00:44:43 INFO Epoch 4: [1244/10940] ---- BYOL Training Loss = 0.15184727311134338
31-01-2023 00:45:01 INFO Epoch 4: [1255/10940] ---- BYOL Training Loss = 0.17344696819782257
31-01-2023 00:45:19 INFO Epoch 4: [1266/10940] ---- BYOL Training Loss = 0.17907850444316864
31-01-2023 00:45:37 INFO Epoch 4: [1277/10940] ---- BYOL Training Loss = 0.18134088814258575
31-01-2023 00:46:29 INFO Epoch 4: [1277/10940] ---- BYOL Validation Loss = 0.14278849959373474
31-01-2023 00:46:47 INFO Epoch 4: [1288/10940] ---- BYOL Training Loss = 0.2476198375225067
31-01-2023 00:47:05 INFO Epoch 4: [1299/10940] ---- BYOL Training Loss = 0.23637378215789795
31-01-2023 00:47:23 INFO Epoch 4: [1310/10940] ---- BYOL Training Loss = 0.19699861109256744
31-01-2023 00:47:41 INFO Epoch 4: [1321/10940] ---- BYOL Training Loss = 0.17530524730682373
31-01-2023 00:48:33 INFO Epoch 4: [1321/10940] ---- BYOL Validation Loss = 0.14729739725589752
31-01-2023 00:48:51 INFO Epoch 4: [1332/10940] ---- BYOL Training Loss = 0.1859537661075592
31-01-2023 00:49:09 INFO Epoch 4: [1343/10940] ---- BYOL Training Loss = 0.19583645462989807
31-01-2023 00:49:27 INFO Epoch 4: [1354/10940] ---- BYOL Training Loss = 0.18958118557929993
31-01-2023 00:49:45 INFO Epoch 4: [1365/10940] ---- BYOL Training Loss = 0.2404082715511322
31-01-2023 00:50:37 INFO Epoch 4: [1365/10940] ---- BYOL Validation Loss = 0.17608191072940826
31-01-2023 00:50:54 INFO Epoch 4: [1376/10940] ---- BYOL Training Loss = 0.21087542176246643
31-01-2023 00:51:12 INFO Epoch 4: [1387/10940] ---- BYOL Training Loss = 0.16477642953395844
31-01-2023 00:51:30 INFO Epoch 4: [1398/10940] ---- BYOL Training Loss = 0.16302171349525452
31-01-2023 00:51:48 INFO Epoch 4: [1409/10940] ---- BYOL Training Loss = 0.2038268744945526
31-01-2023 00:52:40 INFO Epoch 4: [1409/10940] ---- BYOL Validation Loss = 0.16247190535068512
31-01-2023 00:52:58 INFO Epoch 4: [1420/10940] ---- BYOL Training Loss = 0.15806595981121063
31-01-2023 00:53:16 INFO Epoch 4: [1431/10940] ---- BYOL Training Loss = 0.13291339576244354
31-01-2023 00:53:34 INFO Epoch 4: [1442/10940] ---- BYOL Training Loss = 0.15372434258460999
31-01-2023 00:53:52 INFO Epoch 4: [1453/10940] ---- BYOL Training Loss = 0.18662646412849426
31-01-2023 00:54:44 INFO Epoch 4: [1453/10940] ---- BYOL Validation Loss = 0.16297633945941925
31-01-2023 00:55:02 INFO Epoch 4: [1464/10940] ---- BYOL Training Loss = 0.17128941416740417
31-01-2023 00:55:20 INFO Epoch 4: [1475/10940] ---- BYOL Training Loss = 0.18485786020755768
31-01-2023 00:55:38 INFO Epoch 4: [1486/10940] ---- BYOL Training Loss = 0.17260801792144775
31-01-2023 00:55:56 INFO Epoch 4: [1497/10940] ---- BYOL Training Loss = 0.16573461890220642
31-01-2023 00:56:48 INFO Epoch 4: [1497/10940] ---- BYOL Validation Loss = 0.13422372937202454
31-01-2023 00:57:05 INFO Epoch 4: [1508/10940] ---- BYOL Training Loss = 0.19367463886737823
31-01-2023 00:57:23 INFO Epoch 4: [1519/10940] ---- BYOL Training Loss = 0.19234299659729004
31-01-2023 00:57:42 INFO Epoch 4: [1530/10940] ---- BYOL Training Loss = 0.2171906679868698
31-01-2023 00:58:00 INFO Epoch 4: [1541/10940] ---- BYOL Training Loss = 0.19310738146305084
31-01-2023 00:58:52 INFO Epoch 4: [1541/10940] ---- BYOL Validation Loss = 0.11963776499032974
31-01-2023 00:59:09 INFO Epoch 4: [1552/10940] ---- BYOL Training Loss = 0.22736696898937225
31-01-2023 00:59:27 INFO Epoch 4: [1563/10940] ---- BYOL Training Loss = 0.24964311718940735
31-01-2023 00:59:45 INFO Epoch 4: [1574/10940] ---- BYOL Training Loss = 0.1866956204175949
31-01-2023 01:00:03 INFO Epoch 4: [1585/10940] ---- BYOL Training Loss = 0.1760583370923996
31-01-2023 01:00:55 INFO Epoch 4: [1585/10940] ---- BYOL Validation Loss = 0.12103872001171112
31-01-2023 01:01:13 INFO Epoch 4: [1596/10940] ---- BYOL Training Loss = 0.1691095232963562
31-01-2023 01:01:31 INFO Epoch 4: [1607/10940] ---- BYOL Training Loss = 0.1856042444705963
31-01-2023 01:01:49 INFO Epoch 4: [1618/10940] ---- BYOL Training Loss = 0.1503072828054428
31-01-2023 01:02:07 INFO Epoch 4: [1629/10940] ---- BYOL Training Loss = 0.1722174733877182
31-01-2023 01:02:59 INFO Epoch 4: [1629/10940] ---- BYOL Validation Loss = 0.14292657375335693
31-01-2023 01:03:17 INFO Epoch 4: [1640/10940] ---- BYOL Training Loss = 0.21638242900371552
31-01-2023 01:03:35 INFO Epoch 4: [1651/10940] ---- BYOL Training Loss = 0.21249940991401672
31-01-2023 01:03:53 INFO Epoch 4: [1662/10940] ---- BYOL Training Loss = 0.17088823020458221
31-01-2023 01:04:11 INFO Epoch 4: [1673/10940] ---- BYOL Training Loss = 0.16349703073501587
31-01-2023 01:05:03 INFO Epoch 4: [1673/10940] ---- BYOL Validation Loss = 0.1425304114818573
31-01-2023 01:05:21 INFO Epoch 4: [1684/10940] ---- BYOL Training Loss = 0.19859029352664948
31-01-2023 01:05:39 INFO Epoch 4: [1695/10940] ---- BYOL Training Loss = 0.2561333179473877
31-01-2023 01:05:57 INFO Epoch 4: [1706/10940] ---- BYOL Training Loss = 0.2146153748035431
31-01-2023 01:06:15 INFO Epoch 4: [1717/10940] ---- BYOL Training Loss = 0.24462716281414032
31-01-2023 01:07:07 INFO Epoch 4: [1717/10940] ---- BYOL Validation Loss = 0.15438172221183777
31-01-2023 01:07:25 INFO Epoch 4: [1728/10940] ---- BYOL Training Loss = 0.2531016170978546
31-01-2023 01:07:43 INFO Epoch 4: [1739/10940] ---- BYOL Training Loss = 0.16999736428260803
31-01-2023 01:08:01 INFO Epoch 4: [1750/10940] ---- BYOL Training Loss = 0.20075568556785583
31-01-2023 01:08:19 INFO Epoch 4: [1761/10940] ---- BYOL Training Loss = 0.1672402024269104
31-01-2023 01:09:11 INFO Epoch 4: [1761/10940] ---- BYOL Validation Loss = 0.14660120010375977
31-01-2023 01:09:28 INFO Epoch 4: [1772/10940] ---- BYOL Training Loss = 0.17074087262153625
31-01-2023 01:09:47 INFO Epoch 4: [1783/10940] ---- BYOL Training Loss = 0.20577681064605713
31-01-2023 01:10:05 INFO Epoch 4: [1794/10940] ---- BYOL Training Loss = 0.1793004423379898
31-01-2023 01:10:23 INFO Epoch 4: [1805/10940] ---- BYOL Training Loss = 0.1804456263780594
31-01-2023 01:11:15 INFO Epoch 4: [1805/10940] ---- BYOL Validation Loss = 0.1546560823917389
31-01-2023 01:11:32 INFO Epoch 4: [1816/10940] ---- BYOL Training Loss = 0.19294384121894836
31-01-2023 01:11:50 INFO Epoch 4: [1827/10940] ---- BYOL Training Loss = 0.1604243665933609
31-01-2023 01:12:08 INFO Epoch 4: [1838/10940] ---- BYOL Training Loss = 0.16012637317180634
31-01-2023 01:12:26 INFO Epoch 4: [1849/10940] ---- BYOL Training Loss = 0.15721586346626282
31-01-2023 01:13:18 INFO Epoch 4: [1849/10940] ---- BYOL Validation Loss = 0.06637643277645111
31-01-2023 01:13:36 INFO Epoch 4: [1860/10940] ---- BYOL Training Loss = 0.16424351930618286
31-01-2023 01:13:54 INFO Epoch 4: [1871/10940] ---- BYOL Training Loss = 0.18632686138153076
31-01-2023 01:14:12 INFO Epoch 4: [1882/10940] ---- BYOL Training Loss = 0.22432160377502441
31-01-2023 01:14:30 INFO Epoch 4: [1893/10940] ---- BYOL Training Loss = 0.2267797440290451
31-01-2023 01:15:22 INFO Epoch 4: [1893/10940] ---- BYOL Validation Loss = 0.09666301310062408
31-01-2023 01:15:40 INFO Epoch 4: [1904/10940] ---- BYOL Training Loss = 0.1779332011938095
31-01-2023 01:15:58 INFO Epoch 4: [1915/10940] ---- BYOL Training Loss = 0.18321819603443146
31-01-2023 01:16:16 INFO Epoch 4: [1926/10940] ---- BYOL Training Loss = 0.15676617622375488
31-01-2023 01:16:34 INFO Epoch 4: [1937/10940] ---- BYOL Training Loss = 0.1327522248029709
31-01-2023 01:17:26 INFO Epoch 4: [1937/10940] ---- BYOL Validation Loss = 0.10522036999464035
31-01-2023 01:17:44 INFO Epoch 4: [1948/10940] ---- BYOL Training Loss = 0.1684422492980957
31-01-2023 01:18:02 INFO Epoch 4: [1959/10940] ---- BYOL Training Loss = 0.18518847227096558
31-01-2023 01:18:20 INFO Epoch 4: [1970/10940] ---- BYOL Training Loss = 0.1741427779197693
31-01-2023 01:18:38 INFO Epoch 4: [1981/10940] ---- BYOL Training Loss = 0.2005341500043869
31-01-2023 01:19:30 INFO Epoch 4: [1981/10940] ---- BYOL Validation Loss = 0.16854000091552734
31-01-2023 01:19:48 INFO Epoch 4: [1992/10940] ---- BYOL Training Loss = 0.20210833847522736
31-01-2023 01:20:06 INFO Epoch 4: [2003/10940] ---- BYOL Training Loss = 0.17415596544742584
31-01-2023 01:20:24 INFO Epoch 4: [2014/10940] ---- BYOL Training Loss = 0.16035863757133484
31-01-2023 01:20:42 INFO Epoch 4: [2025/10940] ---- BYOL Training Loss = 0.11817629635334015
31-01-2023 01:21:34 INFO Epoch 4: [2025/10940] ---- BYOL Validation Loss = 0.07969053834676743
31-01-2023 01:21:52 INFO Epoch 4: [2036/10940] ---- BYOL Training Loss = 0.11136949062347412
31-01-2023 01:22:10 INFO Epoch 4: [2047/10940] ---- BYOL Training Loss = 0.19729763269424438
31-01-2023 01:22:28 INFO Epoch 4: [2058/10940] ---- BYOL Training Loss = 0.139328271150589
31-01-2023 01:22:46 INFO Epoch 4: [2069/10940] ---- BYOL Training Loss = 0.1618063747882843
31-01-2023 01:23:38 INFO Epoch 4: [2069/10940] ---- BYOL Validation Loss = 0.14432194828987122
31-01-2023 01:23:56 INFO Epoch 4: [2080/10940] ---- BYOL Training Loss = 0.16275079548358917
31-01-2023 01:24:14 INFO Epoch 4: [2091/10940] ---- BYOL Training Loss = 0.1601554900407791
31-01-2023 01:24:32 INFO Epoch 4: [2102/10940] ---- BYOL Training Loss = 0.16312001645565033
31-01-2023 01:24:50 INFO Epoch 4: [2113/10940] ---- BYOL Training Loss = 0.15811873972415924
31-01-2023 01:25:42 INFO Epoch 4: [2113/10940] ---- BYOL Validation Loss = 0.10405300557613373
31-01-2023 01:25:59 INFO Epoch 4: [2124/10940] ---- BYOL Training Loss = 0.17240247130393982
31-01-2023 01:26:18 INFO Epoch 4: [2135/10940] ---- BYOL Training Loss = 0.16792099177837372
31-01-2023 01:26:36 INFO Epoch 4: [2146/10940] ---- BYOL Training Loss = 0.17465075850486755
31-01-2023 01:26:54 INFO Epoch 4: [2157/10940] ---- BYOL Training Loss = 0.16896262764930725
31-01-2023 01:27:46 INFO Epoch 4: [2157/10940] ---- BYOL Validation Loss = 0.1554206758737564
31-01-2023 01:28:03 INFO Epoch 4: [2168/10940] ---- BYOL Training Loss = 0.19818301498889923
31-01-2023 01:28:21 INFO Epoch 4: [2179/10940] ---- BYOL Training Loss = 0.2903265357017517
31-01-2023 01:28:40 INFO Epoch 4: [2190/10940] ---- BYOL Training Loss = 0.30568355321884155
31-01-2023 01:28:58 INFO Epoch 4: [2201/10940] ---- BYOL Training Loss = 0.19850371778011322
31-01-2023 01:29:50 INFO Epoch 4: [2201/10940] ---- BYOL Validation Loss = 0.1265832632780075
31-01-2023 01:30:07 INFO Epoch 4: [2212/10940] ---- BYOL Training Loss = 0.1938411295413971
31-01-2023 01:30:26 INFO Epoch 4: [2223/10940] ---- BYOL Training Loss = 0.17800311744213104
31-01-2023 01:30:44 INFO Epoch 4: [2234/10940] ---- BYOL Training Loss = 0.17549195885658264
31-01-2023 01:31:02 INFO Epoch 4: [2245/10940] ---- BYOL Training Loss = 0.2652431130409241
31-01-2023 01:31:54 INFO Epoch 4: [2245/10940] ---- BYOL Validation Loss = 0.15922130644321442
31-01-2023 01:32:11 INFO Epoch 4: [2256/10940] ---- BYOL Training Loss = 0.23768460750579834
31-01-2023 01:32:29 INFO Epoch 4: [2267/10940] ---- BYOL Training Loss = 0.21488146483898163
31-01-2023 01:32:48 INFO Epoch 4: [2278/10940] ---- BYOL Training Loss = 0.22277989983558655
31-01-2023 01:33:06 INFO Epoch 4: [2289/10940] ---- BYOL Training Loss = 0.19271104037761688
31-01-2023 01:33:58 INFO Epoch 4: [2289/10940] ---- BYOL Validation Loss = 0.153384730219841
31-01-2023 01:34:15 INFO Epoch 4: [2300/10940] ---- BYOL Training Loss = 0.22885791957378387
31-01-2023 01:34:33 INFO Epoch 4: [2311/10940] ---- BYOL Training Loss = 0.18949224054813385
31-01-2023 01:34:52 INFO Epoch 4: [2322/10940] ---- BYOL Training Loss = 0.20288188755512238
31-01-2023 01:35:10 INFO Epoch 4: [2333/10940] ---- BYOL Training Loss = 0.24875406920909882
31-01-2023 01:36:02 INFO Epoch 4: [2333/10940] ---- BYOL Validation Loss = 0.2137386053800583
31-01-2023 01:36:19 INFO Epoch 4: [2344/10940] ---- BYOL Training Loss = 0.19985458254814148
31-01-2023 01:36:37 INFO Epoch 4: [2355/10940] ---- BYOL Training Loss = 0.200773686170578
31-01-2023 01:36:55 INFO Epoch 4: [2366/10940] ---- BYOL Training Loss = 0.2253158986568451
31-01-2023 01:37:13 INFO Epoch 4: [2377/10940] ---- BYOL Training Loss = 0.23579469323158264
31-01-2023 01:38:05 INFO Epoch 4: [2377/10940] ---- BYOL Validation Loss = 0.2179945558309555
31-01-2023 01:38:23 INFO Epoch 4: [2388/10940] ---- BYOL Training Loss = 0.23724694550037384
31-01-2023 01:38:41 INFO Epoch 4: [2399/10940] ---- BYOL Training Loss = 0.22238540649414062
31-01-2023 01:38:59 INFO Epoch 4: [2410/10940] ---- BYOL Training Loss = 0.18166100978851318
31-01-2023 01:39:17 INFO Epoch 4: [2421/10940] ---- BYOL Training Loss = 0.21004974842071533
31-01-2023 01:40:09 INFO Epoch 4: [2421/10940] ---- BYOL Validation Loss = 0.17763853073120117
31-01-2023 01:40:27 INFO Epoch 4: [2432/10940] ---- BYOL Training Loss = 0.2126990258693695
31-01-2023 01:40:46 INFO Epoch 4: [2443/10940] ---- BYOL Training Loss = 0.20003807544708252
31-01-2023 01:41:04 INFO Epoch 4: [2454/10940] ---- BYOL Training Loss = 0.2060655653476715
31-01-2023 01:41:22 INFO Epoch 4: [2465/10940] ---- BYOL Training Loss = 0.2582017779350281
31-01-2023 01:42:14 INFO Epoch 4: [2465/10940] ---- BYOL Validation Loss = 0.21580947935581207
31-01-2023 01:42:31 INFO Epoch 4: [2476/10940] ---- BYOL Training Loss = 0.23181727528572083
31-01-2023 01:42:49 INFO Epoch 4: [2487/10940] ---- BYOL Training Loss = 0.2122655212879181
31-01-2023 01:43:08 INFO Epoch 4: [2498/10940] ---- BYOL Training Loss = 0.20751488208770752
31-01-2023 01:43:26 INFO Epoch 4: [2509/10940] ---- BYOL Training Loss = 0.2039477527141571
31-01-2023 01:44:18 INFO Epoch 4: [2509/10940] ---- BYOL Validation Loss = 0.18081192672252655
31-01-2023 01:44:35 INFO Epoch 4: [2520/10940] ---- BYOL Training Loss = 0.2535357177257538
31-01-2023 01:44:53 INFO Epoch 4: [2531/10940] ---- BYOL Training Loss = 0.2886407971382141
31-01-2023 01:45:11 INFO Epoch 4: [2542/10940] ---- BYOL Training Loss = 0.25211092829704285
31-01-2023 01:45:29 INFO Epoch 4: [2553/10940] ---- BYOL Training Loss = 0.28158342838287354
31-01-2023 01:46:21 INFO Epoch 4: [2553/10940] ---- BYOL Validation Loss = 0.19086365401744843
31-01-2023 01:46:39 INFO Epoch 4: [2564/10940] ---- BYOL Training Loss = 0.2783190608024597
31-01-2023 01:46:57 INFO Epoch 4: [2575/10940] ---- BYOL Training Loss = 0.2853701710700989
31-01-2023 01:47:16 INFO Epoch 4: [2586/10940] ---- BYOL Training Loss = 0.2435894012451172
31-01-2023 01:47:34 INFO Epoch 4: [2597/10940] ---- BYOL Training Loss = 0.2545616626739502
31-01-2023 01:48:26 INFO Epoch 4: [2597/10940] ---- BYOL Validation Loss = 0.26221415400505066
31-01-2023 01:48:43 INFO Epoch 4: [2608/10940] ---- BYOL Training Loss = 0.3064575791358948
31-01-2023 01:49:01 INFO Epoch 4: [2619/10940] ---- BYOL Training Loss = 0.32461148500442505
31-01-2023 01:49:20 INFO Epoch 4: [2630/10940] ---- BYOL Training Loss = 0.2998373210430145
31-01-2023 01:49:38 INFO Epoch 4: [2641/10940] ---- BYOL Training Loss = 0.2812068462371826
31-01-2023 01:50:30 INFO Epoch 4: [2641/10940] ---- BYOL Validation Loss = 0.2694506049156189
31-01-2023 01:50:48 INFO Epoch 4: [2652/10940] ---- BYOL Training Loss = 0.2757473587989807
31-01-2023 01:51:06 INFO Epoch 4: [2663/10940] ---- BYOL Training Loss = 0.23386242985725403
31-01-2023 01:51:24 INFO Epoch 4: [2674/10940] ---- BYOL Training Loss = 0.2682662308216095
31-01-2023 01:51:42 INFO Epoch 4: [2685/10940] ---- BYOL Training Loss = 0.33355361223220825
31-01-2023 01:52:34 INFO Epoch 4: [2685/10940] ---- BYOL Validation Loss = 0.2551807761192322
31-01-2023 01:52:52 INFO Epoch 4: [2696/10940] ---- BYOL Training Loss = 0.31842243671417236
31-01-2023 01:53:10 INFO Epoch 4: [2707/10940] ---- BYOL Training Loss = 0.2716011106967926
31-01-2023 01:53:28 INFO Epoch 4: [2718/10940] ---- BYOL Training Loss = 0.26279547810554504
31-01-2023 01:53:46 INFO Epoch 4: [2729/10940] ---- BYOL Training Loss = 0.2148624211549759
31-01-2023 01:54:39 INFO Epoch 4: [2729/10940] ---- BYOL Validation Loss = 0.2766953408718109
31-01-2023 01:54:56 INFO Epoch 4: [2740/10940] ---- BYOL Training Loss = 0.26425665616989136
31-01-2023 01:55:14 INFO Epoch 4: [2751/10940] ---- BYOL Training Loss = 0.26393482089042664
31-01-2023 01:55:32 INFO Epoch 4: [2762/10940] ---- BYOL Training Loss = 0.26016107201576233
31-01-2023 01:55:51 INFO Epoch 4: [2773/10940] ---- BYOL Training Loss = 0.2646278738975525
31-01-2023 01:56:43 INFO Epoch 4: [2773/10940] ---- BYOL Validation Loss = 0.23231251537799835
31-01-2023 01:57:01 INFO Epoch 4: [2784/10940] ---- BYOL Training Loss = 0.28957825899124146
31-01-2023 01:57:19 INFO Epoch 4: [2795/10940] ---- BYOL Training Loss = 0.3197786211967468
31-01-2023 01:57:37 INFO Epoch 4: [2806/10940] ---- BYOL Training Loss = 0.27560481429100037
31-01-2023 01:57:55 INFO Epoch 4: [2817/10940] ---- BYOL Training Loss = 0.2557981312274933
31-01-2023 01:58:47 INFO Epoch 4: [2817/10940] ---- BYOL Validation Loss = 0.23423084616661072
31-01-2023 01:59:05 INFO Epoch 4: [2828/10940] ---- BYOL Training Loss = 0.2626621127128601
31-01-2023 01:59:23 INFO Epoch 4: [2839/10940] ---- BYOL Training Loss = 0.23504352569580078
31-01-2023 01:59:41 INFO Epoch 4: [2850/10940] ---- BYOL Training Loss = 0.25080934166908264
31-01-2023 01:59:59 INFO Epoch 4: [2861/10940] ---- BYOL Training Loss = 0.26087066531181335
31-01-2023 02:00:51 INFO Epoch 4: [2861/10940] ---- BYOL Validation Loss = 0.24320821464061737
31-01-2023 02:01:09 INFO Epoch 4: [2872/10940] ---- BYOL Training Loss = 0.2359859198331833
31-01-2023 02:01:27 INFO Epoch 4: [2883/10940] ---- BYOL Training Loss = 0.25575822591781616
31-01-2023 02:01:45 INFO Epoch 4: [2894/10940] ---- BYOL Training Loss = 0.22896626591682434
31-01-2023 02:02:04 INFO Epoch 4: [2905/10940] ---- BYOL Training Loss = 0.19786320626735687
31-01-2023 02:02:55 INFO Epoch 4: [2905/10940] ---- BYOL Validation Loss = 0.15314456820487976
31-01-2023 02:03:13 INFO Epoch 4: [2916/10940] ---- BYOL Training Loss = 0.22057123482227325
31-01-2023 02:03:31 INFO Epoch 4: [2927/10940] ---- BYOL Training Loss = 0.25680088996887207
31-01-2023 02:03:49 INFO Epoch 4: [2938/10940] ---- BYOL Training Loss = 0.27642709016799927
31-01-2023 02:04:07 INFO Epoch 4: [2949/10940] ---- BYOL Training Loss = 0.30207258462905884
31-01-2023 02:04:59 INFO Epoch 4: [2949/10940] ---- BYOL Validation Loss = 0.25539538264274597
31-01-2023 02:05:17 INFO Epoch 4: [2960/10940] ---- BYOL Training Loss = 0.269000768661499
31-01-2023 02:05:35 INFO Epoch 4: [2971/10940] ---- BYOL Training Loss = 0.2678470313549042
31-01-2023 02:05:54 INFO Epoch 4: [2982/10940] ---- BYOL Training Loss = 0.19938239455223083
31-01-2023 02:06:12 INFO Epoch 4: [2993/10940] ---- BYOL Training Loss = 0.2643586993217468
31-01-2023 02:07:04 INFO Epoch 4: [2993/10940] ---- BYOL Validation Loss = 0.23046478629112244
31-01-2023 02:07:21 INFO Epoch 4: [3004/10940] ---- BYOL Training Loss = 0.26399558782577515
31-01-2023 02:07:39 INFO Epoch 4: [3015/10940] ---- BYOL Training Loss = 0.2873494029045105
31-01-2023 02:07:57 INFO Epoch 4: [3026/10940] ---- BYOL Training Loss = 0.27532559633255005
31-01-2023 02:08:16 INFO Epoch 4: [3037/10940] ---- BYOL Training Loss = 0.2323470413684845
31-01-2023 02:09:07 INFO Epoch 4: [3037/10940] ---- BYOL Validation Loss = 0.16347262263298035
31-01-2023 02:09:25 INFO Epoch 4: [3048/10940] ---- BYOL Training Loss = 0.20253732800483704
31-01-2023 02:09:43 INFO Epoch 4: [3059/10940] ---- BYOL Training Loss = 0.22312811017036438
31-01-2023 02:10:02 INFO Epoch 4: [3070/10940] ---- BYOL Training Loss = 0.18899071216583252
31-01-2023 02:10:20 INFO Epoch 4: [3081/10940] ---- BYOL Training Loss = 0.2255171835422516
31-01-2023 02:11:12 INFO Epoch 4: [3081/10940] ---- BYOL Validation Loss = 0.20395945012569427
31-01-2023 02:11:30 INFO Epoch 4: [3092/10940] ---- BYOL Training Loss = 0.2368684709072113
31-01-2023 02:11:48 INFO Epoch 4: [3103/10940] ---- BYOL Training Loss = 0.22084017097949982
31-01-2023 02:12:06 INFO Epoch 4: [3114/10940] ---- BYOL Training Loss = 0.1921139806509018
31-01-2023 02:12:24 INFO Epoch 4: [3125/10940] ---- BYOL Training Loss = 0.16651955246925354
31-01-2023 02:13:16 INFO Epoch 4: [3125/10940] ---- BYOL Validation Loss = 0.1542046070098877
31-01-2023 02:13:34 INFO Epoch 4: [3136/10940] ---- BYOL Training Loss = 0.19212372601032257
31-01-2023 02:13:52 INFO Epoch 4: [3147/10940] ---- BYOL Training Loss = 0.244657963514328
31-01-2023 02:14:10 INFO Epoch 4: [3158/10940] ---- BYOL Training Loss = 0.2507748007774353
31-01-2023 02:14:28 INFO Epoch 4: [3169/10940] ---- BYOL Training Loss = 0.28176042437553406
31-01-2023 02:15:20 INFO Epoch 4: [3169/10940] ---- BYOL Validation Loss = 0.20496733486652374
31-01-2023 02:15:38 INFO Epoch 4: [3180/10940] ---- BYOL Training Loss = 0.2820413410663605
31-01-2023 02:15:56 INFO Epoch 4: [3191/10940] ---- BYOL Training Loss = 0.24632644653320312
31-01-2023 02:16:14 INFO Epoch 4: [3202/10940] ---- BYOL Training Loss = 0.21530930697917938
31-01-2023 02:16:32 INFO Epoch 4: [3213/10940] ---- BYOL Training Loss = 0.18917079269886017
31-01-2023 02:17:24 INFO Epoch 4: [3213/10940] ---- BYOL Validation Loss = 0.15028735995292664
31-01-2023 02:17:42 INFO Epoch 4: [3224/10940] ---- BYOL Training Loss = 0.23222112655639648
31-01-2023 02:18:00 INFO Epoch 4: [3235/10940] ---- BYOL Training Loss = 0.22455653548240662
31-01-2023 02:18:18 INFO Epoch 4: [3246/10940] ---- BYOL Training Loss = 0.2960317134857178
31-01-2023 02:18:37 INFO Epoch 4: [3257/10940] ---- BYOL Training Loss = 0.31287673115730286
31-01-2023 02:19:28 INFO Epoch 4: [3257/10940] ---- BYOL Validation Loss = 0.1783479005098343
31-01-2023 02:19:46 INFO Epoch 4: [3268/10940] ---- BYOL Training Loss = 0.25478464365005493
31-01-2023 02:20:04 INFO Epoch 4: [3279/10940] ---- BYOL Training Loss = 0.25503915548324585
31-01-2023 02:20:22 INFO Epoch 4: [3290/10940] ---- BYOL Training Loss = 0.21107585728168488
31-01-2023 02:20:41 INFO Epoch 4: [3301/10940] ---- BYOL Training Loss = 0.20875096321105957
31-01-2023 02:21:33 INFO Epoch 4: [3301/10940] ---- BYOL Validation Loss = 0.20452724397182465
31-01-2023 02:21:51 INFO Epoch 4: [3312/10940] ---- BYOL Training Loss = 0.25752052664756775
31-01-2023 02:22:09 INFO Epoch 4: [3323/10940] ---- BYOL Training Loss = 0.252472460269928
31-01-2023 02:22:27 INFO Epoch 4: [3334/10940] ---- BYOL Training Loss = 0.23997285962104797
31-01-2023 02:22:45 INFO Epoch 4: [3345/10940] ---- BYOL Training Loss = 0.2368820160627365
31-01-2023 02:23:37 INFO Epoch 4: [3345/10940] ---- BYOL Validation Loss = 0.18658657371997833
31-01-2023 02:23:55 INFO Epoch 4: [3356/10940] ---- BYOL Training Loss = 0.2486005276441574
31-01-2023 02:24:13 INFO Epoch 4: [3367/10940] ---- BYOL Training Loss = 0.2142912894487381
31-01-2023 02:24:31 INFO Epoch 4: [3378/10940] ---- BYOL Training Loss = 0.19011139869689941
31-01-2023 02:24:49 INFO Epoch 4: [3389/10940] ---- BYOL Training Loss = 0.22828522324562073
31-01-2023 02:25:41 INFO Epoch 4: [3389/10940] ---- BYOL Validation Loss = 0.19076432287693024
31-01-2023 02:25:59 INFO Epoch 4: [3400/10940] ---- BYOL Training Loss = 0.19302022457122803
31-01-2023 02:26:17 INFO Epoch 4: [3411/10940] ---- BYOL Training Loss = 0.21870338916778564
31-01-2023 02:26:35 INFO Epoch 4: [3422/10940] ---- BYOL Training Loss = 0.2297362983226776
31-01-2023 02:26:53 INFO Epoch 4: [3433/10940] ---- BYOL Training Loss = 0.2193879783153534
31-01-2023 02:27:45 INFO Epoch 4: [3433/10940] ---- BYOL Validation Loss = 0.1417674869298935
31-01-2023 02:28:03 INFO Epoch 4: [3444/10940] ---- BYOL Training Loss = 0.2557738423347473
31-01-2023 02:28:21 INFO Epoch 4: [3455/10940] ---- BYOL Training Loss = 0.20035643875598907
31-01-2023 02:28:39 INFO Epoch 4: [3466/10940] ---- BYOL Training Loss = 0.21655842661857605
31-01-2023 02:28:57 INFO Epoch 4: [3477/10940] ---- BYOL Training Loss = 0.23604218661785126
31-01-2023 02:29:49 INFO Epoch 4: [3477/10940] ---- BYOL Validation Loss = 0.1854221075773239
31-01-2023 02:30:07 INFO Epoch 4: [3488/10940] ---- BYOL Training Loss = 0.23332151770591736
31-01-2023 02:30:25 INFO Epoch 4: [3499/10940] ---- BYOL Training Loss = 0.20291979610919952
31-01-2023 02:30:43 INFO Epoch 4: [3510/10940] ---- BYOL Training Loss = 0.19572298228740692
31-01-2023 02:31:01 INFO Epoch 4: [3521/10940] ---- BYOL Training Loss = 0.21855783462524414
31-01-2023 02:31:53 INFO Epoch 4: [3521/10940] ---- BYOL Validation Loss = 0.1871972382068634
31-01-2023 02:32:12 INFO Epoch 4: [3532/10940] ---- BYOL Training Loss = 0.18983176350593567
31-01-2023 02:32:30 INFO Epoch 4: [3543/10940] ---- BYOL Training Loss = 0.20623011887073517
31-01-2023 02:32:48 INFO Epoch 4: [3554/10940] ---- BYOL Training Loss = 0.22801610827445984
31-01-2023 02:33:06 INFO Epoch 4: [3565/10940] ---- BYOL Training Loss = 0.19644740223884583
31-01-2023 02:33:58 INFO Epoch 4: [3565/10940] ---- BYOL Validation Loss = 0.1818579137325287
31-01-2023 02:34:16 INFO Epoch 4: [3576/10940] ---- BYOL Training Loss = 0.1813078671693802
31-01-2023 02:34:34 INFO Epoch 4: [3587/10940] ---- BYOL Training Loss = 0.2031574696302414
31-01-2023 02:34:52 INFO Epoch 4: [3598/10940] ---- BYOL Training Loss = 0.22201868891716003
31-01-2023 02:35:10 INFO Epoch 4: [3609/10940] ---- BYOL Training Loss = 0.18862226605415344
31-01-2023 02:36:02 INFO Epoch 4: [3609/10940] ---- BYOL Validation Loss = 0.16859497129917145
31-01-2023 02:36:20 INFO Epoch 4: [3620/10940] ---- BYOL Training Loss = 0.24254925549030304
31-01-2023 02:36:38 INFO Epoch 4: [3631/10940] ---- BYOL Training Loss = 0.21565008163452148
31-01-2023 02:36:57 INFO Epoch 4: [3642/10940] ---- BYOL Training Loss = 0.21460318565368652
31-01-2023 02:37:15 INFO Epoch 4: [3653/10940] ---- BYOL Training Loss = 0.1949656456708908
31-01-2023 02:38:07 INFO Epoch 4: [3653/10940] ---- BYOL Validation Loss = 0.12278445810079575
31-01-2023 02:38:24 INFO Epoch 4: [3664/10940] ---- BYOL Training Loss = 0.19641026854515076
31-01-2023 02:38:43 INFO Epoch 4: [3675/10940] ---- BYOL Training Loss = 0.22758576273918152
31-01-2023 02:39:01 INFO Epoch 4: [3686/10940] ---- BYOL Training Loss = 0.22988203167915344
31-01-2023 02:39:19 INFO Epoch 4: [3697/10940] ---- BYOL Training Loss = 0.22258500754833221
31-01-2023 02:40:11 INFO Epoch 4: [3697/10940] ---- BYOL Validation Loss = 0.18406417965888977
31-01-2023 02:40:29 INFO Epoch 4: [3708/10940] ---- BYOL Training Loss = 0.22885513305664062
31-01-2023 02:40:47 INFO Epoch 4: [3719/10940] ---- BYOL Training Loss = 0.2639199495315552
31-01-2023 02:41:05 INFO Epoch 4: [3730/10940] ---- BYOL Training Loss = 0.22363945841789246
31-01-2023 02:41:23 INFO Epoch 4: [3741/10940] ---- BYOL Training Loss = 0.18522319197654724
31-01-2023 02:42:15 INFO Epoch 4: [3741/10940] ---- BYOL Validation Loss = 0.12452549487352371
31-01-2023 02:42:33 INFO Epoch 4: [3752/10940] ---- BYOL Training Loss = 0.20917725563049316
31-01-2023 02:42:52 INFO Epoch 4: [3763/10940] ---- BYOL Training Loss = 0.21637475490570068
31-01-2023 02:43:10 INFO Epoch 4: [3774/10940] ---- BYOL Training Loss = 0.20910188555717468
31-01-2023 02:43:28 INFO Epoch 4: [3785/10940] ---- BYOL Training Loss = 0.2601083517074585
31-01-2023 02:44:20 INFO Epoch 4: [3785/10940] ---- BYOL Validation Loss = 0.19539465010166168
31-01-2023 02:44:37 INFO Epoch 4: [3796/10940] ---- BYOL Training Loss = 0.2309054434299469
31-01-2023 02:44:56 INFO Epoch 4: [3807/10940] ---- BYOL Training Loss = 0.1818881332874298
31-01-2023 02:45:14 INFO Epoch 4: [3818/10940] ---- BYOL Training Loss = 0.15828029811382294
31-01-2023 02:45:32 INFO Epoch 4: [3829/10940] ---- BYOL Training Loss = 0.2019067108631134
31-01-2023 02:46:24 INFO Epoch 4: [3829/10940] ---- BYOL Validation Loss = 0.18485653400421143
31-01-2023 02:46:42 INFO Epoch 4: [3840/10940] ---- BYOL Training Loss = 0.21169082820415497
31-01-2023 02:47:00 INFO Epoch 4: [3851/10940] ---- BYOL Training Loss = 0.21589216589927673
31-01-2023 02:47:18 INFO Epoch 4: [3862/10940] ---- BYOL Training Loss = 0.2105538547039032
31-01-2023 02:47:36 INFO Epoch 4: [3873/10940] ---- BYOL Training Loss = 0.20693616569042206
31-01-2023 02:48:28 INFO Epoch 4: [3873/10940] ---- BYOL Validation Loss = 0.13037869334220886
31-01-2023 02:48:46 INFO Epoch 4: [3884/10940] ---- BYOL Training Loss = 0.1870058923959732
31-01-2023 02:49:04 INFO Epoch 4: [3895/10940] ---- BYOL Training Loss = 0.19655585289001465
31-01-2023 02:49:23 INFO Epoch 4: [3906/10940] ---- BYOL Training Loss = 0.2102368175983429
31-01-2023 02:49:41 INFO Epoch 4: [3917/10940] ---- BYOL Training Loss = 0.1860729157924652
31-01-2023 02:50:33 INFO Epoch 4: [3917/10940] ---- BYOL Validation Loss = 0.1814608871936798
31-01-2023 02:50:50 INFO Epoch 4: [3928/10940] ---- BYOL Training Loss = 0.18040752410888672
31-01-2023 02:51:09 INFO Epoch 4: [3939/10940] ---- BYOL Training Loss = 0.14773871004581451
31-01-2023 02:51:27 INFO Epoch 4: [3950/10940] ---- BYOL Training Loss = 0.13560327887535095
31-01-2023 02:51:45 INFO Epoch 4: [3961/10940] ---- BYOL Training Loss = 0.16003961861133575
31-01-2023 02:52:37 INFO Epoch 4: [3961/10940] ---- BYOL Validation Loss = 0.12053076177835464
31-01-2023 02:52:55 INFO Epoch 4: [3972/10940] ---- BYOL Training Loss = 0.23987320065498352
31-01-2023 02:53:13 INFO Epoch 4: [3983/10940] ---- BYOL Training Loss = 0.1731623262166977
31-01-2023 02:53:31 INFO Epoch 4: [3994/10940] ---- BYOL Training Loss = 0.1682092249393463
31-01-2023 02:53:50 INFO Epoch 4: [4005/10940] ---- BYOL Training Loss = 0.2549234628677368
31-01-2023 02:54:42 INFO Epoch 4: [4005/10940] ---- BYOL Validation Loss = 0.1821768581867218
31-01-2023 02:55:00 INFO Epoch 4: [4016/10940] ---- BYOL Training Loss = 0.2480253279209137
31-01-2023 02:55:18 INFO Epoch 4: [4027/10940] ---- BYOL Training Loss = 0.22512774169445038
31-01-2023 02:55:36 INFO Epoch 4: [4038/10940] ---- BYOL Training Loss = 0.16441096365451813
31-01-2023 02:55:54 INFO Epoch 4: [4049/10940] ---- BYOL Training Loss = 0.1477908492088318
31-01-2023 02:56:46 INFO Epoch 4: [4049/10940] ---- BYOL Validation Loss = 0.1537724882364273
31-01-2023 02:57:04 INFO Epoch 4: [4060/10940] ---- BYOL Training Loss = 0.1683899313211441
31-01-2023 02:57:22 INFO Epoch 4: [4071/10940] ---- BYOL Training Loss = 0.1849549114704132
31-01-2023 02:57:41 INFO Epoch 4: [4082/10940] ---- BYOL Training Loss = 0.1868397295475006
31-01-2023 02:57:59 INFO Epoch 4: [4093/10940] ---- BYOL Training Loss = 0.20842447876930237
31-01-2023 02:58:51 INFO Epoch 4: [4093/10940] ---- BYOL Validation Loss = 0.14886124432086945
31-01-2023 02:59:09 INFO Epoch 4: [4104/10940] ---- BYOL Training Loss = 0.21106354892253876
31-01-2023 02:59:27 INFO Epoch 4: [4115/10940] ---- BYOL Training Loss = 0.20509913563728333
31-01-2023 02:59:45 INFO Epoch 4: [4126/10940] ---- BYOL Training Loss = 0.23198933899402618
31-01-2023 03:00:03 INFO Epoch 4: [4137/10940] ---- BYOL Training Loss = 0.19059458374977112
31-01-2023 03:00:55 INFO Epoch 4: [4137/10940] ---- BYOL Validation Loss = 0.13637255132198334
31-01-2023 03:01:13 INFO Epoch 4: [4148/10940] ---- BYOL Training Loss = 0.16132959723472595
31-01-2023 03:01:32 INFO Epoch 4: [4159/10940] ---- BYOL Training Loss = 0.16818645596504211
31-01-2023 03:01:50 INFO Epoch 4: [4170/10940] ---- BYOL Training Loss = 0.18328514695167542
31-01-2023 03:02:08 INFO Epoch 4: [4181/10940] ---- BYOL Training Loss = 0.20666253566741943
31-01-2023 03:03:00 INFO Epoch 4: [4181/10940] ---- BYOL Validation Loss = 0.14571325480937958
31-01-2023 03:03:18 INFO Epoch 4: [4192/10940] ---- BYOL Training Loss = 0.24611854553222656
31-01-2023 03:03:36 INFO Epoch 4: [4203/10940] ---- BYOL Training Loss = 0.2621760070323944
31-01-2023 03:03:54 INFO Epoch 4: [4214/10940] ---- BYOL Training Loss = 0.20010633766651154
31-01-2023 03:04:13 INFO Epoch 4: [4225/10940] ---- BYOL Training Loss = 0.18885774910449982
31-01-2023 03:05:04 INFO Epoch 4: [4225/10940] ---- BYOL Validation Loss = 0.19375862181186676
31-01-2023 03:05:22 INFO Epoch 4: [4236/10940] ---- BYOL Training Loss = 0.21255961060523987
31-01-2023 03:05:41 INFO Epoch 4: [4247/10940] ---- BYOL Training Loss = 0.19494201242923737
31-01-2023 03:05:59 INFO Epoch 4: [4258/10940] ---- BYOL Training Loss = 0.16761720180511475
31-01-2023 03:06:17 INFO Epoch 4: [4269/10940] ---- BYOL Training Loss = 0.1725531816482544
31-01-2023 03:07:09 INFO Epoch 4: [4269/10940] ---- BYOL Validation Loss = 0.1337668001651764
31-01-2023 03:07:27 INFO Epoch 4: [4280/10940] ---- BYOL Training Loss = 0.16447779536247253
31-01-2023 03:07:45 INFO Epoch 4: [4291/10940] ---- BYOL Training Loss = 0.18505194783210754
31-01-2023 03:08:03 INFO Epoch 4: [4302/10940] ---- BYOL Training Loss = 0.21711058914661407
31-01-2023 03:08:22 INFO Epoch 4: [4313/10940] ---- BYOL Training Loss = 0.22593016922473907
31-01-2023 03:09:13 INFO Epoch 4: [4313/10940] ---- BYOL Validation Loss = 0.19189105927944183
31-01-2023 03:09:32 INFO Epoch 4: [4324/10940] ---- BYOL Training Loss = 0.23089830577373505
31-01-2023 03:09:50 INFO Epoch 4: [4335/10940] ---- BYOL Training Loss = 0.22824008762836456
31-01-2023 03:10:08 INFO Epoch 4: [4346/10940] ---- BYOL Training Loss = 0.17357981204986572
31-01-2023 03:10:26 INFO Epoch 4: [4357/10940] ---- BYOL Training Loss = 0.16766341030597687
31-01-2023 03:11:18 INFO Epoch 4: [4357/10940] ---- BYOL Validation Loss = 0.14945189654827118
31-01-2023 03:11:36 INFO Epoch 4: [4368/10940] ---- BYOL Training Loss = 0.1512618511915207
31-01-2023 03:11:55 INFO Epoch 4: [4379/10940] ---- BYOL Training Loss = 0.17553813755512238
31-01-2023 03:12:13 INFO Epoch 4: [4390/10940] ---- BYOL Training Loss = 0.17621347308158875
31-01-2023 03:12:31 INFO Epoch 4: [4401/10940] ---- BYOL Training Loss = 0.1624840795993805
31-01-2023 03:13:23 INFO Epoch 4: [4401/10940] ---- BYOL Validation Loss = 0.0873442068696022
31-01-2023 03:13:41 INFO Epoch 4: [4412/10940] ---- BYOL Training Loss = 0.15326467156410217
31-01-2023 03:13:59 INFO Epoch 4: [4423/10940] ---- BYOL Training Loss = 0.1723308116197586
31-01-2023 03:14:18 INFO Epoch 4: [4434/10940] ---- BYOL Training Loss = 0.1818966418504715
31-01-2023 03:14:36 INFO Epoch 4: [4445/10940] ---- BYOL Training Loss = 0.2162032574415207
31-01-2023 03:15:28 INFO Epoch 4: [4445/10940] ---- BYOL Validation Loss = 0.15818051993846893
31-01-2023 03:15:46 INFO Epoch 4: [4456/10940] ---- BYOL Training Loss = 0.2095903605222702
31-01-2023 03:16:04 INFO Epoch 4: [4467/10940] ---- BYOL Training Loss = 0.24483628571033478
31-01-2023 03:16:22 INFO Epoch 4: [4478/10940] ---- BYOL Training Loss = 0.21696989238262177
31-01-2023 03:16:40 INFO Epoch 4: [4489/10940] ---- BYOL Training Loss = 0.18921110033988953
31-01-2023 03:17:32 INFO Epoch 4: [4489/10940] ---- BYOL Validation Loss = 0.18629516661167145
31-01-2023 03:17:50 INFO Epoch 4: [4500/10940] ---- BYOL Training Loss = 0.19815579056739807
31-01-2023 03:18:09 INFO Epoch 4: [4511/10940] ---- BYOL Training Loss = 0.19472353160381317
31-01-2023 03:18:27 INFO Epoch 4: [4522/10940] ---- BYOL Training Loss = 0.21307604014873505
31-01-2023 03:18:45 INFO Epoch 4: [4533/10940] ---- BYOL Training Loss = 0.18989194929599762
31-01-2023 03:19:37 INFO Epoch 4: [4533/10940] ---- BYOL Validation Loss = 0.1821013242006302
31-01-2023 03:19:55 INFO Epoch 4: [4544/10940] ---- BYOL Training Loss = 0.159736767411232
31-01-2023 03:20:13 INFO Epoch 4: [4555/10940] ---- BYOL Training Loss = 0.20626255869865417
31-01-2023 03:20:32 INFO Epoch 4: [4566/10940] ---- BYOL Training Loss = 0.26919806003570557
31-01-2023 03:20:50 INFO Epoch 4: [4577/10940] ---- BYOL Training Loss = 0.23712989687919617
31-01-2023 03:21:42 INFO Epoch 4: [4577/10940] ---- BYOL Validation Loss = 0.16863486170768738
31-01-2023 03:22:00 INFO Epoch 4: [4588/10940] ---- BYOL Training Loss = 0.19186630845069885
31-01-2023 03:22:18 INFO Epoch 4: [4599/10940] ---- BYOL Training Loss = 0.21064309775829315
31-01-2023 03:22:37 INFO Epoch 4: [4610/10940] ---- BYOL Training Loss = 0.2546892762184143
31-01-2023 03:22:55 INFO Epoch 4: [4621/10940] ---- BYOL Training Loss = 0.23587346076965332
31-01-2023 03:23:47 INFO Epoch 4: [4621/10940] ---- BYOL Validation Loss = 0.18753497302532196
31-01-2023 03:24:05 INFO Epoch 4: [4632/10940] ---- BYOL Training Loss = 0.2485092431306839
31-01-2023 03:24:23 INFO Epoch 4: [4643/10940] ---- BYOL Training Loss = 0.2144959419965744
31-01-2023 03:24:41 INFO Epoch 4: [4654/10940] ---- BYOL Training Loss = 0.18654894828796387
31-01-2023 03:25:00 INFO Epoch 4: [4665/10940] ---- BYOL Training Loss = 0.19503699243068695
31-01-2023 03:25:51 INFO Epoch 4: [4665/10940] ---- BYOL Validation Loss = 0.19042634963989258
31-01-2023 03:26:09 INFO Epoch 4: [4676/10940] ---- BYOL Training Loss = 0.22732123732566833
31-01-2023 03:26:28 INFO Epoch 4: [4687/10940] ---- BYOL Training Loss = 0.17747819423675537
31-01-2023 03:26:46 INFO Epoch 4: [4698/10940] ---- BYOL Training Loss = 0.16134658455848694
31-01-2023 03:27:04 INFO Epoch 4: [4709/10940] ---- BYOL Training Loss = 0.18200336396694183
31-01-2023 03:27:56 INFO Epoch 4: [4709/10940] ---- BYOL Validation Loss = 0.17754055559635162
31-01-2023 03:28:14 INFO Epoch 4: [4720/10940] ---- BYOL Training Loss = 0.2563863694667816
31-01-2023 03:28:33 INFO Epoch 4: [4731/10940] ---- BYOL Training Loss = 0.19513574242591858
31-01-2023 03:28:51 INFO Epoch 4: [4742/10940] ---- BYOL Training Loss = 0.2084885835647583
31-01-2023 03:29:09 INFO Epoch 4: [4753/10940] ---- BYOL Training Loss = 0.16253912448883057
31-01-2023 03:30:01 INFO Epoch 4: [4753/10940] ---- BYOL Validation Loss = 0.10930594056844711
31-01-2023 03:30:19 INFO Epoch 4: [4764/10940] ---- BYOL Training Loss = 0.20787350833415985
31-01-2023 03:30:37 INFO Epoch 4: [4775/10940] ---- BYOL Training Loss = 0.2471790760755539
31-01-2023 03:30:56 INFO Epoch 4: [4786/10940] ---- BYOL Training Loss = 0.19571518898010254
31-01-2023 03:31:14 INFO Epoch 4: [4797/10940] ---- BYOL Training Loss = 0.1747230589389801
31-01-2023 03:32:06 INFO Epoch 4: [4797/10940] ---- BYOL Validation Loss = 0.14935867488384247
31-01-2023 03:32:24 INFO Epoch 4: [4808/10940] ---- BYOL Training Loss = 0.17357905209064484
31-01-2023 03:32:42 INFO Epoch 4: [4819/10940] ---- BYOL Training Loss = 0.2143864631652832
31-01-2023 03:33:01 INFO Epoch 4: [4830/10940] ---- BYOL Training Loss = 0.19562454521656036
31-01-2023 03:33:19 INFO Epoch 4: [4841/10940] ---- BYOL Training Loss = 0.17892439663410187
31-01-2023 03:34:11 INFO Epoch 4: [4841/10940] ---- BYOL Validation Loss = 0.1277315765619278
31-01-2023 03:34:29 INFO Epoch 4: [4852/10940] ---- BYOL Training Loss = 0.17844799160957336
31-01-2023 03:34:47 INFO Epoch 4: [4863/10940] ---- BYOL Training Loss = 0.2057315558195114
31-01-2023 03:35:05 INFO Epoch 4: [4874/10940] ---- BYOL Training Loss = 0.17713728547096252
31-01-2023 03:35:24 INFO Epoch 4: [4885/10940] ---- BYOL Training Loss = 0.2848151624202728
31-01-2023 03:36:16 INFO Epoch 4: [4885/10940] ---- BYOL Validation Loss = 0.16900917887687683
31-01-2023 03:36:34 INFO Epoch 4: [4896/10940] ---- BYOL Training Loss = 0.23298588395118713
31-01-2023 03:36:52 INFO Epoch 4: [4907/10940] ---- BYOL Training Loss = 0.20210416615009308
31-01-2023 03:37:10 INFO Epoch 4: [4918/10940] ---- BYOL Training Loss = 0.23427148163318634
31-01-2023 03:37:28 INFO Epoch 4: [4929/10940] ---- BYOL Training Loss = 0.19546277821063995
31-01-2023 03:38:20 INFO Epoch 4: [4929/10940] ---- BYOL Validation Loss = 0.15215666592121124
31-01-2023 03:38:38 INFO Epoch 4: [4940/10940] ---- BYOL Training Loss = 0.1807439625263214
31-01-2023 03:38:57 INFO Epoch 4: [4951/10940] ---- BYOL Training Loss = 0.2106427401304245
31-01-2023 03:39:15 INFO Epoch 4: [4962/10940] ---- BYOL Training Loss = 0.2132055014371872
31-01-2023 03:39:33 INFO Epoch 4: [4973/10940] ---- BYOL Training Loss = 0.21088039875030518
31-01-2023 03:40:25 INFO Epoch 4: [4973/10940] ---- BYOL Validation Loss = 0.14687712490558624
31-01-2023 03:40:43 INFO Epoch 4: [4984/10940] ---- BYOL Training Loss = 0.2040865421295166
31-01-2023 03:41:01 INFO Epoch 4: [4995/10940] ---- BYOL Training Loss = 0.1908932328224182
31-01-2023 03:41:20 INFO Epoch 4: [5006/10940] ---- BYOL Training Loss = 0.21254070103168488
31-01-2023 03:41:38 INFO Epoch 4: [5017/10940] ---- BYOL Training Loss = 0.2304685413837433
31-01-2023 03:42:30 INFO Epoch 4: [5017/10940] ---- BYOL Validation Loss = 0.1235043853521347
31-01-2023 03:42:48 INFO Epoch 4: [5028/10940] ---- BYOL Training Loss = 0.22390218079090118
31-01-2023 03:43:06 INFO Epoch 4: [5039/10940] ---- BYOL Training Loss = 0.1797153651714325
31-01-2023 03:43:25 INFO Epoch 4: [5050/10940] ---- BYOL Training Loss = 0.1806168258190155
31-01-2023 03:43:43 INFO Epoch 4: [5061/10940] ---- BYOL Training Loss = 0.19731387495994568
31-01-2023 03:44:35 INFO Epoch 4: [5061/10940] ---- BYOL Validation Loss = 0.17262153327465057
31-01-2023 03:44:53 INFO Epoch 4: [5072/10940] ---- BYOL Training Loss = 0.18630068004131317
31-01-2023 03:45:11 INFO Epoch 4: [5083/10940] ---- BYOL Training Loss = 0.17852632701396942
31-01-2023 03:45:30 INFO Epoch 4: [5094/10940] ---- BYOL Training Loss = 0.1466808170080185
31-01-2023 03:45:48 INFO Epoch 4: [5105/10940] ---- BYOL Training Loss = 0.13877859711647034
31-01-2023 03:46:40 INFO Epoch 4: [5105/10940] ---- BYOL Validation Loss = 0.14818623661994934
31-01-2023 03:46:58 INFO Epoch 4: [5116/10940] ---- BYOL Training Loss = 0.1648835688829422
31-01-2023 03:47:16 INFO Epoch 4: [5127/10940] ---- BYOL Training Loss = 0.19074855744838715
31-01-2023 03:47:35 INFO Epoch 4: [5138/10940] ---- BYOL Training Loss = 0.20102515816688538
31-01-2023 03:47:53 INFO Epoch 4: [5149/10940] ---- BYOL Training Loss = 0.19588960707187653
31-01-2023 03:48:45 INFO Epoch 4: [5149/10940] ---- BYOL Validation Loss = 0.14410574734210968
31-01-2023 03:49:03 INFO Epoch 4: [5160/10940] ---- BYOL Training Loss = 0.20401844382286072
31-01-2023 03:49:21 INFO Epoch 4: [5171/10940] ---- BYOL Training Loss = 0.2104339599609375
31-01-2023 03:49:39 INFO Epoch 4: [5182/10940] ---- BYOL Training Loss = 0.20691077411174774
31-01-2023 03:49:58 INFO Epoch 4: [5193/10940] ---- BYOL Training Loss = 0.15856094658374786
31-01-2023 03:50:50 INFO Epoch 4: [5193/10940] ---- BYOL Validation Loss = 0.1304473727941513
31-01-2023 03:51:08 INFO Epoch 4: [5204/10940] ---- BYOL Training Loss = 0.19237467646598816
31-01-2023 03:51:26 INFO Epoch 4: [5215/10940] ---- BYOL Training Loss = 0.19331136345863342
31-01-2023 03:51:45 INFO Epoch 4: [5226/10940] ---- BYOL Training Loss = 0.18747475743293762
31-01-2023 03:52:03 INFO Epoch 4: [5237/10940] ---- BYOL Training Loss = 0.1839028149843216
31-01-2023 03:52:55 INFO Epoch 4: [5237/10940] ---- BYOL Validation Loss = 0.14625577628612518
31-01-2023 03:53:13 INFO Epoch 4: [5248/10940] ---- BYOL Training Loss = 0.17465391755104065
31-01-2023 03:53:31 INFO Epoch 4: [5259/10940] ---- BYOL Training Loss = 0.18750105798244476
31-01-2023 03:53:49 INFO Epoch 4: [5270/10940] ---- BYOL Training Loss = 0.1716153472661972
31-01-2023 03:54:08 INFO Epoch 4: [5281/10940] ---- BYOL Training Loss = 0.18967846035957336
31-01-2023 03:54:59 INFO Epoch 4: [5281/10940] ---- BYOL Validation Loss = 0.1176769882440567
31-01-2023 03:55:18 INFO Epoch 4: [5292/10940] ---- BYOL Training Loss = 0.17380291223526
31-01-2023 03:55:36 INFO Epoch 4: [5303/10940] ---- BYOL Training Loss = 0.1717691421508789
31-01-2023 03:55:54 INFO Epoch 4: [5314/10940] ---- BYOL Training Loss = 0.20146653056144714
31-01-2023 03:56:13 INFO Epoch 4: [5325/10940] ---- BYOL Training Loss = 0.18372659385204315
31-01-2023 03:57:04 INFO Epoch 4: [5325/10940] ---- BYOL Validation Loss = 0.13746614754199982
31-01-2023 03:57:23 INFO Epoch 4: [5336/10940] ---- BYOL Training Loss = 0.15740592777729034
31-01-2023 03:57:41 INFO Epoch 4: [5347/10940] ---- BYOL Training Loss = 0.19299131631851196
31-01-2023 03:57:59 INFO Epoch 4: [5358/10940] ---- BYOL Training Loss = 0.2596926987171173
31-01-2023 03:58:18 INFO Epoch 4: [5369/10940] ---- BYOL Training Loss = 0.21371793746948242
31-01-2023 03:59:10 INFO Epoch 4: [5369/10940] ---- BYOL Validation Loss = 0.18016628921031952
31-01-2023 03:59:27 INFO Epoch 4: [5380/10940] ---- BYOL Training Loss = 0.19252930581569672
31-01-2023 03:59:46 INFO Epoch 4: [5391/10940] ---- BYOL Training Loss = 0.15559929609298706
31-01-2023 04:00:05 INFO Epoch 4: [5402/10940] ---- BYOL Training Loss = 0.1634543091058731
31-01-2023 04:00:23 INFO Epoch 4: [5413/10940] ---- BYOL Training Loss = 0.21518704295158386
31-01-2023 04:01:15 INFO Epoch 4: [5413/10940] ---- BYOL Validation Loss = 0.15669648349285126
31-01-2023 04:01:33 INFO Epoch 4: [5424/10940] ---- BYOL Training Loss = 0.21191570162773132
31-01-2023 04:01:51 INFO Epoch 4: [5435/10940] ---- BYOL Training Loss = 0.17422650754451752
31-01-2023 04:02:10 INFO Epoch 4: [5446/10940] ---- BYOL Training Loss = 0.16661657392978668
31-01-2023 04:02:28 INFO Epoch 4: [5457/10940] ---- BYOL Training Loss = 0.14661064743995667
31-01-2023 04:03:20 INFO Epoch 4: [5457/10940] ---- BYOL Validation Loss = 0.12605203688144684
31-01-2023 04:03:38 INFO Epoch 4: [5468/10940] ---- BYOL Training Loss = 0.19410806894302368
31-01-2023 04:03:56 INFO Epoch 4: [5479/10940] ---- BYOL Training Loss = 0.22157855331897736
31-01-2023 04:04:15 INFO Epoch 4: [5490/10940] ---- BYOL Training Loss = 0.1773480921983719
31-01-2023 04:04:33 INFO Epoch 4: [5501/10940] ---- BYOL Training Loss = 0.1538061797618866
31-01-2023 04:05:25 INFO Epoch 4: [5501/10940] ---- BYOL Validation Loss = 0.11689461022615433
31-01-2023 04:05:43 INFO Epoch 4: [5512/10940] ---- BYOL Training Loss = 0.16622701287269592
31-01-2023 04:06:01 INFO Epoch 4: [5523/10940] ---- BYOL Training Loss = 0.1728191077709198
31-01-2023 04:06:20 INFO Epoch 4: [5534/10940] ---- BYOL Training Loss = 0.15709052979946136
31-01-2023 04:06:38 INFO Epoch 4: [5545/10940] ---- BYOL Training Loss = 0.1708979606628418
31-01-2023 04:07:30 INFO Epoch 4: [5545/10940] ---- BYOL Validation Loss = 0.11921211332082748
31-01-2023 04:07:48 INFO Epoch 4: [5556/10940] ---- BYOL Training Loss = 0.1709962636232376
31-01-2023 04:08:06 INFO Epoch 4: [5567/10940] ---- BYOL Training Loss = 0.14867663383483887
31-01-2023 04:08:25 INFO Epoch 4: [5578/10940] ---- BYOL Training Loss = 0.16205371916294098
31-01-2023 04:08:43 INFO Epoch 4: [5589/10940] ---- BYOL Training Loss = 0.14582577347755432
31-01-2023 04:09:35 INFO Epoch 4: [5589/10940] ---- BYOL Validation Loss = 0.1061333566904068
31-01-2023 04:09:53 INFO Epoch 4: [5600/10940] ---- BYOL Training Loss = 0.15655210614204407
31-01-2023 04:10:11 INFO Epoch 4: [5611/10940] ---- BYOL Training Loss = 0.1853628158569336
31-01-2023 04:10:30 INFO Epoch 4: [5622/10940] ---- BYOL Training Loss = 0.20125265419483185
31-01-2023 04:10:49 INFO Epoch 4: [5633/10940] ---- BYOL Training Loss = 0.15650886297225952
31-01-2023 04:11:40 INFO Epoch 4: [5633/10940] ---- BYOL Validation Loss = 0.09944988787174225
31-01-2023 04:11:58 INFO Epoch 4: [5644/10940] ---- BYOL Training Loss = 0.1597616821527481
31-01-2023 04:12:17 INFO Epoch 4: [5655/10940] ---- BYOL Training Loss = 0.189898282289505
31-01-2023 04:12:35 INFO Epoch 4: [5666/10940] ---- BYOL Training Loss = 0.1432337611913681
31-01-2023 04:12:54 INFO Epoch 4: [5677/10940] ---- BYOL Training Loss = 0.14636729657649994
31-01-2023 04:13:46 INFO Epoch 4: [5677/10940] ---- BYOL Validation Loss = 0.14465762674808502
31-01-2023 04:14:04 INFO Epoch 4: [5688/10940] ---- BYOL Training Loss = 0.21127696335315704
31-01-2023 04:14:22 INFO Epoch 4: [5699/10940] ---- BYOL Training Loss = 0.21726778149604797
31-01-2023 04:14:41 INFO Epoch 4: [5710/10940] ---- BYOL Training Loss = 0.23692722618579865
31-01-2023 04:14:59 INFO Epoch 4: [5721/10940] ---- BYOL Training Loss = 0.22794902324676514
31-01-2023 04:15:51 INFO Epoch 4: [5721/10940] ---- BYOL Validation Loss = 0.06777600198984146
31-01-2023 04:16:09 INFO Epoch 4: [5732/10940] ---- BYOL Training Loss = 0.19786188006401062
31-01-2023 04:16:27 INFO Epoch 4: [5743/10940] ---- BYOL Training Loss = 0.1997208446264267
31-01-2023 04:16:46 INFO Epoch 4: [5754/10940] ---- BYOL Training Loss = 0.13726051151752472
31-01-2023 04:17:04 INFO Epoch 4: [5765/10940] ---- BYOL Training Loss = 0.14564025402069092
31-01-2023 04:17:56 INFO Epoch 4: [5765/10940] ---- BYOL Validation Loss = 0.12972061336040497
31-01-2023 04:18:14 INFO Epoch 4: [5776/10940] ---- BYOL Training Loss = 0.14860770106315613
31-01-2023 04:18:32 INFO Epoch 4: [5787/10940] ---- BYOL Training Loss = 0.16303284466266632
31-01-2023 04:18:51 INFO Epoch 4: [5798/10940] ---- BYOL Training Loss = 0.192538782954216
31-01-2023 04:19:09 INFO Epoch 4: [5809/10940] ---- BYOL Training Loss = 0.1764460951089859
31-01-2023 04:20:01 INFO Epoch 4: [5809/10940] ---- BYOL Validation Loss = 0.12819825112819672
31-01-2023 04:20:19 INFO Epoch 4: [5820/10940] ---- BYOL Training Loss = 0.15429078042507172
31-01-2023 04:20:37 INFO Epoch 4: [5831/10940] ---- BYOL Training Loss = 0.14645035564899445
31-01-2023 04:20:56 INFO Epoch 4: [5842/10940] ---- BYOL Training Loss = 0.2185998260974884
31-01-2023 04:21:15 INFO Epoch 4: [5853/10940] ---- BYOL Training Loss = 0.2084900140762329
31-01-2023 04:22:06 INFO Epoch 4: [5853/10940] ---- BYOL Validation Loss = 0.1505730301141739
31-01-2023 04:22:24 INFO Epoch 4: [5864/10940] ---- BYOL Training Loss = 0.16761142015457153
31-01-2023 04:22:43 INFO Epoch 4: [5875/10940] ---- BYOL Training Loss = 0.16080859303474426
31-01-2023 04:23:01 INFO Epoch 4: [5886/10940] ---- BYOL Training Loss = 0.20201285183429718
31-01-2023 04:23:20 INFO Epoch 4: [5897/10940] ---- BYOL Training Loss = 0.21474361419677734
31-01-2023 04:24:12 INFO Epoch 4: [5897/10940] ---- BYOL Validation Loss = 0.16556020081043243
31-01-2023 04:24:30 INFO Epoch 4: [5908/10940] ---- BYOL Training Loss = 0.20518331229686737
31-01-2023 04:24:48 INFO Epoch 4: [5919/10940] ---- BYOL Training Loss = 0.20926973223686218
31-01-2023 04:25:07 INFO Epoch 4: [5930/10940] ---- BYOL Training Loss = 0.18702468276023865
31-01-2023 04:25:25 INFO Epoch 4: [5941/10940] ---- BYOL Training Loss = 0.17277248203754425
31-01-2023 04:26:17 INFO Epoch 4: [5941/10940] ---- BYOL Validation Loss = 0.09741400182247162
31-01-2023 04:26:35 INFO Epoch 4: [5952/10940] ---- BYOL Training Loss = 0.18524427711963654
31-01-2023 04:26:54 INFO Epoch 4: [5963/10940] ---- BYOL Training Loss = 0.14951887726783752
31-01-2023 04:27:12 INFO Epoch 4: [5974/10940] ---- BYOL Training Loss = 0.15259607136249542
31-01-2023 04:27:30 INFO Epoch 4: [5985/10940] ---- BYOL Training Loss = 0.16207009553909302
31-01-2023 04:28:22 INFO Epoch 4: [5985/10940] ---- BYOL Validation Loss = 0.1038881316781044
31-01-2023 04:28:40 INFO Epoch 4: [5996/10940] ---- BYOL Training Loss = 0.1367473155260086
31-01-2023 04:28:59 INFO Epoch 4: [6007/10940] ---- BYOL Training Loss = 0.13164623081684113
31-01-2023 04:29:17 INFO Epoch 4: [6018/10940] ---- BYOL Training Loss = 0.144643634557724
31-01-2023 04:29:36 INFO Epoch 4: [6029/10940] ---- BYOL Training Loss = 0.1939743608236313
31-01-2023 04:30:28 INFO Epoch 4: [6029/10940] ---- BYOL Validation Loss = 0.12473160773515701
31-01-2023 04:30:46 INFO Epoch 4: [6040/10940] ---- BYOL Training Loss = 0.2052527368068695
31-01-2023 04:31:04 INFO Epoch 4: [6051/10940] ---- BYOL Training Loss = 0.1890237182378769
31-01-2023 04:31:23 INFO Epoch 4: [6062/10940] ---- BYOL Training Loss = 0.15260162949562073
31-01-2023 04:31:41 INFO Epoch 4: [6073/10940] ---- BYOL Training Loss = 0.14474844932556152
31-01-2023 04:32:33 INFO Epoch 4: [6073/10940] ---- BYOL Validation Loss = 0.1034049317240715
31-01-2023 04:32:52 INFO Epoch 4: [6084/10940] ---- BYOL Training Loss = 0.17663171887397766
31-01-2023 04:33:10 INFO Epoch 4: [6095/10940] ---- BYOL Training Loss = 0.18548208475112915
31-01-2023 04:33:28 INFO Epoch 4: [6106/10940] ---- BYOL Training Loss = 0.1962614357471466
31-01-2023 04:33:47 INFO Epoch 4: [6117/10940] ---- BYOL Training Loss = 0.22845110297203064
31-01-2023 04:34:38 INFO Epoch 4: [6117/10940] ---- BYOL Validation Loss = 0.12836243212223053
31-01-2023 04:34:57 INFO Epoch 4: [6128/10940] ---- BYOL Training Loss = 0.22128836810588837
31-01-2023 04:35:15 INFO Epoch 4: [6139/10940] ---- BYOL Training Loss = 0.20049341022968292
31-01-2023 04:35:34 INFO Epoch 4: [6150/10940] ---- BYOL Training Loss = 0.18721115589141846
31-01-2023 04:35:52 INFO Epoch 4: [6161/10940] ---- BYOL Training Loss = 0.183562234044075
31-01-2023 04:36:44 INFO Epoch 4: [6161/10940] ---- BYOL Validation Loss = 0.126728817820549
31-01-2023 04:37:02 INFO Epoch 4: [6172/10940] ---- BYOL Training Loss = 0.16967055201530457
31-01-2023 04:37:21 INFO Epoch 4: [6183/10940] ---- BYOL Training Loss = 0.21779397130012512
31-01-2023 04:37:39 INFO Epoch 4: [6194/10940] ---- BYOL Training Loss = 0.20268404483795166
31-01-2023 04:37:57 INFO Epoch 4: [6205/10940] ---- BYOL Training Loss = 0.18625280261039734
31-01-2023 04:38:49 INFO Epoch 4: [6205/10940] ---- BYOL Validation Loss = 0.1333908587694168
31-01-2023 04:39:08 INFO Epoch 4: [6216/10940] ---- BYOL Training Loss = 0.14901331067085266
31-01-2023 04:39:26 INFO Epoch 4: [6227/10940] ---- BYOL Training Loss = 0.1799725592136383
31-01-2023 04:39:45 INFO Epoch 4: [6238/10940] ---- BYOL Training Loss = 0.1882283240556717
31-01-2023 04:40:03 INFO Epoch 4: [6249/10940] ---- BYOL Training Loss = 0.15109504759311676
31-01-2023 04:40:55 INFO Epoch 4: [6249/10940] ---- BYOL Validation Loss = 0.10787921398878098
31-01-2023 04:41:13 INFO Epoch 4: [6260/10940] ---- BYOL Training Loss = 0.22965678572654724
31-01-2023 04:41:32 INFO Epoch 4: [6271/10940] ---- BYOL Training Loss = 0.2693854570388794
31-01-2023 04:41:50 INFO Epoch 4: [6282/10940] ---- BYOL Training Loss = 0.19420111179351807
31-01-2023 04:42:09 INFO Epoch 4: [6293/10940] ---- BYOL Training Loss = 0.22280967235565186
31-01-2023 04:43:01 INFO Epoch 4: [6293/10940] ---- BYOL Validation Loss = 0.18103544414043427
31-01-2023 04:43:19 INFO Epoch 4: [6304/10940] ---- BYOL Training Loss = 0.23105785250663757
31-01-2023 04:43:37 INFO Epoch 4: [6315/10940] ---- BYOL Training Loss = 0.2302117794752121
31-01-2023 04:43:56 INFO Epoch 4: [6326/10940] ---- BYOL Training Loss = 0.18404154479503632
31-01-2023 04:44:14 INFO Epoch 4: [6337/10940] ---- BYOL Training Loss = 0.13305094838142395
31-01-2023 04:45:06 INFO Epoch 4: [6337/10940] ---- BYOL Validation Loss = 0.13724729418754578
31-01-2023 04:45:24 INFO Epoch 4: [6348/10940] ---- BYOL Training Loss = 0.18621425330638885
31-01-2023 04:45:42 INFO Epoch 4: [6359/10940] ---- BYOL Training Loss = 0.20915396511554718
31-01-2023 04:46:01 INFO Epoch 4: [6370/10940] ---- BYOL Training Loss = 0.17741243541240692
31-01-2023 04:46:20 INFO Epoch 4: [6381/10940] ---- BYOL Training Loss = 0.17215558886528015
31-01-2023 04:47:12 INFO Epoch 4: [6381/10940] ---- BYOL Validation Loss = 0.12880553305149078
31-01-2023 04:47:30 INFO Epoch 4: [6392/10940] ---- BYOL Training Loss = 0.20132772624492645
31-01-2023 04:47:48 INFO Epoch 4: [6403/10940] ---- BYOL Training Loss = 0.18699844181537628
31-01-2023 04:48:07 INFO Epoch 4: [6414/10940] ---- BYOL Training Loss = 0.18913742899894714
31-01-2023 04:48:25 INFO Epoch 4: [6425/10940] ---- BYOL Training Loss = 0.22371888160705566
31-01-2023 04:49:17 INFO Epoch 4: [6425/10940] ---- BYOL Validation Loss = 0.13745234906673431
31-01-2023 04:49:35 INFO Epoch 4: [6436/10940] ---- BYOL Training Loss = 0.15260380506515503
31-01-2023 04:49:53 INFO Epoch 4: [6447/10940] ---- BYOL Training Loss = 0.14706715941429138
31-01-2023 04:50:12 INFO Epoch 4: [6458/10940] ---- BYOL Training Loss = 0.18564245104789734
31-01-2023 04:50:31 INFO Epoch 4: [6469/10940] ---- BYOL Training Loss = 0.16529539227485657
31-01-2023 04:51:22 INFO Epoch 4: [6469/10940] ---- BYOL Validation Loss = 0.12943436205387115
31-01-2023 04:51:40 INFO Epoch 4: [6480/10940] ---- BYOL Training Loss = 0.19768323004245758
31-01-2023 04:51:59 INFO Epoch 4: [6491/10940] ---- BYOL Training Loss = 0.16407202184200287
31-01-2023 04:52:18 INFO Epoch 4: [6502/10940] ---- BYOL Training Loss = 0.1668611466884613
31-01-2023 04:52:36 INFO Epoch 4: [6513/10940] ---- BYOL Training Loss = 0.1786632388830185
31-01-2023 04:53:28 INFO Epoch 4: [6513/10940] ---- BYOL Validation Loss = 0.1451496183872223
31-01-2023 04:53:46 INFO Epoch 4: [6524/10940] ---- BYOL Training Loss = 0.16053542494773865
31-01-2023 04:54:04 INFO Epoch 4: [6535/10940] ---- BYOL Training Loss = 0.16275234520435333
31-01-2023 04:54:23 INFO Epoch 4: [6546/10940] ---- BYOL Training Loss = 0.19058305025100708
31-01-2023 04:54:41 INFO Epoch 4: [6557/10940] ---- BYOL Training Loss = 0.1550048589706421
31-01-2023 04:55:33 INFO Epoch 4: [6557/10940] ---- BYOL Validation Loss = 0.11208707094192505
31-01-2023 04:55:52 INFO Epoch 4: [6568/10940] ---- BYOL Training Loss = 0.11853192001581192
31-01-2023 04:56:10 INFO Epoch 4: [6579/10940] ---- BYOL Training Loss = 0.12424583733081818
31-01-2023 04:56:28 INFO Epoch 4: [6590/10940] ---- BYOL Training Loss = 0.16298386454582214
31-01-2023 04:56:47 INFO Epoch 4: [6601/10940] ---- BYOL Training Loss = 0.19311866164207458
31-01-2023 04:57:38 INFO Epoch 4: [6601/10940] ---- BYOL Validation Loss = 0.15074145793914795
31-01-2023 04:57:57 INFO Epoch 4: [6612/10940] ---- BYOL Training Loss = 0.21492965519428253
31-01-2023 04:58:15 INFO Epoch 4: [6623/10940] ---- BYOL Training Loss = 0.18091639876365662
31-01-2023 04:58:34 INFO Epoch 4: [6634/10940] ---- BYOL Training Loss = 0.16121840476989746
31-01-2023 04:58:52 INFO Epoch 4: [6645/10940] ---- BYOL Training Loss = 0.17972886562347412
31-01-2023 04:59:44 INFO Epoch 4: [6645/10940] ---- BYOL Validation Loss = 0.15869252383708954
31-01-2023 05:00:03 INFO Epoch 4: [6656/10940] ---- BYOL Training Loss = 0.16587138175964355
31-01-2023 05:00:21 INFO Epoch 4: [6667/10940] ---- BYOL Training Loss = 0.14690226316452026
31-01-2023 05:00:39 INFO Epoch 4: [6678/10940] ---- BYOL Training Loss = 0.1727360337972641
31-01-2023 05:00:58 INFO Epoch 4: [6689/10940] ---- BYOL Training Loss = 0.22233131527900696
31-01-2023 05:01:50 INFO Epoch 4: [6689/10940] ---- BYOL Validation Loss = 0.1433967798948288
31-01-2023 05:02:08 INFO Epoch 4: [6700/10940] ---- BYOL Training Loss = 0.21122440695762634
31-01-2023 05:02:26 INFO Epoch 4: [6711/10940] ---- BYOL Training Loss = 0.20561213791370392
31-01-2023 05:02:45 INFO Epoch 4: [6722/10940] ---- BYOL Training Loss = 0.18346889317035675
31-01-2023 05:03:04 INFO Epoch 4: [6733/10940] ---- BYOL Training Loss = 0.19446350634098053
31-01-2023 05:03:55 INFO Epoch 4: [6733/10940] ---- BYOL Validation Loss = 0.1253151148557663
31-01-2023 05:04:14 INFO Epoch 4: [6744/10940] ---- BYOL Training Loss = 0.2192554920911789
31-01-2023 05:04:32 INFO Epoch 4: [6755/10940] ---- BYOL Training Loss = 0.204209566116333
31-01-2023 05:04:51 INFO Epoch 4: [6766/10940] ---- BYOL Training Loss = 0.18462884426116943
31-01-2023 05:05:09 INFO Epoch 4: [6777/10940] ---- BYOL Training Loss = 0.18389393389225006
31-01-2023 05:06:01 INFO Epoch 4: [6777/10940] ---- BYOL Validation Loss = 0.14430442452430725
31-01-2023 05:06:19 INFO Epoch 4: [6788/10940] ---- BYOL Training Loss = 0.22385282814502716
31-01-2023 05:06:38 INFO Epoch 4: [6799/10940] ---- BYOL Training Loss = 0.24156606197357178
31-01-2023 05:06:56 INFO Epoch 4: [6810/10940] ---- BYOL Training Loss = 0.2160075157880783
31-01-2023 05:07:15 INFO Epoch 4: [6821/10940] ---- BYOL Training Loss = 0.1755043864250183
31-01-2023 05:08:07 INFO Epoch 4: [6821/10940] ---- BYOL Validation Loss = 0.15438535809516907
31-01-2023 05:08:25 INFO Epoch 4: [6832/10940] ---- BYOL Training Loss = 0.1462816745042801
31-01-2023 05:08:44 INFO Epoch 4: [6843/10940] ---- BYOL Training Loss = 0.1516725867986679
31-01-2023 05:09:02 INFO Epoch 4: [6854/10940] ---- BYOL Training Loss = 0.15995708107948303
31-01-2023 05:09:21 INFO Epoch 4: [6865/10940] ---- BYOL Training Loss = 0.21584215760231018
31-01-2023 05:10:12 INFO Epoch 4: [6865/10940] ---- BYOL Validation Loss = 0.16971434652805328
31-01-2023 05:10:31 INFO Epoch 4: [6876/10940] ---- BYOL Training Loss = 0.21487045288085938
31-01-2023 05:10:49 INFO Epoch 4: [6887/10940] ---- BYOL Training Loss = 0.1676088571548462
31-01-2023 05:11:08 INFO Epoch 4: [6898/10940] ---- BYOL Training Loss = 0.1551094800233841
31-01-2023 05:11:27 INFO Epoch 4: [6909/10940] ---- BYOL Training Loss = 0.1643890142440796
31-01-2023 05:12:18 INFO Epoch 4: [6909/10940] ---- BYOL Validation Loss = 0.15737251937389374
31-01-2023 05:12:37 INFO Epoch 4: [6920/10940] ---- BYOL Training Loss = 0.1940794736146927
31-01-2023 05:12:55 INFO Epoch 4: [6931/10940] ---- BYOL Training Loss = 0.21306081116199493
31-01-2023 05:13:13 INFO Epoch 4: [6942/10940] ---- BYOL Training Loss = 0.18147124350070953
31-01-2023 05:13:32 INFO Epoch 4: [6953/10940] ---- BYOL Training Loss = 0.1994621455669403
31-01-2023 05:14:24 INFO Epoch 4: [6953/10940] ---- BYOL Validation Loss = 0.15515808761119843
31-01-2023 05:14:42 INFO Epoch 4: [6964/10940] ---- BYOL Training Loss = 0.19137969613075256
31-01-2023 05:15:01 INFO Epoch 4: [6975/10940] ---- BYOL Training Loss = 0.1566971093416214
31-01-2023 05:15:19 INFO Epoch 4: [6986/10940] ---- BYOL Training Loss = 0.164491206407547
31-01-2023 05:15:38 INFO Epoch 4: [6997/10940] ---- BYOL Training Loss = 0.15739786624908447
31-01-2023 05:16:30 INFO Epoch 4: [6997/10940] ---- BYOL Validation Loss = 0.15876904129981995
31-01-2023 05:16:48 INFO Epoch 4: [7008/10940] ---- BYOL Training Loss = 0.1605605036020279
31-01-2023 05:17:06 INFO Epoch 4: [7019/10940] ---- BYOL Training Loss = 0.167129784822464
31-01-2023 05:17:25 INFO Epoch 4: [7030/10940] ---- BYOL Training Loss = 0.1642683893442154
31-01-2023 05:17:43 INFO Epoch 4: [7041/10940] ---- BYOL Training Loss = 0.16192243993282318
31-01-2023 05:18:35 INFO Epoch 4: [7041/10940] ---- BYOL Validation Loss = 0.1517343521118164
31-01-2023 05:18:53 INFO Epoch 4: [7052/10940] ---- BYOL Training Loss = 0.17330776154994965
31-01-2023 05:19:12 INFO Epoch 4: [7063/10940] ---- BYOL Training Loss = 0.19852295517921448
31-01-2023 05:19:31 INFO Epoch 4: [7074/10940] ---- BYOL Training Loss = 0.14991527795791626
31-01-2023 05:19:49 INFO Epoch 4: [7085/10940] ---- BYOL Training Loss = 0.15149447321891785
31-01-2023 05:20:41 INFO Epoch 4: [7085/10940] ---- BYOL Validation Loss = 0.12903203070163727
31-01-2023 05:20:59 INFO Epoch 4: [7096/10940] ---- BYOL Training Loss = 0.1608196347951889
31-01-2023 05:21:18 INFO Epoch 4: [7107/10940] ---- BYOL Training Loss = 0.20174185931682587
31-01-2023 05:21:36 INFO Epoch 4: [7118/10940] ---- BYOL Training Loss = 0.17002348601818085
31-01-2023 05:21:55 INFO Epoch 4: [7129/10940] ---- BYOL Training Loss = 0.15577904880046844
31-01-2023 05:22:47 INFO Epoch 4: [7129/10940] ---- BYOL Validation Loss = 0.13871893286705017
31-01-2023 05:23:05 INFO Epoch 4: [7140/10940] ---- BYOL Training Loss = 0.14173077046871185
31-01-2023 05:23:24 INFO Epoch 4: [7151/10940] ---- BYOL Training Loss = 0.1257798820734024
31-01-2023 05:23:42 INFO Epoch 4: [7162/10940] ---- BYOL Training Loss = 0.18897651135921478
31-01-2023 05:24:01 INFO Epoch 4: [7173/10940] ---- BYOL Training Loss = 0.21119315922260284
31-01-2023 05:24:53 INFO Epoch 4: [7173/10940] ---- BYOL Validation Loss = 0.1362716406583786
31-01-2023 05:25:11 INFO Epoch 4: [7184/10940] ---- BYOL Training Loss = 0.25622010231018066
31-01-2023 05:25:29 INFO Epoch 4: [7195/10940] ---- BYOL Training Loss = 0.2822229266166687
31-01-2023 05:25:48 INFO Epoch 4: [7206/10940] ---- BYOL Training Loss = 0.221400186419487
31-01-2023 05:26:07 INFO Epoch 4: [7217/10940] ---- BYOL Training Loss = 0.1500137597322464
31-01-2023 05:26:59 INFO Epoch 4: [7217/10940] ---- BYOL Validation Loss = 0.12531863152980804
31-01-2023 05:27:17 INFO Epoch 4: [7228/10940] ---- BYOL Training Loss = 0.15680675208568573
31-01-2023 05:27:36 INFO Epoch 4: [7239/10940] ---- BYOL Training Loss = 0.15684576332569122
31-01-2023 05:27:54 INFO Epoch 4: [7250/10940] ---- BYOL Training Loss = 0.14404915273189545
31-01-2023 05:28:13 INFO Epoch 4: [7261/10940] ---- BYOL Training Loss = 0.13533642888069153
31-01-2023 05:29:04 INFO Epoch 4: [7261/10940] ---- BYOL Validation Loss = 0.14005349576473236
31-01-2023 05:29:23 INFO Epoch 4: [7272/10940] ---- BYOL Training Loss = 0.17119792103767395
31-01-2023 05:29:42 INFO Epoch 4: [7283/10940] ---- BYOL Training Loss = 0.19012399017810822
31-01-2023 05:30:00 INFO Epoch 4: [7294/10940] ---- BYOL Training Loss = 0.18664608895778656
31-01-2023 05:30:18 INFO Epoch 4: [7305/10940] ---- BYOL Training Loss = 0.14389744400978088
31-01-2023 05:31:10 INFO Epoch 4: [7305/10940] ---- BYOL Validation Loss = 0.12931910157203674
31-01-2023 05:31:29 INFO Epoch 4: [7316/10940] ---- BYOL Training Loss = 0.1636391580104828
31-01-2023 05:31:47 INFO Epoch 4: [7327/10940] ---- BYOL Training Loss = 0.22603389620780945
31-01-2023 05:32:06 INFO Epoch 4: [7338/10940] ---- BYOL Training Loss = 0.17421682178974152
31-01-2023 05:32:24 INFO Epoch 4: [7349/10940] ---- BYOL Training Loss = 0.17592930793762207
31-01-2023 05:33:16 INFO Epoch 4: [7349/10940] ---- BYOL Validation Loss = 0.1356891691684723
31-01-2023 05:33:34 INFO Epoch 4: [7360/10940] ---- BYOL Training Loss = 0.1452483981847763
31-01-2023 05:33:53 INFO Epoch 4: [7371/10940] ---- BYOL Training Loss = 0.17875395715236664
31-01-2023 05:34:12 INFO Epoch 4: [7382/10940] ---- BYOL Training Loss = 0.18013855814933777
31-01-2023 05:34:30 INFO Epoch 4: [7393/10940] ---- BYOL Training Loss = 0.18015941977500916
31-01-2023 05:35:22 INFO Epoch 4: [7393/10940] ---- BYOL Validation Loss = 0.1397462636232376
31-01-2023 05:35:40 INFO Epoch 4: [7404/10940] ---- BYOL Training Loss = 0.22052037715911865
31-01-2023 05:35:59 INFO Epoch 4: [7415/10940] ---- BYOL Training Loss = 0.2116898000240326
31-01-2023 05:36:18 INFO Epoch 4: [7426/10940] ---- BYOL Training Loss = 0.17883534729480743
31-01-2023 05:36:36 INFO Epoch 4: [7437/10940] ---- BYOL Training Loss = 0.17271409928798676
31-01-2023 05:37:28 INFO Epoch 4: [7437/10940] ---- BYOL Validation Loss = 0.1538335233926773
31-01-2023 05:37:47 INFO Epoch 4: [7448/10940] ---- BYOL Training Loss = 0.14813204109668732
31-01-2023 05:38:05 INFO Epoch 4: [7459/10940] ---- BYOL Training Loss = 0.15263275802135468
31-01-2023 05:38:24 INFO Epoch 4: [7470/10940] ---- BYOL Training Loss = 0.21021561324596405
31-01-2023 05:38:43 INFO Epoch 4: [7481/10940] ---- BYOL Training Loss = 0.18264278769493103
31-01-2023 05:39:34 INFO Epoch 4: [7481/10940] ---- BYOL Validation Loss = 0.09860534220933914
31-01-2023 05:39:53 INFO Epoch 4: [7492/10940] ---- BYOL Training Loss = 0.16403742134571075
31-01-2023 05:40:11 INFO Epoch 4: [7503/10940] ---- BYOL Training Loss = 0.19013579189777374
31-01-2023 05:40:30 INFO Epoch 4: [7514/10940] ---- BYOL Training Loss = 0.16891250014305115
31-01-2023 05:40:49 INFO Epoch 4: [7525/10940] ---- BYOL Training Loss = 0.132698193192482
31-01-2023 05:41:40 INFO Epoch 4: [7525/10940] ---- BYOL Validation Loss = 0.14278282225131989
31-01-2023 05:41:58 INFO Epoch 4: [7536/10940] ---- BYOL Training Loss = 0.14728370308876038
31-01-2023 05:42:17 INFO Epoch 4: [7547/10940] ---- BYOL Training Loss = 0.17385724186897278
31-01-2023 05:42:36 INFO Epoch 4: [7558/10940] ---- BYOL Training Loss = 0.20013579726219177
31-01-2023 05:42:54 INFO Epoch 4: [7569/10940] ---- BYOL Training Loss = 0.19000382721424103
31-01-2023 05:43:46 INFO Epoch 4: [7569/10940] ---- BYOL Validation Loss = 0.17818191647529602
31-01-2023 05:44:04 INFO Epoch 4: [7580/10940] ---- BYOL Training Loss = 0.17407111823558807
31-01-2023 05:44:23 INFO Epoch 4: [7591/10940] ---- BYOL Training Loss = 0.1964292824268341
31-01-2023 05:44:42 INFO Epoch 4: [7602/10940] ---- BYOL Training Loss = 0.18854576349258423
31-01-2023 05:45:01 INFO Epoch 4: [7613/10940] ---- BYOL Training Loss = 0.1688593477010727
31-01-2023 05:45:53 INFO Epoch 4: [7613/10940] ---- BYOL Validation Loss = 0.13515996932983398
31-01-2023 05:46:11 INFO Epoch 4: [7624/10940] ---- BYOL Training Loss = 0.1298350691795349
slurmstepd-landonia23: error: *** JOB 1507996 ON landonia23 CANCELLED AT 2023-01-31T05:46:15 DUE TO TIME LIMIT ***
