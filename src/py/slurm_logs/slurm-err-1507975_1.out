29-01-2023 20:58:12 INFO Running main & importing modules...
29-01-2023 20:58:40 INFO Parsed arguments: Namespace(batch_size=32, byol_ema_tau=0.99, debug=False, encoder='resnet18', encoder_layer_idx=-2, epochs=5, experiment_name='b-presnet18-e5-b32-t0_99-p64', input='/disk/scratch_big/s1908368/data', log_interval=1000, lr=0.001, output='/disk/scratch_big/s1908368/output', patch_size=64, pretrain_encoder=True, seed=23, simclr_tau=0.99, train_proportion=0.98, use_byol=True)
29-01-2023 20:58:40 INFO File at /disk/scratch_big/s1908368/data/patch_train_dataset_64.pk: True
29-01-2023 20:58:40 INFO File at /disk/scratch_big/s1908368/data/patch_val_dataset_64.pk: True
29-01-2023 20:58:49 INFO Generated training dataset with 350062 samples.
29-01-2023 20:58:49 INFO Generated validation dataset with 7145 samples.
29-01-2023 20:58:51 INFO Using encoder resnet18 with pretrained weights = True
29-01-2023 20:58:52 INFO Using BYOL with tau = 0.99, with encoder layer index = -2
29-01-2023 20:58:52 INFO Using device: cuda
29-01-2023 20:59:01 INFO Starting Epoch: 1
29-01-2023 20:59:22 INFO Epoch 1: [12/10940] ---- BYOL Training Loss = 2.1622159481048584
29-01-2023 20:59:38 INFO Epoch 1: [23/10940] ---- BYOL Training Loss = 1.8017371892929077
29-01-2023 20:59:56 INFO Epoch 1: [34/10940] ---- BYOL Training Loss = 1.6179826259613037
29-01-2023 21:00:13 INFO Epoch 1: [45/10940] ---- BYOL Training Loss = 1.383236289024353
29-01-2023 21:01:05 INFO Epoch 1: [45/10940] ---- BYOL Validation Loss = 1.4027031660079956
29-01-2023 21:01:22 INFO Epoch 1: [56/10940] ---- BYOL Training Loss = 1.202683925628662
29-01-2023 21:01:39 INFO Epoch 1: [67/10940] ---- BYOL Training Loss = 1.0532902479171753
29-01-2023 21:01:56 INFO Epoch 1: [78/10940] ---- BYOL Training Loss = 0.9375961422920227
29-01-2023 21:02:14 INFO Epoch 1: [89/10940] ---- BYOL Training Loss = 0.9166774749755859
29-01-2023 21:03:06 INFO Epoch 1: [89/10940] ---- BYOL Validation Loss = 1.6682833433151245
29-01-2023 21:03:23 INFO Epoch 1: [100/10940] ---- BYOL Training Loss = 0.8792780637741089
29-01-2023 21:03:41 INFO Epoch 1: [111/10940] ---- BYOL Training Loss = 0.75411057472229
29-01-2023 21:03:58 INFO Epoch 1: [122/10940] ---- BYOL Training Loss = 0.6494532227516174
29-01-2023 21:04:15 INFO Epoch 1: [133/10940] ---- BYOL Training Loss = 0.6325966119766235
29-01-2023 21:05:08 INFO Epoch 1: [133/10940] ---- BYOL Validation Loss = 0.7603768706321716
29-01-2023 21:05:25 INFO Epoch 1: [144/10940] ---- BYOL Training Loss = 0.7057331800460815
29-01-2023 21:05:42 INFO Epoch 1: [155/10940] ---- BYOL Training Loss = 0.6989737153053284
29-01-2023 21:05:59 INFO Epoch 1: [166/10940] ---- BYOL Training Loss = 0.6756565570831299
29-01-2023 21:06:17 INFO Epoch 1: [177/10940] ---- BYOL Training Loss = 0.66929030418396
29-01-2023 21:07:09 INFO Epoch 1: [177/10940] ---- BYOL Validation Loss = 0.6983694434165955
29-01-2023 21:07:26 INFO Epoch 1: [188/10940] ---- BYOL Training Loss = 0.6352996230125427
29-01-2023 21:07:44 INFO Epoch 1: [199/10940] ---- BYOL Training Loss = 0.6503362655639648
29-01-2023 21:08:01 INFO Epoch 1: [210/10940] ---- BYOL Training Loss = 0.6467787027359009
29-01-2023 21:08:19 INFO Epoch 1: [221/10940] ---- BYOL Training Loss = 0.6770820021629333
29-01-2023 21:09:11 INFO Epoch 1: [221/10940] ---- BYOL Validation Loss = 0.6619595885276794
29-01-2023 21:09:28 INFO Epoch 1: [232/10940] ---- BYOL Training Loss = 0.6055987477302551
29-01-2023 21:09:46 INFO Epoch 1: [243/10940] ---- BYOL Training Loss = 0.5098605751991272
29-01-2023 21:10:03 INFO Epoch 1: [254/10940] ---- BYOL Training Loss = 0.5485655069351196
29-01-2023 21:10:21 INFO Epoch 1: [265/10940] ---- BYOL Training Loss = 0.633143961429596
29-01-2023 21:11:13 INFO Epoch 1: [265/10940] ---- BYOL Validation Loss = 0.6189695596694946
29-01-2023 21:11:30 INFO Epoch 1: [276/10940] ---- BYOL Training Loss = 0.6090575456619263
29-01-2023 21:11:48 INFO Epoch 1: [287/10940] ---- BYOL Training Loss = 0.5414643287658691
29-01-2023 21:12:05 INFO Epoch 1: [298/10940] ---- BYOL Training Loss = 0.5413668751716614
29-01-2023 21:12:22 INFO Epoch 1: [309/10940] ---- BYOL Training Loss = 0.5850580334663391
29-01-2023 21:13:15 INFO Epoch 1: [309/10940] ---- BYOL Validation Loss = 0.6134815812110901
29-01-2023 21:13:32 INFO Epoch 1: [320/10940] ---- BYOL Training Loss = 0.5463243126869202
29-01-2023 21:13:49 INFO Epoch 1: [331/10940] ---- BYOL Training Loss = 0.5585882067680359
29-01-2023 21:14:07 INFO Epoch 1: [342/10940] ---- BYOL Training Loss = 0.546126663684845
29-01-2023 21:14:24 INFO Epoch 1: [353/10940] ---- BYOL Training Loss = 0.5077947378158569
29-01-2023 21:15:17 INFO Epoch 1: [353/10940] ---- BYOL Validation Loss = 0.564350426197052
29-01-2023 21:15:34 INFO Epoch 1: [364/10940] ---- BYOL Training Loss = 0.4647561013698578
29-01-2023 21:15:52 INFO Epoch 1: [375/10940] ---- BYOL Training Loss = 0.5096338987350464
29-01-2023 21:16:10 INFO Epoch 1: [386/10940] ---- BYOL Training Loss = 0.44972801208496094
29-01-2023 21:16:27 INFO Epoch 1: [397/10940] ---- BYOL Training Loss = 0.4140767455101013
29-01-2023 21:17:20 INFO Epoch 1: [397/10940] ---- BYOL Validation Loss = 0.5377145409584045
29-01-2023 21:17:37 INFO Epoch 1: [408/10940] ---- BYOL Training Loss = 0.457909494638443
29-01-2023 21:17:54 INFO Epoch 1: [419/10940] ---- BYOL Training Loss = 0.528891921043396
29-01-2023 21:18:12 INFO Epoch 1: [430/10940] ---- BYOL Training Loss = 0.5309231877326965
29-01-2023 21:18:29 INFO Epoch 1: [441/10940] ---- BYOL Training Loss = 0.4971291422843933
29-01-2023 21:19:23 INFO Epoch 1: [441/10940] ---- BYOL Validation Loss = 0.506973385810852
29-01-2023 21:19:40 INFO Epoch 1: [452/10940] ---- BYOL Training Loss = 0.4643293023109436
29-01-2023 21:19:57 INFO Epoch 1: [463/10940] ---- BYOL Training Loss = 0.5187991857528687
29-01-2023 21:20:15 INFO Epoch 1: [474/10940] ---- BYOL Training Loss = 0.5053199529647827
29-01-2023 21:20:32 INFO Epoch 1: [485/10940] ---- BYOL Training Loss = 0.5894811749458313
29-01-2023 21:21:25 INFO Epoch 1: [485/10940] ---- BYOL Validation Loss = 0.5011903643608093
29-01-2023 21:21:42 INFO Epoch 1: [496/10940] ---- BYOL Training Loss = 0.5961407423019409
29-01-2023 21:21:59 INFO Epoch 1: [507/10940] ---- BYOL Training Loss = 0.5323659181594849
29-01-2023 21:22:17 INFO Epoch 1: [518/10940] ---- BYOL Training Loss = 0.505055844783783
29-01-2023 21:22:34 INFO Epoch 1: [529/10940] ---- BYOL Training Loss = 0.4964117109775543
29-01-2023 21:23:27 INFO Epoch 1: [529/10940] ---- BYOL Validation Loss = 0.47590890526771545
29-01-2023 21:23:44 INFO Epoch 1: [540/10940] ---- BYOL Training Loss = 0.46981969475746155
29-01-2023 21:24:02 INFO Epoch 1: [551/10940] ---- BYOL Training Loss = 0.47427868843078613
29-01-2023 21:24:19 INFO Epoch 1: [562/10940] ---- BYOL Training Loss = 0.5074706077575684
29-01-2023 21:24:37 INFO Epoch 1: [573/10940] ---- BYOL Training Loss = 0.5234531164169312
29-01-2023 21:25:30 INFO Epoch 1: [573/10940] ---- BYOL Validation Loss = 0.48800256848335266
29-01-2023 21:25:47 INFO Epoch 1: [584/10940] ---- BYOL Training Loss = 0.5714394450187683
29-01-2023 21:26:04 INFO Epoch 1: [595/10940] ---- BYOL Training Loss = 0.556515097618103
29-01-2023 21:26:22 INFO Epoch 1: [606/10940] ---- BYOL Training Loss = 0.519230306148529
29-01-2023 21:26:39 INFO Epoch 1: [617/10940] ---- BYOL Training Loss = 0.49404820799827576
29-01-2023 21:27:32 INFO Epoch 1: [617/10940] ---- BYOL Validation Loss = 0.4696848392486572
29-01-2023 21:27:49 INFO Epoch 1: [628/10940] ---- BYOL Training Loss = 0.49059611558914185
29-01-2023 21:28:07 INFO Epoch 1: [639/10940] ---- BYOL Training Loss = 0.4725016951560974
29-01-2023 21:28:24 INFO Epoch 1: [650/10940] ---- BYOL Training Loss = 0.48422113060951233
29-01-2023 21:28:42 INFO Epoch 1: [661/10940] ---- BYOL Training Loss = 0.4367792010307312
29-01-2023 21:29:34 INFO Epoch 1: [661/10940] ---- BYOL Validation Loss = 0.473195880651474
29-01-2023 21:29:51 INFO Epoch 1: [672/10940] ---- BYOL Training Loss = 0.40027984976768494
29-01-2023 21:30:09 INFO Epoch 1: [683/10940] ---- BYOL Training Loss = 0.4335399568080902
29-01-2023 21:30:26 INFO Epoch 1: [694/10940] ---- BYOL Training Loss = 0.506673276424408
29-01-2023 21:30:44 INFO Epoch 1: [705/10940] ---- BYOL Training Loss = 0.4047352373600006
29-01-2023 21:31:37 INFO Epoch 1: [705/10940] ---- BYOL Validation Loss = 0.44021204113960266
29-01-2023 21:31:54 INFO Epoch 1: [716/10940] ---- BYOL Training Loss = 0.4180881977081299
29-01-2023 21:32:11 INFO Epoch 1: [727/10940] ---- BYOL Training Loss = 0.43615108728408813
29-01-2023 21:32:29 INFO Epoch 1: [738/10940] ---- BYOL Training Loss = 0.4688781797885895
29-01-2023 21:32:46 INFO Epoch 1: [749/10940] ---- BYOL Training Loss = 0.46446457505226135
29-01-2023 21:33:39 INFO Epoch 1: [749/10940] ---- BYOL Validation Loss = 0.453768789768219
29-01-2023 21:33:56 INFO Epoch 1: [760/10940] ---- BYOL Training Loss = 0.47963231801986694
29-01-2023 21:34:14 INFO Epoch 1: [771/10940] ---- BYOL Training Loss = 0.46673765778541565
29-01-2023 21:34:31 INFO Epoch 1: [782/10940] ---- BYOL Training Loss = 0.44152870774269104
29-01-2023 21:34:49 INFO Epoch 1: [793/10940] ---- BYOL Training Loss = 0.4440762400627136
29-01-2023 21:35:41 INFO Epoch 1: [793/10940] ---- BYOL Validation Loss = 0.43270477652549744
29-01-2023 21:35:58 INFO Epoch 1: [804/10940] ---- BYOL Training Loss = 0.37401145696640015
29-01-2023 21:36:16 INFO Epoch 1: [815/10940] ---- BYOL Training Loss = 0.3809245526790619
29-01-2023 21:36:33 INFO Epoch 1: [826/10940] ---- BYOL Training Loss = 0.45408162474632263
29-01-2023 21:36:51 INFO Epoch 1: [837/10940] ---- BYOL Training Loss = 0.47918301820755005
29-01-2023 21:37:44 INFO Epoch 1: [837/10940] ---- BYOL Validation Loss = 0.43819889426231384
29-01-2023 21:38:01 INFO Epoch 1: [848/10940] ---- BYOL Training Loss = 0.43760228157043457
29-01-2023 21:38:18 INFO Epoch 1: [859/10940] ---- BYOL Training Loss = 0.4451591372489929
29-01-2023 21:38:36 INFO Epoch 1: [870/10940] ---- BYOL Training Loss = 0.4702540934085846
29-01-2023 21:38:53 INFO Epoch 1: [881/10940] ---- BYOL Training Loss = 0.4564420282840729
29-01-2023 21:39:46 INFO Epoch 1: [881/10940] ---- BYOL Validation Loss = 0.43202170729637146
29-01-2023 21:40:04 INFO Epoch 1: [892/10940] ---- BYOL Training Loss = 0.4381040036678314
29-01-2023 21:40:22 INFO Epoch 1: [903/10940] ---- BYOL Training Loss = 0.4640159010887146
29-01-2023 21:40:39 INFO Epoch 1: [914/10940] ---- BYOL Training Loss = 0.3995681703090668
29-01-2023 21:40:57 INFO Epoch 1: [925/10940] ---- BYOL Training Loss = 0.42559975385665894
29-01-2023 21:41:50 INFO Epoch 1: [925/10940] ---- BYOL Validation Loss = 0.4155921936035156
29-01-2023 21:42:07 INFO Epoch 1: [936/10940] ---- BYOL Training Loss = 0.4973224103450775
29-01-2023 21:42:24 INFO Epoch 1: [947/10940] ---- BYOL Training Loss = 0.45031070709228516
29-01-2023 21:42:42 INFO Epoch 1: [958/10940] ---- BYOL Training Loss = 0.35180503129959106
29-01-2023 21:42:59 INFO Epoch 1: [969/10940] ---- BYOL Training Loss = 0.41066741943359375
29-01-2023 21:43:52 INFO Epoch 1: [969/10940] ---- BYOL Validation Loss = 0.4267968237400055
29-01-2023 21:44:09 INFO Epoch 1: [980/10940] ---- BYOL Training Loss = 0.4562414586544037
29-01-2023 21:44:27 INFO Epoch 1: [991/10940] ---- BYOL Training Loss = 0.4548083245754242
29-01-2023 21:44:44 INFO Epoch 1: [1002/10940] ---- BYOL Training Loss = 0.5031566619873047
29-01-2023 21:45:02 INFO Epoch 1: [1013/10940] ---- BYOL Training Loss = 0.4282846450805664
29-01-2023 21:45:55 INFO Epoch 1: [1013/10940] ---- BYOL Validation Loss = 0.41188472509384155
29-01-2023 21:46:12 INFO Epoch 1: [1024/10940] ---- BYOL Training Loss = 0.43266749382019043
29-01-2023 21:46:29 INFO Epoch 1: [1035/10940] ---- BYOL Training Loss = 0.40198343992233276
29-01-2023 21:46:47 INFO Epoch 1: [1046/10940] ---- BYOL Training Loss = 0.4202226996421814
29-01-2023 21:47:04 INFO Epoch 1: [1057/10940] ---- BYOL Training Loss = 0.4426119923591614
29-01-2023 21:47:57 INFO Epoch 1: [1057/10940] ---- BYOL Validation Loss = 0.40332311391830444
29-01-2023 21:48:14 INFO Epoch 1: [1068/10940] ---- BYOL Training Loss = 0.38046011328697205
29-01-2023 21:48:32 INFO Epoch 1: [1079/10940] ---- BYOL Training Loss = 0.3222358822822571
29-01-2023 21:48:49 INFO Epoch 1: [1090/10940] ---- BYOL Training Loss = 0.3726027309894562
29-01-2023 21:49:07 INFO Epoch 1: [1101/10940] ---- BYOL Training Loss = 0.4392886757850647
29-01-2023 21:50:00 INFO Epoch 1: [1101/10940] ---- BYOL Validation Loss = 0.41661953926086426
29-01-2023 21:50:17 INFO Epoch 1: [1112/10940] ---- BYOL Training Loss = 0.45183640718460083
29-01-2023 21:50:34 INFO Epoch 1: [1123/10940] ---- BYOL Training Loss = 0.36797410249710083
29-01-2023 21:50:52 INFO Epoch 1: [1134/10940] ---- BYOL Training Loss = 0.4164687693119049
29-01-2023 21:51:09 INFO Epoch 1: [1145/10940] ---- BYOL Training Loss = 0.42082056403160095
29-01-2023 21:52:02 INFO Epoch 1: [1145/10940] ---- BYOL Validation Loss = 0.4252263605594635
29-01-2023 21:52:19 INFO Epoch 1: [1156/10940] ---- BYOL Training Loss = 0.34904155135154724
29-01-2023 21:52:37 INFO Epoch 1: [1167/10940] ---- BYOL Training Loss = 0.41219282150268555
29-01-2023 21:52:54 INFO Epoch 1: [1178/10940] ---- BYOL Training Loss = 0.4260708689689636
29-01-2023 21:53:12 INFO Epoch 1: [1189/10940] ---- BYOL Training Loss = 0.4185766279697418
29-01-2023 21:54:05 INFO Epoch 1: [1189/10940] ---- BYOL Validation Loss = 0.4088467061519623
29-01-2023 21:54:22 INFO Epoch 1: [1200/10940] ---- BYOL Training Loss = 0.3774072527885437
29-01-2023 21:54:40 INFO Epoch 1: [1211/10940] ---- BYOL Training Loss = 0.45082369446754456
29-01-2023 21:54:57 INFO Epoch 1: [1222/10940] ---- BYOL Training Loss = 0.4571850299835205
29-01-2023 21:55:15 INFO Epoch 1: [1233/10940] ---- BYOL Training Loss = 0.42673802375793457
29-01-2023 21:56:08 INFO Epoch 1: [1233/10940] ---- BYOL Validation Loss = 0.4110832214355469
29-01-2023 21:56:25 INFO Epoch 1: [1244/10940] ---- BYOL Training Loss = 0.4314262270927429
29-01-2023 21:56:42 INFO Epoch 1: [1255/10940] ---- BYOL Training Loss = 0.4139941334724426
29-01-2023 21:57:00 INFO Epoch 1: [1266/10940] ---- BYOL Training Loss = 0.3923730254173279
29-01-2023 21:57:17 INFO Epoch 1: [1277/10940] ---- BYOL Training Loss = 0.3686264455318451
29-01-2023 21:58:10 INFO Epoch 1: [1277/10940] ---- BYOL Validation Loss = 0.3961941599845886
29-01-2023 21:58:27 INFO Epoch 1: [1288/10940] ---- BYOL Training Loss = 0.3803999722003937
29-01-2023 21:58:45 INFO Epoch 1: [1299/10940] ---- BYOL Training Loss = 0.4489896893501282
29-01-2023 21:59:02 INFO Epoch 1: [1310/10940] ---- BYOL Training Loss = 0.45169442892074585
29-01-2023 21:59:20 INFO Epoch 1: [1321/10940] ---- BYOL Training Loss = 0.364409863948822
29-01-2023 22:00:13 INFO Epoch 1: [1321/10940] ---- BYOL Validation Loss = 0.3926498591899872
29-01-2023 22:00:30 INFO Epoch 1: [1332/10940] ---- BYOL Training Loss = 0.3348327875137329
29-01-2023 22:00:48 INFO Epoch 1: [1343/10940] ---- BYOL Training Loss = 0.36548447608947754
29-01-2023 22:01:05 INFO Epoch 1: [1354/10940] ---- BYOL Training Loss = 0.3887149691581726
29-01-2023 22:01:23 INFO Epoch 1: [1365/10940] ---- BYOL Training Loss = 0.41934043169021606
29-01-2023 22:02:15 INFO Epoch 1: [1365/10940] ---- BYOL Validation Loss = 0.40322738885879517
29-01-2023 22:02:33 INFO Epoch 1: [1376/10940] ---- BYOL Training Loss = 0.46050864458084106
29-01-2023 22:02:50 INFO Epoch 1: [1387/10940] ---- BYOL Training Loss = 0.4707659184932709
29-01-2023 22:03:08 INFO Epoch 1: [1398/10940] ---- BYOL Training Loss = 0.4169568121433258
29-01-2023 22:03:25 INFO Epoch 1: [1409/10940] ---- BYOL Training Loss = 0.44419795274734497
29-01-2023 22:04:19 INFO Epoch 1: [1409/10940] ---- BYOL Validation Loss = 0.39580005407333374
29-01-2023 22:04:36 INFO Epoch 1: [1420/10940] ---- BYOL Training Loss = 0.4651409983634949
29-01-2023 22:04:53 INFO Epoch 1: [1431/10940] ---- BYOL Training Loss = 0.41676145792007446
29-01-2023 22:05:11 INFO Epoch 1: [1442/10940] ---- BYOL Training Loss = 0.3991895318031311
29-01-2023 22:05:28 INFO Epoch 1: [1453/10940] ---- BYOL Training Loss = 0.4367756247520447
29-01-2023 22:06:21 INFO Epoch 1: [1453/10940] ---- BYOL Validation Loss = 0.39794400334358215
29-01-2023 22:06:39 INFO Epoch 1: [1464/10940] ---- BYOL Training Loss = 0.3540504574775696
29-01-2023 22:06:56 INFO Epoch 1: [1475/10940] ---- BYOL Training Loss = 0.4037722945213318
29-01-2023 22:07:14 INFO Epoch 1: [1486/10940] ---- BYOL Training Loss = 0.43244999647140503
29-01-2023 22:07:32 INFO Epoch 1: [1497/10940] ---- BYOL Training Loss = 0.41707292199134827
29-01-2023 22:08:24 INFO Epoch 1: [1497/10940] ---- BYOL Validation Loss = 0.38533568382263184
29-01-2023 22:08:41 INFO Epoch 1: [1508/10940] ---- BYOL Training Loss = 0.3964373767375946
29-01-2023 22:08:59 INFO Epoch 1: [1519/10940] ---- BYOL Training Loss = 0.34549012780189514
29-01-2023 22:09:17 INFO Epoch 1: [1530/10940] ---- BYOL Training Loss = 0.35403698682785034
29-01-2023 22:09:34 INFO Epoch 1: [1541/10940] ---- BYOL Training Loss = 0.43867072463035583
29-01-2023 22:10:28 INFO Epoch 1: [1541/10940] ---- BYOL Validation Loss = 0.39327335357666016
29-01-2023 22:10:45 INFO Epoch 1: [1552/10940] ---- BYOL Training Loss = 0.39579394459724426
29-01-2023 22:11:02 INFO Epoch 1: [1563/10940] ---- BYOL Training Loss = 0.3562449812889099
29-01-2023 22:11:20 INFO Epoch 1: [1574/10940] ---- BYOL Training Loss = 0.3348087966442108
29-01-2023 22:11:37 INFO Epoch 1: [1585/10940] ---- BYOL Training Loss = 0.3968579173088074
29-01-2023 22:12:30 INFO Epoch 1: [1585/10940] ---- BYOL Validation Loss = 0.38607046008110046
29-01-2023 22:12:47 INFO Epoch 1: [1596/10940] ---- BYOL Training Loss = 0.3728788495063782
29-01-2023 22:13:05 INFO Epoch 1: [1607/10940] ---- BYOL Training Loss = 0.3533089756965637
29-01-2023 22:13:23 INFO Epoch 1: [1618/10940] ---- BYOL Training Loss = 0.3348504900932312
29-01-2023 22:13:40 INFO Epoch 1: [1629/10940] ---- BYOL Training Loss = 0.3320847153663635
29-01-2023 22:14:33 INFO Epoch 1: [1629/10940] ---- BYOL Validation Loss = 0.3661985993385315
29-01-2023 22:14:50 INFO Epoch 1: [1640/10940] ---- BYOL Training Loss = 0.344690203666687
29-01-2023 22:15:08 INFO Epoch 1: [1651/10940] ---- BYOL Training Loss = 0.3541231155395508
29-01-2023 22:15:25 INFO Epoch 1: [1662/10940] ---- BYOL Training Loss = 0.38011202216148376
29-01-2023 22:15:43 INFO Epoch 1: [1673/10940] ---- BYOL Training Loss = 0.3918071389198303
29-01-2023 22:16:36 INFO Epoch 1: [1673/10940] ---- BYOL Validation Loss = 0.39274460077285767
29-01-2023 22:16:53 INFO Epoch 1: [1684/10940] ---- BYOL Training Loss = 0.34222081303596497
29-01-2023 22:17:11 INFO Epoch 1: [1695/10940] ---- BYOL Training Loss = 0.35354700684547424
29-01-2023 22:17:28 INFO Epoch 1: [1706/10940] ---- BYOL Training Loss = 0.4095078408718109
29-01-2023 22:17:46 INFO Epoch 1: [1717/10940] ---- BYOL Training Loss = 0.41530004143714905
29-01-2023 22:18:39 INFO Epoch 1: [1717/10940] ---- BYOL Validation Loss = 0.3876191973686218
29-01-2023 22:18:56 INFO Epoch 1: [1728/10940] ---- BYOL Training Loss = 0.3943469822406769
29-01-2023 22:19:14 INFO Epoch 1: [1739/10940] ---- BYOL Training Loss = 0.34974002838134766
29-01-2023 22:19:32 INFO Epoch 1: [1750/10940] ---- BYOL Training Loss = 0.3762079179286957
29-01-2023 22:19:49 INFO Epoch 1: [1761/10940] ---- BYOL Training Loss = 0.3419109880924225
29-01-2023 22:20:42 INFO Epoch 1: [1761/10940] ---- BYOL Validation Loss = 0.3811569809913635
29-01-2023 22:20:59 INFO Epoch 1: [1772/10940] ---- BYOL Training Loss = 0.3779568672180176
29-01-2023 22:21:17 INFO Epoch 1: [1783/10940] ---- BYOL Training Loss = 0.40489426255226135
29-01-2023 22:21:34 INFO Epoch 1: [1794/10940] ---- BYOL Training Loss = 0.3861158490180969
29-01-2023 22:21:52 INFO Epoch 1: [1805/10940] ---- BYOL Training Loss = 0.39102762937545776
29-01-2023 22:22:45 INFO Epoch 1: [1805/10940] ---- BYOL Validation Loss = 0.3803265690803528
29-01-2023 22:23:02 INFO Epoch 1: [1816/10940] ---- BYOL Training Loss = 0.432542622089386
29-01-2023 22:23:19 INFO Epoch 1: [1827/10940] ---- BYOL Training Loss = 0.422482430934906
29-01-2023 22:23:37 INFO Epoch 1: [1838/10940] ---- BYOL Training Loss = 0.3656350374221802
29-01-2023 22:23:55 INFO Epoch 1: [1849/10940] ---- BYOL Training Loss = 0.34207165241241455
29-01-2023 22:24:47 INFO Epoch 1: [1849/10940] ---- BYOL Validation Loss = 0.37043556571006775
29-01-2023 22:25:04 INFO Epoch 1: [1860/10940] ---- BYOL Training Loss = 0.3590599596500397
29-01-2023 22:25:22 INFO Epoch 1: [1871/10940] ---- BYOL Training Loss = 0.36103540658950806
29-01-2023 22:25:40 INFO Epoch 1: [1882/10940] ---- BYOL Training Loss = 0.35091477632522583
29-01-2023 22:25:57 INFO Epoch 1: [1893/10940] ---- BYOL Training Loss = 0.3628578782081604
29-01-2023 22:26:50 INFO Epoch 1: [1893/10940] ---- BYOL Validation Loss = 0.37605366110801697
29-01-2023 22:27:07 INFO Epoch 1: [1904/10940] ---- BYOL Training Loss = 0.39293763041496277
29-01-2023 22:27:25 INFO Epoch 1: [1915/10940] ---- BYOL Training Loss = 0.36821943521499634
29-01-2023 22:27:43 INFO Epoch 1: [1926/10940] ---- BYOL Training Loss = 0.36789822578430176
29-01-2023 22:28:00 INFO Epoch 1: [1937/10940] ---- BYOL Training Loss = 0.3854884207248688
29-01-2023 22:28:53 INFO Epoch 1: [1937/10940] ---- BYOL Validation Loss = 0.36613231897354126
29-01-2023 22:29:10 INFO Epoch 1: [1948/10940] ---- BYOL Training Loss = 0.379471093416214
29-01-2023 22:29:28 INFO Epoch 1: [1959/10940] ---- BYOL Training Loss = 0.34544187784194946
29-01-2023 22:29:46 INFO Epoch 1: [1970/10940] ---- BYOL Training Loss = 0.35006028413772583
29-01-2023 22:30:03 INFO Epoch 1: [1981/10940] ---- BYOL Training Loss = 0.35439881682395935
29-01-2023 22:30:56 INFO Epoch 1: [1981/10940] ---- BYOL Validation Loss = 0.36977583169937134
29-01-2023 22:31:13 INFO Epoch 1: [1992/10940] ---- BYOL Training Loss = 0.34303736686706543
29-01-2023 22:31:31 INFO Epoch 1: [2003/10940] ---- BYOL Training Loss = 0.3097821772098541
29-01-2023 22:31:48 INFO Epoch 1: [2014/10940] ---- BYOL Training Loss = 0.3184192180633545
29-01-2023 22:32:06 INFO Epoch 1: [2025/10940] ---- BYOL Training Loss = 0.3424164056777954
29-01-2023 22:32:59 INFO Epoch 1: [2025/10940] ---- BYOL Validation Loss = 0.3644963800907135
29-01-2023 22:33:16 INFO Epoch 1: [2036/10940] ---- BYOL Training Loss = 0.37721458077430725
29-01-2023 22:33:34 INFO Epoch 1: [2047/10940] ---- BYOL Training Loss = 0.33853039145469666
29-01-2023 22:33:51 INFO Epoch 1: [2058/10940] ---- BYOL Training Loss = 0.38713377714157104
29-01-2023 22:34:09 INFO Epoch 1: [2069/10940] ---- BYOL Training Loss = 0.3922063708305359
29-01-2023 22:35:02 INFO Epoch 1: [2069/10940] ---- BYOL Validation Loss = 0.37396368384361267
29-01-2023 22:35:19 INFO Epoch 1: [2080/10940] ---- BYOL Training Loss = 0.367564857006073
29-01-2023 22:35:37 INFO Epoch 1: [2091/10940] ---- BYOL Training Loss = 0.37217089533805847
29-01-2023 22:35:55 INFO Epoch 1: [2102/10940] ---- BYOL Training Loss = 0.33865272998809814
29-01-2023 22:36:12 INFO Epoch 1: [2113/10940] ---- BYOL Training Loss = 0.35136279463768005
29-01-2023 22:37:05 INFO Epoch 1: [2113/10940] ---- BYOL Validation Loss = 0.3645499348640442
29-01-2023 22:37:23 INFO Epoch 1: [2124/10940] ---- BYOL Training Loss = 0.4073900580406189
29-01-2023 22:37:40 INFO Epoch 1: [2135/10940] ---- BYOL Training Loss = 0.3506069779396057
29-01-2023 22:37:58 INFO Epoch 1: [2146/10940] ---- BYOL Training Loss = 0.3074088394641876
29-01-2023 22:38:15 INFO Epoch 1: [2157/10940] ---- BYOL Training Loss = 0.3381546139717102
29-01-2023 22:39:08 INFO Epoch 1: [2157/10940] ---- BYOL Validation Loss = 0.3548632264137268
29-01-2023 22:39:25 INFO Epoch 1: [2168/10940] ---- BYOL Training Loss = 0.36930909752845764
29-01-2023 22:39:43 INFO Epoch 1: [2179/10940] ---- BYOL Training Loss = 0.4152943193912506
29-01-2023 22:40:01 INFO Epoch 1: [2190/10940] ---- BYOL Training Loss = 0.3627564311027527
29-01-2023 22:40:18 INFO Epoch 1: [2201/10940] ---- BYOL Training Loss = 0.3394237160682678
29-01-2023 22:41:11 INFO Epoch 1: [2201/10940] ---- BYOL Validation Loss = 0.3857876658439636
29-01-2023 22:41:28 INFO Epoch 1: [2212/10940] ---- BYOL Training Loss = 0.34215080738067627
29-01-2023 22:41:46 INFO Epoch 1: [2223/10940] ---- BYOL Training Loss = 0.38253054022789
29-01-2023 22:42:04 INFO Epoch 1: [2234/10940] ---- BYOL Training Loss = 0.35757017135620117
29-01-2023 22:42:21 INFO Epoch 1: [2245/10940] ---- BYOL Training Loss = 0.3484126031398773
29-01-2023 22:43:14 INFO Epoch 1: [2245/10940] ---- BYOL Validation Loss = 0.35703662037849426
29-01-2023 22:43:32 INFO Epoch 1: [2256/10940] ---- BYOL Training Loss = 0.38488656282424927
29-01-2023 22:43:49 INFO Epoch 1: [2267/10940] ---- BYOL Training Loss = 0.3058978319168091
29-01-2023 22:44:07 INFO Epoch 1: [2278/10940] ---- BYOL Training Loss = 0.3012424409389496
29-01-2023 22:44:24 INFO Epoch 1: [2289/10940] ---- BYOL Training Loss = 0.3514396548271179
29-01-2023 22:45:17 INFO Epoch 1: [2289/10940] ---- BYOL Validation Loss = 0.3665159344673157
29-01-2023 22:45:35 INFO Epoch 1: [2300/10940] ---- BYOL Training Loss = 0.38652387261390686
29-01-2023 22:45:52 INFO Epoch 1: [2311/10940] ---- BYOL Training Loss = 0.33134981989860535
29-01-2023 22:46:10 INFO Epoch 1: [2322/10940] ---- BYOL Training Loss = 0.31806015968322754
29-01-2023 22:46:28 INFO Epoch 1: [2333/10940] ---- BYOL Training Loss = 0.3714611828327179
29-01-2023 22:47:21 INFO Epoch 1: [2333/10940] ---- BYOL Validation Loss = 0.35832875967025757
29-01-2023 22:47:38 INFO Epoch 1: [2344/10940] ---- BYOL Training Loss = 0.3657880127429962
29-01-2023 22:47:56 INFO Epoch 1: [2355/10940] ---- BYOL Training Loss = 0.343946248292923
29-01-2023 22:48:13 INFO Epoch 1: [2366/10940] ---- BYOL Training Loss = 0.3472839891910553
29-01-2023 22:48:31 INFO Epoch 1: [2377/10940] ---- BYOL Training Loss = 0.3174859881401062
29-01-2023 22:49:24 INFO Epoch 1: [2377/10940] ---- BYOL Validation Loss = 0.3561786115169525
29-01-2023 22:49:41 INFO Epoch 1: [2388/10940] ---- BYOL Training Loss = 0.3072253167629242
29-01-2023 22:49:59 INFO Epoch 1: [2399/10940] ---- BYOL Training Loss = 0.36084800958633423
29-01-2023 22:50:16 INFO Epoch 1: [2410/10940] ---- BYOL Training Loss = 0.3539411127567291
29-01-2023 22:50:34 INFO Epoch 1: [2421/10940] ---- BYOL Training Loss = 0.37389546632766724
29-01-2023 22:51:26 INFO Epoch 1: [2421/10940] ---- BYOL Validation Loss = 0.34825754165649414
29-01-2023 22:51:44 INFO Epoch 1: [2432/10940] ---- BYOL Training Loss = 0.32925304770469666
29-01-2023 22:52:01 INFO Epoch 1: [2443/10940] ---- BYOL Training Loss = 0.335848867893219
29-01-2023 22:52:19 INFO Epoch 1: [2454/10940] ---- BYOL Training Loss = 0.2969942092895508
29-01-2023 22:52:37 INFO Epoch 1: [2465/10940] ---- BYOL Training Loss = 0.2639128565788269
29-01-2023 22:53:30 INFO Epoch 1: [2465/10940] ---- BYOL Validation Loss = 0.3441210091114044
29-01-2023 22:53:47 INFO Epoch 1: [2476/10940] ---- BYOL Training Loss = 0.33306828141212463
29-01-2023 22:54:05 INFO Epoch 1: [2487/10940] ---- BYOL Training Loss = 0.3783875107765198
29-01-2023 22:54:22 INFO Epoch 1: [2498/10940] ---- BYOL Training Loss = 0.3451313376426697
29-01-2023 22:54:40 INFO Epoch 1: [2509/10940] ---- BYOL Training Loss = 0.3093198239803314
29-01-2023 22:55:33 INFO Epoch 1: [2509/10940] ---- BYOL Validation Loss = 0.3382870852947235
29-01-2023 22:55:50 INFO Epoch 1: [2520/10940] ---- BYOL Training Loss = 0.28410428762435913
29-01-2023 22:56:08 INFO Epoch 1: [2531/10940] ---- BYOL Training Loss = 0.35217469930648804
29-01-2023 22:56:25 INFO Epoch 1: [2542/10940] ---- BYOL Training Loss = 0.3725576400756836
29-01-2023 22:56:43 INFO Epoch 1: [2553/10940] ---- BYOL Training Loss = 0.33558031916618347
29-01-2023 22:57:36 INFO Epoch 1: [2553/10940] ---- BYOL Validation Loss = 0.3495548665523529
29-01-2023 22:57:54 INFO Epoch 1: [2564/10940] ---- BYOL Training Loss = 0.3781200051307678
29-01-2023 22:58:11 INFO Epoch 1: [2575/10940] ---- BYOL Training Loss = 0.3760279715061188
29-01-2023 22:58:29 INFO Epoch 1: [2586/10940] ---- BYOL Training Loss = 0.36548322439193726
29-01-2023 22:58:47 INFO Epoch 1: [2597/10940] ---- BYOL Training Loss = 0.3459636867046356
29-01-2023 22:59:40 INFO Epoch 1: [2597/10940] ---- BYOL Validation Loss = 0.34762439131736755
29-01-2023 22:59:57 INFO Epoch 1: [2608/10940] ---- BYOL Training Loss = 0.3216312527656555
29-01-2023 23:00:15 INFO Epoch 1: [2619/10940] ---- BYOL Training Loss = 0.31798607110977173
29-01-2023 23:00:32 INFO Epoch 1: [2630/10940] ---- BYOL Training Loss = 0.3349533677101135
29-01-2023 23:00:50 INFO Epoch 1: [2641/10940] ---- BYOL Training Loss = 0.3187558054924011
29-01-2023 23:01:43 INFO Epoch 1: [2641/10940] ---- BYOL Validation Loss = 0.3445259928703308
29-01-2023 23:02:00 INFO Epoch 1: [2652/10940] ---- BYOL Training Loss = 0.332949697971344
29-01-2023 23:02:18 INFO Epoch 1: [2663/10940] ---- BYOL Training Loss = 0.3813561201095581
29-01-2023 23:02:36 INFO Epoch 1: [2674/10940] ---- BYOL Training Loss = 0.40344029664993286
29-01-2023 23:02:53 INFO Epoch 1: [2685/10940] ---- BYOL Training Loss = 0.36141467094421387
29-01-2023 23:03:46 INFO Epoch 1: [2685/10940] ---- BYOL Validation Loss = 0.3506625294685364
29-01-2023 23:04:03 INFO Epoch 1: [2696/10940] ---- BYOL Training Loss = 0.3528320789337158
29-01-2023 23:04:21 INFO Epoch 1: [2707/10940] ---- BYOL Training Loss = 0.39151209592819214
29-01-2023 23:04:39 INFO Epoch 1: [2718/10940] ---- BYOL Training Loss = 0.3735606372356415
29-01-2023 23:04:56 INFO Epoch 1: [2729/10940] ---- BYOL Training Loss = 0.3611353933811188
29-01-2023 23:05:49 INFO Epoch 1: [2729/10940] ---- BYOL Validation Loss = 0.3516024053096771
29-01-2023 23:06:06 INFO Epoch 1: [2740/10940] ---- BYOL Training Loss = 0.3311108350753784
29-01-2023 23:06:24 INFO Epoch 1: [2751/10940] ---- BYOL Training Loss = 0.3354984521865845
29-01-2023 23:06:42 INFO Epoch 1: [2762/10940] ---- BYOL Training Loss = 0.39225131273269653
29-01-2023 23:07:00 INFO Epoch 1: [2773/10940] ---- BYOL Training Loss = 0.3815843462944031
29-01-2023 23:07:53 INFO Epoch 1: [2773/10940] ---- BYOL Validation Loss = 0.35115018486976624
29-01-2023 23:08:10 INFO Epoch 1: [2784/10940] ---- BYOL Training Loss = 0.33890292048454285
29-01-2023 23:08:27 INFO Epoch 1: [2795/10940] ---- BYOL Training Loss = 0.3047221004962921
29-01-2023 23:08:45 INFO Epoch 1: [2806/10940] ---- BYOL Training Loss = 0.3314080834388733
29-01-2023 23:09:03 INFO Epoch 1: [2817/10940] ---- BYOL Training Loss = 0.3196367919445038
29-01-2023 23:09:56 INFO Epoch 1: [2817/10940] ---- BYOL Validation Loss = 0.3597237169742584
29-01-2023 23:10:13 INFO Epoch 1: [2828/10940] ---- BYOL Training Loss = 0.3272554576396942
29-01-2023 23:10:31 INFO Epoch 1: [2839/10940] ---- BYOL Training Loss = 0.3425089418888092
29-01-2023 23:10:49 INFO Epoch 1: [2850/10940] ---- BYOL Training Loss = 0.3947122097015381
29-01-2023 23:11:07 INFO Epoch 1: [2861/10940] ---- BYOL Training Loss = 0.41716867685317993
29-01-2023 23:12:00 INFO Epoch 1: [2861/10940] ---- BYOL Validation Loss = 0.35788577795028687
29-01-2023 23:12:17 INFO Epoch 1: [2872/10940] ---- BYOL Training Loss = 0.4018213152885437
29-01-2023 23:12:35 INFO Epoch 1: [2883/10940] ---- BYOL Training Loss = 0.37635180354118347
29-01-2023 23:12:52 INFO Epoch 1: [2894/10940] ---- BYOL Training Loss = 0.33850806951522827
29-01-2023 23:13:10 INFO Epoch 1: [2905/10940] ---- BYOL Training Loss = 0.3656935691833496
29-01-2023 23:14:03 INFO Epoch 1: [2905/10940] ---- BYOL Validation Loss = 0.3462912142276764
29-01-2023 23:14:20 INFO Epoch 1: [2916/10940] ---- BYOL Training Loss = 0.37559157609939575
29-01-2023 23:14:37 INFO Epoch 1: [2927/10940] ---- BYOL Training Loss = 0.3548106551170349
29-01-2023 23:14:55 INFO Epoch 1: [2938/10940] ---- BYOL Training Loss = 0.3281329870223999
29-01-2023 23:15:13 INFO Epoch 1: [2949/10940] ---- BYOL Training Loss = 0.3768388330936432
29-01-2023 23:16:06 INFO Epoch 1: [2949/10940] ---- BYOL Validation Loss = 0.35054895281791687
29-01-2023 23:16:24 INFO Epoch 1: [2960/10940] ---- BYOL Training Loss = 0.38918155431747437
29-01-2023 23:16:41 INFO Epoch 1: [2971/10940] ---- BYOL Training Loss = 0.31623202562332153
29-01-2023 23:16:59 INFO Epoch 1: [2982/10940] ---- BYOL Training Loss = 0.30609801411628723
29-01-2023 23:17:17 INFO Epoch 1: [2993/10940] ---- BYOL Training Loss = 0.2805216908454895
29-01-2023 23:18:10 INFO Epoch 1: [2993/10940] ---- BYOL Validation Loss = 0.34179070591926575
29-01-2023 23:18:27 INFO Epoch 1: [3004/10940] ---- BYOL Training Loss = 0.32082411646842957
29-01-2023 23:18:45 INFO Epoch 1: [3015/10940] ---- BYOL Training Loss = 0.33381980657577515
29-01-2023 23:19:02 INFO Epoch 1: [3026/10940] ---- BYOL Training Loss = 0.3441309630870819
29-01-2023 23:19:20 INFO Epoch 1: [3037/10940] ---- BYOL Training Loss = 0.38433921337127686
29-01-2023 23:20:13 INFO Epoch 1: [3037/10940] ---- BYOL Validation Loss = 0.3570128083229065
29-01-2023 23:20:31 INFO Epoch 1: [3048/10940] ---- BYOL Training Loss = 0.36804062128067017
29-01-2023 23:20:48 INFO Epoch 1: [3059/10940] ---- BYOL Training Loss = 0.2852344214916229
29-01-2023 23:21:06 INFO Epoch 1: [3070/10940] ---- BYOL Training Loss = 0.3440224528312683
29-01-2023 23:21:24 INFO Epoch 1: [3081/10940] ---- BYOL Training Loss = 0.3584569990634918
29-01-2023 23:22:16 INFO Epoch 1: [3081/10940] ---- BYOL Validation Loss = 0.34006252884864807
29-01-2023 23:22:34 INFO Epoch 1: [3092/10940] ---- BYOL Training Loss = 0.2727147936820984
29-01-2023 23:22:52 INFO Epoch 1: [3103/10940] ---- BYOL Training Loss = 0.33627769351005554
29-01-2023 23:23:09 INFO Epoch 1: [3114/10940] ---- BYOL Training Loss = 0.34115803241729736
29-01-2023 23:23:28 INFO Epoch 1: [3125/10940] ---- BYOL Training Loss = 0.3299935460090637
29-01-2023 23:24:20 INFO Epoch 1: [3125/10940] ---- BYOL Validation Loss = 0.33647093176841736
29-01-2023 23:24:38 INFO Epoch 1: [3136/10940] ---- BYOL Training Loss = 0.3803243041038513
29-01-2023 23:24:55 INFO Epoch 1: [3147/10940] ---- BYOL Training Loss = 0.3646393418312073
29-01-2023 23:25:13 INFO Epoch 1: [3158/10940] ---- BYOL Training Loss = 0.34469348192214966
29-01-2023 23:25:31 INFO Epoch 1: [3169/10940] ---- BYOL Training Loss = 0.36029675602912903
29-01-2023 23:26:23 INFO Epoch 1: [3169/10940] ---- BYOL Validation Loss = 0.3445493280887604
29-01-2023 23:26:41 INFO Epoch 1: [3180/10940] ---- BYOL Training Loss = 0.34862592816352844
29-01-2023 23:26:58 INFO Epoch 1: [3191/10940] ---- BYOL Training Loss = 0.34496304392814636
29-01-2023 23:27:16 INFO Epoch 1: [3202/10940] ---- BYOL Training Loss = 0.33214035630226135
29-01-2023 23:27:33 INFO Epoch 1: [3213/10940] ---- BYOL Training Loss = 0.3074844479560852
29-01-2023 23:28:26 INFO Epoch 1: [3213/10940] ---- BYOL Validation Loss = 0.339650422334671
29-01-2023 23:28:44 INFO Epoch 1: [3224/10940] ---- BYOL Training Loss = 0.30030372738838196
29-01-2023 23:29:02 INFO Epoch 1: [3235/10940] ---- BYOL Training Loss = 0.34226107597351074
29-01-2023 23:29:20 INFO Epoch 1: [3246/10940] ---- BYOL Training Loss = 0.3615129590034485
29-01-2023 23:29:37 INFO Epoch 1: [3257/10940] ---- BYOL Training Loss = 0.33818376064300537
29-01-2023 23:30:30 INFO Epoch 1: [3257/10940] ---- BYOL Validation Loss = 0.35504403710365295
29-01-2023 23:30:47 INFO Epoch 1: [3268/10940] ---- BYOL Training Loss = 0.32769399881362915
29-01-2023 23:31:05 INFO Epoch 1: [3279/10940] ---- BYOL Training Loss = 0.29131990671157837
29-01-2023 23:31:23 INFO Epoch 1: [3290/10940] ---- BYOL Training Loss = 0.3138403594493866
29-01-2023 23:31:41 INFO Epoch 1: [3301/10940] ---- BYOL Training Loss = 0.29552987217903137
29-01-2023 23:32:34 INFO Epoch 1: [3301/10940] ---- BYOL Validation Loss = 0.3488597869873047
29-01-2023 23:32:51 INFO Epoch 1: [3312/10940] ---- BYOL Training Loss = 0.3165036737918854
29-01-2023 23:33:09 INFO Epoch 1: [3323/10940] ---- BYOL Training Loss = 0.3762584328651428
29-01-2023 23:33:26 INFO Epoch 1: [3334/10940] ---- BYOL Training Loss = 0.4084812104701996
29-01-2023 23:33:44 INFO Epoch 1: [3345/10940] ---- BYOL Training Loss = 0.3806600272655487
29-01-2023 23:34:37 INFO Epoch 1: [3345/10940] ---- BYOL Validation Loss = 0.34183698892593384
29-01-2023 23:34:54 INFO Epoch 1: [3356/10940] ---- BYOL Training Loss = 0.3681853413581848
29-01-2023 23:35:12 INFO Epoch 1: [3367/10940] ---- BYOL Training Loss = 0.3211670219898224
29-01-2023 23:35:30 INFO Epoch 1: [3378/10940] ---- BYOL Training Loss = 0.3145662248134613
29-01-2023 23:35:48 INFO Epoch 1: [3389/10940] ---- BYOL Training Loss = 0.3349204659461975
29-01-2023 23:36:41 INFO Epoch 1: [3389/10940] ---- BYOL Validation Loss = 0.3425847887992859
29-01-2023 23:36:58 INFO Epoch 1: [3400/10940] ---- BYOL Training Loss = 0.3858638107776642
29-01-2023 23:37:16 INFO Epoch 1: [3411/10940] ---- BYOL Training Loss = 0.35228314995765686
29-01-2023 23:37:34 INFO Epoch 1: [3422/10940] ---- BYOL Training Loss = 0.33169788122177124
29-01-2023 23:37:51 INFO Epoch 1: [3433/10940] ---- BYOL Training Loss = 0.3298082947731018
29-01-2023 23:38:44 INFO Epoch 1: [3433/10940] ---- BYOL Validation Loss = 0.33860594034194946
29-01-2023 23:39:01 INFO Epoch 1: [3444/10940] ---- BYOL Training Loss = 0.30715498328208923
29-01-2023 23:39:19 INFO Epoch 1: [3455/10940] ---- BYOL Training Loss = 0.2951861023902893
29-01-2023 23:39:37 INFO Epoch 1: [3466/10940] ---- BYOL Training Loss = 0.3627384901046753
29-01-2023 23:39:55 INFO Epoch 1: [3477/10940] ---- BYOL Training Loss = 0.34897205233573914
29-01-2023 23:40:48 INFO Epoch 1: [3477/10940] ---- BYOL Validation Loss = 0.3315613269805908
29-01-2023 23:41:05 INFO Epoch 1: [3488/10940] ---- BYOL Training Loss = 0.3113020956516266
29-01-2023 23:41:23 INFO Epoch 1: [3499/10940] ---- BYOL Training Loss = 0.3392286002635956
29-01-2023 23:41:41 INFO Epoch 1: [3510/10940] ---- BYOL Training Loss = 0.3589520752429962
29-01-2023 23:41:59 INFO Epoch 1: [3521/10940] ---- BYOL Training Loss = 0.38508063554763794
29-01-2023 23:42:52 INFO Epoch 1: [3521/10940] ---- BYOL Validation Loss = 0.3352287709712982
29-01-2023 23:43:10 INFO Epoch 1: [3532/10940] ---- BYOL Training Loss = 0.42977675795555115
29-01-2023 23:43:28 INFO Epoch 1: [3543/10940] ---- BYOL Training Loss = 0.3809413015842438
29-01-2023 23:43:45 INFO Epoch 1: [3554/10940] ---- BYOL Training Loss = 0.33037978410720825
29-01-2023 23:44:03 INFO Epoch 1: [3565/10940] ---- BYOL Training Loss = 0.2920418381690979
29-01-2023 23:44:56 INFO Epoch 1: [3565/10940] ---- BYOL Validation Loss = 0.32689905166625977
29-01-2023 23:45:13 INFO Epoch 1: [3576/10940] ---- BYOL Training Loss = 0.336792916059494
29-01-2023 23:45:31 INFO Epoch 1: [3587/10940] ---- BYOL Training Loss = 0.3596043288707733
29-01-2023 23:45:49 INFO Epoch 1: [3598/10940] ---- BYOL Training Loss = 0.3428665101528168
29-01-2023 23:46:07 INFO Epoch 1: [3609/10940] ---- BYOL Training Loss = 0.34200161695480347
29-01-2023 23:47:00 INFO Epoch 1: [3609/10940] ---- BYOL Validation Loss = 0.3392921984195709
29-01-2023 23:47:17 INFO Epoch 1: [3620/10940] ---- BYOL Training Loss = 0.35576745867729187
29-01-2023 23:47:35 INFO Epoch 1: [3631/10940] ---- BYOL Training Loss = 0.38594815135002136
29-01-2023 23:47:53 INFO Epoch 1: [3642/10940] ---- BYOL Training Loss = 0.340244859457016
29-01-2023 23:48:10 INFO Epoch 1: [3653/10940] ---- BYOL Training Loss = 0.2624059021472931
29-01-2023 23:49:04 INFO Epoch 1: [3653/10940] ---- BYOL Validation Loss = 0.33149290084838867
29-01-2023 23:49:21 INFO Epoch 1: [3664/10940] ---- BYOL Training Loss = 0.27908891439437866
29-01-2023 23:49:39 INFO Epoch 1: [3675/10940] ---- BYOL Training Loss = 0.3482359051704407
29-01-2023 23:49:57 INFO Epoch 1: [3686/10940] ---- BYOL Training Loss = 0.38425442576408386
29-01-2023 23:50:15 INFO Epoch 1: [3697/10940] ---- BYOL Training Loss = 0.3561317026615143
29-01-2023 23:51:08 INFO Epoch 1: [3697/10940] ---- BYOL Validation Loss = 0.33828625082969666
29-01-2023 23:51:25 INFO Epoch 1: [3708/10940] ---- BYOL Training Loss = 0.3361738920211792
29-01-2023 23:51:43 INFO Epoch 1: [3719/10940] ---- BYOL Training Loss = 0.34336602687835693
29-01-2023 23:52:01 INFO Epoch 1: [3730/10940] ---- BYOL Training Loss = 0.3511217534542084
29-01-2023 23:52:18 INFO Epoch 1: [3741/10940] ---- BYOL Training Loss = 0.3484063744544983
29-01-2023 23:53:11 INFO Epoch 1: [3741/10940] ---- BYOL Validation Loss = 0.3420455753803253
29-01-2023 23:53:29 INFO Epoch 1: [3752/10940] ---- BYOL Training Loss = 0.3060125410556793
29-01-2023 23:53:47 INFO Epoch 1: [3763/10940] ---- BYOL Training Loss = 0.3269120454788208
29-01-2023 23:54:04 INFO Epoch 1: [3774/10940] ---- BYOL Training Loss = 0.3122369945049286
29-01-2023 23:54:22 INFO Epoch 1: [3785/10940] ---- BYOL Training Loss = 0.33216381072998047
29-01-2023 23:55:15 INFO Epoch 1: [3785/10940] ---- BYOL Validation Loss = 0.3464171290397644
29-01-2023 23:55:32 INFO Epoch 1: [3796/10940] ---- BYOL Training Loss = 0.3723154366016388
29-01-2023 23:55:50 INFO Epoch 1: [3807/10940] ---- BYOL Training Loss = 0.3675617575645447
29-01-2023 23:56:08 INFO Epoch 1: [3818/10940] ---- BYOL Training Loss = 0.36542078852653503
29-01-2023 23:56:26 INFO Epoch 1: [3829/10940] ---- BYOL Training Loss = 0.37221843004226685
29-01-2023 23:57:19 INFO Epoch 1: [3829/10940] ---- BYOL Validation Loss = 0.34658083319664
29-01-2023 23:57:36 INFO Epoch 1: [3840/10940] ---- BYOL Training Loss = 0.3754326403141022
29-01-2023 23:57:54 INFO Epoch 1: [3851/10940] ---- BYOL Training Loss = 0.34842154383659363
29-01-2023 23:58:12 INFO Epoch 1: [3862/10940] ---- BYOL Training Loss = 0.3313218355178833
29-01-2023 23:58:29 INFO Epoch 1: [3873/10940] ---- BYOL Training Loss = 0.3571338951587677
29-01-2023 23:59:23 INFO Epoch 1: [3873/10940] ---- BYOL Validation Loss = 0.3388984799385071
29-01-2023 23:59:40 INFO Epoch 1: [3884/10940] ---- BYOL Training Loss = 0.3455126881599426
29-01-2023 23:59:58 INFO Epoch 1: [3895/10940] ---- BYOL Training Loss = 0.3338502049446106
30-01-2023 00:00:16 INFO Epoch 1: [3906/10940] ---- BYOL Training Loss = 0.3511345088481903
30-01-2023 00:00:34 INFO Epoch 1: [3917/10940] ---- BYOL Training Loss = 0.31979650259017944
30-01-2023 00:01:26 INFO Epoch 1: [3917/10940] ---- BYOL Validation Loss = 0.33824649453163147
30-01-2023 00:01:44 INFO Epoch 1: [3928/10940] ---- BYOL Training Loss = 0.31057921051979065
30-01-2023 00:02:02 INFO Epoch 1: [3939/10940] ---- BYOL Training Loss = 0.30895981192588806
30-01-2023 00:02:20 INFO Epoch 1: [3950/10940] ---- BYOL Training Loss = 0.32965612411499023
30-01-2023 00:02:38 INFO Epoch 1: [3961/10940] ---- BYOL Training Loss = 0.3554050624370575
30-01-2023 00:03:31 INFO Epoch 1: [3961/10940] ---- BYOL Validation Loss = 0.3391382396221161
30-01-2023 00:03:48 INFO Epoch 1: [3972/10940] ---- BYOL Training Loss = 0.3088442385196686
30-01-2023 00:04:06 INFO Epoch 1: [3983/10940] ---- BYOL Training Loss = 0.3178795278072357
30-01-2023 00:04:24 INFO Epoch 1: [3994/10940] ---- BYOL Training Loss = 0.29406553506851196
30-01-2023 00:04:41 INFO Epoch 1: [4005/10940] ---- BYOL Training Loss = 0.31620755791664124
30-01-2023 00:05:34 INFO Epoch 1: [4005/10940] ---- BYOL Validation Loss = 0.3299050033092499
30-01-2023 00:05:52 INFO Epoch 1: [4016/10940] ---- BYOL Training Loss = 0.3291812539100647
30-01-2023 00:06:10 INFO Epoch 1: [4027/10940] ---- BYOL Training Loss = 0.339515745639801
30-01-2023 00:06:28 INFO Epoch 1: [4038/10940] ---- BYOL Training Loss = 0.3621787428855896
30-01-2023 00:06:45 INFO Epoch 1: [4049/10940] ---- BYOL Training Loss = 0.34078818559646606
30-01-2023 00:07:38 INFO Epoch 1: [4049/10940] ---- BYOL Validation Loss = 0.3238508403301239
30-01-2023 00:07:56 INFO Epoch 1: [4060/10940] ---- BYOL Training Loss = 0.3263668417930603
30-01-2023 00:08:13 INFO Epoch 1: [4071/10940] ---- BYOL Training Loss = 0.3264027535915375
30-01-2023 00:08:31 INFO Epoch 1: [4082/10940] ---- BYOL Training Loss = 0.3664509952068329
30-01-2023 00:08:50 INFO Epoch 1: [4093/10940] ---- BYOL Training Loss = 0.33692696690559387
30-01-2023 00:09:43 INFO Epoch 1: [4093/10940] ---- BYOL Validation Loss = 0.33127841353416443
30-01-2023 00:10:00 INFO Epoch 1: [4104/10940] ---- BYOL Training Loss = 0.3171703517436981
30-01-2023 00:10:18 INFO Epoch 1: [4115/10940] ---- BYOL Training Loss = 0.3062208890914917
30-01-2023 00:10:36 INFO Epoch 1: [4126/10940] ---- BYOL Training Loss = 0.31079936027526855
30-01-2023 00:10:53 INFO Epoch 1: [4137/10940] ---- BYOL Training Loss = 0.29953843355178833
30-01-2023 00:11:46 INFO Epoch 1: [4137/10940] ---- BYOL Validation Loss = 0.32924938201904297
30-01-2023 00:12:04 INFO Epoch 1: [4148/10940] ---- BYOL Training Loss = 0.31706172227859497
30-01-2023 00:12:22 INFO Epoch 1: [4159/10940] ---- BYOL Training Loss = 0.3200797140598297
30-01-2023 00:12:40 INFO Epoch 1: [4170/10940] ---- BYOL Training Loss = 0.31244292855262756
30-01-2023 00:12:58 INFO Epoch 1: [4181/10940] ---- BYOL Training Loss = 0.34920838475227356
30-01-2023 00:13:51 INFO Epoch 1: [4181/10940] ---- BYOL Validation Loss = 0.3366042673587799
30-01-2023 00:14:08 INFO Epoch 1: [4192/10940] ---- BYOL Training Loss = 0.3406476080417633
30-01-2023 00:14:26 INFO Epoch 1: [4203/10940] ---- BYOL Training Loss = 0.3148180842399597
30-01-2023 00:14:44 INFO Epoch 1: [4214/10940] ---- BYOL Training Loss = 0.2692510187625885
30-01-2023 00:15:02 INFO Epoch 1: [4225/10940] ---- BYOL Training Loss = 0.3197266459465027
30-01-2023 00:15:56 INFO Epoch 1: [4225/10940] ---- BYOL Validation Loss = 0.3258218467235565
30-01-2023 00:16:13 INFO Epoch 1: [4236/10940] ---- BYOL Training Loss = 0.33260196447372437
30-01-2023 00:16:31 INFO Epoch 1: [4247/10940] ---- BYOL Training Loss = 0.2783896327018738
30-01-2023 00:16:49 INFO Epoch 1: [4258/10940] ---- BYOL Training Loss = 0.3305884301662445
30-01-2023 00:17:06 INFO Epoch 1: [4269/10940] ---- BYOL Training Loss = 0.3516601026058197
30-01-2023 00:17:59 INFO Epoch 1: [4269/10940] ---- BYOL Validation Loss = 0.31707701086997986
30-01-2023 00:18:17 INFO Epoch 1: [4280/10940] ---- BYOL Training Loss = 0.3406641483306885
30-01-2023 00:18:35 INFO Epoch 1: [4291/10940] ---- BYOL Training Loss = 0.32879024744033813
30-01-2023 00:18:53 INFO Epoch 1: [4302/10940] ---- BYOL Training Loss = 0.3656432330608368
30-01-2023 00:19:11 INFO Epoch 1: [4313/10940] ---- BYOL Training Loss = 0.35484546422958374
30-01-2023 00:20:04 INFO Epoch 1: [4313/10940] ---- BYOL Validation Loss = 0.3300803601741791
30-01-2023 00:20:21 INFO Epoch 1: [4324/10940] ---- BYOL Training Loss = 0.3080977499485016
30-01-2023 00:20:39 INFO Epoch 1: [4335/10940] ---- BYOL Training Loss = 0.3263603746891022
30-01-2023 00:20:57 INFO Epoch 1: [4346/10940] ---- BYOL Training Loss = 0.32107943296432495
30-01-2023 00:21:15 INFO Epoch 1: [4357/10940] ---- BYOL Training Loss = 0.323504775762558
30-01-2023 00:22:08 INFO Epoch 1: [4357/10940] ---- BYOL Validation Loss = 0.32466697692871094
30-01-2023 00:22:25 INFO Epoch 1: [4368/10940] ---- BYOL Training Loss = 0.34152647852897644
30-01-2023 00:22:43 INFO Epoch 1: [4379/10940] ---- BYOL Training Loss = 0.3580530285835266
30-01-2023 00:23:01 INFO Epoch 1: [4390/10940] ---- BYOL Training Loss = 0.3169803023338318
30-01-2023 00:23:19 INFO Epoch 1: [4401/10940] ---- BYOL Training Loss = 0.2743123173713684
30-01-2023 00:24:12 INFO Epoch 1: [4401/10940] ---- BYOL Validation Loss = 0.32140985131263733
30-01-2023 00:24:29 INFO Epoch 1: [4412/10940] ---- BYOL Training Loss = 0.3115168511867523
30-01-2023 00:24:47 INFO Epoch 1: [4423/10940] ---- BYOL Training Loss = 0.32409533858299255
30-01-2023 00:25:05 INFO Epoch 1: [4434/10940] ---- BYOL Training Loss = 0.413889080286026
30-01-2023 00:25:23 INFO Epoch 1: [4445/10940] ---- BYOL Training Loss = 0.3868463933467865
30-01-2023 00:26:16 INFO Epoch 1: [4445/10940] ---- BYOL Validation Loss = 0.3290089964866638
30-01-2023 00:26:34 INFO Epoch 1: [4456/10940] ---- BYOL Training Loss = 0.3405049443244934
30-01-2023 00:26:52 INFO Epoch 1: [4467/10940] ---- BYOL Training Loss = 0.35622379183769226
30-01-2023 00:27:09 INFO Epoch 1: [4478/10940] ---- BYOL Training Loss = 0.3324626386165619
30-01-2023 00:27:27 INFO Epoch 1: [4489/10940] ---- BYOL Training Loss = 0.32939091324806213
30-01-2023 00:28:20 INFO Epoch 1: [4489/10940] ---- BYOL Validation Loss = 0.32986122369766235
30-01-2023 00:28:37 INFO Epoch 1: [4500/10940] ---- BYOL Training Loss = 0.33864328265190125
30-01-2023 00:28:55 INFO Epoch 1: [4511/10940] ---- BYOL Training Loss = 0.30316367745399475
30-01-2023 00:29:13 INFO Epoch 1: [4522/10940] ---- BYOL Training Loss = 0.32233312726020813
30-01-2023 00:29:31 INFO Epoch 1: [4533/10940] ---- BYOL Training Loss = 0.34107738733291626
30-01-2023 00:30:25 INFO Epoch 1: [4533/10940] ---- BYOL Validation Loss = 0.33572933077812195
30-01-2023 00:30:42 INFO Epoch 1: [4544/10940] ---- BYOL Training Loss = 0.29122668504714966
30-01-2023 00:31:00 INFO Epoch 1: [4555/10940] ---- BYOL Training Loss = 0.3190538287162781
30-01-2023 00:31:17 INFO Epoch 1: [4566/10940] ---- BYOL Training Loss = 0.33644723892211914
30-01-2023 00:31:36 INFO Epoch 1: [4577/10940] ---- BYOL Training Loss = 0.33702418208122253
30-01-2023 00:32:29 INFO Epoch 1: [4577/10940] ---- BYOL Validation Loss = 0.3255814015865326
30-01-2023 00:32:46 INFO Epoch 1: [4588/10940] ---- BYOL Training Loss = 0.29080501198768616
30-01-2023 00:33:04 INFO Epoch 1: [4599/10940] ---- BYOL Training Loss = 0.3032355010509491
30-01-2023 00:33:22 INFO Epoch 1: [4610/10940] ---- BYOL Training Loss = 0.33738672733306885
30-01-2023 00:33:40 INFO Epoch 1: [4621/10940] ---- BYOL Training Loss = 0.3451732397079468
30-01-2023 00:34:32 INFO Epoch 1: [4621/10940] ---- BYOL Validation Loss = 0.3295277953147888
30-01-2023 00:34:50 INFO Epoch 1: [4632/10940] ---- BYOL Training Loss = 0.3214690387248993
30-01-2023 00:35:08 INFO Epoch 1: [4643/10940] ---- BYOL Training Loss = 0.3188715875148773
30-01-2023 00:35:26 INFO Epoch 1: [4654/10940] ---- BYOL Training Loss = 0.3277946710586548
30-01-2023 00:35:44 INFO Epoch 1: [4665/10940] ---- BYOL Training Loss = 0.3600073456764221
30-01-2023 00:36:37 INFO Epoch 1: [4665/10940] ---- BYOL Validation Loss = 0.32735320925712585
30-01-2023 00:36:54 INFO Epoch 1: [4676/10940] ---- BYOL Training Loss = 0.35406672954559326
30-01-2023 00:37:12 INFO Epoch 1: [4687/10940] ---- BYOL Training Loss = 0.36549073457717896
30-01-2023 00:37:30 INFO Epoch 1: [4698/10940] ---- BYOL Training Loss = 0.3501436114311218
30-01-2023 00:37:48 INFO Epoch 1: [4709/10940] ---- BYOL Training Loss = 0.30613547563552856
30-01-2023 00:38:41 INFO Epoch 1: [4709/10940] ---- BYOL Validation Loss = 0.32092127203941345
30-01-2023 00:38:58 INFO Epoch 1: [4720/10940] ---- BYOL Training Loss = 0.28829410672187805
30-01-2023 00:39:16 INFO Epoch 1: [4731/10940] ---- BYOL Training Loss = 0.3048754930496216
30-01-2023 00:39:34 INFO Epoch 1: [4742/10940] ---- BYOL Training Loss = 0.3618919849395752
30-01-2023 00:39:52 INFO Epoch 1: [4753/10940] ---- BYOL Training Loss = 0.37065696716308594
30-01-2023 00:40:45 INFO Epoch 1: [4753/10940] ---- BYOL Validation Loss = 0.33724474906921387
30-01-2023 00:41:03 INFO Epoch 1: [4764/10940] ---- BYOL Training Loss = 0.34856051206588745
30-01-2023 00:41:21 INFO Epoch 1: [4775/10940] ---- BYOL Training Loss = 0.31358417868614197
30-01-2023 00:41:39 INFO Epoch 1: [4786/10940] ---- BYOL Training Loss = 0.2835853099822998
30-01-2023 00:41:57 INFO Epoch 1: [4797/10940] ---- BYOL Training Loss = 0.2999119162559509
30-01-2023 00:42:49 INFO Epoch 1: [4797/10940] ---- BYOL Validation Loss = 0.3226161003112793
30-01-2023 00:43:07 INFO Epoch 1: [4808/10940] ---- BYOL Training Loss = 0.31377938389778137
30-01-2023 00:43:25 INFO Epoch 1: [4819/10940] ---- BYOL Training Loss = 0.32785072922706604
30-01-2023 00:43:43 INFO Epoch 1: [4830/10940] ---- BYOL Training Loss = 0.3024747967720032
30-01-2023 00:44:01 INFO Epoch 1: [4841/10940] ---- BYOL Training Loss = 0.2817879021167755
30-01-2023 00:44:54 INFO Epoch 1: [4841/10940] ---- BYOL Validation Loss = 0.3196853697299957
30-01-2023 00:45:11 INFO Epoch 1: [4852/10940] ---- BYOL Training Loss = 0.29505831003189087
30-01-2023 00:45:30 INFO Epoch 1: [4863/10940] ---- BYOL Training Loss = 0.2977939248085022
30-01-2023 00:45:47 INFO Epoch 1: [4874/10940] ---- BYOL Training Loss = 0.3119467496871948
30-01-2023 00:46:05 INFO Epoch 1: [4885/10940] ---- BYOL Training Loss = 0.34205740690231323
30-01-2023 00:46:58 INFO Epoch 1: [4885/10940] ---- BYOL Validation Loss = 0.3314104676246643
30-01-2023 00:47:16 INFO Epoch 1: [4896/10940] ---- BYOL Training Loss = 0.34020939469337463
30-01-2023 00:47:34 INFO Epoch 1: [4907/10940] ---- BYOL Training Loss = 0.31292492151260376
30-01-2023 00:47:52 INFO Epoch 1: [4918/10940] ---- BYOL Training Loss = 0.2997129559516907
30-01-2023 00:48:10 INFO Epoch 1: [4929/10940] ---- BYOL Training Loss = 0.3746843934059143
30-01-2023 00:49:03 INFO Epoch 1: [4929/10940] ---- BYOL Validation Loss = 0.32824182510375977
30-01-2023 00:49:21 INFO Epoch 1: [4940/10940] ---- BYOL Training Loss = 0.3457767367362976
30-01-2023 00:49:38 INFO Epoch 1: [4951/10940] ---- BYOL Training Loss = 0.32858115434646606
30-01-2023 00:49:57 INFO Epoch 1: [4962/10940] ---- BYOL Training Loss = 0.3085719048976898
30-01-2023 00:50:15 INFO Epoch 1: [4973/10940] ---- BYOL Training Loss = 0.2977577745914459
30-01-2023 00:51:08 INFO Epoch 1: [4973/10940] ---- BYOL Validation Loss = 0.31721606850624084
30-01-2023 00:51:25 INFO Epoch 1: [4984/10940] ---- BYOL Training Loss = 0.29305118322372437
30-01-2023 00:51:43 INFO Epoch 1: [4995/10940] ---- BYOL Training Loss = 0.3038933277130127
30-01-2023 00:52:01 INFO Epoch 1: [5006/10940] ---- BYOL Training Loss = 0.26855048537254333
30-01-2023 00:52:19 INFO Epoch 1: [5017/10940] ---- BYOL Training Loss = 0.2659454047679901
30-01-2023 00:53:12 INFO Epoch 1: [5017/10940] ---- BYOL Validation Loss = 0.3240145146846771
30-01-2023 00:53:30 INFO Epoch 1: [5028/10940] ---- BYOL Training Loss = 0.3005223870277405
30-01-2023 00:53:48 INFO Epoch 1: [5039/10940] ---- BYOL Training Loss = 0.30567222833633423
30-01-2023 00:54:06 INFO Epoch 1: [5050/10940] ---- BYOL Training Loss = 0.33901846408843994
30-01-2023 00:54:24 INFO Epoch 1: [5061/10940] ---- BYOL Training Loss = 0.32264047861099243
30-01-2023 00:55:17 INFO Epoch 1: [5061/10940] ---- BYOL Validation Loss = 0.3215182423591614
30-01-2023 00:55:35 INFO Epoch 1: [5072/10940] ---- BYOL Training Loss = 0.3058983087539673
30-01-2023 00:55:53 INFO Epoch 1: [5083/10940] ---- BYOL Training Loss = 0.3089103698730469
30-01-2023 00:56:11 INFO Epoch 1: [5094/10940] ---- BYOL Training Loss = 0.29870498180389404
30-01-2023 00:56:28 INFO Epoch 1: [5105/10940] ---- BYOL Training Loss = 0.32805296778678894
30-01-2023 00:57:21 INFO Epoch 1: [5105/10940] ---- BYOL Validation Loss = 0.32369399070739746
30-01-2023 00:57:39 INFO Epoch 1: [5116/10940] ---- BYOL Training Loss = 0.33629339933395386
30-01-2023 00:57:57 INFO Epoch 1: [5127/10940] ---- BYOL Training Loss = 0.31403031945228577
30-01-2023 00:58:15 INFO Epoch 1: [5138/10940] ---- BYOL Training Loss = 0.3200637102127075
30-01-2023 00:58:33 INFO Epoch 1: [5149/10940] ---- BYOL Training Loss = 0.2930421233177185
30-01-2023 00:59:26 INFO Epoch 1: [5149/10940] ---- BYOL Validation Loss = 0.31900957226753235
30-01-2023 00:59:43 INFO Epoch 1: [5160/10940] ---- BYOL Training Loss = 0.36153358221054077
30-01-2023 01:00:01 INFO Epoch 1: [5171/10940] ---- BYOL Training Loss = 0.36011797189712524
30-01-2023 01:00:19 INFO Epoch 1: [5182/10940] ---- BYOL Training Loss = 0.31884077191352844
30-01-2023 01:00:37 INFO Epoch 1: [5193/10940] ---- BYOL Training Loss = 0.3146822452545166
30-01-2023 01:01:30 INFO Epoch 1: [5193/10940] ---- BYOL Validation Loss = 0.3214760422706604
30-01-2023 01:01:47 INFO Epoch 1: [5204/10940] ---- BYOL Training Loss = 0.3035668134689331
30-01-2023 01:02:05 INFO Epoch 1: [5215/10940] ---- BYOL Training Loss = 0.30249539017677307
30-01-2023 01:02:24 INFO Epoch 1: [5226/10940] ---- BYOL Training Loss = 0.3041134178638458
30-01-2023 01:02:41 INFO Epoch 1: [5237/10940] ---- BYOL Training Loss = 0.32649192214012146
30-01-2023 01:03:34 INFO Epoch 1: [5237/10940] ---- BYOL Validation Loss = 0.3223867416381836
30-01-2023 01:03:52 INFO Epoch 1: [5248/10940] ---- BYOL Training Loss = 0.3673606514930725
30-01-2023 01:04:10 INFO Epoch 1: [5259/10940] ---- BYOL Training Loss = 0.3353070914745331
30-01-2023 01:04:28 INFO Epoch 1: [5270/10940] ---- BYOL Training Loss = 0.3271641731262207
30-01-2023 01:04:46 INFO Epoch 1: [5281/10940] ---- BYOL Training Loss = 0.37538832426071167
30-01-2023 01:05:39 INFO Epoch 1: [5281/10940] ---- BYOL Validation Loss = 0.33207792043685913
30-01-2023 01:05:57 INFO Epoch 1: [5292/10940] ---- BYOL Training Loss = 0.3539811670780182
30-01-2023 01:06:15 INFO Epoch 1: [5303/10940] ---- BYOL Training Loss = 0.3581075668334961
30-01-2023 01:06:33 INFO Epoch 1: [5314/10940] ---- BYOL Training Loss = 0.3677258789539337
30-01-2023 01:06:51 INFO Epoch 1: [5325/10940] ---- BYOL Training Loss = 0.34736669063568115
30-01-2023 01:07:44 INFO Epoch 1: [5325/10940] ---- BYOL Validation Loss = 0.32916584610939026
30-01-2023 01:08:01 INFO Epoch 1: [5336/10940] ---- BYOL Training Loss = 0.35363686084747314
30-01-2023 01:08:19 INFO Epoch 1: [5347/10940] ---- BYOL Training Loss = 0.32639291882514954
30-01-2023 01:08:37 INFO Epoch 1: [5358/10940] ---- BYOL Training Loss = 0.3259049952030182
30-01-2023 01:08:55 INFO Epoch 1: [5369/10940] ---- BYOL Training Loss = 0.3411649167537689
30-01-2023 01:09:48 INFO Epoch 1: [5369/10940] ---- BYOL Validation Loss = 0.31169161200523376
30-01-2023 01:10:06 INFO Epoch 1: [5380/10940] ---- BYOL Training Loss = 0.30932536721229553
30-01-2023 01:10:24 INFO Epoch 1: [5391/10940] ---- BYOL Training Loss = 0.3311997652053833
30-01-2023 01:10:42 INFO Epoch 1: [5402/10940] ---- BYOL Training Loss = 0.32367080450057983
30-01-2023 01:11:00 INFO Epoch 1: [5413/10940] ---- BYOL Training Loss = 0.2882445156574249
30-01-2023 01:11:53 INFO Epoch 1: [5413/10940] ---- BYOL Validation Loss = 0.31434887647628784
30-01-2023 01:12:11 INFO Epoch 1: [5424/10940] ---- BYOL Training Loss = 0.3048098683357239
30-01-2023 01:12:29 INFO Epoch 1: [5435/10940] ---- BYOL Training Loss = 0.3029140830039978
30-01-2023 01:12:47 INFO Epoch 1: [5446/10940] ---- BYOL Training Loss = 0.2755044996738434
30-01-2023 01:13:05 INFO Epoch 1: [5457/10940] ---- BYOL Training Loss = 0.2961570620536804
30-01-2023 01:13:57 INFO Epoch 1: [5457/10940] ---- BYOL Validation Loss = 0.32395458221435547
30-01-2023 01:14:16 INFO Epoch 1: [5468/10940] ---- BYOL Training Loss = 0.31886589527130127
30-01-2023 01:14:33 INFO Epoch 1: [5479/10940] ---- BYOL Training Loss = 0.34583842754364014
30-01-2023 01:14:51 INFO Epoch 1: [5490/10940] ---- BYOL Training Loss = 0.3095892071723938
30-01-2023 01:15:09 INFO Epoch 1: [5501/10940] ---- BYOL Training Loss = 0.33422866463661194
30-01-2023 01:16:03 INFO Epoch 1: [5501/10940] ---- BYOL Validation Loss = 0.3294386863708496
30-01-2023 01:16:21 INFO Epoch 1: [5512/10940] ---- BYOL Training Loss = 0.34681805968284607
30-01-2023 01:16:38 INFO Epoch 1: [5523/10940] ---- BYOL Training Loss = 0.33249375224113464
30-01-2023 01:16:56 INFO Epoch 1: [5534/10940] ---- BYOL Training Loss = 0.3031889498233795
30-01-2023 01:17:14 INFO Epoch 1: [5545/10940] ---- BYOL Training Loss = 0.32118943333625793
30-01-2023 01:18:07 INFO Epoch 1: [5545/10940] ---- BYOL Validation Loss = 0.3103412091732025
30-01-2023 01:18:25 INFO Epoch 1: [5556/10940] ---- BYOL Training Loss = 0.31134504079818726
30-01-2023 01:18:43 INFO Epoch 1: [5567/10940] ---- BYOL Training Loss = 0.28224891424179077
30-01-2023 01:19:01 INFO Epoch 1: [5578/10940] ---- BYOL Training Loss = 0.3405296206474304
30-01-2023 01:19:19 INFO Epoch 1: [5589/10940] ---- BYOL Training Loss = 0.32880479097366333
30-01-2023 01:20:12 INFO Epoch 1: [5589/10940] ---- BYOL Validation Loss = 0.3196086287498474
30-01-2023 01:20:30 INFO Epoch 1: [5600/10940] ---- BYOL Training Loss = 0.29181963205337524
30-01-2023 01:20:48 INFO Epoch 1: [5611/10940] ---- BYOL Training Loss = 0.31125128269195557
30-01-2023 01:21:06 INFO Epoch 1: [5622/10940] ---- BYOL Training Loss = 0.31305986642837524
30-01-2023 01:21:24 INFO Epoch 1: [5633/10940] ---- BYOL Training Loss = 0.31333979964256287
30-01-2023 01:22:17 INFO Epoch 1: [5633/10940] ---- BYOL Validation Loss = 0.3274190127849579
30-01-2023 01:22:35 INFO Epoch 1: [5644/10940] ---- BYOL Training Loss = 0.3268377184867859
30-01-2023 01:22:53 INFO Epoch 1: [5655/10940] ---- BYOL Training Loss = 0.31845593452453613
30-01-2023 01:23:11 INFO Epoch 1: [5666/10940] ---- BYOL Training Loss = 0.3067437410354614
30-01-2023 01:23:29 INFO Epoch 1: [5677/10940] ---- BYOL Training Loss = 0.30832141637802124
30-01-2023 01:24:22 INFO Epoch 1: [5677/10940] ---- BYOL Validation Loss = 0.3275682032108307
30-01-2023 01:24:39 INFO Epoch 1: [5688/10940] ---- BYOL Training Loss = 0.30684131383895874
30-01-2023 01:24:57 INFO Epoch 1: [5699/10940] ---- BYOL Training Loss = 0.3013785779476166
30-01-2023 01:25:15 INFO Epoch 1: [5710/10940] ---- BYOL Training Loss = 0.3420394957065582
30-01-2023 01:25:33 INFO Epoch 1: [5721/10940] ---- BYOL Training Loss = 0.36060720682144165
30-01-2023 01:26:26 INFO Epoch 1: [5721/10940] ---- BYOL Validation Loss = 0.3408997356891632
30-01-2023 01:26:44 INFO Epoch 1: [5732/10940] ---- BYOL Training Loss = 0.3405872881412506
30-01-2023 01:27:02 INFO Epoch 1: [5743/10940] ---- BYOL Training Loss = 0.29761070013046265
30-01-2023 01:27:20 INFO Epoch 1: [5754/10940] ---- BYOL Training Loss = 0.32675060629844666
30-01-2023 01:27:38 INFO Epoch 1: [5765/10940] ---- BYOL Training Loss = 0.3726864457130432
30-01-2023 01:28:31 INFO Epoch 1: [5765/10940] ---- BYOL Validation Loss = 0.36228471994400024
30-01-2023 01:28:48 INFO Epoch 1: [5776/10940] ---- BYOL Training Loss = 0.4122381806373596
30-01-2023 01:29:06 INFO Epoch 1: [5787/10940] ---- BYOL Training Loss = 0.38051727414131165
30-01-2023 01:29:25 INFO Epoch 1: [5798/10940] ---- BYOL Training Loss = 0.3464948832988739
30-01-2023 01:29:43 INFO Epoch 1: [5809/10940] ---- BYOL Training Loss = 0.36167827248573303
30-01-2023 01:30:36 INFO Epoch 1: [5809/10940] ---- BYOL Validation Loss = 0.32474851608276367
30-01-2023 01:30:53 INFO Epoch 1: [5820/10940] ---- BYOL Training Loss = 0.34842821955680847
30-01-2023 01:31:12 INFO Epoch 1: [5831/10940] ---- BYOL Training Loss = 0.37079018354415894
30-01-2023 01:31:30 INFO Epoch 1: [5842/10940] ---- BYOL Training Loss = 0.3386191725730896
30-01-2023 01:31:48 INFO Epoch 1: [5853/10940] ---- BYOL Training Loss = 0.3279791474342346
30-01-2023 01:32:41 INFO Epoch 1: [5853/10940] ---- BYOL Validation Loss = 0.31645387411117554
30-01-2023 01:32:58 INFO Epoch 1: [5864/10940] ---- BYOL Training Loss = 0.3108798861503601
30-01-2023 01:33:16 INFO Epoch 1: [5875/10940] ---- BYOL Training Loss = 0.2883893847465515
30-01-2023 01:33:34 INFO Epoch 1: [5886/10940] ---- BYOL Training Loss = 0.3183077275753021
30-01-2023 01:33:52 INFO Epoch 1: [5897/10940] ---- BYOL Training Loss = 0.30367347598075867
30-01-2023 01:34:46 INFO Epoch 1: [5897/10940] ---- BYOL Validation Loss = 0.31760385632514954
30-01-2023 01:35:03 INFO Epoch 1: [5908/10940] ---- BYOL Training Loss = 0.3017244338989258
30-01-2023 01:35:21 INFO Epoch 1: [5919/10940] ---- BYOL Training Loss = 0.32135266065597534
30-01-2023 01:35:40 INFO Epoch 1: [5930/10940] ---- BYOL Training Loss = 0.2813187539577484
30-01-2023 01:35:57 INFO Epoch 1: [5941/10940] ---- BYOL Training Loss = 0.3119395673274994
30-01-2023 01:36:50 INFO Epoch 1: [5941/10940] ---- BYOL Validation Loss = 0.3133586347103119
30-01-2023 01:37:08 INFO Epoch 1: [5952/10940] ---- BYOL Training Loss = 0.3243904113769531
30-01-2023 01:37:26 INFO Epoch 1: [5963/10940] ---- BYOL Training Loss = 0.326606422662735
30-01-2023 01:37:44 INFO Epoch 1: [5974/10940] ---- BYOL Training Loss = 0.3302595913410187
30-01-2023 01:38:02 INFO Epoch 1: [5985/10940] ---- BYOL Training Loss = 0.3562716543674469
30-01-2023 01:38:55 INFO Epoch 1: [5985/10940] ---- BYOL Validation Loss = 0.3143652081489563
30-01-2023 01:39:13 INFO Epoch 1: [5996/10940] ---- BYOL Training Loss = 0.30888208746910095
30-01-2023 01:39:31 INFO Epoch 1: [6007/10940] ---- BYOL Training Loss = 0.26680511236190796
30-01-2023 01:39:49 INFO Epoch 1: [6018/10940] ---- BYOL Training Loss = 0.31680503487586975
30-01-2023 01:40:07 INFO Epoch 1: [6029/10940] ---- BYOL Training Loss = 0.28524741530418396
30-01-2023 01:41:00 INFO Epoch 1: [6029/10940] ---- BYOL Validation Loss = 0.31401968002319336
30-01-2023 01:41:17 INFO Epoch 1: [6040/10940] ---- BYOL Training Loss = 0.26097217202186584
30-01-2023 01:41:36 INFO Epoch 1: [6051/10940] ---- BYOL Training Loss = 0.3185020089149475
30-01-2023 01:41:54 INFO Epoch 1: [6062/10940] ---- BYOL Training Loss = 0.35626649856567383
30-01-2023 01:42:12 INFO Epoch 1: [6073/10940] ---- BYOL Training Loss = 0.31573182344436646
30-01-2023 01:43:06 INFO Epoch 1: [6073/10940] ---- BYOL Validation Loss = 0.3006693422794342
30-01-2023 01:43:23 INFO Epoch 1: [6084/10940] ---- BYOL Training Loss = 0.29948437213897705
30-01-2023 01:43:42 INFO Epoch 1: [6095/10940] ---- BYOL Training Loss = 0.3128385543823242
30-01-2023 01:44:00 INFO Epoch 1: [6106/10940] ---- BYOL Training Loss = 0.3134244382381439
30-01-2023 01:44:18 INFO Epoch 1: [6117/10940] ---- BYOL Training Loss = 0.30156606435775757
30-01-2023 01:45:11 INFO Epoch 1: [6117/10940] ---- BYOL Validation Loss = 0.3062761127948761
30-01-2023 01:45:29 INFO Epoch 1: [6128/10940] ---- BYOL Training Loss = 0.304813027381897
30-01-2023 01:45:47 INFO Epoch 1: [6139/10940] ---- BYOL Training Loss = 0.3274509310722351
30-01-2023 01:46:05 INFO Epoch 1: [6150/10940] ---- BYOL Training Loss = 0.3048040270805359
30-01-2023 01:46:23 INFO Epoch 1: [6161/10940] ---- BYOL Training Loss = 0.343115895986557
30-01-2023 01:47:16 INFO Epoch 1: [6161/10940] ---- BYOL Validation Loss = 0.3065922260284424
30-01-2023 01:47:34 INFO Epoch 1: [6172/10940] ---- BYOL Training Loss = 0.3282444179058075
30-01-2023 01:47:52 INFO Epoch 1: [6183/10940] ---- BYOL Training Loss = 0.31152328848838806
30-01-2023 01:48:10 INFO Epoch 1: [6194/10940] ---- BYOL Training Loss = 0.27470284700393677
30-01-2023 01:48:28 INFO Epoch 1: [6205/10940] ---- BYOL Training Loss = 0.28184258937835693
30-01-2023 01:49:21 INFO Epoch 1: [6205/10940] ---- BYOL Validation Loss = 0.314782053232193
30-01-2023 01:49:39 INFO Epoch 1: [6216/10940] ---- BYOL Training Loss = 0.317064106464386
30-01-2023 01:49:58 INFO Epoch 1: [6227/10940] ---- BYOL Training Loss = 0.29096782207489014
30-01-2023 01:50:15 INFO Epoch 1: [6238/10940] ---- BYOL Training Loss = 0.29397326707839966
30-01-2023 01:50:33 INFO Epoch 1: [6249/10940] ---- BYOL Training Loss = 0.3134765028953552
30-01-2023 01:51:26 INFO Epoch 1: [6249/10940] ---- BYOL Validation Loss = 0.30878332257270813
30-01-2023 01:51:44 INFO Epoch 1: [6260/10940] ---- BYOL Training Loss = 0.2925597131252289
30-01-2023 01:52:02 INFO Epoch 1: [6271/10940] ---- BYOL Training Loss = 0.2889917492866516
30-01-2023 01:52:20 INFO Epoch 1: [6282/10940] ---- BYOL Training Loss = 0.30494511127471924
30-01-2023 01:52:38 INFO Epoch 1: [6293/10940] ---- BYOL Training Loss = 0.3612697124481201
30-01-2023 01:53:31 INFO Epoch 1: [6293/10940] ---- BYOL Validation Loss = 0.3254493176937103
30-01-2023 01:53:49 INFO Epoch 1: [6304/10940] ---- BYOL Training Loss = 0.33246493339538574
30-01-2023 01:54:07 INFO Epoch 1: [6315/10940] ---- BYOL Training Loss = 0.29173415899276733
30-01-2023 01:54:25 INFO Epoch 1: [6326/10940] ---- BYOL Training Loss = 0.34161680936813354
30-01-2023 01:54:43 INFO Epoch 1: [6337/10940] ---- BYOL Training Loss = 0.34005650877952576
30-01-2023 01:55:37 INFO Epoch 1: [6337/10940] ---- BYOL Validation Loss = 0.31147217750549316
30-01-2023 01:55:54 INFO Epoch 1: [6348/10940] ---- BYOL Training Loss = 0.32479327917099
30-01-2023 01:56:13 INFO Epoch 1: [6359/10940] ---- BYOL Training Loss = 0.3135235905647278
30-01-2023 01:56:30 INFO Epoch 1: [6370/10940] ---- BYOL Training Loss = 0.3152243196964264
30-01-2023 01:56:48 INFO Epoch 1: [6381/10940] ---- BYOL Training Loss = 0.2950335741043091
30-01-2023 01:57:41 INFO Epoch 1: [6381/10940] ---- BYOL Validation Loss = 0.30953243374824524
30-01-2023 01:57:59 INFO Epoch 1: [6392/10940] ---- BYOL Training Loss = 0.2962763011455536
30-01-2023 01:58:17 INFO Epoch 1: [6403/10940] ---- BYOL Training Loss = 0.32352811098098755
30-01-2023 01:58:36 INFO Epoch 1: [6414/10940] ---- BYOL Training Loss = 0.30186599493026733
30-01-2023 01:58:54 INFO Epoch 1: [6425/10940] ---- BYOL Training Loss = 0.29961463809013367
30-01-2023 01:59:47 INFO Epoch 1: [6425/10940] ---- BYOL Validation Loss = 0.31419411301612854
30-01-2023 02:00:05 INFO Epoch 1: [6436/10940] ---- BYOL Training Loss = 0.3149605691432953
30-01-2023 02:00:23 INFO Epoch 1: [6447/10940] ---- BYOL Training Loss = 0.2890554964542389
30-01-2023 02:00:41 INFO Epoch 1: [6458/10940] ---- BYOL Training Loss = 0.2697135806083679
30-01-2023 02:00:59 INFO Epoch 1: [6469/10940] ---- BYOL Training Loss = 0.2988453209400177
30-01-2023 02:01:52 INFO Epoch 1: [6469/10940] ---- BYOL Validation Loss = 0.30708518624305725
30-01-2023 02:02:10 INFO Epoch 1: [6480/10940] ---- BYOL Training Loss = 0.27439653873443604
30-01-2023 02:02:28 INFO Epoch 1: [6491/10940] ---- BYOL Training Loss = 0.2535210847854614
30-01-2023 02:02:46 INFO Epoch 1: [6502/10940] ---- BYOL Training Loss = 0.2791236639022827
30-01-2023 02:03:04 INFO Epoch 1: [6513/10940] ---- BYOL Training Loss = 0.30568063259124756
30-01-2023 02:03:57 INFO Epoch 1: [6513/10940] ---- BYOL Validation Loss = 0.30316585302352905
30-01-2023 02:04:15 INFO Epoch 1: [6524/10940] ---- BYOL Training Loss = 0.28335708379745483
30-01-2023 02:04:33 INFO Epoch 1: [6535/10940] ---- BYOL Training Loss = 0.2885446548461914
30-01-2023 02:04:51 INFO Epoch 1: [6546/10940] ---- BYOL Training Loss = 0.3171696662902832
30-01-2023 02:05:10 INFO Epoch 1: [6557/10940] ---- BYOL Training Loss = 0.30840790271759033
30-01-2023 02:06:03 INFO Epoch 1: [6557/10940] ---- BYOL Validation Loss = 0.3060145378112793
30-01-2023 02:06:21 INFO Epoch 1: [6568/10940] ---- BYOL Training Loss = 0.3245628774166107
30-01-2023 02:06:39 INFO Epoch 1: [6579/10940] ---- BYOL Training Loss = 0.34033894538879395
30-01-2023 02:06:57 INFO Epoch 1: [6590/10940] ---- BYOL Training Loss = 0.33119651675224304
30-01-2023 02:07:15 INFO Epoch 1: [6601/10940] ---- BYOL Training Loss = 0.32172834873199463
30-01-2023 02:08:08 INFO Epoch 1: [6601/10940] ---- BYOL Validation Loss = 0.3061233162879944
30-01-2023 02:08:26 INFO Epoch 1: [6612/10940] ---- BYOL Training Loss = 0.2814776301383972
30-01-2023 02:08:44 INFO Epoch 1: [6623/10940] ---- BYOL Training Loss = 0.299102783203125
30-01-2023 02:09:03 INFO Epoch 1: [6634/10940] ---- BYOL Training Loss = 0.2950393557548523
30-01-2023 02:09:21 INFO Epoch 1: [6645/10940] ---- BYOL Training Loss = 0.3139866292476654
30-01-2023 02:10:14 INFO Epoch 1: [6645/10940] ---- BYOL Validation Loss = 0.31614822149276733
30-01-2023 02:10:31 INFO Epoch 1: [6656/10940] ---- BYOL Training Loss = 0.3229263722896576
30-01-2023 02:10:49 INFO Epoch 1: [6667/10940] ---- BYOL Training Loss = 0.3055604100227356
30-01-2023 02:11:08 INFO Epoch 1: [6678/10940] ---- BYOL Training Loss = 0.2972845137119293
30-01-2023 02:11:26 INFO Epoch 1: [6689/10940] ---- BYOL Training Loss = 0.2660391926765442
30-01-2023 02:12:19 INFO Epoch 1: [6689/10940] ---- BYOL Validation Loss = 0.30833005905151367
30-01-2023 02:12:37 INFO Epoch 1: [6700/10940] ---- BYOL Training Loss = 0.2768954932689667
30-01-2023 02:12:55 INFO Epoch 1: [6711/10940] ---- BYOL Training Loss = 0.3048551082611084
30-01-2023 02:13:13 INFO Epoch 1: [6722/10940] ---- BYOL Training Loss = 0.3622340261936188
30-01-2023 02:13:31 INFO Epoch 1: [6733/10940] ---- BYOL Training Loss = 0.3303375542163849
30-01-2023 02:14:24 INFO Epoch 1: [6733/10940] ---- BYOL Validation Loss = 0.3044041693210602
30-01-2023 02:14:42 INFO Epoch 1: [6744/10940] ---- BYOL Training Loss = 0.2972594201564789
30-01-2023 02:15:00 INFO Epoch 1: [6755/10940] ---- BYOL Training Loss = 0.2864260971546173
30-01-2023 02:15:18 INFO Epoch 1: [6766/10940] ---- BYOL Training Loss = 0.30754852294921875
30-01-2023 02:15:36 INFO Epoch 1: [6777/10940] ---- BYOL Training Loss = 0.2996942400932312
30-01-2023 02:16:30 INFO Epoch 1: [6777/10940] ---- BYOL Validation Loss = 0.3165585696697235
30-01-2023 02:16:47 INFO Epoch 1: [6788/10940] ---- BYOL Training Loss = 0.3239077925682068
30-01-2023 02:17:06 INFO Epoch 1: [6799/10940] ---- BYOL Training Loss = 0.32465261220932007
30-01-2023 02:17:24 INFO Epoch 1: [6810/10940] ---- BYOL Training Loss = 0.28073713183403015
30-01-2023 02:17:42 INFO Epoch 1: [6821/10940] ---- BYOL Training Loss = 0.3078530430793762
30-01-2023 02:18:35 INFO Epoch 1: [6821/10940] ---- BYOL Validation Loss = 0.3089517056941986
30-01-2023 02:18:53 INFO Epoch 1: [6832/10940] ---- BYOL Training Loss = 0.3446873426437378
30-01-2023 02:19:11 INFO Epoch 1: [6843/10940] ---- BYOL Training Loss = 0.34240150451660156
30-01-2023 02:19:29 INFO Epoch 1: [6854/10940] ---- BYOL Training Loss = 0.3361111283302307
30-01-2023 02:19:48 INFO Epoch 1: [6865/10940] ---- BYOL Training Loss = 0.30921033024787903
30-01-2023 02:20:41 INFO Epoch 1: [6865/10940] ---- BYOL Validation Loss = 0.30731651186943054
30-01-2023 02:20:59 INFO Epoch 1: [6876/10940] ---- BYOL Training Loss = 0.31922370195388794
30-01-2023 02:21:17 INFO Epoch 1: [6887/10940] ---- BYOL Training Loss = 0.3342433273792267
30-01-2023 02:21:35 INFO Epoch 1: [6898/10940] ---- BYOL Training Loss = 0.3193301558494568
30-01-2023 02:21:53 INFO Epoch 1: [6909/10940] ---- BYOL Training Loss = 0.3585647940635681
30-01-2023 02:22:47 INFO Epoch 1: [6909/10940] ---- BYOL Validation Loss = 0.3047136664390564
30-01-2023 02:23:04 INFO Epoch 1: [6920/10940] ---- BYOL Training Loss = 0.3585338592529297
30-01-2023 02:23:23 INFO Epoch 1: [6931/10940] ---- BYOL Training Loss = 0.37004539370536804
30-01-2023 02:23:41 INFO Epoch 1: [6942/10940] ---- BYOL Training Loss = 0.3270898461341858
30-01-2023 02:23:59 INFO Epoch 1: [6953/10940] ---- BYOL Training Loss = 0.2674682140350342
30-01-2023 02:24:53 INFO Epoch 1: [6953/10940] ---- BYOL Validation Loss = 0.3101930618286133
30-01-2023 02:25:11 INFO Epoch 1: [6964/10940] ---- BYOL Training Loss = 0.29555124044418335
30-01-2023 02:25:29 INFO Epoch 1: [6975/10940] ---- BYOL Training Loss = 0.31226059794425964
30-01-2023 02:25:47 INFO Epoch 1: [6986/10940] ---- BYOL Training Loss = 0.29513072967529297
30-01-2023 02:26:05 INFO Epoch 1: [6997/10940] ---- BYOL Training Loss = 0.33765724301338196
30-01-2023 02:26:58 INFO Epoch 1: [6997/10940] ---- BYOL Validation Loss = 0.31905895471572876
30-01-2023 02:27:16 INFO Epoch 1: [7008/10940] ---- BYOL Training Loss = 0.34116360545158386
30-01-2023 02:27:35 INFO Epoch 1: [7019/10940] ---- BYOL Training Loss = 0.32763776183128357
30-01-2023 02:27:53 INFO Epoch 1: [7030/10940] ---- BYOL Training Loss = 0.3307689130306244
30-01-2023 02:28:11 INFO Epoch 1: [7041/10940] ---- BYOL Training Loss = 0.30479204654693604
30-01-2023 02:29:05 INFO Epoch 1: [7041/10940] ---- BYOL Validation Loss = 0.3021332323551178
30-01-2023 02:29:22 INFO Epoch 1: [7052/10940] ---- BYOL Training Loss = 0.326511949300766
30-01-2023 02:29:41 INFO Epoch 1: [7063/10940] ---- BYOL Training Loss = 0.3205682337284088
30-01-2023 02:29:59 INFO Epoch 1: [7074/10940] ---- BYOL Training Loss = 0.306079238653183
30-01-2023 02:30:17 INFO Epoch 1: [7085/10940] ---- BYOL Training Loss = 0.2751827836036682
30-01-2023 02:31:10 INFO Epoch 1: [7085/10940] ---- BYOL Validation Loss = 0.3089410662651062
30-01-2023 02:31:28 INFO Epoch 1: [7096/10940] ---- BYOL Training Loss = 0.2676754295825958
30-01-2023 02:31:46 INFO Epoch 1: [7107/10940] ---- BYOL Training Loss = 0.2832155227661133
30-01-2023 02:32:04 INFO Epoch 1: [7118/10940] ---- BYOL Training Loss = 0.2970713973045349
30-01-2023 02:32:22 INFO Epoch 1: [7129/10940] ---- BYOL Training Loss = 0.2912999093532562
30-01-2023 02:33:15 INFO Epoch 1: [7129/10940] ---- BYOL Validation Loss = 0.3038177490234375
30-01-2023 02:33:33 INFO Epoch 1: [7140/10940] ---- BYOL Training Loss = 0.27544811367988586
30-01-2023 02:33:51 INFO Epoch 1: [7151/10940] ---- BYOL Training Loss = 0.2515828609466553
30-01-2023 02:34:09 INFO Epoch 1: [7162/10940] ---- BYOL Training Loss = 0.26811856031417847
30-01-2023 02:34:28 INFO Epoch 1: [7173/10940] ---- BYOL Training Loss = 0.29533690214157104
30-01-2023 02:35:21 INFO Epoch 1: [7173/10940] ---- BYOL Validation Loss = 0.3137933909893036
30-01-2023 02:35:39 INFO Epoch 1: [7184/10940] ---- BYOL Training Loss = 0.274075448513031
30-01-2023 02:35:57 INFO Epoch 1: [7195/10940] ---- BYOL Training Loss = 0.3007577061653137
30-01-2023 02:36:15 INFO Epoch 1: [7206/10940] ---- BYOL Training Loss = 0.3331576883792877
30-01-2023 02:36:34 INFO Epoch 1: [7217/10940] ---- BYOL Training Loss = 0.32721924781799316
30-01-2023 02:37:27 INFO Epoch 1: [7217/10940] ---- BYOL Validation Loss = 0.30774810910224915
30-01-2023 02:37:44 INFO Epoch 1: [7228/10940] ---- BYOL Training Loss = 0.3117513656616211
30-01-2023 02:38:02 INFO Epoch 1: [7239/10940] ---- BYOL Training Loss = 0.33794859051704407
30-01-2023 02:38:21 INFO Epoch 1: [7250/10940] ---- BYOL Training Loss = 0.305769145488739
30-01-2023 02:38:39 INFO Epoch 1: [7261/10940] ---- BYOL Training Loss = 0.2865605056285858
30-01-2023 02:39:32 INFO Epoch 1: [7261/10940] ---- BYOL Validation Loss = 0.30372709035873413
30-01-2023 02:39:50 INFO Epoch 1: [7272/10940] ---- BYOL Training Loss = 0.2941824793815613
30-01-2023 02:40:08 INFO Epoch 1: [7283/10940] ---- BYOL Training Loss = 0.30599528551101685
30-01-2023 02:40:27 INFO Epoch 1: [7294/10940] ---- BYOL Training Loss = 0.300577849149704
30-01-2023 02:40:45 INFO Epoch 1: [7305/10940] ---- BYOL Training Loss = 0.30725449323654175
30-01-2023 02:41:38 INFO Epoch 1: [7305/10940] ---- BYOL Validation Loss = 0.3174937069416046
30-01-2023 02:41:55 INFO Epoch 1: [7316/10940] ---- BYOL Training Loss = 0.3128473162651062
30-01-2023 02:42:14 INFO Epoch 1: [7327/10940] ---- BYOL Training Loss = 0.35318899154663086
30-01-2023 02:42:32 INFO Epoch 1: [7338/10940] ---- BYOL Training Loss = 0.33231237530708313
30-01-2023 02:42:50 INFO Epoch 1: [7349/10940] ---- BYOL Training Loss = 0.31624695658683777
30-01-2023 02:43:43 INFO Epoch 1: [7349/10940] ---- BYOL Validation Loss = 0.3115869164466858
30-01-2023 02:44:01 INFO Epoch 1: [7360/10940] ---- BYOL Training Loss = 0.2913571000099182
30-01-2023 02:44:19 INFO Epoch 1: [7371/10940] ---- BYOL Training Loss = 0.298694372177124
30-01-2023 02:44:38 INFO Epoch 1: [7382/10940] ---- BYOL Training Loss = 0.3247172236442566
30-01-2023 02:44:56 INFO Epoch 1: [7393/10940] ---- BYOL Training Loss = 0.3486051857471466
30-01-2023 02:45:49 INFO Epoch 1: [7393/10940] ---- BYOL Validation Loss = 0.3116217255592346
30-01-2023 02:46:07 INFO Epoch 1: [7404/10940] ---- BYOL Training Loss = 0.3182357847690582
30-01-2023 02:46:25 INFO Epoch 1: [7415/10940] ---- BYOL Training Loss = 0.3390533924102783
30-01-2023 02:46:44 INFO Epoch 1: [7426/10940] ---- BYOL Training Loss = 0.35232073068618774
30-01-2023 02:47:02 INFO Epoch 1: [7437/10940] ---- BYOL Training Loss = 0.3452393114566803
30-01-2023 02:47:55 INFO Epoch 1: [7437/10940] ---- BYOL Validation Loss = 0.31449371576309204
30-01-2023 02:48:13 INFO Epoch 1: [7448/10940] ---- BYOL Training Loss = 0.27858418226242065
30-01-2023 02:48:31 INFO Epoch 1: [7459/10940] ---- BYOL Training Loss = 0.28049546480178833
30-01-2023 02:48:49 INFO Epoch 1: [7470/10940] ---- BYOL Training Loss = 0.26493269205093384
30-01-2023 02:49:08 INFO Epoch 1: [7481/10940] ---- BYOL Training Loss = 0.29293200373649597
30-01-2023 02:50:01 INFO Epoch 1: [7481/10940] ---- BYOL Validation Loss = 0.31353759765625
30-01-2023 02:50:18 INFO Epoch 1: [7492/10940] ---- BYOL Training Loss = 0.3142915368080139
30-01-2023 02:50:37 INFO Epoch 1: [7503/10940] ---- BYOL Training Loss = 0.34552639722824097
30-01-2023 02:50:55 INFO Epoch 1: [7514/10940] ---- BYOL Training Loss = 0.29004284739494324
30-01-2023 02:51:13 INFO Epoch 1: [7525/10940] ---- BYOL Training Loss = 0.3152844309806824
30-01-2023 02:52:06 INFO Epoch 1: [7525/10940] ---- BYOL Validation Loss = 0.3258936107158661
30-01-2023 02:52:25 INFO Epoch 1: [7536/10940] ---- BYOL Training Loss = 0.3084173798561096
30-01-2023 02:52:43 INFO Epoch 1: [7547/10940] ---- BYOL Training Loss = 0.30347567796707153
30-01-2023 02:53:01 INFO Epoch 1: [7558/10940] ---- BYOL Training Loss = 0.314322292804718
30-01-2023 02:53:19 INFO Epoch 1: [7569/10940] ---- BYOL Training Loss = 0.33533450961112976
30-01-2023 02:54:12 INFO Epoch 1: [7569/10940] ---- BYOL Validation Loss = 0.3137829899787903
30-01-2023 02:54:30 INFO Epoch 1: [7580/10940] ---- BYOL Training Loss = 0.3190070688724518
30-01-2023 02:54:49 INFO Epoch 1: [7591/10940] ---- BYOL Training Loss = 0.29637736082077026
30-01-2023 02:55:07 INFO Epoch 1: [7602/10940] ---- BYOL Training Loss = 0.32830312848091125
30-01-2023 02:55:25 INFO Epoch 1: [7613/10940] ---- BYOL Training Loss = 0.37110525369644165
30-01-2023 02:56:18 INFO Epoch 1: [7613/10940] ---- BYOL Validation Loss = 0.31152862310409546
30-01-2023 02:56:36 INFO Epoch 1: [7624/10940] ---- BYOL Training Loss = 0.37001854181289673
30-01-2023 02:56:54 INFO Epoch 1: [7635/10940] ---- BYOL Training Loss = 0.3430231511592865
30-01-2023 02:57:13 INFO Epoch 1: [7646/10940] ---- BYOL Training Loss = 0.3230929374694824
30-01-2023 02:57:31 INFO Epoch 1: [7657/10940] ---- BYOL Training Loss = 0.31700101494789124
30-01-2023 02:58:24 INFO Epoch 1: [7657/10940] ---- BYOL Validation Loss = 0.3104036748409271
30-01-2023 02:58:42 INFO Epoch 1: [7668/10940] ---- BYOL Training Loss = 0.30899563431739807
30-01-2023 02:59:01 INFO Epoch 1: [7679/10940] ---- BYOL Training Loss = 0.29216480255126953
30-01-2023 02:59:19 INFO Epoch 1: [7690/10940] ---- BYOL Training Loss = 0.26959213614463806
30-01-2023 02:59:37 INFO Epoch 1: [7701/10940] ---- BYOL Training Loss = 0.28652507066726685
30-01-2023 03:00:30 INFO Epoch 1: [7701/10940] ---- BYOL Validation Loss = 0.30806872248649597
30-01-2023 03:00:48 INFO Epoch 1: [7712/10940] ---- BYOL Training Loss = 0.2971445322036743
30-01-2023 03:01:06 INFO Epoch 1: [7723/10940] ---- BYOL Training Loss = 0.3260464072227478
30-01-2023 03:01:25 INFO Epoch 1: [7734/10940] ---- BYOL Training Loss = 0.30134978890419006
30-01-2023 03:01:43 INFO Epoch 1: [7745/10940] ---- BYOL Training Loss = 0.3132696747779846
30-01-2023 03:02:36 INFO Epoch 1: [7745/10940] ---- BYOL Validation Loss = 0.3076116442680359
30-01-2023 03:02:54 INFO Epoch 1: [7756/10940] ---- BYOL Training Loss = 0.28885990381240845
30-01-2023 03:03:12 INFO Epoch 1: [7767/10940] ---- BYOL Training Loss = 0.25683730840682983
30-01-2023 03:03:31 INFO Epoch 1: [7778/10940] ---- BYOL Training Loss = 0.2948194444179535
30-01-2023 03:03:49 INFO Epoch 1: [7789/10940] ---- BYOL Training Loss = 0.3460085690021515
30-01-2023 03:04:42 INFO Epoch 1: [7789/10940] ---- BYOL Validation Loss = 0.3052445352077484
30-01-2023 03:05:00 INFO Epoch 1: [7800/10940] ---- BYOL Training Loss = 0.3723287284374237
30-01-2023 03:05:18 INFO Epoch 1: [7811/10940] ---- BYOL Training Loss = 0.3467186391353607
30-01-2023 03:05:37 INFO Epoch 1: [7822/10940] ---- BYOL Training Loss = 0.3225996494293213
30-01-2023 03:05:55 INFO Epoch 1: [7833/10940] ---- BYOL Training Loss = 0.33473920822143555
30-01-2023 03:06:47 INFO Epoch 1: [7833/10940] ---- BYOL Validation Loss = 0.31026554107666016
30-01-2023 03:07:06 INFO Epoch 1: [7844/10940] ---- BYOL Training Loss = 0.28286463022232056
30-01-2023 03:07:24 INFO Epoch 1: [7855/10940] ---- BYOL Training Loss = 0.30007702112197876
30-01-2023 03:07:42 INFO Epoch 1: [7866/10940] ---- BYOL Training Loss = 0.3292723298072815
30-01-2023 03:08:01 INFO Epoch 1: [7877/10940] ---- BYOL Training Loss = 0.3030104339122772
30-01-2023 03:08:54 INFO Epoch 1: [7877/10940] ---- BYOL Validation Loss = 0.3186952769756317
30-01-2023 03:09:12 INFO Epoch 1: [7888/10940] ---- BYOL Training Loss = 0.28066298365592957
30-01-2023 03:09:30 INFO Epoch 1: [7899/10940] ---- BYOL Training Loss = 0.32892516255378723
30-01-2023 03:09:48 INFO Epoch 1: [7910/10940] ---- BYOL Training Loss = 0.3374159038066864
30-01-2023 03:10:07 INFO Epoch 1: [7921/10940] ---- BYOL Training Loss = 0.29656821489334106
30-01-2023 03:11:00 INFO Epoch 1: [7921/10940] ---- BYOL Validation Loss = 0.32322725653648376
30-01-2023 03:11:17 INFO Epoch 1: [7932/10940] ---- BYOL Training Loss = 0.3057917058467865
30-01-2023 03:11:36 INFO Epoch 1: [7943/10940] ---- BYOL Training Loss = 0.32322055101394653
30-01-2023 03:11:54 INFO Epoch 1: [7954/10940] ---- BYOL Training Loss = 0.3264966607093811
30-01-2023 03:12:13 INFO Epoch 1: [7965/10940] ---- BYOL Training Loss = 0.30853933095932007
30-01-2023 03:13:06 INFO Epoch 1: [7965/10940] ---- BYOL Validation Loss = 0.31099754571914673
30-01-2023 03:13:24 INFO Epoch 1: [7976/10940] ---- BYOL Training Loss = 0.2972414195537567
30-01-2023 03:13:42 INFO Epoch 1: [7987/10940] ---- BYOL Training Loss = 0.30670639872550964
30-01-2023 03:14:00 INFO Epoch 1: [7998/10940] ---- BYOL Training Loss = 0.2649526596069336
30-01-2023 03:14:19 INFO Epoch 1: [8009/10940] ---- BYOL Training Loss = 0.25533443689346313
30-01-2023 03:15:12 INFO Epoch 1: [8009/10940] ---- BYOL Validation Loss = 0.3049473166465759
30-01-2023 03:15:29 INFO Epoch 1: [8020/10940] ---- BYOL Training Loss = 0.2907354235649109
30-01-2023 03:15:48 INFO Epoch 1: [8031/10940] ---- BYOL Training Loss = 0.3326355516910553
30-01-2023 03:16:06 INFO Epoch 1: [8042/10940] ---- BYOL Training Loss = 0.30544355511665344
30-01-2023 03:16:24 INFO Epoch 1: [8053/10940] ---- BYOL Training Loss = 0.3311907947063446
30-01-2023 03:17:18 INFO Epoch 1: [8053/10940] ---- BYOL Validation Loss = 0.3217320442199707
30-01-2023 03:17:35 INFO Epoch 1: [8064/10940] ---- BYOL Training Loss = 0.2973281443119049
30-01-2023 03:17:54 INFO Epoch 1: [8075/10940] ---- BYOL Training Loss = 0.2886751592159271
30-01-2023 03:18:12 INFO Epoch 1: [8086/10940] ---- BYOL Training Loss = 0.341412216424942
30-01-2023 03:18:31 INFO Epoch 1: [8097/10940] ---- BYOL Training Loss = 0.32920172810554504
30-01-2023 03:19:24 INFO Epoch 1: [8097/10940] ---- BYOL Validation Loss = 0.3186771869659424
30-01-2023 03:19:42 INFO Epoch 1: [8108/10940] ---- BYOL Training Loss = 0.3072238564491272
30-01-2023 03:20:00 INFO Epoch 1: [8119/10940] ---- BYOL Training Loss = 0.33987826108932495
30-01-2023 03:20:18 INFO Epoch 1: [8130/10940] ---- BYOL Training Loss = 0.34518375992774963
30-01-2023 03:20:37 INFO Epoch 1: [8141/10940] ---- BYOL Training Loss = 0.30300983786582947
30-01-2023 03:21:30 INFO Epoch 1: [8141/10940] ---- BYOL Validation Loss = 0.3178238272666931
30-01-2023 03:21:47 INFO Epoch 1: [8152/10940] ---- BYOL Training Loss = 0.2568870186805725
30-01-2023 03:22:06 INFO Epoch 1: [8163/10940] ---- BYOL Training Loss = 0.2738390564918518
30-01-2023 03:22:24 INFO Epoch 1: [8174/10940] ---- BYOL Training Loss = 0.33912691473960876
30-01-2023 03:22:42 INFO Epoch 1: [8185/10940] ---- BYOL Training Loss = 0.34500446915626526
30-01-2023 03:23:35 INFO Epoch 1: [8185/10940] ---- BYOL Validation Loss = 0.31429097056388855
30-01-2023 03:23:53 INFO Epoch 1: [8196/10940] ---- BYOL Training Loss = 0.3111775517463684
30-01-2023 03:24:12 INFO Epoch 1: [8207/10940] ---- BYOL Training Loss = 0.28342777490615845
30-01-2023 03:24:30 INFO Epoch 1: [8218/10940] ---- BYOL Training Loss = 0.3076706528663635
30-01-2023 03:24:48 INFO Epoch 1: [8229/10940] ---- BYOL Training Loss = 0.368490070104599
30-01-2023 03:25:41 INFO Epoch 1: [8229/10940] ---- BYOL Validation Loss = 0.3136497139930725
30-01-2023 03:25:59 INFO Epoch 1: [8240/10940] ---- BYOL Training Loss = 0.35913777351379395
30-01-2023 03:26:17 INFO Epoch 1: [8251/10940] ---- BYOL Training Loss = 0.3123411536216736
30-01-2023 03:26:36 INFO Epoch 1: [8262/10940] ---- BYOL Training Loss = 0.31066611409187317
30-01-2023 03:26:54 INFO Epoch 1: [8273/10940] ---- BYOL Training Loss = 0.2931302785873413
30-01-2023 03:27:47 INFO Epoch 1: [8273/10940] ---- BYOL Validation Loss = 0.31948962807655334
30-01-2023 03:28:05 INFO Epoch 1: [8284/10940] ---- BYOL Training Loss = 0.3098388612270355
30-01-2023 03:28:24 INFO Epoch 1: [8295/10940] ---- BYOL Training Loss = 0.35311558842658997
30-01-2023 03:28:42 INFO Epoch 1: [8306/10940] ---- BYOL Training Loss = 0.37123948335647583
30-01-2023 03:29:00 INFO Epoch 1: [8317/10940] ---- BYOL Training Loss = 0.3361080288887024
30-01-2023 03:29:53 INFO Epoch 1: [8317/10940] ---- BYOL Validation Loss = 0.31891360878944397
30-01-2023 03:30:11 INFO Epoch 1: [8328/10940] ---- BYOL Training Loss = 0.3146215081214905
30-01-2023 03:30:29 INFO Epoch 1: [8339/10940] ---- BYOL Training Loss = 0.3380703926086426
30-01-2023 03:30:48 INFO Epoch 1: [8350/10940] ---- BYOL Training Loss = 0.3253346085548401
30-01-2023 03:31:06 INFO Epoch 1: [8361/10940] ---- BYOL Training Loss = 0.34387460350990295
30-01-2023 03:31:59 INFO Epoch 1: [8361/10940] ---- BYOL Validation Loss = 0.31815305352211
30-01-2023 03:32:17 INFO Epoch 1: [8372/10940] ---- BYOL Training Loss = 0.31899726390838623
30-01-2023 03:32:35 INFO Epoch 1: [8383/10940] ---- BYOL Training Loss = 0.30740392208099365
30-01-2023 03:32:54 INFO Epoch 1: [8394/10940] ---- BYOL Training Loss = 0.3399283289909363
30-01-2023 03:33:12 INFO Epoch 1: [8405/10940] ---- BYOL Training Loss = 0.3216125965118408
30-01-2023 03:34:05 INFO Epoch 1: [8405/10940] ---- BYOL Validation Loss = 0.32198163866996765
30-01-2023 03:34:23 INFO Epoch 1: [8416/10940] ---- BYOL Training Loss = 0.35663560032844543
30-01-2023 03:34:41 INFO Epoch 1: [8427/10940] ---- BYOL Training Loss = 0.36101847887039185
30-01-2023 03:34:59 INFO Epoch 1: [8438/10940] ---- BYOL Training Loss = 0.34595686197280884
30-01-2023 03:35:18 INFO Epoch 1: [8449/10940] ---- BYOL Training Loss = 0.33829572796821594
30-01-2023 03:36:11 INFO Epoch 1: [8449/10940] ---- BYOL Validation Loss = 0.3180416524410248
30-01-2023 03:36:28 INFO Epoch 1: [8460/10940] ---- BYOL Training Loss = 0.3182651102542877
30-01-2023 03:36:47 INFO Epoch 1: [8471/10940] ---- BYOL Training Loss = 0.30159786343574524
30-01-2023 03:37:05 INFO Epoch 1: [8482/10940] ---- BYOL Training Loss = 0.32902252674102783
30-01-2023 03:37:23 INFO Epoch 1: [8493/10940] ---- BYOL Training Loss = 0.33129939436912537
30-01-2023 03:38:17 INFO Epoch 1: [8493/10940] ---- BYOL Validation Loss = 0.30583181977272034
30-01-2023 03:38:35 INFO Epoch 1: [8504/10940] ---- BYOL Training Loss = 0.2891460657119751
30-01-2023 03:38:53 INFO Epoch 1: [8515/10940] ---- BYOL Training Loss = 0.3050152063369751
30-01-2023 03:39:12 INFO Epoch 1: [8526/10940] ---- BYOL Training Loss = 0.343923956155777
30-01-2023 03:39:30 INFO Epoch 1: [8537/10940] ---- BYOL Training Loss = 0.3543502688407898
30-01-2023 03:40:23 INFO Epoch 1: [8537/10940] ---- BYOL Validation Loss = 0.33118778467178345
30-01-2023 03:40:41 INFO Epoch 1: [8548/10940] ---- BYOL Training Loss = 0.3203066289424896
30-01-2023 03:40:59 INFO Epoch 1: [8559/10940] ---- BYOL Training Loss = 0.33030375838279724
30-01-2023 03:41:18 INFO Epoch 1: [8570/10940] ---- BYOL Training Loss = 0.3473712205886841
30-01-2023 03:41:36 INFO Epoch 1: [8581/10940] ---- BYOL Training Loss = 0.3046596646308899
30-01-2023 03:42:29 INFO Epoch 1: [8581/10940] ---- BYOL Validation Loss = 0.3139095902442932
30-01-2023 03:42:47 INFO Epoch 1: [8592/10940] ---- BYOL Training Loss = 0.2902058959007263
30-01-2023 03:43:05 INFO Epoch 1: [8603/10940] ---- BYOL Training Loss = 0.31210970878601074
30-01-2023 03:43:24 INFO Epoch 1: [8614/10940] ---- BYOL Training Loss = 0.3508930802345276
30-01-2023 03:43:42 INFO Epoch 1: [8625/10940] ---- BYOL Training Loss = 0.3169556260108948
30-01-2023 03:44:35 INFO Epoch 1: [8625/10940] ---- BYOL Validation Loss = 0.3206598460674286
30-01-2023 03:44:53 INFO Epoch 1: [8636/10940] ---- BYOL Training Loss = 0.3104526996612549
30-01-2023 03:45:12 INFO Epoch 1: [8647/10940] ---- BYOL Training Loss = 0.3192199170589447
30-01-2023 03:45:30 INFO Epoch 1: [8658/10940] ---- BYOL Training Loss = 0.31743162870407104
30-01-2023 03:45:49 INFO Epoch 1: [8669/10940] ---- BYOL Training Loss = 0.2823520302772522
30-01-2023 03:46:42 INFO Epoch 1: [8669/10940] ---- BYOL Validation Loss = 0.31319352984428406
30-01-2023 03:46:59 INFO Epoch 1: [8680/10940] ---- BYOL Training Loss = 0.27791836857795715
30-01-2023 03:47:18 INFO Epoch 1: [8691/10940] ---- BYOL Training Loss = 0.31474173069000244
30-01-2023 03:47:36 INFO Epoch 1: [8702/10940] ---- BYOL Training Loss = 0.326998770236969
30-01-2023 03:47:55 INFO Epoch 1: [8713/10940] ---- BYOL Training Loss = 0.3311348259449005
30-01-2023 03:48:48 INFO Epoch 1: [8713/10940] ---- BYOL Validation Loss = 0.31558164954185486
30-01-2023 03:49:06 INFO Epoch 1: [8724/10940] ---- BYOL Training Loss = 0.34003180265426636
30-01-2023 03:49:24 INFO Epoch 1: [8735/10940] ---- BYOL Training Loss = 0.30035752058029175
30-01-2023 03:49:42 INFO Epoch 1: [8746/10940] ---- BYOL Training Loss = 0.28494247794151306
30-01-2023 03:50:01 INFO Epoch 1: [8757/10940] ---- BYOL Training Loss = 0.3276030421257019
30-01-2023 03:50:54 INFO Epoch 1: [8757/10940] ---- BYOL Validation Loss = 0.31952419877052307
30-01-2023 03:51:11 INFO Epoch 1: [8768/10940] ---- BYOL Training Loss = 0.29189491271972656
30-01-2023 03:51:30 INFO Epoch 1: [8779/10940] ---- BYOL Training Loss = 0.31147301197052
30-01-2023 03:51:48 INFO Epoch 1: [8790/10940] ---- BYOL Training Loss = 0.37408214807510376
30-01-2023 03:52:07 INFO Epoch 1: [8801/10940] ---- BYOL Training Loss = 0.3815825581550598
30-01-2023 03:53:00 INFO Epoch 1: [8801/10940] ---- BYOL Validation Loss = 0.3291053771972656
30-01-2023 03:53:18 INFO Epoch 1: [8812/10940] ---- BYOL Training Loss = 0.3454747796058655
30-01-2023 03:53:36 INFO Epoch 1: [8823/10940] ---- BYOL Training Loss = 0.31492921710014343
30-01-2023 03:53:54 INFO Epoch 1: [8834/10940] ---- BYOL Training Loss = 0.33652910590171814
30-01-2023 03:54:13 INFO Epoch 1: [8845/10940] ---- BYOL Training Loss = 0.3066209554672241
30-01-2023 03:55:06 INFO Epoch 1: [8845/10940] ---- BYOL Validation Loss = 0.3106273114681244
30-01-2023 03:55:24 INFO Epoch 1: [8856/10940] ---- BYOL Training Loss = 0.28238728642463684
30-01-2023 03:55:42 INFO Epoch 1: [8867/10940] ---- BYOL Training Loss = 0.33157068490982056
30-01-2023 03:56:01 INFO Epoch 1: [8878/10940] ---- BYOL Training Loss = 0.35450199246406555
30-01-2023 03:56:19 INFO Epoch 1: [8889/10940] ---- BYOL Training Loss = 0.3383437693119049
30-01-2023 03:57:12 INFO Epoch 1: [8889/10940] ---- BYOL Validation Loss = 0.32211998105049133
30-01-2023 03:57:30 INFO Epoch 1: [8900/10940] ---- BYOL Training Loss = 0.29847198724746704
30-01-2023 03:57:49 INFO Epoch 1: [8911/10940] ---- BYOL Training Loss = 0.2881544232368469
30-01-2023 03:58:07 INFO Epoch 1: [8922/10940] ---- BYOL Training Loss = 0.25428545475006104
30-01-2023 03:58:26 INFO Epoch 1: [8933/10940] ---- BYOL Training Loss = 0.25166448950767517
30-01-2023 03:59:19 INFO Epoch 1: [8933/10940] ---- BYOL Validation Loss = 0.31580618023872375
30-01-2023 03:59:37 INFO Epoch 1: [8944/10940] ---- BYOL Training Loss = 0.3157620131969452
30-01-2023 03:59:55 INFO Epoch 1: [8955/10940] ---- BYOL Training Loss = 0.35352006554603577
30-01-2023 04:00:13 INFO Epoch 1: [8966/10940] ---- BYOL Training Loss = 0.30496713519096375
30-01-2023 04:00:32 INFO Epoch 1: [8977/10940] ---- BYOL Training Loss = 0.2728838324546814
30-01-2023 04:01:25 INFO Epoch 1: [8977/10940] ---- BYOL Validation Loss = 0.3116230368614197
30-01-2023 04:01:43 INFO Epoch 1: [8988/10940] ---- BYOL Training Loss = 0.2691240906715393
30-01-2023 04:02:02 INFO Epoch 1: [8999/10940] ---- BYOL Training Loss = 0.2755308151245117
30-01-2023 04:02:20 INFO Epoch 1: [9010/10940] ---- BYOL Training Loss = 0.2963371276855469
30-01-2023 04:02:38 INFO Epoch 1: [9021/10940] ---- BYOL Training Loss = 0.30041465163230896
30-01-2023 04:03:31 INFO Epoch 1: [9021/10940] ---- BYOL Validation Loss = 0.31389790773391724
30-01-2023 04:03:49 INFO Epoch 1: [9032/10940] ---- BYOL Training Loss = 0.29710522294044495
30-01-2023 04:04:07 INFO Epoch 1: [9043/10940] ---- BYOL Training Loss = 0.3242616057395935
30-01-2023 04:04:26 INFO Epoch 1: [9054/10940] ---- BYOL Training Loss = 0.3035314083099365
30-01-2023 04:04:44 INFO Epoch 1: [9065/10940] ---- BYOL Training Loss = 0.3141496181488037
30-01-2023 04:05:37 INFO Epoch 1: [9065/10940] ---- BYOL Validation Loss = 0.31130820512771606
30-01-2023 04:05:56 INFO Epoch 1: [9076/10940] ---- BYOL Training Loss = 0.32680803537368774
30-01-2023 04:06:14 INFO Epoch 1: [9087/10940] ---- BYOL Training Loss = 0.33196359872817993
30-01-2023 04:06:32 INFO Epoch 1: [9098/10940] ---- BYOL Training Loss = 0.30189886689186096
30-01-2023 04:06:51 INFO Epoch 1: [9109/10940] ---- BYOL Training Loss = 0.2950041890144348
30-01-2023 04:07:44 INFO Epoch 1: [9109/10940] ---- BYOL Validation Loss = 0.31436124444007874
30-01-2023 04:08:02 INFO Epoch 1: [9120/10940] ---- BYOL Training Loss = 0.2859744131565094
30-01-2023 04:08:21 INFO Epoch 1: [9131/10940] ---- BYOL Training Loss = 0.34253937005996704
30-01-2023 04:08:39 INFO Epoch 1: [9142/10940] ---- BYOL Training Loss = 0.34858691692352295
30-01-2023 04:08:58 INFO Epoch 1: [9153/10940] ---- BYOL Training Loss = 0.32929497957229614
30-01-2023 04:09:51 INFO Epoch 1: [9153/10940] ---- BYOL Validation Loss = 0.31488990783691406
30-01-2023 04:10:09 INFO Epoch 1: [9164/10940] ---- BYOL Training Loss = 0.3005267083644867
30-01-2023 04:10:28 INFO Epoch 1: [9175/10940] ---- BYOL Training Loss = 0.26810798048973083
30-01-2023 04:10:46 INFO Epoch 1: [9186/10940] ---- BYOL Training Loss = 0.26370900869369507
30-01-2023 04:11:05 INFO Epoch 1: [9197/10940] ---- BYOL Training Loss = 0.27525249123573303
30-01-2023 04:11:58 INFO Epoch 1: [9197/10940] ---- BYOL Validation Loss = 0.31799015402793884
30-01-2023 04:12:15 INFO Epoch 1: [9208/10940] ---- BYOL Training Loss = 0.32173630595207214
30-01-2023 04:12:34 INFO Epoch 1: [9219/10940] ---- BYOL Training Loss = 0.3496309220790863
30-01-2023 04:12:52 INFO Epoch 1: [9230/10940] ---- BYOL Training Loss = 0.36890754103660583
30-01-2023 04:13:10 INFO Epoch 1: [9241/10940] ---- BYOL Training Loss = 0.4038654863834381
30-01-2023 04:14:04 INFO Epoch 1: [9241/10940] ---- BYOL Validation Loss = 0.3230144679546356
30-01-2023 04:14:22 INFO Epoch 1: [9252/10940] ---- BYOL Training Loss = 0.37951359152793884
30-01-2023 04:14:41 INFO Epoch 1: [9263/10940] ---- BYOL Training Loss = 0.33793967962265015
30-01-2023 04:14:59 INFO Epoch 1: [9274/10940] ---- BYOL Training Loss = 0.31912583112716675
30-01-2023 04:15:17 INFO Epoch 1: [9285/10940] ---- BYOL Training Loss = 0.35612577199935913
30-01-2023 04:16:11 INFO Epoch 1: [9285/10940] ---- BYOL Validation Loss = 0.31909412145614624
30-01-2023 04:16:28 INFO Epoch 1: [9296/10940] ---- BYOL Training Loss = 0.3497457504272461
30-01-2023 04:16:47 INFO Epoch 1: [9307/10940] ---- BYOL Training Loss = 0.31251949071884155
30-01-2023 04:17:05 INFO Epoch 1: [9318/10940] ---- BYOL Training Loss = 0.32669782638549805
30-01-2023 04:17:24 INFO Epoch 1: [9329/10940] ---- BYOL Training Loss = 0.29504284262657166
30-01-2023 04:18:17 INFO Epoch 1: [9329/10940] ---- BYOL Validation Loss = 0.3144609332084656
30-01-2023 04:18:35 INFO Epoch 1: [9340/10940] ---- BYOL Training Loss = 0.32203203439712524
30-01-2023 04:18:53 INFO Epoch 1: [9351/10940] ---- BYOL Training Loss = 0.30178239941596985
30-01-2023 04:19:12 INFO Epoch 1: [9362/10940] ---- BYOL Training Loss = 0.2746979594230652
30-01-2023 04:19:30 INFO Epoch 1: [9373/10940] ---- BYOL Training Loss = 0.3234334886074066
30-01-2023 04:20:23 INFO Epoch 1: [9373/10940] ---- BYOL Validation Loss = 0.31881919503211975
30-01-2023 04:20:41 INFO Epoch 1: [9384/10940] ---- BYOL Training Loss = 0.33921343088150024
30-01-2023 04:21:00 INFO Epoch 1: [9395/10940] ---- BYOL Training Loss = 0.34872516989707947
30-01-2023 04:21:19 INFO Epoch 1: [9406/10940] ---- BYOL Training Loss = 0.33191120624542236
30-01-2023 04:21:37 INFO Epoch 1: [9417/10940] ---- BYOL Training Loss = 0.3096424341201782
30-01-2023 04:22:30 INFO Epoch 1: [9417/10940] ---- BYOL Validation Loss = 0.3128029406070709
30-01-2023 04:22:48 INFO Epoch 1: [9428/10940] ---- BYOL Training Loss = 0.3348683714866638
30-01-2023 04:23:06 INFO Epoch 1: [9439/10940] ---- BYOL Training Loss = 0.3485965132713318
30-01-2023 04:23:25 INFO Epoch 1: [9450/10940] ---- BYOL Training Loss = 0.3446890115737915
30-01-2023 04:23:43 INFO Epoch 1: [9461/10940] ---- BYOL Training Loss = 0.31618747115135193
30-01-2023 04:24:37 INFO Epoch 1: [9461/10940] ---- BYOL Validation Loss = 0.3170587718486786
30-01-2023 04:24:55 INFO Epoch 1: [9472/10940] ---- BYOL Training Loss = 0.30078285932540894
30-01-2023 04:25:13 INFO Epoch 1: [9483/10940] ---- BYOL Training Loss = 0.31960374116897583
30-01-2023 04:25:32 INFO Epoch 1: [9494/10940] ---- BYOL Training Loss = 0.32466304302215576
30-01-2023 04:25:50 INFO Epoch 1: [9505/10940] ---- BYOL Training Loss = 0.3092826008796692
30-01-2023 04:26:43 INFO Epoch 1: [9505/10940] ---- BYOL Validation Loss = 0.30937787890434265
30-01-2023 04:27:01 INFO Epoch 1: [9516/10940] ---- BYOL Training Loss = 0.24145880341529846
30-01-2023 04:27:19 INFO Epoch 1: [9527/10940] ---- BYOL Training Loss = 0.29792189598083496
30-01-2023 04:27:38 INFO Epoch 1: [9538/10940] ---- BYOL Training Loss = 0.3583875298500061
30-01-2023 04:27:56 INFO Epoch 1: [9549/10940] ---- BYOL Training Loss = 0.3106344938278198
30-01-2023 04:28:50 INFO Epoch 1: [9549/10940] ---- BYOL Validation Loss = 0.30830660462379456
30-01-2023 04:29:08 INFO Epoch 1: [9560/10940] ---- BYOL Training Loss = 0.3359316885471344
30-01-2023 04:29:26 INFO Epoch 1: [9571/10940] ---- BYOL Training Loss = 0.306804895401001
30-01-2023 04:29:45 INFO Epoch 1: [9582/10940] ---- BYOL Training Loss = 0.2867259681224823
30-01-2023 04:30:03 INFO Epoch 1: [9593/10940] ---- BYOL Training Loss = 0.3079838454723358
30-01-2023 04:30:56 INFO Epoch 1: [9593/10940] ---- BYOL Validation Loss = 0.3106521964073181
30-01-2023 04:31:14 INFO Epoch 1: [9604/10940] ---- BYOL Training Loss = 0.31958383321762085
30-01-2023 04:31:33 INFO Epoch 1: [9615/10940] ---- BYOL Training Loss = 0.3675133287906647
30-01-2023 04:31:51 INFO Epoch 1: [9626/10940] ---- BYOL Training Loss = 0.3270071744918823
30-01-2023 04:32:10 INFO Epoch 1: [9637/10940] ---- BYOL Training Loss = 0.2816413938999176
30-01-2023 04:33:03 INFO Epoch 1: [9637/10940] ---- BYOL Validation Loss = 0.31748417019844055
30-01-2023 04:33:21 INFO Epoch 1: [9648/10940] ---- BYOL Training Loss = 0.3255426287651062
30-01-2023 04:33:39 INFO Epoch 1: [9659/10940] ---- BYOL Training Loss = 0.3155602514743805
30-01-2023 04:33:58 INFO Epoch 1: [9670/10940] ---- BYOL Training Loss = 0.28427571058273315
30-01-2023 04:34:16 INFO Epoch 1: [9681/10940] ---- BYOL Training Loss = 0.31849223375320435
30-01-2023 04:35:10 INFO Epoch 1: [9681/10940] ---- BYOL Validation Loss = 0.3180740177631378
30-01-2023 04:35:28 INFO Epoch 1: [9692/10940] ---- BYOL Training Loss = 0.3564361035823822
30-01-2023 04:35:46 INFO Epoch 1: [9703/10940] ---- BYOL Training Loss = 0.3384135663509369
30-01-2023 04:36:05 INFO Epoch 1: [9714/10940] ---- BYOL Training Loss = 0.33684784173965454
30-01-2023 04:36:23 INFO Epoch 1: [9725/10940] ---- BYOL Training Loss = 0.31117957830429077
30-01-2023 04:37:16 INFO Epoch 1: [9725/10940] ---- BYOL Validation Loss = 0.3106761574745178
30-01-2023 04:37:34 INFO Epoch 1: [9736/10940] ---- BYOL Training Loss = 0.2960658669471741
30-01-2023 04:37:53 INFO Epoch 1: [9747/10940] ---- BYOL Training Loss = 0.31564968824386597
30-01-2023 04:38:12 INFO Epoch 1: [9758/10940] ---- BYOL Training Loss = 0.349547803401947
30-01-2023 04:38:30 INFO Epoch 1: [9769/10940] ---- BYOL Training Loss = 0.34502166509628296
30-01-2023 04:39:23 INFO Epoch 1: [9769/10940] ---- BYOL Validation Loss = 0.30782628059387207
30-01-2023 04:39:42 INFO Epoch 1: [9780/10940] ---- BYOL Training Loss = 0.34668219089508057
30-01-2023 04:40:00 INFO Epoch 1: [9791/10940] ---- BYOL Training Loss = 0.31757691502571106
30-01-2023 04:40:19 INFO Epoch 1: [9802/10940] ---- BYOL Training Loss = 0.3532162308692932
30-01-2023 04:40:37 INFO Epoch 1: [9813/10940] ---- BYOL Training Loss = 0.3506862223148346
30-01-2023 04:41:30 INFO Epoch 1: [9813/10940] ---- BYOL Validation Loss = 0.31343793869018555
30-01-2023 04:41:48 INFO Epoch 1: [9824/10940] ---- BYOL Training Loss = 0.31620359420776367
30-01-2023 04:42:07 INFO Epoch 1: [9835/10940] ---- BYOL Training Loss = 0.33451518416404724
30-01-2023 04:42:25 INFO Epoch 1: [9846/10940] ---- BYOL Training Loss = 0.3475310802459717
30-01-2023 04:42:44 INFO Epoch 1: [9857/10940] ---- BYOL Training Loss = 0.3612990379333496
30-01-2023 04:43:37 INFO Epoch 1: [9857/10940] ---- BYOL Validation Loss = 0.3157952129840851
30-01-2023 04:43:55 INFO Epoch 1: [9868/10940] ---- BYOL Training Loss = 0.3425922393798828
30-01-2023 04:44:13 INFO Epoch 1: [9879/10940] ---- BYOL Training Loss = 0.32275956869125366
30-01-2023 04:44:32 INFO Epoch 1: [9890/10940] ---- BYOL Training Loss = 0.31368833780288696
30-01-2023 04:44:50 INFO Epoch 1: [9901/10940] ---- BYOL Training Loss = 0.32802683115005493
30-01-2023 04:45:43 INFO Epoch 1: [9901/10940] ---- BYOL Validation Loss = 0.31523963809013367
30-01-2023 04:46:02 INFO Epoch 1: [9912/10940] ---- BYOL Training Loss = 0.3362498879432678
30-01-2023 04:46:20 INFO Epoch 1: [9923/10940] ---- BYOL Training Loss = 0.28091588616371155
30-01-2023 04:46:38 INFO Epoch 1: [9934/10940] ---- BYOL Training Loss = 0.2585464417934418
30-01-2023 04:46:57 INFO Epoch 1: [9945/10940] ---- BYOL Training Loss = 0.26942911744117737
30-01-2023 04:47:50 INFO Epoch 1: [9945/10940] ---- BYOL Validation Loss = 0.311845600605011
30-01-2023 04:48:08 INFO Epoch 1: [9956/10940] ---- BYOL Training Loss = 0.2983851730823517
30-01-2023 04:48:27 INFO Epoch 1: [9967/10940] ---- BYOL Training Loss = 0.31019705533981323
30-01-2023 04:48:45 INFO Epoch 1: [9978/10940] ---- BYOL Training Loss = 0.30727291107177734
30-01-2023 04:49:04 INFO Epoch 1: [9989/10940] ---- BYOL Training Loss = 0.31100329756736755
30-01-2023 04:49:57 INFO Epoch 1: [9989/10940] ---- BYOL Validation Loss = 0.3146952688694
30-01-2023 04:50:15 INFO Epoch 1: [10000/10940] ---- BYOL Training Loss = 0.3640396296977997
30-01-2023 04:50:33 INFO Epoch 1: [10011/10940] ---- BYOL Training Loss = 0.3546641767024994
30-01-2023 04:50:52 INFO Epoch 1: [10022/10940] ---- BYOL Training Loss = 0.2987080514431
30-01-2023 04:51:11 INFO Epoch 1: [10033/10940] ---- BYOL Training Loss = 0.312575101852417
30-01-2023 04:52:04 INFO Epoch 1: [10033/10940] ---- BYOL Validation Loss = 0.3155572712421417
30-01-2023 04:52:22 INFO Epoch 1: [10044/10940] ---- BYOL Training Loss = 0.3021602928638458
30-01-2023 04:52:40 INFO Epoch 1: [10055/10940] ---- BYOL Training Loss = 0.2746054530143738
30-01-2023 04:52:59 INFO Epoch 1: [10066/10940] ---- BYOL Training Loss = 0.3204248547554016
30-01-2023 04:53:17 INFO Epoch 1: [10077/10940] ---- BYOL Training Loss = 0.3462309241294861
30-01-2023 04:54:10 INFO Epoch 1: [10077/10940] ---- BYOL Validation Loss = 0.3131386935710907
30-01-2023 04:54:28 INFO Epoch 1: [10088/10940] ---- BYOL Training Loss = 0.3222337067127228
30-01-2023 04:54:47 INFO Epoch 1: [10099/10940] ---- BYOL Training Loss = 0.3173655867576599
30-01-2023 04:55:06 INFO Epoch 1: [10110/10940] ---- BYOL Training Loss = 0.2972111701965332
30-01-2023 04:55:24 INFO Epoch 1: [10121/10940] ---- BYOL Training Loss = 0.31578195095062256
30-01-2023 04:56:17 INFO Epoch 1: [10121/10940] ---- BYOL Validation Loss = 0.31516551971435547
30-01-2023 04:56:35 INFO Epoch 1: [10132/10940] ---- BYOL Training Loss = 0.3256457448005676
30-01-2023 04:56:53 INFO Epoch 1: [10143/10940] ---- BYOL Training Loss = 0.3171767592430115
30-01-2023 04:57:12 INFO Epoch 1: [10154/10940] ---- BYOL Training Loss = 0.3229963481426239
30-01-2023 04:57:31 INFO Epoch 1: [10165/10940] ---- BYOL Training Loss = 0.27976199984550476
30-01-2023 04:58:24 INFO Epoch 1: [10165/10940] ---- BYOL Validation Loss = 0.31503647565841675
30-01-2023 04:58:43 INFO Epoch 1: [10176/10940] ---- BYOL Training Loss = 0.28221312165260315
30-01-2023 04:59:01 INFO Epoch 1: [10187/10940] ---- BYOL Training Loss = 0.30570438504219055
30-01-2023 04:59:19 INFO Epoch 1: [10198/10940] ---- BYOL Training Loss = 0.3230806589126587
30-01-2023 04:59:38 INFO Epoch 1: [10209/10940] ---- BYOL Training Loss = 0.2831927537918091
30-01-2023 05:00:31 INFO Epoch 1: [10209/10940] ---- BYOL Validation Loss = 0.31379225850105286
30-01-2023 05:00:49 INFO Epoch 1: [10220/10940] ---- BYOL Training Loss = 0.28395262360572815
30-01-2023 05:01:08 INFO Epoch 1: [10231/10940] ---- BYOL Training Loss = 0.2805374264717102
30-01-2023 05:01:26 INFO Epoch 1: [10242/10940] ---- BYOL Training Loss = 0.2981073260307312
30-01-2023 05:01:45 INFO Epoch 1: [10253/10940] ---- BYOL Training Loss = 0.3106848895549774
30-01-2023 05:02:38 INFO Epoch 1: [10253/10940] ---- BYOL Validation Loss = 0.3098897635936737
30-01-2023 05:02:56 INFO Epoch 1: [10264/10940] ---- BYOL Training Loss = 0.3490988314151764
30-01-2023 05:03:14 INFO Epoch 1: [10275/10940] ---- BYOL Training Loss = 0.3354857563972473
30-01-2023 05:03:33 INFO Epoch 1: [10286/10940] ---- BYOL Training Loss = 0.30405884981155396
30-01-2023 05:03:51 INFO Epoch 1: [10297/10940] ---- BYOL Training Loss = 0.29109323024749756
30-01-2023 05:04:45 INFO Epoch 1: [10297/10940] ---- BYOL Validation Loss = 0.3121674358844757
30-01-2023 05:05:03 INFO Epoch 1: [10308/10940] ---- BYOL Training Loss = 0.3129454255104065
30-01-2023 05:05:22 INFO Epoch 1: [10319/10940] ---- BYOL Training Loss = 0.3294859826564789
30-01-2023 05:05:40 INFO Epoch 1: [10330/10940] ---- BYOL Training Loss = 0.28098800778388977
30-01-2023 05:05:58 INFO Epoch 1: [10341/10940] ---- BYOL Training Loss = 0.2755034863948822
30-01-2023 05:06:52 INFO Epoch 1: [10341/10940] ---- BYOL Validation Loss = 0.30689767003059387
30-01-2023 05:07:10 INFO Epoch 1: [10352/10940] ---- BYOL Training Loss = 0.26266545057296753
30-01-2023 05:07:29 INFO Epoch 1: [10363/10940] ---- BYOL Training Loss = 0.28546056151390076
30-01-2023 05:07:47 INFO Epoch 1: [10374/10940] ---- BYOL Training Loss = 0.3092832565307617
30-01-2023 05:08:06 INFO Epoch 1: [10385/10940] ---- BYOL Training Loss = 0.3039073348045349
30-01-2023 05:08:59 INFO Epoch 1: [10385/10940] ---- BYOL Validation Loss = 0.3005879521369934
30-01-2023 05:09:17 INFO Epoch 1: [10396/10940] ---- BYOL Training Loss = 0.30047059059143066
30-01-2023 05:09:36 INFO Epoch 1: [10407/10940] ---- BYOL Training Loss = 0.3047102093696594
30-01-2023 05:09:54 INFO Epoch 1: [10418/10940] ---- BYOL Training Loss = 0.3118038773536682
30-01-2023 05:10:13 INFO Epoch 1: [10429/10940] ---- BYOL Training Loss = 0.27821797132492065
30-01-2023 05:11:06 INFO Epoch 1: [10429/10940] ---- BYOL Validation Loss = 0.311218798160553
30-01-2023 05:11:24 INFO Epoch 1: [10440/10940] ---- BYOL Training Loss = 0.2640996277332306
30-01-2023 05:11:43 INFO Epoch 1: [10451/10940] ---- BYOL Training Loss = 0.31152716279029846
30-01-2023 05:12:02 INFO Epoch 1: [10462/10940] ---- BYOL Training Loss = 0.33763760328292847
30-01-2023 05:12:20 INFO Epoch 1: [10473/10940] ---- BYOL Training Loss = 0.3153274953365326
30-01-2023 05:13:13 INFO Epoch 1: [10473/10940] ---- BYOL Validation Loss = 0.31527599692344666
30-01-2023 05:13:31 INFO Epoch 1: [10484/10940] ---- BYOL Training Loss = 0.32205942273139954
30-01-2023 05:13:50 INFO Epoch 1: [10495/10940] ---- BYOL Training Loss = 0.33981263637542725
30-01-2023 05:14:09 INFO Epoch 1: [10506/10940] ---- BYOL Training Loss = 0.31333789229393005
30-01-2023 05:14:27 INFO Epoch 1: [10517/10940] ---- BYOL Training Loss = 0.32465288043022156
30-01-2023 05:15:20 INFO Epoch 1: [10517/10940] ---- BYOL Validation Loss = 0.3125157356262207
30-01-2023 05:15:38 INFO Epoch 1: [10528/10940] ---- BYOL Training Loss = 0.3226671516895294
30-01-2023 05:15:57 INFO Epoch 1: [10539/10940] ---- BYOL Training Loss = 0.28740355372428894
30-01-2023 05:16:15 INFO Epoch 1: [10550/10940] ---- BYOL Training Loss = 0.24535627663135529
30-01-2023 05:16:34 INFO Epoch 1: [10561/10940] ---- BYOL Training Loss = 0.2735534906387329
30-01-2023 05:17:27 INFO Epoch 1: [10561/10940] ---- BYOL Validation Loss = 0.3027653694152832
30-01-2023 05:17:45 INFO Epoch 1: [10572/10940] ---- BYOL Training Loss = 0.36087796092033386
30-01-2023 05:18:04 INFO Epoch 1: [10583/10940] ---- BYOL Training Loss = 0.3507249057292938
30-01-2023 05:18:23 INFO Epoch 1: [10594/10940] ---- BYOL Training Loss = 0.35079193115234375
30-01-2023 05:18:41 INFO Epoch 1: [10605/10940] ---- BYOL Training Loss = 0.33396658301353455
30-01-2023 05:19:34 INFO Epoch 1: [10605/10940] ---- BYOL Validation Loss = 0.308331161737442
30-01-2023 05:19:53 INFO Epoch 1: [10616/10940] ---- BYOL Training Loss = 0.2909502685070038
30-01-2023 05:20:11 INFO Epoch 1: [10627/10940] ---- BYOL Training Loss = 0.33641383051872253
30-01-2023 05:20:30 INFO Epoch 1: [10638/10940] ---- BYOL Training Loss = 0.3450010418891907
30-01-2023 05:20:48 INFO Epoch 1: [10649/10940] ---- BYOL Training Loss = 0.35170188546180725
30-01-2023 05:21:42 INFO Epoch 1: [10649/10940] ---- BYOL Validation Loss = 0.3147658705711365
30-01-2023 05:22:01 INFO Epoch 1: [10660/10940] ---- BYOL Training Loss = 0.34347230195999146
30-01-2023 05:22:19 INFO Epoch 1: [10671/10940] ---- BYOL Training Loss = 0.3019329607486725
30-01-2023 05:22:38 INFO Epoch 1: [10682/10940] ---- BYOL Training Loss = 0.2892170548439026
30-01-2023 05:22:56 INFO Epoch 1: [10693/10940] ---- BYOL Training Loss = 0.308224618434906
30-01-2023 05:23:49 INFO Epoch 1: [10693/10940] ---- BYOL Validation Loss = 0.312357097864151
30-01-2023 05:24:08 INFO Epoch 1: [10704/10940] ---- BYOL Training Loss = 0.3409053385257721
30-01-2023 05:24:26 INFO Epoch 1: [10715/10940] ---- BYOL Training Loss = 0.31163015961647034
30-01-2023 05:24:45 INFO Epoch 1: [10726/10940] ---- BYOL Training Loss = 0.30341339111328125
30-01-2023 05:25:04 INFO Epoch 1: [10737/10940] ---- BYOL Training Loss = 0.29566100239753723
30-01-2023 05:25:57 INFO Epoch 1: [10737/10940] ---- BYOL Validation Loss = 0.30397629737854004
30-01-2023 05:26:15 INFO Epoch 1: [10748/10940] ---- BYOL Training Loss = 0.31894344091415405
30-01-2023 05:26:34 INFO Epoch 1: [10759/10940] ---- BYOL Training Loss = 0.36046499013900757
30-01-2023 05:26:52 INFO Epoch 1: [10770/10940] ---- BYOL Training Loss = 0.3583300709724426
30-01-2023 05:27:11 INFO Epoch 1: [10781/10940] ---- BYOL Training Loss = 0.34005290269851685
30-01-2023 05:28:04 INFO Epoch 1: [10781/10940] ---- BYOL Validation Loss = 0.30864885449409485
30-01-2023 05:28:22 INFO Epoch 1: [10792/10940] ---- BYOL Training Loss = 0.28404372930526733
30-01-2023 05:28:41 INFO Epoch 1: [10803/10940] ---- BYOL Training Loss = 0.2896663248538971
30-01-2023 05:29:00 INFO Epoch 1: [10814/10940] ---- BYOL Training Loss = 0.3299826979637146
30-01-2023 05:29:19 INFO Epoch 1: [10825/10940] ---- BYOL Training Loss = 0.30477291345596313
30-01-2023 05:30:12 INFO Epoch 1: [10825/10940] ---- BYOL Validation Loss = 0.31461358070373535
30-01-2023 05:30:30 INFO Epoch 1: [10836/10940] ---- BYOL Training Loss = 0.2711631655693054
30-01-2023 05:30:49 INFO Epoch 1: [10847/10940] ---- BYOL Training Loss = 0.2729957103729248
30-01-2023 05:31:08 INFO Epoch 1: [10858/10940] ---- BYOL Training Loss = 0.2895974814891815
30-01-2023 05:31:26 INFO Epoch 1: [10869/10940] ---- BYOL Training Loss = 0.3269660770893097
30-01-2023 05:32:19 INFO Epoch 1: [10869/10940] ---- BYOL Validation Loss = 0.3135306239128113
30-01-2023 05:32:38 INFO Epoch 1: [10880/10940] ---- BYOL Training Loss = 0.3292333483695984
30-01-2023 05:32:56 INFO Epoch 1: [10891/10940] ---- BYOL Training Loss = 0.30860525369644165
30-01-2023 05:33:15 INFO Epoch 1: [10902/10940] ---- BYOL Training Loss = 0.3365009129047394
30-01-2023 05:33:33 INFO Epoch 1: [10913/10940] ---- BYOL Training Loss = 0.32121044397354126
30-01-2023 05:34:27 INFO Epoch 1: [10913/10940] ---- BYOL Validation Loss = 0.2998932898044586
30-01-2023 05:34:45 INFO Epoch 1: [10924/10940] ---- BYOL Training Loss = 0.326170951128006
30-01-2023 05:35:04 INFO Epoch 1: [10935/10940] ---- BYOL Training Loss = 0.3200991451740265
30-01-2023 05:35:13 INFO Starting Epoch: 2
30-01-2023 05:35:32 INFO Epoch 2: [12/10940] ---- BYOL Training Loss = 0.3241499066352844
30-01-2023 05:35:49 INFO Epoch 2: [23/10940] ---- BYOL Training Loss = 0.29168668389320374
30-01-2023 05:36:07 INFO Epoch 2: [34/10940] ---- BYOL Training Loss = 0.27736538648605347
30-01-2023 05:36:24 INFO Epoch 2: [45/10940] ---- BYOL Training Loss = 0.2704945206642151
30-01-2023 05:37:17 INFO Epoch 2: [45/10940] ---- BYOL Validation Loss = 0.30757763981819153
30-01-2023 05:37:34 INFO Epoch 2: [56/10940] ---- BYOL Training Loss = 0.288443386554718
30-01-2023 05:37:52 INFO Epoch 2: [67/10940] ---- BYOL Training Loss = 0.283789724111557
30-01-2023 05:38:09 INFO Epoch 2: [78/10940] ---- BYOL Training Loss = 0.3251972198486328
30-01-2023 05:38:27 INFO Epoch 2: [89/10940] ---- BYOL Training Loss = 0.3139916956424713
30-01-2023 05:39:20 INFO Epoch 2: [89/10940] ---- BYOL Validation Loss = 0.30663570761680603
30-01-2023 05:39:37 INFO Epoch 2: [100/10940] ---- BYOL Training Loss = 0.2722676396369934
30-01-2023 05:39:54 INFO Epoch 2: [111/10940] ---- BYOL Training Loss = 0.2754833400249481
30-01-2023 05:40:12 INFO Epoch 2: [122/10940] ---- BYOL Training Loss = 0.27129843831062317
30-01-2023 05:40:29 INFO Epoch 2: [133/10940] ---- BYOL Training Loss = 0.30970773100852966
30-01-2023 05:41:22 INFO Epoch 2: [133/10940] ---- BYOL Validation Loss = 0.30846524238586426
30-01-2023 05:41:40 INFO Epoch 2: [144/10940] ---- BYOL Training Loss = 0.34989041090011597
30-01-2023 05:41:57 INFO Epoch 2: [155/10940] ---- BYOL Training Loss = 0.3292751610279083
30-01-2023 05:42:15 INFO Epoch 2: [166/10940] ---- BYOL Training Loss = 0.3038780391216278
30-01-2023 05:42:32 INFO Epoch 2: [177/10940] ---- BYOL Training Loss = 0.28329190611839294
30-01-2023 05:43:25 INFO Epoch 2: [177/10940] ---- BYOL Validation Loss = 0.3111288249492645
30-01-2023 05:43:42 INFO Epoch 2: [188/10940] ---- BYOL Training Loss = 0.2842278778553009
30-01-2023 05:44:00 INFO Epoch 2: [199/10940] ---- BYOL Training Loss = 0.25116345286369324
30-01-2023 05:44:17 INFO Epoch 2: [210/10940] ---- BYOL Training Loss = 0.29447269439697266
30-01-2023 05:44:35 INFO Epoch 2: [221/10940] ---- BYOL Training Loss = 0.3131760060787201
30-01-2023 05:45:28 INFO Epoch 2: [221/10940] ---- BYOL Validation Loss = 0.3095495104789734
30-01-2023 05:45:45 INFO Epoch 2: [232/10940] ---- BYOL Training Loss = 0.3206806778907776
30-01-2023 05:46:02 INFO Epoch 2: [243/10940] ---- BYOL Training Loss = 0.2958516776561737
30-01-2023 05:46:20 INFO Epoch 2: [254/10940] ---- BYOL Training Loss = 0.2787701487541199
30-01-2023 05:46:37 INFO Epoch 2: [265/10940] ---- BYOL Training Loss = 0.2510526478290558
30-01-2023 05:47:30 INFO Epoch 2: [265/10940] ---- BYOL Validation Loss = 0.3089362680912018
30-01-2023 05:47:47 INFO Epoch 2: [276/10940] ---- BYOL Training Loss = 0.2763814330101013
30-01-2023 05:48:05 INFO Epoch 2: [287/10940] ---- BYOL Training Loss = 0.3322847783565521
30-01-2023 05:48:22 INFO Epoch 2: [298/10940] ---- BYOL Training Loss = 0.31504979729652405
30-01-2023 05:48:40 INFO Epoch 2: [309/10940] ---- BYOL Training Loss = 0.2998571991920471
30-01-2023 05:49:33 INFO Epoch 2: [309/10940] ---- BYOL Validation Loss = 0.3095793128013611
30-01-2023 05:49:50 INFO Epoch 2: [320/10940] ---- BYOL Training Loss = 0.30871012806892395
30-01-2023 05:50:08 INFO Epoch 2: [331/10940] ---- BYOL Training Loss = 0.29127585887908936
30-01-2023 05:50:26 INFO Epoch 2: [342/10940] ---- BYOL Training Loss = 0.3048841655254364
30-01-2023 05:50:43 INFO Epoch 2: [353/10940] ---- BYOL Training Loss = 0.3274739384651184
30-01-2023 05:51:36 INFO Epoch 2: [353/10940] ---- BYOL Validation Loss = 0.30907800793647766
30-01-2023 05:51:54 INFO Epoch 2: [364/10940] ---- BYOL Training Loss = 0.34882494807243347
30-01-2023 05:52:11 INFO Epoch 2: [375/10940] ---- BYOL Training Loss = 0.3318359851837158
30-01-2023 05:52:29 INFO Epoch 2: [386/10940] ---- BYOL Training Loss = 0.2697417140007019
30-01-2023 05:52:46 INFO Epoch 2: [397/10940] ---- BYOL Training Loss = 0.2982638478279114
30-01-2023 05:53:39 INFO Epoch 2: [397/10940] ---- BYOL Validation Loss = 0.3060004413127899
30-01-2023 05:53:57 INFO Epoch 2: [408/10940] ---- BYOL Training Loss = 0.2796143889427185
30-01-2023 05:54:14 INFO Epoch 2: [419/10940] ---- BYOL Training Loss = 0.28878137469291687
30-01-2023 05:54:32 INFO Epoch 2: [430/10940] ---- BYOL Training Loss = 0.32770323753356934
30-01-2023 05:54:49 INFO Epoch 2: [441/10940] ---- BYOL Training Loss = 0.3461964428424835
30-01-2023 05:55:42 INFO Epoch 2: [441/10940] ---- BYOL Validation Loss = 0.30299997329711914
30-01-2023 05:55:59 INFO Epoch 2: [452/10940] ---- BYOL Training Loss = 0.3457203209400177
30-01-2023 05:56:17 INFO Epoch 2: [463/10940] ---- BYOL Training Loss = 0.3412500023841858
30-01-2023 05:56:34 INFO Epoch 2: [474/10940] ---- BYOL Training Loss = 0.34163329005241394
30-01-2023 05:56:52 INFO Epoch 2: [485/10940] ---- BYOL Training Loss = 0.3225047290325165
30-01-2023 05:57:45 INFO Epoch 2: [485/10940] ---- BYOL Validation Loss = 0.30341434478759766
30-01-2023 05:58:02 INFO Epoch 2: [496/10940] ---- BYOL Training Loss = 0.2793961763381958
30-01-2023 05:58:20 INFO Epoch 2: [507/10940] ---- BYOL Training Loss = 0.28277990221977234
30-01-2023 05:58:37 INFO Epoch 2: [518/10940] ---- BYOL Training Loss = 0.2600720524787903
30-01-2023 05:58:55 INFO Epoch 2: [529/10940] ---- BYOL Training Loss = 0.30219292640686035
30-01-2023 05:59:48 INFO Epoch 2: [529/10940] ---- BYOL Validation Loss = 0.31099772453308105
30-01-2023 06:00:05 INFO Epoch 2: [540/10940] ---- BYOL Training Loss = 0.331582635641098
30-01-2023 06:00:23 INFO Epoch 2: [551/10940] ---- BYOL Training Loss = 0.27428755164146423
30-01-2023 06:00:40 INFO Epoch 2: [562/10940] ---- BYOL Training Loss = 0.2742219567298889
30-01-2023 06:00:58 INFO Epoch 2: [573/10940] ---- BYOL Training Loss = 0.27191489934921265
30-01-2023 06:01:51 INFO Epoch 2: [573/10940] ---- BYOL Validation Loss = 0.30219414830207825
30-01-2023 06:02:08 INFO Epoch 2: [584/10940] ---- BYOL Training Loss = 0.30053284764289856
30-01-2023 06:02:25 INFO Epoch 2: [595/10940] ---- BYOL Training Loss = 0.29668518900871277
30-01-2023 06:02:43 INFO Epoch 2: [606/10940] ---- BYOL Training Loss = 0.3164629638195038
30-01-2023 06:03:00 INFO Epoch 2: [617/10940] ---- BYOL Training Loss = 0.3248029947280884
30-01-2023 06:03:54 INFO Epoch 2: [617/10940] ---- BYOL Validation Loss = 0.30453401803970337
30-01-2023 06:04:11 INFO Epoch 2: [628/10940] ---- BYOL Training Loss = 0.324253648519516
30-01-2023 06:04:28 INFO Epoch 2: [639/10940] ---- BYOL Training Loss = 0.2975374758243561
30-01-2023 06:04:46 INFO Epoch 2: [650/10940] ---- BYOL Training Loss = 0.3065866529941559
30-01-2023 06:05:03 INFO Epoch 2: [661/10940] ---- BYOL Training Loss = 0.32382863759994507
30-01-2023 06:05:56 INFO Epoch 2: [661/10940] ---- BYOL Validation Loss = 0.2966257631778717
30-01-2023 06:06:14 INFO Epoch 2: [672/10940] ---- BYOL Training Loss = 0.2950421869754791
30-01-2023 06:06:31 INFO Epoch 2: [683/10940] ---- BYOL Training Loss = 0.2563648819923401
30-01-2023 06:06:48 INFO Epoch 2: [694/10940] ---- BYOL Training Loss = 0.2789398729801178
30-01-2023 06:07:06 INFO Epoch 2: [705/10940] ---- BYOL Training Loss = 0.3641931712627411
30-01-2023 06:07:59 INFO Epoch 2: [705/10940] ---- BYOL Validation Loss = 0.3047258257865906
30-01-2023 06:08:17 INFO Epoch 2: [716/10940] ---- BYOL Training Loss = 0.354808509349823
30-01-2023 06:08:34 INFO Epoch 2: [727/10940] ---- BYOL Training Loss = 0.28934159874916077
30-01-2023 06:08:52 INFO Epoch 2: [738/10940] ---- BYOL Training Loss = 0.27498507499694824
30-01-2023 06:09:09 INFO Epoch 2: [749/10940] ---- BYOL Training Loss = 0.3234420418739319
30-01-2023 06:10:02 INFO Epoch 2: [749/10940] ---- BYOL Validation Loss = 0.3098902404308319
30-01-2023 06:10:19 INFO Epoch 2: [760/10940] ---- BYOL Training Loss = 0.3639596104621887
30-01-2023 06:10:37 INFO Epoch 2: [771/10940] ---- BYOL Training Loss = 0.322234183549881
30-01-2023 06:10:55 INFO Epoch 2: [782/10940] ---- BYOL Training Loss = 0.2831297218799591
30-01-2023 06:11:13 INFO Epoch 2: [793/10940] ---- BYOL Training Loss = 0.26439088582992554
30-01-2023 06:12:05 INFO Epoch 2: [793/10940] ---- BYOL Validation Loss = 0.29403916001319885
30-01-2023 06:12:23 INFO Epoch 2: [804/10940] ---- BYOL Training Loss = 0.31604161858558655
30-01-2023 06:12:40 INFO Epoch 2: [815/10940] ---- BYOL Training Loss = 0.30944183468818665
30-01-2023 06:12:58 INFO Epoch 2: [826/10940] ---- BYOL Training Loss = 0.29968032240867615
30-01-2023 06:13:15 INFO Epoch 2: [837/10940] ---- BYOL Training Loss = 0.2729332447052002
30-01-2023 06:14:08 INFO Epoch 2: [837/10940] ---- BYOL Validation Loss = 0.3019894063472748
30-01-2023 06:14:25 INFO Epoch 2: [848/10940] ---- BYOL Training Loss = 0.2735862731933594
30-01-2023 06:14:43 INFO Epoch 2: [859/10940] ---- BYOL Training Loss = 0.2865990698337555
30-01-2023 06:15:01 INFO Epoch 2: [870/10940] ---- BYOL Training Loss = 0.24906019866466522
30-01-2023 06:15:18 INFO Epoch 2: [881/10940] ---- BYOL Training Loss = 0.2818501591682434
30-01-2023 06:16:11 INFO Epoch 2: [881/10940] ---- BYOL Validation Loss = 0.3051116466522217
30-01-2023 06:16:28 INFO Epoch 2: [892/10940] ---- BYOL Training Loss = 0.31754714250564575
30-01-2023 06:16:46 INFO Epoch 2: [903/10940] ---- BYOL Training Loss = 0.3239254653453827
30-01-2023 06:17:04 INFO Epoch 2: [914/10940] ---- BYOL Training Loss = 0.2655108869075775
30-01-2023 06:17:21 INFO Epoch 2: [925/10940] ---- BYOL Training Loss = 0.27145034074783325
30-01-2023 06:18:14 INFO Epoch 2: [925/10940] ---- BYOL Validation Loss = 0.2987061142921448
30-01-2023 06:18:31 INFO Epoch 2: [936/10940] ---- BYOL Training Loss = 0.28182703256607056
30-01-2023 06:18:49 INFO Epoch 2: [947/10940] ---- BYOL Training Loss = 0.26005202531814575
30-01-2023 06:19:06 INFO Epoch 2: [958/10940] ---- BYOL Training Loss = 0.3205152153968811
30-01-2023 06:19:24 INFO Epoch 2: [969/10940] ---- BYOL Training Loss = 0.3071405291557312
30-01-2023 06:20:17 INFO Epoch 2: [969/10940] ---- BYOL Validation Loss = 0.3063512444496155
30-01-2023 06:20:34 INFO Epoch 2: [980/10940] ---- BYOL Training Loss = 0.2786097228527069
30-01-2023 06:20:52 INFO Epoch 2: [991/10940] ---- BYOL Training Loss = 0.31794339418411255
30-01-2023 06:21:10 INFO Epoch 2: [1002/10940] ---- BYOL Training Loss = 0.26353615522384644
30-01-2023 06:21:27 INFO Epoch 2: [1013/10940] ---- BYOL Training Loss = 0.2295248955488205
30-01-2023 06:22:20 INFO Epoch 2: [1013/10940] ---- BYOL Validation Loss = 0.3000551760196686
30-01-2023 06:22:38 INFO Epoch 2: [1024/10940] ---- BYOL Training Loss = 0.2413521260023117
30-01-2023 06:22:55 INFO Epoch 2: [1035/10940] ---- BYOL Training Loss = 0.2885262966156006
30-01-2023 06:23:13 INFO Epoch 2: [1046/10940] ---- BYOL Training Loss = 0.2861243784427643
30-01-2023 06:23:30 INFO Epoch 2: [1057/10940] ---- BYOL Training Loss = 0.26989108324050903
30-01-2023 06:24:24 INFO Epoch 2: [1057/10940] ---- BYOL Validation Loss = 0.2944084703922272
30-01-2023 06:24:41 INFO Epoch 2: [1068/10940] ---- BYOL Training Loss = 0.28038671612739563
30-01-2023 06:24:58 INFO Epoch 2: [1079/10940] ---- BYOL Training Loss = 0.36461618542671204
30-01-2023 06:25:16 INFO Epoch 2: [1090/10940] ---- BYOL Training Loss = 0.4260402321815491
30-01-2023 06:25:34 INFO Epoch 2: [1101/10940] ---- BYOL Training Loss = 0.3583335280418396
30-01-2023 06:26:27 INFO Epoch 2: [1101/10940] ---- BYOL Validation Loss = 0.3087176978588104
30-01-2023 06:26:44 INFO Epoch 2: [1112/10940] ---- BYOL Training Loss = 0.34856992959976196
30-01-2023 06:27:01 INFO Epoch 2: [1123/10940] ---- BYOL Training Loss = 0.3488417863845825
30-01-2023 06:27:19 INFO Epoch 2: [1134/10940] ---- BYOL Training Loss = 0.3272555470466614
30-01-2023 06:27:36 INFO Epoch 2: [1145/10940] ---- BYOL Training Loss = 0.317733496427536
30-01-2023 06:28:30 INFO Epoch 2: [1145/10940] ---- BYOL Validation Loss = 0.31257301568984985
30-01-2023 06:28:47 INFO Epoch 2: [1156/10940] ---- BYOL Training Loss = 0.3128645122051239
30-01-2023 06:29:05 INFO Epoch 2: [1167/10940] ---- BYOL Training Loss = 0.31980961561203003
30-01-2023 06:29:22 INFO Epoch 2: [1178/10940] ---- BYOL Training Loss = 0.29654428362846375
30-01-2023 06:29:40 INFO Epoch 2: [1189/10940] ---- BYOL Training Loss = 0.325350284576416
30-01-2023 06:30:33 INFO Epoch 2: [1189/10940] ---- BYOL Validation Loss = 0.31227484345436096
30-01-2023 06:30:50 INFO Epoch 2: [1200/10940] ---- BYOL Training Loss = 0.32189884781837463
30-01-2023 06:31:08 INFO Epoch 2: [1211/10940] ---- BYOL Training Loss = 0.25679582357406616
30-01-2023 06:31:25 INFO Epoch 2: [1222/10940] ---- BYOL Training Loss = 0.2945202887058258
30-01-2023 06:31:43 INFO Epoch 2: [1233/10940] ---- BYOL Training Loss = 0.2865715026855469
30-01-2023 06:32:36 INFO Epoch 2: [1233/10940] ---- BYOL Validation Loss = 0.30833354592323303
30-01-2023 06:32:53 INFO Epoch 2: [1244/10940] ---- BYOL Training Loss = 0.28003737330436707
30-01-2023 06:33:11 INFO Epoch 2: [1255/10940] ---- BYOL Training Loss = 0.28961437940597534
30-01-2023 06:33:29 INFO Epoch 2: [1266/10940] ---- BYOL Training Loss = 0.25112825632095337
30-01-2023 06:33:46 INFO Epoch 2: [1277/10940] ---- BYOL Training Loss = 0.2458045780658722
30-01-2023 06:34:40 INFO Epoch 2: [1277/10940] ---- BYOL Validation Loss = 0.29979467391967773
30-01-2023 06:34:57 INFO Epoch 2: [1288/10940] ---- BYOL Training Loss = 0.24672389030456543
30-01-2023 06:35:15 INFO Epoch 2: [1299/10940] ---- BYOL Training Loss = 0.26027360558509827
30-01-2023 06:35:32 INFO Epoch 2: [1310/10940] ---- BYOL Training Loss = 0.2946436405181885
30-01-2023 06:35:50 INFO Epoch 2: [1321/10940] ---- BYOL Training Loss = 0.31044864654541016
30-01-2023 06:36:43 INFO Epoch 2: [1321/10940] ---- BYOL Validation Loss = 0.3044916093349457
30-01-2023 06:37:00 INFO Epoch 2: [1332/10940] ---- BYOL Training Loss = 0.2840126156806946
30-01-2023 06:37:17 INFO Epoch 2: [1343/10940] ---- BYOL Training Loss = 0.31415802240371704
30-01-2023 06:37:35 INFO Epoch 2: [1354/10940] ---- BYOL Training Loss = 0.36131322383880615
30-01-2023 06:37:52 INFO Epoch 2: [1365/10940] ---- BYOL Training Loss = 0.30894309282302856
30-01-2023 06:38:45 INFO Epoch 2: [1365/10940] ---- BYOL Validation Loss = 0.2987612187862396
30-01-2023 06:39:02 INFO Epoch 2: [1376/10940] ---- BYOL Training Loss = 0.2915661633014679
30-01-2023 06:39:20 INFO Epoch 2: [1387/10940] ---- BYOL Training Loss = 0.27416104078292847
30-01-2023 06:39:38 INFO Epoch 2: [1398/10940] ---- BYOL Training Loss = 0.2648617625236511
30-01-2023 06:39:55 INFO Epoch 2: [1409/10940] ---- BYOL Training Loss = 0.27417343854904175
30-01-2023 06:40:48 INFO Epoch 2: [1409/10940] ---- BYOL Validation Loss = 0.29815953969955444
30-01-2023 06:41:05 INFO Epoch 2: [1420/10940] ---- BYOL Training Loss = 0.28141289949417114
30-01-2023 06:41:23 INFO Epoch 2: [1431/10940] ---- BYOL Training Loss = 0.30216044187545776
30-01-2023 06:41:41 INFO Epoch 2: [1442/10940] ---- BYOL Training Loss = 0.29773348569869995
30-01-2023 06:41:58 INFO Epoch 2: [1453/10940] ---- BYOL Training Loss = 0.2691569924354553
30-01-2023 06:42:51 INFO Epoch 2: [1453/10940] ---- BYOL Validation Loss = 0.305084764957428
30-01-2023 06:43:09 INFO Epoch 2: [1464/10940] ---- BYOL Training Loss = 0.27145689725875854
30-01-2023 06:43:26 INFO Epoch 2: [1475/10940] ---- BYOL Training Loss = 0.2659229636192322
30-01-2023 06:43:44 INFO Epoch 2: [1486/10940] ---- BYOL Training Loss = 0.28239718079566956
30-01-2023 06:44:01 INFO Epoch 2: [1497/10940] ---- BYOL Training Loss = 0.28539153933525085
30-01-2023 06:44:54 INFO Epoch 2: [1497/10940] ---- BYOL Validation Loss = 0.303972065448761
30-01-2023 06:45:11 INFO Epoch 2: [1508/10940] ---- BYOL Training Loss = 0.29382258653640747
30-01-2023 06:45:29 INFO Epoch 2: [1519/10940] ---- BYOL Training Loss = 0.32518261671066284
30-01-2023 06:45:47 INFO Epoch 2: [1530/10940] ---- BYOL Training Loss = 0.29796677827835083
30-01-2023 06:46:05 INFO Epoch 2: [1541/10940] ---- BYOL Training Loss = 0.2633158266544342
30-01-2023 06:46:57 INFO Epoch 2: [1541/10940] ---- BYOL Validation Loss = 0.30000898241996765
30-01-2023 06:47:15 INFO Epoch 2: [1552/10940] ---- BYOL Training Loss = 0.25534510612487793
30-01-2023 06:47:32 INFO Epoch 2: [1563/10940] ---- BYOL Training Loss = 0.3075883686542511
30-01-2023 06:47:50 INFO Epoch 2: [1574/10940] ---- BYOL Training Loss = 0.2833016514778137
30-01-2023 06:48:08 INFO Epoch 2: [1585/10940] ---- BYOL Training Loss = 0.25102195143699646
30-01-2023 06:49:01 INFO Epoch 2: [1585/10940] ---- BYOL Validation Loss = 0.2990257441997528
30-01-2023 06:49:18 INFO Epoch 2: [1596/10940] ---- BYOL Training Loss = 0.2868211567401886
30-01-2023 06:49:36 INFO Epoch 2: [1607/10940] ---- BYOL Training Loss = 0.3205035328865051
30-01-2023 06:49:53 INFO Epoch 2: [1618/10940] ---- BYOL Training Loss = 0.2994082272052765
30-01-2023 06:50:11 INFO Epoch 2: [1629/10940] ---- BYOL Training Loss = 0.26654133200645447
30-01-2023 06:51:04 INFO Epoch 2: [1629/10940] ---- BYOL Validation Loss = 0.299170583486557
30-01-2023 06:51:22 INFO Epoch 2: [1640/10940] ---- BYOL Training Loss = 0.2696889638900757
30-01-2023 06:51:39 INFO Epoch 2: [1651/10940] ---- BYOL Training Loss = 0.28517574071884155
30-01-2023 06:51:57 INFO Epoch 2: [1662/10940] ---- BYOL Training Loss = 0.3300730586051941
30-01-2023 06:52:15 INFO Epoch 2: [1673/10940] ---- BYOL Training Loss = 0.3310638666152954
30-01-2023 06:53:08 INFO Epoch 2: [1673/10940] ---- BYOL Validation Loss = 0.30799955129623413
30-01-2023 06:53:25 INFO Epoch 2: [1684/10940] ---- BYOL Training Loss = 0.3067644238471985
30-01-2023 06:53:43 INFO Epoch 2: [1695/10940] ---- BYOL Training Loss = 0.3081366717815399
30-01-2023 06:54:00 INFO Epoch 2: [1706/10940] ---- BYOL Training Loss = 0.31918174028396606
30-01-2023 06:54:18 INFO Epoch 2: [1717/10940] ---- BYOL Training Loss = 0.3176545798778534
30-01-2023 06:55:11 INFO Epoch 2: [1717/10940] ---- BYOL Validation Loss = 0.30519500374794006
30-01-2023 06:55:28 INFO Epoch 2: [1728/10940] ---- BYOL Training Loss = 0.324739009141922
30-01-2023 06:55:46 INFO Epoch 2: [1739/10940] ---- BYOL Training Loss = 0.3006824553012848
30-01-2023 06:56:04 INFO Epoch 2: [1750/10940] ---- BYOL Training Loss = 0.2963583469390869
30-01-2023 06:56:21 INFO Epoch 2: [1761/10940] ---- BYOL Training Loss = 0.28580576181411743
30-01-2023 06:57:14 INFO Epoch 2: [1761/10940] ---- BYOL Validation Loss = 0.30134686827659607
30-01-2023 06:57:32 INFO Epoch 2: [1772/10940] ---- BYOL Training Loss = 0.2750830352306366
30-01-2023 06:57:50 INFO Epoch 2: [1783/10940] ---- BYOL Training Loss = 0.2768539488315582
30-01-2023 06:58:08 INFO Epoch 2: [1794/10940] ---- BYOL Training Loss = 0.3080674707889557
30-01-2023 06:58:25 INFO Epoch 2: [1805/10940] ---- BYOL Training Loss = 0.31832563877105713
30-01-2023 06:59:18 INFO Epoch 2: [1805/10940] ---- BYOL Validation Loss = 0.29041147232055664
30-01-2023 06:59:36 INFO Epoch 2: [1816/10940] ---- BYOL Training Loss = 0.2972666323184967
30-01-2023 06:59:53 INFO Epoch 2: [1827/10940] ---- BYOL Training Loss = 0.3425639271736145
30-01-2023 07:00:11 INFO Epoch 2: [1838/10940] ---- BYOL Training Loss = 0.32384517788887024
30-01-2023 07:00:28 INFO Epoch 2: [1849/10940] ---- BYOL Training Loss = 0.3167642056941986
30-01-2023 07:01:22 INFO Epoch 2: [1849/10940] ---- BYOL Validation Loss = 0.2935323119163513
30-01-2023 07:01:39 INFO Epoch 2: [1860/10940] ---- BYOL Training Loss = 0.37135830521583557
30-01-2023 07:01:57 INFO Epoch 2: [1871/10940] ---- BYOL Training Loss = 0.34296688437461853
30-01-2023 07:02:14 INFO Epoch 2: [1882/10940] ---- BYOL Training Loss = 0.2921440005302429
30-01-2023 07:02:32 INFO Epoch 2: [1893/10940] ---- BYOL Training Loss = 0.2972416281700134
30-01-2023 07:03:25 INFO Epoch 2: [1893/10940] ---- BYOL Validation Loss = 0.29756927490234375
30-01-2023 07:03:43 INFO Epoch 2: [1904/10940] ---- BYOL Training Loss = 0.30952566862106323
30-01-2023 07:04:00 INFO Epoch 2: [1915/10940] ---- BYOL Training Loss = 0.2894238829612732
30-01-2023 07:04:18 INFO Epoch 2: [1926/10940] ---- BYOL Training Loss = 0.3051891624927521
30-01-2023 07:04:36 INFO Epoch 2: [1937/10940] ---- BYOL Training Loss = 0.274779736995697
30-01-2023 07:05:29 INFO Epoch 2: [1937/10940] ---- BYOL Validation Loss = 0.28854820132255554
30-01-2023 07:05:46 INFO Epoch 2: [1948/10940] ---- BYOL Training Loss = 0.2717705965042114
30-01-2023 07:06:04 INFO Epoch 2: [1959/10940] ---- BYOL Training Loss = 0.3230171799659729
30-01-2023 07:06:22 INFO Epoch 2: [1970/10940] ---- BYOL Training Loss = 0.3629620671272278
30-01-2023 07:06:39 INFO Epoch 2: [1981/10940] ---- BYOL Training Loss = 0.3159463107585907
30-01-2023 07:07:33 INFO Epoch 2: [1981/10940] ---- BYOL Validation Loss = 0.29685714840888977
30-01-2023 07:07:50 INFO Epoch 2: [1992/10940] ---- BYOL Training Loss = 0.2969147562980652
30-01-2023 07:08:08 INFO Epoch 2: [2003/10940] ---- BYOL Training Loss = 0.31296494603157043
30-01-2023 07:08:26 INFO Epoch 2: [2014/10940] ---- BYOL Training Loss = 0.27465564012527466
30-01-2023 07:08:43 INFO Epoch 2: [2025/10940] ---- BYOL Training Loss = 0.2692967355251312
30-01-2023 07:09:36 INFO Epoch 2: [2025/10940] ---- BYOL Validation Loss = 0.30638089776039124
30-01-2023 07:09:54 INFO Epoch 2: [2036/10940] ---- BYOL Training Loss = 0.2974016070365906
30-01-2023 07:10:11 INFO Epoch 2: [2047/10940] ---- BYOL Training Loss = 0.3213154375553131
30-01-2023 07:10:29 INFO Epoch 2: [2058/10940] ---- BYOL Training Loss = 0.3246222138404846
30-01-2023 07:10:46 INFO Epoch 2: [2069/10940] ---- BYOL Training Loss = 0.2711181044578552
30-01-2023 07:11:40 INFO Epoch 2: [2069/10940] ---- BYOL Validation Loss = 0.2942456901073456
30-01-2023 07:11:57 INFO Epoch 2: [2080/10940] ---- BYOL Training Loss = 0.24055707454681396
30-01-2023 07:12:15 INFO Epoch 2: [2091/10940] ---- BYOL Training Loss = 0.27850282192230225
30-01-2023 07:12:33 INFO Epoch 2: [2102/10940] ---- BYOL Training Loss = 0.3012836277484894
30-01-2023 07:12:51 INFO Epoch 2: [2113/10940] ---- BYOL Training Loss = 0.31739598512649536
30-01-2023 07:13:44 INFO Epoch 2: [2113/10940] ---- BYOL Validation Loss = 0.29662635922431946
30-01-2023 07:14:01 INFO Epoch 2: [2124/10940] ---- BYOL Training Loss = 0.3961411714553833
30-01-2023 07:14:19 INFO Epoch 2: [2135/10940] ---- BYOL Training Loss = 0.3510371148586273
30-01-2023 07:14:36 INFO Epoch 2: [2146/10940] ---- BYOL Training Loss = 0.27264833450317383
30-01-2023 07:14:54 INFO Epoch 2: [2157/10940] ---- BYOL Training Loss = 0.25378018617630005
30-01-2023 07:15:47 INFO Epoch 2: [2157/10940] ---- BYOL Validation Loss = 0.30149999260902405
30-01-2023 07:16:05 INFO Epoch 2: [2168/10940] ---- BYOL Training Loss = 0.29672104120254517
30-01-2023 07:16:22 INFO Epoch 2: [2179/10940] ---- BYOL Training Loss = 0.33021873235702515
30-01-2023 07:16:40 INFO Epoch 2: [2190/10940] ---- BYOL Training Loss = 0.31907856464385986
30-01-2023 07:16:57 INFO Epoch 2: [2201/10940] ---- BYOL Training Loss = 0.29059848189353943
30-01-2023 07:17:51 INFO Epoch 2: [2201/10940] ---- BYOL Validation Loss = 0.3110901415348053
30-01-2023 07:18:08 INFO Epoch 2: [2212/10940] ---- BYOL Training Loss = 0.2437889128923416
30-01-2023 07:18:26 INFO Epoch 2: [2223/10940] ---- BYOL Training Loss = 0.24485819041728973
30-01-2023 07:18:43 INFO Epoch 2: [2234/10940] ---- BYOL Training Loss = 0.2680737376213074
30-01-2023 07:19:01 INFO Epoch 2: [2245/10940] ---- BYOL Training Loss = 0.30453383922576904
30-01-2023 07:19:54 INFO Epoch 2: [2245/10940] ---- BYOL Validation Loss = 0.2969457805156708
30-01-2023 07:20:12 INFO Epoch 2: [2256/10940] ---- BYOL Training Loss = 0.2833464741706848
30-01-2023 07:20:29 INFO Epoch 2: [2267/10940] ---- BYOL Training Loss = 0.3101816177368164
30-01-2023 07:20:47 INFO Epoch 2: [2278/10940] ---- BYOL Training Loss = 0.32206812500953674
30-01-2023 07:21:05 INFO Epoch 2: [2289/10940] ---- BYOL Training Loss = 0.30647218227386475
30-01-2023 07:21:58 INFO Epoch 2: [2289/10940] ---- BYOL Validation Loss = 0.2993916869163513
30-01-2023 07:22:15 INFO Epoch 2: [2300/10940] ---- BYOL Training Loss = 0.31051427125930786
30-01-2023 07:22:33 INFO Epoch 2: [2311/10940] ---- BYOL Training Loss = 0.29997873306274414
30-01-2023 07:22:51 INFO Epoch 2: [2322/10940] ---- BYOL Training Loss = 0.2805524170398712
30-01-2023 07:23:08 INFO Epoch 2: [2333/10940] ---- BYOL Training Loss = 0.2816457748413086
30-01-2023 07:24:01 INFO Epoch 2: [2333/10940] ---- BYOL Validation Loss = 0.30592483282089233
30-01-2023 07:24:18 INFO Epoch 2: [2344/10940] ---- BYOL Training Loss = 0.2988353967666626
30-01-2023 07:24:36 INFO Epoch 2: [2355/10940] ---- BYOL Training Loss = 0.2673448920249939
30-01-2023 07:24:54 INFO Epoch 2: [2366/10940] ---- BYOL Training Loss = 0.3110659420490265
30-01-2023 07:25:12 INFO Epoch 2: [2377/10940] ---- BYOL Training Loss = 0.3185134530067444
30-01-2023 07:26:05 INFO Epoch 2: [2377/10940] ---- BYOL Validation Loss = 0.29817819595336914
30-01-2023 07:26:22 INFO Epoch 2: [2388/10940] ---- BYOL Training Loss = 0.2946155369281769
30-01-2023 07:26:40 INFO Epoch 2: [2399/10940] ---- BYOL Training Loss = 0.28539353609085083
30-01-2023 07:26:58 INFO Epoch 2: [2410/10940] ---- BYOL Training Loss = 0.29906919598579407
30-01-2023 07:27:15 INFO Epoch 2: [2421/10940] ---- BYOL Training Loss = 0.33698850870132446
30-01-2023 07:28:09 INFO Epoch 2: [2421/10940] ---- BYOL Validation Loss = 0.30153825879096985
30-01-2023 07:28:26 INFO Epoch 2: [2432/10940] ---- BYOL Training Loss = 0.3044384717941284
30-01-2023 07:28:44 INFO Epoch 2: [2443/10940] ---- BYOL Training Loss = 0.2864868640899658
30-01-2023 07:29:01 INFO Epoch 2: [2454/10940] ---- BYOL Training Loss = 0.29606741666793823
30-01-2023 07:29:19 INFO Epoch 2: [2465/10940] ---- BYOL Training Loss = 0.30161404609680176
30-01-2023 07:30:12 INFO Epoch 2: [2465/10940] ---- BYOL Validation Loss = 0.31270673871040344
30-01-2023 07:30:29 INFO Epoch 2: [2476/10940] ---- BYOL Training Loss = 0.2886214852333069
30-01-2023 07:30:47 INFO Epoch 2: [2487/10940] ---- BYOL Training Loss = 0.27339500188827515
30-01-2023 07:31:05 INFO Epoch 2: [2498/10940] ---- BYOL Training Loss = 0.26529398560523987
30-01-2023 07:31:23 INFO Epoch 2: [2509/10940] ---- BYOL Training Loss = 0.3006539046764374
30-01-2023 07:32:16 INFO Epoch 2: [2509/10940] ---- BYOL Validation Loss = 0.30219635367393494
30-01-2023 07:32:34 INFO Epoch 2: [2520/10940] ---- BYOL Training Loss = 0.29842421412467957
30-01-2023 07:32:51 INFO Epoch 2: [2531/10940] ---- BYOL Training Loss = 0.32422128319740295
30-01-2023 07:33:09 INFO Epoch 2: [2542/10940] ---- BYOL Training Loss = 0.3280194401741028
30-01-2023 07:33:27 INFO Epoch 2: [2553/10940] ---- BYOL Training Loss = 0.2770135998725891
30-01-2023 07:34:20 INFO Epoch 2: [2553/10940] ---- BYOL Validation Loss = 0.29775068163871765
30-01-2023 07:34:37 INFO Epoch 2: [2564/10940] ---- BYOL Training Loss = 0.2718585729598999
30-01-2023 07:34:55 INFO Epoch 2: [2575/10940] ---- BYOL Training Loss = 0.2717096209526062
30-01-2023 07:35:12 INFO Epoch 2: [2586/10940] ---- BYOL Training Loss = 0.270040363073349
30-01-2023 07:35:30 INFO Epoch 2: [2597/10940] ---- BYOL Training Loss = 0.2805771827697754
30-01-2023 07:36:23 INFO Epoch 2: [2597/10940] ---- BYOL Validation Loss = 0.2948114573955536
30-01-2023 07:36:41 INFO Epoch 2: [2608/10940] ---- BYOL Training Loss = 0.27589982748031616
30-01-2023 07:36:58 INFO Epoch 2: [2619/10940] ---- BYOL Training Loss = 0.26848742365837097
30-01-2023 07:37:17 INFO Epoch 2: [2630/10940] ---- BYOL Training Loss = 0.2995244562625885
30-01-2023 07:37:34 INFO Epoch 2: [2641/10940] ---- BYOL Training Loss = 0.27284950017929077
30-01-2023 07:38:27 INFO Epoch 2: [2641/10940] ---- BYOL Validation Loss = 0.29031091928482056
30-01-2023 07:38:45 INFO Epoch 2: [2652/10940] ---- BYOL Training Loss = 0.2706579864025116
30-01-2023 07:39:03 INFO Epoch 2: [2663/10940] ---- BYOL Training Loss = 0.27852120995521545
30-01-2023 07:39:20 INFO Epoch 2: [2674/10940] ---- BYOL Training Loss = 0.31605538725852966
30-01-2023 07:39:38 INFO Epoch 2: [2685/10940] ---- BYOL Training Loss = 0.2834022343158722
30-01-2023 07:40:31 INFO Epoch 2: [2685/10940] ---- BYOL Validation Loss = 0.30264124274253845
30-01-2023 07:40:48 INFO Epoch 2: [2696/10940] ---- BYOL Training Loss = 0.2566410005092621
30-01-2023 07:41:06 INFO Epoch 2: [2707/10940] ---- BYOL Training Loss = 0.2884218990802765
30-01-2023 07:41:23 INFO Epoch 2: [2718/10940] ---- BYOL Training Loss = 0.2937048673629761
30-01-2023 07:41:42 INFO Epoch 2: [2729/10940] ---- BYOL Training Loss = 0.2882993519306183
30-01-2023 07:42:35 INFO Epoch 2: [2729/10940] ---- BYOL Validation Loss = 0.2931850850582123
30-01-2023 07:42:52 INFO Epoch 2: [2740/10940] ---- BYOL Training Loss = 0.31666669249534607
30-01-2023 07:43:10 INFO Epoch 2: [2751/10940] ---- BYOL Training Loss = 0.3537689447402954
30-01-2023 07:43:27 INFO Epoch 2: [2762/10940] ---- BYOL Training Loss = 0.31990498304367065
30-01-2023 07:43:45 INFO Epoch 2: [2773/10940] ---- BYOL Training Loss = 0.2631337642669678
30-01-2023 07:44:38 INFO Epoch 2: [2773/10940] ---- BYOL Validation Loss = 0.2982946038246155
30-01-2023 07:44:55 INFO Epoch 2: [2784/10940] ---- BYOL Training Loss = 0.2836102545261383
30-01-2023 07:45:13 INFO Epoch 2: [2795/10940] ---- BYOL Training Loss = 0.2907867729663849
30-01-2023 07:45:31 INFO Epoch 2: [2806/10940] ---- BYOL Training Loss = 0.3113362193107605
30-01-2023 07:45:49 INFO Epoch 2: [2817/10940] ---- BYOL Training Loss = 0.2842079997062683
30-01-2023 07:46:42 INFO Epoch 2: [2817/10940] ---- BYOL Validation Loss = 0.2969934642314911
30-01-2023 07:47:00 INFO Epoch 2: [2828/10940] ---- BYOL Training Loss = 0.27920442819595337
30-01-2023 07:47:18 INFO Epoch 2: [2839/10940] ---- BYOL Training Loss = 0.2853180766105652
30-01-2023 07:47:35 INFO Epoch 2: [2850/10940] ---- BYOL Training Loss = 0.2742181420326233
30-01-2023 07:47:53 INFO Epoch 2: [2861/10940] ---- BYOL Training Loss = 0.28795039653778076
30-01-2023 07:48:46 INFO Epoch 2: [2861/10940] ---- BYOL Validation Loss = 0.2899951934814453
30-01-2023 07:49:04 INFO Epoch 2: [2872/10940] ---- BYOL Training Loss = 0.3030739426612854
30-01-2023 07:49:21 INFO Epoch 2: [2883/10940] ---- BYOL Training Loss = 0.3224777579307556
30-01-2023 07:49:39 INFO Epoch 2: [2894/10940] ---- BYOL Training Loss = 0.33176225423812866
30-01-2023 07:49:57 INFO Epoch 2: [2905/10940] ---- BYOL Training Loss = 0.27301713824272156
30-01-2023 07:50:50 INFO Epoch 2: [2905/10940] ---- BYOL Validation Loss = 0.29901012778282166
30-01-2023 07:51:07 INFO Epoch 2: [2916/10940] ---- BYOL Training Loss = 0.26167088747024536
30-01-2023 07:51:25 INFO Epoch 2: [2927/10940] ---- BYOL Training Loss = 0.3004710078239441
30-01-2023 07:51:43 INFO Epoch 2: [2938/10940] ---- BYOL Training Loss = 0.33034974336624146
30-01-2023 07:52:01 INFO Epoch 2: [2949/10940] ---- BYOL Training Loss = 0.30855873227119446
30-01-2023 07:52:54 INFO Epoch 2: [2949/10940] ---- BYOL Validation Loss = 0.2948934733867645
30-01-2023 07:53:11 INFO Epoch 2: [2960/10940] ---- BYOL Training Loss = 0.2794307768344879
30-01-2023 07:53:29 INFO Epoch 2: [2971/10940] ---- BYOL Training Loss = 0.3256811201572418
30-01-2023 07:53:47 INFO Epoch 2: [2982/10940] ---- BYOL Training Loss = 0.36058253049850464
30-01-2023 07:54:04 INFO Epoch 2: [2993/10940] ---- BYOL Training Loss = 0.3546600043773651
30-01-2023 07:54:58 INFO Epoch 2: [2993/10940] ---- BYOL Validation Loss = 0.2917809784412384
30-01-2023 07:55:15 INFO Epoch 2: [3004/10940] ---- BYOL Training Loss = 0.32057732343673706
30-01-2023 07:55:33 INFO Epoch 2: [3015/10940] ---- BYOL Training Loss = 0.2861554026603699
30-01-2023 07:55:51 INFO Epoch 2: [3026/10940] ---- BYOL Training Loss = 0.26550623774528503
30-01-2023 07:56:09 INFO Epoch 2: [3037/10940] ---- BYOL Training Loss = 0.31019943952560425
30-01-2023 07:57:02 INFO Epoch 2: [3037/10940] ---- BYOL Validation Loss = 0.2986104190349579
30-01-2023 07:57:19 INFO Epoch 2: [3048/10940] ---- BYOL Training Loss = 0.3364207148551941
30-01-2023 07:57:37 INFO Epoch 2: [3059/10940] ---- BYOL Training Loss = 0.30344313383102417
30-01-2023 07:57:55 INFO Epoch 2: [3070/10940] ---- BYOL Training Loss = 0.3044983744621277
30-01-2023 07:58:12 INFO Epoch 2: [3081/10940] ---- BYOL Training Loss = 0.30175668001174927
30-01-2023 07:59:06 INFO Epoch 2: [3081/10940] ---- BYOL Validation Loss = 0.297201931476593
30-01-2023 07:59:23 INFO Epoch 2: [3092/10940] ---- BYOL Training Loss = 0.2678321301937103
30-01-2023 07:59:41 INFO Epoch 2: [3103/10940] ---- BYOL Training Loss = 0.3205868899822235
30-01-2023 07:59:59 INFO Epoch 2: [3114/10940] ---- BYOL Training Loss = 0.3436340391635895
30-01-2023 08:00:16 INFO Epoch 2: [3125/10940] ---- BYOL Training Loss = 0.28351110219955444
30-01-2023 08:01:10 INFO Epoch 2: [3125/10940] ---- BYOL Validation Loss = 0.2934306561946869
30-01-2023 08:01:27 INFO Epoch 2: [3136/10940] ---- BYOL Training Loss = 0.29664239287376404
30-01-2023 08:01:45 INFO Epoch 2: [3147/10940] ---- BYOL Training Loss = 0.3287549912929535
30-01-2023 08:02:03 INFO Epoch 2: [3158/10940] ---- BYOL Training Loss = 0.3106713891029358
30-01-2023 08:02:20 INFO Epoch 2: [3169/10940] ---- BYOL Training Loss = 0.28699225187301636
30-01-2023 08:03:14 INFO Epoch 2: [3169/10940] ---- BYOL Validation Loss = 0.2994866371154785
30-01-2023 08:03:31 INFO Epoch 2: [3180/10940] ---- BYOL Training Loss = 0.3045472502708435
30-01-2023 08:03:49 INFO Epoch 2: [3191/10940] ---- BYOL Training Loss = 0.32543009519577026
30-01-2023 08:04:07 INFO Epoch 2: [3202/10940] ---- BYOL Training Loss = 0.31890997290611267
30-01-2023 08:04:25 INFO Epoch 2: [3213/10940] ---- BYOL Training Loss = 0.27255159616470337
30-01-2023 08:05:18 INFO Epoch 2: [3213/10940] ---- BYOL Validation Loss = 0.2948644757270813
30-01-2023 08:05:35 INFO Epoch 2: [3224/10940] ---- BYOL Training Loss = 0.26954203844070435
30-01-2023 08:05:53 INFO Epoch 2: [3235/10940] ---- BYOL Training Loss = 0.30734914541244507
30-01-2023 08:06:11 INFO Epoch 2: [3246/10940] ---- BYOL Training Loss = 0.29891374707221985
30-01-2023 08:06:28 INFO Epoch 2: [3257/10940] ---- BYOL Training Loss = 0.2993502616882324
30-01-2023 08:07:21 INFO Epoch 2: [3257/10940] ---- BYOL Validation Loss = 0.2985399067401886
30-01-2023 08:07:39 INFO Epoch 2: [3268/10940] ---- BYOL Training Loss = 0.31879669427871704
30-01-2023 08:07:57 INFO Epoch 2: [3279/10940] ---- BYOL Training Loss = 0.32290714979171753
30-01-2023 08:08:14 INFO Epoch 2: [3290/10940] ---- BYOL Training Loss = 0.3239006996154785
30-01-2023 08:08:32 INFO Epoch 2: [3301/10940] ---- BYOL Training Loss = 0.31609776616096497
30-01-2023 08:09:25 INFO Epoch 2: [3301/10940] ---- BYOL Validation Loss = 0.2989024221897125
30-01-2023 08:09:43 INFO Epoch 2: [3312/10940] ---- BYOL Training Loss = 0.2775237560272217
30-01-2023 08:10:01 INFO Epoch 2: [3323/10940] ---- BYOL Training Loss = 0.2787858843803406
30-01-2023 08:10:18 INFO Epoch 2: [3334/10940] ---- BYOL Training Loss = 0.29857200384140015
30-01-2023 08:10:36 INFO Epoch 2: [3345/10940] ---- BYOL Training Loss = 0.3141842782497406
30-01-2023 08:11:29 INFO Epoch 2: [3345/10940] ---- BYOL Validation Loss = 0.29303812980651855
30-01-2023 08:11:47 INFO Epoch 2: [3356/10940] ---- BYOL Training Loss = 0.29417309165000916
30-01-2023 08:12:05 INFO Epoch 2: [3367/10940] ---- BYOL Training Loss = 0.3254556655883789
30-01-2023 08:12:22 INFO Epoch 2: [3378/10940] ---- BYOL Training Loss = 0.3363342583179474
30-01-2023 08:12:40 INFO Epoch 2: [3389/10940] ---- BYOL Training Loss = 0.27249082922935486
30-01-2023 08:13:33 INFO Epoch 2: [3389/10940] ---- BYOL Validation Loss = 0.28466346859931946
30-01-2023 08:13:51 INFO Epoch 2: [3400/10940] ---- BYOL Training Loss = 0.26389598846435547
30-01-2023 08:14:08 INFO Epoch 2: [3411/10940] ---- BYOL Training Loss = 0.32283592224121094
30-01-2023 08:14:27 INFO Epoch 2: [3422/10940] ---- BYOL Training Loss = 0.3133334815502167
30-01-2023 08:14:44 INFO Epoch 2: [3433/10940] ---- BYOL Training Loss = 0.3438391089439392
30-01-2023 08:15:38 INFO Epoch 2: [3433/10940] ---- BYOL Validation Loss = 0.2987315356731415
30-01-2023 08:15:55 INFO Epoch 2: [3444/10940] ---- BYOL Training Loss = 0.3564102351665497
30-01-2023 08:16:13 INFO Epoch 2: [3455/10940] ---- BYOL Training Loss = 0.32029324769973755
30-01-2023 08:16:30 INFO Epoch 2: [3466/10940] ---- BYOL Training Loss = 0.35131746530532837
30-01-2023 08:16:48 INFO Epoch 2: [3477/10940] ---- BYOL Training Loss = 0.3263930082321167
30-01-2023 08:17:41 INFO Epoch 2: [3477/10940] ---- BYOL Validation Loss = 0.2990188002586365
30-01-2023 08:17:59 INFO Epoch 2: [3488/10940] ---- BYOL Training Loss = 0.2762649655342102
30-01-2023 08:18:17 INFO Epoch 2: [3499/10940] ---- BYOL Training Loss = 0.30038395524024963
30-01-2023 08:18:35 INFO Epoch 2: [3510/10940] ---- BYOL Training Loss = 0.3170675039291382
30-01-2023 08:18:53 INFO Epoch 2: [3521/10940] ---- BYOL Training Loss = 0.324830025434494
30-01-2023 08:19:46 INFO Epoch 2: [3521/10940] ---- BYOL Validation Loss = 0.30149248242378235
30-01-2023 08:20:03 INFO Epoch 2: [3532/10940] ---- BYOL Training Loss = 0.3312378227710724
30-01-2023 08:20:21 INFO Epoch 2: [3543/10940] ---- BYOL Training Loss = 0.3192562460899353
30-01-2023 08:20:39 INFO Epoch 2: [3554/10940] ---- BYOL Training Loss = 0.2592813968658447
30-01-2023 08:20:56 INFO Epoch 2: [3565/10940] ---- BYOL Training Loss = 0.2369128167629242
30-01-2023 08:21:50 INFO Epoch 2: [3565/10940] ---- BYOL Validation Loss = 0.2864179015159607
30-01-2023 08:22:07 INFO Epoch 2: [3576/10940] ---- BYOL Training Loss = 0.27952122688293457
30-01-2023 08:22:25 INFO Epoch 2: [3587/10940] ---- BYOL Training Loss = 0.29243072867393494
30-01-2023 08:22:43 INFO Epoch 2: [3598/10940] ---- BYOL Training Loss = 0.2909316122531891
30-01-2023 08:23:01 INFO Epoch 2: [3609/10940] ---- BYOL Training Loss = 0.2570091485977173
30-01-2023 08:23:54 INFO Epoch 2: [3609/10940] ---- BYOL Validation Loss = 0.2913079261779785
30-01-2023 08:24:11 INFO Epoch 2: [3620/10940] ---- BYOL Training Loss = 0.2565682530403137
30-01-2023 08:24:29 INFO Epoch 2: [3631/10940] ---- BYOL Training Loss = 0.27654772996902466
30-01-2023 08:24:47 INFO Epoch 2: [3642/10940] ---- BYOL Training Loss = 0.28070634603500366
30-01-2023 08:25:05 INFO Epoch 2: [3653/10940] ---- BYOL Training Loss = 0.33098703622817993
30-01-2023 08:25:58 INFO Epoch 2: [3653/10940] ---- BYOL Validation Loss = 0.2850455343723297
30-01-2023 08:26:16 INFO Epoch 2: [3664/10940] ---- BYOL Training Loss = 0.2805168032646179
30-01-2023 08:26:33 INFO Epoch 2: [3675/10940] ---- BYOL Training Loss = 0.28015756607055664
30-01-2023 08:26:51 INFO Epoch 2: [3686/10940] ---- BYOL Training Loss = 0.3171842396259308
30-01-2023 08:27:09 INFO Epoch 2: [3697/10940] ---- BYOL Training Loss = 0.31166014075279236
30-01-2023 08:28:02 INFO Epoch 2: [3697/10940] ---- BYOL Validation Loss = 0.2856721580028534
30-01-2023 08:28:19 INFO Epoch 2: [3708/10940] ---- BYOL Training Loss = 0.31516221165657043
30-01-2023 08:28:37 INFO Epoch 2: [3719/10940] ---- BYOL Training Loss = 0.3178880214691162
30-01-2023 08:28:55 INFO Epoch 2: [3730/10940] ---- BYOL Training Loss = 0.27783194184303284
30-01-2023 08:29:13 INFO Epoch 2: [3741/10940] ---- BYOL Training Loss = 0.3015947937965393
30-01-2023 08:30:06 INFO Epoch 2: [3741/10940] ---- BYOL Validation Loss = 0.29254812002182007
30-01-2023 08:30:24 INFO Epoch 2: [3752/10940] ---- BYOL Training Loss = 0.33130544424057007
30-01-2023 08:30:41 INFO Epoch 2: [3763/10940] ---- BYOL Training Loss = 0.29516011476516724
30-01-2023 08:30:59 INFO Epoch 2: [3774/10940] ---- BYOL Training Loss = 0.2638464570045471
30-01-2023 08:31:17 INFO Epoch 2: [3785/10940] ---- BYOL Training Loss = 0.30040302872657776
30-01-2023 08:32:10 INFO Epoch 2: [3785/10940] ---- BYOL Validation Loss = 0.2891879081726074
30-01-2023 08:32:28 INFO Epoch 2: [3796/10940] ---- BYOL Training Loss = 0.33387845754623413
30-01-2023 08:32:46 INFO Epoch 2: [3807/10940] ---- BYOL Training Loss = 0.2929539978504181
30-01-2023 08:33:03 INFO Epoch 2: [3818/10940] ---- BYOL Training Loss = 0.26499882340431213
30-01-2023 08:33:21 INFO Epoch 2: [3829/10940] ---- BYOL Training Loss = 0.3151225447654724
30-01-2023 08:34:14 INFO Epoch 2: [3829/10940] ---- BYOL Validation Loss = 0.2942538857460022
30-01-2023 08:34:32 INFO Epoch 2: [3840/10940] ---- BYOL Training Loss = 0.34308570623397827
30-01-2023 08:34:49 INFO Epoch 2: [3851/10940] ---- BYOL Training Loss = 0.2855225205421448
30-01-2023 08:35:08 INFO Epoch 2: [3862/10940] ---- BYOL Training Loss = 0.25892096757888794
30-01-2023 08:35:26 INFO Epoch 2: [3873/10940] ---- BYOL Training Loss = 0.27263423800468445
30-01-2023 08:36:19 INFO Epoch 2: [3873/10940] ---- BYOL Validation Loss = 0.29188844561576843
30-01-2023 08:36:36 INFO Epoch 2: [3884/10940] ---- BYOL Training Loss = 0.27584612369537354
30-01-2023 08:36:54 INFO Epoch 2: [3895/10940] ---- BYOL Training Loss = 0.29726189374923706
30-01-2023 08:37:12 INFO Epoch 2: [3906/10940] ---- BYOL Training Loss = 0.2703592777252197
30-01-2023 08:37:29 INFO Epoch 2: [3917/10940] ---- BYOL Training Loss = 0.2890881896018982
30-01-2023 08:38:23 INFO Epoch 2: [3917/10940] ---- BYOL Validation Loss = 0.29127031564712524
30-01-2023 08:38:40 INFO Epoch 2: [3928/10940] ---- BYOL Training Loss = 0.30570146441459656
30-01-2023 08:38:58 INFO Epoch 2: [3939/10940] ---- BYOL Training Loss = 0.27794384956359863
30-01-2023 08:39:16 INFO Epoch 2: [3950/10940] ---- BYOL Training Loss = 0.2842252850532532
30-01-2023 08:39:34 INFO Epoch 2: [3961/10940] ---- BYOL Training Loss = 0.3265824019908905
30-01-2023 08:40:27 INFO Epoch 2: [3961/10940] ---- BYOL Validation Loss = 0.28579261898994446
30-01-2023 08:40:45 INFO Epoch 2: [3972/10940] ---- BYOL Training Loss = 0.31561964750289917
30-01-2023 08:41:03 INFO Epoch 2: [3983/10940] ---- BYOL Training Loss = 0.32996007800102234
30-01-2023 08:41:20 INFO Epoch 2: [3994/10940] ---- BYOL Training Loss = 0.29097098112106323
30-01-2023 08:41:39 INFO Epoch 2: [4005/10940] ---- BYOL Training Loss = 0.26835593581199646
30-01-2023 08:42:32 INFO Epoch 2: [4005/10940] ---- BYOL Validation Loss = 0.28590187430381775
30-01-2023 08:42:49 INFO Epoch 2: [4016/10940] ---- BYOL Training Loss = 0.2689321041107178
30-01-2023 08:43:07 INFO Epoch 2: [4027/10940] ---- BYOL Training Loss = 0.278931200504303
30-01-2023 08:43:25 INFO Epoch 2: [4038/10940] ---- BYOL Training Loss = 0.29181772470474243
30-01-2023 08:43:43 INFO Epoch 2: [4049/10940] ---- BYOL Training Loss = 0.27345114946365356
30-01-2023 08:44:36 INFO Epoch 2: [4049/10940] ---- BYOL Validation Loss = 0.2875227928161621
30-01-2023 08:44:53 INFO Epoch 2: [4060/10940] ---- BYOL Training Loss = 0.24868819117546082
30-01-2023 08:45:11 INFO Epoch 2: [4071/10940] ---- BYOL Training Loss = 0.30341821908950806
30-01-2023 08:45:29 INFO Epoch 2: [4082/10940] ---- BYOL Training Loss = 0.2831955552101135
30-01-2023 08:45:47 INFO Epoch 2: [4093/10940] ---- BYOL Training Loss = 0.30731892585754395
30-01-2023 08:46:40 INFO Epoch 2: [4093/10940] ---- BYOL Validation Loss = 0.2863975167274475
30-01-2023 08:46:58 INFO Epoch 2: [4104/10940] ---- BYOL Training Loss = 0.32166069746017456
30-01-2023 08:47:16 INFO Epoch 2: [4115/10940] ---- BYOL Training Loss = 0.3028915524482727
30-01-2023 08:47:33 INFO Epoch 2: [4126/10940] ---- BYOL Training Loss = 0.27548709511756897
30-01-2023 08:47:51 INFO Epoch 2: [4137/10940] ---- BYOL Training Loss = 0.27010273933410645
30-01-2023 08:48:44 INFO Epoch 2: [4137/10940] ---- BYOL Validation Loss = 0.28829166293144226
30-01-2023 08:49:02 INFO Epoch 2: [4148/10940] ---- BYOL Training Loss = 0.323861300945282
30-01-2023 08:49:20 INFO Epoch 2: [4159/10940] ---- BYOL Training Loss = 0.3048112988471985
30-01-2023 08:49:38 INFO Epoch 2: [4170/10940] ---- BYOL Training Loss = 0.2506777048110962
30-01-2023 08:49:56 INFO Epoch 2: [4181/10940] ---- BYOL Training Loss = 0.23726752400398254
30-01-2023 08:50:49 INFO Epoch 2: [4181/10940] ---- BYOL Validation Loss = 0.2865538001060486
30-01-2023 08:51:06 INFO Epoch 2: [4192/10940] ---- BYOL Training Loss = 0.309601366519928
30-01-2023 08:51:24 INFO Epoch 2: [4203/10940] ---- BYOL Training Loss = 0.3112834692001343
30-01-2023 08:51:42 INFO Epoch 2: [4214/10940] ---- BYOL Training Loss = 0.27912887930870056
30-01-2023 08:52:00 INFO Epoch 2: [4225/10940] ---- BYOL Training Loss = 0.2817484140396118
30-01-2023 08:52:53 INFO Epoch 2: [4225/10940] ---- BYOL Validation Loss = 0.285800963640213
30-01-2023 08:53:11 INFO Epoch 2: [4236/10940] ---- BYOL Training Loss = 0.2903110384941101
30-01-2023 08:53:29 INFO Epoch 2: [4247/10940] ---- BYOL Training Loss = 0.31488269567489624
30-01-2023 08:53:47 INFO Epoch 2: [4258/10940] ---- BYOL Training Loss = 0.2871338725090027
30-01-2023 08:54:05 INFO Epoch 2: [4269/10940] ---- BYOL Training Loss = 0.31241199374198914
30-01-2023 08:54:58 INFO Epoch 2: [4269/10940] ---- BYOL Validation Loss = 0.2928297221660614
30-01-2023 08:55:16 INFO Epoch 2: [4280/10940] ---- BYOL Training Loss = 0.31367576122283936
30-01-2023 08:55:34 INFO Epoch 2: [4291/10940] ---- BYOL Training Loss = 0.33164939284324646
30-01-2023 08:55:52 INFO Epoch 2: [4302/10940] ---- BYOL Training Loss = 0.31125035881996155
30-01-2023 08:56:10 INFO Epoch 2: [4313/10940] ---- BYOL Training Loss = 0.2771376371383667
30-01-2023 08:57:03 INFO Epoch 2: [4313/10940] ---- BYOL Validation Loss = 0.29509297013282776
30-01-2023 08:57:21 INFO Epoch 2: [4324/10940] ---- BYOL Training Loss = 0.30161720514297485
30-01-2023 08:57:39 INFO Epoch 2: [4335/10940] ---- BYOL Training Loss = 0.30643099546432495
30-01-2023 08:57:57 INFO Epoch 2: [4346/10940] ---- BYOL Training Loss = 0.3134097456932068
30-01-2023 08:58:15 INFO Epoch 2: [4357/10940] ---- BYOL Training Loss = 0.29974564909935
30-01-2023 08:59:08 INFO Epoch 2: [4357/10940] ---- BYOL Validation Loss = 0.2944179177284241
30-01-2023 08:59:25 INFO Epoch 2: [4368/10940] ---- BYOL Training Loss = 0.27317023277282715
30-01-2023 08:59:43 INFO Epoch 2: [4379/10940] ---- BYOL Training Loss = 0.27403125166893005
30-01-2023 09:00:01 INFO Epoch 2: [4390/10940] ---- BYOL Training Loss = 0.3256320059299469
30-01-2023 09:00:19 INFO Epoch 2: [4401/10940] ---- BYOL Training Loss = 0.3106166422367096
30-01-2023 09:01:12 INFO Epoch 2: [4401/10940] ---- BYOL Validation Loss = 0.2924574315547943
30-01-2023 09:01:30 INFO Epoch 2: [4412/10940] ---- BYOL Training Loss = 0.28051379323005676
30-01-2023 09:01:48 INFO Epoch 2: [4423/10940] ---- BYOL Training Loss = 0.2600513994693756
30-01-2023 09:02:06 INFO Epoch 2: [4434/10940] ---- BYOL Training Loss = 0.2697869539260864
30-01-2023 09:02:24 INFO Epoch 2: [4445/10940] ---- BYOL Training Loss = 0.2654596269130707
30-01-2023 09:03:17 INFO Epoch 2: [4445/10940] ---- BYOL Validation Loss = 0.2841264605522156
30-01-2023 09:03:35 INFO Epoch 2: [4456/10940] ---- BYOL Training Loss = 0.26437050104141235
30-01-2023 09:03:52 INFO Epoch 2: [4467/10940] ---- BYOL Training Loss = 0.2393152266740799
30-01-2023 09:04:10 INFO Epoch 2: [4478/10940] ---- BYOL Training Loss = 0.2506040930747986
30-01-2023 09:04:28 INFO Epoch 2: [4489/10940] ---- BYOL Training Loss = 0.2399304360151291
30-01-2023 09:05:21 INFO Epoch 2: [4489/10940] ---- BYOL Validation Loss = 0.28588470816612244
30-01-2023 09:05:39 INFO Epoch 2: [4500/10940] ---- BYOL Training Loss = 0.25928860902786255
30-01-2023 09:05:57 INFO Epoch 2: [4511/10940] ---- BYOL Training Loss = 0.3237519860267639
30-01-2023 09:06:15 INFO Epoch 2: [4522/10940] ---- BYOL Training Loss = 0.337724506855011
30-01-2023 09:06:33 INFO Epoch 2: [4533/10940] ---- BYOL Training Loss = 0.2936161160469055
30-01-2023 09:07:26 INFO Epoch 2: [4533/10940] ---- BYOL Validation Loss = 0.28699102997779846
30-01-2023 09:07:43 INFO Epoch 2: [4544/10940] ---- BYOL Training Loss = 0.25420981645584106
30-01-2023 09:08:01 INFO Epoch 2: [4555/10940] ---- BYOL Training Loss = 0.25922703742980957
30-01-2023 09:08:19 INFO Epoch 2: [4566/10940] ---- BYOL Training Loss = 0.2635398507118225
30-01-2023 09:08:37 INFO Epoch 2: [4577/10940] ---- BYOL Training Loss = 0.31476494669914246
30-01-2023 09:09:31 INFO Epoch 2: [4577/10940] ---- BYOL Validation Loss = 0.2924623489379883
30-01-2023 09:09:48 INFO Epoch 2: [4588/10940] ---- BYOL Training Loss = 0.3557030260562897
30-01-2023 09:10:06 INFO Epoch 2: [4599/10940] ---- BYOL Training Loss = 0.2889329493045807
30-01-2023 09:10:24 INFO Epoch 2: [4610/10940] ---- BYOL Training Loss = 0.297745019197464
30-01-2023 09:10:42 INFO Epoch 2: [4621/10940] ---- BYOL Training Loss = 0.2923787534236908
30-01-2023 09:11:36 INFO Epoch 2: [4621/10940] ---- BYOL Validation Loss = 0.2905641496181488
30-01-2023 09:11:53 INFO Epoch 2: [4632/10940] ---- BYOL Training Loss = 0.2810836732387543
30-01-2023 09:12:11 INFO Epoch 2: [4643/10940] ---- BYOL Training Loss = 0.2736487090587616
30-01-2023 09:12:29 INFO Epoch 2: [4654/10940] ---- BYOL Training Loss = 0.26909953355789185
30-01-2023 09:12:47 INFO Epoch 2: [4665/10940] ---- BYOL Training Loss = 0.31576335430145264
30-01-2023 09:13:41 INFO Epoch 2: [4665/10940] ---- BYOL Validation Loss = 0.301066130399704
30-01-2023 09:13:58 INFO Epoch 2: [4676/10940] ---- BYOL Training Loss = 0.32447534799575806
30-01-2023 09:14:16 INFO Epoch 2: [4687/10940] ---- BYOL Training Loss = 0.2695375978946686
30-01-2023 09:14:34 INFO Epoch 2: [4698/10940] ---- BYOL Training Loss = 0.2715977728366852
30-01-2023 09:14:52 INFO Epoch 2: [4709/10940] ---- BYOL Training Loss = 0.2984584867954254
30-01-2023 09:15:45 INFO Epoch 2: [4709/10940] ---- BYOL Validation Loss = 0.29198622703552246
30-01-2023 09:16:03 INFO Epoch 2: [4720/10940] ---- BYOL Training Loss = 0.31266289949417114
30-01-2023 09:16:21 INFO Epoch 2: [4731/10940] ---- BYOL Training Loss = 0.31453827023506165
30-01-2023 09:16:39 INFO Epoch 2: [4742/10940] ---- BYOL Training Loss = 0.2667537331581116
30-01-2023 09:16:57 INFO Epoch 2: [4753/10940] ---- BYOL Training Loss = 0.2770705819129944
30-01-2023 09:17:50 INFO Epoch 2: [4753/10940] ---- BYOL Validation Loss = 0.2830679714679718
30-01-2023 09:18:07 INFO Epoch 2: [4764/10940] ---- BYOL Training Loss = 0.2677628695964813
30-01-2023 09:18:25 INFO Epoch 2: [4775/10940] ---- BYOL Training Loss = 0.2896042466163635
30-01-2023 09:18:43 INFO Epoch 2: [4786/10940] ---- BYOL Training Loss = 0.2862452268600464
30-01-2023 09:19:01 INFO Epoch 2: [4797/10940] ---- BYOL Training Loss = 0.29122036695480347
30-01-2023 09:19:55 INFO Epoch 2: [4797/10940] ---- BYOL Validation Loss = 0.30058762431144714
30-01-2023 09:20:12 INFO Epoch 2: [4808/10940] ---- BYOL Training Loss = 0.28631025552749634
30-01-2023 09:20:30 INFO Epoch 2: [4819/10940] ---- BYOL Training Loss = 0.2869807183742523
30-01-2023 09:20:48 INFO Epoch 2: [4830/10940] ---- BYOL Training Loss = 0.29362747073173523
30-01-2023 09:21:06 INFO Epoch 2: [4841/10940] ---- BYOL Training Loss = 0.2959774136543274
30-01-2023 09:22:00 INFO Epoch 2: [4841/10940] ---- BYOL Validation Loss = 0.2916107773780823
30-01-2023 09:22:17 INFO Epoch 2: [4852/10940] ---- BYOL Training Loss = 0.2913493812084198
30-01-2023 09:22:35 INFO Epoch 2: [4863/10940] ---- BYOL Training Loss = 0.28321102261543274
30-01-2023 09:22:53 INFO Epoch 2: [4874/10940] ---- BYOL Training Loss = 0.26738250255584717
30-01-2023 09:23:11 INFO Epoch 2: [4885/10940] ---- BYOL Training Loss = 0.31139880418777466
30-01-2023 09:24:05 INFO Epoch 2: [4885/10940] ---- BYOL Validation Loss = 0.3547394275665283
30-01-2023 09:24:22 INFO Epoch 2: [4896/10940] ---- BYOL Training Loss = 0.31112849712371826
30-01-2023 09:24:41 INFO Epoch 2: [4907/10940] ---- BYOL Training Loss = 0.28701114654541016
30-01-2023 09:24:59 INFO Epoch 2: [4918/10940] ---- BYOL Training Loss = 0.2792423963546753
30-01-2023 09:25:17 INFO Epoch 2: [4929/10940] ---- BYOL Training Loss = 0.2885218858718872
30-01-2023 09:26:10 INFO Epoch 2: [4929/10940] ---- BYOL Validation Loss = 0.29480117559432983
30-01-2023 09:26:28 INFO Epoch 2: [4940/10940] ---- BYOL Training Loss = 0.27200788259506226
30-01-2023 09:26:45 INFO Epoch 2: [4951/10940] ---- BYOL Training Loss = 0.2674456536769867
30-01-2023 09:27:04 INFO Epoch 2: [4962/10940] ---- BYOL Training Loss = 0.25606149435043335
30-01-2023 09:27:22 INFO Epoch 2: [4973/10940] ---- BYOL Training Loss = 0.2628636956214905
30-01-2023 09:28:15 INFO Epoch 2: [4973/10940] ---- BYOL Validation Loss = 0.2922186255455017
30-01-2023 09:28:32 INFO Epoch 2: [4984/10940] ---- BYOL Training Loss = 0.31687408685684204
30-01-2023 09:28:50 INFO Epoch 2: [4995/10940] ---- BYOL Training Loss = 0.3153352737426758
30-01-2023 09:29:08 INFO Epoch 2: [5006/10940] ---- BYOL Training Loss = 0.2731051445007324
30-01-2023 09:29:27 INFO Epoch 2: [5017/10940] ---- BYOL Training Loss = 0.2641051411628723
30-01-2023 09:30:20 INFO Epoch 2: [5017/10940] ---- BYOL Validation Loss = 0.2861674129962921
30-01-2023 09:30:37 INFO Epoch 2: [5028/10940] ---- BYOL Training Loss = 0.3031342029571533
30-01-2023 09:30:55 INFO Epoch 2: [5039/10940] ---- BYOL Training Loss = 0.2904135584831238
30-01-2023 09:31:13 INFO Epoch 2: [5050/10940] ---- BYOL Training Loss = 0.2957245409488678
30-01-2023 09:31:31 INFO Epoch 2: [5061/10940] ---- BYOL Training Loss = 0.3521481156349182
30-01-2023 09:32:24 INFO Epoch 2: [5061/10940] ---- BYOL Validation Loss = 0.29022136330604553
30-01-2023 09:32:42 INFO Epoch 2: [5072/10940] ---- BYOL Training Loss = 0.3415144085884094
30-01-2023 09:33:00 INFO Epoch 2: [5083/10940] ---- BYOL Training Loss = 0.3142152726650238
30-01-2023 09:33:18 INFO Epoch 2: [5094/10940] ---- BYOL Training Loss = 0.2917816936969757
30-01-2023 09:33:36 INFO Epoch 2: [5105/10940] ---- BYOL Training Loss = 0.2802773118019104
30-01-2023 09:34:29 INFO Epoch 2: [5105/10940] ---- BYOL Validation Loss = 0.2942807376384735
30-01-2023 09:34:47 INFO Epoch 2: [5116/10940] ---- BYOL Training Loss = 0.3176030218601227
30-01-2023 09:35:05 INFO Epoch 2: [5127/10940] ---- BYOL Training Loss = 0.3071708679199219
30-01-2023 09:35:23 INFO Epoch 2: [5138/10940] ---- BYOL Training Loss = 0.2936653792858124
30-01-2023 09:35:41 INFO Epoch 2: [5149/10940] ---- BYOL Training Loss = 0.3037172555923462
30-01-2023 09:36:34 INFO Epoch 2: [5149/10940] ---- BYOL Validation Loss = 0.28824692964553833
30-01-2023 09:36:52 INFO Epoch 2: [5160/10940] ---- BYOL Training Loss = 0.27959975600242615
30-01-2023 09:37:10 INFO Epoch 2: [5171/10940] ---- BYOL Training Loss = 0.2597793638706207
30-01-2023 09:37:28 INFO Epoch 2: [5182/10940] ---- BYOL Training Loss = 0.2969399690628052
30-01-2023 09:37:46 INFO Epoch 2: [5193/10940] ---- BYOL Training Loss = 0.269939124584198
30-01-2023 09:38:39 INFO Epoch 2: [5193/10940] ---- BYOL Validation Loss = 0.2945600152015686
30-01-2023 09:38:57 INFO Epoch 2: [5204/10940] ---- BYOL Training Loss = 0.2799091935157776
30-01-2023 09:39:15 INFO Epoch 2: [5215/10940] ---- BYOL Training Loss = 0.30041956901550293
30-01-2023 09:39:33 INFO Epoch 2: [5226/10940] ---- BYOL Training Loss = 0.31504160165786743
30-01-2023 09:39:51 INFO Epoch 2: [5237/10940] ---- BYOL Training Loss = 0.31905397772789
30-01-2023 09:40:44 INFO Epoch 2: [5237/10940] ---- BYOL Validation Loss = 0.28916555643081665
30-01-2023 09:41:02 INFO Epoch 2: [5248/10940] ---- BYOL Training Loss = 0.29863613843917847
30-01-2023 09:41:20 INFO Epoch 2: [5259/10940] ---- BYOL Training Loss = 0.2892991900444031
30-01-2023 09:41:38 INFO Epoch 2: [5270/10940] ---- BYOL Training Loss = 0.3122372031211853
30-01-2023 09:41:56 INFO Epoch 2: [5281/10940] ---- BYOL Training Loss = 0.29042285680770874
30-01-2023 09:42:49 INFO Epoch 2: [5281/10940] ---- BYOL Validation Loss = 0.2942710518836975
30-01-2023 09:43:07 INFO Epoch 2: [5292/10940] ---- BYOL Training Loss = 0.2671646475791931
30-01-2023 09:43:25 INFO Epoch 2: [5303/10940] ---- BYOL Training Loss = 0.27938732504844666
30-01-2023 09:43:43 INFO Epoch 2: [5314/10940] ---- BYOL Training Loss = 0.2583213150501251
30-01-2023 09:44:01 INFO Epoch 2: [5325/10940] ---- BYOL Training Loss = 0.27730149030685425
30-01-2023 09:44:54 INFO Epoch 2: [5325/10940] ---- BYOL Validation Loss = 0.2807927429676056
30-01-2023 09:45:11 INFO Epoch 2: [5336/10940] ---- BYOL Training Loss = 0.28943195939064026
30-01-2023 09:45:29 INFO Epoch 2: [5347/10940] ---- BYOL Training Loss = 0.30713000893592834
30-01-2023 09:45:47 INFO Epoch 2: [5358/10940] ---- BYOL Training Loss = 0.3094901740550995
30-01-2023 09:46:06 INFO Epoch 2: [5369/10940] ---- BYOL Training Loss = 0.29587918519973755
30-01-2023 09:46:59 INFO Epoch 2: [5369/10940] ---- BYOL Validation Loss = 0.2833154797554016
30-01-2023 09:47:17 INFO Epoch 2: [5380/10940] ---- BYOL Training Loss = 0.2974169850349426
30-01-2023 09:47:35 INFO Epoch 2: [5391/10940] ---- BYOL Training Loss = 0.31832465529441833
30-01-2023 09:47:53 INFO Epoch 2: [5402/10940] ---- BYOL Training Loss = 0.2962721288204193
30-01-2023 09:48:11 INFO Epoch 2: [5413/10940] ---- BYOL Training Loss = 0.28810617327690125
30-01-2023 09:49:04 INFO Epoch 2: [5413/10940] ---- BYOL Validation Loss = 0.2817201614379883
30-01-2023 09:49:22 INFO Epoch 2: [5424/10940] ---- BYOL Training Loss = 0.2653234004974365
30-01-2023 09:49:40 INFO Epoch 2: [5435/10940] ---- BYOL Training Loss = 0.266478955745697
30-01-2023 09:49:58 INFO Epoch 2: [5446/10940] ---- BYOL Training Loss = 0.28034499287605286
30-01-2023 09:50:16 INFO Epoch 2: [5457/10940] ---- BYOL Training Loss = 0.2762083411216736
30-01-2023 09:51:10 INFO Epoch 2: [5457/10940] ---- BYOL Validation Loss = 0.2844852805137634
30-01-2023 09:51:27 INFO Epoch 2: [5468/10940] ---- BYOL Training Loss = 0.29160264134407043
30-01-2023 09:51:45 INFO Epoch 2: [5479/10940] ---- BYOL Training Loss = 0.3018566370010376
30-01-2023 09:52:03 INFO Epoch 2: [5490/10940] ---- BYOL Training Loss = 0.2716265618801117
30-01-2023 09:52:21 INFO Epoch 2: [5501/10940] ---- BYOL Training Loss = 0.3197087347507477
30-01-2023 09:53:15 INFO Epoch 2: [5501/10940] ---- BYOL Validation Loss = 0.28883475065231323
30-01-2023 09:53:33 INFO Epoch 2: [5512/10940] ---- BYOL Training Loss = 0.3416891396045685
30-01-2023 09:53:51 INFO Epoch 2: [5523/10940] ---- BYOL Training Loss = 0.28305792808532715
30-01-2023 09:54:09 INFO Epoch 2: [5534/10940] ---- BYOL Training Loss = 0.27041804790496826
30-01-2023 09:54:27 INFO Epoch 2: [5545/10940] ---- BYOL Training Loss = 0.27781739830970764
30-01-2023 09:55:20 INFO Epoch 2: [5545/10940] ---- BYOL Validation Loss = 0.2865573465824127
30-01-2023 09:55:38 INFO Epoch 2: [5556/10940] ---- BYOL Training Loss = 0.30967652797698975
30-01-2023 09:55:56 INFO Epoch 2: [5567/10940] ---- BYOL Training Loss = 0.3148212730884552
30-01-2023 09:56:14 INFO Epoch 2: [5578/10940] ---- BYOL Training Loss = 0.329498291015625
30-01-2023 09:56:32 INFO Epoch 2: [5589/10940] ---- BYOL Training Loss = 0.27983251214027405
30-01-2023 09:57:25 INFO Epoch 2: [5589/10940] ---- BYOL Validation Loss = 0.2769968807697296
30-01-2023 09:57:43 INFO Epoch 2: [5600/10940] ---- BYOL Training Loss = 0.2818208932876587
30-01-2023 09:58:01 INFO Epoch 2: [5611/10940] ---- BYOL Training Loss = 0.2831854224205017
30-01-2023 09:58:19 INFO Epoch 2: [5622/10940] ---- BYOL Training Loss = 0.26298242807388306
30-01-2023 09:58:37 INFO Epoch 2: [5633/10940] ---- BYOL Training Loss = 0.3097769618034363
30-01-2023 09:59:31 INFO Epoch 2: [5633/10940] ---- BYOL Validation Loss = 0.29940780997276306
30-01-2023 09:59:49 INFO Epoch 2: [5644/10940] ---- BYOL Training Loss = 0.2966673970222473
30-01-2023 10:00:07 INFO Epoch 2: [5655/10940] ---- BYOL Training Loss = 0.30253562331199646
30-01-2023 10:00:25 INFO Epoch 2: [5666/10940] ---- BYOL Training Loss = 0.30694106221199036
30-01-2023 10:00:43 INFO Epoch 2: [5677/10940] ---- BYOL Training Loss = 0.27706241607666016
30-01-2023 10:01:36 INFO Epoch 2: [5677/10940] ---- BYOL Validation Loss = 0.28517836332321167
30-01-2023 10:01:53 INFO Epoch 2: [5688/10940] ---- BYOL Training Loss = 0.2785572111606598
30-01-2023 10:02:12 INFO Epoch 2: [5699/10940] ---- BYOL Training Loss = 0.27480924129486084
30-01-2023 10:02:30 INFO Epoch 2: [5710/10940] ---- BYOL Training Loss = 0.27704423666000366
30-01-2023 10:02:48 INFO Epoch 2: [5721/10940] ---- BYOL Training Loss = 0.27490612864494324
30-01-2023 10:03:41 INFO Epoch 2: [5721/10940] ---- BYOL Validation Loss = 0.2858331501483917
30-01-2023 10:03:59 INFO Epoch 2: [5732/10940] ---- BYOL Training Loss = 0.3212360143661499
30-01-2023 10:04:17 INFO Epoch 2: [5743/10940] ---- BYOL Training Loss = 0.31819966435432434
30-01-2023 10:04:35 INFO Epoch 2: [5754/10940] ---- BYOL Training Loss = 0.3441089391708374
30-01-2023 10:04:53 INFO Epoch 2: [5765/10940] ---- BYOL Training Loss = 0.3439902365207672
30-01-2023 10:05:46 INFO Epoch 2: [5765/10940] ---- BYOL Validation Loss = 0.2921515107154846
30-01-2023 10:06:04 INFO Epoch 2: [5776/10940] ---- BYOL Training Loss = 0.32602977752685547
30-01-2023 10:06:22 INFO Epoch 2: [5787/10940] ---- BYOL Training Loss = 0.2995719313621521
30-01-2023 10:06:40 INFO Epoch 2: [5798/10940] ---- BYOL Training Loss = 0.3220743238925934
30-01-2023 10:06:58 INFO Epoch 2: [5809/10940] ---- BYOL Training Loss = 0.3271753489971161
30-01-2023 10:07:52 INFO Epoch 2: [5809/10940] ---- BYOL Validation Loss = 0.2756726145744324
30-01-2023 10:08:09 INFO Epoch 2: [5820/10940] ---- BYOL Training Loss = 0.2818382680416107
30-01-2023 10:08:28 INFO Epoch 2: [5831/10940] ---- BYOL Training Loss = 0.31264451146125793
30-01-2023 10:08:46 INFO Epoch 2: [5842/10940] ---- BYOL Training Loss = 0.32938021421432495
30-01-2023 10:09:04 INFO Epoch 2: [5853/10940] ---- BYOL Training Loss = 0.3203720450401306
30-01-2023 10:09:57 INFO Epoch 2: [5853/10940] ---- BYOL Validation Loss = 0.28880974650382996
30-01-2023 10:10:14 INFO Epoch 2: [5864/10940] ---- BYOL Training Loss = 0.29127514362335205
30-01-2023 10:10:33 INFO Epoch 2: [5875/10940] ---- BYOL Training Loss = 0.280573308467865
30-01-2023 10:10:51 INFO Epoch 2: [5886/10940] ---- BYOL Training Loss = 0.271805077791214
30-01-2023 10:11:09 INFO Epoch 2: [5897/10940] ---- BYOL Training Loss = 0.26807543635368347
30-01-2023 10:12:02 INFO Epoch 2: [5897/10940] ---- BYOL Validation Loss = 0.2818019390106201
30-01-2023 10:12:20 INFO Epoch 2: [5908/10940] ---- BYOL Training Loss = 0.2674444913864136
30-01-2023 10:12:38 INFO Epoch 2: [5919/10940] ---- BYOL Training Loss = 0.2963387668132782
30-01-2023 10:12:57 INFO Epoch 2: [5930/10940] ---- BYOL Training Loss = 0.3292185366153717
30-01-2023 10:13:15 INFO Epoch 2: [5941/10940] ---- BYOL Training Loss = 0.30792415142059326
30-01-2023 10:14:08 INFO Epoch 2: [5941/10940] ---- BYOL Validation Loss = 0.2847607433795929
30-01-2023 10:14:26 INFO Epoch 2: [5952/10940] ---- BYOL Training Loss = 0.26502782106399536
30-01-2023 10:14:44 INFO Epoch 2: [5963/10940] ---- BYOL Training Loss = 0.25210994482040405
30-01-2023 10:15:02 INFO Epoch 2: [5974/10940] ---- BYOL Training Loss = 0.25729918479919434
30-01-2023 10:15:20 INFO Epoch 2: [5985/10940] ---- BYOL Training Loss = 0.2871873676776886
30-01-2023 10:16:13 INFO Epoch 2: [5985/10940] ---- BYOL Validation Loss = 0.2777118384838104
30-01-2023 10:16:31 INFO Epoch 2: [5996/10940] ---- BYOL Training Loss = 0.2813515067100525
30-01-2023 10:16:50 INFO Epoch 2: [6007/10940] ---- BYOL Training Loss = 0.26223164796829224
30-01-2023 10:17:08 INFO Epoch 2: [6018/10940] ---- BYOL Training Loss = 0.30157020688056946
30-01-2023 10:17:26 INFO Epoch 2: [6029/10940] ---- BYOL Training Loss = 0.28510475158691406
30-01-2023 10:18:19 INFO Epoch 2: [6029/10940] ---- BYOL Validation Loss = 0.2775103747844696
30-01-2023 10:18:37 INFO Epoch 2: [6040/10940] ---- BYOL Training Loss = 0.26490771770477295
30-01-2023 10:18:55 INFO Epoch 2: [6051/10940] ---- BYOL Training Loss = 0.28410133719444275
30-01-2023 10:19:13 INFO Epoch 2: [6062/10940] ---- BYOL Training Loss = 0.29488712549209595
30-01-2023 10:19:31 INFO Epoch 2: [6073/10940] ---- BYOL Training Loss = 0.3192374110221863
30-01-2023 10:20:25 INFO Epoch 2: [6073/10940] ---- BYOL Validation Loss = 0.280290424823761
30-01-2023 10:20:43 INFO Epoch 2: [6084/10940] ---- BYOL Training Loss = 0.2931572198867798
30-01-2023 10:21:01 INFO Epoch 2: [6095/10940] ---- BYOL Training Loss = 0.3365853428840637
30-01-2023 10:21:18 INFO Epoch 2: [6106/10940] ---- BYOL Training Loss = 0.30004802346229553
30-01-2023 10:21:36 INFO Epoch 2: [6117/10940] ---- BYOL Training Loss = 0.3015170693397522
30-01-2023 10:22:30 INFO Epoch 2: [6117/10940] ---- BYOL Validation Loss = 0.2849704623222351
30-01-2023 10:22:48 INFO Epoch 2: [6128/10940] ---- BYOL Training Loss = 0.2711770236492157
30-01-2023 10:23:06 INFO Epoch 2: [6139/10940] ---- BYOL Training Loss = 0.30187538266181946
30-01-2023 10:23:24 INFO Epoch 2: [6150/10940] ---- BYOL Training Loss = 0.3496638238430023
30-01-2023 10:23:42 INFO Epoch 2: [6161/10940] ---- BYOL Training Loss = 0.33668071031570435
30-01-2023 10:24:35 INFO Epoch 2: [6161/10940] ---- BYOL Validation Loss = 0.2790064215660095
30-01-2023 10:24:53 INFO Epoch 2: [6172/10940] ---- BYOL Training Loss = 0.24828371405601501
30-01-2023 10:25:11 INFO Epoch 2: [6183/10940] ---- BYOL Training Loss = 0.25940510630607605
30-01-2023 10:25:29 INFO Epoch 2: [6194/10940] ---- BYOL Training Loss = 0.2657574415206909
30-01-2023 10:25:47 INFO Epoch 2: [6205/10940] ---- BYOL Training Loss = 0.28565675020217896
30-01-2023 10:26:41 INFO Epoch 2: [6205/10940] ---- BYOL Validation Loss = 0.2834974527359009
30-01-2023 10:26:59 INFO Epoch 2: [6216/10940] ---- BYOL Training Loss = 0.30308473110198975
30-01-2023 10:27:17 INFO Epoch 2: [6227/10940] ---- BYOL Training Loss = 0.29697397351264954
30-01-2023 10:27:35 INFO Epoch 2: [6238/10940] ---- BYOL Training Loss = 0.30522245168685913
30-01-2023 10:27:53 INFO Epoch 2: [6249/10940] ---- BYOL Training Loss = 0.33262255787849426
30-01-2023 10:28:46 INFO Epoch 2: [6249/10940] ---- BYOL Validation Loss = 0.2903701663017273
30-01-2023 10:29:04 INFO Epoch 2: [6260/10940] ---- BYOL Training Loss = 0.30219584703445435
30-01-2023 10:29:22 INFO Epoch 2: [6271/10940] ---- BYOL Training Loss = 0.21668195724487305
30-01-2023 10:29:40 INFO Epoch 2: [6282/10940] ---- BYOL Training Loss = 0.22276099026203156
30-01-2023 10:29:59 INFO Epoch 2: [6293/10940] ---- BYOL Training Loss = 0.25602665543556213
30-01-2023 10:30:52 INFO Epoch 2: [6293/10940] ---- BYOL Validation Loss = 0.27890560030937195
30-01-2023 10:31:10 INFO Epoch 2: [6304/10940] ---- BYOL Training Loss = 0.2769802510738373
30-01-2023 10:31:28 INFO Epoch 2: [6315/10940] ---- BYOL Training Loss = 0.2782033383846283
30-01-2023 10:31:46 INFO Epoch 2: [6326/10940] ---- BYOL Training Loss = 0.3084332346916199
30-01-2023 10:32:05 INFO Epoch 2: [6337/10940] ---- BYOL Training Loss = 0.296906977891922
30-01-2023 10:32:58 INFO Epoch 2: [6337/10940] ---- BYOL Validation Loss = 0.28325921297073364
30-01-2023 10:33:16 INFO Epoch 2: [6348/10940] ---- BYOL Training Loss = 0.2652894854545593
30-01-2023 10:33:34 INFO Epoch 2: [6359/10940] ---- BYOL Training Loss = 0.2542394995689392
30-01-2023 10:33:52 INFO Epoch 2: [6370/10940] ---- BYOL Training Loss = 0.26214760541915894
30-01-2023 10:34:10 INFO Epoch 2: [6381/10940] ---- BYOL Training Loss = 0.28708693385124207
30-01-2023 10:35:03 INFO Epoch 2: [6381/10940] ---- BYOL Validation Loss = 0.27918803691864014
30-01-2023 10:35:21 INFO Epoch 2: [6392/10940] ---- BYOL Training Loss = 0.31325098872184753
30-01-2023 10:35:39 INFO Epoch 2: [6403/10940] ---- BYOL Training Loss = 0.30237215757369995
30-01-2023 10:35:57 INFO Epoch 2: [6414/10940] ---- BYOL Training Loss = 0.3006250262260437
30-01-2023 10:36:15 INFO Epoch 2: [6425/10940] ---- BYOL Training Loss = 0.2669682204723358
30-01-2023 10:37:08 INFO Epoch 2: [6425/10940] ---- BYOL Validation Loss = 0.2752719223499298
30-01-2023 10:37:26 INFO Epoch 2: [6436/10940] ---- BYOL Training Loss = 0.2715783715248108
30-01-2023 10:37:44 INFO Epoch 2: [6447/10940] ---- BYOL Training Loss = 0.26756173372268677
30-01-2023 10:38:03 INFO Epoch 2: [6458/10940] ---- BYOL Training Loss = 0.2314576655626297
30-01-2023 10:38:20 INFO Epoch 2: [6469/10940] ---- BYOL Training Loss = 0.2582922577857971
30-01-2023 10:39:13 INFO Epoch 2: [6469/10940] ---- BYOL Validation Loss = 0.28030768036842346
30-01-2023 10:39:31 INFO Epoch 2: [6480/10940] ---- BYOL Training Loss = 0.2897058427333832
30-01-2023 10:39:49 INFO Epoch 2: [6491/10940] ---- BYOL Training Loss = 0.2770174741744995
30-01-2023 10:40:08 INFO Epoch 2: [6502/10940] ---- BYOL Training Loss = 0.30771106481552124
30-01-2023 10:40:26 INFO Epoch 2: [6513/10940] ---- BYOL Training Loss = 0.28004151582717896
30-01-2023 10:41:19 INFO Epoch 2: [6513/10940] ---- BYOL Validation Loss = 0.275094598531723
30-01-2023 10:41:36 INFO Epoch 2: [6524/10940] ---- BYOL Training Loss = 0.28148365020751953
30-01-2023 10:41:54 INFO Epoch 2: [6535/10940] ---- BYOL Training Loss = 0.26825228333473206
30-01-2023 10:42:13 INFO Epoch 2: [6546/10940] ---- BYOL Training Loss = 0.2680060863494873
30-01-2023 10:42:31 INFO Epoch 2: [6557/10940] ---- BYOL Training Loss = 0.2986536920070648
30-01-2023 10:43:24 INFO Epoch 2: [6557/10940] ---- BYOL Validation Loss = 0.29015251994132996
30-01-2023 10:43:41 INFO Epoch 2: [6568/10940] ---- BYOL Training Loss = 0.30989474058151245
30-01-2023 10:44:00 INFO Epoch 2: [6579/10940] ---- BYOL Training Loss = 0.30949920415878296
30-01-2023 10:44:18 INFO Epoch 2: [6590/10940] ---- BYOL Training Loss = 0.28656697273254395
30-01-2023 10:44:36 INFO Epoch 2: [6601/10940] ---- BYOL Training Loss = 0.27831974625587463
30-01-2023 10:45:29 INFO Epoch 2: [6601/10940] ---- BYOL Validation Loss = 0.27518144249916077
30-01-2023 10:45:47 INFO Epoch 2: [6612/10940] ---- BYOL Training Loss = 0.2588758170604706
30-01-2023 10:46:05 INFO Epoch 2: [6623/10940] ---- BYOL Training Loss = 0.2781120240688324
30-01-2023 10:46:23 INFO Epoch 2: [6634/10940] ---- BYOL Training Loss = 0.26980775594711304
30-01-2023 10:46:41 INFO Epoch 2: [6645/10940] ---- BYOL Training Loss = 0.3199658691883087
30-01-2023 10:47:34 INFO Epoch 2: [6645/10940] ---- BYOL Validation Loss = 0.27542126178741455
30-01-2023 10:47:52 INFO Epoch 2: [6656/10940] ---- BYOL Training Loss = 0.29217231273651123
30-01-2023 10:48:10 INFO Epoch 2: [6667/10940] ---- BYOL Training Loss = 0.24599525332450867
30-01-2023 10:48:28 INFO Epoch 2: [6678/10940] ---- BYOL Training Loss = 0.25903111696243286
30-01-2023 10:48:46 INFO Epoch 2: [6689/10940] ---- BYOL Training Loss = 0.27655088901519775
30-01-2023 10:49:39 INFO Epoch 2: [6689/10940] ---- BYOL Validation Loss = 0.2744142413139343
30-01-2023 10:49:57 INFO Epoch 2: [6700/10940] ---- BYOL Training Loss = 0.28404396772384644
30-01-2023 10:50:15 INFO Epoch 2: [6711/10940] ---- BYOL Training Loss = 0.27714672684669495
30-01-2023 10:50:33 INFO Epoch 2: [6722/10940] ---- BYOL Training Loss = 0.2818748354911804
30-01-2023 10:50:52 INFO Epoch 2: [6733/10940] ---- BYOL Training Loss = 0.26283642649650574
30-01-2023 10:51:44 INFO Epoch 2: [6733/10940] ---- BYOL Validation Loss = 0.2719845175743103
30-01-2023 10:52:02 INFO Epoch 2: [6744/10940] ---- BYOL Training Loss = 0.2701696753501892
30-01-2023 10:52:20 INFO Epoch 2: [6755/10940] ---- BYOL Training Loss = 0.29088088870048523
30-01-2023 10:52:38 INFO Epoch 2: [6766/10940] ---- BYOL Training Loss = 0.2984517216682434
30-01-2023 10:52:57 INFO Epoch 2: [6777/10940] ---- BYOL Training Loss = 0.28053203225135803
30-01-2023 10:53:50 INFO Epoch 2: [6777/10940] ---- BYOL Validation Loss = 0.2660507559776306
30-01-2023 10:54:08 INFO Epoch 2: [6788/10940] ---- BYOL Training Loss = 0.29520362615585327
30-01-2023 10:54:26 INFO Epoch 2: [6799/10940] ---- BYOL Training Loss = 0.2998591661453247
30-01-2023 10:54:44 INFO Epoch 2: [6810/10940] ---- BYOL Training Loss = 0.2860051989555359
30-01-2023 10:55:02 INFO Epoch 2: [6821/10940] ---- BYOL Training Loss = 0.28645429015159607
30-01-2023 10:55:55 INFO Epoch 2: [6821/10940] ---- BYOL Validation Loss = 0.2820809483528137
30-01-2023 10:56:13 INFO Epoch 2: [6832/10940] ---- BYOL Training Loss = 0.2859618067741394
30-01-2023 10:56:31 INFO Epoch 2: [6843/10940] ---- BYOL Training Loss = 0.2769762873649597
30-01-2023 10:56:50 INFO Epoch 2: [6854/10940] ---- BYOL Training Loss = 0.28531956672668457
30-01-2023 10:57:08 INFO Epoch 2: [6865/10940] ---- BYOL Training Loss = 0.289754718542099
30-01-2023 10:58:01 INFO Epoch 2: [6865/10940] ---- BYOL Validation Loss = 0.27641165256500244
30-01-2023 10:58:19 INFO Epoch 2: [6876/10940] ---- BYOL Training Loss = 0.2936985492706299
30-01-2023 10:58:37 INFO Epoch 2: [6887/10940] ---- BYOL Training Loss = 0.30633872747421265
30-01-2023 10:58:55 INFO Epoch 2: [6898/10940] ---- BYOL Training Loss = 0.2663213908672333
30-01-2023 10:59:13 INFO Epoch 2: [6909/10940] ---- BYOL Training Loss = 0.23795250058174133
30-01-2023 11:00:06 INFO Epoch 2: [6909/10940] ---- BYOL Validation Loss = 0.27362748980522156
30-01-2023 11:00:24 INFO Epoch 2: [6920/10940] ---- BYOL Training Loss = 0.2500936985015869
30-01-2023 11:00:43 INFO Epoch 2: [6931/10940] ---- BYOL Training Loss = 0.2737458348274231
30-01-2023 11:01:01 INFO Epoch 2: [6942/10940] ---- BYOL Training Loss = 0.30130618810653687
30-01-2023 11:01:19 INFO Epoch 2: [6953/10940] ---- BYOL Training Loss = 0.28364139795303345
30-01-2023 11:02:12 INFO Epoch 2: [6953/10940] ---- BYOL Validation Loss = 0.2775353789329529
30-01-2023 11:02:31 INFO Epoch 2: [6964/10940] ---- BYOL Training Loss = 0.2573288083076477
30-01-2023 11:02:49 INFO Epoch 2: [6975/10940] ---- BYOL Training Loss = 0.2788771688938141
30-01-2023 11:03:07 INFO Epoch 2: [6986/10940] ---- BYOL Training Loss = 0.2873504161834717
30-01-2023 11:03:25 INFO Epoch 2: [6997/10940] ---- BYOL Training Loss = 0.2577210068702698
30-01-2023 11:04:18 INFO Epoch 2: [6997/10940] ---- BYOL Validation Loss = 0.27199888229370117
30-01-2023 11:04:36 INFO Epoch 2: [7008/10940] ---- BYOL Training Loss = 0.27995210886001587
30-01-2023 11:04:54 INFO Epoch 2: [7019/10940] ---- BYOL Training Loss = 0.2846624553203583
30-01-2023 11:05:12 INFO Epoch 2: [7030/10940] ---- BYOL Training Loss = 0.28532201051712036
30-01-2023 11:05:31 INFO Epoch 2: [7041/10940] ---- BYOL Training Loss = 0.290693461894989
30-01-2023 11:06:24 INFO Epoch 2: [7041/10940] ---- BYOL Validation Loss = 0.2740802764892578
30-01-2023 11:06:42 INFO Epoch 2: [7052/10940] ---- BYOL Training Loss = 0.2884211242198944
30-01-2023 11:07:00 INFO Epoch 2: [7063/10940] ---- BYOL Training Loss = 0.2899223566055298
30-01-2023 11:07:18 INFO Epoch 2: [7074/10940] ---- BYOL Training Loss = 0.2903260290622711
30-01-2023 11:07:37 INFO Epoch 2: [7085/10940] ---- BYOL Training Loss = 0.29453960061073303
30-01-2023 11:08:30 INFO Epoch 2: [7085/10940] ---- BYOL Validation Loss = 0.26924368739128113
30-01-2023 11:08:47 INFO Epoch 2: [7096/10940] ---- BYOL Training Loss = 0.299442857503891
30-01-2023 11:09:05 INFO Epoch 2: [7107/10940] ---- BYOL Training Loss = 0.291638046503067
30-01-2023 11:09:24 INFO Epoch 2: [7118/10940] ---- BYOL Training Loss = 0.295472651720047
30-01-2023 11:09:42 INFO Epoch 2: [7129/10940] ---- BYOL Training Loss = 0.3065630793571472
30-01-2023 11:10:35 INFO Epoch 2: [7129/10940] ---- BYOL Validation Loss = 0.27985915541648865
30-01-2023 11:10:53 INFO Epoch 2: [7140/10940] ---- BYOL Training Loss = 0.3069562315940857
30-01-2023 11:11:12 INFO Epoch 2: [7151/10940] ---- BYOL Training Loss = 0.2881191074848175
30-01-2023 11:11:30 INFO Epoch 2: [7162/10940] ---- BYOL Training Loss = 0.2666699290275574
30-01-2023 11:11:48 INFO Epoch 2: [7173/10940] ---- BYOL Training Loss = 0.2586803138256073
30-01-2023 11:12:41 INFO Epoch 2: [7173/10940] ---- BYOL Validation Loss = 0.2695160508155823
30-01-2023 11:12:59 INFO Epoch 2: [7184/10940] ---- BYOL Training Loss = 0.3004487156867981
30-01-2023 11:13:17 INFO Epoch 2: [7195/10940] ---- BYOL Training Loss = 0.3062429428100586
30-01-2023 11:13:35 INFO Epoch 2: [7206/10940] ---- BYOL Training Loss = 0.27519869804382324
30-01-2023 11:13:53 INFO Epoch 2: [7217/10940] ---- BYOL Training Loss = 0.27556735277175903
30-01-2023 11:14:46 INFO Epoch 2: [7217/10940] ---- BYOL Validation Loss = 0.27398255467414856
30-01-2023 11:15:05 INFO Epoch 2: [7228/10940] ---- BYOL Training Loss = 0.2838755249977112
30-01-2023 11:15:23 INFO Epoch 2: [7239/10940] ---- BYOL Training Loss = 0.28849896788597107
30-01-2023 11:15:41 INFO Epoch 2: [7250/10940] ---- BYOL Training Loss = 0.2869870960712433
30-01-2023 11:16:00 INFO Epoch 2: [7261/10940] ---- BYOL Training Loss = 0.3425237238407135
30-01-2023 11:16:53 INFO Epoch 2: [7261/10940] ---- BYOL Validation Loss = 0.2772187292575836
30-01-2023 11:17:11 INFO Epoch 2: [7272/10940] ---- BYOL Training Loss = 0.30840176343917847
30-01-2023 11:17:29 INFO Epoch 2: [7283/10940] ---- BYOL Training Loss = 0.2812482714653015
30-01-2023 11:17:48 INFO Epoch 2: [7294/10940] ---- BYOL Training Loss = 0.27018672227859497
30-01-2023 11:18:06 INFO Epoch 2: [7305/10940] ---- BYOL Training Loss = 0.2793269753456116
30-01-2023 11:18:59 INFO Epoch 2: [7305/10940] ---- BYOL Validation Loss = 0.2693745493888855
30-01-2023 11:19:17 INFO Epoch 2: [7316/10940] ---- BYOL Training Loss = 0.29300451278686523
30-01-2023 11:19:35 INFO Epoch 2: [7327/10940] ---- BYOL Training Loss = 0.3143784999847412
30-01-2023 11:19:53 INFO Epoch 2: [7338/10940] ---- BYOL Training Loss = 0.26925989985466003
30-01-2023 11:20:11 INFO Epoch 2: [7349/10940] ---- BYOL Training Loss = 0.2299213409423828
30-01-2023 11:21:04 INFO Epoch 2: [7349/10940] ---- BYOL Validation Loss = 0.27081483602523804
30-01-2023 11:21:22 INFO Epoch 2: [7360/10940] ---- BYOL Training Loss = 0.24117200076580048
30-01-2023 11:21:41 INFO Epoch 2: [7371/10940] ---- BYOL Training Loss = 0.2473972588777542
30-01-2023 11:21:59 INFO Epoch 2: [7382/10940] ---- BYOL Training Loss = 0.2613357603549957
30-01-2023 11:22:17 INFO Epoch 2: [7393/10940] ---- BYOL Training Loss = 0.25106388330459595
30-01-2023 11:23:10 INFO Epoch 2: [7393/10940] ---- BYOL Validation Loss = 0.26709461212158203
30-01-2023 11:23:28 INFO Epoch 2: [7404/10940] ---- BYOL Training Loss = 0.3213284909725189
30-01-2023 11:23:46 INFO Epoch 2: [7415/10940] ---- BYOL Training Loss = 0.3620595633983612
30-01-2023 11:24:05 INFO Epoch 2: [7426/10940] ---- BYOL Training Loss = 0.3529643416404724
30-01-2023 11:24:23 INFO Epoch 2: [7437/10940] ---- BYOL Training Loss = 0.3156859874725342
30-01-2023 11:25:16 INFO Epoch 2: [7437/10940] ---- BYOL Validation Loss = 0.2659718096256256
30-01-2023 11:25:34 INFO Epoch 2: [7448/10940] ---- BYOL Training Loss = 0.30160847306251526
30-01-2023 11:25:52 INFO Epoch 2: [7459/10940] ---- BYOL Training Loss = 0.2887120544910431
30-01-2023 11:26:11 INFO Epoch 2: [7470/10940] ---- BYOL Training Loss = 0.3188084661960602
30-01-2023 11:26:29 INFO Epoch 2: [7481/10940] ---- BYOL Training Loss = 0.32842373847961426
30-01-2023 11:27:22 INFO Epoch 2: [7481/10940] ---- BYOL Validation Loss = 0.2753297984600067
30-01-2023 11:27:39 INFO Epoch 2: [7492/10940] ---- BYOL Training Loss = 0.2682158350944519
30-01-2023 11:27:58 INFO Epoch 2: [7503/10940] ---- BYOL Training Loss = 0.2600872218608856
30-01-2023 11:28:16 INFO Epoch 2: [7514/10940] ---- BYOL Training Loss = 0.2504277229309082
30-01-2023 11:28:34 INFO Epoch 2: [7525/10940] ---- BYOL Training Loss = 0.2595759332180023
30-01-2023 11:29:27 INFO Epoch 2: [7525/10940] ---- BYOL Validation Loss = 0.27382320165634155
30-01-2023 11:29:45 INFO Epoch 2: [7536/10940] ---- BYOL Training Loss = 0.3059033751487732
30-01-2023 11:30:04 INFO Epoch 2: [7547/10940] ---- BYOL Training Loss = 0.31888216733932495
30-01-2023 11:30:22 INFO Epoch 2: [7558/10940] ---- BYOL Training Loss = 0.34419211745262146
30-01-2023 11:30:40 INFO Epoch 2: [7569/10940] ---- BYOL Training Loss = 0.3727879822254181
30-01-2023 11:31:34 INFO Epoch 2: [7569/10940] ---- BYOL Validation Loss = 0.2796928286552429
30-01-2023 11:31:52 INFO Epoch 2: [7580/10940] ---- BYOL Training Loss = 0.3555690348148346
30-01-2023 11:32:10 INFO Epoch 2: [7591/10940] ---- BYOL Training Loss = 0.2755427658557892
30-01-2023 11:32:28 INFO Epoch 2: [7602/10940] ---- BYOL Training Loss = 0.24905148148536682
30-01-2023 11:32:47 INFO Epoch 2: [7613/10940] ---- BYOL Training Loss = 0.3076198399066925
30-01-2023 11:33:40 INFO Epoch 2: [7613/10940] ---- BYOL Validation Loss = 0.26688265800476074
30-01-2023 11:33:57 INFO Epoch 2: [7624/10940] ---- BYOL Training Loss = 0.31454962491989136
30-01-2023 11:34:16 INFO Epoch 2: [7635/10940] ---- BYOL Training Loss = 0.25485649704933167
30-01-2023 11:34:34 INFO Epoch 2: [7646/10940] ---- BYOL Training Loss = 0.22752876579761505
30-01-2023 11:34:52 INFO Epoch 2: [7657/10940] ---- BYOL Training Loss = 0.2690105140209198
30-01-2023 11:35:46 INFO Epoch 2: [7657/10940] ---- BYOL Validation Loss = 0.26312318444252014
30-01-2023 11:36:03 INFO Epoch 2: [7668/10940] ---- BYOL Training Loss = 0.27710074186325073
30-01-2023 11:36:22 INFO Epoch 2: [7679/10940] ---- BYOL Training Loss = 0.3029494881629944
30-01-2023 11:36:40 INFO Epoch 2: [7690/10940] ---- BYOL Training Loss = 0.28394991159439087
30-01-2023 11:36:58 INFO Epoch 2: [7701/10940] ---- BYOL Training Loss = 0.2710266709327698
30-01-2023 11:37:51 INFO Epoch 2: [7701/10940] ---- BYOL Validation Loss = 0.27225735783576965
30-01-2023 11:38:10 INFO Epoch 2: [7712/10940] ---- BYOL Training Loss = 0.3239772915840149
30-01-2023 11:38:28 INFO Epoch 2: [7723/10940] ---- BYOL Training Loss = 0.30045953392982483
30-01-2023 11:38:46 INFO Epoch 2: [7734/10940] ---- BYOL Training Loss = 0.27333658933639526
30-01-2023 11:39:05 INFO Epoch 2: [7745/10940] ---- BYOL Training Loss = 0.2996487021446228
30-01-2023 11:39:58 INFO Epoch 2: [7745/10940] ---- BYOL Validation Loss = 0.2600908577442169
30-01-2023 11:40:15 INFO Epoch 2: [7756/10940] ---- BYOL Training Loss = 0.33294031023979187
30-01-2023 11:40:34 INFO Epoch 2: [7767/10940] ---- BYOL Training Loss = 0.3190515637397766
30-01-2023 11:40:52 INFO Epoch 2: [7778/10940] ---- BYOL Training Loss = 0.27751898765563965
30-01-2023 11:41:10 INFO Epoch 2: [7789/10940] ---- BYOL Training Loss = 0.2675602436065674
30-01-2023 11:42:03 INFO Epoch 2: [7789/10940] ---- BYOL Validation Loss = 0.2614745497703552
30-01-2023 11:42:21 INFO Epoch 2: [7800/10940] ---- BYOL Training Loss = 0.26842957735061646
30-01-2023 11:42:39 INFO Epoch 2: [7811/10940] ---- BYOL Training Loss = 0.2877250909805298
30-01-2023 11:42:57 INFO Epoch 2: [7822/10940] ---- BYOL Training Loss = 0.2904941439628601
30-01-2023 11:43:16 INFO Epoch 2: [7833/10940] ---- BYOL Training Loss = 0.33333054184913635
30-01-2023 11:44:09 INFO Epoch 2: [7833/10940] ---- BYOL Validation Loss = 0.30809953808784485
30-01-2023 11:44:27 INFO Epoch 2: [7844/10940] ---- BYOL Training Loss = 0.2793586850166321
30-01-2023 11:44:45 INFO Epoch 2: [7855/10940] ---- BYOL Training Loss = 0.2628445625305176
30-01-2023 11:45:03 INFO Epoch 2: [7866/10940] ---- BYOL Training Loss = 0.2926959693431854
30-01-2023 11:45:21 INFO Epoch 2: [7877/10940] ---- BYOL Training Loss = 0.30620619654655457
30-01-2023 11:46:14 INFO Epoch 2: [7877/10940] ---- BYOL Validation Loss = 0.27118322253227234
30-01-2023 11:46:32 INFO Epoch 2: [7888/10940] ---- BYOL Training Loss = 0.29590630531311035
30-01-2023 11:46:50 INFO Epoch 2: [7899/10940] ---- BYOL Training Loss = 0.244397833943367
30-01-2023 11:47:09 INFO Epoch 2: [7910/10940] ---- BYOL Training Loss = 0.25201091170310974
30-01-2023 11:47:27 INFO Epoch 2: [7921/10940] ---- BYOL Training Loss = 0.26760590076446533
30-01-2023 11:48:20 INFO Epoch 2: [7921/10940] ---- BYOL Validation Loss = 0.2748071849346161
30-01-2023 11:48:38 INFO Epoch 2: [7932/10940] ---- BYOL Training Loss = 0.2944032549858093
30-01-2023 11:48:56 INFO Epoch 2: [7943/10940] ---- BYOL Training Loss = 0.3003888726234436
30-01-2023 11:49:14 INFO Epoch 2: [7954/10940] ---- BYOL Training Loss = 0.2483997642993927
30-01-2023 11:49:33 INFO Epoch 2: [7965/10940] ---- BYOL Training Loss = 0.2637535035610199
30-01-2023 11:50:26 INFO Epoch 2: [7965/10940] ---- BYOL Validation Loss = 0.27158400416374207
30-01-2023 11:50:43 INFO Epoch 2: [7976/10940] ---- BYOL Training Loss = 0.2713988423347473
30-01-2023 11:51:01 INFO Epoch 2: [7987/10940] ---- BYOL Training Loss = 0.3016528785228729
30-01-2023 11:51:20 INFO Epoch 2: [7998/10940] ---- BYOL Training Loss = 0.3233993649482727
30-01-2023 11:51:38 INFO Epoch 2: [8009/10940] ---- BYOL Training Loss = 0.3000124990940094
30-01-2023 11:52:31 INFO Epoch 2: [8009/10940] ---- BYOL Validation Loss = 0.276954710483551
30-01-2023 11:52:49 INFO Epoch 2: [8020/10940] ---- BYOL Training Loss = 0.2471323013305664
30-01-2023 11:53:07 INFO Epoch 2: [8031/10940] ---- BYOL Training Loss = 0.2488173544406891
30-01-2023 11:53:25 INFO Epoch 2: [8042/10940] ---- BYOL Training Loss = 0.2735196650028229
30-01-2023 11:53:43 INFO Epoch 2: [8053/10940] ---- BYOL Training Loss = 0.27073150873184204
30-01-2023 11:54:36 INFO Epoch 2: [8053/10940] ---- BYOL Validation Loss = 0.2582935094833374
30-01-2023 11:54:55 INFO Epoch 2: [8064/10940] ---- BYOL Training Loss = 0.29559218883514404
30-01-2023 11:55:13 INFO Epoch 2: [8075/10940] ---- BYOL Training Loss = 0.28053683042526245
30-01-2023 11:55:31 INFO Epoch 2: [8086/10940] ---- BYOL Training Loss = 0.25350573658943176
30-01-2023 11:55:49 INFO Epoch 2: [8097/10940] ---- BYOL Training Loss = 0.2551129460334778
30-01-2023 11:56:42 INFO Epoch 2: [8097/10940] ---- BYOL Validation Loss = 0.2717794179916382
30-01-2023 11:57:00 INFO Epoch 2: [8108/10940] ---- BYOL Training Loss = 0.29661324620246887
30-01-2023 11:57:18 INFO Epoch 2: [8119/10940] ---- BYOL Training Loss = 0.30893978476524353
30-01-2023 11:57:37 INFO Epoch 2: [8130/10940] ---- BYOL Training Loss = 0.27397042512893677
30-01-2023 11:57:55 INFO Epoch 2: [8141/10940] ---- BYOL Training Loss = 0.24798233807086945
30-01-2023 11:58:48 INFO Epoch 2: [8141/10940] ---- BYOL Validation Loss = 0.25575166940689087
30-01-2023 11:59:06 INFO Epoch 2: [8152/10940] ---- BYOL Training Loss = 0.26249727606773376
30-01-2023 11:59:24 INFO Epoch 2: [8163/10940] ---- BYOL Training Loss = 0.28651511669158936
30-01-2023 11:59:42 INFO Epoch 2: [8174/10940] ---- BYOL Training Loss = 0.3035438656806946
30-01-2023 12:00:00 INFO Epoch 2: [8185/10940] ---- BYOL Training Loss = 0.2936840057373047
30-01-2023 12:00:53 INFO Epoch 2: [8185/10940] ---- BYOL Validation Loss = 0.25904300808906555
30-01-2023 12:01:12 INFO Epoch 2: [8196/10940] ---- BYOL Training Loss = 0.28764063119888306
30-01-2023 12:01:30 INFO Epoch 2: [8207/10940] ---- BYOL Training Loss = 0.290923535823822
30-01-2023 12:01:48 INFO Epoch 2: [8218/10940] ---- BYOL Training Loss = 0.2716766893863678
30-01-2023 12:02:07 INFO Epoch 2: [8229/10940] ---- BYOL Training Loss = 0.2512543499469757
30-01-2023 12:02:59 INFO Epoch 2: [8229/10940] ---- BYOL Validation Loss = 0.25077903270721436
30-01-2023 12:03:17 INFO Epoch 2: [8240/10940] ---- BYOL Training Loss = 0.24236004054546356
30-01-2023 12:03:35 INFO Epoch 2: [8251/10940] ---- BYOL Training Loss = 0.24994727969169617
30-01-2023 12:03:54 INFO Epoch 2: [8262/10940] ---- BYOL Training Loss = 0.2578025162220001
30-01-2023 12:04:12 INFO Epoch 2: [8273/10940] ---- BYOL Training Loss = 0.2533112168312073
30-01-2023 12:05:05 INFO Epoch 2: [8273/10940] ---- BYOL Validation Loss = 0.26588234305381775
30-01-2023 12:05:23 INFO Epoch 2: [8284/10940] ---- BYOL Training Loss = 0.26895207166671753
30-01-2023 12:05:41 INFO Epoch 2: [8295/10940] ---- BYOL Training Loss = 0.2740642726421356
30-01-2023 12:06:00 INFO Epoch 2: [8306/10940] ---- BYOL Training Loss = 0.29936644434928894
30-01-2023 12:06:18 INFO Epoch 2: [8317/10940] ---- BYOL Training Loss = 0.2860935628414154
30-01-2023 12:07:11 INFO Epoch 2: [8317/10940] ---- BYOL Validation Loss = 0.25423914194107056
30-01-2023 12:07:29 INFO Epoch 2: [8328/10940] ---- BYOL Training Loss = 0.2508032023906708
30-01-2023 12:07:47 INFO Epoch 2: [8339/10940] ---- BYOL Training Loss = 0.2685260474681854
30-01-2023 12:08:05 INFO Epoch 2: [8350/10940] ---- BYOL Training Loss = 0.24825036525726318
30-01-2023 12:08:24 INFO Epoch 2: [8361/10940] ---- BYOL Training Loss = 0.2938646078109741
30-01-2023 12:09:16 INFO Epoch 2: [8361/10940] ---- BYOL Validation Loss = 0.2685966193675995
30-01-2023 12:09:34 INFO Epoch 2: [8372/10940] ---- BYOL Training Loss = 0.3230336010456085
30-01-2023 12:09:52 INFO Epoch 2: [8383/10940] ---- BYOL Training Loss = 0.2755991816520691
30-01-2023 12:10:11 INFO Epoch 2: [8394/10940] ---- BYOL Training Loss = 0.2423439472913742
30-01-2023 12:10:29 INFO Epoch 2: [8405/10940] ---- BYOL Training Loss = 0.2764876186847687
30-01-2023 12:11:21 INFO Epoch 2: [8405/10940] ---- BYOL Validation Loss = 0.27022498846054077
30-01-2023 12:11:40 INFO Epoch 2: [8416/10940] ---- BYOL Training Loss = 0.320600301027298
30-01-2023 12:11:58 INFO Epoch 2: [8427/10940] ---- BYOL Training Loss = 0.2683854401111603
30-01-2023 12:12:16 INFO Epoch 2: [8438/10940] ---- BYOL Training Loss = 0.25275206565856934
30-01-2023 12:12:34 INFO Epoch 2: [8449/10940] ---- BYOL Training Loss = 0.27902480959892273
30-01-2023 12:13:27 INFO Epoch 2: [8449/10940] ---- BYOL Validation Loss = 0.2647230327129364
30-01-2023 12:13:45 INFO Epoch 2: [8460/10940] ---- BYOL Training Loss = 0.27334529161453247
30-01-2023 12:14:03 INFO Epoch 2: [8471/10940] ---- BYOL Training Loss = 0.27804452180862427
30-01-2023 12:14:21 INFO Epoch 2: [8482/10940] ---- BYOL Training Loss = 0.26530295610427856
30-01-2023 12:14:40 INFO Epoch 2: [8493/10940] ---- BYOL Training Loss = 0.26308897137641907
30-01-2023 12:15:32 INFO Epoch 2: [8493/10940] ---- BYOL Validation Loss = 0.2620590925216675
30-01-2023 12:15:50 INFO Epoch 2: [8504/10940] ---- BYOL Training Loss = 0.3128051161766052
30-01-2023 12:16:09 INFO Epoch 2: [8515/10940] ---- BYOL Training Loss = 0.3193475604057312
30-01-2023 12:16:27 INFO Epoch 2: [8526/10940] ---- BYOL Training Loss = 0.3016686737537384
30-01-2023 12:16:45 INFO Epoch 2: [8537/10940] ---- BYOL Training Loss = 0.2894648611545563
30-01-2023 12:17:38 INFO Epoch 2: [8537/10940] ---- BYOL Validation Loss = 0.26767948269844055
30-01-2023 12:17:56 INFO Epoch 2: [8548/10940] ---- BYOL Training Loss = 0.3303868770599365
30-01-2023 12:18:14 INFO Epoch 2: [8559/10940] ---- BYOL Training Loss = 0.3177497684955597
30-01-2023 12:18:33 INFO Epoch 2: [8570/10940] ---- BYOL Training Loss = 0.23637275397777557
30-01-2023 12:18:51 INFO Epoch 2: [8581/10940] ---- BYOL Training Loss = 0.2310398519039154
30-01-2023 12:19:44 INFO Epoch 2: [8581/10940] ---- BYOL Validation Loss = 0.25298699736595154
30-01-2023 12:20:01 INFO Epoch 2: [8592/10940] ---- BYOL Training Loss = 0.27714860439300537
30-01-2023 12:20:20 INFO Epoch 2: [8603/10940] ---- BYOL Training Loss = 0.28479698300361633
30-01-2023 12:20:38 INFO Epoch 2: [8614/10940] ---- BYOL Training Loss = 0.26272815465927124
30-01-2023 12:20:56 INFO Epoch 2: [8625/10940] ---- BYOL Training Loss = 0.257483571767807
30-01-2023 12:21:49 INFO Epoch 2: [8625/10940] ---- BYOL Validation Loss = 0.26608943939208984
30-01-2023 12:22:07 INFO Epoch 2: [8636/10940] ---- BYOL Training Loss = 0.26309990882873535
30-01-2023 12:22:25 INFO Epoch 2: [8647/10940] ---- BYOL Training Loss = 0.27238065004348755
30-01-2023 12:22:43 INFO Epoch 2: [8658/10940] ---- BYOL Training Loss = 0.3180128037929535
30-01-2023 12:23:02 INFO Epoch 2: [8669/10940] ---- BYOL Training Loss = 0.3376062512397766
30-01-2023 12:23:54 INFO Epoch 2: [8669/10940] ---- BYOL Validation Loss = 0.2756774425506592
30-01-2023 12:24:12 INFO Epoch 2: [8680/10940] ---- BYOL Training Loss = 0.2988051474094391
30-01-2023 12:24:31 INFO Epoch 2: [8691/10940] ---- BYOL Training Loss = 0.2623719573020935
30-01-2023 12:24:49 INFO Epoch 2: [8702/10940] ---- BYOL Training Loss = 0.23634009063243866
30-01-2023 12:25:07 INFO Epoch 2: [8713/10940] ---- BYOL Training Loss = 0.2900155484676361
30-01-2023 12:26:00 INFO Epoch 2: [8713/10940] ---- BYOL Validation Loss = 0.27369195222854614
30-01-2023 12:26:18 INFO Epoch 2: [8724/10940] ---- BYOL Training Loss = 0.3435496389865875
30-01-2023 12:26:36 INFO Epoch 2: [8735/10940] ---- BYOL Training Loss = 0.261764794588089
30-01-2023 12:26:55 INFO Epoch 2: [8746/10940] ---- BYOL Training Loss = 0.2911854684352875
30-01-2023 12:27:13 INFO Epoch 2: [8757/10940] ---- BYOL Training Loss = 0.2925233840942383
30-01-2023 12:28:06 INFO Epoch 2: [8757/10940] ---- BYOL Validation Loss = 0.26343056559562683
30-01-2023 12:28:24 INFO Epoch 2: [8768/10940] ---- BYOL Training Loss = 0.26261717081069946
30-01-2023 12:28:42 INFO Epoch 2: [8779/10940] ---- BYOL Training Loss = 0.2943347692489624
30-01-2023 12:29:01 INFO Epoch 2: [8790/10940] ---- BYOL Training Loss = 0.30278319120407104
30-01-2023 12:29:19 INFO Epoch 2: [8801/10940] ---- BYOL Training Loss = 0.2711644172668457
30-01-2023 12:30:11 INFO Epoch 2: [8801/10940] ---- BYOL Validation Loss = 0.271711528301239
30-01-2023 12:30:30 INFO Epoch 2: [8812/10940] ---- BYOL Training Loss = 0.260320782661438
30-01-2023 12:30:48 INFO Epoch 2: [8823/10940] ---- BYOL Training Loss = 0.30027100443840027
30-01-2023 12:31:06 INFO Epoch 2: [8834/10940] ---- BYOL Training Loss = 0.29195135831832886
30-01-2023 12:31:25 INFO Epoch 2: [8845/10940] ---- BYOL Training Loss = 0.2779301106929779
30-01-2023 12:32:18 INFO Epoch 2: [8845/10940] ---- BYOL Validation Loss = 0.26308831572532654
30-01-2023 12:32:36 INFO Epoch 2: [8856/10940] ---- BYOL Training Loss = 0.27471381425857544
30-01-2023 12:32:54 INFO Epoch 2: [8867/10940] ---- BYOL Training Loss = 0.2571527063846588
30-01-2023 12:33:13 INFO Epoch 2: [8878/10940] ---- BYOL Training Loss = 0.24439117312431335
30-01-2023 12:33:31 INFO Epoch 2: [8889/10940] ---- BYOL Training Loss = 0.2439514696598053
30-01-2023 12:34:24 INFO Epoch 2: [8889/10940] ---- BYOL Validation Loss = 0.2551940083503723
30-01-2023 12:34:42 INFO Epoch 2: [8900/10940] ---- BYOL Training Loss = 0.2642909288406372
30-01-2023 12:35:00 INFO Epoch 2: [8911/10940] ---- BYOL Training Loss = 0.2621235251426697
30-01-2023 12:35:18 INFO Epoch 2: [8922/10940] ---- BYOL Training Loss = 0.2555120289325714
30-01-2023 12:35:37 INFO Epoch 2: [8933/10940] ---- BYOL Training Loss = 0.2323811799287796
30-01-2023 12:36:29 INFO Epoch 2: [8933/10940] ---- BYOL Validation Loss = 0.26170000433921814
30-01-2023 12:36:47 INFO Epoch 2: [8944/10940] ---- BYOL Training Loss = 0.17257627844810486
30-01-2023 12:37:05 INFO Epoch 2: [8955/10940] ---- BYOL Training Loss = 0.20667386054992676
30-01-2023 12:37:24 INFO Epoch 2: [8966/10940] ---- BYOL Training Loss = 0.2978622615337372
30-01-2023 12:37:42 INFO Epoch 2: [8977/10940] ---- BYOL Training Loss = 0.277534544467926
30-01-2023 12:38:35 INFO Epoch 2: [8977/10940] ---- BYOL Validation Loss = 0.2681439518928528
30-01-2023 12:38:53 INFO Epoch 2: [8988/10940] ---- BYOL Training Loss = 0.23510070145130157
30-01-2023 12:39:11 INFO Epoch 2: [8999/10940] ---- BYOL Training Loss = 0.27765172719955444
30-01-2023 12:39:30 INFO Epoch 2: [9010/10940] ---- BYOL Training Loss = 0.3121660351753235
30-01-2023 12:39:48 INFO Epoch 2: [9021/10940] ---- BYOL Training Loss = 0.28314292430877686
30-01-2023 12:40:41 INFO Epoch 2: [9021/10940] ---- BYOL Validation Loss = 0.261890709400177
30-01-2023 12:40:59 INFO Epoch 2: [9032/10940] ---- BYOL Training Loss = 0.28417980670928955
30-01-2023 12:41:17 INFO Epoch 2: [9043/10940] ---- BYOL Training Loss = 0.2888008952140808
30-01-2023 12:41:36 INFO Epoch 2: [9054/10940] ---- BYOL Training Loss = 0.2446366846561432
30-01-2023 12:41:54 INFO Epoch 2: [9065/10940] ---- BYOL Training Loss = 0.2506323456764221
30-01-2023 12:42:47 INFO Epoch 2: [9065/10940] ---- BYOL Validation Loss = 0.26791757345199585
30-01-2023 12:43:04 INFO Epoch 2: [9076/10940] ---- BYOL Training Loss = 0.2784321904182434
30-01-2023 12:43:23 INFO Epoch 2: [9087/10940] ---- BYOL Training Loss = 0.2825540006160736
30-01-2023 12:43:41 INFO Epoch 2: [9098/10940] ---- BYOL Training Loss = 0.23762920498847961
30-01-2023 12:44:00 INFO Epoch 2: [9109/10940] ---- BYOL Training Loss = 0.20855458080768585
30-01-2023 12:44:53 INFO Epoch 2: [9109/10940] ---- BYOL Validation Loss = 0.26223883032798767
30-01-2023 12:45:10 INFO Epoch 2: [9120/10940] ---- BYOL Training Loss = 0.24069413542747498
30-01-2023 12:45:28 INFO Epoch 2: [9131/10940] ---- BYOL Training Loss = 0.26771193742752075
30-01-2023 12:45:47 INFO Epoch 2: [9142/10940] ---- BYOL Training Loss = 0.3011821210384369
30-01-2023 12:46:05 INFO Epoch 2: [9153/10940] ---- BYOL Training Loss = 0.28436970710754395
30-01-2023 12:46:58 INFO Epoch 2: [9153/10940] ---- BYOL Validation Loss = 0.26633334159851074
30-01-2023 12:47:16 INFO Epoch 2: [9164/10940] ---- BYOL Training Loss = 0.2872944474220276
30-01-2023 12:47:35 INFO Epoch 2: [9175/10940] ---- BYOL Training Loss = 0.2897249758243561
30-01-2023 12:47:53 INFO Epoch 2: [9186/10940] ---- BYOL Training Loss = 0.27408814430236816
30-01-2023 12:48:12 INFO Epoch 2: [9197/10940] ---- BYOL Training Loss = 0.29270869493484497
30-01-2023 12:49:04 INFO Epoch 2: [9197/10940] ---- BYOL Validation Loss = 0.26065847277641296
30-01-2023 12:49:22 INFO Epoch 2: [9208/10940] ---- BYOL Training Loss = 0.27251100540161133
30-01-2023 12:49:40 INFO Epoch 2: [9219/10940] ---- BYOL Training Loss = 0.2370947301387787
30-01-2023 12:49:59 INFO Epoch 2: [9230/10940] ---- BYOL Training Loss = 0.2502758502960205
30-01-2023 12:50:17 INFO Epoch 2: [9241/10940] ---- BYOL Training Loss = 0.25313520431518555
30-01-2023 12:51:10 INFO Epoch 2: [9241/10940] ---- BYOL Validation Loss = 0.26106691360473633
30-01-2023 12:51:27 INFO Epoch 2: [9252/10940] ---- BYOL Training Loss = 0.2718461751937866
30-01-2023 12:51:46 INFO Epoch 2: [9263/10940] ---- BYOL Training Loss = 0.2901253402233124
30-01-2023 12:52:04 INFO Epoch 2: [9274/10940] ---- BYOL Training Loss = 0.2721073627471924
30-01-2023 12:52:23 INFO Epoch 2: [9285/10940] ---- BYOL Training Loss = 0.2544749081134796
30-01-2023 12:53:16 INFO Epoch 2: [9285/10940] ---- BYOL Validation Loss = 0.26409295201301575
30-01-2023 12:53:33 INFO Epoch 2: [9296/10940] ---- BYOL Training Loss = 0.2854437232017517
30-01-2023 12:53:52 INFO Epoch 2: [9307/10940] ---- BYOL Training Loss = 0.2932688891887665
30-01-2023 12:54:10 INFO Epoch 2: [9318/10940] ---- BYOL Training Loss = 0.2705226540565491
30-01-2023 12:54:29 INFO Epoch 2: [9329/10940] ---- BYOL Training Loss = 0.2655428647994995
30-01-2023 12:55:21 INFO Epoch 2: [9329/10940] ---- BYOL Validation Loss = 0.25796636939048767
30-01-2023 12:55:40 INFO Epoch 2: [9340/10940] ---- BYOL Training Loss = 0.26825982332229614
30-01-2023 12:55:58 INFO Epoch 2: [9351/10940] ---- BYOL Training Loss = 0.288718044757843
30-01-2023 12:56:16 INFO Epoch 2: [9362/10940] ---- BYOL Training Loss = 0.2601434886455536
30-01-2023 12:56:35 INFO Epoch 2: [9373/10940] ---- BYOL Training Loss = 0.2602262496948242
30-01-2023 12:57:27 INFO Epoch 2: [9373/10940] ---- BYOL Validation Loss = 0.25863149762153625
30-01-2023 12:57:45 INFO Epoch 2: [9384/10940] ---- BYOL Training Loss = 0.2499479353427887
30-01-2023 12:58:04 INFO Epoch 2: [9395/10940] ---- BYOL Training Loss = 0.2669171392917633
30-01-2023 12:58:22 INFO Epoch 2: [9406/10940] ---- BYOL Training Loss = 0.2706604301929474
30-01-2023 12:58:41 INFO Epoch 2: [9417/10940] ---- BYOL Training Loss = 0.2572241425514221
30-01-2023 12:59:33 INFO Epoch 2: [9417/10940] ---- BYOL Validation Loss = 0.23468075692653656
30-01-2023 12:59:52 INFO Epoch 2: [9428/10940] ---- BYOL Training Loss = 0.23760946094989777
30-01-2023 13:00:10 INFO Epoch 2: [9439/10940] ---- BYOL Training Loss = 0.26859837770462036
30-01-2023 13:00:28 INFO Epoch 2: [9450/10940] ---- BYOL Training Loss = 0.28693097829818726
30-01-2023 13:00:47 INFO Epoch 2: [9461/10940] ---- BYOL Training Loss = 0.2871357202529907
30-01-2023 13:01:40 INFO Epoch 2: [9461/10940] ---- BYOL Validation Loss = 0.24575884640216827
30-01-2023 13:01:57 INFO Epoch 2: [9472/10940] ---- BYOL Training Loss = 0.26896676421165466
30-01-2023 13:02:16 INFO Epoch 2: [9483/10940] ---- BYOL Training Loss = 0.24577856063842773
30-01-2023 13:02:34 INFO Epoch 2: [9494/10940] ---- BYOL Training Loss = 0.27007585763931274
30-01-2023 13:02:52 INFO Epoch 2: [9505/10940] ---- BYOL Training Loss = 0.2711600363254547
30-01-2023 13:03:45 INFO Epoch 2: [9505/10940] ---- BYOL Validation Loss = 0.265372097492218
30-01-2023 13:04:03 INFO Epoch 2: [9516/10940] ---- BYOL Training Loss = 0.288139283657074
30-01-2023 13:04:22 INFO Epoch 2: [9527/10940] ---- BYOL Training Loss = 0.28721246123313904
30-01-2023 13:04:40 INFO Epoch 2: [9538/10940] ---- BYOL Training Loss = 0.2397812306880951
30-01-2023 13:04:58 INFO Epoch 2: [9549/10940] ---- BYOL Training Loss = 0.23416081070899963
30-01-2023 13:05:51 INFO Epoch 2: [9549/10940] ---- BYOL Validation Loss = 0.25229892134666443
30-01-2023 13:06:09 INFO Epoch 2: [9560/10940] ---- BYOL Training Loss = 0.23901036381721497
30-01-2023 13:06:28 INFO Epoch 2: [9571/10940] ---- BYOL Training Loss = 0.22683556377887726
30-01-2023 13:06:46 INFO Epoch 2: [9582/10940] ---- BYOL Training Loss = 0.25463905930519104
30-01-2023 13:07:05 INFO Epoch 2: [9593/10940] ---- BYOL Training Loss = 0.2881641983985901
30-01-2023 13:07:58 INFO Epoch 2: [9593/10940] ---- BYOL Validation Loss = 0.2615235149860382
30-01-2023 13:08:16 INFO Epoch 2: [9604/10940] ---- BYOL Training Loss = 0.2897200584411621
30-01-2023 13:08:34 INFO Epoch 2: [9615/10940] ---- BYOL Training Loss = 0.26633507013320923
30-01-2023 13:08:53 INFO Epoch 2: [9626/10940] ---- BYOL Training Loss = 0.2126038819551468
30-01-2023 13:09:11 INFO Epoch 2: [9637/10940] ---- BYOL Training Loss = 0.24697479605674744
30-01-2023 13:10:04 INFO Epoch 2: [9637/10940] ---- BYOL Validation Loss = 0.25515344738960266
30-01-2023 13:10:23 INFO Epoch 2: [9648/10940] ---- BYOL Training Loss = 0.2646065950393677
30-01-2023 13:10:41 INFO Epoch 2: [9659/10940] ---- BYOL Training Loss = 0.23862676322460175
30-01-2023 13:11:00 INFO Epoch 2: [9670/10940] ---- BYOL Training Loss = 0.2548006474971771
30-01-2023 13:11:18 INFO Epoch 2: [9681/10940] ---- BYOL Training Loss = 0.26979681849479675
30-01-2023 13:12:11 INFO Epoch 2: [9681/10940] ---- BYOL Validation Loss = 0.25686103105545044
30-01-2023 13:12:29 INFO Epoch 2: [9692/10940] ---- BYOL Training Loss = 0.265794038772583
30-01-2023 13:12:47 INFO Epoch 2: [9703/10940] ---- BYOL Training Loss = 0.24774523079395294
30-01-2023 13:13:06 INFO Epoch 2: [9714/10940] ---- BYOL Training Loss = 0.2316916435956955
30-01-2023 13:13:24 INFO Epoch 2: [9725/10940] ---- BYOL Training Loss = 0.26712509989738464
30-01-2023 13:14:17 INFO Epoch 2: [9725/10940] ---- BYOL Validation Loss = 0.2491822987794876
30-01-2023 13:14:35 INFO Epoch 2: [9736/10940] ---- BYOL Training Loss = 0.2578667998313904
30-01-2023 13:14:53 INFO Epoch 2: [9747/10940] ---- BYOL Training Loss = 0.24623069167137146
30-01-2023 13:15:12 INFO Epoch 2: [9758/10940] ---- BYOL Training Loss = 0.23684649169445038
30-01-2023 13:15:30 INFO Epoch 2: [9769/10940] ---- BYOL Training Loss = 0.23940515518188477
30-01-2023 13:16:23 INFO Epoch 2: [9769/10940] ---- BYOL Validation Loss = 0.2575700581073761
30-01-2023 13:16:41 INFO Epoch 2: [9780/10940] ---- BYOL Training Loss = 0.2645656168460846
30-01-2023 13:17:00 INFO Epoch 2: [9791/10940] ---- BYOL Training Loss = 0.2951419949531555
30-01-2023 13:17:18 INFO Epoch 2: [9802/10940] ---- BYOL Training Loss = 0.29050523042678833
30-01-2023 13:17:36 INFO Epoch 2: [9813/10940] ---- BYOL Training Loss = 0.2509317100048065
30-01-2023 13:18:29 INFO Epoch 2: [9813/10940] ---- BYOL Validation Loss = 0.2661379277706146
30-01-2023 13:18:47 INFO Epoch 2: [9824/10940] ---- BYOL Training Loss = 0.2879396378993988
30-01-2023 13:19:06 INFO Epoch 2: [9835/10940] ---- BYOL Training Loss = 0.32290929555892944
30-01-2023 13:19:24 INFO Epoch 2: [9846/10940] ---- BYOL Training Loss = 0.29026204347610474
30-01-2023 13:19:43 INFO Epoch 2: [9857/10940] ---- BYOL Training Loss = 0.2538127303123474
30-01-2023 13:20:35 INFO Epoch 2: [9857/10940] ---- BYOL Validation Loss = 0.25628504157066345
30-01-2023 13:20:54 INFO Epoch 2: [9868/10940] ---- BYOL Training Loss = 0.25055190920829773
30-01-2023 13:21:12 INFO Epoch 2: [9879/10940] ---- BYOL Training Loss = 0.33404436707496643
30-01-2023 13:21:30 INFO Epoch 2: [9890/10940] ---- BYOL Training Loss = 0.3045410215854645
30-01-2023 13:21:49 INFO Epoch 2: [9901/10940] ---- BYOL Training Loss = 0.29396048188209534
30-01-2023 13:22:42 INFO Epoch 2: [9901/10940] ---- BYOL Validation Loss = 0.2588377594947815
30-01-2023 13:23:00 INFO Epoch 2: [9912/10940] ---- BYOL Training Loss = 0.2594301104545593
30-01-2023 13:23:19 INFO Epoch 2: [9923/10940] ---- BYOL Training Loss = 0.26603806018829346
30-01-2023 13:23:37 INFO Epoch 2: [9934/10940] ---- BYOL Training Loss = 0.28544771671295166
30-01-2023 13:23:56 INFO Epoch 2: [9945/10940] ---- BYOL Training Loss = 0.28542187809944153
30-01-2023 13:24:48 INFO Epoch 2: [9945/10940] ---- BYOL Validation Loss = 0.26803064346313477
30-01-2023 13:25:06 INFO Epoch 2: [9956/10940] ---- BYOL Training Loss = 0.25158625841140747
30-01-2023 13:25:25 INFO Epoch 2: [9967/10940] ---- BYOL Training Loss = 0.2581377625465393
30-01-2023 13:25:43 INFO Epoch 2: [9978/10940] ---- BYOL Training Loss = 0.27565163373947144
30-01-2023 13:26:02 INFO Epoch 2: [9989/10940] ---- BYOL Training Loss = 0.30896085500717163
30-01-2023 13:26:54 INFO Epoch 2: [9989/10940] ---- BYOL Validation Loss = 0.2705298960208893
30-01-2023 13:27:13 INFO Epoch 2: [10000/10940] ---- BYOL Training Loss = 0.32658785581588745
30-01-2023 13:27:31 INFO Epoch 2: [10011/10940] ---- BYOL Training Loss = 0.2416660487651825
30-01-2023 13:27:49 INFO Epoch 2: [10022/10940] ---- BYOL Training Loss = 0.28004613518714905
30-01-2023 13:28:08 INFO Epoch 2: [10033/10940] ---- BYOL Training Loss = 0.30076417326927185
30-01-2023 13:29:01 INFO Epoch 2: [10033/10940] ---- BYOL Validation Loss = 0.23984408378601074
30-01-2023 13:29:19 INFO Epoch 2: [10044/10940] ---- BYOL Training Loss = 0.27166548371315
30-01-2023 13:29:37 INFO Epoch 2: [10055/10940] ---- BYOL Training Loss = 0.25672847032546997
30-01-2023 13:29:56 INFO Epoch 2: [10066/10940] ---- BYOL Training Loss = 0.24487197399139404
30-01-2023 13:30:14 INFO Epoch 2: [10077/10940] ---- BYOL Training Loss = 0.2585211396217346
30-01-2023 13:31:07 INFO Epoch 2: [10077/10940] ---- BYOL Validation Loss = 0.25360599160194397
30-01-2023 13:31:25 INFO Epoch 2: [10088/10940] ---- BYOL Training Loss = 0.24255509674549103
30-01-2023 13:31:43 INFO Epoch 2: [10099/10940] ---- BYOL Training Loss = 0.26832315325737
30-01-2023 13:32:02 INFO Epoch 2: [10110/10940] ---- BYOL Training Loss = 0.2861654758453369
30-01-2023 13:32:20 INFO Epoch 2: [10121/10940] ---- BYOL Training Loss = 0.25748389959335327
30-01-2023 13:33:13 INFO Epoch 2: [10121/10940] ---- BYOL Validation Loss = 0.2595006227493286
30-01-2023 13:33:31 INFO Epoch 2: [10132/10940] ---- BYOL Training Loss = 0.2466636449098587
30-01-2023 13:33:50 INFO Epoch 2: [10143/10940] ---- BYOL Training Loss = 0.2895576059818268
30-01-2023 13:34:08 INFO Epoch 2: [10154/10940] ---- BYOL Training Loss = 0.3037869334220886
30-01-2023 13:34:27 INFO Epoch 2: [10165/10940] ---- BYOL Training Loss = 0.27096983790397644
30-01-2023 13:35:19 INFO Epoch 2: [10165/10940] ---- BYOL Validation Loss = 0.25232362747192383
30-01-2023 13:35:37 INFO Epoch 2: [10176/10940] ---- BYOL Training Loss = 0.2408687174320221
30-01-2023 13:35:56 INFO Epoch 2: [10187/10940] ---- BYOL Training Loss = 0.28966599702835083
30-01-2023 13:36:15 INFO Epoch 2: [10198/10940] ---- BYOL Training Loss = 0.28983017802238464
30-01-2023 13:36:34 INFO Epoch 2: [10209/10940] ---- BYOL Training Loss = 0.2959665060043335
30-01-2023 13:37:27 INFO Epoch 2: [10209/10940] ---- BYOL Validation Loss = 0.25992709398269653
30-01-2023 13:37:45 INFO Epoch 2: [10220/10940] ---- BYOL Training Loss = 0.29747962951660156
30-01-2023 13:38:03 INFO Epoch 2: [10231/10940] ---- BYOL Training Loss = 0.31627506017684937
30-01-2023 13:38:22 INFO Epoch 2: [10242/10940] ---- BYOL Training Loss = 0.3068455159664154
30-01-2023 13:38:40 INFO Epoch 2: [10253/10940] ---- BYOL Training Loss = 0.2992568016052246
30-01-2023 13:39:33 INFO Epoch 2: [10253/10940] ---- BYOL Validation Loss = 0.2594699263572693
30-01-2023 13:39:51 INFO Epoch 2: [10264/10940] ---- BYOL Training Loss = 0.34050655364990234
30-01-2023 13:40:10 INFO Epoch 2: [10275/10940] ---- BYOL Training Loss = 0.299963116645813
30-01-2023 13:40:28 INFO Epoch 2: [10286/10940] ---- BYOL Training Loss = 0.2511925995349884
30-01-2023 13:40:47 INFO Epoch 2: [10297/10940] ---- BYOL Training Loss = 0.23443913459777832
30-01-2023 13:41:39 INFO Epoch 2: [10297/10940] ---- BYOL Validation Loss = 0.2501523792743683
30-01-2023 13:41:57 INFO Epoch 2: [10308/10940] ---- BYOL Training Loss = 0.23344102501869202
30-01-2023 13:42:16 INFO Epoch 2: [10319/10940] ---- BYOL Training Loss = 0.23276075720787048
30-01-2023 13:42:34 INFO Epoch 2: [10330/10940] ---- BYOL Training Loss = 0.2322114259004593
30-01-2023 13:42:53 INFO Epoch 2: [10341/10940] ---- BYOL Training Loss = 0.24080507457256317
30-01-2023 13:43:46 INFO Epoch 2: [10341/10940] ---- BYOL Validation Loss = 0.24437345564365387
30-01-2023 13:44:03 INFO Epoch 2: [10352/10940] ---- BYOL Training Loss = 0.25863638520240784
30-01-2023 13:44:22 INFO Epoch 2: [10363/10940] ---- BYOL Training Loss = 0.28519898653030396
30-01-2023 13:44:40 INFO Epoch 2: [10374/10940] ---- BYOL Training Loss = 0.29919683933258057
30-01-2023 13:44:59 INFO Epoch 2: [10385/10940] ---- BYOL Training Loss = 0.31016311049461365
30-01-2023 13:45:51 INFO Epoch 2: [10385/10940] ---- BYOL Validation Loss = 0.27388060092926025
30-01-2023 13:46:10 INFO Epoch 2: [10396/10940] ---- BYOL Training Loss = 0.2938920855522156
30-01-2023 13:46:28 INFO Epoch 2: [10407/10940] ---- BYOL Training Loss = 0.3139762878417969
30-01-2023 13:46:47 INFO Epoch 2: [10418/10940] ---- BYOL Training Loss = 0.313044011592865
30-01-2023 13:47:05 INFO Epoch 2: [10429/10940] ---- BYOL Training Loss = 0.2614174485206604
30-01-2023 13:47:58 INFO Epoch 2: [10429/10940] ---- BYOL Validation Loss = 0.26128077507019043
30-01-2023 13:48:16 INFO Epoch 2: [10440/10940] ---- BYOL Training Loss = 0.24673259258270264
30-01-2023 13:48:35 INFO Epoch 2: [10451/10940] ---- BYOL Training Loss = 0.2731212377548218
30-01-2023 13:48:53 INFO Epoch 2: [10462/10940] ---- BYOL Training Loss = 0.26879802346229553
30-01-2023 13:49:12 INFO Epoch 2: [10473/10940] ---- BYOL Training Loss = 0.3036155104637146
30-01-2023 13:50:04 INFO Epoch 2: [10473/10940] ---- BYOL Validation Loss = 0.26375412940979004
30-01-2023 13:50:22 INFO Epoch 2: [10484/10940] ---- BYOL Training Loss = 0.2773168683052063
30-01-2023 13:50:41 INFO Epoch 2: [10495/10940] ---- BYOL Training Loss = 0.2532767355442047
30-01-2023 13:50:59 INFO Epoch 2: [10506/10940] ---- BYOL Training Loss = 0.2505284249782562
30-01-2023 13:51:18 INFO Epoch 2: [10517/10940] ---- BYOL Training Loss = 0.2610190212726593
30-01-2023 13:52:11 INFO Epoch 2: [10517/10940] ---- BYOL Validation Loss = 0.25048306584358215
30-01-2023 13:52:29 INFO Epoch 2: [10528/10940] ---- BYOL Training Loss = 0.2595164477825165
30-01-2023 13:52:48 INFO Epoch 2: [10539/10940] ---- BYOL Training Loss = 0.27777600288391113
30-01-2023 13:53:06 INFO Epoch 2: [10550/10940] ---- BYOL Training Loss = 0.2939493954181671
30-01-2023 13:53:25 INFO Epoch 2: [10561/10940] ---- BYOL Training Loss = 0.26947036385536194
30-01-2023 13:54:17 INFO Epoch 2: [10561/10940] ---- BYOL Validation Loss = 0.2291475385427475
30-01-2023 13:54:35 INFO Epoch 2: [10572/10940] ---- BYOL Training Loss = 0.2231278419494629
30-01-2023 13:54:54 INFO Epoch 2: [10583/10940] ---- BYOL Training Loss = 0.24169322848320007
30-01-2023 13:55:12 INFO Epoch 2: [10594/10940] ---- BYOL Training Loss = 0.25176483392715454
30-01-2023 13:55:31 INFO Epoch 2: [10605/10940] ---- BYOL Training Loss = 0.22884945571422577
30-01-2023 13:56:23 INFO Epoch 2: [10605/10940] ---- BYOL Validation Loss = 0.26435741782188416
30-01-2023 13:56:42 INFO Epoch 2: [10616/10940] ---- BYOL Training Loss = 0.25549331307411194
30-01-2023 13:57:00 INFO Epoch 2: [10627/10940] ---- BYOL Training Loss = 0.2852345407009125
30-01-2023 13:57:19 INFO Epoch 2: [10638/10940] ---- BYOL Training Loss = 0.27889057993888855
30-01-2023 13:57:37 INFO Epoch 2: [10649/10940] ---- BYOL Training Loss = 0.22018161416053772
30-01-2023 13:58:30 INFO Epoch 2: [10649/10940] ---- BYOL Validation Loss = 0.2436111867427826
30-01-2023 13:58:48 INFO Epoch 2: [10660/10940] ---- BYOL Training Loss = 0.23773089051246643
30-01-2023 13:59:07 INFO Epoch 2: [10671/10940] ---- BYOL Training Loss = 0.2849627137184143
30-01-2023 13:59:25 INFO Epoch 2: [10682/10940] ---- BYOL Training Loss = 0.24365253746509552
30-01-2023 13:59:44 INFO Epoch 2: [10693/10940] ---- BYOL Training Loss = 0.2509952783584595
30-01-2023 14:00:37 INFO Epoch 2: [10693/10940] ---- BYOL Validation Loss = 0.24719850718975067
30-01-2023 14:00:55 INFO Epoch 2: [10704/10940] ---- BYOL Training Loss = 0.27421432733535767
30-01-2023 14:01:13 INFO Epoch 2: [10715/10940] ---- BYOL Training Loss = 0.26575973629951477
30-01-2023 14:01:32 INFO Epoch 2: [10726/10940] ---- BYOL Training Loss = 0.28713202476501465
30-01-2023 14:01:51 INFO Epoch 2: [10737/10940] ---- BYOL Training Loss = 0.2902572453022003
30-01-2023 14:02:43 INFO Epoch 2: [10737/10940] ---- BYOL Validation Loss = 0.2461402416229248
30-01-2023 14:03:01 INFO Epoch 2: [10748/10940] ---- BYOL Training Loss = 0.25939762592315674
30-01-2023 14:03:20 INFO Epoch 2: [10759/10940] ---- BYOL Training Loss = 0.25293686985969543
30-01-2023 14:03:39 INFO Epoch 2: [10770/10940] ---- BYOL Training Loss = 0.2399863749742508
30-01-2023 14:03:57 INFO Epoch 2: [10781/10940] ---- BYOL Training Loss = 0.26963862776756287
30-01-2023 14:04:49 INFO Epoch 2: [10781/10940] ---- BYOL Validation Loss = 0.2534308433532715
30-01-2023 14:05:08 INFO Epoch 2: [10792/10940] ---- BYOL Training Loss = 0.2764586806297302
30-01-2023 14:05:27 INFO Epoch 2: [10803/10940] ---- BYOL Training Loss = 0.30494424700737
30-01-2023 14:05:45 INFO Epoch 2: [10814/10940] ---- BYOL Training Loss = 0.29251545667648315
30-01-2023 14:06:04 INFO Epoch 2: [10825/10940] ---- BYOL Training Loss = 0.328648179769516
30-01-2023 14:06:57 INFO Epoch 2: [10825/10940] ---- BYOL Validation Loss = 0.26863303780555725
30-01-2023 14:07:15 INFO Epoch 2: [10836/10940] ---- BYOL Training Loss = 0.29298052191734314
30-01-2023 14:07:33 INFO Epoch 2: [10847/10940] ---- BYOL Training Loss = 0.2699299454689026
30-01-2023 14:07:52 INFO Epoch 2: [10858/10940] ---- BYOL Training Loss = 0.2811064124107361
30-01-2023 14:08:10 INFO Epoch 2: [10869/10940] ---- BYOL Training Loss = 0.2641759514808655
30-01-2023 14:09:03 INFO Epoch 2: [10869/10940] ---- BYOL Validation Loss = 0.2546209990978241
30-01-2023 14:09:21 INFO Epoch 2: [10880/10940] ---- BYOL Training Loss = 0.22460484504699707
30-01-2023 14:09:40 INFO Epoch 2: [10891/10940] ---- BYOL Training Loss = 0.25235864520072937
30-01-2023 14:09:58 INFO Epoch 2: [10902/10940] ---- BYOL Training Loss = 0.2645079493522644
30-01-2023 14:10:17 INFO Epoch 2: [10913/10940] ---- BYOL Training Loss = 0.262850284576416
30-01-2023 14:11:10 INFO Epoch 2: [10913/10940] ---- BYOL Validation Loss = 0.25812748074531555
30-01-2023 14:11:28 INFO Epoch 2: [10924/10940] ---- BYOL Training Loss = 0.2768927812576294
30-01-2023 14:11:46 INFO Epoch 2: [10935/10940] ---- BYOL Training Loss = 0.24233832955360413
30-01-2023 14:11:55 INFO Starting Epoch: 3
30-01-2023 14:12:14 INFO Epoch 3: [12/10940] ---- BYOL Training Loss = 0.26087480783462524
30-01-2023 14:12:31 INFO Epoch 3: [23/10940] ---- BYOL Training Loss = 0.2570032775402069
30-01-2023 14:12:49 INFO Epoch 3: [34/10940] ---- BYOL Training Loss = 0.2551586329936981
30-01-2023 14:13:06 INFO Epoch 3: [45/10940] ---- BYOL Training Loss = 0.22504529356956482
30-01-2023 14:13:59 INFO Epoch 3: [45/10940] ---- BYOL Validation Loss = 0.22330056130886078
30-01-2023 14:14:16 INFO Epoch 3: [56/10940] ---- BYOL Training Loss = 0.22509512305259705
30-01-2023 14:14:33 INFO Epoch 3: [67/10940] ---- BYOL Training Loss = 0.22887298464775085
30-01-2023 14:14:51 INFO Epoch 3: [78/10940] ---- BYOL Training Loss = 0.255272775888443
30-01-2023 14:15:08 INFO Epoch 3: [89/10940] ---- BYOL Training Loss = 0.23929838836193085
30-01-2023 14:16:01 INFO Epoch 3: [89/10940] ---- BYOL Validation Loss = 0.24247527122497559
30-01-2023 14:16:18 INFO Epoch 3: [100/10940] ---- BYOL Training Loss = 0.22245588898658752
30-01-2023 14:16:36 INFO Epoch 3: [111/10940] ---- BYOL Training Loss = 0.24057511985301971
30-01-2023 14:16:53 INFO Epoch 3: [122/10940] ---- BYOL Training Loss = 0.24849078059196472
30-01-2023 14:17:11 INFO Epoch 3: [133/10940] ---- BYOL Training Loss = 0.24115554988384247
30-01-2023 14:18:03 INFO Epoch 3: [133/10940] ---- BYOL Validation Loss = 0.2441103756427765
30-01-2023 14:18:20 INFO Epoch 3: [144/10940] ---- BYOL Training Loss = 0.23471471667289734
30-01-2023 14:18:38 INFO Epoch 3: [155/10940] ---- BYOL Training Loss = 0.23554711043834686
30-01-2023 14:18:55 INFO Epoch 3: [166/10940] ---- BYOL Training Loss = 0.2572041153907776
30-01-2023 14:19:13 INFO Epoch 3: [177/10940] ---- BYOL Training Loss = 0.321346253156662
30-01-2023 14:20:05 INFO Epoch 3: [177/10940] ---- BYOL Validation Loss = 0.25603601336479187
30-01-2023 14:20:22 INFO Epoch 3: [188/10940] ---- BYOL Training Loss = 0.299955278635025
30-01-2023 14:20:40 INFO Epoch 3: [199/10940] ---- BYOL Training Loss = 0.26673009991645813
30-01-2023 14:20:57 INFO Epoch 3: [210/10940] ---- BYOL Training Loss = 0.2158491313457489
30-01-2023 14:21:15 INFO Epoch 3: [221/10940] ---- BYOL Training Loss = 0.242658331990242
30-01-2023 14:22:07 INFO Epoch 3: [221/10940] ---- BYOL Validation Loss = 0.235633984208107
30-01-2023 14:22:25 INFO Epoch 3: [232/10940] ---- BYOL Training Loss = 0.2659161686897278
30-01-2023 14:22:42 INFO Epoch 3: [243/10940] ---- BYOL Training Loss = 0.26408591866493225
30-01-2023 14:23:00 INFO Epoch 3: [254/10940] ---- BYOL Training Loss = 0.23361293971538544
30-01-2023 14:23:17 INFO Epoch 3: [265/10940] ---- BYOL Training Loss = 0.2638672888278961
30-01-2023 14:24:10 INFO Epoch 3: [265/10940] ---- BYOL Validation Loss = 0.24994489550590515
30-01-2023 14:24:27 INFO Epoch 3: [276/10940] ---- BYOL Training Loss = 0.26350632309913635
30-01-2023 14:24:44 INFO Epoch 3: [287/10940] ---- BYOL Training Loss = 0.27026063203811646
30-01-2023 14:25:02 INFO Epoch 3: [298/10940] ---- BYOL Training Loss = 0.242025688290596
30-01-2023 14:25:19 INFO Epoch 3: [309/10940] ---- BYOL Training Loss = 0.24783265590667725
30-01-2023 14:26:12 INFO Epoch 3: [309/10940] ---- BYOL Validation Loss = 0.2477509081363678
30-01-2023 14:26:29 INFO Epoch 3: [320/10940] ---- BYOL Training Loss = 0.2885308861732483
30-01-2023 14:26:47 INFO Epoch 3: [331/10940] ---- BYOL Training Loss = 0.274691641330719
30-01-2023 14:27:04 INFO Epoch 3: [342/10940] ---- BYOL Training Loss = 0.23576799035072327
30-01-2023 14:27:22 INFO Epoch 3: [353/10940] ---- BYOL Training Loss = 0.22751784324645996
30-01-2023 14:28:14 INFO Epoch 3: [353/10940] ---- BYOL Validation Loss = 0.23660339415073395
30-01-2023 14:28:31 INFO Epoch 3: [364/10940] ---- BYOL Training Loss = 0.25140517950057983
30-01-2023 14:28:49 INFO Epoch 3: [375/10940] ---- BYOL Training Loss = 0.23681893944740295
30-01-2023 14:29:06 INFO Epoch 3: [386/10940] ---- BYOL Training Loss = 0.27637577056884766
30-01-2023 14:29:24 INFO Epoch 3: [397/10940] ---- BYOL Training Loss = 0.2682840824127197
30-01-2023 14:30:17 INFO Epoch 3: [397/10940] ---- BYOL Validation Loss = 0.2698853015899658
30-01-2023 14:30:34 INFO Epoch 3: [408/10940] ---- BYOL Training Loss = 0.2780706286430359
30-01-2023 14:30:51 INFO Epoch 3: [419/10940] ---- BYOL Training Loss = 0.28268885612487793
30-01-2023 14:31:09 INFO Epoch 3: [430/10940] ---- BYOL Training Loss = 0.2694433331489563
30-01-2023 14:31:26 INFO Epoch 3: [441/10940] ---- BYOL Training Loss = 0.24331212043762207
30-01-2023 14:32:19 INFO Epoch 3: [441/10940] ---- BYOL Validation Loss = 0.2654392421245575
30-01-2023 14:32:36 INFO Epoch 3: [452/10940] ---- BYOL Training Loss = 0.2872798442840576
30-01-2023 14:32:54 INFO Epoch 3: [463/10940] ---- BYOL Training Loss = 0.3321194052696228
30-01-2023 14:33:11 INFO Epoch 3: [474/10940] ---- BYOL Training Loss = 0.3339347243309021
30-01-2023 14:33:29 INFO Epoch 3: [485/10940] ---- BYOL Training Loss = 0.32639843225479126
30-01-2023 14:34:21 INFO Epoch 3: [485/10940] ---- BYOL Validation Loss = 0.24737785756587982
30-01-2023 14:34:38 INFO Epoch 3: [496/10940] ---- BYOL Training Loss = 0.3151172697544098
30-01-2023 14:34:56 INFO Epoch 3: [507/10940] ---- BYOL Training Loss = 0.2821936011314392
30-01-2023 14:35:13 INFO Epoch 3: [518/10940] ---- BYOL Training Loss = 0.26244229078292847
30-01-2023 14:35:31 INFO Epoch 3: [529/10940] ---- BYOL Training Loss = 0.25361689925193787
30-01-2023 14:36:24 INFO Epoch 3: [529/10940] ---- BYOL Validation Loss = 0.2517792880535126
30-01-2023 14:36:41 INFO Epoch 3: [540/10940] ---- BYOL Training Loss = 0.27913323044776917
30-01-2023 14:36:58 INFO Epoch 3: [551/10940] ---- BYOL Training Loss = 0.29408591985702515
30-01-2023 14:37:16 INFO Epoch 3: [562/10940] ---- BYOL Training Loss = 0.2800150215625763
30-01-2023 14:37:33 INFO Epoch 3: [573/10940] ---- BYOL Training Loss = 0.28173238039016724
30-01-2023 14:38:26 INFO Epoch 3: [573/10940] ---- BYOL Validation Loss = 0.26478996872901917
30-01-2023 14:38:43 INFO Epoch 3: [584/10940] ---- BYOL Training Loss = 0.26946085691452026
30-01-2023 14:39:01 INFO Epoch 3: [595/10940] ---- BYOL Training Loss = 0.2410140037536621
30-01-2023 14:39:18 INFO Epoch 3: [606/10940] ---- BYOL Training Loss = 0.25672173500061035
30-01-2023 14:39:36 INFO Epoch 3: [617/10940] ---- BYOL Training Loss = 0.24566027522087097
30-01-2023 14:40:29 INFO Epoch 3: [617/10940] ---- BYOL Validation Loss = 0.24358074367046356
30-01-2023 14:40:46 INFO Epoch 3: [628/10940] ---- BYOL Training Loss = 0.25039881467819214
30-01-2023 14:41:03 INFO Epoch 3: [639/10940] ---- BYOL Training Loss = 0.2621217370033264
30-01-2023 14:41:21 INFO Epoch 3: [650/10940] ---- BYOL Training Loss = 0.25801384449005127
30-01-2023 14:41:38 INFO Epoch 3: [661/10940] ---- BYOL Training Loss = 0.2956596314907074
30-01-2023 14:42:31 INFO Epoch 3: [661/10940] ---- BYOL Validation Loss = 0.2673681676387787
30-01-2023 14:42:48 INFO Epoch 3: [672/10940] ---- BYOL Training Loss = 0.30595663189888
30-01-2023 14:43:06 INFO Epoch 3: [683/10940] ---- BYOL Training Loss = 0.2747900187969208
30-01-2023 14:43:23 INFO Epoch 3: [694/10940] ---- BYOL Training Loss = 0.27575987577438354
30-01-2023 14:43:41 INFO Epoch 3: [705/10940] ---- BYOL Training Loss = 0.3092311918735504
30-01-2023 14:44:34 INFO Epoch 3: [705/10940] ---- BYOL Validation Loss = 0.24525482952594757
30-01-2023 14:44:51 INFO Epoch 3: [716/10940] ---- BYOL Training Loss = 0.2867673635482788
30-01-2023 14:45:08 INFO Epoch 3: [727/10940] ---- BYOL Training Loss = 0.2646487355232239
30-01-2023 14:45:26 INFO Epoch 3: [738/10940] ---- BYOL Training Loss = 0.2914155423641205
30-01-2023 14:45:44 INFO Epoch 3: [749/10940] ---- BYOL Training Loss = 0.32411134243011475
30-01-2023 14:46:36 INFO Epoch 3: [749/10940] ---- BYOL Validation Loss = 0.18689748644828796
30-01-2023 14:46:54 INFO Epoch 3: [760/10940] ---- BYOL Training Loss = 0.3125426471233368
30-01-2023 14:47:11 INFO Epoch 3: [771/10940] ---- BYOL Training Loss = 0.28883033990859985
30-01-2023 14:47:29 INFO Epoch 3: [782/10940] ---- BYOL Training Loss = 0.2939832806587219
30-01-2023 14:47:46 INFO Epoch 3: [793/10940] ---- BYOL Training Loss = 0.2690372169017792
30-01-2023 14:48:39 INFO Epoch 3: [793/10940] ---- BYOL Validation Loss = 0.2642068862915039
30-01-2023 14:48:56 INFO Epoch 3: [804/10940] ---- BYOL Training Loss = 0.2646428942680359
30-01-2023 14:49:14 INFO Epoch 3: [815/10940] ---- BYOL Training Loss = 0.265678346157074
30-01-2023 14:49:31 INFO Epoch 3: [826/10940] ---- BYOL Training Loss = 0.22210995852947235
30-01-2023 14:49:49 INFO Epoch 3: [837/10940] ---- BYOL Training Loss = 0.29865798354148865
30-01-2023 14:50:42 INFO Epoch 3: [837/10940] ---- BYOL Validation Loss = 0.2572416663169861
30-01-2023 14:50:59 INFO Epoch 3: [848/10940] ---- BYOL Training Loss = 0.2887752056121826
30-01-2023 14:51:17 INFO Epoch 3: [859/10940] ---- BYOL Training Loss = 0.28238481283187866
30-01-2023 14:51:34 INFO Epoch 3: [870/10940] ---- BYOL Training Loss = 0.30572885274887085
30-01-2023 14:51:52 INFO Epoch 3: [881/10940] ---- BYOL Training Loss = 0.35138434171676636
30-01-2023 14:52:44 INFO Epoch 3: [881/10940] ---- BYOL Validation Loss = 0.2607874274253845
30-01-2023 14:53:02 INFO Epoch 3: [892/10940] ---- BYOL Training Loss = 0.30263179540634155
30-01-2023 14:53:19 INFO Epoch 3: [903/10940] ---- BYOL Training Loss = 0.24509945511817932
30-01-2023 14:53:37 INFO Epoch 3: [914/10940] ---- BYOL Training Loss = 0.24691414833068848
30-01-2023 14:53:54 INFO Epoch 3: [925/10940] ---- BYOL Training Loss = 0.2721519470214844
30-01-2023 14:54:47 INFO Epoch 3: [925/10940] ---- BYOL Validation Loss = 0.2516332268714905
30-01-2023 14:55:04 INFO Epoch 3: [936/10940] ---- BYOL Training Loss = 0.27254718542099
30-01-2023 14:55:22 INFO Epoch 3: [947/10940] ---- BYOL Training Loss = 0.26956692337989807
30-01-2023 14:55:40 INFO Epoch 3: [958/10940] ---- BYOL Training Loss = 0.2197052240371704
30-01-2023 14:55:57 INFO Epoch 3: [969/10940] ---- BYOL Training Loss = 0.2396966516971588
30-01-2023 14:56:50 INFO Epoch 3: [969/10940] ---- BYOL Validation Loss = 0.2601872384548187
30-01-2023 14:57:08 INFO Epoch 3: [980/10940] ---- BYOL Training Loss = 0.29400375485420227
30-01-2023 14:57:25 INFO Epoch 3: [991/10940] ---- BYOL Training Loss = 0.30189812183380127
30-01-2023 14:57:43 INFO Epoch 3: [1002/10940] ---- BYOL Training Loss = 0.27617147564888
30-01-2023 14:58:00 INFO Epoch 3: [1013/10940] ---- BYOL Training Loss = 0.28541475534439087
30-01-2023 14:58:53 INFO Epoch 3: [1013/10940] ---- BYOL Validation Loss = 0.2676122784614563
30-01-2023 14:59:10 INFO Epoch 3: [1024/10940] ---- BYOL Training Loss = 0.23906679451465607
30-01-2023 14:59:28 INFO Epoch 3: [1035/10940] ---- BYOL Training Loss = 0.24293163418769836
30-01-2023 14:59:45 INFO Epoch 3: [1046/10940] ---- BYOL Training Loss = 0.2560497522354126
30-01-2023 15:00:03 INFO Epoch 3: [1057/10940] ---- BYOL Training Loss = 0.26051047444343567
30-01-2023 15:00:56 INFO Epoch 3: [1057/10940] ---- BYOL Validation Loss = 0.25716546177864075
30-01-2023 15:01:13 INFO Epoch 3: [1068/10940] ---- BYOL Training Loss = 0.28020375967025757
30-01-2023 15:01:30 INFO Epoch 3: [1079/10940] ---- BYOL Training Loss = 0.27826783061027527
30-01-2023 15:01:48 INFO Epoch 3: [1090/10940] ---- BYOL Training Loss = 0.24665096402168274
30-01-2023 15:02:05 INFO Epoch 3: [1101/10940] ---- BYOL Training Loss = 0.24263599514961243
30-01-2023 15:02:58 INFO Epoch 3: [1101/10940] ---- BYOL Validation Loss = 0.25403672456741333
30-01-2023 15:03:15 INFO Epoch 3: [1112/10940] ---- BYOL Training Loss = 0.2621766924858093
30-01-2023 15:03:33 INFO Epoch 3: [1123/10940] ---- BYOL Training Loss = 0.258815735578537
30-01-2023 15:03:50 INFO Epoch 3: [1134/10940] ---- BYOL Training Loss = 0.2889666259288788
30-01-2023 15:04:08 INFO Epoch 3: [1145/10940] ---- BYOL Training Loss = 0.26040634512901306
30-01-2023 15:05:00 INFO Epoch 3: [1145/10940] ---- BYOL Validation Loss = 0.256675660610199
30-01-2023 15:05:18 INFO Epoch 3: [1156/10940] ---- BYOL Training Loss = 0.25293421745300293
30-01-2023 15:05:35 INFO Epoch 3: [1167/10940] ---- BYOL Training Loss = 0.26263493299484253
30-01-2023 15:05:53 INFO Epoch 3: [1178/10940] ---- BYOL Training Loss = 0.25003188848495483
30-01-2023 15:06:10 INFO Epoch 3: [1189/10940] ---- BYOL Training Loss = 0.2733791470527649
30-01-2023 15:07:03 INFO Epoch 3: [1189/10940] ---- BYOL Validation Loss = 0.24388626217842102
30-01-2023 15:07:20 INFO Epoch 3: [1200/10940] ---- BYOL Training Loss = 0.3112807869911194
30-01-2023 15:07:38 INFO Epoch 3: [1211/10940] ---- BYOL Training Loss = 0.27590784430503845
30-01-2023 15:07:55 INFO Epoch 3: [1222/10940] ---- BYOL Training Loss = 0.31757989525794983
30-01-2023 15:08:13 INFO Epoch 3: [1233/10940] ---- BYOL Training Loss = 0.30073171854019165
30-01-2023 15:09:05 INFO Epoch 3: [1233/10940] ---- BYOL Validation Loss = 0.2684323489665985
30-01-2023 15:09:22 INFO Epoch 3: [1244/10940] ---- BYOL Training Loss = 0.290102481842041
30-01-2023 15:09:40 INFO Epoch 3: [1255/10940] ---- BYOL Training Loss = 0.26351863145828247
30-01-2023 15:09:58 INFO Epoch 3: [1266/10940] ---- BYOL Training Loss = 0.24287471175193787
30-01-2023 15:10:15 INFO Epoch 3: [1277/10940] ---- BYOL Training Loss = 0.30526864528656006
30-01-2023 15:11:08 INFO Epoch 3: [1277/10940] ---- BYOL Validation Loss = 0.2710968554019928
30-01-2023 15:11:25 INFO Epoch 3: [1288/10940] ---- BYOL Training Loss = 0.31496134400367737
30-01-2023 15:11:43 INFO Epoch 3: [1299/10940] ---- BYOL Training Loss = 0.2653188705444336
30-01-2023 15:12:00 INFO Epoch 3: [1310/10940] ---- BYOL Training Loss = 0.2732158303260803
30-01-2023 15:12:18 INFO Epoch 3: [1321/10940] ---- BYOL Training Loss = 0.29591548442840576
30-01-2023 15:13:11 INFO Epoch 3: [1321/10940] ---- BYOL Validation Loss = 0.24573874473571777
30-01-2023 15:13:29 INFO Epoch 3: [1332/10940] ---- BYOL Training Loss = 0.3171287178993225
30-01-2023 15:13:46 INFO Epoch 3: [1343/10940] ---- BYOL Training Loss = 0.3537943959236145
30-01-2023 15:14:04 INFO Epoch 3: [1354/10940] ---- BYOL Training Loss = 0.292199045419693
30-01-2023 15:14:21 INFO Epoch 3: [1365/10940] ---- BYOL Training Loss = 0.2743958830833435
30-01-2023 15:15:14 INFO Epoch 3: [1365/10940] ---- BYOL Validation Loss = 0.26867833733558655
30-01-2023 15:15:31 INFO Epoch 3: [1376/10940] ---- BYOL Training Loss = 0.2520955801010132
30-01-2023 15:15:49 INFO Epoch 3: [1387/10940] ---- BYOL Training Loss = 0.26067274808883667
30-01-2023 15:16:06 INFO Epoch 3: [1398/10940] ---- BYOL Training Loss = 0.2638581693172455
30-01-2023 15:16:24 INFO Epoch 3: [1409/10940] ---- BYOL Training Loss = 0.26195135712623596
30-01-2023 15:17:17 INFO Epoch 3: [1409/10940] ---- BYOL Validation Loss = 0.2467944175004959
30-01-2023 15:17:34 INFO Epoch 3: [1420/10940] ---- BYOL Training Loss = 0.2817849814891815
30-01-2023 15:17:51 INFO Epoch 3: [1431/10940] ---- BYOL Training Loss = 0.28777602314949036
30-01-2023 15:18:09 INFO Epoch 3: [1442/10940] ---- BYOL Training Loss = 0.2879742980003357
30-01-2023 15:18:26 INFO Epoch 3: [1453/10940] ---- BYOL Training Loss = 0.2687556743621826
30-01-2023 15:19:19 INFO Epoch 3: [1453/10940] ---- BYOL Validation Loss = 0.2437676191329956
30-01-2023 15:19:37 INFO Epoch 3: [1464/10940] ---- BYOL Training Loss = 0.24740830063819885
30-01-2023 15:19:54 INFO Epoch 3: [1475/10940] ---- BYOL Training Loss = 0.294831246137619
30-01-2023 15:20:12 INFO Epoch 3: [1486/10940] ---- BYOL Training Loss = 0.31312137842178345
30-01-2023 15:20:30 INFO Epoch 3: [1497/10940] ---- BYOL Training Loss = 0.2814639210700989
30-01-2023 15:21:22 INFO Epoch 3: [1497/10940] ---- BYOL Validation Loss = 0.26011785864830017
30-01-2023 15:21:39 INFO Epoch 3: [1508/10940] ---- BYOL Training Loss = 0.256159245967865
30-01-2023 15:21:57 INFO Epoch 3: [1519/10940] ---- BYOL Training Loss = 0.3004773259162903
30-01-2023 15:22:14 INFO Epoch 3: [1530/10940] ---- BYOL Training Loss = 0.3227563798427582
30-01-2023 15:22:32 INFO Epoch 3: [1541/10940] ---- BYOL Training Loss = 0.273183673620224
30-01-2023 15:23:25 INFO Epoch 3: [1541/10940] ---- BYOL Validation Loss = 0.2763161361217499
30-01-2023 15:23:42 INFO Epoch 3: [1552/10940] ---- BYOL Training Loss = 0.28174611926078796
30-01-2023 15:24:00 INFO Epoch 3: [1563/10940] ---- BYOL Training Loss = 0.28708013892173767
30-01-2023 15:24:18 INFO Epoch 3: [1574/10940] ---- BYOL Training Loss = 0.2793963849544525
30-01-2023 15:24:35 INFO Epoch 3: [1585/10940] ---- BYOL Training Loss = 0.2717869281768799
30-01-2023 15:25:28 INFO Epoch 3: [1585/10940] ---- BYOL Validation Loss = 0.27296146750450134
30-01-2023 15:25:45 INFO Epoch 3: [1596/10940] ---- BYOL Training Loss = 0.3072947561740875
30-01-2023 15:26:03 INFO Epoch 3: [1607/10940] ---- BYOL Training Loss = 0.2829420864582062
30-01-2023 15:26:21 INFO Epoch 3: [1618/10940] ---- BYOL Training Loss = 0.3079105019569397
30-01-2023 15:26:38 INFO Epoch 3: [1629/10940] ---- BYOL Training Loss = 0.31521788239479065
30-01-2023 15:27:31 INFO Epoch 3: [1629/10940] ---- BYOL Validation Loss = 0.27321764826774597
30-01-2023 15:27:48 INFO Epoch 3: [1640/10940] ---- BYOL Training Loss = 0.32451358437538147
30-01-2023 15:28:06 INFO Epoch 3: [1651/10940] ---- BYOL Training Loss = 0.26746660470962524
30-01-2023 15:28:23 INFO Epoch 3: [1662/10940] ---- BYOL Training Loss = 0.29559260606765747
30-01-2023 15:28:41 INFO Epoch 3: [1673/10940] ---- BYOL Training Loss = 0.2996653914451599
30-01-2023 15:29:34 INFO Epoch 3: [1673/10940] ---- BYOL Validation Loss = 0.28793856501579285
30-01-2023 15:29:51 INFO Epoch 3: [1684/10940] ---- BYOL Training Loss = 0.2641749382019043
30-01-2023 15:30:08 INFO Epoch 3: [1695/10940] ---- BYOL Training Loss = 0.29942476749420166
30-01-2023 15:30:26 INFO Epoch 3: [1706/10940] ---- BYOL Training Loss = 0.30667662620544434
30-01-2023 15:30:43 INFO Epoch 3: [1717/10940] ---- BYOL Training Loss = 0.2583330571651459
30-01-2023 15:31:36 INFO Epoch 3: [1717/10940] ---- BYOL Validation Loss = 0.23639079928398132
30-01-2023 15:31:54 INFO Epoch 3: [1728/10940] ---- BYOL Training Loss = 0.26652705669403076
30-01-2023 15:32:11 INFO Epoch 3: [1739/10940] ---- BYOL Training Loss = 0.2515144944190979
30-01-2023 15:32:29 INFO Epoch 3: [1750/10940] ---- BYOL Training Loss = 0.2526337802410126
30-01-2023 15:32:47 INFO Epoch 3: [1761/10940] ---- BYOL Training Loss = 0.2647550106048584
30-01-2023 15:33:39 INFO Epoch 3: [1761/10940] ---- BYOL Validation Loss = 0.2956429421901703
30-01-2023 15:33:57 INFO Epoch 3: [1772/10940] ---- BYOL Training Loss = 0.2850891947746277
30-01-2023 15:34:14 INFO Epoch 3: [1783/10940] ---- BYOL Training Loss = 0.2572387754917145
30-01-2023 15:34:32 INFO Epoch 3: [1794/10940] ---- BYOL Training Loss = 0.2561163008213043
30-01-2023 15:34:50 INFO Epoch 3: [1805/10940] ---- BYOL Training Loss = 0.26931166648864746
30-01-2023 15:35:42 INFO Epoch 3: [1805/10940] ---- BYOL Validation Loss = 0.28805556893348694
30-01-2023 15:36:00 INFO Epoch 3: [1816/10940] ---- BYOL Training Loss = 0.31398019194602966
30-01-2023 15:36:17 INFO Epoch 3: [1827/10940] ---- BYOL Training Loss = 0.3271641433238983
30-01-2023 15:36:35 INFO Epoch 3: [1838/10940] ---- BYOL Training Loss = 0.314129114151001
30-01-2023 15:36:52 INFO Epoch 3: [1849/10940] ---- BYOL Training Loss = 0.28183573484420776
30-01-2023 15:37:45 INFO Epoch 3: [1849/10940] ---- BYOL Validation Loss = 0.27099964022636414
30-01-2023 15:38:03 INFO Epoch 3: [1860/10940] ---- BYOL Training Loss = 0.3394046723842621
30-01-2023 15:38:20 INFO Epoch 3: [1871/10940] ---- BYOL Training Loss = 0.370462030172348
30-01-2023 15:38:38 INFO Epoch 3: [1882/10940] ---- BYOL Training Loss = 0.36066147685050964
30-01-2023 15:38:55 INFO Epoch 3: [1893/10940] ---- BYOL Training Loss = 0.32249701023101807
30-01-2023 15:39:48 INFO Epoch 3: [1893/10940] ---- BYOL Validation Loss = 0.23100654780864716
30-01-2023 15:40:05 INFO Epoch 3: [1904/10940] ---- BYOL Training Loss = 0.2934775650501251
30-01-2023 15:40:23 INFO Epoch 3: [1915/10940] ---- BYOL Training Loss = 0.3028932213783264
30-01-2023 15:40:41 INFO Epoch 3: [1926/10940] ---- BYOL Training Loss = 0.303799033164978
30-01-2023 15:40:58 INFO Epoch 3: [1937/10940] ---- BYOL Training Loss = 0.30585142970085144
30-01-2023 15:41:51 INFO Epoch 3: [1937/10940] ---- BYOL Validation Loss = 0.29443031549453735
30-01-2023 15:42:08 INFO Epoch 3: [1948/10940] ---- BYOL Training Loss = 0.35118189454078674
30-01-2023 15:42:26 INFO Epoch 3: [1959/10940] ---- BYOL Training Loss = 0.33713993430137634
30-01-2023 15:42:44 INFO Epoch 3: [1970/10940] ---- BYOL Training Loss = 0.33332309126853943
30-01-2023 15:43:01 INFO Epoch 3: [1981/10940] ---- BYOL Training Loss = 0.31003981828689575
30-01-2023 15:43:54 INFO Epoch 3: [1981/10940] ---- BYOL Validation Loss = 0.23771679401397705
30-01-2023 15:44:11 INFO Epoch 3: [1992/10940] ---- BYOL Training Loss = 0.2544790208339691
30-01-2023 15:44:29 INFO Epoch 3: [2003/10940] ---- BYOL Training Loss = 0.2917724847793579
30-01-2023 15:44:46 INFO Epoch 3: [2014/10940] ---- BYOL Training Loss = 0.28109487891197205
30-01-2023 15:45:04 INFO Epoch 3: [2025/10940] ---- BYOL Training Loss = 0.26868683099746704
30-01-2023 15:45:57 INFO Epoch 3: [2025/10940] ---- BYOL Validation Loss = 0.25493907928466797
30-01-2023 15:46:14 INFO Epoch 3: [2036/10940] ---- BYOL Training Loss = 0.29034310579299927
30-01-2023 15:46:32 INFO Epoch 3: [2047/10940] ---- BYOL Training Loss = 0.3549453914165497
30-01-2023 15:46:50 INFO Epoch 3: [2058/10940] ---- BYOL Training Loss = 0.38955822587013245
30-01-2023 15:47:07 INFO Epoch 3: [2069/10940] ---- BYOL Training Loss = 0.3005222678184509
30-01-2023 15:48:00 INFO Epoch 3: [2069/10940] ---- BYOL Validation Loss = 0.22826340794563293
30-01-2023 15:48:17 INFO Epoch 3: [2080/10940] ---- BYOL Training Loss = 0.24660225212574005
30-01-2023 15:48:35 INFO Epoch 3: [2091/10940] ---- BYOL Training Loss = 0.2751147449016571
30-01-2023 15:48:53 INFO Epoch 3: [2102/10940] ---- BYOL Training Loss = 0.30607157945632935
30-01-2023 15:49:10 INFO Epoch 3: [2113/10940] ---- BYOL Training Loss = 0.21823987364768982
30-01-2023 15:50:03 INFO Epoch 3: [2113/10940] ---- BYOL Validation Loss = 0.22958026826381683
30-01-2023 15:50:20 INFO Epoch 3: [2124/10940] ---- BYOL Training Loss = 0.2669408321380615
30-01-2023 15:50:38 INFO Epoch 3: [2135/10940] ---- BYOL Training Loss = 0.2766987979412079
30-01-2023 15:50:55 INFO Epoch 3: [2146/10940] ---- BYOL Training Loss = 0.2913293242454529
30-01-2023 15:51:13 INFO Epoch 3: [2157/10940] ---- BYOL Training Loss = 0.28566133975982666
30-01-2023 15:52:06 INFO Epoch 3: [2157/10940] ---- BYOL Validation Loss = 0.2123255729675293
30-01-2023 15:52:23 INFO Epoch 3: [2168/10940] ---- BYOL Training Loss = 0.27421921491622925
30-01-2023 15:52:41 INFO Epoch 3: [2179/10940] ---- BYOL Training Loss = 0.2798936665058136
30-01-2023 15:52:59 INFO Epoch 3: [2190/10940] ---- BYOL Training Loss = 0.26383525133132935
30-01-2023 15:53:16 INFO Epoch 3: [2201/10940] ---- BYOL Training Loss = 0.3133445978164673
30-01-2023 15:54:09 INFO Epoch 3: [2201/10940] ---- BYOL Validation Loss = 0.270619660615921
30-01-2023 15:54:26 INFO Epoch 3: [2212/10940] ---- BYOL Training Loss = 0.3459450900554657
30-01-2023 15:54:44 INFO Epoch 3: [2223/10940] ---- BYOL Training Loss = 0.34386831521987915
30-01-2023 15:55:01 INFO Epoch 3: [2234/10940] ---- BYOL Training Loss = 0.29005858302116394
30-01-2023 15:55:19 INFO Epoch 3: [2245/10940] ---- BYOL Training Loss = 0.2898237109184265
30-01-2023 15:56:12 INFO Epoch 3: [2245/10940] ---- BYOL Validation Loss = 0.253630131483078
30-01-2023 15:56:29 INFO Epoch 3: [2256/10940] ---- BYOL Training Loss = 0.351107120513916
30-01-2023 15:56:47 INFO Epoch 3: [2267/10940] ---- BYOL Training Loss = 0.3618740439414978
30-01-2023 15:57:04 INFO Epoch 3: [2278/10940] ---- BYOL Training Loss = 0.2773821949958801
30-01-2023 15:57:22 INFO Epoch 3: [2289/10940] ---- BYOL Training Loss = 0.2297181636095047
30-01-2023 15:58:15 INFO Epoch 3: [2289/10940] ---- BYOL Validation Loss = 0.21981589496135712
30-01-2023 15:58:32 INFO Epoch 3: [2300/10940] ---- BYOL Training Loss = 0.20717331767082214
30-01-2023 15:58:50 INFO Epoch 3: [2311/10940] ---- BYOL Training Loss = 0.2156166136264801
30-01-2023 15:59:08 INFO Epoch 3: [2322/10940] ---- BYOL Training Loss = 0.24498507380485535
30-01-2023 15:59:25 INFO Epoch 3: [2333/10940] ---- BYOL Training Loss = 0.24441532790660858
30-01-2023 16:00:18 INFO Epoch 3: [2333/10940] ---- BYOL Validation Loss = 0.2619022727012634
30-01-2023 16:00:35 INFO Epoch 3: [2344/10940] ---- BYOL Training Loss = 0.3193661570549011
30-01-2023 16:00:53 INFO Epoch 3: [2355/10940] ---- BYOL Training Loss = 0.2654077410697937
30-01-2023 16:01:11 INFO Epoch 3: [2366/10940] ---- BYOL Training Loss = 0.24554935097694397
30-01-2023 16:01:28 INFO Epoch 3: [2377/10940] ---- BYOL Training Loss = 0.3059006333351135
30-01-2023 16:02:21 INFO Epoch 3: [2377/10940] ---- BYOL Validation Loss = 0.2781996726989746
30-01-2023 16:02:38 INFO Epoch 3: [2388/10940] ---- BYOL Training Loss = 0.25747984647750854
30-01-2023 16:02:56 INFO Epoch 3: [2399/10940] ---- BYOL Training Loss = 0.226105734705925
30-01-2023 16:03:14 INFO Epoch 3: [2410/10940] ---- BYOL Training Loss = 0.2228049486875534
30-01-2023 16:03:32 INFO Epoch 3: [2421/10940] ---- BYOL Training Loss = 0.23575229942798615
30-01-2023 16:04:24 INFO Epoch 3: [2421/10940] ---- BYOL Validation Loss = 0.22250357270240784
30-01-2023 16:04:42 INFO Epoch 3: [2432/10940] ---- BYOL Training Loss = 0.29647591710090637
30-01-2023 16:04:59 INFO Epoch 3: [2443/10940] ---- BYOL Training Loss = 0.2941780388355255
30-01-2023 16:05:17 INFO Epoch 3: [2454/10940] ---- BYOL Training Loss = 0.2619099020957947
30-01-2023 16:05:35 INFO Epoch 3: [2465/10940] ---- BYOL Training Loss = 0.27357959747314453
30-01-2023 16:06:28 INFO Epoch 3: [2465/10940] ---- BYOL Validation Loss = 0.2372945100069046
30-01-2023 16:06:45 INFO Epoch 3: [2476/10940] ---- BYOL Training Loss = 0.23098281025886536
30-01-2023 16:07:03 INFO Epoch 3: [2487/10940] ---- BYOL Training Loss = 0.23537059128284454
30-01-2023 16:07:20 INFO Epoch 3: [2498/10940] ---- BYOL Training Loss = 0.2842845022678375
30-01-2023 16:07:38 INFO Epoch 3: [2509/10940] ---- BYOL Training Loss = 0.259816974401474
30-01-2023 16:08:31 INFO Epoch 3: [2509/10940] ---- BYOL Validation Loss = 0.21055908501148224
30-01-2023 16:08:48 INFO Epoch 3: [2520/10940] ---- BYOL Training Loss = 0.2959383726119995
30-01-2023 16:09:07 INFO Epoch 3: [2531/10940] ---- BYOL Training Loss = 0.2471705675125122
30-01-2023 16:09:24 INFO Epoch 3: [2542/10940] ---- BYOL Training Loss = 0.3612968623638153
30-01-2023 16:09:42 INFO Epoch 3: [2553/10940] ---- BYOL Training Loss = 0.3646305501461029
30-01-2023 16:10:35 INFO Epoch 3: [2553/10940] ---- BYOL Validation Loss = 0.2890257239341736
30-01-2023 16:10:52 INFO Epoch 3: [2564/10940] ---- BYOL Training Loss = 0.24986660480499268
30-01-2023 16:11:09 INFO Epoch 3: [2575/10940] ---- BYOL Training Loss = 0.22597475349903107
30-01-2023 16:11:27 INFO Epoch 3: [2586/10940] ---- BYOL Training Loss = 0.26320523023605347
30-01-2023 16:11:45 INFO Epoch 3: [2597/10940] ---- BYOL Training Loss = 0.2864684462547302
30-01-2023 16:12:38 INFO Epoch 3: [2597/10940] ---- BYOL Validation Loss = 0.21641576290130615
30-01-2023 16:12:56 INFO Epoch 3: [2608/10940] ---- BYOL Training Loss = 0.33016180992126465
30-01-2023 16:13:13 INFO Epoch 3: [2619/10940] ---- BYOL Training Loss = 0.28303200006484985
30-01-2023 16:13:32 INFO Epoch 3: [2630/10940] ---- BYOL Training Loss = 0.284737765789032
30-01-2023 16:13:49 INFO Epoch 3: [2641/10940] ---- BYOL Training Loss = 0.28396469354629517
30-01-2023 16:14:42 INFO Epoch 3: [2641/10940] ---- BYOL Validation Loss = 0.206303209066391
30-01-2023 16:14:59 INFO Epoch 3: [2652/10940] ---- BYOL Training Loss = 0.2740231156349182
30-01-2023 16:15:17 INFO Epoch 3: [2663/10940] ---- BYOL Training Loss = 0.26730743050575256
30-01-2023 16:15:35 INFO Epoch 3: [2674/10940] ---- BYOL Training Loss = 0.2696757912635803
30-01-2023 16:15:53 INFO Epoch 3: [2685/10940] ---- BYOL Training Loss = 0.2740858793258667
30-01-2023 16:16:46 INFO Epoch 3: [2685/10940] ---- BYOL Validation Loss = 0.2763402760028839
30-01-2023 16:17:03 INFO Epoch 3: [2696/10940] ---- BYOL Training Loss = 0.323490709066391
30-01-2023 16:17:21 INFO Epoch 3: [2707/10940] ---- BYOL Training Loss = 0.3357359766960144
30-01-2023 16:17:38 INFO Epoch 3: [2718/10940] ---- BYOL Training Loss = 0.2915448546409607
30-01-2023 16:17:56 INFO Epoch 3: [2729/10940] ---- BYOL Training Loss = 0.2499634474515915
30-01-2023 16:18:49 INFO Epoch 3: [2729/10940] ---- BYOL Validation Loss = 0.2606895864009857
30-01-2023 16:19:07 INFO Epoch 3: [2740/10940] ---- BYOL Training Loss = 0.26271942257881165
30-01-2023 16:19:24 INFO Epoch 3: [2751/10940] ---- BYOL Training Loss = 0.29582616686820984
30-01-2023 16:19:42 INFO Epoch 3: [2762/10940] ---- BYOL Training Loss = 0.3081943392753601
30-01-2023 16:20:00 INFO Epoch 3: [2773/10940] ---- BYOL Training Loss = 0.24538251757621765
30-01-2023 16:20:52 INFO Epoch 3: [2773/10940] ---- BYOL Validation Loss = 0.1723385900259018
30-01-2023 16:21:10 INFO Epoch 3: [2784/10940] ---- BYOL Training Loss = 0.27277159690856934
30-01-2023 16:21:27 INFO Epoch 3: [2795/10940] ---- BYOL Training Loss = 0.3034815192222595
30-01-2023 16:21:45 INFO Epoch 3: [2806/10940] ---- BYOL Training Loss = 0.2897835075855255
30-01-2023 16:22:03 INFO Epoch 3: [2817/10940] ---- BYOL Training Loss = 0.24490220844745636
30-01-2023 16:22:56 INFO Epoch 3: [2817/10940] ---- BYOL Validation Loss = 0.16859839856624603
30-01-2023 16:23:13 INFO Epoch 3: [2828/10940] ---- BYOL Training Loss = 0.24734818935394287
30-01-2023 16:23:31 INFO Epoch 3: [2839/10940] ---- BYOL Training Loss = 0.3074519634246826
30-01-2023 16:23:49 INFO Epoch 3: [2850/10940] ---- BYOL Training Loss = 0.3364512622356415
30-01-2023 16:24:06 INFO Epoch 3: [2861/10940] ---- BYOL Training Loss = 0.30280253291130066
30-01-2023 16:24:59 INFO Epoch 3: [2861/10940] ---- BYOL Validation Loss = 0.26684388518333435
30-01-2023 16:25:16 INFO Epoch 3: [2872/10940] ---- BYOL Training Loss = 0.24745360016822815
30-01-2023 16:25:34 INFO Epoch 3: [2883/10940] ---- BYOL Training Loss = 0.2254684716463089
30-01-2023 16:25:52 INFO Epoch 3: [2894/10940] ---- BYOL Training Loss = 0.2507750689983368
30-01-2023 16:26:10 INFO Epoch 3: [2905/10940] ---- BYOL Training Loss = 0.28475600481033325
30-01-2023 16:27:03 INFO Epoch 3: [2905/10940] ---- BYOL Validation Loss = 0.26267147064208984
30-01-2023 16:27:20 INFO Epoch 3: [2916/10940] ---- BYOL Training Loss = 0.2665853500366211
30-01-2023 16:27:38 INFO Epoch 3: [2927/10940] ---- BYOL Training Loss = 0.2462838590145111
30-01-2023 16:27:56 INFO Epoch 3: [2938/10940] ---- BYOL Training Loss = 0.20623281598091125
30-01-2023 16:28:13 INFO Epoch 3: [2949/10940] ---- BYOL Training Loss = 0.231998011469841
30-01-2023 16:29:06 INFO Epoch 3: [2949/10940] ---- BYOL Validation Loss = 0.20287874341011047
30-01-2023 16:29:23 INFO Epoch 3: [2960/10940] ---- BYOL Training Loss = 0.28104257583618164
30-01-2023 16:29:41 INFO Epoch 3: [2971/10940] ---- BYOL Training Loss = 0.3276510536670685
30-01-2023 16:29:59 INFO Epoch 3: [2982/10940] ---- BYOL Training Loss = 0.31375712156295776
30-01-2023 16:30:17 INFO Epoch 3: [2993/10940] ---- BYOL Training Loss = 0.30281922221183777
30-01-2023 16:31:09 INFO Epoch 3: [2993/10940] ---- BYOL Validation Loss = 0.1953701227903366
30-01-2023 16:31:27 INFO Epoch 3: [3004/10940] ---- BYOL Training Loss = 0.27336275577545166
30-01-2023 16:31:44 INFO Epoch 3: [3015/10940] ---- BYOL Training Loss = 0.2650351822376251
30-01-2023 16:32:02 INFO Epoch 3: [3026/10940] ---- BYOL Training Loss = 0.4209249019622803
30-01-2023 16:32:20 INFO Epoch 3: [3037/10940] ---- BYOL Training Loss = 0.3258458077907562
30-01-2023 16:33:13 INFO Epoch 3: [3037/10940] ---- BYOL Validation Loss = 0.26337236166000366
30-01-2023 16:33:31 INFO Epoch 3: [3048/10940] ---- BYOL Training Loss = 0.27157488465309143
30-01-2023 16:33:48 INFO Epoch 3: [3059/10940] ---- BYOL Training Loss = 0.26836857199668884
30-01-2023 16:34:06 INFO Epoch 3: [3070/10940] ---- BYOL Training Loss = 0.2927653193473816
30-01-2023 16:34:23 INFO Epoch 3: [3081/10940] ---- BYOL Training Loss = 0.25884127616882324
30-01-2023 16:35:16 INFO Epoch 3: [3081/10940] ---- BYOL Validation Loss = 0.2099524289369583
30-01-2023 16:35:34 INFO Epoch 3: [3092/10940] ---- BYOL Training Loss = 0.2712838351726532
30-01-2023 16:35:51 INFO Epoch 3: [3103/10940] ---- BYOL Training Loss = 0.3075729310512543
30-01-2023 16:36:10 INFO Epoch 3: [3114/10940] ---- BYOL Training Loss = 0.4555976986885071
30-01-2023 16:36:27 INFO Epoch 3: [3125/10940] ---- BYOL Training Loss = 0.4260493218898773
30-01-2023 16:37:20 INFO Epoch 3: [3125/10940] ---- BYOL Validation Loss = 0.22240403294563293
30-01-2023 16:37:37 INFO Epoch 3: [3136/10940] ---- BYOL Training Loss = 0.30841919779777527
30-01-2023 16:37:55 INFO Epoch 3: [3147/10940] ---- BYOL Training Loss = 0.2634194493293762
30-01-2023 16:38:13 INFO Epoch 3: [3158/10940] ---- BYOL Training Loss = 0.2575496733188629
30-01-2023 16:38:31 INFO Epoch 3: [3169/10940] ---- BYOL Training Loss = 0.22727027535438538
30-01-2023 16:39:24 INFO Epoch 3: [3169/10940] ---- BYOL Validation Loss = 0.23872582614421844
30-01-2023 16:39:41 INFO Epoch 3: [3180/10940] ---- BYOL Training Loss = 0.2442895919084549
30-01-2023 16:39:59 INFO Epoch 3: [3191/10940] ---- BYOL Training Loss = 0.26019030809402466
30-01-2023 16:40:17 INFO Epoch 3: [3202/10940] ---- BYOL Training Loss = 0.3292306065559387
30-01-2023 16:40:35 INFO Epoch 3: [3213/10940] ---- BYOL Training Loss = 0.3932421803474426
30-01-2023 16:41:27 INFO Epoch 3: [3213/10940] ---- BYOL Validation Loss = 0.37472280859947205
30-01-2023 16:41:45 INFO Epoch 3: [3224/10940] ---- BYOL Training Loss = 0.46266621351242065
30-01-2023 16:42:02 INFO Epoch 3: [3235/10940] ---- BYOL Training Loss = 0.475836843252182
30-01-2023 16:42:20 INFO Epoch 3: [3246/10940] ---- BYOL Training Loss = 0.33209243416786194
30-01-2023 16:42:38 INFO Epoch 3: [3257/10940] ---- BYOL Training Loss = 0.3063977062702179
30-01-2023 16:43:31 INFO Epoch 3: [3257/10940] ---- BYOL Validation Loss = 0.2520141899585724
30-01-2023 16:43:48 INFO Epoch 3: [3268/10940] ---- BYOL Training Loss = 0.29732903838157654
30-01-2023 16:44:06 INFO Epoch 3: [3279/10940] ---- BYOL Training Loss = 0.29726478457450867
30-01-2023 16:44:24 INFO Epoch 3: [3290/10940] ---- BYOL Training Loss = 0.28882041573524475
30-01-2023 16:44:41 INFO Epoch 3: [3301/10940] ---- BYOL Training Loss = 0.2977847158908844
30-01-2023 16:45:34 INFO Epoch 3: [3301/10940] ---- BYOL Validation Loss = 0.25667405128479004
30-01-2023 16:45:52 INFO Epoch 3: [3312/10940] ---- BYOL Training Loss = 0.30330324172973633
30-01-2023 16:46:10 INFO Epoch 3: [3323/10940] ---- BYOL Training Loss = 0.31965699791908264
30-01-2023 16:46:28 INFO Epoch 3: [3334/10940] ---- BYOL Training Loss = 0.2848288118839264
30-01-2023 16:46:45 INFO Epoch 3: [3345/10940] ---- BYOL Training Loss = 0.2383495569229126
30-01-2023 16:47:38 INFO Epoch 3: [3345/10940] ---- BYOL Validation Loss = 0.21485114097595215
30-01-2023 16:47:55 INFO Epoch 3: [3356/10940] ---- BYOL Training Loss = 0.2401660680770874
30-01-2023 16:48:14 INFO Epoch 3: [3367/10940] ---- BYOL Training Loss = 0.25493353605270386
30-01-2023 16:48:31 INFO Epoch 3: [3378/10940] ---- BYOL Training Loss = 0.26971709728240967
30-01-2023 16:48:49 INFO Epoch 3: [3389/10940] ---- BYOL Training Loss = 0.2843526005744934
30-01-2023 16:49:42 INFO Epoch 3: [3389/10940] ---- BYOL Validation Loss = 0.2669547498226166
30-01-2023 16:49:59 INFO Epoch 3: [3400/10940] ---- BYOL Training Loss = 0.2640860676765442
30-01-2023 16:50:17 INFO Epoch 3: [3411/10940] ---- BYOL Training Loss = 0.2713354825973511
30-01-2023 16:50:35 INFO Epoch 3: [3422/10940] ---- BYOL Training Loss = 0.2776210904121399
30-01-2023 16:50:52 INFO Epoch 3: [3433/10940] ---- BYOL Training Loss = 0.24433574080467224
30-01-2023 16:51:45 INFO Epoch 3: [3433/10940] ---- BYOL Validation Loss = 0.19351179897785187
30-01-2023 16:52:02 INFO Epoch 3: [3444/10940] ---- BYOL Training Loss = 0.2152075320482254
30-01-2023 16:52:20 INFO Epoch 3: [3455/10940] ---- BYOL Training Loss = 0.205274298787117
30-01-2023 16:52:38 INFO Epoch 3: [3466/10940] ---- BYOL Training Loss = 0.2543300986289978
30-01-2023 16:52:56 INFO Epoch 3: [3477/10940] ---- BYOL Training Loss = 0.25163203477859497
30-01-2023 16:53:49 INFO Epoch 3: [3477/10940] ---- BYOL Validation Loss = 0.2405949980020523
30-01-2023 16:54:06 INFO Epoch 3: [3488/10940] ---- BYOL Training Loss = 0.2454424798488617
30-01-2023 16:54:24 INFO Epoch 3: [3499/10940] ---- BYOL Training Loss = 0.23895704746246338
30-01-2023 16:54:42 INFO Epoch 3: [3510/10940] ---- BYOL Training Loss = 0.22252914309501648
30-01-2023 16:55:00 INFO Epoch 3: [3521/10940] ---- BYOL Training Loss = 0.24527034163475037
30-01-2023 16:55:53 INFO Epoch 3: [3521/10940] ---- BYOL Validation Loss = 0.2422253042459488
30-01-2023 16:56:10 INFO Epoch 3: [3532/10940] ---- BYOL Training Loss = 0.22799094021320343
30-01-2023 16:56:28 INFO Epoch 3: [3543/10940] ---- BYOL Training Loss = 0.2685905992984772
30-01-2023 16:56:46 INFO Epoch 3: [3554/10940] ---- BYOL Training Loss = 0.2660139799118042
30-01-2023 16:57:04 INFO Epoch 3: [3565/10940] ---- BYOL Training Loss = 0.27667149901390076
30-01-2023 16:57:56 INFO Epoch 3: [3565/10940] ---- BYOL Validation Loss = 0.1822701245546341
30-01-2023 16:58:14 INFO Epoch 3: [3576/10940] ---- BYOL Training Loss = 0.26675644516944885
30-01-2023 16:58:31 INFO Epoch 3: [3587/10940] ---- BYOL Training Loss = 0.24901926517486572
30-01-2023 16:58:49 INFO Epoch 3: [3598/10940] ---- BYOL Training Loss = 0.20386819541454315
30-01-2023 16:59:07 INFO Epoch 3: [3609/10940] ---- BYOL Training Loss = 0.24077174067497253
30-01-2023 17:00:00 INFO Epoch 3: [3609/10940] ---- BYOL Validation Loss = 0.2251131236553192
30-01-2023 17:00:18 INFO Epoch 3: [3620/10940] ---- BYOL Training Loss = 0.2532503306865692
30-01-2023 17:00:35 INFO Epoch 3: [3631/10940] ---- BYOL Training Loss = 0.2648085951805115
30-01-2023 17:00:53 INFO Epoch 3: [3642/10940] ---- BYOL Training Loss = 0.2415478229522705
30-01-2023 17:01:11 INFO Epoch 3: [3653/10940] ---- BYOL Training Loss = 0.27001363039016724
30-01-2023 17:02:04 INFO Epoch 3: [3653/10940] ---- BYOL Validation Loss = 0.24570848047733307
30-01-2023 17:02:21 INFO Epoch 3: [3664/10940] ---- BYOL Training Loss = 0.2595757246017456
30-01-2023 17:02:39 INFO Epoch 3: [3675/10940] ---- BYOL Training Loss = 0.24567918479442596
30-01-2023 17:02:57 INFO Epoch 3: [3686/10940] ---- BYOL Training Loss = 0.2907564043998718
30-01-2023 17:03:15 INFO Epoch 3: [3697/10940] ---- BYOL Training Loss = 0.2544124722480774
30-01-2023 17:04:08 INFO Epoch 3: [3697/10940] ---- BYOL Validation Loss = 0.2024993896484375
30-01-2023 17:04:26 INFO Epoch 3: [3708/10940] ---- BYOL Training Loss = 0.24992935359477997
30-01-2023 17:04:43 INFO Epoch 3: [3719/10940] ---- BYOL Training Loss = 0.29518502950668335
30-01-2023 17:05:01 INFO Epoch 3: [3730/10940] ---- BYOL Training Loss = 0.306485652923584
30-01-2023 17:05:19 INFO Epoch 3: [3741/10940] ---- BYOL Training Loss = 0.2811431288719177
30-01-2023 17:06:12 INFO Epoch 3: [3741/10940] ---- BYOL Validation Loss = 0.24371756613254547
30-01-2023 17:06:30 INFO Epoch 3: [3752/10940] ---- BYOL Training Loss = 0.27039772272109985
30-01-2023 17:06:47 INFO Epoch 3: [3763/10940] ---- BYOL Training Loss = 0.25172704458236694
30-01-2023 17:07:05 INFO Epoch 3: [3774/10940] ---- BYOL Training Loss = 0.24302509427070618
30-01-2023 17:07:23 INFO Epoch 3: [3785/10940] ---- BYOL Training Loss = 0.23351505398750305
30-01-2023 17:08:16 INFO Epoch 3: [3785/10940] ---- BYOL Validation Loss = 0.2285761535167694
30-01-2023 17:08:33 INFO Epoch 3: [3796/10940] ---- BYOL Training Loss = 0.2459842413663864
30-01-2023 17:08:51 INFO Epoch 3: [3807/10940] ---- BYOL Training Loss = 0.2551760673522949
30-01-2023 17:09:09 INFO Epoch 3: [3818/10940] ---- BYOL Training Loss = 0.2698209881782532
30-01-2023 17:09:27 INFO Epoch 3: [3829/10940] ---- BYOL Training Loss = 0.2595583200454712
30-01-2023 17:10:20 INFO Epoch 3: [3829/10940] ---- BYOL Validation Loss = 0.2282194346189499
30-01-2023 17:10:37 INFO Epoch 3: [3840/10940] ---- BYOL Training Loss = 0.23832829296588898
30-01-2023 17:10:55 INFO Epoch 3: [3851/10940] ---- BYOL Training Loss = 0.22268514335155487
30-01-2023 17:11:13 INFO Epoch 3: [3862/10940] ---- BYOL Training Loss = 0.21008038520812988
30-01-2023 17:11:30 INFO Epoch 3: [3873/10940] ---- BYOL Training Loss = 0.2334752082824707
30-01-2023 17:12:23 INFO Epoch 3: [3873/10940] ---- BYOL Validation Loss = 0.21283483505249023
30-01-2023 17:12:41 INFO Epoch 3: [3884/10940] ---- BYOL Training Loss = 0.28452491760253906
30-01-2023 17:12:59 INFO Epoch 3: [3895/10940] ---- BYOL Training Loss = 0.28034746646881104
30-01-2023 17:13:17 INFO Epoch 3: [3906/10940] ---- BYOL Training Loss = 0.2944996654987335
30-01-2023 17:13:34 INFO Epoch 3: [3917/10940] ---- BYOL Training Loss = 0.3197215795516968
30-01-2023 17:14:27 INFO Epoch 3: [3917/10940] ---- BYOL Validation Loss = 0.25395312905311584
30-01-2023 17:14:44 INFO Epoch 3: [3928/10940] ---- BYOL Training Loss = 0.3111270070075989
30-01-2023 17:15:02 INFO Epoch 3: [3939/10940] ---- BYOL Training Loss = 0.27928608655929565
30-01-2023 17:15:20 INFO Epoch 3: [3950/10940] ---- BYOL Training Loss = 0.20347639918327332
30-01-2023 17:15:38 INFO Epoch 3: [3961/10940] ---- BYOL Training Loss = 0.24166586995124817
30-01-2023 17:16:31 INFO Epoch 3: [3961/10940] ---- BYOL Validation Loss = 0.2283376306295395
30-01-2023 17:16:49 INFO Epoch 3: [3972/10940] ---- BYOL Training Loss = 0.27234742045402527
30-01-2023 17:17:06 INFO Epoch 3: [3983/10940] ---- BYOL Training Loss = 0.24832072854042053
30-01-2023 17:17:24 INFO Epoch 3: [3994/10940] ---- BYOL Training Loss = 0.24892660975456238
30-01-2023 17:17:42 INFO Epoch 3: [4005/10940] ---- BYOL Training Loss = 0.22868256270885468
30-01-2023 17:18:35 INFO Epoch 3: [4005/10940] ---- BYOL Validation Loss = 0.24421633780002594
30-01-2023 17:18:52 INFO Epoch 3: [4016/10940] ---- BYOL Training Loss = 0.2242758572101593
30-01-2023 17:19:10 INFO Epoch 3: [4027/10940] ---- BYOL Training Loss = 0.2355937659740448
30-01-2023 17:19:28 INFO Epoch 3: [4038/10940] ---- BYOL Training Loss = 0.27630743384361267
30-01-2023 17:19:46 INFO Epoch 3: [4049/10940] ---- BYOL Training Loss = 0.27850329875946045
30-01-2023 17:20:39 INFO Epoch 3: [4049/10940] ---- BYOL Validation Loss = 0.2122202217578888
30-01-2023 17:20:56 INFO Epoch 3: [4060/10940] ---- BYOL Training Loss = 0.2391813099384308
30-01-2023 17:21:14 INFO Epoch 3: [4071/10940] ---- BYOL Training Loss = 0.21044275164604187
30-01-2023 17:21:32 INFO Epoch 3: [4082/10940] ---- BYOL Training Loss = 0.21065807342529297
30-01-2023 17:21:50 INFO Epoch 3: [4093/10940] ---- BYOL Training Loss = 0.24997110664844513
30-01-2023 17:22:43 INFO Epoch 3: [4093/10940] ---- BYOL Validation Loss = 0.24280036985874176
30-01-2023 17:23:01 INFO Epoch 3: [4104/10940] ---- BYOL Training Loss = 0.23160076141357422
30-01-2023 17:23:18 INFO Epoch 3: [4115/10940] ---- BYOL Training Loss = 0.2338850200176239
30-01-2023 17:23:36 INFO Epoch 3: [4126/10940] ---- BYOL Training Loss = 0.2386031150817871
30-01-2023 17:23:54 INFO Epoch 3: [4137/10940] ---- BYOL Training Loss = 0.19086427986621857
30-01-2023 17:24:47 INFO Epoch 3: [4137/10940] ---- BYOL Validation Loss = 0.2122560292482376
30-01-2023 17:25:05 INFO Epoch 3: [4148/10940] ---- BYOL Training Loss = 0.2820338308811188
30-01-2023 17:25:23 INFO Epoch 3: [4159/10940] ---- BYOL Training Loss = 0.34860527515411377
30-01-2023 17:25:40 INFO Epoch 3: [4170/10940] ---- BYOL Training Loss = 0.2552710473537445
30-01-2023 17:25:58 INFO Epoch 3: [4181/10940] ---- BYOL Training Loss = 0.2884841561317444
30-01-2023 17:26:51 INFO Epoch 3: [4181/10940] ---- BYOL Validation Loss = 0.21972081065177917
30-01-2023 17:27:09 INFO Epoch 3: [4192/10940] ---- BYOL Training Loss = 0.305467814207077
30-01-2023 17:27:26 INFO Epoch 3: [4203/10940] ---- BYOL Training Loss = 0.2952284514904022
30-01-2023 17:27:44 INFO Epoch 3: [4214/10940] ---- BYOL Training Loss = 0.26484963297843933
30-01-2023 17:28:02 INFO Epoch 3: [4225/10940] ---- BYOL Training Loss = 0.2636694610118866
30-01-2023 17:28:55 INFO Epoch 3: [4225/10940] ---- BYOL Validation Loss = 0.21637757122516632
30-01-2023 17:29:13 INFO Epoch 3: [4236/10940] ---- BYOL Training Loss = 0.24091264605522156
30-01-2023 17:29:31 INFO Epoch 3: [4247/10940] ---- BYOL Training Loss = 0.33733507990837097
30-01-2023 17:29:49 INFO Epoch 3: [4258/10940] ---- BYOL Training Loss = 0.3264923691749573
30-01-2023 17:30:06 INFO Epoch 3: [4269/10940] ---- BYOL Training Loss = 0.21099703013896942
30-01-2023 17:30:59 INFO Epoch 3: [4269/10940] ---- BYOL Validation Loss = 0.19704784452915192
30-01-2023 17:31:17 INFO Epoch 3: [4280/10940] ---- BYOL Training Loss = 0.22855255007743835
30-01-2023 17:31:35 INFO Epoch 3: [4291/10940] ---- BYOL Training Loss = 0.21427690982818604
30-01-2023 17:31:53 INFO Epoch 3: [4302/10940] ---- BYOL Training Loss = 0.20174920558929443
30-01-2023 17:32:11 INFO Epoch 3: [4313/10940] ---- BYOL Training Loss = 0.19470037519931793
30-01-2023 17:33:03 INFO Epoch 3: [4313/10940] ---- BYOL Validation Loss = 0.13233351707458496
30-01-2023 17:33:21 INFO Epoch 3: [4324/10940] ---- BYOL Training Loss = 0.16427645087242126
30-01-2023 17:33:39 INFO Epoch 3: [4335/10940] ---- BYOL Training Loss = 0.20435269176959991
30-01-2023 17:33:57 INFO Epoch 3: [4346/10940] ---- BYOL Training Loss = 0.24209575355052948
30-01-2023 17:34:15 INFO Epoch 3: [4357/10940] ---- BYOL Training Loss = 0.2778792083263397
30-01-2023 17:35:07 INFO Epoch 3: [4357/10940] ---- BYOL Validation Loss = 0.23210598528385162
30-01-2023 17:35:25 INFO Epoch 3: [4368/10940] ---- BYOL Training Loss = 0.25043368339538574
30-01-2023 17:35:43 INFO Epoch 3: [4379/10940] ---- BYOL Training Loss = 0.21732108294963837
30-01-2023 17:36:01 INFO Epoch 3: [4390/10940] ---- BYOL Training Loss = 0.24411854147911072
30-01-2023 17:36:18 INFO Epoch 3: [4401/10940] ---- BYOL Training Loss = 0.3258510231971741
30-01-2023 17:37:11 INFO Epoch 3: [4401/10940] ---- BYOL Validation Loss = 0.2018759399652481
30-01-2023 17:37:29 INFO Epoch 3: [4412/10940] ---- BYOL Training Loss = 0.3913537859916687
30-01-2023 17:37:47 INFO Epoch 3: [4423/10940] ---- BYOL Training Loss = 0.259988009929657
30-01-2023 17:38:04 INFO Epoch 3: [4434/10940] ---- BYOL Training Loss = 0.2472783774137497
30-01-2023 17:38:22 INFO Epoch 3: [4445/10940] ---- BYOL Training Loss = 0.2537156939506531
30-01-2023 17:39:15 INFO Epoch 3: [4445/10940] ---- BYOL Validation Loss = 0.2188996970653534
30-01-2023 17:39:32 INFO Epoch 3: [4456/10940] ---- BYOL Training Loss = 0.27135521173477173
30-01-2023 17:39:51 INFO Epoch 3: [4467/10940] ---- BYOL Training Loss = 0.3099322021007538
30-01-2023 17:40:09 INFO Epoch 3: [4478/10940] ---- BYOL Training Loss = 0.32176774740219116
30-01-2023 17:40:26 INFO Epoch 3: [4489/10940] ---- BYOL Training Loss = 0.29842284321784973
30-01-2023 17:41:19 INFO Epoch 3: [4489/10940] ---- BYOL Validation Loss = 0.22754764556884766
30-01-2023 17:41:37 INFO Epoch 3: [4500/10940] ---- BYOL Training Loss = 0.2805458605289459
30-01-2023 17:41:54 INFO Epoch 3: [4511/10940] ---- BYOL Training Loss = 0.24418997764587402
30-01-2023 17:42:13 INFO Epoch 3: [4522/10940] ---- BYOL Training Loss = 0.22458913922309875
30-01-2023 17:42:30 INFO Epoch 3: [4533/10940] ---- BYOL Training Loss = 0.21688148379325867
30-01-2023 17:43:23 INFO Epoch 3: [4533/10940] ---- BYOL Validation Loss = 0.22712989151477814
30-01-2023 17:43:41 INFO Epoch 3: [4544/10940] ---- BYOL Training Loss = 0.20170411467552185
30-01-2023 17:43:59 INFO Epoch 3: [4555/10940] ---- BYOL Training Loss = 0.20943348109722137
30-01-2023 17:44:16 INFO Epoch 3: [4566/10940] ---- BYOL Training Loss = 0.2339247167110443
30-01-2023 17:44:34 INFO Epoch 3: [4577/10940] ---- BYOL Training Loss = 0.27256736159324646
30-01-2023 17:45:27 INFO Epoch 3: [4577/10940] ---- BYOL Validation Loss = 0.24968446791172028
30-01-2023 17:45:45 INFO Epoch 3: [4588/10940] ---- BYOL Training Loss = 0.28678232431411743
30-01-2023 17:46:03 INFO Epoch 3: [4599/10940] ---- BYOL Training Loss = 0.2692577540874481
30-01-2023 17:46:21 INFO Epoch 3: [4610/10940] ---- BYOL Training Loss = 0.2515488266944885
30-01-2023 17:46:38 INFO Epoch 3: [4621/10940] ---- BYOL Training Loss = 0.2261999547481537
30-01-2023 17:47:31 INFO Epoch 3: [4621/10940] ---- BYOL Validation Loss = 0.1846863180398941
30-01-2023 17:47:49 INFO Epoch 3: [4632/10940] ---- BYOL Training Loss = 0.3750927746295929
30-01-2023 17:48:07 INFO Epoch 3: [4643/10940] ---- BYOL Training Loss = 0.40081191062927246
30-01-2023 17:48:24 INFO Epoch 3: [4654/10940] ---- BYOL Training Loss = 0.27968209981918335
30-01-2023 17:48:42 INFO Epoch 3: [4665/10940] ---- BYOL Training Loss = 0.25864681601524353
30-01-2023 17:49:35 INFO Epoch 3: [4665/10940] ---- BYOL Validation Loss = 0.22722934186458588
30-01-2023 17:49:53 INFO Epoch 3: [4676/10940] ---- BYOL Training Loss = 0.27262118458747864
30-01-2023 17:50:11 INFO Epoch 3: [4687/10940] ---- BYOL Training Loss = 0.2655869126319885
30-01-2023 17:50:29 INFO Epoch 3: [4698/10940] ---- BYOL Training Loss = 0.3145785629749298
30-01-2023 17:50:46 INFO Epoch 3: [4709/10940] ---- BYOL Training Loss = 0.3178451955318451
30-01-2023 17:51:39 INFO Epoch 3: [4709/10940] ---- BYOL Validation Loss = 0.1723671704530716
30-01-2023 17:51:57 INFO Epoch 3: [4720/10940] ---- BYOL Training Loss = 0.2227359116077423
30-01-2023 17:52:15 INFO Epoch 3: [4731/10940] ---- BYOL Training Loss = 0.23963257670402527
30-01-2023 17:52:33 INFO Epoch 3: [4742/10940] ---- BYOL Training Loss = 0.2981414198875427
30-01-2023 17:52:51 INFO Epoch 3: [4753/10940] ---- BYOL Training Loss = 0.255508691072464
30-01-2023 17:53:44 INFO Epoch 3: [4753/10940] ---- BYOL Validation Loss = 0.13733185827732086
30-01-2023 17:54:01 INFO Epoch 3: [4764/10940] ---- BYOL Training Loss = 0.2611721158027649
30-01-2023 17:54:19 INFO Epoch 3: [4775/10940] ---- BYOL Training Loss = 0.26219049096107483
30-01-2023 17:54:37 INFO Epoch 3: [4786/10940] ---- BYOL Training Loss = 0.24841324985027313
30-01-2023 17:54:55 INFO Epoch 3: [4797/10940] ---- BYOL Training Loss = 0.24096688628196716
30-01-2023 17:55:48 INFO Epoch 3: [4797/10940] ---- BYOL Validation Loss = 0.22180183231830597
30-01-2023 17:56:05 INFO Epoch 3: [4808/10940] ---- BYOL Training Loss = 0.2645748555660248
30-01-2023 17:56:23 INFO Epoch 3: [4819/10940] ---- BYOL Training Loss = 0.26108071208000183
30-01-2023 17:56:41 INFO Epoch 3: [4830/10940] ---- BYOL Training Loss = 0.23611128330230713
30-01-2023 17:56:59 INFO Epoch 3: [4841/10940] ---- BYOL Training Loss = 0.24572834372520447
30-01-2023 17:57:51 INFO Epoch 3: [4841/10940] ---- BYOL Validation Loss = 0.1861967146396637
30-01-2023 17:58:09 INFO Epoch 3: [4852/10940] ---- BYOL Training Loss = 0.21853728592395782
30-01-2023 17:58:27 INFO Epoch 3: [4863/10940] ---- BYOL Training Loss = 0.1990918517112732
30-01-2023 17:58:45 INFO Epoch 3: [4874/10940] ---- BYOL Training Loss = 0.2299758940935135
30-01-2023 17:59:03 INFO Epoch 3: [4885/10940] ---- BYOL Training Loss = 0.3105847239494324
30-01-2023 17:59:56 INFO Epoch 3: [4885/10940] ---- BYOL Validation Loss = 0.19567576050758362
30-01-2023 18:00:13 INFO Epoch 3: [4896/10940] ---- BYOL Training Loss = 0.292096883058548
30-01-2023 18:00:31 INFO Epoch 3: [4907/10940] ---- BYOL Training Loss = 0.20272794365882874
30-01-2023 18:00:49 INFO Epoch 3: [4918/10940] ---- BYOL Training Loss = 0.2142079621553421
30-01-2023 18:01:07 INFO Epoch 3: [4929/10940] ---- BYOL Training Loss = 0.26855725049972534
30-01-2023 18:02:00 INFO Epoch 3: [4929/10940] ---- BYOL Validation Loss = 0.19858786463737488
30-01-2023 18:02:18 INFO Epoch 3: [4940/10940] ---- BYOL Training Loss = 0.3252512812614441
30-01-2023 18:02:35 INFO Epoch 3: [4951/10940] ---- BYOL Training Loss = 0.3463645875453949
30-01-2023 18:02:54 INFO Epoch 3: [4962/10940] ---- BYOL Training Loss = 0.2843177020549774
30-01-2023 18:03:12 INFO Epoch 3: [4973/10940] ---- BYOL Training Loss = 0.22338108718395233
30-01-2023 18:04:04 INFO Epoch 3: [4973/10940] ---- BYOL Validation Loss = 0.2043486386537552
30-01-2023 18:04:22 INFO Epoch 3: [4984/10940] ---- BYOL Training Loss = 0.35583147406578064
30-01-2023 18:04:39 INFO Epoch 3: [4995/10940] ---- BYOL Training Loss = 0.41082173585891724
30-01-2023 18:04:57 INFO Epoch 3: [5006/10940] ---- BYOL Training Loss = 0.3086155652999878
30-01-2023 18:05:16 INFO Epoch 3: [5017/10940] ---- BYOL Training Loss = 0.2701060473918915
30-01-2023 18:06:09 INFO Epoch 3: [5017/10940] ---- BYOL Validation Loss = 0.14657224714756012
30-01-2023 18:06:26 INFO Epoch 3: [5028/10940] ---- BYOL Training Loss = 0.2084948569536209
30-01-2023 18:06:44 INFO Epoch 3: [5039/10940] ---- BYOL Training Loss = 0.275184690952301
30-01-2023 18:07:02 INFO Epoch 3: [5050/10940] ---- BYOL Training Loss = 0.2924940884113312
30-01-2023 18:07:20 INFO Epoch 3: [5061/10940] ---- BYOL Training Loss = 0.3053358197212219
30-01-2023 18:08:13 INFO Epoch 3: [5061/10940] ---- BYOL Validation Loss = 0.23367677628993988
30-01-2023 18:08:31 INFO Epoch 3: [5072/10940] ---- BYOL Training Loss = 0.28709033131599426
30-01-2023 18:08:49 INFO Epoch 3: [5083/10940] ---- BYOL Training Loss = 0.2044280767440796
30-01-2023 18:09:06 INFO Epoch 3: [5094/10940] ---- BYOL Training Loss = 0.189107745885849
30-01-2023 18:09:24 INFO Epoch 3: [5105/10940] ---- BYOL Training Loss = 0.26769331097602844
30-01-2023 18:10:17 INFO Epoch 3: [5105/10940] ---- BYOL Validation Loss = 0.21622489392757416
30-01-2023 18:10:35 INFO Epoch 3: [5116/10940] ---- BYOL Training Loss = 0.24751834571361542
30-01-2023 18:10:53 INFO Epoch 3: [5127/10940] ---- BYOL Training Loss = 0.24543198943138123
30-01-2023 18:11:11 INFO Epoch 3: [5138/10940] ---- BYOL Training Loss = 0.29854217171669006
30-01-2023 18:11:29 INFO Epoch 3: [5149/10940] ---- BYOL Training Loss = 0.3067716658115387
30-01-2023 18:12:21 INFO Epoch 3: [5149/10940] ---- BYOL Validation Loss = 0.24987468123435974
30-01-2023 18:12:39 INFO Epoch 3: [5160/10940] ---- BYOL Training Loss = 0.286056250333786
30-01-2023 18:12:57 INFO Epoch 3: [5171/10940] ---- BYOL Training Loss = 0.25270363688468933
30-01-2023 18:13:15 INFO Epoch 3: [5182/10940] ---- BYOL Training Loss = 0.2401208132505417
30-01-2023 18:13:33 INFO Epoch 3: [5193/10940] ---- BYOL Training Loss = 0.2307511568069458
30-01-2023 18:14:26 INFO Epoch 3: [5193/10940] ---- BYOL Validation Loss = 0.25676482915878296
30-01-2023 18:14:43 INFO Epoch 3: [5204/10940] ---- BYOL Training Loss = 0.2072860300540924
30-01-2023 18:15:01 INFO Epoch 3: [5215/10940] ---- BYOL Training Loss = 0.2724478542804718
30-01-2023 18:15:19 INFO Epoch 3: [5226/10940] ---- BYOL Training Loss = 0.22018544375896454
30-01-2023 18:15:37 INFO Epoch 3: [5237/10940] ---- BYOL Training Loss = 0.24391131103038788
30-01-2023 18:16:30 INFO Epoch 3: [5237/10940] ---- BYOL Validation Loss = 0.14196652173995972
30-01-2023 18:16:47 INFO Epoch 3: [5248/10940] ---- BYOL Training Loss = 0.2845211625099182
30-01-2023 18:17:05 INFO Epoch 3: [5259/10940] ---- BYOL Training Loss = 0.3446447551250458
30-01-2023 18:17:23 INFO Epoch 3: [5270/10940] ---- BYOL Training Loss = 0.38655003905296326
30-01-2023 18:17:41 INFO Epoch 3: [5281/10940] ---- BYOL Training Loss = 0.31857895851135254
30-01-2023 18:18:34 INFO Epoch 3: [5281/10940] ---- BYOL Validation Loss = 0.19462935626506805
30-01-2023 18:18:51 INFO Epoch 3: [5292/10940] ---- BYOL Training Loss = 0.2533227801322937
30-01-2023 18:19:09 INFO Epoch 3: [5303/10940] ---- BYOL Training Loss = 0.24268503487110138
30-01-2023 18:19:28 INFO Epoch 3: [5314/10940] ---- BYOL Training Loss = 0.2418045997619629
30-01-2023 18:19:46 INFO Epoch 3: [5325/10940] ---- BYOL Training Loss = 0.23913326859474182
30-01-2023 18:20:38 INFO Epoch 3: [5325/10940] ---- BYOL Validation Loss = 0.23653443157672882
30-01-2023 18:20:56 INFO Epoch 3: [5336/10940] ---- BYOL Training Loss = 0.2752479612827301
30-01-2023 18:21:14 INFO Epoch 3: [5347/10940] ---- BYOL Training Loss = 0.29062420129776
30-01-2023 18:21:31 INFO Epoch 3: [5358/10940] ---- BYOL Training Loss = 0.3063807189464569
30-01-2023 18:21:50 INFO Epoch 3: [5369/10940] ---- BYOL Training Loss = 0.3029158115386963
30-01-2023 18:22:43 INFO Epoch 3: [5369/10940] ---- BYOL Validation Loss = 0.23683761060237885
30-01-2023 18:23:00 INFO Epoch 3: [5380/10940] ---- BYOL Training Loss = 0.2870712876319885
30-01-2023 18:23:18 INFO Epoch 3: [5391/10940] ---- BYOL Training Loss = 0.2541177272796631
30-01-2023 18:23:36 INFO Epoch 3: [5402/10940] ---- BYOL Training Loss = 0.23691627383232117
30-01-2023 18:23:54 INFO Epoch 3: [5413/10940] ---- BYOL Training Loss = 0.30437397956848145
30-01-2023 18:24:47 INFO Epoch 3: [5413/10940] ---- BYOL Validation Loss = 0.15115393698215485
30-01-2023 18:25:04 INFO Epoch 3: [5424/10940] ---- BYOL Training Loss = 0.3765389323234558
30-01-2023 18:25:22 INFO Epoch 3: [5435/10940] ---- BYOL Training Loss = 0.31694191694259644
30-01-2023 18:25:40 INFO Epoch 3: [5446/10940] ---- BYOL Training Loss = 0.2648155093193054
30-01-2023 18:25:58 INFO Epoch 3: [5457/10940] ---- BYOL Training Loss = 0.268524169921875
30-01-2023 18:26:51 INFO Epoch 3: [5457/10940] ---- BYOL Validation Loss = 0.23150785267353058
30-01-2023 18:27:09 INFO Epoch 3: [5468/10940] ---- BYOL Training Loss = 0.25612086057662964
30-01-2023 18:27:27 INFO Epoch 3: [5479/10940] ---- BYOL Training Loss = 0.2715829014778137
30-01-2023 18:27:45 INFO Epoch 3: [5490/10940] ---- BYOL Training Loss = 0.24057607352733612
30-01-2023 18:28:02 INFO Epoch 3: [5501/10940] ---- BYOL Training Loss = 0.24188928306102753
30-01-2023 18:28:55 INFO Epoch 3: [5501/10940] ---- BYOL Validation Loss = 0.23032797873020172
30-01-2023 18:29:13 INFO Epoch 3: [5512/10940] ---- BYOL Training Loss = 0.24965092539787292
30-01-2023 18:29:31 INFO Epoch 3: [5523/10940] ---- BYOL Training Loss = 0.187492236495018
30-01-2023 18:29:49 INFO Epoch 3: [5534/10940] ---- BYOL Training Loss = 0.27442318201065063
30-01-2023 18:30:07 INFO Epoch 3: [5545/10940] ---- BYOL Training Loss = 0.2798785865306854
30-01-2023 18:31:00 INFO Epoch 3: [5545/10940] ---- BYOL Validation Loss = 0.10207825899124146
30-01-2023 18:31:18 INFO Epoch 3: [5556/10940] ---- BYOL Training Loss = 0.22322818636894226
30-01-2023 18:31:36 INFO Epoch 3: [5567/10940] ---- BYOL Training Loss = 0.2891250550746918
30-01-2023 18:31:54 INFO Epoch 3: [5578/10940] ---- BYOL Training Loss = 0.2926099896430969
30-01-2023 18:32:12 INFO Epoch 3: [5589/10940] ---- BYOL Training Loss = 0.21337005496025085
30-01-2023 18:33:04 INFO Epoch 3: [5589/10940] ---- BYOL Validation Loss = 0.24137775599956512
30-01-2023 18:33:22 INFO Epoch 3: [5600/10940] ---- BYOL Training Loss = 0.22534838318824768
30-01-2023 18:33:40 INFO Epoch 3: [5611/10940] ---- BYOL Training Loss = 0.2329087257385254
30-01-2023 18:33:58 INFO Epoch 3: [5622/10940] ---- BYOL Training Loss = 0.23625969886779785
30-01-2023 18:34:16 INFO Epoch 3: [5633/10940] ---- BYOL Training Loss = 0.28613588213920593
30-01-2023 18:35:09 INFO Epoch 3: [5633/10940] ---- BYOL Validation Loss = 0.1882053166627884
30-01-2023 18:35:26 INFO Epoch 3: [5644/10940] ---- BYOL Training Loss = 0.2897600531578064
30-01-2023 18:35:45 INFO Epoch 3: [5655/10940] ---- BYOL Training Loss = 0.28276464343070984
30-01-2023 18:36:03 INFO Epoch 3: [5666/10940] ---- BYOL Training Loss = 0.24320904910564423
30-01-2023 18:36:21 INFO Epoch 3: [5677/10940] ---- BYOL Training Loss = 0.26416486501693726
30-01-2023 18:37:14 INFO Epoch 3: [5677/10940] ---- BYOL Validation Loss = 0.2138262540102005
30-01-2023 18:37:31 INFO Epoch 3: [5688/10940] ---- BYOL Training Loss = 0.2125970870256424
30-01-2023 18:37:49 INFO Epoch 3: [5699/10940] ---- BYOL Training Loss = 0.18565431237220764
30-01-2023 18:38:07 INFO Epoch 3: [5710/10940] ---- BYOL Training Loss = 0.2411194145679474
30-01-2023 18:38:25 INFO Epoch 3: [5721/10940] ---- BYOL Training Loss = 0.19716176390647888
30-01-2023 18:39:18 INFO Epoch 3: [5721/10940] ---- BYOL Validation Loss = 0.08473067730665207
30-01-2023 18:39:36 INFO Epoch 3: [5732/10940] ---- BYOL Training Loss = 0.20449793338775635
30-01-2023 18:39:54 INFO Epoch 3: [5743/10940] ---- BYOL Training Loss = 0.28719988465309143
30-01-2023 18:40:12 INFO Epoch 3: [5754/10940] ---- BYOL Training Loss = 0.2972904443740845
30-01-2023 18:40:30 INFO Epoch 3: [5765/10940] ---- BYOL Training Loss = 0.37401464581489563
30-01-2023 18:41:23 INFO Epoch 3: [5765/10940] ---- BYOL Validation Loss = 0.21524976193904877
30-01-2023 18:41:40 INFO Epoch 3: [5776/10940] ---- BYOL Training Loss = 0.25785064697265625
30-01-2023 18:41:59 INFO Epoch 3: [5787/10940] ---- BYOL Training Loss = 0.24550874531269073
30-01-2023 18:42:17 INFO Epoch 3: [5798/10940] ---- BYOL Training Loss = 0.1887061893939972
30-01-2023 18:42:35 INFO Epoch 3: [5809/10940] ---- BYOL Training Loss = 0.20929165184497833
30-01-2023 18:43:28 INFO Epoch 3: [5809/10940] ---- BYOL Validation Loss = 0.16794981062412262
30-01-2023 18:43:45 INFO Epoch 3: [5820/10940] ---- BYOL Training Loss = 0.22714093327522278
30-01-2023 18:44:04 INFO Epoch 3: [5831/10940] ---- BYOL Training Loss = 0.24595892429351807
30-01-2023 18:44:21 INFO Epoch 3: [5842/10940] ---- BYOL Training Loss = 0.23978742957115173
30-01-2023 18:44:39 INFO Epoch 3: [5853/10940] ---- BYOL Training Loss = 0.24751634895801544
30-01-2023 18:45:32 INFO Epoch 3: [5853/10940] ---- BYOL Validation Loss = 0.10387790203094482
30-01-2023 18:45:50 INFO Epoch 3: [5864/10940] ---- BYOL Training Loss = 0.21894435584545135
30-01-2023 18:46:08 INFO Epoch 3: [5875/10940] ---- BYOL Training Loss = 0.25887030363082886
30-01-2023 18:46:26 INFO Epoch 3: [5886/10940] ---- BYOL Training Loss = 0.26287761330604553
30-01-2023 18:46:44 INFO Epoch 3: [5897/10940] ---- BYOL Training Loss = 0.27165427803993225
30-01-2023 18:47:37 INFO Epoch 3: [5897/10940] ---- BYOL Validation Loss = 0.12318770587444305
30-01-2023 18:47:54 INFO Epoch 3: [5908/10940] ---- BYOL Training Loss = 0.2878105640411377
30-01-2023 18:48:13 INFO Epoch 3: [5919/10940] ---- BYOL Training Loss = 0.25504162907600403
30-01-2023 18:48:31 INFO Epoch 3: [5930/10940] ---- BYOL Training Loss = 0.23703265190124512
30-01-2023 18:48:49 INFO Epoch 3: [5941/10940] ---- BYOL Training Loss = 0.27438172698020935
30-01-2023 18:49:42 INFO Epoch 3: [5941/10940] ---- BYOL Validation Loss = 0.1403723657131195
30-01-2023 18:50:00 INFO Epoch 3: [5952/10940] ---- BYOL Training Loss = 0.24278537929058075
30-01-2023 18:50:17 INFO Epoch 3: [5963/10940] ---- BYOL Training Loss = 0.22912704944610596
30-01-2023 18:50:36 INFO Epoch 3: [5974/10940] ---- BYOL Training Loss = 0.24510999023914337
30-01-2023 18:50:54 INFO Epoch 3: [5985/10940] ---- BYOL Training Loss = 0.2809605598449707
30-01-2023 18:51:46 INFO Epoch 3: [5985/10940] ---- BYOL Validation Loss = 0.24436287581920624
30-01-2023 18:52:04 INFO Epoch 3: [5996/10940] ---- BYOL Training Loss = 0.26798370480537415
30-01-2023 18:52:22 INFO Epoch 3: [6007/10940] ---- BYOL Training Loss = 0.26621177792549133
30-01-2023 18:52:41 INFO Epoch 3: [6018/10940] ---- BYOL Training Loss = 0.23784835636615753
30-01-2023 18:52:59 INFO Epoch 3: [6029/10940] ---- BYOL Training Loss = 0.24852637946605682
30-01-2023 18:53:51 INFO Epoch 3: [6029/10940] ---- BYOL Validation Loss = 0.22963322699069977
30-01-2023 18:54:09 INFO Epoch 3: [6040/10940] ---- BYOL Training Loss = 0.2477131187915802
30-01-2023 18:54:27 INFO Epoch 3: [6051/10940] ---- BYOL Training Loss = 0.248981311917305
30-01-2023 18:54:45 INFO Epoch 3: [6062/10940] ---- BYOL Training Loss = 0.18452909588813782
30-01-2023 18:55:03 INFO Epoch 3: [6073/10940] ---- BYOL Training Loss = 0.2009970247745514
30-01-2023 18:55:56 INFO Epoch 3: [6073/10940] ---- BYOL Validation Loss = 0.2202848643064499
30-01-2023 18:56:14 INFO Epoch 3: [6084/10940] ---- BYOL Training Loss = 0.22495794296264648
30-01-2023 18:56:32 INFO Epoch 3: [6095/10940] ---- BYOL Training Loss = 0.2431683987379074
30-01-2023 18:56:50 INFO Epoch 3: [6106/10940] ---- BYOL Training Loss = 0.2915133535861969
30-01-2023 18:57:08 INFO Epoch 3: [6117/10940] ---- BYOL Training Loss = 0.34650859236717224
30-01-2023 18:58:01 INFO Epoch 3: [6117/10940] ---- BYOL Validation Loss = 0.3231763243675232
30-01-2023 18:58:18 INFO Epoch 3: [6128/10940] ---- BYOL Training Loss = 0.35841768980026245
30-01-2023 18:58:36 INFO Epoch 3: [6139/10940] ---- BYOL Training Loss = 0.5112648606300354
30-01-2023 18:58:55 INFO Epoch 3: [6150/10940] ---- BYOL Training Loss = 0.5431966781616211
30-01-2023 18:59:13 INFO Epoch 3: [6161/10940] ---- BYOL Training Loss = 0.34054458141326904
30-01-2023 19:00:06 INFO Epoch 3: [6161/10940] ---- BYOL Validation Loss = 0.17384685575962067
30-01-2023 19:00:23 INFO Epoch 3: [6172/10940] ---- BYOL Training Loss = 0.2098434418439865
30-01-2023 19:00:42 INFO Epoch 3: [6183/10940] ---- BYOL Training Loss = 0.26825398206710815
30-01-2023 19:01:00 INFO Epoch 3: [6194/10940] ---- BYOL Training Loss = 0.30373328924179077
30-01-2023 19:01:18 INFO Epoch 3: [6205/10940] ---- BYOL Training Loss = 0.2636084258556366
30-01-2023 19:02:10 INFO Epoch 3: [6205/10940] ---- BYOL Validation Loss = 0.18313179910182953
30-01-2023 19:02:28 INFO Epoch 3: [6216/10940] ---- BYOL Training Loss = 0.30196258425712585
30-01-2023 19:02:46 INFO Epoch 3: [6227/10940] ---- BYOL Training Loss = 0.2892141342163086
30-01-2023 19:03:04 INFO Epoch 3: [6238/10940] ---- BYOL Training Loss = 0.2905988097190857
30-01-2023 19:03:22 INFO Epoch 3: [6249/10940] ---- BYOL Training Loss = 0.28472018241882324
30-01-2023 19:04:15 INFO Epoch 3: [6249/10940] ---- BYOL Validation Loss = 0.14784960448741913
30-01-2023 19:04:33 INFO Epoch 3: [6260/10940] ---- BYOL Training Loss = 0.2591627240180969
30-01-2023 19:04:51 INFO Epoch 3: [6271/10940] ---- BYOL Training Loss = 0.2475835531949997
30-01-2023 19:05:09 INFO Epoch 3: [6282/10940] ---- BYOL Training Loss = 0.21986576914787292
30-01-2023 19:05:27 INFO Epoch 3: [6293/10940] ---- BYOL Training Loss = 0.22773118317127228
30-01-2023 19:06:20 INFO Epoch 3: [6293/10940] ---- BYOL Validation Loss = 0.24834761023521423
30-01-2023 19:06:37 INFO Epoch 3: [6304/10940] ---- BYOL Training Loss = 0.2771754264831543
30-01-2023 19:06:56 INFO Epoch 3: [6315/10940] ---- BYOL Training Loss = 0.2732239365577698
30-01-2023 19:07:14 INFO Epoch 3: [6326/10940] ---- BYOL Training Loss = 0.22438570857048035
30-01-2023 19:07:32 INFO Epoch 3: [6337/10940] ---- BYOL Training Loss = 0.18161232769489288
30-01-2023 19:08:25 INFO Epoch 3: [6337/10940] ---- BYOL Validation Loss = 0.1099608764052391
30-01-2023 19:08:42 INFO Epoch 3: [6348/10940] ---- BYOL Training Loss = 0.2133379876613617
30-01-2023 19:09:01 INFO Epoch 3: [6359/10940] ---- BYOL Training Loss = 0.2813587784767151
30-01-2023 19:09:19 INFO Epoch 3: [6370/10940] ---- BYOL Training Loss = 0.24124714732170105
30-01-2023 19:09:37 INFO Epoch 3: [6381/10940] ---- BYOL Training Loss = 0.32113614678382874
30-01-2023 19:10:30 INFO Epoch 3: [6381/10940] ---- BYOL Validation Loss = 0.2399844378232956
30-01-2023 19:10:48 INFO Epoch 3: [6392/10940] ---- BYOL Training Loss = 0.38655659556388855
30-01-2023 19:11:06 INFO Epoch 3: [6403/10940] ---- BYOL Training Loss = 0.31235626339912415
30-01-2023 19:11:24 INFO Epoch 3: [6414/10940] ---- BYOL Training Loss = 0.2727895677089691
30-01-2023 19:11:42 INFO Epoch 3: [6425/10940] ---- BYOL Training Loss = 0.24227401614189148
30-01-2023 19:12:35 INFO Epoch 3: [6425/10940] ---- BYOL Validation Loss = 0.1235770508646965
30-01-2023 19:12:53 INFO Epoch 3: [6436/10940] ---- BYOL Training Loss = 0.2390352040529251
30-01-2023 19:13:11 INFO Epoch 3: [6447/10940] ---- BYOL Training Loss = 0.34297820925712585
30-01-2023 19:13:29 INFO Epoch 3: [6458/10940] ---- BYOL Training Loss = 0.3445412516593933
30-01-2023 19:13:47 INFO Epoch 3: [6469/10940] ---- BYOL Training Loss = 0.3764989972114563
30-01-2023 19:14:39 INFO Epoch 3: [6469/10940] ---- BYOL Validation Loss = 0.33624568581581116
30-01-2023 19:14:58 INFO Epoch 3: [6480/10940] ---- BYOL Training Loss = 0.30982282757759094
30-01-2023 19:15:16 INFO Epoch 3: [6491/10940] ---- BYOL Training Loss = 0.2636193633079529
30-01-2023 19:15:34 INFO Epoch 3: [6502/10940] ---- BYOL Training Loss = 0.2893731892108917
30-01-2023 19:15:52 INFO Epoch 3: [6513/10940] ---- BYOL Training Loss = 0.3202974200248718
30-01-2023 19:16:45 INFO Epoch 3: [6513/10940] ---- BYOL Validation Loss = 0.22672538459300995
30-01-2023 19:17:03 INFO Epoch 3: [6524/10940] ---- BYOL Training Loss = 0.3117824196815491
30-01-2023 19:17:21 INFO Epoch 3: [6535/10940] ---- BYOL Training Loss = 0.27437910437583923
30-01-2023 19:17:39 INFO Epoch 3: [6546/10940] ---- BYOL Training Loss = 0.24451033771038055
30-01-2023 19:17:57 INFO Epoch 3: [6557/10940] ---- BYOL Training Loss = 0.22233667969703674
30-01-2023 19:18:50 INFO Epoch 3: [6557/10940] ---- BYOL Validation Loss = 0.18080440163612366
30-01-2023 19:19:07 INFO Epoch 3: [6568/10940] ---- BYOL Training Loss = 0.24614545702934265
30-01-2023 19:19:25 INFO Epoch 3: [6579/10940] ---- BYOL Training Loss = 0.24381785094738007
30-01-2023 19:19:43 INFO Epoch 3: [6590/10940] ---- BYOL Training Loss = 0.22408291697502136
30-01-2023 19:20:02 INFO Epoch 3: [6601/10940] ---- BYOL Training Loss = 0.3138657510280609
30-01-2023 19:20:55 INFO Epoch 3: [6601/10940] ---- BYOL Validation Loss = 0.24028904736042023
30-01-2023 19:21:12 INFO Epoch 3: [6612/10940] ---- BYOL Training Loss = 0.3069279193878174
30-01-2023 19:21:30 INFO Epoch 3: [6623/10940] ---- BYOL Training Loss = 0.31703588366508484
30-01-2023 19:21:49 INFO Epoch 3: [6634/10940] ---- BYOL Training Loss = 0.30541351437568665
30-01-2023 19:22:07 INFO Epoch 3: [6645/10940] ---- BYOL Training Loss = 0.25240716338157654
30-01-2023 19:23:00 INFO Epoch 3: [6645/10940] ---- BYOL Validation Loss = 0.22975459694862366
30-01-2023 19:23:18 INFO Epoch 3: [6656/10940] ---- BYOL Training Loss = 0.23602883517742157
30-01-2023 19:23:36 INFO Epoch 3: [6667/10940] ---- BYOL Training Loss = 0.2617872953414917
30-01-2023 19:23:54 INFO Epoch 3: [6678/10940] ---- BYOL Training Loss = 0.30882787704467773
30-01-2023 19:24:12 INFO Epoch 3: [6689/10940] ---- BYOL Training Loss = 0.2876918911933899
30-01-2023 19:25:05 INFO Epoch 3: [6689/10940] ---- BYOL Validation Loss = 0.19972030818462372
30-01-2023 19:25:23 INFO Epoch 3: [6700/10940] ---- BYOL Training Loss = 0.33596765995025635
30-01-2023 19:25:41 INFO Epoch 3: [6711/10940] ---- BYOL Training Loss = 0.2717546820640564
30-01-2023 19:25:59 INFO Epoch 3: [6722/10940] ---- BYOL Training Loss = 0.41077834367752075
30-01-2023 19:26:18 INFO Epoch 3: [6733/10940] ---- BYOL Training Loss = 0.38172703981399536
30-01-2023 19:27:10 INFO Epoch 3: [6733/10940] ---- BYOL Validation Loss = 0.24494023621082306
30-01-2023 19:27:28 INFO Epoch 3: [6744/10940] ---- BYOL Training Loss = 0.2668880224227905
30-01-2023 19:27:46 INFO Epoch 3: [6755/10940] ---- BYOL Training Loss = 0.26373404264450073
30-01-2023 19:28:04 INFO Epoch 3: [6766/10940] ---- BYOL Training Loss = 0.27644819021224976
30-01-2023 19:28:22 INFO Epoch 3: [6777/10940] ---- BYOL Training Loss = 0.24439628422260284
30-01-2023 19:29:15 INFO Epoch 3: [6777/10940] ---- BYOL Validation Loss = 0.24570763111114502
30-01-2023 19:29:34 INFO Epoch 3: [6788/10940] ---- BYOL Training Loss = 0.24824237823486328
30-01-2023 19:29:52 INFO Epoch 3: [6799/10940] ---- BYOL Training Loss = 0.22530409693717957
30-01-2023 19:30:10 INFO Epoch 3: [6810/10940] ---- BYOL Training Loss = 0.2508535385131836
30-01-2023 19:30:28 INFO Epoch 3: [6821/10940] ---- BYOL Training Loss = 0.3687899112701416
30-01-2023 19:31:20 INFO Epoch 3: [6821/10940] ---- BYOL Validation Loss = 0.15068398416042328
30-01-2023 19:31:39 INFO Epoch 3: [6832/10940] ---- BYOL Training Loss = 0.331499844789505
30-01-2023 19:31:57 INFO Epoch 3: [6843/10940] ---- BYOL Training Loss = 0.24646063148975372
30-01-2023 19:32:15 INFO Epoch 3: [6854/10940] ---- BYOL Training Loss = 0.2800672650337219
30-01-2023 19:32:34 INFO Epoch 3: [6865/10940] ---- BYOL Training Loss = 0.2697252035140991
30-01-2023 19:33:27 INFO Epoch 3: [6865/10940] ---- BYOL Validation Loss = 0.23348745703697205
30-01-2023 19:33:44 INFO Epoch 3: [6876/10940] ---- BYOL Training Loss = 0.2683340609073639
30-01-2023 19:34:02 INFO Epoch 3: [6887/10940] ---- BYOL Training Loss = 0.28362172842025757
30-01-2023 19:34:20 INFO Epoch 3: [6898/10940] ---- BYOL Training Loss = 0.23835213482379913
30-01-2023 19:34:39 INFO Epoch 3: [6909/10940] ---- BYOL Training Loss = 0.2379796952009201
30-01-2023 19:35:32 INFO Epoch 3: [6909/10940] ---- BYOL Validation Loss = 0.09587250649929047
30-01-2023 19:35:49 INFO Epoch 3: [6920/10940] ---- BYOL Training Loss = 0.22863760590553284
30-01-2023 19:36:07 INFO Epoch 3: [6931/10940] ---- BYOL Training Loss = 0.1856459379196167
30-01-2023 19:36:26 INFO Epoch 3: [6942/10940] ---- BYOL Training Loss = 0.2466570883989334
30-01-2023 19:36:44 INFO Epoch 3: [6953/10940] ---- BYOL Training Loss = 0.261465460062027
30-01-2023 19:37:37 INFO Epoch 3: [6953/10940] ---- BYOL Validation Loss = 0.14507147669792175
30-01-2023 19:37:54 INFO Epoch 3: [6964/10940] ---- BYOL Training Loss = 0.2475772202014923
30-01-2023 19:38:12 INFO Epoch 3: [6975/10940] ---- BYOL Training Loss = 0.2088964432477951
30-01-2023 19:38:31 INFO Epoch 3: [6986/10940] ---- BYOL Training Loss = 0.19083228707313538
30-01-2023 19:38:49 INFO Epoch 3: [6997/10940] ---- BYOL Training Loss = 0.18192553520202637
30-01-2023 19:39:42 INFO Epoch 3: [6997/10940] ---- BYOL Validation Loss = 0.14578984677791595
30-01-2023 19:40:00 INFO Epoch 3: [7008/10940] ---- BYOL Training Loss = 0.2366938591003418
30-01-2023 19:40:19 INFO Epoch 3: [7019/10940] ---- BYOL Training Loss = 0.2370108664035797
30-01-2023 19:40:37 INFO Epoch 3: [7030/10940] ---- BYOL Training Loss = 0.2603497803211212
30-01-2023 19:40:55 INFO Epoch 3: [7041/10940] ---- BYOL Training Loss = 0.2784937918186188
30-01-2023 19:41:48 INFO Epoch 3: [7041/10940] ---- BYOL Validation Loss = 0.1593424379825592
30-01-2023 19:42:06 INFO Epoch 3: [7052/10940] ---- BYOL Training Loss = 0.30275052785873413
30-01-2023 19:42:24 INFO Epoch 3: [7063/10940] ---- BYOL Training Loss = 0.33646029233932495
30-01-2023 19:42:42 INFO Epoch 3: [7074/10940] ---- BYOL Training Loss = 0.26060324907302856
30-01-2023 19:43:00 INFO Epoch 3: [7085/10940] ---- BYOL Training Loss = 0.2554319500923157
30-01-2023 19:43:53 INFO Epoch 3: [7085/10940] ---- BYOL Validation Loss = 0.19394288957118988
30-01-2023 19:44:11 INFO Epoch 3: [7096/10940] ---- BYOL Training Loss = 0.28565964102745056
30-01-2023 19:44:29 INFO Epoch 3: [7107/10940] ---- BYOL Training Loss = 0.2645161747932434
30-01-2023 19:44:47 INFO Epoch 3: [7118/10940] ---- BYOL Training Loss = 0.23771294951438904
30-01-2023 19:45:06 INFO Epoch 3: [7129/10940] ---- BYOL Training Loss = 0.25377050042152405
30-01-2023 19:45:59 INFO Epoch 3: [7129/10940] ---- BYOL Validation Loss = 0.22653675079345703
30-01-2023 19:46:17 INFO Epoch 3: [7140/10940] ---- BYOL Training Loss = 0.2673609256744385
30-01-2023 19:46:35 INFO Epoch 3: [7151/10940] ---- BYOL Training Loss = 0.23299722373485565
30-01-2023 19:46:53 INFO Epoch 3: [7162/10940] ---- BYOL Training Loss = 0.2335454672574997
30-01-2023 19:47:11 INFO Epoch 3: [7173/10940] ---- BYOL Training Loss = 0.24281685054302216
30-01-2023 19:48:04 INFO Epoch 3: [7173/10940] ---- BYOL Validation Loss = 0.162055104970932
30-01-2023 19:48:22 INFO Epoch 3: [7184/10940] ---- BYOL Training Loss = 0.2507641613483429
30-01-2023 19:48:40 INFO Epoch 3: [7195/10940] ---- BYOL Training Loss = 0.2513999938964844
30-01-2023 19:48:58 INFO Epoch 3: [7206/10940] ---- BYOL Training Loss = 0.25591909885406494
30-01-2023 19:49:17 INFO Epoch 3: [7217/10940] ---- BYOL Training Loss = 0.2163728028535843
30-01-2023 19:50:10 INFO Epoch 3: [7217/10940] ---- BYOL Validation Loss = 0.23065140843391418
30-01-2023 19:50:27 INFO Epoch 3: [7228/10940] ---- BYOL Training Loss = 0.2524467408657074
30-01-2023 19:50:46 INFO Epoch 3: [7239/10940] ---- BYOL Training Loss = 0.25268298387527466
30-01-2023 19:51:04 INFO Epoch 3: [7250/10940] ---- BYOL Training Loss = 0.23089340329170227
30-01-2023 19:51:22 INFO Epoch 3: [7261/10940] ---- BYOL Training Loss = 0.22789864242076874
30-01-2023 19:52:15 INFO Epoch 3: [7261/10940] ---- BYOL Validation Loss = 0.22257782518863678
30-01-2023 19:52:33 INFO Epoch 3: [7272/10940] ---- BYOL Training Loss = 0.2583094835281372
30-01-2023 19:52:51 INFO Epoch 3: [7283/10940] ---- BYOL Training Loss = 0.2381351739168167
30-01-2023 19:53:09 INFO Epoch 3: [7294/10940] ---- BYOL Training Loss = 0.3079979121685028
30-01-2023 19:53:28 INFO Epoch 3: [7305/10940] ---- BYOL Training Loss = 0.3344420790672302
30-01-2023 19:54:21 INFO Epoch 3: [7305/10940] ---- BYOL Validation Loss = 0.19256040453910828
30-01-2023 19:54:38 INFO Epoch 3: [7316/10940] ---- BYOL Training Loss = 0.3637714982032776
30-01-2023 19:54:56 INFO Epoch 3: [7327/10940] ---- BYOL Training Loss = 0.23410959541797638
30-01-2023 19:55:15 INFO Epoch 3: [7338/10940] ---- BYOL Training Loss = 0.23955027759075165
30-01-2023 19:55:33 INFO Epoch 3: [7349/10940] ---- BYOL Training Loss = 0.20150235295295715
30-01-2023 19:56:26 INFO Epoch 3: [7349/10940] ---- BYOL Validation Loss = 0.17817974090576172
30-01-2023 19:56:44 INFO Epoch 3: [7360/10940] ---- BYOL Training Loss = 0.19804170727729797
30-01-2023 19:57:02 INFO Epoch 3: [7371/10940] ---- BYOL Training Loss = 0.24134080111980438
30-01-2023 19:57:21 INFO Epoch 3: [7382/10940] ---- BYOL Training Loss = 0.2608613967895508
30-01-2023 19:57:39 INFO Epoch 3: [7393/10940] ---- BYOL Training Loss = 0.2188357412815094
30-01-2023 19:58:32 INFO Epoch 3: [7393/10940] ---- BYOL Validation Loss = 0.1845022290945053
30-01-2023 19:58:50 INFO Epoch 3: [7404/10940] ---- BYOL Training Loss = 0.23636698722839355
30-01-2023 19:59:08 INFO Epoch 3: [7415/10940] ---- BYOL Training Loss = 0.2581625282764435
30-01-2023 19:59:26 INFO Epoch 3: [7426/10940] ---- BYOL Training Loss = 0.28637003898620605
30-01-2023 19:59:44 INFO Epoch 3: [7437/10940] ---- BYOL Training Loss = 0.2729279100894928
30-01-2023 20:00:37 INFO Epoch 3: [7437/10940] ---- BYOL Validation Loss = 0.19412963092327118
30-01-2023 20:00:55 INFO Epoch 3: [7448/10940] ---- BYOL Training Loss = 0.24361832439899445
30-01-2023 20:01:13 INFO Epoch 3: [7459/10940] ---- BYOL Training Loss = 0.21635964512825012
30-01-2023 20:01:32 INFO Epoch 3: [7470/10940] ---- BYOL Training Loss = 0.2324492484331131
30-01-2023 20:01:50 INFO Epoch 3: [7481/10940] ---- BYOL Training Loss = 0.267147034406662
30-01-2023 20:02:43 INFO Epoch 3: [7481/10940] ---- BYOL Validation Loss = 0.2039579451084137
30-01-2023 20:03:01 INFO Epoch 3: [7492/10940] ---- BYOL Training Loss = 0.24095502495765686
30-01-2023 20:03:19 INFO Epoch 3: [7503/10940] ---- BYOL Training Loss = 0.32624441385269165
30-01-2023 20:03:37 INFO Epoch 3: [7514/10940] ---- BYOL Training Loss = 0.3562498986721039
30-01-2023 20:03:56 INFO Epoch 3: [7525/10940] ---- BYOL Training Loss = 0.36648061871528625
30-01-2023 20:04:48 INFO Epoch 3: [7525/10940] ---- BYOL Validation Loss = 0.20759637653827667
30-01-2023 20:05:06 INFO Epoch 3: [7536/10940] ---- BYOL Training Loss = 0.3548281788825989
30-01-2023 20:05:24 INFO Epoch 3: [7547/10940] ---- BYOL Training Loss = 0.2803899645805359
30-01-2023 20:05:43 INFO Epoch 3: [7558/10940] ---- BYOL Training Loss = 0.2988622784614563
30-01-2023 20:06:01 INFO Epoch 3: [7569/10940] ---- BYOL Training Loss = 0.27551329135894775
30-01-2023 20:06:54 INFO Epoch 3: [7569/10940] ---- BYOL Validation Loss = 0.13561315834522247
30-01-2023 20:07:12 INFO Epoch 3: [7580/10940] ---- BYOL Training Loss = 0.19923700392246246
30-01-2023 20:07:30 INFO Epoch 3: [7591/10940] ---- BYOL Training Loss = 0.25292322039604187
30-01-2023 20:07:48 INFO Epoch 3: [7602/10940] ---- BYOL Training Loss = 0.28786343336105347
30-01-2023 20:08:06 INFO Epoch 3: [7613/10940] ---- BYOL Training Loss = 0.21750064194202423
30-01-2023 20:08:59 INFO Epoch 3: [7613/10940] ---- BYOL Validation Loss = 0.14400427043437958
30-01-2023 20:09:17 INFO Epoch 3: [7624/10940] ---- BYOL Training Loss = 0.20279626548290253
30-01-2023 20:09:36 INFO Epoch 3: [7635/10940] ---- BYOL Training Loss = 0.19741708040237427
30-01-2023 20:09:54 INFO Epoch 3: [7646/10940] ---- BYOL Training Loss = 0.19698461890220642
30-01-2023 20:10:12 INFO Epoch 3: [7657/10940] ---- BYOL Training Loss = 0.22807228565216064
30-01-2023 20:11:05 INFO Epoch 3: [7657/10940] ---- BYOL Validation Loss = 0.1570386439561844
30-01-2023 20:11:23 INFO Epoch 3: [7668/10940] ---- BYOL Training Loss = 0.22646644711494446
30-01-2023 20:11:41 INFO Epoch 3: [7679/10940] ---- BYOL Training Loss = 0.24032792448997498
30-01-2023 20:12:00 INFO Epoch 3: [7690/10940] ---- BYOL Training Loss = 0.24653466045856476
30-01-2023 20:12:18 INFO Epoch 3: [7701/10940] ---- BYOL Training Loss = 0.22765466570854187
30-01-2023 20:13:11 INFO Epoch 3: [7701/10940] ---- BYOL Validation Loss = 0.15359072387218475
30-01-2023 20:13:29 INFO Epoch 3: [7712/10940] ---- BYOL Training Loss = 0.22583551704883575
30-01-2023 20:13:47 INFO Epoch 3: [7723/10940] ---- BYOL Training Loss = 0.22049927711486816
30-01-2023 20:14:05 INFO Epoch 3: [7734/10940] ---- BYOL Training Loss = 0.21367008984088898
30-01-2023 20:14:23 INFO Epoch 3: [7745/10940] ---- BYOL Training Loss = 0.22228321433067322
30-01-2023 20:15:16 INFO Epoch 3: [7745/10940] ---- BYOL Validation Loss = 0.09468165785074234
30-01-2023 20:15:35 INFO Epoch 3: [7756/10940] ---- BYOL Training Loss = 0.17937012016773224
30-01-2023 20:15:53 INFO Epoch 3: [7767/10940] ---- BYOL Training Loss = 0.18828430771827698
30-01-2023 20:16:11 INFO Epoch 3: [7778/10940] ---- BYOL Training Loss = 0.21302995085716248
30-01-2023 20:16:29 INFO Epoch 3: [7789/10940] ---- BYOL Training Loss = 0.2820870876312256
30-01-2023 20:17:22 INFO Epoch 3: [7789/10940] ---- BYOL Validation Loss = 0.17493438720703125
30-01-2023 20:17:40 INFO Epoch 3: [7800/10940] ---- BYOL Training Loss = 0.2636576294898987
30-01-2023 20:17:58 INFO Epoch 3: [7811/10940] ---- BYOL Training Loss = 0.24796900153160095
30-01-2023 20:18:17 INFO Epoch 3: [7822/10940] ---- BYOL Training Loss = 0.19772885739803314
30-01-2023 20:18:35 INFO Epoch 3: [7833/10940] ---- BYOL Training Loss = 0.19911521673202515
30-01-2023 20:19:28 INFO Epoch 3: [7833/10940] ---- BYOL Validation Loss = 0.16553844511508942
30-01-2023 20:19:46 INFO Epoch 3: [7844/10940] ---- BYOL Training Loss = 0.19354481995105743
30-01-2023 20:20:04 INFO Epoch 3: [7855/10940] ---- BYOL Training Loss = 0.1540895700454712
30-01-2023 20:20:22 INFO Epoch 3: [7866/10940] ---- BYOL Training Loss = 0.21214981377124786
30-01-2023 20:20:41 INFO Epoch 3: [7877/10940] ---- BYOL Training Loss = 0.27812647819519043
30-01-2023 20:21:33 INFO Epoch 3: [7877/10940] ---- BYOL Validation Loss = 0.24507057666778564
30-01-2023 20:21:51 INFO Epoch 3: [7888/10940] ---- BYOL Training Loss = 0.2639211118221283
30-01-2023 20:22:10 INFO Epoch 3: [7899/10940] ---- BYOL Training Loss = 0.2534371614456177
30-01-2023 20:22:28 INFO Epoch 3: [7910/10940] ---- BYOL Training Loss = 0.26063743233680725
30-01-2023 20:22:47 INFO Epoch 3: [7921/10940] ---- BYOL Training Loss = 0.22977033257484436
30-01-2023 20:23:40 INFO Epoch 3: [7921/10940] ---- BYOL Validation Loss = 0.13520392775535583
30-01-2023 20:23:57 INFO Epoch 3: [7932/10940] ---- BYOL Training Loss = 0.24345675110816956
30-01-2023 20:24:16 INFO Epoch 3: [7943/10940] ---- BYOL Training Loss = 0.24795500934123993
30-01-2023 20:24:34 INFO Epoch 3: [7954/10940] ---- BYOL Training Loss = 0.26047977805137634
30-01-2023 20:24:52 INFO Epoch 3: [7965/10940] ---- BYOL Training Loss = 0.23209837079048157
30-01-2023 20:25:45 INFO Epoch 3: [7965/10940] ---- BYOL Validation Loss = 0.1972617357969284
30-01-2023 20:26:03 INFO Epoch 3: [7976/10940] ---- BYOL Training Loss = 0.25102323293685913
30-01-2023 20:26:22 INFO Epoch 3: [7987/10940] ---- BYOL Training Loss = 0.2644104063510895
30-01-2023 20:26:40 INFO Epoch 3: [7998/10940] ---- BYOL Training Loss = 0.1952240765094757
30-01-2023 20:26:58 INFO Epoch 3: [8009/10940] ---- BYOL Training Loss = 0.2192147970199585
30-01-2023 20:27:51 INFO Epoch 3: [8009/10940] ---- BYOL Validation Loss = 0.19142617285251617
30-01-2023 20:28:09 INFO Epoch 3: [8020/10940] ---- BYOL Training Loss = 0.24908900260925293
30-01-2023 20:28:27 INFO Epoch 3: [8031/10940] ---- BYOL Training Loss = 0.22729071974754333
30-01-2023 20:28:46 INFO Epoch 3: [8042/10940] ---- BYOL Training Loss = 0.20220816135406494
30-01-2023 20:29:04 INFO Epoch 3: [8053/10940] ---- BYOL Training Loss = 0.18692420423030853
30-01-2023 20:29:57 INFO Epoch 3: [8053/10940] ---- BYOL Validation Loss = 0.10904498398303986
30-01-2023 20:30:15 INFO Epoch 3: [8064/10940] ---- BYOL Training Loss = 0.21309597790241241
30-01-2023 20:30:33 INFO Epoch 3: [8075/10940] ---- BYOL Training Loss = 0.22765615582466125
30-01-2023 20:30:51 INFO Epoch 3: [8086/10940] ---- BYOL Training Loss = 0.22195176780223846
30-01-2023 20:31:10 INFO Epoch 3: [8097/10940] ---- BYOL Training Loss = 0.26015704870224
30-01-2023 20:32:03 INFO Epoch 3: [8097/10940] ---- BYOL Validation Loss = 0.22413216531276703
30-01-2023 20:32:21 INFO Epoch 3: [8108/10940] ---- BYOL Training Loss = 0.26579445600509644
30-01-2023 20:32:39 INFO Epoch 3: [8119/10940] ---- BYOL Training Loss = 0.2850053012371063
30-01-2023 20:32:58 INFO Epoch 3: [8130/10940] ---- BYOL Training Loss = 0.3289830684661865
30-01-2023 20:33:16 INFO Epoch 3: [8141/10940] ---- BYOL Training Loss = 0.36274653673171997
30-01-2023 20:34:09 INFO Epoch 3: [8141/10940] ---- BYOL Validation Loss = 0.2548608183860779
30-01-2023 20:34:27 INFO Epoch 3: [8152/10940] ---- BYOL Training Loss = 0.3294260501861572
30-01-2023 20:34:45 INFO Epoch 3: [8163/10940] ---- BYOL Training Loss = 0.27359873056411743
30-01-2023 20:35:03 INFO Epoch 3: [8174/10940] ---- BYOL Training Loss = 0.23519881069660187
30-01-2023 20:35:22 INFO Epoch 3: [8185/10940] ---- BYOL Training Loss = 0.3008718490600586
30-01-2023 20:36:15 INFO Epoch 3: [8185/10940] ---- BYOL Validation Loss = 0.2525418698787689
30-01-2023 20:36:33 INFO Epoch 3: [8196/10940] ---- BYOL Training Loss = 0.3499840497970581
30-01-2023 20:36:51 INFO Epoch 3: [8207/10940] ---- BYOL Training Loss = 0.31204694509506226
30-01-2023 20:37:09 INFO Epoch 3: [8218/10940] ---- BYOL Training Loss = 0.27418389916419983
30-01-2023 20:37:28 INFO Epoch 3: [8229/10940] ---- BYOL Training Loss = 0.3299122452735901
30-01-2023 20:38:20 INFO Epoch 3: [8229/10940] ---- BYOL Validation Loss = 0.18493588268756866
30-01-2023 20:38:38 INFO Epoch 3: [8240/10940] ---- BYOL Training Loss = 0.36421242356300354
30-01-2023 20:38:57 INFO Epoch 3: [8251/10940] ---- BYOL Training Loss = 0.2932615578174591
30-01-2023 20:39:15 INFO Epoch 3: [8262/10940] ---- BYOL Training Loss = 0.2368580400943756
30-01-2023 20:39:33 INFO Epoch 3: [8273/10940] ---- BYOL Training Loss = 0.22686341404914856
30-01-2023 20:40:26 INFO Epoch 3: [8273/10940] ---- BYOL Validation Loss = 0.23061762750148773
30-01-2023 20:40:44 INFO Epoch 3: [8284/10940] ---- BYOL Training Loss = 0.23568005859851837
30-01-2023 20:41:02 INFO Epoch 3: [8295/10940] ---- BYOL Training Loss = 0.2605421841144562
30-01-2023 20:41:20 INFO Epoch 3: [8306/10940] ---- BYOL Training Loss = 0.3068927228450775
30-01-2023 20:41:39 INFO Epoch 3: [8317/10940] ---- BYOL Training Loss = 0.32415902614593506
30-01-2023 20:42:31 INFO Epoch 3: [8317/10940] ---- BYOL Validation Loss = 0.24749228358268738
30-01-2023 20:42:49 INFO Epoch 3: [8328/10940] ---- BYOL Training Loss = 0.2934604287147522
30-01-2023 20:43:07 INFO Epoch 3: [8339/10940] ---- BYOL Training Loss = 0.25309017300605774
30-01-2023 20:43:26 INFO Epoch 3: [8350/10940] ---- BYOL Training Loss = 0.27039486169815063
30-01-2023 20:43:44 INFO Epoch 3: [8361/10940] ---- BYOL Training Loss = 0.23933914303779602
30-01-2023 20:44:37 INFO Epoch 3: [8361/10940] ---- BYOL Validation Loss = 0.22189317643642426
30-01-2023 20:44:55 INFO Epoch 3: [8372/10940] ---- BYOL Training Loss = 0.18383607268333435
30-01-2023 20:45:13 INFO Epoch 3: [8383/10940] ---- BYOL Training Loss = 0.19602826237678528
30-01-2023 20:45:31 INFO Epoch 3: [8394/10940] ---- BYOL Training Loss = 0.26895204186439514
30-01-2023 20:45:50 INFO Epoch 3: [8405/10940] ---- BYOL Training Loss = 0.2851884365081787
30-01-2023 20:46:42 INFO Epoch 3: [8405/10940] ---- BYOL Validation Loss = 0.12518657743930817
30-01-2023 20:47:00 INFO Epoch 3: [8416/10940] ---- BYOL Training Loss = 0.2811911404132843
30-01-2023 20:47:19 INFO Epoch 3: [8427/10940] ---- BYOL Training Loss = 0.263542115688324
30-01-2023 20:47:37 INFO Epoch 3: [8438/10940] ---- BYOL Training Loss = 0.2296878546476364
30-01-2023 20:47:55 INFO Epoch 3: [8449/10940] ---- BYOL Training Loss = 0.25778600573539734
30-01-2023 20:48:48 INFO Epoch 3: [8449/10940] ---- BYOL Validation Loss = 0.21925589442253113
30-01-2023 20:49:06 INFO Epoch 3: [8460/10940] ---- BYOL Training Loss = 0.24678580462932587
30-01-2023 20:49:24 INFO Epoch 3: [8471/10940] ---- BYOL Training Loss = 0.21917803585529327
30-01-2023 20:49:43 INFO Epoch 3: [8482/10940] ---- BYOL Training Loss = 0.17776897549629211
30-01-2023 20:50:01 INFO Epoch 3: [8493/10940] ---- BYOL Training Loss = 0.1636536568403244
30-01-2023 20:50:53 INFO Epoch 3: [8493/10940] ---- BYOL Validation Loss = 0.15581358969211578
30-01-2023 20:51:11 INFO Epoch 3: [8504/10940] ---- BYOL Training Loss = 0.19532260298728943
30-01-2023 20:51:30 INFO Epoch 3: [8515/10940] ---- BYOL Training Loss = 0.30145320296287537
30-01-2023 20:51:48 INFO Epoch 3: [8526/10940] ---- BYOL Training Loss = 0.3124825954437256
30-01-2023 20:52:07 INFO Epoch 3: [8537/10940] ---- BYOL Training Loss = 0.1812211275100708
30-01-2023 20:52:59 INFO Epoch 3: [8537/10940] ---- BYOL Validation Loss = 0.1923264116048813
30-01-2023 20:53:17 INFO Epoch 3: [8548/10940] ---- BYOL Training Loss = 0.2488459050655365
30-01-2023 20:53:35 INFO Epoch 3: [8559/10940] ---- BYOL Training Loss = 0.3347488343715668
30-01-2023 20:53:54 INFO Epoch 3: [8570/10940] ---- BYOL Training Loss = 0.30509623885154724
30-01-2023 20:54:12 INFO Epoch 3: [8581/10940] ---- BYOL Training Loss = 0.2810748219490051
30-01-2023 20:55:05 INFO Epoch 3: [8581/10940] ---- BYOL Validation Loss = 0.1323837786912918
30-01-2023 20:55:23 INFO Epoch 3: [8592/10940] ---- BYOL Training Loss = 0.28324365615844727
30-01-2023 20:55:41 INFO Epoch 3: [8603/10940] ---- BYOL Training Loss = 0.28864556550979614
30-01-2023 20:56:00 INFO Epoch 3: [8614/10940] ---- BYOL Training Loss = 0.266139954328537
30-01-2023 20:56:18 INFO Epoch 3: [8625/10940] ---- BYOL Training Loss = 0.2815815806388855
30-01-2023 20:57:10 INFO Epoch 3: [8625/10940] ---- BYOL Validation Loss = 0.11723197996616364
30-01-2023 20:57:29 INFO Epoch 3: [8636/10940] ---- BYOL Training Loss = 0.3370741009712219
30-01-2023 20:57:47 INFO Epoch 3: [8647/10940] ---- BYOL Training Loss = 0.39895594120025635
30-01-2023 20:58:05 INFO Epoch 3: [8658/10940] ---- BYOL Training Loss = 0.25273364782333374
30-01-2023 20:58:23 INFO Epoch 3: [8669/10940] ---- BYOL Training Loss = 0.33964163064956665
30-01-2023 20:59:16 INFO Epoch 3: [8669/10940] ---- BYOL Validation Loss = 0.08330944925546646
30-01-2023 20:59:34 INFO Epoch 3: [8680/10940] ---- BYOL Training Loss = 0.3658190667629242
30-01-2023 20:59:53 INFO Epoch 3: [8691/10940] ---- BYOL Training Loss = 0.334703266620636
30-01-2023 21:00:11 INFO Epoch 3: [8702/10940] ---- BYOL Training Loss = 0.3440234661102295
30-01-2023 21:00:29 INFO Epoch 3: [8713/10940] ---- BYOL Training Loss = 0.2443527728319168
30-01-2023 21:01:22 INFO Epoch 3: [8713/10940] ---- BYOL Validation Loss = 0.12231475859880447
30-01-2023 21:01:40 INFO Epoch 3: [8724/10940] ---- BYOL Training Loss = 0.26806241273880005
30-01-2023 21:01:58 INFO Epoch 3: [8735/10940] ---- BYOL Training Loss = 0.22775907814502716
30-01-2023 21:02:16 INFO Epoch 3: [8746/10940] ---- BYOL Training Loss = 0.2640489935874939
30-01-2023 21:02:35 INFO Epoch 3: [8757/10940] ---- BYOL Training Loss = 0.327197402715683
30-01-2023 21:03:28 INFO Epoch 3: [8757/10940] ---- BYOL Validation Loss = 0.21166500449180603
30-01-2023 21:03:46 INFO Epoch 3: [8768/10940] ---- BYOL Training Loss = 0.41600942611694336
30-01-2023 21:04:04 INFO Epoch 3: [8779/10940] ---- BYOL Training Loss = 0.3393588960170746
30-01-2023 21:04:22 INFO Epoch 3: [8790/10940] ---- BYOL Training Loss = 0.2665730118751526
30-01-2023 21:04:41 INFO Epoch 3: [8801/10940] ---- BYOL Training Loss = 0.24991050362586975
30-01-2023 21:05:33 INFO Epoch 3: [8801/10940] ---- BYOL Validation Loss = 0.1338915079832077
30-01-2023 21:05:52 INFO Epoch 3: [8812/10940] ---- BYOL Training Loss = 0.2230398952960968
30-01-2023 21:06:10 INFO Epoch 3: [8823/10940] ---- BYOL Training Loss = 0.23788562417030334
30-01-2023 21:06:28 INFO Epoch 3: [8834/10940] ---- BYOL Training Loss = 0.2584613561630249
30-01-2023 21:06:47 INFO Epoch 3: [8845/10940] ---- BYOL Training Loss = 0.28271013498306274
30-01-2023 21:07:39 INFO Epoch 3: [8845/10940] ---- BYOL Validation Loss = 0.18309374153614044
30-01-2023 21:07:57 INFO Epoch 3: [8856/10940] ---- BYOL Training Loss = 0.25284749269485474
30-01-2023 21:08:15 INFO Epoch 3: [8867/10940] ---- BYOL Training Loss = 0.21197882294654846
30-01-2023 21:08:34 INFO Epoch 3: [8878/10940] ---- BYOL Training Loss = 0.19435672461986542
30-01-2023 21:08:52 INFO Epoch 3: [8889/10940] ---- BYOL Training Loss = 0.22176602482795715
30-01-2023 21:09:45 INFO Epoch 3: [8889/10940] ---- BYOL Validation Loss = 0.2145337015390396
30-01-2023 21:10:03 INFO Epoch 3: [8900/10940] ---- BYOL Training Loss = 0.23080432415008545
30-01-2023 21:10:22 INFO Epoch 3: [8911/10940] ---- BYOL Training Loss = 0.2521274983882904
30-01-2023 21:10:40 INFO Epoch 3: [8922/10940] ---- BYOL Training Loss = 0.22416436672210693
30-01-2023 21:10:59 INFO Epoch 3: [8933/10940] ---- BYOL Training Loss = 0.2369704246520996
30-01-2023 21:11:51 INFO Epoch 3: [8933/10940] ---- BYOL Validation Loss = 0.1539309173822403
30-01-2023 21:12:09 INFO Epoch 3: [8944/10940] ---- BYOL Training Loss = 0.237078458070755
30-01-2023 21:12:27 INFO Epoch 3: [8955/10940] ---- BYOL Training Loss = 0.24198386073112488
30-01-2023 21:12:46 INFO Epoch 3: [8966/10940] ---- BYOL Training Loss = 0.23150137066841125
30-01-2023 21:13:04 INFO Epoch 3: [8977/10940] ---- BYOL Training Loss = 0.2545214593410492
30-01-2023 21:13:57 INFO Epoch 3: [8977/10940] ---- BYOL Validation Loss = 0.2007070779800415
30-01-2023 21:14:15 INFO Epoch 3: [8988/10940] ---- BYOL Training Loss = 0.18654806911945343
30-01-2023 21:14:34 INFO Epoch 3: [8999/10940] ---- BYOL Training Loss = 0.18737387657165527
30-01-2023 21:14:52 INFO Epoch 3: [9010/10940] ---- BYOL Training Loss = 0.23164422810077667
30-01-2023 21:15:10 INFO Epoch 3: [9021/10940] ---- BYOL Training Loss = 0.21108512580394745
30-01-2023 21:16:03 INFO Epoch 3: [9021/10940] ---- BYOL Validation Loss = 0.10673213750123978
30-01-2023 21:16:21 INFO Epoch 3: [9032/10940] ---- BYOL Training Loss = 0.1918214112520218
30-01-2023 21:16:39 INFO Epoch 3: [9043/10940] ---- BYOL Training Loss = 0.21478214859962463
30-01-2023 21:16:58 INFO Epoch 3: [9054/10940] ---- BYOL Training Loss = 0.28434017300605774
30-01-2023 21:17:16 INFO Epoch 3: [9065/10940] ---- BYOL Training Loss = 0.3948768079280853
30-01-2023 21:18:09 INFO Epoch 3: [9065/10940] ---- BYOL Validation Loss = 0.20507968962192535
30-01-2023 21:18:27 INFO Epoch 3: [9076/10940] ---- BYOL Training Loss = 0.3428574502468109
30-01-2023 21:18:45 INFO Epoch 3: [9087/10940] ---- BYOL Training Loss = 0.20756156742572784
30-01-2023 21:19:04 INFO Epoch 3: [9098/10940] ---- BYOL Training Loss = 0.1812705099582672
30-01-2023 21:19:22 INFO Epoch 3: [9109/10940] ---- BYOL Training Loss = 0.36177024245262146
30-01-2023 21:20:15 INFO Epoch 3: [9109/10940] ---- BYOL Validation Loss = 0.20754073560237885
30-01-2023 21:20:33 INFO Epoch 3: [9120/10940] ---- BYOL Training Loss = 0.41951265931129456
30-01-2023 21:20:51 INFO Epoch 3: [9131/10940] ---- BYOL Training Loss = 0.24580100178718567
30-01-2023 21:21:10 INFO Epoch 3: [9142/10940] ---- BYOL Training Loss = 0.2530471384525299
30-01-2023 21:21:28 INFO Epoch 3: [9153/10940] ---- BYOL Training Loss = 0.31727927923202515
30-01-2023 21:22:20 INFO Epoch 3: [9153/10940] ---- BYOL Validation Loss = 0.23826082050800323
30-01-2023 21:22:39 INFO Epoch 3: [9164/10940] ---- BYOL Training Loss = 0.2671322226524353
30-01-2023 21:22:57 INFO Epoch 3: [9175/10940] ---- BYOL Training Loss = 0.2645745873451233
30-01-2023 21:23:15 INFO Epoch 3: [9186/10940] ---- BYOL Training Loss = 0.2366938591003418
30-01-2023 21:23:34 INFO Epoch 3: [9197/10940] ---- BYOL Training Loss = 0.17660167813301086
30-01-2023 21:24:27 INFO Epoch 3: [9197/10940] ---- BYOL Validation Loss = 0.09962458908557892
30-01-2023 21:24:44 INFO Epoch 3: [9208/10940] ---- BYOL Training Loss = 0.23173518478870392
30-01-2023 21:25:03 INFO Epoch 3: [9219/10940] ---- BYOL Training Loss = 0.2968345284461975
30-01-2023 21:25:21 INFO Epoch 3: [9230/10940] ---- BYOL Training Loss = 0.2743403911590576
30-01-2023 21:25:39 INFO Epoch 3: [9241/10940] ---- BYOL Training Loss = 0.25483474135398865
30-01-2023 21:26:32 INFO Epoch 3: [9241/10940] ---- BYOL Validation Loss = 0.22357991337776184
30-01-2023 21:26:50 INFO Epoch 3: [9252/10940] ---- BYOL Training Loss = 0.294687956571579
30-01-2023 21:27:09 INFO Epoch 3: [9263/10940] ---- BYOL Training Loss = 0.25824877619743347
30-01-2023 21:27:27 INFO Epoch 3: [9274/10940] ---- BYOL Training Loss = 0.1770011931657791
30-01-2023 21:27:45 INFO Epoch 3: [9285/10940] ---- BYOL Training Loss = 0.23476901650428772
30-01-2023 21:28:38 INFO Epoch 3: [9285/10940] ---- BYOL Validation Loss = 0.1707315593957901
30-01-2023 21:28:56 INFO Epoch 3: [9296/10940] ---- BYOL Training Loss = 0.24321050941944122
30-01-2023 21:29:15 INFO Epoch 3: [9307/10940] ---- BYOL Training Loss = 0.20921511948108673
30-01-2023 21:29:33 INFO Epoch 3: [9318/10940] ---- BYOL Training Loss = 0.1746790111064911
30-01-2023 21:29:52 INFO Epoch 3: [9329/10940] ---- BYOL Training Loss = 0.29137665033340454
30-01-2023 21:30:44 INFO Epoch 3: [9329/10940] ---- BYOL Validation Loss = 0.1597958356142044
30-01-2023 21:31:02 INFO Epoch 3: [9340/10940] ---- BYOL Training Loss = 0.3298882842063904
30-01-2023 21:31:21 INFO Epoch 3: [9351/10940] ---- BYOL Training Loss = 0.23357483744621277
30-01-2023 21:31:39 INFO Epoch 3: [9362/10940] ---- BYOL Training Loss = 0.22933220863342285
30-01-2023 21:31:57 INFO Epoch 3: [9373/10940] ---- BYOL Training Loss = 0.2339114397764206
30-01-2023 21:32:50 INFO Epoch 3: [9373/10940] ---- BYOL Validation Loss = 0.1892947107553482
30-01-2023 21:33:08 INFO Epoch 3: [9384/10940] ---- BYOL Training Loss = 0.22498337924480438
30-01-2023 21:33:27 INFO Epoch 3: [9395/10940] ---- BYOL Training Loss = 0.2544412314891815
30-01-2023 21:33:45 INFO Epoch 3: [9406/10940] ---- BYOL Training Loss = 0.21994106471538544
30-01-2023 21:34:04 INFO Epoch 3: [9417/10940] ---- BYOL Training Loss = 0.20587511360645294
30-01-2023 21:34:56 INFO Epoch 3: [9417/10940] ---- BYOL Validation Loss = 0.13995636999607086
30-01-2023 21:35:14 INFO Epoch 3: [9428/10940] ---- BYOL Training Loss = 0.21921619772911072
30-01-2023 21:35:32 INFO Epoch 3: [9439/10940] ---- BYOL Training Loss = 0.19399376213550568
30-01-2023 21:35:51 INFO Epoch 3: [9450/10940] ---- BYOL Training Loss = 0.1895221769809723
30-01-2023 21:36:09 INFO Epoch 3: [9461/10940] ---- BYOL Training Loss = 0.2503420114517212
30-01-2023 21:37:02 INFO Epoch 3: [9461/10940] ---- BYOL Validation Loss = 0.23978400230407715
30-01-2023 21:37:21 INFO Epoch 3: [9472/10940] ---- BYOL Training Loss = 0.22902771830558777
30-01-2023 21:37:39 INFO Epoch 3: [9483/10940] ---- BYOL Training Loss = 0.2195175588130951
30-01-2023 21:37:57 INFO Epoch 3: [9494/10940] ---- BYOL Training Loss = 0.3851487636566162
30-01-2023 21:38:16 INFO Epoch 3: [9505/10940] ---- BYOL Training Loss = 0.3764466345310211
30-01-2023 21:39:08 INFO Epoch 3: [9505/10940] ---- BYOL Validation Loss = 0.22933340072631836
30-01-2023 21:39:26 INFO Epoch 3: [9516/10940] ---- BYOL Training Loss = 0.2947528064250946
30-01-2023 21:39:45 INFO Epoch 3: [9527/10940] ---- BYOL Training Loss = 0.3064485490322113
30-01-2023 21:40:03 INFO Epoch 3: [9538/10940] ---- BYOL Training Loss = 0.2775542736053467
30-01-2023 21:40:22 INFO Epoch 3: [9549/10940] ---- BYOL Training Loss = 0.27927523851394653
30-01-2023 21:41:14 INFO Epoch 3: [9549/10940] ---- BYOL Validation Loss = 0.25136175751686096
30-01-2023 21:41:32 INFO Epoch 3: [9560/10940] ---- BYOL Training Loss = 0.25906363129615784
30-01-2023 21:41:51 INFO Epoch 3: [9571/10940] ---- BYOL Training Loss = 0.23480145633220673
30-01-2023 21:42:09 INFO Epoch 3: [9582/10940] ---- BYOL Training Loss = 0.19979122281074524
30-01-2023 21:42:28 INFO Epoch 3: [9593/10940] ---- BYOL Training Loss = 0.20817983150482178
30-01-2023 21:43:21 INFO Epoch 3: [9593/10940] ---- BYOL Validation Loss = 0.17226052284240723
30-01-2023 21:43:39 INFO Epoch 3: [9604/10940] ---- BYOL Training Loss = 0.21590308845043182
30-01-2023 21:43:57 INFO Epoch 3: [9615/10940] ---- BYOL Training Loss = 0.26456552743911743
30-01-2023 21:44:15 INFO Epoch 3: [9626/10940] ---- BYOL Training Loss = 0.24687471985816956
30-01-2023 21:44:34 INFO Epoch 3: [9637/10940] ---- BYOL Training Loss = 0.21435800194740295
30-01-2023 21:45:27 INFO Epoch 3: [9637/10940] ---- BYOL Validation Loss = 0.24548088014125824
30-01-2023 21:45:45 INFO Epoch 3: [9648/10940] ---- BYOL Training Loss = 0.2918204069137573
30-01-2023 21:46:03 INFO Epoch 3: [9659/10940] ---- BYOL Training Loss = 0.34842491149902344
30-01-2023 21:46:22 INFO Epoch 3: [9670/10940] ---- BYOL Training Loss = 0.308854341506958
30-01-2023 21:46:40 INFO Epoch 3: [9681/10940] ---- BYOL Training Loss = 0.2740613520145416
30-01-2023 21:47:32 INFO Epoch 3: [9681/10940] ---- BYOL Validation Loss = 0.2286665439605713
30-01-2023 21:47:51 INFO Epoch 3: [9692/10940] ---- BYOL Training Loss = 0.3038853406906128
30-01-2023 21:48:09 INFO Epoch 3: [9703/10940] ---- BYOL Training Loss = 0.26730889081954956
30-01-2023 21:48:28 INFO Epoch 3: [9714/10940] ---- BYOL Training Loss = 0.20842592418193817
30-01-2023 21:48:46 INFO Epoch 3: [9725/10940] ---- BYOL Training Loss = 0.2664564847946167
30-01-2023 21:49:38 INFO Epoch 3: [9725/10940] ---- BYOL Validation Loss = 0.1242801621556282
30-01-2023 21:49:56 INFO Epoch 3: [9736/10940] ---- BYOL Training Loss = 0.2751700282096863
30-01-2023 21:50:15 INFO Epoch 3: [9747/10940] ---- BYOL Training Loss = 0.263882040977478
30-01-2023 21:50:33 INFO Epoch 3: [9758/10940] ---- BYOL Training Loss = 0.26470616459846497
30-01-2023 21:50:52 INFO Epoch 3: [9769/10940] ---- BYOL Training Loss = 0.3655025064945221
30-01-2023 21:51:45 INFO Epoch 3: [9769/10940] ---- BYOL Validation Loss = 0.21234925091266632
30-01-2023 21:52:02 INFO Epoch 3: [9780/10940] ---- BYOL Training Loss = 0.3795344829559326
30-01-2023 21:52:21 INFO Epoch 3: [9791/10940] ---- BYOL Training Loss = 0.2769097089767456
30-01-2023 21:52:40 INFO Epoch 3: [9802/10940] ---- BYOL Training Loss = 0.21012750267982483
30-01-2023 21:52:58 INFO Epoch 3: [9813/10940] ---- BYOL Training Loss = 0.19681492447853088
30-01-2023 21:53:51 INFO Epoch 3: [9813/10940] ---- BYOL Validation Loss = 0.22801314294338226
30-01-2023 21:54:09 INFO Epoch 3: [9824/10940] ---- BYOL Training Loss = 0.215854212641716
30-01-2023 21:54:27 INFO Epoch 3: [9835/10940] ---- BYOL Training Loss = 0.20383617281913757
30-01-2023 21:54:46 INFO Epoch 3: [9846/10940] ---- BYOL Training Loss = 0.3456125259399414
30-01-2023 21:55:04 INFO Epoch 3: [9857/10940] ---- BYOL Training Loss = 0.33407288789749146
30-01-2023 21:55:57 INFO Epoch 3: [9857/10940] ---- BYOL Validation Loss = 0.1875292956829071
30-01-2023 21:56:15 INFO Epoch 3: [9868/10940] ---- BYOL Training Loss = 0.28812116384506226
30-01-2023 21:56:34 INFO Epoch 3: [9879/10940] ---- BYOL Training Loss = 0.24999144673347473
30-01-2023 21:56:52 INFO Epoch 3: [9890/10940] ---- BYOL Training Loss = 0.16930167376995087
30-01-2023 21:57:11 INFO Epoch 3: [9901/10940] ---- BYOL Training Loss = 0.22949989140033722
30-01-2023 21:58:03 INFO Epoch 3: [9901/10940] ---- BYOL Validation Loss = 0.16997875273227692
30-01-2023 21:58:21 INFO Epoch 3: [9912/10940] ---- BYOL Training Loss = 0.29731616377830505
30-01-2023 21:58:39 INFO Epoch 3: [9923/10940] ---- BYOL Training Loss = 0.28658056259155273
30-01-2023 21:58:58 INFO Epoch 3: [9934/10940] ---- BYOL Training Loss = 0.3108733296394348
30-01-2023 21:59:16 INFO Epoch 3: [9945/10940] ---- BYOL Training Loss = 0.16937199234962463
30-01-2023 22:00:09 INFO Epoch 3: [9945/10940] ---- BYOL Validation Loss = 0.15221074223518372
30-01-2023 22:00:28 INFO Epoch 3: [9956/10940] ---- BYOL Training Loss = 0.19780698418617249
30-01-2023 22:00:46 INFO Epoch 3: [9967/10940] ---- BYOL Training Loss = 0.227467343211174
30-01-2023 22:01:04 INFO Epoch 3: [9978/10940] ---- BYOL Training Loss = 0.2254120409488678
30-01-2023 22:01:23 INFO Epoch 3: [9989/10940] ---- BYOL Training Loss = 0.23982639610767365
30-01-2023 22:02:15 INFO Epoch 3: [9989/10940] ---- BYOL Validation Loss = 0.23107899725437164
30-01-2023 22:02:33 INFO Epoch 3: [10000/10940] ---- BYOL Training Loss = 0.23029617965221405
30-01-2023 22:02:52 INFO Epoch 3: [10011/10940] ---- BYOL Training Loss = 0.34707552194595337
30-01-2023 22:03:10 INFO Epoch 3: [10022/10940] ---- BYOL Training Loss = 0.3349155783653259
30-01-2023 22:03:28 INFO Epoch 3: [10033/10940] ---- BYOL Training Loss = 0.17593072354793549
30-01-2023 22:04:21 INFO Epoch 3: [10033/10940] ---- BYOL Validation Loss = 0.08987995237112045
30-01-2023 22:04:39 INFO Epoch 3: [10044/10940] ---- BYOL Training Loss = 0.15312650799751282
30-01-2023 22:04:58 INFO Epoch 3: [10055/10940] ---- BYOL Training Loss = 0.18156512081623077
30-01-2023 22:05:16 INFO Epoch 3: [10066/10940] ---- BYOL Training Loss = 0.19824543595314026
30-01-2023 22:05:34 INFO Epoch 3: [10077/10940] ---- BYOL Training Loss = 0.24773085117340088
30-01-2023 22:06:27 INFO Epoch 3: [10077/10940] ---- BYOL Validation Loss = 0.22191143035888672
30-01-2023 22:06:45 INFO Epoch 3: [10088/10940] ---- BYOL Training Loss = 0.25841039419174194
30-01-2023 22:07:04 INFO Epoch 3: [10099/10940] ---- BYOL Training Loss = 0.22402219474315643
30-01-2023 22:07:22 INFO Epoch 3: [10110/10940] ---- BYOL Training Loss = 0.21253478527069092
30-01-2023 22:07:41 INFO Epoch 3: [10121/10940] ---- BYOL Training Loss = 0.20568561553955078
30-01-2023 22:08:33 INFO Epoch 3: [10121/10940] ---- BYOL Validation Loss = 0.13447114825248718
30-01-2023 22:08:51 INFO Epoch 3: [10132/10940] ---- BYOL Training Loss = 0.22870680689811707
30-01-2023 22:09:10 INFO Epoch 3: [10143/10940] ---- BYOL Training Loss = 0.2652472257614136
30-01-2023 22:09:28 INFO Epoch 3: [10154/10940] ---- BYOL Training Loss = 0.2089029848575592
30-01-2023 22:09:47 INFO Epoch 3: [10165/10940] ---- BYOL Training Loss = 0.18552649021148682
30-01-2023 22:10:39 INFO Epoch 3: [10165/10940] ---- BYOL Validation Loss = 0.11367775499820709
30-01-2023 22:10:57 INFO Epoch 3: [10176/10940] ---- BYOL Training Loss = 0.1662886142730713
30-01-2023 22:11:16 INFO Epoch 3: [10187/10940] ---- BYOL Training Loss = 0.21256104111671448
30-01-2023 22:11:34 INFO Epoch 3: [10198/10940] ---- BYOL Training Loss = 0.3117372393608093
30-01-2023 22:11:52 INFO Epoch 3: [10209/10940] ---- BYOL Training Loss = 0.3847010135650635
30-01-2023 22:12:45 INFO Epoch 3: [10209/10940] ---- BYOL Validation Loss = 0.2053494155406952
30-01-2023 22:13:03 INFO Epoch 3: [10220/10940] ---- BYOL Training Loss = 0.34639355540275574
30-01-2023 22:13:22 INFO Epoch 3: [10231/10940] ---- BYOL Training Loss = 0.31296080350875854
30-01-2023 22:13:40 INFO Epoch 3: [10242/10940] ---- BYOL Training Loss = 0.28434616327285767
30-01-2023 22:13:59 INFO Epoch 3: [10253/10940] ---- BYOL Training Loss = 0.28239887952804565
30-01-2023 22:14:51 INFO Epoch 3: [10253/10940] ---- BYOL Validation Loss = 0.22612111270427704
30-01-2023 22:15:09 INFO Epoch 3: [10264/10940] ---- BYOL Training Loss = 0.2858857214450836
30-01-2023 22:15:28 INFO Epoch 3: [10275/10940] ---- BYOL Training Loss = 0.24709638953208923
30-01-2023 22:15:46 INFO Epoch 3: [10286/10940] ---- BYOL Training Loss = 0.25824683904647827
30-01-2023 22:16:05 INFO Epoch 3: [10297/10940] ---- BYOL Training Loss = 0.268296480178833
30-01-2023 22:16:57 INFO Epoch 3: [10297/10940] ---- BYOL Validation Loss = 0.11837101727724075
30-01-2023 22:17:15 INFO Epoch 3: [10308/10940] ---- BYOL Training Loss = 0.3096309304237366
30-01-2023 22:17:34 INFO Epoch 3: [10319/10940] ---- BYOL Training Loss = 0.3197590112686157
30-01-2023 22:17:52 INFO Epoch 3: [10330/10940] ---- BYOL Training Loss = 0.2771386206150055
30-01-2023 22:18:10 INFO Epoch 3: [10341/10940] ---- BYOL Training Loss = 0.23425054550170898
30-01-2023 22:19:03 INFO Epoch 3: [10341/10940] ---- BYOL Validation Loss = 0.16156795620918274
30-01-2023 22:19:21 INFO Epoch 3: [10352/10940] ---- BYOL Training Loss = 0.15790578722953796
30-01-2023 22:19:40 INFO Epoch 3: [10363/10940] ---- BYOL Training Loss = 0.19012735784053802
30-01-2023 22:19:58 INFO Epoch 3: [10374/10940] ---- BYOL Training Loss = 0.258395791053772
30-01-2023 22:20:17 INFO Epoch 3: [10385/10940] ---- BYOL Training Loss = 0.24553728103637695
30-01-2023 22:21:09 INFO Epoch 3: [10385/10940] ---- BYOL Validation Loss = 0.1393970102071762
30-01-2023 22:21:27 INFO Epoch 3: [10396/10940] ---- BYOL Training Loss = 0.23042328655719757
30-01-2023 22:21:46 INFO Epoch 3: [10407/10940] ---- BYOL Training Loss = 0.22327139973640442
30-01-2023 22:22:04 INFO Epoch 3: [10418/10940] ---- BYOL Training Loss = 0.24754223227500916
30-01-2023 22:22:23 INFO Epoch 3: [10429/10940] ---- BYOL Training Loss = 0.21842792630195618
30-01-2023 22:23:15 INFO Epoch 3: [10429/10940] ---- BYOL Validation Loss = 0.18795831501483917
30-01-2023 22:23:33 INFO Epoch 3: [10440/10940] ---- BYOL Training Loss = 0.20514920353889465
30-01-2023 22:23:52 INFO Epoch 3: [10451/10940] ---- BYOL Training Loss = 0.22430217266082764
30-01-2023 22:24:10 INFO Epoch 3: [10462/10940] ---- BYOL Training Loss = 0.23276469111442566
30-01-2023 22:24:29 INFO Epoch 3: [10473/10940] ---- BYOL Training Loss = 0.25859877467155457
30-01-2023 22:25:21 INFO Epoch 3: [10473/10940] ---- BYOL Validation Loss = 0.16714753210544586
30-01-2023 22:25:39 INFO Epoch 3: [10484/10940] ---- BYOL Training Loss = 0.2561325430870056
30-01-2023 22:25:58 INFO Epoch 3: [10495/10940] ---- BYOL Training Loss = 0.2993605136871338
30-01-2023 22:26:16 INFO Epoch 3: [10506/10940] ---- BYOL Training Loss = 0.296194463968277
30-01-2023 22:26:35 INFO Epoch 3: [10517/10940] ---- BYOL Training Loss = 0.2714490592479706
30-01-2023 22:27:27 INFO Epoch 3: [10517/10940] ---- BYOL Validation Loss = 0.21952500939369202
30-01-2023 22:27:46 INFO Epoch 3: [10528/10940] ---- BYOL Training Loss = 0.2670719623565674
30-01-2023 22:28:04 INFO Epoch 3: [10539/10940] ---- BYOL Training Loss = 0.2712605595588684
30-01-2023 22:28:22 INFO Epoch 3: [10550/10940] ---- BYOL Training Loss = 0.24742421507835388
30-01-2023 22:28:41 INFO Epoch 3: [10561/10940] ---- BYOL Training Loss = 0.23890356719493866
30-01-2023 22:29:33 INFO Epoch 3: [10561/10940] ---- BYOL Validation Loss = 0.23361308872699738
30-01-2023 22:29:52 INFO Epoch 3: [10572/10940] ---- BYOL Training Loss = 0.25300973653793335
30-01-2023 22:30:10 INFO Epoch 3: [10583/10940] ---- BYOL Training Loss = 0.22525569796562195
30-01-2023 22:30:28 INFO Epoch 3: [10594/10940] ---- BYOL Training Loss = 0.195217102766037
30-01-2023 22:30:47 INFO Epoch 3: [10605/10940] ---- BYOL Training Loss = 0.21061548590660095
30-01-2023 22:31:40 INFO Epoch 3: [10605/10940] ---- BYOL Validation Loss = 0.18530236184597015
30-01-2023 22:31:58 INFO Epoch 3: [10616/10940] ---- BYOL Training Loss = 0.23341438174247742
30-01-2023 22:32:16 INFO Epoch 3: [10627/10940] ---- BYOL Training Loss = 0.21661023795604706
30-01-2023 22:32:35 INFO Epoch 3: [10638/10940] ---- BYOL Training Loss = 0.22583548724651337
30-01-2023 22:32:53 INFO Epoch 3: [10649/10940] ---- BYOL Training Loss = 0.2263573855161667
30-01-2023 22:33:46 INFO Epoch 3: [10649/10940] ---- BYOL Validation Loss = 0.2163916379213333
30-01-2023 22:34:04 INFO Epoch 3: [10660/10940] ---- BYOL Training Loss = 0.21037991344928741
30-01-2023 22:34:23 INFO Epoch 3: [10671/10940] ---- BYOL Training Loss = 0.2400510609149933
30-01-2023 22:34:41 INFO Epoch 3: [10682/10940] ---- BYOL Training Loss = 0.31196287274360657
30-01-2023 22:34:59 INFO Epoch 3: [10693/10940] ---- BYOL Training Loss = 0.30859461426734924
30-01-2023 22:35:52 INFO Epoch 3: [10693/10940] ---- BYOL Validation Loss = 0.20131608843803406
30-01-2023 22:36:10 INFO Epoch 3: [10704/10940] ---- BYOL Training Loss = 0.2720243036746979
30-01-2023 22:36:29 INFO Epoch 3: [10715/10940] ---- BYOL Training Loss = 0.2825133800506592
30-01-2023 22:36:47 INFO Epoch 3: [10726/10940] ---- BYOL Training Loss = 0.2617139220237732
30-01-2023 22:37:06 INFO Epoch 3: [10737/10940] ---- BYOL Training Loss = 0.29888421297073364
30-01-2023 22:37:58 INFO Epoch 3: [10737/10940] ---- BYOL Validation Loss = 0.23409847915172577
30-01-2023 22:38:17 INFO Epoch 3: [10748/10940] ---- BYOL Training Loss = 0.2982983887195587
30-01-2023 22:38:35 INFO Epoch 3: [10759/10940] ---- BYOL Training Loss = 0.30913838744163513
30-01-2023 22:38:54 INFO Epoch 3: [10770/10940] ---- BYOL Training Loss = 0.2753045856952667
30-01-2023 22:39:12 INFO Epoch 3: [10781/10940] ---- BYOL Training Loss = 0.2484014928340912
30-01-2023 22:40:05 INFO Epoch 3: [10781/10940] ---- BYOL Validation Loss = 0.1697421818971634
30-01-2023 22:40:24 INFO Epoch 3: [10792/10940] ---- BYOL Training Loss = 0.24415333569049835
30-01-2023 22:40:42 INFO Epoch 3: [10803/10940] ---- BYOL Training Loss = 0.21465878188610077
30-01-2023 22:41:01 INFO Epoch 3: [10814/10940] ---- BYOL Training Loss = 0.3812219202518463
30-01-2023 22:41:19 INFO Epoch 3: [10825/10940] ---- BYOL Training Loss = 0.4005317687988281
30-01-2023 22:42:12 INFO Epoch 3: [10825/10940] ---- BYOL Validation Loss = 0.20503009855747223
30-01-2023 22:42:30 INFO Epoch 3: [10836/10940] ---- BYOL Training Loss = 0.23680703341960907
30-01-2023 22:42:49 INFO Epoch 3: [10847/10940] ---- BYOL Training Loss = 0.3247923254966736
30-01-2023 22:43:07 INFO Epoch 3: [10858/10940] ---- BYOL Training Loss = 0.2856917083263397
30-01-2023 22:43:26 INFO Epoch 3: [10869/10940] ---- BYOL Training Loss = 0.25650760531425476
30-01-2023 22:44:18 INFO Epoch 3: [10869/10940] ---- BYOL Validation Loss = 0.25357601046562195
30-01-2023 22:44:36 INFO Epoch 3: [10880/10940] ---- BYOL Training Loss = 0.2630484402179718
30-01-2023 22:44:55 INFO Epoch 3: [10891/10940] ---- BYOL Training Loss = 0.18851958215236664
30-01-2023 22:45:13 INFO Epoch 3: [10902/10940] ---- BYOL Training Loss = 0.20242254436016083
30-01-2023 22:45:32 INFO Epoch 3: [10913/10940] ---- BYOL Training Loss = 0.21002575755119324
30-01-2023 22:46:25 INFO Epoch 3: [10913/10940] ---- BYOL Validation Loss = 0.20295794308185577
30-01-2023 22:46:43 INFO Epoch 3: [10924/10940] ---- BYOL Training Loss = 0.2598493993282318
30-01-2023 22:47:01 INFO Epoch 3: [10935/10940] ---- BYOL Training Loss = 0.2885087728500366
30-01-2023 22:47:11 INFO Starting Epoch: 4
30-01-2023 22:47:29 INFO Epoch 4: [12/10940] ---- BYOL Training Loss = 0.17734135687351227
30-01-2023 22:47:46 INFO Epoch 4: [23/10940] ---- BYOL Training Loss = 0.21138517558574677
30-01-2023 22:48:04 INFO Epoch 4: [34/10940] ---- BYOL Training Loss = 0.23740823566913605
30-01-2023 22:48:21 INFO Epoch 4: [45/10940] ---- BYOL Training Loss = 0.20926415920257568
30-01-2023 22:49:14 INFO Epoch 4: [45/10940] ---- BYOL Validation Loss = 0.21565185487270355
30-01-2023 22:49:31 INFO Epoch 4: [56/10940] ---- BYOL Training Loss = 0.20846755802631378
30-01-2023 22:49:48 INFO Epoch 4: [67/10940] ---- BYOL Training Loss = 0.18547753989696503
30-01-2023 22:50:06 INFO Epoch 4: [78/10940] ---- BYOL Training Loss = 0.19930177927017212
30-01-2023 22:50:23 INFO Epoch 4: [89/10940] ---- BYOL Training Loss = 0.19090303778648376
30-01-2023 22:51:16 INFO Epoch 4: [89/10940] ---- BYOL Validation Loss = 0.1339595913887024
30-01-2023 22:51:33 INFO Epoch 4: [100/10940] ---- BYOL Training Loss = 0.16653792560100555
30-01-2023 22:51:50 INFO Epoch 4: [111/10940] ---- BYOL Training Loss = 0.15792757272720337
30-01-2023 22:52:08 INFO Epoch 4: [122/10940] ---- BYOL Training Loss = 0.2076086550951004
30-01-2023 22:52:25 INFO Epoch 4: [133/10940] ---- BYOL Training Loss = 0.23190343379974365
30-01-2023 22:53:18 INFO Epoch 4: [133/10940] ---- BYOL Validation Loss = 0.17600707709789276
30-01-2023 22:53:35 INFO Epoch 4: [144/10940] ---- BYOL Training Loss = 0.31340986490249634
30-01-2023 22:53:52 INFO Epoch 4: [155/10940] ---- BYOL Training Loss = 0.2905500531196594
30-01-2023 22:54:10 INFO Epoch 4: [166/10940] ---- BYOL Training Loss = 0.16789184510707855
30-01-2023 22:54:27 INFO Epoch 4: [177/10940] ---- BYOL Training Loss = 0.16768407821655273
30-01-2023 22:55:20 INFO Epoch 4: [177/10940] ---- BYOL Validation Loss = 0.1207701787352562
30-01-2023 22:55:37 INFO Epoch 4: [188/10940] ---- BYOL Training Loss = 0.19138842821121216
30-01-2023 22:55:54 INFO Epoch 4: [199/10940] ---- BYOL Training Loss = 0.23671381175518036
30-01-2023 22:56:12 INFO Epoch 4: [210/10940] ---- BYOL Training Loss = 0.26930761337280273
30-01-2023 22:56:29 INFO Epoch 4: [221/10940] ---- BYOL Training Loss = 0.2249254733324051
30-01-2023 22:57:22 INFO Epoch 4: [221/10940] ---- BYOL Validation Loss = 0.20903952419757843
30-01-2023 22:57:39 INFO Epoch 4: [232/10940] ---- BYOL Training Loss = 0.22014455497264862
30-01-2023 22:57:57 INFO Epoch 4: [243/10940] ---- BYOL Training Loss = 0.2207024097442627
30-01-2023 22:58:14 INFO Epoch 4: [254/10940] ---- BYOL Training Loss = 0.21012535691261292
30-01-2023 22:58:31 INFO Epoch 4: [265/10940] ---- BYOL Training Loss = 0.25255104899406433
30-01-2023 22:59:24 INFO Epoch 4: [265/10940] ---- BYOL Validation Loss = 0.20599135756492615
30-01-2023 22:59:41 INFO Epoch 4: [276/10940] ---- BYOL Training Loss = 0.2528038024902344
30-01-2023 22:59:58 INFO Epoch 4: [287/10940] ---- BYOL Training Loss = 0.23087672889232635
30-01-2023 23:00:16 INFO Epoch 4: [298/10940] ---- BYOL Training Loss = 0.23250308632850647
30-01-2023 23:00:33 INFO Epoch 4: [309/10940] ---- BYOL Training Loss = 0.2585284113883972
30-01-2023 23:01:26 INFO Epoch 4: [309/10940] ---- BYOL Validation Loss = 0.09616299718618393
30-01-2023 23:01:43 INFO Epoch 4: [320/10940] ---- BYOL Training Loss = 0.27053993940353394
30-01-2023 23:02:00 INFO Epoch 4: [331/10940] ---- BYOL Training Loss = 0.21227598190307617
30-01-2023 23:02:18 INFO Epoch 4: [342/10940] ---- BYOL Training Loss = 0.3092508912086487
30-01-2023 23:02:35 INFO Epoch 4: [353/10940] ---- BYOL Training Loss = 0.36069896817207336
30-01-2023 23:03:28 INFO Epoch 4: [353/10940] ---- BYOL Validation Loss = 0.22530396282672882
30-01-2023 23:03:45 INFO Epoch 4: [364/10940] ---- BYOL Training Loss = 0.2541044354438782
30-01-2023 23:04:03 INFO Epoch 4: [375/10940] ---- BYOL Training Loss = 0.23496298491954803
30-01-2023 23:04:21 INFO Epoch 4: [386/10940] ---- BYOL Training Loss = 0.2876513600349426
30-01-2023 23:04:38 INFO Epoch 4: [397/10940] ---- BYOL Training Loss = 0.3050341010093689
30-01-2023 23:05:31 INFO Epoch 4: [397/10940] ---- BYOL Validation Loss = 0.21354611217975616
30-01-2023 23:05:48 INFO Epoch 4: [408/10940] ---- BYOL Training Loss = 0.22089776396751404
30-01-2023 23:06:06 INFO Epoch 4: [419/10940] ---- BYOL Training Loss = 0.18975895643234253
30-01-2023 23:06:23 INFO Epoch 4: [430/10940] ---- BYOL Training Loss = 0.21929745376110077
30-01-2023 23:06:41 INFO Epoch 4: [441/10940] ---- BYOL Training Loss = 0.2543601393699646
30-01-2023 23:07:33 INFO Epoch 4: [441/10940] ---- BYOL Validation Loss = 0.23889119923114777
30-01-2023 23:07:50 INFO Epoch 4: [452/10940] ---- BYOL Training Loss = 0.19490480422973633
30-01-2023 23:08:08 INFO Epoch 4: [463/10940] ---- BYOL Training Loss = 0.1756979376077652
30-01-2023 23:08:25 INFO Epoch 4: [474/10940] ---- BYOL Training Loss = 0.18862006068229675
30-01-2023 23:08:43 INFO Epoch 4: [485/10940] ---- BYOL Training Loss = 0.18418894708156586
30-01-2023 23:09:35 INFO Epoch 4: [485/10940] ---- BYOL Validation Loss = 0.1943107396364212
30-01-2023 23:09:52 INFO Epoch 4: [496/10940] ---- BYOL Training Loss = 0.19363021850585938
30-01-2023 23:10:10 INFO Epoch 4: [507/10940] ---- BYOL Training Loss = 0.19078440964221954
30-01-2023 23:10:27 INFO Epoch 4: [518/10940] ---- BYOL Training Loss = 0.2112848311662674
30-01-2023 23:10:45 INFO Epoch 4: [529/10940] ---- BYOL Training Loss = 0.21093206107616425
30-01-2023 23:11:38 INFO Epoch 4: [529/10940] ---- BYOL Validation Loss = 0.08913743495941162
30-01-2023 23:11:55 INFO Epoch 4: [540/10940] ---- BYOL Training Loss = 0.22102117538452148
30-01-2023 23:12:12 INFO Epoch 4: [551/10940] ---- BYOL Training Loss = 0.26514849066734314
30-01-2023 23:12:29 INFO Epoch 4: [562/10940] ---- BYOL Training Loss = 0.25223392248153687
30-01-2023 23:12:47 INFO Epoch 4: [573/10940] ---- BYOL Training Loss = 0.2844315767288208
30-01-2023 23:13:40 INFO Epoch 4: [573/10940] ---- BYOL Validation Loss = 0.3504996597766876
30-01-2023 23:13:57 INFO Epoch 4: [584/10940] ---- BYOL Training Loss = 0.2712145745754242
30-01-2023 23:14:15 INFO Epoch 4: [595/10940] ---- BYOL Training Loss = 0.3084228038787842
30-01-2023 23:14:32 INFO Epoch 4: [606/10940] ---- BYOL Training Loss = 0.3240965008735657
30-01-2023 23:14:49 INFO Epoch 4: [617/10940] ---- BYOL Training Loss = 0.2238188087940216
30-01-2023 23:15:42 INFO Epoch 4: [617/10940] ---- BYOL Validation Loss = 0.182408407330513
30-01-2023 23:15:59 INFO Epoch 4: [628/10940] ---- BYOL Training Loss = 0.1695210039615631
30-01-2023 23:16:17 INFO Epoch 4: [639/10940] ---- BYOL Training Loss = 0.20249256491661072
30-01-2023 23:16:34 INFO Epoch 4: [650/10940] ---- BYOL Training Loss = 0.1751263439655304
30-01-2023 23:16:52 INFO Epoch 4: [661/10940] ---- BYOL Training Loss = 0.20411622524261475
30-01-2023 23:17:45 INFO Epoch 4: [661/10940] ---- BYOL Validation Loss = 0.20185433328151703
30-01-2023 23:18:02 INFO Epoch 4: [672/10940] ---- BYOL Training Loss = 0.166956827044487
30-01-2023 23:18:19 INFO Epoch 4: [683/10940] ---- BYOL Training Loss = 0.2050580531358719
30-01-2023 23:18:37 INFO Epoch 4: [694/10940] ---- BYOL Training Loss = 0.2754465937614441
30-01-2023 23:18:54 INFO Epoch 4: [705/10940] ---- BYOL Training Loss = 0.24053804576396942
30-01-2023 23:19:47 INFO Epoch 4: [705/10940] ---- BYOL Validation Loss = 0.2105291187763214
30-01-2023 23:20:04 INFO Epoch 4: [716/10940] ---- BYOL Training Loss = 0.22448015213012695
30-01-2023 23:20:22 INFO Epoch 4: [727/10940] ---- BYOL Training Loss = 0.2763248682022095
30-01-2023 23:20:39 INFO Epoch 4: [738/10940] ---- BYOL Training Loss = 0.28772425651550293
30-01-2023 23:20:57 INFO Epoch 4: [749/10940] ---- BYOL Training Loss = 0.24086157977581024
30-01-2023 23:21:50 INFO Epoch 4: [749/10940] ---- BYOL Validation Loss = 0.1504831165075302
30-01-2023 23:22:07 INFO Epoch 4: [760/10940] ---- BYOL Training Loss = 0.2566821277141571
30-01-2023 23:22:24 INFO Epoch 4: [771/10940] ---- BYOL Training Loss = 0.2812190353870392
30-01-2023 23:22:41 INFO Epoch 4: [782/10940] ---- BYOL Training Loss = 0.2574039399623871
30-01-2023 23:22:59 INFO Epoch 4: [793/10940] ---- BYOL Training Loss = 0.20979002118110657
30-01-2023 23:23:52 INFO Epoch 4: [793/10940] ---- BYOL Validation Loss = 0.14285895228385925
30-01-2023 23:24:09 INFO Epoch 4: [804/10940] ---- BYOL Training Loss = 0.22503086924552917
30-01-2023 23:24:27 INFO Epoch 4: [815/10940] ---- BYOL Training Loss = 0.26624053716659546
30-01-2023 23:24:44 INFO Epoch 4: [826/10940] ---- BYOL Training Loss = 0.23420529067516327
30-01-2023 23:25:02 INFO Epoch 4: [837/10940] ---- BYOL Training Loss = 0.18443886935710907
30-01-2023 23:25:54 INFO Epoch 4: [837/10940] ---- BYOL Validation Loss = 0.1986316293478012
30-01-2023 23:26:11 INFO Epoch 4: [848/10940] ---- BYOL Training Loss = 0.15428206324577332
30-01-2023 23:26:29 INFO Epoch 4: [859/10940] ---- BYOL Training Loss = 0.20693401992321014
30-01-2023 23:26:46 INFO Epoch 4: [870/10940] ---- BYOL Training Loss = 0.24654217064380646
30-01-2023 23:27:04 INFO Epoch 4: [881/10940] ---- BYOL Training Loss = 0.22381877899169922
30-01-2023 23:27:57 INFO Epoch 4: [881/10940] ---- BYOL Validation Loss = 0.1814614236354828
30-01-2023 23:28:14 INFO Epoch 4: [892/10940] ---- BYOL Training Loss = 0.21896147727966309
30-01-2023 23:28:31 INFO Epoch 4: [903/10940] ---- BYOL Training Loss = 0.22989392280578613
30-01-2023 23:28:49 INFO Epoch 4: [914/10940] ---- BYOL Training Loss = 0.229038804769516
30-01-2023 23:29:07 INFO Epoch 4: [925/10940] ---- BYOL Training Loss = 0.19071799516677856
30-01-2023 23:30:00 INFO Epoch 4: [925/10940] ---- BYOL Validation Loss = 0.128061905503273
30-01-2023 23:30:17 INFO Epoch 4: [936/10940] ---- BYOL Training Loss = 0.21731483936309814
30-01-2023 23:30:35 INFO Epoch 4: [947/10940] ---- BYOL Training Loss = 0.2639254629611969
30-01-2023 23:30:52 INFO Epoch 4: [958/10940] ---- BYOL Training Loss = 0.2689635753631592
30-01-2023 23:31:10 INFO Epoch 4: [969/10940] ---- BYOL Training Loss = 0.24296286702156067
30-01-2023 23:32:02 INFO Epoch 4: [969/10940] ---- BYOL Validation Loss = 0.14887429773807526
30-01-2023 23:32:19 INFO Epoch 4: [980/10940] ---- BYOL Training Loss = 0.2885824143886566
30-01-2023 23:32:37 INFO Epoch 4: [991/10940] ---- BYOL Training Loss = 0.2497158795595169
30-01-2023 23:32:54 INFO Epoch 4: [1002/10940] ---- BYOL Training Loss = 0.2193123996257782
30-01-2023 23:33:12 INFO Epoch 4: [1013/10940] ---- BYOL Training Loss = 0.2229582518339157
30-01-2023 23:34:05 INFO Epoch 4: [1013/10940] ---- BYOL Validation Loss = 0.16987594962120056
30-01-2023 23:34:22 INFO Epoch 4: [1024/10940] ---- BYOL Training Loss = 0.2092934101819992
30-01-2023 23:34:39 INFO Epoch 4: [1035/10940] ---- BYOL Training Loss = 0.21850153803825378
30-01-2023 23:34:57 INFO Epoch 4: [1046/10940] ---- BYOL Training Loss = 0.2284073829650879
30-01-2023 23:35:15 INFO Epoch 4: [1057/10940] ---- BYOL Training Loss = 0.1994180530309677
30-01-2023 23:36:07 INFO Epoch 4: [1057/10940] ---- BYOL Validation Loss = 0.1952245533466339
30-01-2023 23:36:24 INFO Epoch 4: [1068/10940] ---- BYOL Training Loss = 0.22745788097381592
30-01-2023 23:36:42 INFO Epoch 4: [1079/10940] ---- BYOL Training Loss = 0.2517392635345459
30-01-2023 23:37:00 INFO Epoch 4: [1090/10940] ---- BYOL Training Loss = 0.21866266429424286
30-01-2023 23:37:17 INFO Epoch 4: [1101/10940] ---- BYOL Training Loss = 0.2613440454006195
30-01-2023 23:38:10 INFO Epoch 4: [1101/10940] ---- BYOL Validation Loss = 0.19624190032482147
30-01-2023 23:38:27 INFO Epoch 4: [1112/10940] ---- BYOL Training Loss = 0.20258653163909912
30-01-2023 23:38:45 INFO Epoch 4: [1123/10940] ---- BYOL Training Loss = 0.270434707403183
30-01-2023 23:39:02 INFO Epoch 4: [1134/10940] ---- BYOL Training Loss = 0.34158605337142944
30-01-2023 23:39:19 INFO Epoch 4: [1145/10940] ---- BYOL Training Loss = 0.26713958382606506
30-01-2023 23:40:12 INFO Epoch 4: [1145/10940] ---- BYOL Validation Loss = 0.19571371376514435
30-01-2023 23:40:30 INFO Epoch 4: [1156/10940] ---- BYOL Training Loss = 0.22519826889038086
30-01-2023 23:40:47 INFO Epoch 4: [1167/10940] ---- BYOL Training Loss = 0.2553845942020416
30-01-2023 23:41:05 INFO Epoch 4: [1178/10940] ---- BYOL Training Loss = 0.29826706647872925
30-01-2023 23:41:22 INFO Epoch 4: [1189/10940] ---- BYOL Training Loss = 0.2555943727493286
30-01-2023 23:42:15 INFO Epoch 4: [1189/10940] ---- BYOL Validation Loss = 0.16155409812927246
30-01-2023 23:42:32 INFO Epoch 4: [1200/10940] ---- BYOL Training Loss = 0.23815515637397766
30-01-2023 23:42:50 INFO Epoch 4: [1211/10940] ---- BYOL Training Loss = 0.171352356672287
30-01-2023 23:43:08 INFO Epoch 4: [1222/10940] ---- BYOL Training Loss = 0.29028376936912537
30-01-2023 23:43:25 INFO Epoch 4: [1233/10940] ---- BYOL Training Loss = 0.2112552672624588
30-01-2023 23:44:18 INFO Epoch 4: [1233/10940] ---- BYOL Validation Loss = 0.18191538751125336
30-01-2023 23:44:35 INFO Epoch 4: [1244/10940] ---- BYOL Training Loss = 0.2146107405424118
30-01-2023 23:44:53 INFO Epoch 4: [1255/10940] ---- BYOL Training Loss = 0.259796679019928
30-01-2023 23:45:10 INFO Epoch 4: [1266/10940] ---- BYOL Training Loss = 0.24330182373523712
30-01-2023 23:45:28 INFO Epoch 4: [1277/10940] ---- BYOL Training Loss = 0.20739547908306122
30-01-2023 23:46:21 INFO Epoch 4: [1277/10940] ---- BYOL Validation Loss = 0.2114483267068863
30-01-2023 23:46:38 INFO Epoch 4: [1288/10940] ---- BYOL Training Loss = 0.2321055382490158
30-01-2023 23:46:55 INFO Epoch 4: [1299/10940] ---- BYOL Training Loss = 0.2096598893404007
30-01-2023 23:47:13 INFO Epoch 4: [1310/10940] ---- BYOL Training Loss = 0.22581002116203308
30-01-2023 23:47:30 INFO Epoch 4: [1321/10940] ---- BYOL Training Loss = 0.2479170858860016
30-01-2023 23:48:23 INFO Epoch 4: [1321/10940] ---- BYOL Validation Loss = 0.18875275552272797
30-01-2023 23:48:40 INFO Epoch 4: [1332/10940] ---- BYOL Training Loss = 0.24538835883140564
30-01-2023 23:48:58 INFO Epoch 4: [1343/10940] ---- BYOL Training Loss = 0.1909932643175125
30-01-2023 23:49:15 INFO Epoch 4: [1354/10940] ---- BYOL Training Loss = 0.18404966592788696
30-01-2023 23:49:33 INFO Epoch 4: [1365/10940] ---- BYOL Training Loss = 0.25921693444252014
30-01-2023 23:50:26 INFO Epoch 4: [1365/10940] ---- BYOL Validation Loss = 0.12284167110919952
30-01-2023 23:50:43 INFO Epoch 4: [1376/10940] ---- BYOL Training Loss = 0.25757789611816406
30-01-2023 23:51:01 INFO Epoch 4: [1387/10940] ---- BYOL Training Loss = 0.19899767637252808
30-01-2023 23:51:18 INFO Epoch 4: [1398/10940] ---- BYOL Training Loss = 0.24284768104553223
30-01-2023 23:51:36 INFO Epoch 4: [1409/10940] ---- BYOL Training Loss = 0.22603242099285126
30-01-2023 23:52:28 INFO Epoch 4: [1409/10940] ---- BYOL Validation Loss = 0.21871577203273773
30-01-2023 23:52:46 INFO Epoch 4: [1420/10940] ---- BYOL Training Loss = 0.21485953032970428
30-01-2023 23:53:03 INFO Epoch 4: [1431/10940] ---- BYOL Training Loss = 0.2501201629638672
30-01-2023 23:53:21 INFO Epoch 4: [1442/10940] ---- BYOL Training Loss = 0.21615934371948242
30-01-2023 23:53:38 INFO Epoch 4: [1453/10940] ---- BYOL Training Loss = 0.20149950683116913
30-01-2023 23:54:31 INFO Epoch 4: [1453/10940] ---- BYOL Validation Loss = 0.19146527349948883
30-01-2023 23:54:48 INFO Epoch 4: [1464/10940] ---- BYOL Training Loss = 0.21884945034980774
30-01-2023 23:55:06 INFO Epoch 4: [1475/10940] ---- BYOL Training Loss = 0.17668262124061584
30-01-2023 23:55:24 INFO Epoch 4: [1486/10940] ---- BYOL Training Loss = 0.19967682659626007
30-01-2023 23:55:41 INFO Epoch 4: [1497/10940] ---- BYOL Training Loss = 0.20795801281929016
30-01-2023 23:56:34 INFO Epoch 4: [1497/10940] ---- BYOL Validation Loss = 0.23285606503486633
30-01-2023 23:56:51 INFO Epoch 4: [1508/10940] ---- BYOL Training Loss = 0.2696402668952942
30-01-2023 23:57:09 INFO Epoch 4: [1519/10940] ---- BYOL Training Loss = 0.23443475365638733
30-01-2023 23:57:26 INFO Epoch 4: [1530/10940] ---- BYOL Training Loss = 0.18752668797969818
30-01-2023 23:57:44 INFO Epoch 4: [1541/10940] ---- BYOL Training Loss = 0.2358156442642212
30-01-2023 23:58:37 INFO Epoch 4: [1541/10940] ---- BYOL Validation Loss = 0.2389799803495407
30-01-2023 23:58:54 INFO Epoch 4: [1552/10940] ---- BYOL Training Loss = 0.21628907322883606
30-01-2023 23:59:12 INFO Epoch 4: [1563/10940] ---- BYOL Training Loss = 0.22883224487304688
30-01-2023 23:59:29 INFO Epoch 4: [1574/10940] ---- BYOL Training Loss = 0.269662082195282
30-01-2023 23:59:47 INFO Epoch 4: [1585/10940] ---- BYOL Training Loss = 0.237928107380867
31-01-2023 00:00:40 INFO Epoch 4: [1585/10940] ---- BYOL Validation Loss = 0.17225751280784607
31-01-2023 00:00:57 INFO Epoch 4: [1596/10940] ---- BYOL Training Loss = 0.2100348025560379
31-01-2023 00:01:14 INFO Epoch 4: [1607/10940] ---- BYOL Training Loss = 0.1974857747554779
31-01-2023 00:01:32 INFO Epoch 4: [1618/10940] ---- BYOL Training Loss = 0.29947414994239807
31-01-2023 00:01:49 INFO Epoch 4: [1629/10940] ---- BYOL Training Loss = 0.28606265783309937
31-01-2023 00:02:42 INFO Epoch 4: [1629/10940] ---- BYOL Validation Loss = 0.173410102725029
31-01-2023 00:02:59 INFO Epoch 4: [1640/10940] ---- BYOL Training Loss = 0.2008313238620758
31-01-2023 00:03:17 INFO Epoch 4: [1651/10940] ---- BYOL Training Loss = 0.3845059275627136
31-01-2023 00:03:34 INFO Epoch 4: [1662/10940] ---- BYOL Training Loss = 0.25111985206604004
31-01-2023 00:03:53 INFO Epoch 4: [1673/10940] ---- BYOL Training Loss = 0.20432701706886292
31-01-2023 00:04:45 INFO Epoch 4: [1673/10940] ---- BYOL Validation Loss = 0.18671253323554993
31-01-2023 00:05:03 INFO Epoch 4: [1684/10940] ---- BYOL Training Loss = 0.24397003650665283
31-01-2023 00:05:20 INFO Epoch 4: [1695/10940] ---- BYOL Training Loss = 0.23378121852874756
31-01-2023 00:05:38 INFO Epoch 4: [1706/10940] ---- BYOL Training Loss = 0.24345502257347107
31-01-2023 00:05:55 INFO Epoch 4: [1717/10940] ---- BYOL Training Loss = 0.29236194491386414
31-01-2023 00:06:48 INFO Epoch 4: [1717/10940] ---- BYOL Validation Loss = 0.19166789948940277
31-01-2023 00:07:05 INFO Epoch 4: [1728/10940] ---- BYOL Training Loss = 0.2610246241092682
31-01-2023 00:07:23 INFO Epoch 4: [1739/10940] ---- BYOL Training Loss = 0.21260222792625427
31-01-2023 00:07:41 INFO Epoch 4: [1750/10940] ---- BYOL Training Loss = 0.21726533770561218
31-01-2023 00:07:58 INFO Epoch 4: [1761/10940] ---- BYOL Training Loss = 0.24082712829113007
31-01-2023 00:08:51 INFO Epoch 4: [1761/10940] ---- BYOL Validation Loss = 0.14495012164115906
31-01-2023 00:09:08 INFO Epoch 4: [1772/10940] ---- BYOL Training Loss = 0.2227623015642166
31-01-2023 00:09:25 INFO Epoch 4: [1783/10940] ---- BYOL Training Loss = 0.22874851524829865
31-01-2023 00:09:43 INFO Epoch 4: [1794/10940] ---- BYOL Training Loss = 0.20039597153663635
31-01-2023 00:10:01 INFO Epoch 4: [1805/10940] ---- BYOL Training Loss = 0.18615931272506714
31-01-2023 00:10:53 INFO Epoch 4: [1805/10940] ---- BYOL Validation Loss = 0.19260798394680023
31-01-2023 00:11:11 INFO Epoch 4: [1816/10940] ---- BYOL Training Loss = 0.15970513224601746
31-01-2023 00:11:28 INFO Epoch 4: [1827/10940] ---- BYOL Training Loss = 0.1801632046699524
31-01-2023 00:11:46 INFO Epoch 4: [1838/10940] ---- BYOL Training Loss = 0.21273589134216309
31-01-2023 00:12:03 INFO Epoch 4: [1849/10940] ---- BYOL Training Loss = 0.1926807016134262
31-01-2023 00:12:56 INFO Epoch 4: [1849/10940] ---- BYOL Validation Loss = 0.1723252534866333
31-01-2023 00:13:13 INFO Epoch 4: [1860/10940] ---- BYOL Training Loss = 0.19810113310813904
31-01-2023 00:13:31 INFO Epoch 4: [1871/10940] ---- BYOL Training Loss = 0.24102672934532166
31-01-2023 00:13:48 INFO Epoch 4: [1882/10940] ---- BYOL Training Loss = 0.24258653819561005
31-01-2023 00:14:06 INFO Epoch 4: [1893/10940] ---- BYOL Training Loss = 0.2533624768257141
31-01-2023 00:14:59 INFO Epoch 4: [1893/10940] ---- BYOL Validation Loss = 0.19984422624111176
31-01-2023 00:15:16 INFO Epoch 4: [1904/10940] ---- BYOL Training Loss = 0.2556566596031189
31-01-2023 00:15:33 INFO Epoch 4: [1915/10940] ---- BYOL Training Loss = 0.24693477153778076
31-01-2023 00:15:51 INFO Epoch 4: [1926/10940] ---- BYOL Training Loss = 0.21089310944080353
31-01-2023 00:16:08 INFO Epoch 4: [1937/10940] ---- BYOL Training Loss = 0.23598480224609375
31-01-2023 00:17:01 INFO Epoch 4: [1937/10940] ---- BYOL Validation Loss = 0.12612676620483398
31-01-2023 00:17:18 INFO Epoch 4: [1948/10940] ---- BYOL Training Loss = 0.24794796109199524
31-01-2023 00:17:36 INFO Epoch 4: [1959/10940] ---- BYOL Training Loss = 0.20949280261993408
31-01-2023 00:17:53 INFO Epoch 4: [1970/10940] ---- BYOL Training Loss = 0.22850275039672852
31-01-2023 00:18:11 INFO Epoch 4: [1981/10940] ---- BYOL Training Loss = 0.2528981566429138
31-01-2023 00:19:04 INFO Epoch 4: [1981/10940] ---- BYOL Validation Loss = 0.1729656606912613
31-01-2023 00:19:21 INFO Epoch 4: [1992/10940] ---- BYOL Training Loss = 0.24096259474754333
31-01-2023 00:19:38 INFO Epoch 4: [2003/10940] ---- BYOL Training Loss = 0.3357427716255188
31-01-2023 00:19:56 INFO Epoch 4: [2014/10940] ---- BYOL Training Loss = 0.3155038356781006
31-01-2023 00:20:13 INFO Epoch 4: [2025/10940] ---- BYOL Training Loss = 0.2619294822216034
31-01-2023 00:21:06 INFO Epoch 4: [2025/10940] ---- BYOL Validation Loss = 0.14799778163433075
31-01-2023 00:21:23 INFO Epoch 4: [2036/10940] ---- BYOL Training Loss = 0.24511396884918213
31-01-2023 00:21:41 INFO Epoch 4: [2047/10940] ---- BYOL Training Loss = 0.2519800364971161
31-01-2023 00:21:59 INFO Epoch 4: [2058/10940] ---- BYOL Training Loss = 0.2280234396457672
31-01-2023 00:22:16 INFO Epoch 4: [2069/10940] ---- BYOL Training Loss = 0.19516174495220184
31-01-2023 00:23:09 INFO Epoch 4: [2069/10940] ---- BYOL Validation Loss = 0.1748776137828827
31-01-2023 00:23:26 INFO Epoch 4: [2080/10940] ---- BYOL Training Loss = 0.1896596997976303
31-01-2023 00:23:44 INFO Epoch 4: [2091/10940] ---- BYOL Training Loss = 0.1645992547273636
31-01-2023 00:24:01 INFO Epoch 4: [2102/10940] ---- BYOL Training Loss = 0.21136252582073212
31-01-2023 00:24:19 INFO Epoch 4: [2113/10940] ---- BYOL Training Loss = 0.35500872135162354
31-01-2023 00:25:12 INFO Epoch 4: [2113/10940] ---- BYOL Validation Loss = 0.1720750480890274
31-01-2023 00:25:29 INFO Epoch 4: [2124/10940] ---- BYOL Training Loss = 0.34268999099731445
31-01-2023 00:25:47 INFO Epoch 4: [2135/10940] ---- BYOL Training Loss = 0.29451537132263184
31-01-2023 00:26:04 INFO Epoch 4: [2146/10940] ---- BYOL Training Loss = 0.25524500012397766
31-01-2023 00:26:22 INFO Epoch 4: [2157/10940] ---- BYOL Training Loss = 0.2156037539243698
31-01-2023 00:27:14 INFO Epoch 4: [2157/10940] ---- BYOL Validation Loss = 0.2104770690202713
31-01-2023 00:27:32 INFO Epoch 4: [2168/10940] ---- BYOL Training Loss = 0.30039921402931213
31-01-2023 00:27:49 INFO Epoch 4: [2179/10940] ---- BYOL Training Loss = 0.2813493311405182
31-01-2023 00:28:07 INFO Epoch 4: [2190/10940] ---- BYOL Training Loss = 0.20733311772346497
31-01-2023 00:28:25 INFO Epoch 4: [2201/10940] ---- BYOL Training Loss = 0.19996052980422974
31-01-2023 00:29:17 INFO Epoch 4: [2201/10940] ---- BYOL Validation Loss = 0.16293802857398987
31-01-2023 00:29:35 INFO Epoch 4: [2212/10940] ---- BYOL Training Loss = 0.2889464795589447
31-01-2023 00:29:52 INFO Epoch 4: [2223/10940] ---- BYOL Training Loss = 0.3343575894832611
31-01-2023 00:30:10 INFO Epoch 4: [2234/10940] ---- BYOL Training Loss = 0.24922005832195282
31-01-2023 00:30:27 INFO Epoch 4: [2245/10940] ---- BYOL Training Loss = 0.2341027557849884
31-01-2023 00:31:20 INFO Epoch 4: [2245/10940] ---- BYOL Validation Loss = 0.1985367089509964
31-01-2023 00:31:37 INFO Epoch 4: [2256/10940] ---- BYOL Training Loss = 0.26228567957878113
31-01-2023 00:31:55 INFO Epoch 4: [2267/10940] ---- BYOL Training Loss = 0.24703726172447205
31-01-2023 00:32:13 INFO Epoch 4: [2278/10940] ---- BYOL Training Loss = 0.21889202296733856
31-01-2023 00:32:30 INFO Epoch 4: [2289/10940] ---- BYOL Training Loss = 0.2161199301481247
31-01-2023 00:33:23 INFO Epoch 4: [2289/10940] ---- BYOL Validation Loss = 0.18202291429042816
31-01-2023 00:33:40 INFO Epoch 4: [2300/10940] ---- BYOL Training Loss = 0.20126661658287048
31-01-2023 00:33:58 INFO Epoch 4: [2311/10940] ---- BYOL Training Loss = 0.31102344393730164
31-01-2023 00:34:16 INFO Epoch 4: [2322/10940] ---- BYOL Training Loss = 0.26035699248313904
31-01-2023 00:34:33 INFO Epoch 4: [2333/10940] ---- BYOL Training Loss = 0.23002156615257263
31-01-2023 00:35:26 INFO Epoch 4: [2333/10940] ---- BYOL Validation Loss = 0.18855039775371552
31-01-2023 00:35:43 INFO Epoch 4: [2344/10940] ---- BYOL Training Loss = 0.2375410795211792
31-01-2023 00:36:01 INFO Epoch 4: [2355/10940] ---- BYOL Training Loss = 0.19269131124019623
31-01-2023 00:36:18 INFO Epoch 4: [2366/10940] ---- BYOL Training Loss = 0.2041209638118744
31-01-2023 00:36:36 INFO Epoch 4: [2377/10940] ---- BYOL Training Loss = 0.2845630645751953
31-01-2023 00:37:29 INFO Epoch 4: [2377/10940] ---- BYOL Validation Loss = 0.211455300450325
31-01-2023 00:37:46 INFO Epoch 4: [2388/10940] ---- BYOL Training Loss = 0.26330944895744324
31-01-2023 00:38:03 INFO Epoch 4: [2399/10940] ---- BYOL Training Loss = 0.16927668452262878
31-01-2023 00:38:21 INFO Epoch 4: [2410/10940] ---- BYOL Training Loss = 0.1757977455854416
31-01-2023 00:38:39 INFO Epoch 4: [2421/10940] ---- BYOL Training Loss = 0.19747743010520935
31-01-2023 00:39:32 INFO Epoch 4: [2421/10940] ---- BYOL Validation Loss = 0.2104865461587906
31-01-2023 00:39:49 INFO Epoch 4: [2432/10940] ---- BYOL Training Loss = 0.21685893833637238
31-01-2023 00:40:07 INFO Epoch 4: [2443/10940] ---- BYOL Training Loss = 0.31708329916000366
31-01-2023 00:40:24 INFO Epoch 4: [2454/10940] ---- BYOL Training Loss = 0.28585827350616455
31-01-2023 00:40:42 INFO Epoch 4: [2465/10940] ---- BYOL Training Loss = 0.17015163600444794
31-01-2023 00:41:35 INFO Epoch 4: [2465/10940] ---- BYOL Validation Loss = 0.1510208398103714
31-01-2023 00:41:52 INFO Epoch 4: [2476/10940] ---- BYOL Training Loss = 0.2862953841686249
31-01-2023 00:42:10 INFO Epoch 4: [2487/10940] ---- BYOL Training Loss = 0.21129611134529114
31-01-2023 00:42:27 INFO Epoch 4: [2498/10940] ---- BYOL Training Loss = 0.23314335942268372
31-01-2023 00:42:45 INFO Epoch 4: [2509/10940] ---- BYOL Training Loss = 0.22115866839885712
31-01-2023 00:43:37 INFO Epoch 4: [2509/10940] ---- BYOL Validation Loss = 0.1849246472120285
31-01-2023 00:43:55 INFO Epoch 4: [2520/10940] ---- BYOL Training Loss = 0.2146189957857132
31-01-2023 00:44:12 INFO Epoch 4: [2531/10940] ---- BYOL Training Loss = 0.2236052006483078
31-01-2023 00:44:30 INFO Epoch 4: [2542/10940] ---- BYOL Training Loss = 0.2619701325893402
31-01-2023 00:44:48 INFO Epoch 4: [2553/10940] ---- BYOL Training Loss = 0.2668147385120392
31-01-2023 00:45:40 INFO Epoch 4: [2553/10940] ---- BYOL Validation Loss = 0.21139204502105713
31-01-2023 00:45:58 INFO Epoch 4: [2564/10940] ---- BYOL Training Loss = 0.23640494048595428
31-01-2023 00:46:15 INFO Epoch 4: [2575/10940] ---- BYOL Training Loss = 0.20940735936164856
31-01-2023 00:46:33 INFO Epoch 4: [2586/10940] ---- BYOL Training Loss = 0.20756784081459045
31-01-2023 00:46:51 INFO Epoch 4: [2597/10940] ---- BYOL Training Loss = 0.22801165282726288
31-01-2023 00:47:44 INFO Epoch 4: [2597/10940] ---- BYOL Validation Loss = 0.15333867073059082
31-01-2023 00:48:01 INFO Epoch 4: [2608/10940] ---- BYOL Training Loss = 0.2159326821565628
31-01-2023 00:48:19 INFO Epoch 4: [2619/10940] ---- BYOL Training Loss = 0.2206704169511795
31-01-2023 00:48:36 INFO Epoch 4: [2630/10940] ---- BYOL Training Loss = 0.23822703957557678
31-01-2023 00:48:54 INFO Epoch 4: [2641/10940] ---- BYOL Training Loss = 0.23864701390266418
31-01-2023 00:49:46 INFO Epoch 4: [2641/10940] ---- BYOL Validation Loss = 0.2132323980331421
31-01-2023 00:50:04 INFO Epoch 4: [2652/10940] ---- BYOL Training Loss = 0.2725368142127991
31-01-2023 00:50:21 INFO Epoch 4: [2663/10940] ---- BYOL Training Loss = 0.22571465373039246
31-01-2023 00:50:39 INFO Epoch 4: [2674/10940] ---- BYOL Training Loss = 0.2366258203983307
31-01-2023 00:50:57 INFO Epoch 4: [2685/10940] ---- BYOL Training Loss = 0.23908844590187073
31-01-2023 00:51:49 INFO Epoch 4: [2685/10940] ---- BYOL Validation Loss = 0.18534240126609802
31-01-2023 00:52:07 INFO Epoch 4: [2696/10940] ---- BYOL Training Loss = 0.1949487328529358
31-01-2023 00:52:25 INFO Epoch 4: [2707/10940] ---- BYOL Training Loss = 0.24730460345745087
31-01-2023 00:52:42 INFO Epoch 4: [2718/10940] ---- BYOL Training Loss = 0.2696111500263214
31-01-2023 00:53:00 INFO Epoch 4: [2729/10940] ---- BYOL Training Loss = 0.28234487771987915
31-01-2023 00:53:53 INFO Epoch 4: [2729/10940] ---- BYOL Validation Loss = 0.21910513937473297
31-01-2023 00:54:10 INFO Epoch 4: [2740/10940] ---- BYOL Training Loss = 0.23204848170280457
31-01-2023 00:54:28 INFO Epoch 4: [2751/10940] ---- BYOL Training Loss = 0.1620602309703827
31-01-2023 00:54:46 INFO Epoch 4: [2762/10940] ---- BYOL Training Loss = 0.17361736297607422
31-01-2023 00:55:03 INFO Epoch 4: [2773/10940] ---- BYOL Training Loss = 0.20781831443309784
31-01-2023 00:55:56 INFO Epoch 4: [2773/10940] ---- BYOL Validation Loss = 0.2290932983160019
31-01-2023 00:56:13 INFO Epoch 4: [2784/10940] ---- BYOL Training Loss = 0.20752301812171936
31-01-2023 00:56:31 INFO Epoch 4: [2795/10940] ---- BYOL Training Loss = 0.2627964913845062
31-01-2023 00:56:49 INFO Epoch 4: [2806/10940] ---- BYOL Training Loss = 0.31507939100265503
31-01-2023 00:57:07 INFO Epoch 4: [2817/10940] ---- BYOL Training Loss = 0.2432766854763031
31-01-2023 00:57:59 INFO Epoch 4: [2817/10940] ---- BYOL Validation Loss = 0.1825619786977768
31-01-2023 00:58:16 INFO Epoch 4: [2828/10940] ---- BYOL Training Loss = 0.17083077132701874
31-01-2023 00:58:34 INFO Epoch 4: [2839/10940] ---- BYOL Training Loss = 0.1909080296754837
31-01-2023 00:58:52 INFO Epoch 4: [2850/10940] ---- BYOL Training Loss = 0.18526099622249603
31-01-2023 00:59:09 INFO Epoch 4: [2861/10940] ---- BYOL Training Loss = 0.23812003433704376
31-01-2023 01:00:02 INFO Epoch 4: [2861/10940] ---- BYOL Validation Loss = 0.15202714502811432
31-01-2023 01:00:20 INFO Epoch 4: [2872/10940] ---- BYOL Training Loss = 0.22225885093212128
31-01-2023 01:00:37 INFO Epoch 4: [2883/10940] ---- BYOL Training Loss = 0.21759621798992157
31-01-2023 01:00:55 INFO Epoch 4: [2894/10940] ---- BYOL Training Loss = 0.22503840923309326
31-01-2023 01:01:13 INFO Epoch 4: [2905/10940] ---- BYOL Training Loss = 0.22458848357200623
31-01-2023 01:02:06 INFO Epoch 4: [2905/10940] ---- BYOL Validation Loss = 0.21781595051288605
31-01-2023 01:02:23 INFO Epoch 4: [2916/10940] ---- BYOL Training Loss = 0.21784958243370056
31-01-2023 01:02:41 INFO Epoch 4: [2927/10940] ---- BYOL Training Loss = 0.19434811174869537
31-01-2023 01:02:58 INFO Epoch 4: [2938/10940] ---- BYOL Training Loss = 0.24080514907836914
31-01-2023 01:03:16 INFO Epoch 4: [2949/10940] ---- BYOL Training Loss = 0.2099875509738922
31-01-2023 01:04:09 INFO Epoch 4: [2949/10940] ---- BYOL Validation Loss = 0.10774220526218414
31-01-2023 01:04:26 INFO Epoch 4: [2960/10940] ---- BYOL Training Loss = 0.16675636172294617
31-01-2023 01:04:44 INFO Epoch 4: [2971/10940] ---- BYOL Training Loss = 0.17875254154205322
31-01-2023 01:05:01 INFO Epoch 4: [2982/10940] ---- BYOL Training Loss = 0.19788488745689392
31-01-2023 01:05:20 INFO Epoch 4: [2993/10940] ---- BYOL Training Loss = 0.21599802374839783
31-01-2023 01:06:12 INFO Epoch 4: [2993/10940] ---- BYOL Validation Loss = 0.19015635550022125
31-01-2023 01:06:30 INFO Epoch 4: [3004/10940] ---- BYOL Training Loss = 0.2957105338573456
31-01-2023 01:06:47 INFO Epoch 4: [3015/10940] ---- BYOL Training Loss = 0.32837215065956116
31-01-2023 01:07:05 INFO Epoch 4: [3026/10940] ---- BYOL Training Loss = 0.23209825158119202
31-01-2023 01:07:22 INFO Epoch 4: [3037/10940] ---- BYOL Training Loss = 0.22333016991615295
31-01-2023 01:08:15 INFO Epoch 4: [3037/10940] ---- BYOL Validation Loss = 0.22372253239154816
31-01-2023 01:08:32 INFO Epoch 4: [3048/10940] ---- BYOL Training Loss = 0.28854042291641235
31-01-2023 01:08:50 INFO Epoch 4: [3059/10940] ---- BYOL Training Loss = 0.2108624279499054
31-01-2023 01:09:08 INFO Epoch 4: [3070/10940] ---- BYOL Training Loss = 0.21719172596931458
31-01-2023 01:09:26 INFO Epoch 4: [3081/10940] ---- BYOL Training Loss = 0.2528330683708191
31-01-2023 01:10:18 INFO Epoch 4: [3081/10940] ---- BYOL Validation Loss = 0.1912534385919571
31-01-2023 01:10:36 INFO Epoch 4: [3092/10940] ---- BYOL Training Loss = 0.25416988134384155
31-01-2023 01:10:54 INFO Epoch 4: [3103/10940] ---- BYOL Training Loss = 0.1800491064786911
31-01-2023 01:11:12 INFO Epoch 4: [3114/10940] ---- BYOL Training Loss = 0.13839676976203918
31-01-2023 01:11:30 INFO Epoch 4: [3125/10940] ---- BYOL Training Loss = 0.240418940782547
31-01-2023 01:12:22 INFO Epoch 4: [3125/10940] ---- BYOL Validation Loss = 0.18142271041870117
31-01-2023 01:12:40 INFO Epoch 4: [3136/10940] ---- BYOL Training Loss = 0.2679578959941864
31-01-2023 01:12:57 INFO Epoch 4: [3147/10940] ---- BYOL Training Loss = 0.23626697063446045
31-01-2023 01:13:15 INFO Epoch 4: [3158/10940] ---- BYOL Training Loss = 0.23722119629383087
31-01-2023 01:13:33 INFO Epoch 4: [3169/10940] ---- BYOL Training Loss = 0.20053589344024658
31-01-2023 01:14:25 INFO Epoch 4: [3169/10940] ---- BYOL Validation Loss = 0.2341504842042923
31-01-2023 01:14:43 INFO Epoch 4: [3180/10940] ---- BYOL Training Loss = 0.24508650600910187
31-01-2023 01:15:01 INFO Epoch 4: [3191/10940] ---- BYOL Training Loss = 0.2661353349685669
31-01-2023 01:15:19 INFO Epoch 4: [3202/10940] ---- BYOL Training Loss = 0.2297222912311554
31-01-2023 01:15:36 INFO Epoch 4: [3213/10940] ---- BYOL Training Loss = 0.2071414440870285
31-01-2023 01:16:29 INFO Epoch 4: [3213/10940] ---- BYOL Validation Loss = 0.19239377975463867
31-01-2023 01:16:46 INFO Epoch 4: [3224/10940] ---- BYOL Training Loss = 0.21348747611045837
31-01-2023 01:17:04 INFO Epoch 4: [3235/10940] ---- BYOL Training Loss = 0.1947418749332428
31-01-2023 01:17:21 INFO Epoch 4: [3246/10940] ---- BYOL Training Loss = 0.25389623641967773
31-01-2023 01:17:39 INFO Epoch 4: [3257/10940] ---- BYOL Training Loss = 0.29939860105514526
31-01-2023 01:18:32 INFO Epoch 4: [3257/10940] ---- BYOL Validation Loss = 0.23167181015014648
31-01-2023 01:18:49 INFO Epoch 4: [3268/10940] ---- BYOL Training Loss = 0.2370927780866623
31-01-2023 01:19:07 INFO Epoch 4: [3279/10940] ---- BYOL Training Loss = 0.26410236954689026
31-01-2023 01:19:25 INFO Epoch 4: [3290/10940] ---- BYOL Training Loss = 0.2825027406215668
31-01-2023 01:19:43 INFO Epoch 4: [3301/10940] ---- BYOL Training Loss = 0.2216046303510666
31-01-2023 01:20:35 INFO Epoch 4: [3301/10940] ---- BYOL Validation Loss = 0.14843715727329254
31-01-2023 01:20:53 INFO Epoch 4: [3312/10940] ---- BYOL Training Loss = 0.20839664340019226
31-01-2023 01:21:10 INFO Epoch 4: [3323/10940] ---- BYOL Training Loss = 0.33316749334335327
31-01-2023 01:21:28 INFO Epoch 4: [3334/10940] ---- BYOL Training Loss = 0.3430408239364624
31-01-2023 01:21:46 INFO Epoch 4: [3345/10940] ---- BYOL Training Loss = 0.20866863429546356
31-01-2023 01:22:39 INFO Epoch 4: [3345/10940] ---- BYOL Validation Loss = 0.1820783168077469
31-01-2023 01:22:56 INFO Epoch 4: [3356/10940] ---- BYOL Training Loss = 0.23742182552814484
31-01-2023 01:23:14 INFO Epoch 4: [3367/10940] ---- BYOL Training Loss = 0.2405371218919754
31-01-2023 01:23:32 INFO Epoch 4: [3378/10940] ---- BYOL Training Loss = 0.21423737704753876
31-01-2023 01:23:49 INFO Epoch 4: [3389/10940] ---- BYOL Training Loss = 0.18193867802619934
31-01-2023 01:24:42 INFO Epoch 4: [3389/10940] ---- BYOL Validation Loss = 0.10177581757307053
31-01-2023 01:24:59 INFO Epoch 4: [3400/10940] ---- BYOL Training Loss = 0.2049529254436493
31-01-2023 01:25:17 INFO Epoch 4: [3411/10940] ---- BYOL Training Loss = 0.2280803620815277
31-01-2023 01:25:35 INFO Epoch 4: [3422/10940] ---- BYOL Training Loss = 0.24708068370819092
31-01-2023 01:25:53 INFO Epoch 4: [3433/10940] ---- BYOL Training Loss = 0.21957381069660187
31-01-2023 01:26:46 INFO Epoch 4: [3433/10940] ---- BYOL Validation Loss = 0.1347018927335739
31-01-2023 01:27:03 INFO Epoch 4: [3444/10940] ---- BYOL Training Loss = 0.21732158958911896
31-01-2023 01:27:21 INFO Epoch 4: [3455/10940] ---- BYOL Training Loss = 0.24767597019672394
31-01-2023 01:27:38 INFO Epoch 4: [3466/10940] ---- BYOL Training Loss = 0.22531840205192566
31-01-2023 01:27:56 INFO Epoch 4: [3477/10940] ---- BYOL Training Loss = 0.2636200785636902
31-01-2023 01:28:49 INFO Epoch 4: [3477/10940] ---- BYOL Validation Loss = 0.17768366634845734
31-01-2023 01:29:07 INFO Epoch 4: [3488/10940] ---- BYOL Training Loss = 0.24878057837486267
31-01-2023 01:29:25 INFO Epoch 4: [3499/10940] ---- BYOL Training Loss = 0.24107725918293
31-01-2023 01:29:43 INFO Epoch 4: [3510/10940] ---- BYOL Training Loss = 0.23525211215019226
31-01-2023 01:30:00 INFO Epoch 4: [3521/10940] ---- BYOL Training Loss = 0.21595653891563416
31-01-2023 01:30:53 INFO Epoch 4: [3521/10940] ---- BYOL Validation Loss = 0.20864620804786682
31-01-2023 01:31:10 INFO Epoch 4: [3532/10940] ---- BYOL Training Loss = 0.21013662219047546
31-01-2023 01:31:28 INFO Epoch 4: [3543/10940] ---- BYOL Training Loss = 0.31260618567466736
31-01-2023 01:31:46 INFO Epoch 4: [3554/10940] ---- BYOL Training Loss = 0.23461946845054626
31-01-2023 01:32:03 INFO Epoch 4: [3565/10940] ---- BYOL Training Loss = 0.20185056328773499
31-01-2023 01:32:56 INFO Epoch 4: [3565/10940] ---- BYOL Validation Loss = 0.23115751147270203
31-01-2023 01:33:14 INFO Epoch 4: [3576/10940] ---- BYOL Training Loss = 0.2041660100221634
31-01-2023 01:33:32 INFO Epoch 4: [3587/10940] ---- BYOL Training Loss = 0.19646500051021576
31-01-2023 01:33:49 INFO Epoch 4: [3598/10940] ---- BYOL Training Loss = 0.21514162421226501
31-01-2023 01:34:07 INFO Epoch 4: [3609/10940] ---- BYOL Training Loss = 0.2322746217250824
31-01-2023 01:35:00 INFO Epoch 4: [3609/10940] ---- BYOL Validation Loss = 0.18068817257881165
31-01-2023 01:35:17 INFO Epoch 4: [3620/10940] ---- BYOL Training Loss = 0.2583271563053131
31-01-2023 01:35:35 INFO Epoch 4: [3631/10940] ---- BYOL Training Loss = 0.25536003708839417
31-01-2023 01:35:53 INFO Epoch 4: [3642/10940] ---- BYOL Training Loss = 0.2253684103488922
31-01-2023 01:36:11 INFO Epoch 4: [3653/10940] ---- BYOL Training Loss = 0.22070343792438507
31-01-2023 01:37:04 INFO Epoch 4: [3653/10940] ---- BYOL Validation Loss = 0.15643468499183655
31-01-2023 01:37:21 INFO Epoch 4: [3664/10940] ---- BYOL Training Loss = 0.21800848841667175
31-01-2023 01:37:39 INFO Epoch 4: [3675/10940] ---- BYOL Training Loss = 0.1989389806985855
31-01-2023 01:37:57 INFO Epoch 4: [3686/10940] ---- BYOL Training Loss = 0.23285984992980957
31-01-2023 01:38:15 INFO Epoch 4: [3697/10940] ---- BYOL Training Loss = 0.24635839462280273
31-01-2023 01:39:08 INFO Epoch 4: [3697/10940] ---- BYOL Validation Loss = 0.1897677332162857
31-01-2023 01:39:25 INFO Epoch 4: [3708/10940] ---- BYOL Training Loss = 0.24935424327850342
31-01-2023 01:39:43 INFO Epoch 4: [3719/10940] ---- BYOL Training Loss = 0.21090123057365417
31-01-2023 01:40:01 INFO Epoch 4: [3730/10940] ---- BYOL Training Loss = 0.20533601939678192
31-01-2023 01:40:19 INFO Epoch 4: [3741/10940] ---- BYOL Training Loss = 0.21394649147987366
31-01-2023 01:41:11 INFO Epoch 4: [3741/10940] ---- BYOL Validation Loss = 0.21578571200370789
31-01-2023 01:41:29 INFO Epoch 4: [3752/10940] ---- BYOL Training Loss = 0.2324303686618805
31-01-2023 01:41:47 INFO Epoch 4: [3763/10940] ---- BYOL Training Loss = 0.24644121527671814
31-01-2023 01:42:05 INFO Epoch 4: [3774/10940] ---- BYOL Training Loss = 0.1940409243106842
31-01-2023 01:42:22 INFO Epoch 4: [3785/10940] ---- BYOL Training Loss = 0.2219613492488861
31-01-2023 01:43:15 INFO Epoch 4: [3785/10940] ---- BYOL Validation Loss = 0.19861389696598053
31-01-2023 01:43:33 INFO Epoch 4: [3796/10940] ---- BYOL Training Loss = 0.2967083752155304
31-01-2023 01:43:51 INFO Epoch 4: [3807/10940] ---- BYOL Training Loss = 0.32202860713005066
31-01-2023 01:44:08 INFO Epoch 4: [3818/10940] ---- BYOL Training Loss = 0.2496928721666336
31-01-2023 01:44:26 INFO Epoch 4: [3829/10940] ---- BYOL Training Loss = 0.2285953313112259
31-01-2023 01:45:19 INFO Epoch 4: [3829/10940] ---- BYOL Validation Loss = 0.23757751286029816
31-01-2023 01:45:37 INFO Epoch 4: [3840/10940] ---- BYOL Training Loss = 0.21385879814624786
31-01-2023 01:45:55 INFO Epoch 4: [3851/10940] ---- BYOL Training Loss = 0.2132761925458908
31-01-2023 01:46:13 INFO Epoch 4: [3862/10940] ---- BYOL Training Loss = 0.2724483907222748
31-01-2023 01:46:30 INFO Epoch 4: [3873/10940] ---- BYOL Training Loss = 0.29462337493896484
31-01-2023 01:47:23 INFO Epoch 4: [3873/10940] ---- BYOL Validation Loss = 0.24438275396823883
31-01-2023 01:47:40 INFO Epoch 4: [3884/10940] ---- BYOL Training Loss = 0.34243589639663696
31-01-2023 01:47:58 INFO Epoch 4: [3895/10940] ---- BYOL Training Loss = 0.26260849833488464
31-01-2023 01:48:16 INFO Epoch 4: [3906/10940] ---- BYOL Training Loss = 0.2026294767856598
31-01-2023 01:48:34 INFO Epoch 4: [3917/10940] ---- BYOL Training Loss = 0.32429277896881104
31-01-2023 01:49:27 INFO Epoch 4: [3917/10940] ---- BYOL Validation Loss = 0.16393303871154785
31-01-2023 01:49:45 INFO Epoch 4: [3928/10940] ---- BYOL Training Loss = 0.3332432210445404
31-01-2023 01:50:02 INFO Epoch 4: [3939/10940] ---- BYOL Training Loss = 0.2861174941062927
31-01-2023 01:50:20 INFO Epoch 4: [3950/10940] ---- BYOL Training Loss = 0.29955920577049255
31-01-2023 01:50:38 INFO Epoch 4: [3961/10940] ---- BYOL Training Loss = 0.25815820693969727
31-01-2023 01:51:31 INFO Epoch 4: [3961/10940] ---- BYOL Validation Loss = 0.20204409956932068
31-01-2023 01:51:48 INFO Epoch 4: [3972/10940] ---- BYOL Training Loss = 0.18550123274326324
31-01-2023 01:52:06 INFO Epoch 4: [3983/10940] ---- BYOL Training Loss = 0.2023942768573761
31-01-2023 01:52:24 INFO Epoch 4: [3994/10940] ---- BYOL Training Loss = 0.25501030683517456
31-01-2023 01:52:42 INFO Epoch 4: [4005/10940] ---- BYOL Training Loss = 0.23007747530937195
31-01-2023 01:53:35 INFO Epoch 4: [4005/10940] ---- BYOL Validation Loss = 0.20811091363430023
31-01-2023 01:53:52 INFO Epoch 4: [4016/10940] ---- BYOL Training Loss = 0.20324957370758057
31-01-2023 01:54:10 INFO Epoch 4: [4027/10940] ---- BYOL Training Loss = 0.24045705795288086
31-01-2023 01:54:28 INFO Epoch 4: [4038/10940] ---- BYOL Training Loss = 0.2854050099849701
31-01-2023 01:54:46 INFO Epoch 4: [4049/10940] ---- BYOL Training Loss = 0.2674991488456726
31-01-2023 01:55:39 INFO Epoch 4: [4049/10940] ---- BYOL Validation Loss = 0.13333375751972198
31-01-2023 01:55:56 INFO Epoch 4: [4060/10940] ---- BYOL Training Loss = 0.17319180071353912
31-01-2023 01:56:14 INFO Epoch 4: [4071/10940] ---- BYOL Training Loss = 0.20352105796337128
31-01-2023 01:56:32 INFO Epoch 4: [4082/10940] ---- BYOL Training Loss = 0.241158127784729
31-01-2023 01:56:50 INFO Epoch 4: [4093/10940] ---- BYOL Training Loss = 0.2629622519016266
31-01-2023 01:57:42 INFO Epoch 4: [4093/10940] ---- BYOL Validation Loss = 0.2018740028142929
31-01-2023 01:58:00 INFO Epoch 4: [4104/10940] ---- BYOL Training Loss = 0.24658700823783875
31-01-2023 01:58:18 INFO Epoch 4: [4115/10940] ---- BYOL Training Loss = 0.21012994647026062
31-01-2023 01:58:36 INFO Epoch 4: [4126/10940] ---- BYOL Training Loss = 0.20411574840545654
31-01-2023 01:58:54 INFO Epoch 4: [4137/10940] ---- BYOL Training Loss = 0.21891477704048157
31-01-2023 01:59:47 INFO Epoch 4: [4137/10940] ---- BYOL Validation Loss = 0.1947317123413086
31-01-2023 02:00:04 INFO Epoch 4: [4148/10940] ---- BYOL Training Loss = 0.19707044959068298
31-01-2023 02:00:22 INFO Epoch 4: [4159/10940] ---- BYOL Training Loss = 0.1643040031194687
31-01-2023 02:00:40 INFO Epoch 4: [4170/10940] ---- BYOL Training Loss = 0.21337223052978516
31-01-2023 02:00:57 INFO Epoch 4: [4181/10940] ---- BYOL Training Loss = 0.24958941340446472
31-01-2023 02:01:50 INFO Epoch 4: [4181/10940] ---- BYOL Validation Loss = 0.23648007214069366
31-01-2023 02:02:08 INFO Epoch 4: [4192/10940] ---- BYOL Training Loss = 0.24968221783638
31-01-2023 02:02:26 INFO Epoch 4: [4203/10940] ---- BYOL Training Loss = 0.2232029139995575
31-01-2023 02:02:44 INFO Epoch 4: [4214/10940] ---- BYOL Training Loss = 0.2602704167366028
31-01-2023 02:03:02 INFO Epoch 4: [4225/10940] ---- BYOL Training Loss = 0.2870714068412781
31-01-2023 02:03:55 INFO Epoch 4: [4225/10940] ---- BYOL Validation Loss = 0.23803262412548065
31-01-2023 02:04:12 INFO Epoch 4: [4236/10940] ---- BYOL Training Loss = 0.26144009828567505
31-01-2023 02:04:30 INFO Epoch 4: [4247/10940] ---- BYOL Training Loss = 0.20236900448799133
31-01-2023 02:04:48 INFO Epoch 4: [4258/10940] ---- BYOL Training Loss = 0.24186833202838898
31-01-2023 02:05:06 INFO Epoch 4: [4269/10940] ---- BYOL Training Loss = 0.3308117687702179
31-01-2023 02:05:59 INFO Epoch 4: [4269/10940] ---- BYOL Validation Loss = 0.2566172480583191
31-01-2023 02:06:17 INFO Epoch 4: [4280/10940] ---- BYOL Training Loss = 0.24889162182807922
31-01-2023 02:06:34 INFO Epoch 4: [4291/10940] ---- BYOL Training Loss = 0.19957736134529114
31-01-2023 02:06:52 INFO Epoch 4: [4302/10940] ---- BYOL Training Loss = 0.21326076984405518
31-01-2023 02:07:10 INFO Epoch 4: [4313/10940] ---- BYOL Training Loss = 0.28661149740219116
31-01-2023 02:08:03 INFO Epoch 4: [4313/10940] ---- BYOL Validation Loss = 0.24516534805297852
31-01-2023 02:08:21 INFO Epoch 4: [4324/10940] ---- BYOL Training Loss = 0.25386154651641846
31-01-2023 02:08:39 INFO Epoch 4: [4335/10940] ---- BYOL Training Loss = 0.23345966637134552
31-01-2023 02:08:56 INFO Epoch 4: [4346/10940] ---- BYOL Training Loss = 0.21095117926597595
31-01-2023 02:09:14 INFO Epoch 4: [4357/10940] ---- BYOL Training Loss = 0.1815798133611679
31-01-2023 02:10:07 INFO Epoch 4: [4357/10940] ---- BYOL Validation Loss = 0.17819617688655853
31-01-2023 02:10:24 INFO Epoch 4: [4368/10940] ---- BYOL Training Loss = 0.2071075439453125
31-01-2023 02:10:43 INFO Epoch 4: [4379/10940] ---- BYOL Training Loss = 0.2458384484052658
31-01-2023 02:11:01 INFO Epoch 4: [4390/10940] ---- BYOL Training Loss = 0.17428401112556458
31-01-2023 02:11:18 INFO Epoch 4: [4401/10940] ---- BYOL Training Loss = 0.19640731811523438
31-01-2023 02:12:11 INFO Epoch 4: [4401/10940] ---- BYOL Validation Loss = 0.22897179424762726
31-01-2023 02:12:29 INFO Epoch 4: [4412/10940] ---- BYOL Training Loss = 0.22864560782909393
31-01-2023 02:12:47 INFO Epoch 4: [4423/10940] ---- BYOL Training Loss = 0.24697387218475342
31-01-2023 02:13:05 INFO Epoch 4: [4434/10940] ---- BYOL Training Loss = 0.2408093959093094
31-01-2023 02:13:23 INFO Epoch 4: [4445/10940] ---- BYOL Training Loss = 0.26369020342826843
31-01-2023 02:14:15 INFO Epoch 4: [4445/10940] ---- BYOL Validation Loss = 0.2531229853630066
31-01-2023 02:14:33 INFO Epoch 4: [4456/10940] ---- BYOL Training Loss = 0.2360997498035431
31-01-2023 02:14:51 INFO Epoch 4: [4467/10940] ---- BYOL Training Loss = 0.19624099135398865
31-01-2023 02:15:09 INFO Epoch 4: [4478/10940] ---- BYOL Training Loss = 0.19543412327766418
31-01-2023 02:15:27 INFO Epoch 4: [4489/10940] ---- BYOL Training Loss = 0.26118287444114685
31-01-2023 02:16:19 INFO Epoch 4: [4489/10940] ---- BYOL Validation Loss = 0.23337581753730774
31-01-2023 02:16:37 INFO Epoch 4: [4500/10940] ---- BYOL Training Loss = 0.23552235960960388
31-01-2023 02:16:55 INFO Epoch 4: [4511/10940] ---- BYOL Training Loss = 0.25066298246383667
31-01-2023 02:17:13 INFO Epoch 4: [4522/10940] ---- BYOL Training Loss = 0.23608990013599396
31-01-2023 02:17:30 INFO Epoch 4: [4533/10940] ---- BYOL Training Loss = 0.21730387210845947
31-01-2023 02:18:23 INFO Epoch 4: [4533/10940] ---- BYOL Validation Loss = 0.2388763427734375
31-01-2023 02:18:41 INFO Epoch 4: [4544/10940] ---- BYOL Training Loss = 0.2851642072200775
31-01-2023 02:18:59 INFO Epoch 4: [4555/10940] ---- BYOL Training Loss = 0.2839851975440979
31-01-2023 02:19:17 INFO Epoch 4: [4566/10940] ---- BYOL Training Loss = 0.2661201059818268
31-01-2023 02:19:35 INFO Epoch 4: [4577/10940] ---- BYOL Training Loss = 0.2737964987754822
31-01-2023 02:20:28 INFO Epoch 4: [4577/10940] ---- BYOL Validation Loss = 0.25248509645462036
31-01-2023 02:20:45 INFO Epoch 4: [4588/10940] ---- BYOL Training Loss = 0.254546582698822
31-01-2023 02:21:03 INFO Epoch 4: [4599/10940] ---- BYOL Training Loss = 0.256556898355484
31-01-2023 02:21:21 INFO Epoch 4: [4610/10940] ---- BYOL Training Loss = 0.22486615180969238
31-01-2023 02:21:39 INFO Epoch 4: [4621/10940] ---- BYOL Training Loss = 0.20762693881988525
31-01-2023 02:22:32 INFO Epoch 4: [4621/10940] ---- BYOL Validation Loss = 0.19363291561603546
31-01-2023 02:22:50 INFO Epoch 4: [4632/10940] ---- BYOL Training Loss = 0.22613616287708282
31-01-2023 02:23:07 INFO Epoch 4: [4643/10940] ---- BYOL Training Loss = 0.2969561219215393
31-01-2023 02:23:25 INFO Epoch 4: [4654/10940] ---- BYOL Training Loss = 0.25930970907211304
31-01-2023 02:23:43 INFO Epoch 4: [4665/10940] ---- BYOL Training Loss = 0.21917656064033508
31-01-2023 02:24:36 INFO Epoch 4: [4665/10940] ---- BYOL Validation Loss = 0.2414582222700119
31-01-2023 02:24:54 INFO Epoch 4: [4676/10940] ---- BYOL Training Loss = 0.23409736156463623
31-01-2023 02:25:12 INFO Epoch 4: [4687/10940] ---- BYOL Training Loss = 0.24479155242443085
31-01-2023 02:25:29 INFO Epoch 4: [4698/10940] ---- BYOL Training Loss = 0.23470625281333923
31-01-2023 02:25:47 INFO Epoch 4: [4709/10940] ---- BYOL Training Loss = 0.24219612777233124
31-01-2023 02:26:40 INFO Epoch 4: [4709/10940] ---- BYOL Validation Loss = 0.21841323375701904
31-01-2023 02:26:58 INFO Epoch 4: [4720/10940] ---- BYOL Training Loss = 0.2612890899181366
31-01-2023 02:27:16 INFO Epoch 4: [4731/10940] ---- BYOL Training Loss = 0.2969837486743927
31-01-2023 02:27:34 INFO Epoch 4: [4742/10940] ---- BYOL Training Loss = 0.26914894580841064
31-01-2023 02:27:52 INFO Epoch 4: [4753/10940] ---- BYOL Training Loss = 0.2883361279964447
31-01-2023 02:28:44 INFO Epoch 4: [4753/10940] ---- BYOL Validation Loss = 0.24781166017055511
31-01-2023 02:29:02 INFO Epoch 4: [4764/10940] ---- BYOL Training Loss = 0.24447771906852722
31-01-2023 02:29:20 INFO Epoch 4: [4775/10940] ---- BYOL Training Loss = 0.20913469791412354
31-01-2023 02:29:38 INFO Epoch 4: [4786/10940] ---- BYOL Training Loss = 0.26181676983833313
31-01-2023 02:29:56 INFO Epoch 4: [4797/10940] ---- BYOL Training Loss = 0.281541645526886
31-01-2023 02:30:49 INFO Epoch 4: [4797/10940] ---- BYOL Validation Loss = 0.27991384267807007
31-01-2023 02:31:06 INFO Epoch 4: [4808/10940] ---- BYOL Training Loss = 0.28539639711380005
31-01-2023 02:31:24 INFO Epoch 4: [4819/10940] ---- BYOL Training Loss = 0.2851991355419159
31-01-2023 02:31:42 INFO Epoch 4: [4830/10940] ---- BYOL Training Loss = 0.2602826952934265
31-01-2023 02:32:00 INFO Epoch 4: [4841/10940] ---- BYOL Training Loss = 0.21900665760040283
31-01-2023 02:32:53 INFO Epoch 4: [4841/10940] ---- BYOL Validation Loss = 0.24698781967163086
31-01-2023 02:33:10 INFO Epoch 4: [4852/10940] ---- BYOL Training Loss = 0.26071447134017944
31-01-2023 02:33:28 INFO Epoch 4: [4863/10940] ---- BYOL Training Loss = 0.2403644323348999
31-01-2023 02:33:46 INFO Epoch 4: [4874/10940] ---- BYOL Training Loss = 0.16232527792453766
31-01-2023 02:34:04 INFO Epoch 4: [4885/10940] ---- BYOL Training Loss = 0.19924798607826233
31-01-2023 02:34:57 INFO Epoch 4: [4885/10940] ---- BYOL Validation Loss = 0.24910058081150055
31-01-2023 02:35:15 INFO Epoch 4: [4896/10940] ---- BYOL Training Loss = 0.26056593656539917
31-01-2023 02:35:33 INFO Epoch 4: [4907/10940] ---- BYOL Training Loss = 0.3005582392215729
31-01-2023 02:35:51 INFO Epoch 4: [4918/10940] ---- BYOL Training Loss = 0.26271870732307434
31-01-2023 02:36:09 INFO Epoch 4: [4929/10940] ---- BYOL Training Loss = 0.266839861869812
31-01-2023 02:37:01 INFO Epoch 4: [4929/10940] ---- BYOL Validation Loss = 0.23628179728984833
31-01-2023 02:37:19 INFO Epoch 4: [4940/10940] ---- BYOL Training Loss = 0.23736152052879333
31-01-2023 02:37:37 INFO Epoch 4: [4951/10940] ---- BYOL Training Loss = 0.18809397518634796
31-01-2023 02:37:55 INFO Epoch 4: [4962/10940] ---- BYOL Training Loss = 0.224263995885849
31-01-2023 02:38:13 INFO Epoch 4: [4973/10940] ---- BYOL Training Loss = 0.24941375851631165
31-01-2023 02:39:06 INFO Epoch 4: [4973/10940] ---- BYOL Validation Loss = 0.25336137413978577
31-01-2023 02:39:23 INFO Epoch 4: [4984/10940] ---- BYOL Training Loss = 0.23488382995128632
31-01-2023 02:39:41 INFO Epoch 4: [4995/10940] ---- BYOL Training Loss = 0.22353792190551758
31-01-2023 02:39:59 INFO Epoch 4: [5006/10940] ---- BYOL Training Loss = 0.17974475026130676
31-01-2023 02:40:17 INFO Epoch 4: [5017/10940] ---- BYOL Training Loss = 0.2504345774650574
31-01-2023 02:41:10 INFO Epoch 4: [5017/10940] ---- BYOL Validation Loss = 0.23119667172431946
31-01-2023 02:41:27 INFO Epoch 4: [5028/10940] ---- BYOL Training Loss = 0.2920669913291931
31-01-2023 02:41:46 INFO Epoch 4: [5039/10940] ---- BYOL Training Loss = 0.24715766310691833
31-01-2023 02:42:04 INFO Epoch 4: [5050/10940] ---- BYOL Training Loss = 0.24185514450073242
31-01-2023 02:42:21 INFO Epoch 4: [5061/10940] ---- BYOL Training Loss = 0.20098206400871277
31-01-2023 02:43:14 INFO Epoch 4: [5061/10940] ---- BYOL Validation Loss = 0.24378609657287598
31-01-2023 02:43:32 INFO Epoch 4: [5072/10940] ---- BYOL Training Loss = 0.21127012372016907
31-01-2023 02:43:50 INFO Epoch 4: [5083/10940] ---- BYOL Training Loss = 0.23541998863220215
31-01-2023 02:44:08 INFO Epoch 4: [5094/10940] ---- BYOL Training Loss = 0.20077729225158691
31-01-2023 02:44:26 INFO Epoch 4: [5105/10940] ---- BYOL Training Loss = 0.1793653964996338
31-01-2023 02:45:19 INFO Epoch 4: [5105/10940] ---- BYOL Validation Loss = 0.15277254581451416
31-01-2023 02:45:36 INFO Epoch 4: [5116/10940] ---- BYOL Training Loss = 0.21921952068805695
31-01-2023 02:45:54 INFO Epoch 4: [5127/10940] ---- BYOL Training Loss = 0.25812333822250366
31-01-2023 02:46:13 INFO Epoch 4: [5138/10940] ---- BYOL Training Loss = 0.241193026304245
31-01-2023 02:46:30 INFO Epoch 4: [5149/10940] ---- BYOL Training Loss = 0.23669545352458954
31-01-2023 02:47:23 INFO Epoch 4: [5149/10940] ---- BYOL Validation Loss = 0.16983048617839813
31-01-2023 02:47:41 INFO Epoch 4: [5160/10940] ---- BYOL Training Loss = 0.2742774784564972
31-01-2023 02:47:59 INFO Epoch 4: [5171/10940] ---- BYOL Training Loss = 0.22376862168312073
31-01-2023 02:48:17 INFO Epoch 4: [5182/10940] ---- BYOL Training Loss = 0.17164897918701172
31-01-2023 02:48:35 INFO Epoch 4: [5193/10940] ---- BYOL Training Loss = 0.19017653167247772
31-01-2023 02:49:27 INFO Epoch 4: [5193/10940] ---- BYOL Validation Loss = 0.22790248692035675
31-01-2023 02:49:45 INFO Epoch 4: [5204/10940] ---- BYOL Training Loss = 0.2570454478263855
31-01-2023 02:50:03 INFO Epoch 4: [5215/10940] ---- BYOL Training Loss = 0.28057804703712463
31-01-2023 02:50:21 INFO Epoch 4: [5226/10940] ---- BYOL Training Loss = 0.21486195921897888
31-01-2023 02:50:39 INFO Epoch 4: [5237/10940] ---- BYOL Training Loss = 0.19121238589286804
31-01-2023 02:51:32 INFO Epoch 4: [5237/10940] ---- BYOL Validation Loss = 0.17296843230724335
31-01-2023 02:51:50 INFO Epoch 4: [5248/10940] ---- BYOL Training Loss = 0.2098998725414276
31-01-2023 02:52:08 INFO Epoch 4: [5259/10940] ---- BYOL Training Loss = 0.24249449372291565
31-01-2023 02:52:26 INFO Epoch 4: [5270/10940] ---- BYOL Training Loss = 0.2346220761537552
31-01-2023 02:52:44 INFO Epoch 4: [5281/10940] ---- BYOL Training Loss = 0.22058811783790588
31-01-2023 02:53:36 INFO Epoch 4: [5281/10940] ---- BYOL Validation Loss = 0.2682383954524994
31-01-2023 02:53:54 INFO Epoch 4: [5292/10940] ---- BYOL Training Loss = 0.24319764971733093
31-01-2023 02:54:12 INFO Epoch 4: [5303/10940] ---- BYOL Training Loss = 0.24452464282512665
31-01-2023 02:54:30 INFO Epoch 4: [5314/10940] ---- BYOL Training Loss = 0.24435655772686005
31-01-2023 02:54:48 INFO Epoch 4: [5325/10940] ---- BYOL Training Loss = 0.2256041318178177
31-01-2023 02:55:41 INFO Epoch 4: [5325/10940] ---- BYOL Validation Loss = 0.20801107585430145
31-01-2023 02:55:59 INFO Epoch 4: [5336/10940] ---- BYOL Training Loss = 0.20668944716453552
31-01-2023 02:56:17 INFO Epoch 4: [5347/10940] ---- BYOL Training Loss = 0.23570480942726135
31-01-2023 02:56:34 INFO Epoch 4: [5358/10940] ---- BYOL Training Loss = 0.29008230566978455
31-01-2023 02:56:52 INFO Epoch 4: [5369/10940] ---- BYOL Training Loss = 0.3070004880428314
31-01-2023 02:57:45 INFO Epoch 4: [5369/10940] ---- BYOL Validation Loss = 0.2012447863817215
31-01-2023 02:58:03 INFO Epoch 4: [5380/10940] ---- BYOL Training Loss = 0.3055214583873749
31-01-2023 02:58:21 INFO Epoch 4: [5391/10940] ---- BYOL Training Loss = 0.2629222273826599
31-01-2023 02:58:39 INFO Epoch 4: [5402/10940] ---- BYOL Training Loss = 0.22429117560386658
31-01-2023 02:58:57 INFO Epoch 4: [5413/10940] ---- BYOL Training Loss = 0.19588010013103485
31-01-2023 02:59:50 INFO Epoch 4: [5413/10940] ---- BYOL Validation Loss = 0.155194953083992
31-01-2023 03:00:07 INFO Epoch 4: [5424/10940] ---- BYOL Training Loss = 0.24536080658435822
31-01-2023 03:00:25 INFO Epoch 4: [5435/10940] ---- BYOL Training Loss = 0.2946348786354065
31-01-2023 03:00:43 INFO Epoch 4: [5446/10940] ---- BYOL Training Loss = 0.2816154956817627
31-01-2023 03:01:01 INFO Epoch 4: [5457/10940] ---- BYOL Training Loss = 0.2272208034992218
31-01-2023 03:01:54 INFO Epoch 4: [5457/10940] ---- BYOL Validation Loss = 0.11594540625810623
31-01-2023 03:02:12 INFO Epoch 4: [5468/10940] ---- BYOL Training Loss = 0.2275867462158203
31-01-2023 03:02:30 INFO Epoch 4: [5479/10940] ---- BYOL Training Loss = 0.285639226436615
31-01-2023 03:02:48 INFO Epoch 4: [5490/10940] ---- BYOL Training Loss = 0.22150158882141113
31-01-2023 03:03:06 INFO Epoch 4: [5501/10940] ---- BYOL Training Loss = 0.223338320851326
31-01-2023 03:03:58 INFO Epoch 4: [5501/10940] ---- BYOL Validation Loss = 0.24750752747058868
31-01-2023 03:04:16 INFO Epoch 4: [5512/10940] ---- BYOL Training Loss = 0.2503841519355774
31-01-2023 03:04:35 INFO Epoch 4: [5523/10940] ---- BYOL Training Loss = 0.258209764957428
31-01-2023 03:04:53 INFO Epoch 4: [5534/10940] ---- BYOL Training Loss = 0.24437551200389862
31-01-2023 03:05:11 INFO Epoch 4: [5545/10940] ---- BYOL Training Loss = 0.250080943107605
31-01-2023 03:06:03 INFO Epoch 4: [5545/10940] ---- BYOL Validation Loss = 0.09830795228481293
31-01-2023 03:06:21 INFO Epoch 4: [5556/10940] ---- BYOL Training Loss = 0.23575690388679504
31-01-2023 03:06:39 INFO Epoch 4: [5567/10940] ---- BYOL Training Loss = 0.21485015749931335
31-01-2023 03:06:57 INFO Epoch 4: [5578/10940] ---- BYOL Training Loss = 0.23837439715862274
31-01-2023 03:07:15 INFO Epoch 4: [5589/10940] ---- BYOL Training Loss = 0.27157023549079895
31-01-2023 03:08:08 INFO Epoch 4: [5589/10940] ---- BYOL Validation Loss = 0.23656770586967468
31-01-2023 03:08:26 INFO Epoch 4: [5600/10940] ---- BYOL Training Loss = 0.3562786281108856
31-01-2023 03:08:44 INFO Epoch 4: [5611/10940] ---- BYOL Training Loss = 0.32058092951774597
31-01-2023 03:09:02 INFO Epoch 4: [5622/10940] ---- BYOL Training Loss = 0.2977631390094757
31-01-2023 03:09:20 INFO Epoch 4: [5633/10940] ---- BYOL Training Loss = 0.24616630375385284
31-01-2023 03:10:12 INFO Epoch 4: [5633/10940] ---- BYOL Validation Loss = 0.2276916801929474
31-01-2023 03:10:30 INFO Epoch 4: [5644/10940] ---- BYOL Training Loss = 0.299610435962677
31-01-2023 03:10:48 INFO Epoch 4: [5655/10940] ---- BYOL Training Loss = 0.2802286744117737
31-01-2023 03:11:07 INFO Epoch 4: [5666/10940] ---- BYOL Training Loss = 0.22251638770103455
31-01-2023 03:11:24 INFO Epoch 4: [5677/10940] ---- BYOL Training Loss = 0.23256468772888184
31-01-2023 03:12:17 INFO Epoch 4: [5677/10940] ---- BYOL Validation Loss = 0.13170668482780457
31-01-2023 03:12:35 INFO Epoch 4: [5688/10940] ---- BYOL Training Loss = 0.3038899302482605
31-01-2023 03:12:52 INFO Epoch 4: [5699/10940] ---- BYOL Training Loss = 0.3417648673057556
31-01-2023 03:13:10 INFO Epoch 4: [5710/10940] ---- BYOL Training Loss = 0.29803401231765747
31-01-2023 03:13:29 INFO Epoch 4: [5721/10940] ---- BYOL Training Loss = 0.27651485800743103
31-01-2023 03:14:21 INFO Epoch 4: [5721/10940] ---- BYOL Validation Loss = 0.2203092724084854
31-01-2023 03:14:39 INFO Epoch 4: [5732/10940] ---- BYOL Training Loss = 0.29919010400772095
31-01-2023 03:14:57 INFO Epoch 4: [5743/10940] ---- BYOL Training Loss = 0.2855335772037506
31-01-2023 03:15:15 INFO Epoch 4: [5754/10940] ---- BYOL Training Loss = 0.2750857472419739
31-01-2023 03:15:33 INFO Epoch 4: [5765/10940] ---- BYOL Training Loss = 0.2696821093559265
31-01-2023 03:16:26 INFO Epoch 4: [5765/10940] ---- BYOL Validation Loss = 0.16787520051002502
31-01-2023 03:16:43 INFO Epoch 4: [5776/10940] ---- BYOL Training Loss = 0.2671409249305725
31-01-2023 03:17:01 INFO Epoch 4: [5787/10940] ---- BYOL Training Loss = 0.2784743010997772
31-01-2023 03:17:19 INFO Epoch 4: [5798/10940] ---- BYOL Training Loss = 0.32901066541671753
31-01-2023 03:17:38 INFO Epoch 4: [5809/10940] ---- BYOL Training Loss = 0.26487964391708374
31-01-2023 03:18:31 INFO Epoch 4: [5809/10940] ---- BYOL Validation Loss = 0.288240909576416
31-01-2023 03:18:48 INFO Epoch 4: [5820/10940] ---- BYOL Training Loss = 0.2619481384754181
31-01-2023 03:19:06 INFO Epoch 4: [5831/10940] ---- BYOL Training Loss = 0.27551203966140747
31-01-2023 03:19:24 INFO Epoch 4: [5842/10940] ---- BYOL Training Loss = 0.3342098593711853
31-01-2023 03:19:42 INFO Epoch 4: [5853/10940] ---- BYOL Training Loss = 0.3203180432319641
31-01-2023 03:20:35 INFO Epoch 4: [5853/10940] ---- BYOL Validation Loss = 0.20409251749515533
31-01-2023 03:20:53 INFO Epoch 4: [5864/10940] ---- BYOL Training Loss = 0.2334231436252594
31-01-2023 03:21:11 INFO Epoch 4: [5875/10940] ---- BYOL Training Loss = 0.2291138619184494
31-01-2023 03:21:29 INFO Epoch 4: [5886/10940] ---- BYOL Training Loss = 0.20728173851966858
31-01-2023 03:21:47 INFO Epoch 4: [5897/10940] ---- BYOL Training Loss = 0.2865613102912903
31-01-2023 03:22:40 INFO Epoch 4: [5897/10940] ---- BYOL Validation Loss = 0.21975073218345642
31-01-2023 03:22:57 INFO Epoch 4: [5908/10940] ---- BYOL Training Loss = 0.26309773325920105
31-01-2023 03:23:15 INFO Epoch 4: [5919/10940] ---- BYOL Training Loss = 0.21681877970695496
31-01-2023 03:23:33 INFO Epoch 4: [5930/10940] ---- BYOL Training Loss = 0.20887914299964905
31-01-2023 03:23:51 INFO Epoch 4: [5941/10940] ---- BYOL Training Loss = 0.18774525821208954
31-01-2023 03:24:44 INFO Epoch 4: [5941/10940] ---- BYOL Validation Loss = 0.12229330837726593
31-01-2023 03:25:02 INFO Epoch 4: [5952/10940] ---- BYOL Training Loss = 0.24430981278419495
31-01-2023 03:25:19 INFO Epoch 4: [5963/10940] ---- BYOL Training Loss = 0.2820846438407898
31-01-2023 03:25:37 INFO Epoch 4: [5974/10940] ---- BYOL Training Loss = 0.243565171957016
31-01-2023 03:25:56 INFO Epoch 4: [5985/10940] ---- BYOL Training Loss = 0.26562830805778503
31-01-2023 03:26:48 INFO Epoch 4: [5985/10940] ---- BYOL Validation Loss = 0.18551765382289886
31-01-2023 03:27:06 INFO Epoch 4: [5996/10940] ---- BYOL Training Loss = 0.2680378556251526
31-01-2023 03:27:24 INFO Epoch 4: [6007/10940] ---- BYOL Training Loss = 0.33741235733032227
31-01-2023 03:27:42 INFO Epoch 4: [6018/10940] ---- BYOL Training Loss = 0.4094296991825104
31-01-2023 03:28:00 INFO Epoch 4: [6029/10940] ---- BYOL Training Loss = 0.29339882731437683
31-01-2023 03:28:53 INFO Epoch 4: [6029/10940] ---- BYOL Validation Loss = 0.1791514903306961
31-01-2023 03:29:11 INFO Epoch 4: [6040/10940] ---- BYOL Training Loss = 0.4197513461112976
31-01-2023 03:29:28 INFO Epoch 4: [6051/10940] ---- BYOL Training Loss = 0.4573465883731842
31-01-2023 03:29:46 INFO Epoch 4: [6062/10940] ---- BYOL Training Loss = 0.33201584219932556
31-01-2023 03:30:04 INFO Epoch 4: [6073/10940] ---- BYOL Training Loss = 0.239518404006958
31-01-2023 03:30:57 INFO Epoch 4: [6073/10940] ---- BYOL Validation Loss = 0.2227582484483719
31-01-2023 03:31:15 INFO Epoch 4: [6084/10940] ---- BYOL Training Loss = 0.2568005621433258
31-01-2023 03:31:33 INFO Epoch 4: [6095/10940] ---- BYOL Training Loss = 0.30115261673927307
31-01-2023 03:31:51 INFO Epoch 4: [6106/10940] ---- BYOL Training Loss = 0.33434656262397766
31-01-2023 03:32:10 INFO Epoch 4: [6117/10940] ---- BYOL Training Loss = 0.3835182785987854
31-01-2023 03:33:02 INFO Epoch 4: [6117/10940] ---- BYOL Validation Loss = 0.13798296451568604
31-01-2023 03:33:20 INFO Epoch 4: [6128/10940] ---- BYOL Training Loss = 0.33589664101600647
31-01-2023 03:33:38 INFO Epoch 4: [6139/10940] ---- BYOL Training Loss = 0.26674342155456543
31-01-2023 03:33:56 INFO Epoch 4: [6150/10940] ---- BYOL Training Loss = 0.3985798954963684
31-01-2023 03:34:14 INFO Epoch 4: [6161/10940] ---- BYOL Training Loss = 0.37546923756599426
31-01-2023 03:35:07 INFO Epoch 4: [6161/10940] ---- BYOL Validation Loss = 0.19781801104545593
31-01-2023 03:35:25 INFO Epoch 4: [6172/10940] ---- BYOL Training Loss = 0.24549224972724915
31-01-2023 03:35:43 INFO Epoch 4: [6183/10940] ---- BYOL Training Loss = 0.249053955078125
31-01-2023 03:36:01 INFO Epoch 4: [6194/10940] ---- BYOL Training Loss = 0.21449334919452667
31-01-2023 03:36:19 INFO Epoch 4: [6205/10940] ---- BYOL Training Loss = 0.27399522066116333
31-01-2023 03:37:12 INFO Epoch 4: [6205/10940] ---- BYOL Validation Loss = 0.24144478142261505
31-01-2023 03:37:29 INFO Epoch 4: [6216/10940] ---- BYOL Training Loss = 0.2889711260795593
31-01-2023 03:37:47 INFO Epoch 4: [6227/10940] ---- BYOL Training Loss = 0.24260735511779785
31-01-2023 03:38:05 INFO Epoch 4: [6238/10940] ---- BYOL Training Loss = 0.23100590705871582
31-01-2023 03:38:24 INFO Epoch 4: [6249/10940] ---- BYOL Training Loss = 0.2121424674987793
31-01-2023 03:39:16 INFO Epoch 4: [6249/10940] ---- BYOL Validation Loss = 0.23421435058116913
31-01-2023 03:39:34 INFO Epoch 4: [6260/10940] ---- BYOL Training Loss = 0.2246185839176178
31-01-2023 03:39:52 INFO Epoch 4: [6271/10940] ---- BYOL Training Loss = 0.2085340917110443
31-01-2023 03:40:10 INFO Epoch 4: [6282/10940] ---- BYOL Training Loss = 0.20489010214805603
31-01-2023 03:40:28 INFO Epoch 4: [6293/10940] ---- BYOL Training Loss = 0.23144206404685974
31-01-2023 03:41:21 INFO Epoch 4: [6293/10940] ---- BYOL Validation Loss = 0.14043034613132477
31-01-2023 03:41:39 INFO Epoch 4: [6304/10940] ---- BYOL Training Loss = 0.24539896845817566
31-01-2023 03:41:57 INFO Epoch 4: [6315/10940] ---- BYOL Training Loss = 0.25288039445877075
31-01-2023 03:42:15 INFO Epoch 4: [6326/10940] ---- BYOL Training Loss = 0.20850467681884766
31-01-2023 03:42:33 INFO Epoch 4: [6337/10940] ---- BYOL Training Loss = 0.24436001479625702
31-01-2023 03:43:26 INFO Epoch 4: [6337/10940] ---- BYOL Validation Loss = 0.163169726729393
31-01-2023 03:43:43 INFO Epoch 4: [6348/10940] ---- BYOL Training Loss = 0.30420196056365967
31-01-2023 03:44:01 INFO Epoch 4: [6359/10940] ---- BYOL Training Loss = 0.33576473593711853
31-01-2023 03:44:20 INFO Epoch 4: [6370/10940] ---- BYOL Training Loss = 0.3179556429386139
31-01-2023 03:44:38 INFO Epoch 4: [6381/10940] ---- BYOL Training Loss = 0.3281763195991516
31-01-2023 03:45:30 INFO Epoch 4: [6381/10940] ---- BYOL Validation Loss = 0.1887606680393219
31-01-2023 03:45:48 INFO Epoch 4: [6392/10940] ---- BYOL Training Loss = 0.3443683385848999
31-01-2023 03:46:06 INFO Epoch 4: [6403/10940] ---- BYOL Training Loss = 0.4041479527950287
31-01-2023 03:46:24 INFO Epoch 4: [6414/10940] ---- BYOL Training Loss = 0.3642212748527527
31-01-2023 03:46:42 INFO Epoch 4: [6425/10940] ---- BYOL Training Loss = 0.2506785988807678
31-01-2023 03:47:35 INFO Epoch 4: [6425/10940] ---- BYOL Validation Loss = 0.23642709851264954
31-01-2023 03:47:53 INFO Epoch 4: [6436/10940] ---- BYOL Training Loss = 0.26250892877578735
31-01-2023 03:48:11 INFO Epoch 4: [6447/10940] ---- BYOL Training Loss = 0.23111310601234436
31-01-2023 03:48:29 INFO Epoch 4: [6458/10940] ---- BYOL Training Loss = 0.22784169018268585
31-01-2023 03:48:47 INFO Epoch 4: [6469/10940] ---- BYOL Training Loss = 0.24142614006996155
31-01-2023 03:49:40 INFO Epoch 4: [6469/10940] ---- BYOL Validation Loss = 0.2213285267353058
31-01-2023 03:49:57 INFO Epoch 4: [6480/10940] ---- BYOL Training Loss = 0.24791674315929413
31-01-2023 03:50:16 INFO Epoch 4: [6491/10940] ---- BYOL Training Loss = 0.25107163190841675
31-01-2023 03:50:34 INFO Epoch 4: [6502/10940] ---- BYOL Training Loss = 0.1872430294752121
31-01-2023 03:50:52 INFO Epoch 4: [6513/10940] ---- BYOL Training Loss = 0.18878018856048584
31-01-2023 03:51:45 INFO Epoch 4: [6513/10940] ---- BYOL Validation Loss = 0.1493213176727295
31-01-2023 03:52:03 INFO Epoch 4: [6524/10940] ---- BYOL Training Loss = 0.2556040585041046
31-01-2023 03:52:21 INFO Epoch 4: [6535/10940] ---- BYOL Training Loss = 0.2894454896450043
31-01-2023 03:52:39 INFO Epoch 4: [6546/10940] ---- BYOL Training Loss = 0.23097333312034607
31-01-2023 03:52:57 INFO Epoch 4: [6557/10940] ---- BYOL Training Loss = 0.22520272433757782
31-01-2023 03:53:50 INFO Epoch 4: [6557/10940] ---- BYOL Validation Loss = 0.20477382838726044
31-01-2023 03:54:07 INFO Epoch 4: [6568/10940] ---- BYOL Training Loss = 0.2300795018672943
31-01-2023 03:54:26 INFO Epoch 4: [6579/10940] ---- BYOL Training Loss = 0.2262982428073883
31-01-2023 03:54:44 INFO Epoch 4: [6590/10940] ---- BYOL Training Loss = 0.27417874336242676
31-01-2023 03:55:02 INFO Epoch 4: [6601/10940] ---- BYOL Training Loss = 0.24669964611530304
31-01-2023 03:55:55 INFO Epoch 4: [6601/10940] ---- BYOL Validation Loss = 0.22542531788349152
31-01-2023 03:56:13 INFO Epoch 4: [6612/10940] ---- BYOL Training Loss = 0.18807750940322876
31-01-2023 03:56:31 INFO Epoch 4: [6623/10940] ---- BYOL Training Loss = 0.2322298288345337
31-01-2023 03:56:49 INFO Epoch 4: [6634/10940] ---- BYOL Training Loss = 0.2017194926738739
31-01-2023 03:57:07 INFO Epoch 4: [6645/10940] ---- BYOL Training Loss = 0.19054599106311798
31-01-2023 03:58:00 INFO Epoch 4: [6645/10940] ---- BYOL Validation Loss = 0.1784975230693817
31-01-2023 03:58:18 INFO Epoch 4: [6656/10940] ---- BYOL Training Loss = 0.20687267184257507
31-01-2023 03:58:36 INFO Epoch 4: [6667/10940] ---- BYOL Training Loss = 0.17197267711162567
31-01-2023 03:58:54 INFO Epoch 4: [6678/10940] ---- BYOL Training Loss = 0.17976053059101105
31-01-2023 03:59:12 INFO Epoch 4: [6689/10940] ---- BYOL Training Loss = 0.24896860122680664
31-01-2023 04:00:05 INFO Epoch 4: [6689/10940] ---- BYOL Validation Loss = 0.16641709208488464
31-01-2023 04:00:23 INFO Epoch 4: [6700/10940] ---- BYOL Training Loss = 0.27065524458885193
31-01-2023 04:00:41 INFO Epoch 4: [6711/10940] ---- BYOL Training Loss = 0.26102787256240845
31-01-2023 04:00:59 INFO Epoch 4: [6722/10940] ---- BYOL Training Loss = 0.2169676274061203
31-01-2023 04:01:17 INFO Epoch 4: [6733/10940] ---- BYOL Training Loss = 0.2066027820110321
31-01-2023 04:02:10 INFO Epoch 4: [6733/10940] ---- BYOL Validation Loss = 0.11596301943063736
31-01-2023 04:02:28 INFO Epoch 4: [6744/10940] ---- BYOL Training Loss = 0.21422572433948517
31-01-2023 04:02:46 INFO Epoch 4: [6755/10940] ---- BYOL Training Loss = 0.2015218436717987
31-01-2023 04:03:04 INFO Epoch 4: [6766/10940] ---- BYOL Training Loss = 0.17986202239990234
31-01-2023 04:03:22 INFO Epoch 4: [6777/10940] ---- BYOL Training Loss = 0.24048800766468048
31-01-2023 04:04:15 INFO Epoch 4: [6777/10940] ---- BYOL Validation Loss = 0.19059665501117706
31-01-2023 04:04:33 INFO Epoch 4: [6788/10940] ---- BYOL Training Loss = 0.3127727806568146
31-01-2023 04:04:51 INFO Epoch 4: [6799/10940] ---- BYOL Training Loss = 0.27886706590652466
31-01-2023 04:05:09 INFO Epoch 4: [6810/10940] ---- BYOL Training Loss = 0.20461198687553406
31-01-2023 04:05:28 INFO Epoch 4: [6821/10940] ---- BYOL Training Loss = 0.2106519192457199
31-01-2023 04:06:20 INFO Epoch 4: [6821/10940] ---- BYOL Validation Loss = 0.1598385125398636
31-01-2023 04:06:38 INFO Epoch 4: [6832/10940] ---- BYOL Training Loss = 0.16679921746253967
31-01-2023 04:06:56 INFO Epoch 4: [6843/10940] ---- BYOL Training Loss = 0.19095449149608612
31-01-2023 04:07:14 INFO Epoch 4: [6854/10940] ---- BYOL Training Loss = 0.23658402264118195
31-01-2023 04:07:33 INFO Epoch 4: [6865/10940] ---- BYOL Training Loss = 0.2406875640153885
31-01-2023 04:08:25 INFO Epoch 4: [6865/10940] ---- BYOL Validation Loss = 0.15971289575099945
31-01-2023 04:08:43 INFO Epoch 4: [6876/10940] ---- BYOL Training Loss = 0.22629204392433167
31-01-2023 04:09:01 INFO Epoch 4: [6887/10940] ---- BYOL Training Loss = 0.23597590625286102
31-01-2023 04:09:19 INFO Epoch 4: [6898/10940] ---- BYOL Training Loss = 0.21359243988990784
31-01-2023 04:09:37 INFO Epoch 4: [6909/10940] ---- BYOL Training Loss = 0.18987323343753815
31-01-2023 04:10:30 INFO Epoch 4: [6909/10940] ---- BYOL Validation Loss = 0.06594666093587875
31-01-2023 04:10:48 INFO Epoch 4: [6920/10940] ---- BYOL Training Loss = 0.16231082379817963
31-01-2023 04:11:06 INFO Epoch 4: [6931/10940] ---- BYOL Training Loss = 0.15984097123146057
31-01-2023 04:11:24 INFO Epoch 4: [6942/10940] ---- BYOL Training Loss = 0.22376814484596252
31-01-2023 04:11:42 INFO Epoch 4: [6953/10940] ---- BYOL Training Loss = 0.24733440577983856
31-01-2023 04:12:34 INFO Epoch 4: [6953/10940] ---- BYOL Validation Loss = 0.19464614987373352
31-01-2023 04:12:52 INFO Epoch 4: [6964/10940] ---- BYOL Training Loss = 0.21958866715431213
31-01-2023 04:13:10 INFO Epoch 4: [6975/10940] ---- BYOL Training Loss = 0.2568632960319519
31-01-2023 04:13:28 INFO Epoch 4: [6986/10940] ---- BYOL Training Loss = 0.24356544017791748
31-01-2023 04:13:47 INFO Epoch 4: [6997/10940] ---- BYOL Training Loss = 0.28630656003952026
31-01-2023 04:14:39 INFO Epoch 4: [6997/10940] ---- BYOL Validation Loss = 0.21111957728862762
31-01-2023 04:14:57 INFO Epoch 4: [7008/10940] ---- BYOL Training Loss = 0.2839350700378418
31-01-2023 04:15:15 INFO Epoch 4: [7019/10940] ---- BYOL Training Loss = 0.2426728755235672
31-01-2023 04:15:33 INFO Epoch 4: [7030/10940] ---- BYOL Training Loss = 0.254433810710907
31-01-2023 04:15:51 INFO Epoch 4: [7041/10940] ---- BYOL Training Loss = 0.2633618712425232
31-01-2023 04:16:44 INFO Epoch 4: [7041/10940] ---- BYOL Validation Loss = 0.17436523735523224
31-01-2023 04:17:02 INFO Epoch 4: [7052/10940] ---- BYOL Training Loss = 0.2175096571445465
31-01-2023 04:17:20 INFO Epoch 4: [7063/10940] ---- BYOL Training Loss = 0.2647556960582733
31-01-2023 04:17:38 INFO Epoch 4: [7074/10940] ---- BYOL Training Loss = 0.27450257539749146
31-01-2023 04:17:56 INFO Epoch 4: [7085/10940] ---- BYOL Training Loss = 0.2582556903362274
31-01-2023 04:18:49 INFO Epoch 4: [7085/10940] ---- BYOL Validation Loss = 0.19171826541423798
31-01-2023 04:19:06 INFO Epoch 4: [7096/10940] ---- BYOL Training Loss = 0.2907481789588928
31-01-2023 04:19:25 INFO Epoch 4: [7107/10940] ---- BYOL Training Loss = 0.3547658324241638
31-01-2023 04:19:42 INFO Epoch 4: [7118/10940] ---- BYOL Training Loss = 0.3231934905052185
31-01-2023 04:20:01 INFO Epoch 4: [7129/10940] ---- BYOL Training Loss = 0.25907284021377563
31-01-2023 04:20:53 INFO Epoch 4: [7129/10940] ---- BYOL Validation Loss = 0.13208012282848358
31-01-2023 04:21:11 INFO Epoch 4: [7140/10940] ---- BYOL Training Loss = 0.22295264899730682
31-01-2023 04:21:29 INFO Epoch 4: [7151/10940] ---- BYOL Training Loss = 0.25293806195259094
31-01-2023 04:21:47 INFO Epoch 4: [7162/10940] ---- BYOL Training Loss = 0.26307445764541626
31-01-2023 04:22:05 INFO Epoch 4: [7173/10940] ---- BYOL Training Loss = 0.242652028799057
31-01-2023 04:22:58 INFO Epoch 4: [7173/10940] ---- BYOL Validation Loss = 0.21606802940368652
31-01-2023 04:23:16 INFO Epoch 4: [7184/10940] ---- BYOL Training Loss = 0.2544642984867096
31-01-2023 04:23:34 INFO Epoch 4: [7195/10940] ---- BYOL Training Loss = 0.2401718646287918
31-01-2023 04:23:52 INFO Epoch 4: [7206/10940] ---- BYOL Training Loss = 0.2615777850151062
31-01-2023 04:24:10 INFO Epoch 4: [7217/10940] ---- BYOL Training Loss = 0.21456961333751678
31-01-2023 04:25:03 INFO Epoch 4: [7217/10940] ---- BYOL Validation Loss = 0.13922327756881714
31-01-2023 04:25:21 INFO Epoch 4: [7228/10940] ---- BYOL Training Loss = 0.22891347110271454
31-01-2023 04:25:39 INFO Epoch 4: [7239/10940] ---- BYOL Training Loss = 0.19185343384742737
31-01-2023 04:25:57 INFO Epoch 4: [7250/10940] ---- BYOL Training Loss = 0.2540218234062195
31-01-2023 04:26:15 INFO Epoch 4: [7261/10940] ---- BYOL Training Loss = 0.2515895366668701
31-01-2023 04:27:08 INFO Epoch 4: [7261/10940] ---- BYOL Validation Loss = 0.1300792247056961
31-01-2023 04:27:26 INFO Epoch 4: [7272/10940] ---- BYOL Training Loss = 0.24384117126464844
31-01-2023 04:27:44 INFO Epoch 4: [7283/10940] ---- BYOL Training Loss = 0.26649990677833557
31-01-2023 04:28:02 INFO Epoch 4: [7294/10940] ---- BYOL Training Loss = 0.29189857840538025
31-01-2023 04:28:20 INFO Epoch 4: [7305/10940] ---- BYOL Training Loss = 0.2545265555381775
31-01-2023 04:29:13 INFO Epoch 4: [7305/10940] ---- BYOL Validation Loss = 0.18921902775764465
31-01-2023 04:29:31 INFO Epoch 4: [7316/10940] ---- BYOL Training Loss = 0.29332277178764343
31-01-2023 04:29:49 INFO Epoch 4: [7327/10940] ---- BYOL Training Loss = 0.35513168573379517
31-01-2023 04:30:07 INFO Epoch 4: [7338/10940] ---- BYOL Training Loss = 0.38939133286476135
31-01-2023 04:30:25 INFO Epoch 4: [7349/10940] ---- BYOL Training Loss = 0.2831191420555115
31-01-2023 04:31:18 INFO Epoch 4: [7349/10940] ---- BYOL Validation Loss = 0.1325068324804306
31-01-2023 04:31:35 INFO Epoch 4: [7360/10940] ---- BYOL Training Loss = 0.2880629003047943
31-01-2023 04:31:54 INFO Epoch 4: [7371/10940] ---- BYOL Training Loss = 0.27226513624191284
31-01-2023 04:32:12 INFO Epoch 4: [7382/10940] ---- BYOL Training Loss = 0.29396897554397583
31-01-2023 04:32:30 INFO Epoch 4: [7393/10940] ---- BYOL Training Loss = 0.3210250437259674
31-01-2023 04:33:22 INFO Epoch 4: [7393/10940] ---- BYOL Validation Loss = 0.17316794395446777
31-01-2023 04:33:40 INFO Epoch 4: [7404/10940] ---- BYOL Training Loss = 0.32064712047576904
31-01-2023 04:33:58 INFO Epoch 4: [7415/10940] ---- BYOL Training Loss = 0.2693774700164795
31-01-2023 04:34:17 INFO Epoch 4: [7426/10940] ---- BYOL Training Loss = 0.22631165385246277
31-01-2023 04:34:35 INFO Epoch 4: [7437/10940] ---- BYOL Training Loss = 0.24351494014263153
31-01-2023 04:35:27 INFO Epoch 4: [7437/10940] ---- BYOL Validation Loss = 0.21162663400173187
31-01-2023 04:35:45 INFO Epoch 4: [7448/10940] ---- BYOL Training Loss = 0.2176578789949417
31-01-2023 04:36:03 INFO Epoch 4: [7459/10940] ---- BYOL Training Loss = 0.18847522139549255
31-01-2023 04:36:21 INFO Epoch 4: [7470/10940] ---- BYOL Training Loss = 0.23825597763061523
31-01-2023 04:36:40 INFO Epoch 4: [7481/10940] ---- BYOL Training Loss = 0.19751840829849243
31-01-2023 04:37:32 INFO Epoch 4: [7481/10940] ---- BYOL Validation Loss = 0.1379418522119522
31-01-2023 04:37:50 INFO Epoch 4: [7492/10940] ---- BYOL Training Loss = 0.16846022009849548
31-01-2023 04:38:08 INFO Epoch 4: [7503/10940] ---- BYOL Training Loss = 0.23423251509666443
31-01-2023 04:38:27 INFO Epoch 4: [7514/10940] ---- BYOL Training Loss = 0.22558169066905975
31-01-2023 04:38:45 INFO Epoch 4: [7525/10940] ---- BYOL Training Loss = 0.2288537323474884
31-01-2023 04:39:38 INFO Epoch 4: [7525/10940] ---- BYOL Validation Loss = 0.21182991564273834
31-01-2023 04:39:55 INFO Epoch 4: [7536/10940] ---- BYOL Training Loss = 0.22314321994781494
31-01-2023 04:40:14 INFO Epoch 4: [7547/10940] ---- BYOL Training Loss = 0.234969824552536
31-01-2023 04:40:32 INFO Epoch 4: [7558/10940] ---- BYOL Training Loss = 0.23303654789924622
31-01-2023 04:40:50 INFO Epoch 4: [7569/10940] ---- BYOL Training Loss = 0.23753643035888672
31-01-2023 04:41:43 INFO Epoch 4: [7569/10940] ---- BYOL Validation Loss = 0.2136448174715042
31-01-2023 04:42:01 INFO Epoch 4: [7580/10940] ---- BYOL Training Loss = 0.2528405487537384
31-01-2023 04:42:19 INFO Epoch 4: [7591/10940] ---- BYOL Training Loss = 0.20035667717456818
31-01-2023 04:42:37 INFO Epoch 4: [7602/10940] ---- BYOL Training Loss = 0.21954584121704102
31-01-2023 04:42:55 INFO Epoch 4: [7613/10940] ---- BYOL Training Loss = 0.21799059212207794
31-01-2023 04:43:48 INFO Epoch 4: [7613/10940] ---- BYOL Validation Loss = 0.18377825617790222
31-01-2023 04:44:05 INFO Epoch 4: [7624/10940] ---- BYOL Training Loss = 0.2389393150806427
31-01-2023 04:44:23 INFO Epoch 4: [7635/10940] ---- BYOL Training Loss = 0.17444558441638947
31-01-2023 04:44:42 INFO Epoch 4: [7646/10940] ---- BYOL Training Loss = 0.2560094892978668
31-01-2023 04:45:00 INFO Epoch 4: [7657/10940] ---- BYOL Training Loss = 0.24798378348350525
31-01-2023 04:45:52 INFO Epoch 4: [7657/10940] ---- BYOL Validation Loss = 0.08964193612337112
31-01-2023 04:46:10 INFO Epoch 4: [7668/10940] ---- BYOL Training Loss = 0.16778579354286194
31-01-2023 04:46:28 INFO Epoch 4: [7679/10940] ---- BYOL Training Loss = 0.28746461868286133
31-01-2023 04:46:47 INFO Epoch 4: [7690/10940] ---- BYOL Training Loss = 0.3262595236301422
31-01-2023 04:47:05 INFO Epoch 4: [7701/10940] ---- BYOL Training Loss = 0.26046162843704224
31-01-2023 04:47:58 INFO Epoch 4: [7701/10940] ---- BYOL Validation Loss = 0.12610366940498352
31-01-2023 04:48:15 INFO Epoch 4: [7712/10940] ---- BYOL Training Loss = 0.3076402544975281
31-01-2023 04:48:34 INFO Epoch 4: [7723/10940] ---- BYOL Training Loss = 0.24569496512413025
31-01-2023 04:48:52 INFO Epoch 4: [7734/10940] ---- BYOL Training Loss = 0.1935727894306183
31-01-2023 04:49:10 INFO Epoch 4: [7745/10940] ---- BYOL Training Loss = 0.1920246183872223
31-01-2023 04:50:02 INFO Epoch 4: [7745/10940] ---- BYOL Validation Loss = 0.24335084855556488
31-01-2023 04:50:21 INFO Epoch 4: [7756/10940] ---- BYOL Training Loss = 0.2198769599199295
31-01-2023 04:50:39 INFO Epoch 4: [7767/10940] ---- BYOL Training Loss = 0.21975824236869812
31-01-2023 04:50:57 INFO Epoch 4: [7778/10940] ---- BYOL Training Loss = 0.2172284871339798
31-01-2023 04:51:15 INFO Epoch 4: [7789/10940] ---- BYOL Training Loss = 0.2063644379377365
31-01-2023 04:52:08 INFO Epoch 4: [7789/10940] ---- BYOL Validation Loss = 0.14283165335655212
31-01-2023 04:52:26 INFO Epoch 4: [7800/10940] ---- BYOL Training Loss = 0.2462964504957199
31-01-2023 04:52:44 INFO Epoch 4: [7811/10940] ---- BYOL Training Loss = 0.2277783453464508
31-01-2023 04:53:02 INFO Epoch 4: [7822/10940] ---- BYOL Training Loss = 0.2529889643192291
31-01-2023 04:53:20 INFO Epoch 4: [7833/10940] ---- BYOL Training Loss = 0.23554947972297668
31-01-2023 04:54:13 INFO Epoch 4: [7833/10940] ---- BYOL Validation Loss = 0.19191966950893402
31-01-2023 04:54:31 INFO Epoch 4: [7844/10940] ---- BYOL Training Loss = 0.1786719113588333
31-01-2023 04:54:49 INFO Epoch 4: [7855/10940] ---- BYOL Training Loss = 0.24453110992908478
31-01-2023 04:55:07 INFO Epoch 4: [7866/10940] ---- BYOL Training Loss = 0.2828386425971985
31-01-2023 04:55:25 INFO Epoch 4: [7877/10940] ---- BYOL Training Loss = 0.1929382085800171
31-01-2023 04:56:18 INFO Epoch 4: [7877/10940] ---- BYOL Validation Loss = 0.17559382319450378
31-01-2023 04:56:36 INFO Epoch 4: [7888/10940] ---- BYOL Training Loss = 0.2234746664762497
31-01-2023 04:56:54 INFO Epoch 4: [7899/10940] ---- BYOL Training Loss = 0.28518810868263245
31-01-2023 04:57:12 INFO Epoch 4: [7910/10940] ---- BYOL Training Loss = 0.27499157190322876
31-01-2023 04:57:31 INFO Epoch 4: [7921/10940] ---- BYOL Training Loss = 0.25576093792915344
slurmstepd-landonia22: error: *** JOB 1507976 ON landonia22 CANCELLED AT 2023-01-31T04:58:14 DUE TO TIME LIMIT ***
