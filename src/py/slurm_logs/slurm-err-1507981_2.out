29-01-2023 21:22:11 INFO Running main & importing modules...
29-01-2023 21:22:35 INFO Parsed arguments: Namespace(batch_size=32, byol_ema_tau=0.99, debug=False, encoder='resnet18', encoder_layer_idx=-2, epochs=5, experiment_name='b-resnet18-e5-b32-t0_99-p64', input='/disk/scratch_big/s1908368/data', log_interval=1000, lr=0.001, output='/disk/scratch_big/s1908368/output', patch_size=64, pretrain_encoder=False, seed=23, simclr_tau=0.99, train_proportion=0.98, use_byol=True)
29-01-2023 21:22:35 INFO File at /disk/scratch_big/s1908368/data/patch_train_dataset_64.pk: False
29-01-2023 21:22:35 INFO File at /disk/scratch_big/s1908368/data/patch_val_dataset_64.pk: False
29-01-2023 21:22:35 INFO Directories found: ['1', '10', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '6', '7', '8', '9']
29-01-2023 21:22:35 INFO Files in first directory: ['82877289.png', '82877292.png', '82877286.png']
29-01-2023 21:22:35 INFO Fetching patches from folder: 51
29-01-2023 21:22:40 INFO Fetching patches from folder: 52
29-01-2023 21:22:44 INFO Fetching patches from folder: 19
29-01-2023 21:22:55 INFO Fetching patches from folder: 32
29-01-2023 21:23:05 INFO Fetching patches from folder: 33
29-01-2023 21:23:15 INFO Fetching patches from folder: 18
29-01-2023 21:23:28 INFO Fetching patches from folder: 4
29-01-2023 21:23:36 INFO Fetching patches from folder: 1
29-01-2023 21:23:47 INFO Fetching patches from folder: 14
29-01-2023 21:23:56 INFO Fetching patches from folder: 2
29-01-2023 21:24:04 INFO Fetching patches from folder: 36
29-01-2023 21:24:12 INFO Fetching patches from folder: 39
29-01-2023 21:24:22 INFO Fetching patches from folder: 38
29-01-2023 21:24:31 INFO Fetching patches from folder: 46
29-01-2023 21:24:36 INFO Fetching patches from folder: 3
29-01-2023 21:24:44 INFO Fetching patches from folder: 41
29-01-2023 21:24:48 INFO Fetching patches from folder: 53
29-01-2023 21:24:53 INFO Fetching patches from folder: 40
29-01-2023 21:24:59 INFO Fetching patches from folder: 13
29-01-2023 21:25:09 INFO Fetching patches from folder: 5
29-01-2023 21:25:18 INFO Fetching patches from folder: 47
29-01-2023 21:25:22 INFO Fetching patches from folder: 25
29-01-2023 21:25:36 INFO Fetching patches from folder: 7
29-01-2023 21:25:44 INFO Fetching patches from folder: 48
29-01-2023 21:25:47 INFO Fetching patches from folder: 50
29-01-2023 21:25:51 INFO Fetching patches from folder: 26
29-01-2023 21:26:03 INFO Fetching patches from folder: 9
29-01-2023 21:26:13 INFO Fetching patches from folder: 12
29-01-2023 21:26:17 INFO Fetching patches from folder: 49
29-01-2023 21:26:20 INFO Fetching patches from folder: 15
29-01-2023 21:26:30 INFO Fetching patches from folder: 42
29-01-2023 21:26:35 INFO Fetching patches from folder: 43
29-01-2023 21:26:41 INFO Fetching patches from folder: 45
29-01-2023 21:26:45 INFO Fetching patches from folder: 22
29-01-2023 21:26:54 INFO Fetching patches from folder: 16
29-01-2023 21:27:06 INFO Fetching patches from folder: 55
29-01-2023 21:27:11 INFO Fetching patches from folder: 30
29-01-2023 21:27:21 INFO Fetching patches from folder: 6
29-01-2023 21:27:28 INFO Fetching patches from folder: 35
29-01-2023 21:27:37 INFO Fetching patches from folder: 8
29-01-2023 21:27:45 INFO Fetching patches from folder: 17
29-01-2023 21:27:58 INFO Fetching patches from folder: 37
29-01-2023 21:28:06 INFO Fetching patches from folder: 34
29-01-2023 21:28:15 INFO Fetching patches from folder: 10
29-01-2023 21:28:24 INFO Fetching patches from folder: 24
29-01-2023 21:28:35 INFO Fetching patches from folder: 56
29-01-2023 21:28:39 INFO Fetching patches from folder: 31
29-01-2023 21:28:51 INFO Fetching patches from folder: 23
29-01-2023 21:29:03 INFO Fetching patches from folder: 54
29-01-2023 21:29:07 INFO Fetching patches from folder: 57
29-01-2023 21:29:10 INFO Fetching patches from folder: 20
29-01-2023 21:29:13 INFO Fetching patches from folder: 29
29-01-2023 21:29:21 INFO Fetching patches from folder: 21
29-01-2023 21:29:29 INFO Fetching patches from folder: 44
29-01-2023 21:29:35 INFO Generated 357207 positive pairs, after removing 264063 positive pairs.
29-01-2023 21:30:30 INFO Generated training dataset with 350062 samples.
29-01-2023 21:30:30 INFO Generated validation dataset with 7145 samples.
29-01-2023 21:30:31 INFO Using encoder resnet18 with pretrained weights = False
29-01-2023 21:30:32 INFO Using BYOL with tau = 0.99, with encoder layer index = -2
29-01-2023 21:30:32 INFO Using device: cuda
29-01-2023 21:30:42 INFO Starting Epoch: 1
29-01-2023 21:31:02 INFO Epoch 1: [12/10940] ---- BYOL Training Loss = 1.8448057174682617
29-01-2023 21:31:19 INFO Epoch 1: [23/10940] ---- BYOL Training Loss = 1.4801280498504639
29-01-2023 21:31:37 INFO Epoch 1: [34/10940] ---- BYOL Training Loss = 1.328916072845459
29-01-2023 21:31:55 INFO Epoch 1: [45/10940] ---- BYOL Training Loss = 1.0922855138778687
29-01-2023 21:32:46 INFO Epoch 1: [45/10940] ---- BYOL Validation Loss = 1.7971700429916382
29-01-2023 21:33:04 INFO Epoch 1: [56/10940] ---- BYOL Training Loss = 0.9275432825088501
29-01-2023 21:33:21 INFO Epoch 1: [67/10940] ---- BYOL Training Loss = 0.7903876304626465
29-01-2023 21:33:39 INFO Epoch 1: [78/10940] ---- BYOL Training Loss = 0.800524890422821
29-01-2023 21:33:56 INFO Epoch 1: [89/10940] ---- BYOL Training Loss = 0.856820285320282
29-01-2023 21:34:48 INFO Epoch 1: [89/10940] ---- BYOL Validation Loss = 0.8169495463371277
29-01-2023 21:35:05 INFO Epoch 1: [100/10940] ---- BYOL Training Loss = 0.7740164399147034
29-01-2023 21:35:23 INFO Epoch 1: [111/10940] ---- BYOL Training Loss = 0.7383565902709961
29-01-2023 21:35:40 INFO Epoch 1: [122/10940] ---- BYOL Training Loss = 0.7059262990951538
29-01-2023 21:35:58 INFO Epoch 1: [133/10940] ---- BYOL Training Loss = 0.7248938679695129
29-01-2023 21:36:50 INFO Epoch 1: [133/10940] ---- BYOL Validation Loss = 1.4090946912765503
29-01-2023 21:37:07 INFO Epoch 1: [144/10940] ---- BYOL Training Loss = 0.6892465353012085
29-01-2023 21:37:25 INFO Epoch 1: [155/10940] ---- BYOL Training Loss = 0.6755738854408264
29-01-2023 21:37:42 INFO Epoch 1: [166/10940] ---- BYOL Training Loss = 0.6306731104850769
29-01-2023 21:38:00 INFO Epoch 1: [177/10940] ---- BYOL Training Loss = 0.6852617263793945
29-01-2023 21:38:52 INFO Epoch 1: [177/10940] ---- BYOL Validation Loss = 0.7348045110702515
29-01-2023 21:39:09 INFO Epoch 1: [188/10940] ---- BYOL Training Loss = 0.6809324026107788
29-01-2023 21:39:26 INFO Epoch 1: [199/10940] ---- BYOL Training Loss = 0.674277663230896
29-01-2023 21:39:44 INFO Epoch 1: [210/10940] ---- BYOL Training Loss = 0.8231288194656372
29-01-2023 21:40:01 INFO Epoch 1: [221/10940] ---- BYOL Training Loss = 0.8180434107780457
29-01-2023 21:40:54 INFO Epoch 1: [221/10940] ---- BYOL Validation Loss = 2.858131170272827
29-01-2023 21:41:11 INFO Epoch 1: [232/10940] ---- BYOL Training Loss = 0.7803667783737183
29-01-2023 21:41:28 INFO Epoch 1: [243/10940] ---- BYOL Training Loss = 0.7314965128898621
29-01-2023 21:41:46 INFO Epoch 1: [254/10940] ---- BYOL Training Loss = 0.7567728757858276
29-01-2023 21:42:03 INFO Epoch 1: [265/10940] ---- BYOL Training Loss = 0.758009135723114
29-01-2023 21:42:55 INFO Epoch 1: [265/10940] ---- BYOL Validation Loss = 0.9989407658576965
29-01-2023 21:43:12 INFO Epoch 1: [276/10940] ---- BYOL Training Loss = 0.8151691555976868
29-01-2023 21:43:30 INFO Epoch 1: [287/10940] ---- BYOL Training Loss = 0.8381900787353516
29-01-2023 21:43:47 INFO Epoch 1: [298/10940] ---- BYOL Training Loss = 0.8044697046279907
29-01-2023 21:44:05 INFO Epoch 1: [309/10940] ---- BYOL Training Loss = 0.8162544369697571
29-01-2023 21:44:57 INFO Epoch 1: [309/10940] ---- BYOL Validation Loss = 1.4636353254318237
29-01-2023 21:45:14 INFO Epoch 1: [320/10940] ---- BYOL Training Loss = 0.6973451972007751
29-01-2023 21:45:32 INFO Epoch 1: [331/10940] ---- BYOL Training Loss = 0.6471270322799683
29-01-2023 21:45:49 INFO Epoch 1: [342/10940] ---- BYOL Training Loss = 0.7296102046966553
29-01-2023 21:46:07 INFO Epoch 1: [353/10940] ---- BYOL Training Loss = 0.8320842981338501
29-01-2023 21:46:59 INFO Epoch 1: [353/10940] ---- BYOL Validation Loss = 0.791283905506134
29-01-2023 21:47:16 INFO Epoch 1: [364/10940] ---- BYOL Training Loss = 0.8006793856620789
29-01-2023 21:47:34 INFO Epoch 1: [375/10940] ---- BYOL Training Loss = 0.6947535276412964
29-01-2023 21:47:51 INFO Epoch 1: [386/10940] ---- BYOL Training Loss = 0.6783984303474426
29-01-2023 21:48:09 INFO Epoch 1: [397/10940] ---- BYOL Training Loss = 0.6394237279891968
29-01-2023 21:49:01 INFO Epoch 1: [397/10940] ---- BYOL Validation Loss = 2.579054117202759
29-01-2023 21:49:18 INFO Epoch 1: [408/10940] ---- BYOL Training Loss = 0.6897711157798767
29-01-2023 21:49:36 INFO Epoch 1: [419/10940] ---- BYOL Training Loss = 0.6890988945960999
29-01-2023 21:49:54 INFO Epoch 1: [430/10940] ---- BYOL Training Loss = 0.7888877391815186
29-01-2023 21:50:11 INFO Epoch 1: [441/10940] ---- BYOL Training Loss = 0.7390749454498291
29-01-2023 21:51:03 INFO Epoch 1: [441/10940] ---- BYOL Validation Loss = 0.780644416809082
29-01-2023 21:51:20 INFO Epoch 1: [452/10940] ---- BYOL Training Loss = 0.7522759437561035
29-01-2023 21:51:38 INFO Epoch 1: [463/10940] ---- BYOL Training Loss = 0.6919811964035034
29-01-2023 21:51:55 INFO Epoch 1: [474/10940] ---- BYOL Training Loss = 0.6372107267379761
29-01-2023 21:52:13 INFO Epoch 1: [485/10940] ---- BYOL Training Loss = 0.6080434322357178
29-01-2023 21:53:05 INFO Epoch 1: [485/10940] ---- BYOL Validation Loss = 0.6184786558151245
29-01-2023 21:53:22 INFO Epoch 1: [496/10940] ---- BYOL Training Loss = 0.5749306678771973
29-01-2023 21:53:40 INFO Epoch 1: [507/10940] ---- BYOL Training Loss = 0.6364514231681824
29-01-2023 21:53:57 INFO Epoch 1: [518/10940] ---- BYOL Training Loss = 0.7180651426315308
29-01-2023 21:54:15 INFO Epoch 1: [529/10940] ---- BYOL Training Loss = 0.7604098916053772
29-01-2023 21:55:07 INFO Epoch 1: [529/10940] ---- BYOL Validation Loss = 2.7299959659576416
29-01-2023 21:55:24 INFO Epoch 1: [540/10940] ---- BYOL Training Loss = 0.7582073211669922
29-01-2023 21:55:42 INFO Epoch 1: [551/10940] ---- BYOL Training Loss = 0.5950566530227661
29-01-2023 21:55:59 INFO Epoch 1: [562/10940] ---- BYOL Training Loss = 0.658406138420105
29-01-2023 21:56:17 INFO Epoch 1: [573/10940] ---- BYOL Training Loss = 0.6659391522407532
29-01-2023 21:57:09 INFO Epoch 1: [573/10940] ---- BYOL Validation Loss = 0.6561278104782104
29-01-2023 21:57:26 INFO Epoch 1: [584/10940] ---- BYOL Training Loss = 0.6273179054260254
29-01-2023 21:57:44 INFO Epoch 1: [595/10940] ---- BYOL Training Loss = 0.6525771021842957
29-01-2023 21:58:01 INFO Epoch 1: [606/10940] ---- BYOL Training Loss = 0.6166059374809265
29-01-2023 21:58:19 INFO Epoch 1: [617/10940] ---- BYOL Training Loss = 0.6169113516807556
29-01-2023 21:59:11 INFO Epoch 1: [617/10940] ---- BYOL Validation Loss = 0.656794548034668
29-01-2023 21:59:28 INFO Epoch 1: [628/10940] ---- BYOL Training Loss = 0.6792401075363159
29-01-2023 21:59:45 INFO Epoch 1: [639/10940] ---- BYOL Training Loss = 0.6631357669830322
29-01-2023 22:00:03 INFO Epoch 1: [650/10940] ---- BYOL Training Loss = 0.717761754989624
29-01-2023 22:00:20 INFO Epoch 1: [661/10940] ---- BYOL Training Loss = 0.7413030862808228
29-01-2023 22:01:13 INFO Epoch 1: [661/10940] ---- BYOL Validation Loss = 0.6362408399581909
29-01-2023 22:01:30 INFO Epoch 1: [672/10940] ---- BYOL Training Loss = 0.6940759420394897
29-01-2023 22:01:47 INFO Epoch 1: [683/10940] ---- BYOL Training Loss = 0.7553516626358032
29-01-2023 22:02:05 INFO Epoch 1: [694/10940] ---- BYOL Training Loss = 0.7010955810546875
29-01-2023 22:02:22 INFO Epoch 1: [705/10940] ---- BYOL Training Loss = 0.5736919045448303
29-01-2023 22:03:14 INFO Epoch 1: [705/10940] ---- BYOL Validation Loss = 0.7096373438835144
29-01-2023 22:03:32 INFO Epoch 1: [716/10940] ---- BYOL Training Loss = 0.6096993684768677
29-01-2023 22:03:49 INFO Epoch 1: [727/10940] ---- BYOL Training Loss = 0.5719941854476929
29-01-2023 22:04:07 INFO Epoch 1: [738/10940] ---- BYOL Training Loss = 0.5869448184967041
29-01-2023 22:04:24 INFO Epoch 1: [749/10940] ---- BYOL Training Loss = 0.6623553037643433
29-01-2023 22:05:16 INFO Epoch 1: [749/10940] ---- BYOL Validation Loss = 0.5750141143798828
29-01-2023 22:05:33 INFO Epoch 1: [760/10940] ---- BYOL Training Loss = 0.6156536340713501
29-01-2023 22:05:51 INFO Epoch 1: [771/10940] ---- BYOL Training Loss = 0.6095134019851685
29-01-2023 22:06:09 INFO Epoch 1: [782/10940] ---- BYOL Training Loss = 0.562390923500061
29-01-2023 22:06:26 INFO Epoch 1: [793/10940] ---- BYOL Training Loss = 0.5588196516036987
29-01-2023 22:07:18 INFO Epoch 1: [793/10940] ---- BYOL Validation Loss = 0.5822973847389221
29-01-2023 22:07:36 INFO Epoch 1: [804/10940] ---- BYOL Training Loss = 0.6643484830856323
29-01-2023 22:07:53 INFO Epoch 1: [815/10940] ---- BYOL Training Loss = 0.6096609234809875
29-01-2023 22:08:11 INFO Epoch 1: [826/10940] ---- BYOL Training Loss = 0.549923837184906
29-01-2023 22:08:29 INFO Epoch 1: [837/10940] ---- BYOL Training Loss = 0.5904194712638855
29-01-2023 22:09:21 INFO Epoch 1: [837/10940] ---- BYOL Validation Loss = 0.5999728441238403
29-01-2023 22:09:38 INFO Epoch 1: [848/10940] ---- BYOL Training Loss = 0.6559919118881226
29-01-2023 22:09:56 INFO Epoch 1: [859/10940] ---- BYOL Training Loss = 0.5983378291130066
29-01-2023 22:10:13 INFO Epoch 1: [870/10940] ---- BYOL Training Loss = 0.560372531414032
29-01-2023 22:10:31 INFO Epoch 1: [881/10940] ---- BYOL Training Loss = 0.6713458895683289
29-01-2023 22:11:23 INFO Epoch 1: [881/10940] ---- BYOL Validation Loss = 0.5751763582229614
29-01-2023 22:11:41 INFO Epoch 1: [892/10940] ---- BYOL Training Loss = 0.6459733843803406
29-01-2023 22:11:59 INFO Epoch 1: [903/10940] ---- BYOL Training Loss = 0.5076044797897339
29-01-2023 22:12:16 INFO Epoch 1: [914/10940] ---- BYOL Training Loss = 0.4884171485900879
29-01-2023 22:12:34 INFO Epoch 1: [925/10940] ---- BYOL Training Loss = 0.5077741146087646
29-01-2023 22:13:26 INFO Epoch 1: [925/10940] ---- BYOL Validation Loss = 0.5931726694107056
29-01-2023 22:13:43 INFO Epoch 1: [936/10940] ---- BYOL Training Loss = 0.5700618028640747
29-01-2023 22:14:01 INFO Epoch 1: [947/10940] ---- BYOL Training Loss = 0.5305298566818237
29-01-2023 22:14:18 INFO Epoch 1: [958/10940] ---- BYOL Training Loss = 0.5395239591598511
29-01-2023 22:14:36 INFO Epoch 1: [969/10940] ---- BYOL Training Loss = 0.5123476386070251
29-01-2023 22:15:28 INFO Epoch 1: [969/10940] ---- BYOL Validation Loss = 0.5535212159156799
29-01-2023 22:15:46 INFO Epoch 1: [980/10940] ---- BYOL Training Loss = 0.5324078798294067
29-01-2023 22:16:03 INFO Epoch 1: [991/10940] ---- BYOL Training Loss = 0.6099894046783447
29-01-2023 22:16:21 INFO Epoch 1: [1002/10940] ---- BYOL Training Loss = 0.5544880032539368
29-01-2023 22:16:39 INFO Epoch 1: [1013/10940] ---- BYOL Training Loss = 0.5425275564193726
29-01-2023 22:17:31 INFO Epoch 1: [1013/10940] ---- BYOL Validation Loss = 0.6230215430259705
29-01-2023 22:17:48 INFO Epoch 1: [1024/10940] ---- BYOL Training Loss = 0.6050281524658203
29-01-2023 22:18:06 INFO Epoch 1: [1035/10940] ---- BYOL Training Loss = 0.6102483868598938
29-01-2023 22:18:23 INFO Epoch 1: [1046/10940] ---- BYOL Training Loss = 0.6015822887420654
29-01-2023 22:18:41 INFO Epoch 1: [1057/10940] ---- BYOL Training Loss = 0.6136354207992554
29-01-2023 22:19:33 INFO Epoch 1: [1057/10940] ---- BYOL Validation Loss = 2.82674241065979
29-01-2023 22:19:50 INFO Epoch 1: [1068/10940] ---- BYOL Training Loss = 0.6113415956497192
29-01-2023 22:20:08 INFO Epoch 1: [1079/10940] ---- BYOL Training Loss = 0.5540263652801514
29-01-2023 22:20:25 INFO Epoch 1: [1090/10940] ---- BYOL Training Loss = 0.5822718143463135
29-01-2023 22:20:43 INFO Epoch 1: [1101/10940] ---- BYOL Training Loss = 0.6397886276245117
29-01-2023 22:21:35 INFO Epoch 1: [1101/10940] ---- BYOL Validation Loss = 1.583997130393982
29-01-2023 22:21:52 INFO Epoch 1: [1112/10940] ---- BYOL Training Loss = 0.5851215124130249
29-01-2023 22:22:10 INFO Epoch 1: [1123/10940] ---- BYOL Training Loss = 0.5070047378540039
29-01-2023 22:22:28 INFO Epoch 1: [1134/10940] ---- BYOL Training Loss = 0.5332735776901245
29-01-2023 22:22:45 INFO Epoch 1: [1145/10940] ---- BYOL Training Loss = 0.5003433227539062
29-01-2023 22:23:37 INFO Epoch 1: [1145/10940] ---- BYOL Validation Loss = 0.5492797493934631
29-01-2023 22:23:55 INFO Epoch 1: [1156/10940] ---- BYOL Training Loss = 0.5767233371734619
29-01-2023 22:24:12 INFO Epoch 1: [1167/10940] ---- BYOL Training Loss = 0.5881839394569397
29-01-2023 22:24:30 INFO Epoch 1: [1178/10940] ---- BYOL Training Loss = 0.5968266725540161
29-01-2023 22:24:48 INFO Epoch 1: [1189/10940] ---- BYOL Training Loss = 0.577407717704773
29-01-2023 22:25:40 INFO Epoch 1: [1189/10940] ---- BYOL Validation Loss = 0.6782410740852356
29-01-2023 22:25:57 INFO Epoch 1: [1200/10940] ---- BYOL Training Loss = 0.5111626386642456
29-01-2023 22:26:15 INFO Epoch 1: [1211/10940] ---- BYOL Training Loss = 0.47459760308265686
29-01-2023 22:26:32 INFO Epoch 1: [1222/10940] ---- BYOL Training Loss = 0.53397536277771
29-01-2023 22:26:50 INFO Epoch 1: [1233/10940] ---- BYOL Training Loss = 0.5280040502548218
29-01-2023 22:27:42 INFO Epoch 1: [1233/10940] ---- BYOL Validation Loss = 0.8433249592781067
29-01-2023 22:27:59 INFO Epoch 1: [1244/10940] ---- BYOL Training Loss = 0.5379085540771484
29-01-2023 22:28:17 INFO Epoch 1: [1255/10940] ---- BYOL Training Loss = 0.54911208152771
29-01-2023 22:28:34 INFO Epoch 1: [1266/10940] ---- BYOL Training Loss = 0.5875737071037292
29-01-2023 22:28:52 INFO Epoch 1: [1277/10940] ---- BYOL Training Loss = 0.5080921053886414
29-01-2023 22:29:44 INFO Epoch 1: [1277/10940] ---- BYOL Validation Loss = 0.5368608236312866
29-01-2023 22:30:02 INFO Epoch 1: [1288/10940] ---- BYOL Training Loss = 0.4575660824775696
29-01-2023 22:30:19 INFO Epoch 1: [1299/10940] ---- BYOL Training Loss = 0.5807598829269409
29-01-2023 22:30:37 INFO Epoch 1: [1310/10940] ---- BYOL Training Loss = 0.6192296743392944
29-01-2023 22:30:54 INFO Epoch 1: [1321/10940] ---- BYOL Training Loss = 0.529060959815979
29-01-2023 22:31:47 INFO Epoch 1: [1321/10940] ---- BYOL Validation Loss = 0.5707369446754456
29-01-2023 22:32:04 INFO Epoch 1: [1332/10940] ---- BYOL Training Loss = 0.4622153639793396
29-01-2023 22:32:22 INFO Epoch 1: [1343/10940] ---- BYOL Training Loss = 0.4652791917324066
29-01-2023 22:32:39 INFO Epoch 1: [1354/10940] ---- BYOL Training Loss = 0.4934767782688141
29-01-2023 22:32:57 INFO Epoch 1: [1365/10940] ---- BYOL Training Loss = 0.5227595567703247
29-01-2023 22:33:49 INFO Epoch 1: [1365/10940] ---- BYOL Validation Loss = 0.5729407072067261
29-01-2023 22:34:06 INFO Epoch 1: [1376/10940] ---- BYOL Training Loss = 0.5611333847045898
29-01-2023 22:34:24 INFO Epoch 1: [1387/10940] ---- BYOL Training Loss = 0.5977568030357361
29-01-2023 22:34:41 INFO Epoch 1: [1398/10940] ---- BYOL Training Loss = 0.5334457755088806
29-01-2023 22:34:59 INFO Epoch 1: [1409/10940] ---- BYOL Training Loss = 0.5530482530593872
29-01-2023 22:35:51 INFO Epoch 1: [1409/10940] ---- BYOL Validation Loss = 0.5936635136604309
29-01-2023 22:36:08 INFO Epoch 1: [1420/10940] ---- BYOL Training Loss = 0.5800420641899109
29-01-2023 22:36:26 INFO Epoch 1: [1431/10940] ---- BYOL Training Loss = 0.5079898238182068
29-01-2023 22:36:44 INFO Epoch 1: [1442/10940] ---- BYOL Training Loss = 0.5257997512817383
29-01-2023 22:37:01 INFO Epoch 1: [1453/10940] ---- BYOL Training Loss = 0.5455020070075989
29-01-2023 22:37:53 INFO Epoch 1: [1453/10940] ---- BYOL Validation Loss = 0.5486651062965393
29-01-2023 22:38:11 INFO Epoch 1: [1464/10940] ---- BYOL Training Loss = 0.519316554069519
29-01-2023 22:38:28 INFO Epoch 1: [1475/10940] ---- BYOL Training Loss = 0.5216060876846313
29-01-2023 22:38:46 INFO Epoch 1: [1486/10940] ---- BYOL Training Loss = 0.48419785499572754
29-01-2023 22:39:03 INFO Epoch 1: [1497/10940] ---- BYOL Training Loss = 0.44841867685317993
29-01-2023 22:39:56 INFO Epoch 1: [1497/10940] ---- BYOL Validation Loss = 0.5257928967475891
29-01-2023 22:40:13 INFO Epoch 1: [1508/10940] ---- BYOL Training Loss = 0.5103557705879211
29-01-2023 22:40:30 INFO Epoch 1: [1519/10940] ---- BYOL Training Loss = 0.4454900622367859
29-01-2023 22:40:48 INFO Epoch 1: [1530/10940] ---- BYOL Training Loss = 0.5251191854476929
29-01-2023 22:41:06 INFO Epoch 1: [1541/10940] ---- BYOL Training Loss = 0.6072582602500916
29-01-2023 22:41:58 INFO Epoch 1: [1541/10940] ---- BYOL Validation Loss = 0.5269923806190491
29-01-2023 22:42:16 INFO Epoch 1: [1552/10940] ---- BYOL Training Loss = 0.6195293068885803
29-01-2023 22:42:33 INFO Epoch 1: [1563/10940] ---- BYOL Training Loss = 0.6219892501831055
29-01-2023 22:42:51 INFO Epoch 1: [1574/10940] ---- BYOL Training Loss = 0.5808584094047546
29-01-2023 22:43:08 INFO Epoch 1: [1585/10940] ---- BYOL Training Loss = 0.5742824077606201
29-01-2023 22:44:01 INFO Epoch 1: [1585/10940] ---- BYOL Validation Loss = 1.9393266439437866
29-01-2023 22:44:18 INFO Epoch 1: [1596/10940] ---- BYOL Training Loss = 0.5286842584609985
29-01-2023 22:44:36 INFO Epoch 1: [1607/10940] ---- BYOL Training Loss = 0.4367595613002777
29-01-2023 22:44:53 INFO Epoch 1: [1618/10940] ---- BYOL Training Loss = 0.45778435468673706
29-01-2023 22:45:11 INFO Epoch 1: [1629/10940] ---- BYOL Training Loss = 0.5121866464614868
29-01-2023 22:46:03 INFO Epoch 1: [1629/10940] ---- BYOL Validation Loss = 0.5482140183448792
29-01-2023 22:46:21 INFO Epoch 1: [1640/10940] ---- BYOL Training Loss = 0.5527194738388062
29-01-2023 22:46:38 INFO Epoch 1: [1651/10940] ---- BYOL Training Loss = 0.5783920884132385
29-01-2023 22:46:56 INFO Epoch 1: [1662/10940] ---- BYOL Training Loss = 0.5062333345413208
29-01-2023 22:47:14 INFO Epoch 1: [1673/10940] ---- BYOL Training Loss = 0.46487680077552795
29-01-2023 22:48:06 INFO Epoch 1: [1673/10940] ---- BYOL Validation Loss = 0.512813925743103
29-01-2023 22:48:23 INFO Epoch 1: [1684/10940] ---- BYOL Training Loss = 0.43400755524635315
29-01-2023 22:48:41 INFO Epoch 1: [1695/10940] ---- BYOL Training Loss = 0.451212078332901
29-01-2023 22:48:58 INFO Epoch 1: [1706/10940] ---- BYOL Training Loss = 0.49694475531578064
29-01-2023 22:49:16 INFO Epoch 1: [1717/10940] ---- BYOL Training Loss = 0.48106732964515686
29-01-2023 22:50:08 INFO Epoch 1: [1717/10940] ---- BYOL Validation Loss = 0.5065956115722656
29-01-2023 22:50:25 INFO Epoch 1: [1728/10940] ---- BYOL Training Loss = 0.5046793222427368
29-01-2023 22:50:43 INFO Epoch 1: [1739/10940] ---- BYOL Training Loss = 0.5053870677947998
29-01-2023 22:51:01 INFO Epoch 1: [1750/10940] ---- BYOL Training Loss = 0.5417965650558472
29-01-2023 22:51:19 INFO Epoch 1: [1761/10940] ---- BYOL Training Loss = 0.4899527430534363
29-01-2023 22:52:11 INFO Epoch 1: [1761/10940] ---- BYOL Validation Loss = 0.5518035292625427
29-01-2023 22:52:28 INFO Epoch 1: [1772/10940] ---- BYOL Training Loss = 0.43921732902526855
29-01-2023 22:52:46 INFO Epoch 1: [1783/10940] ---- BYOL Training Loss = 0.5261326432228088
29-01-2023 22:53:03 INFO Epoch 1: [1794/10940] ---- BYOL Training Loss = 0.5661340355873108
29-01-2023 22:53:21 INFO Epoch 1: [1805/10940] ---- BYOL Training Loss = 0.6096072196960449
29-01-2023 22:54:13 INFO Epoch 1: [1805/10940] ---- BYOL Validation Loss = 0.5336772203445435
29-01-2023 22:54:31 INFO Epoch 1: [1816/10940] ---- BYOL Training Loss = 0.6063779592514038
29-01-2023 22:54:48 INFO Epoch 1: [1827/10940] ---- BYOL Training Loss = 0.5162221789360046
29-01-2023 22:55:06 INFO Epoch 1: [1838/10940] ---- BYOL Training Loss = 0.4821397364139557
29-01-2023 22:55:24 INFO Epoch 1: [1849/10940] ---- BYOL Training Loss = 0.49657565355300903
29-01-2023 22:56:16 INFO Epoch 1: [1849/10940] ---- BYOL Validation Loss = 0.541496217250824
29-01-2023 22:56:33 INFO Epoch 1: [1860/10940] ---- BYOL Training Loss = 0.5131534934043884
29-01-2023 22:56:51 INFO Epoch 1: [1871/10940] ---- BYOL Training Loss = 0.48952898383140564
29-01-2023 22:57:09 INFO Epoch 1: [1882/10940] ---- BYOL Training Loss = 0.4535701870918274
29-01-2023 22:57:26 INFO Epoch 1: [1893/10940] ---- BYOL Training Loss = 0.5067415833473206
29-01-2023 22:58:19 INFO Epoch 1: [1893/10940] ---- BYOL Validation Loss = 0.5285746455192566
29-01-2023 22:58:36 INFO Epoch 1: [1904/10940] ---- BYOL Training Loss = 0.5657922029495239
29-01-2023 22:58:54 INFO Epoch 1: [1915/10940] ---- BYOL Training Loss = 0.5006723403930664
29-01-2023 22:59:12 INFO Epoch 1: [1926/10940] ---- BYOL Training Loss = 0.48951274156570435
29-01-2023 22:59:30 INFO Epoch 1: [1937/10940] ---- BYOL Training Loss = 0.47768130898475647
29-01-2023 23:00:22 INFO Epoch 1: [1937/10940] ---- BYOL Validation Loss = 0.5539087057113647
29-01-2023 23:00:39 INFO Epoch 1: [1948/10940] ---- BYOL Training Loss = 0.4747944474220276
29-01-2023 23:00:57 INFO Epoch 1: [1959/10940] ---- BYOL Training Loss = 0.5286095142364502
29-01-2023 23:01:15 INFO Epoch 1: [1970/10940] ---- BYOL Training Loss = 0.5297150611877441
29-01-2023 23:01:32 INFO Epoch 1: [1981/10940] ---- BYOL Training Loss = 0.501610279083252
29-01-2023 23:02:25 INFO Epoch 1: [1981/10940] ---- BYOL Validation Loss = 0.5204190015792847
29-01-2023 23:02:42 INFO Epoch 1: [1992/10940] ---- BYOL Training Loss = 0.5580549240112305
29-01-2023 23:03:00 INFO Epoch 1: [2003/10940] ---- BYOL Training Loss = 0.5774914026260376
29-01-2023 23:03:17 INFO Epoch 1: [2014/10940] ---- BYOL Training Loss = 0.529544472694397
29-01-2023 23:03:35 INFO Epoch 1: [2025/10940] ---- BYOL Training Loss = 0.5468320846557617
29-01-2023 23:04:27 INFO Epoch 1: [2025/10940] ---- BYOL Validation Loss = 0.5198662877082825
29-01-2023 23:04:45 INFO Epoch 1: [2036/10940] ---- BYOL Training Loss = 0.5246627926826477
29-01-2023 23:05:02 INFO Epoch 1: [2047/10940] ---- BYOL Training Loss = 0.5069894790649414
29-01-2023 23:05:20 INFO Epoch 1: [2058/10940] ---- BYOL Training Loss = 0.5519524812698364
29-01-2023 23:05:38 INFO Epoch 1: [2069/10940] ---- BYOL Training Loss = 0.5041183829307556
29-01-2023 23:06:30 INFO Epoch 1: [2069/10940] ---- BYOL Validation Loss = 0.49936559796333313
29-01-2023 23:06:47 INFO Epoch 1: [2080/10940] ---- BYOL Training Loss = 0.5288453102111816
29-01-2023 23:07:05 INFO Epoch 1: [2091/10940] ---- BYOL Training Loss = 0.4517977833747864
29-01-2023 23:07:23 INFO Epoch 1: [2102/10940] ---- BYOL Training Loss = 0.4794742465019226
29-01-2023 23:07:41 INFO Epoch 1: [2113/10940] ---- BYOL Training Loss = 0.5354098081588745
29-01-2023 23:08:33 INFO Epoch 1: [2113/10940] ---- BYOL Validation Loss = 0.5581479072570801
29-01-2023 23:08:50 INFO Epoch 1: [2124/10940] ---- BYOL Training Loss = 0.46192771196365356
29-01-2023 23:09:08 INFO Epoch 1: [2135/10940] ---- BYOL Training Loss = 0.5274753570556641
29-01-2023 23:09:26 INFO Epoch 1: [2146/10940] ---- BYOL Training Loss = 0.5595493912696838
29-01-2023 23:09:43 INFO Epoch 1: [2157/10940] ---- BYOL Training Loss = 0.5464050769805908
29-01-2023 23:10:35 INFO Epoch 1: [2157/10940] ---- BYOL Validation Loss = 0.5037657022476196
29-01-2023 23:10:53 INFO Epoch 1: [2168/10940] ---- BYOL Training Loss = 0.5762045383453369
29-01-2023 23:11:10 INFO Epoch 1: [2179/10940] ---- BYOL Training Loss = 0.5636669397354126
29-01-2023 23:11:28 INFO Epoch 1: [2190/10940] ---- BYOL Training Loss = 0.4908265173435211
29-01-2023 23:11:46 INFO Epoch 1: [2201/10940] ---- BYOL Training Loss = 0.40913325548171997
29-01-2023 23:12:38 INFO Epoch 1: [2201/10940] ---- BYOL Validation Loss = 0.4554460644721985
29-01-2023 23:12:55 INFO Epoch 1: [2212/10940] ---- BYOL Training Loss = 0.4705687463283539
29-01-2023 23:13:13 INFO Epoch 1: [2223/10940] ---- BYOL Training Loss = 0.5367251634597778
29-01-2023 23:13:31 INFO Epoch 1: [2234/10940] ---- BYOL Training Loss = 0.5262469053268433
29-01-2023 23:13:49 INFO Epoch 1: [2245/10940] ---- BYOL Training Loss = 0.5366209745407104
29-01-2023 23:14:41 INFO Epoch 1: [2245/10940] ---- BYOL Validation Loss = 0.4957595467567444
29-01-2023 23:14:58 INFO Epoch 1: [2256/10940] ---- BYOL Training Loss = 0.49580803513526917
29-01-2023 23:15:16 INFO Epoch 1: [2267/10940] ---- BYOL Training Loss = 0.5282970666885376
29-01-2023 23:15:33 INFO Epoch 1: [2278/10940] ---- BYOL Training Loss = 0.5476730465888977
29-01-2023 23:15:51 INFO Epoch 1: [2289/10940] ---- BYOL Training Loss = 0.5839318037033081
29-01-2023 23:16:43 INFO Epoch 1: [2289/10940] ---- BYOL Validation Loss = 0.5536589026451111
29-01-2023 23:17:00 INFO Epoch 1: [2300/10940] ---- BYOL Training Loss = 0.5081826448440552
29-01-2023 23:17:18 INFO Epoch 1: [2311/10940] ---- BYOL Training Loss = 0.48067277669906616
29-01-2023 23:17:36 INFO Epoch 1: [2322/10940] ---- BYOL Training Loss = 0.5302733182907104
29-01-2023 23:17:53 INFO Epoch 1: [2333/10940] ---- BYOL Training Loss = 0.5506930947303772
29-01-2023 23:18:46 INFO Epoch 1: [2333/10940] ---- BYOL Validation Loss = 0.49014443159103394
29-01-2023 23:19:03 INFO Epoch 1: [2344/10940] ---- BYOL Training Loss = 0.5553985834121704
29-01-2023 23:19:21 INFO Epoch 1: [2355/10940] ---- BYOL Training Loss = 0.4399310052394867
29-01-2023 23:19:39 INFO Epoch 1: [2366/10940] ---- BYOL Training Loss = 0.33006295561790466
29-01-2023 23:19:57 INFO Epoch 1: [2377/10940] ---- BYOL Training Loss = 0.42263665795326233
29-01-2023 23:20:49 INFO Epoch 1: [2377/10940] ---- BYOL Validation Loss = 0.5280377864837646
29-01-2023 23:21:06 INFO Epoch 1: [2388/10940] ---- BYOL Training Loss = 0.5823942422866821
29-01-2023 23:21:24 INFO Epoch 1: [2399/10940] ---- BYOL Training Loss = 0.48711681365966797
29-01-2023 23:21:41 INFO Epoch 1: [2410/10940] ---- BYOL Training Loss = 0.36796554923057556
29-01-2023 23:21:59 INFO Epoch 1: [2421/10940] ---- BYOL Training Loss = 0.4021502137184143
29-01-2023 23:22:51 INFO Epoch 1: [2421/10940] ---- BYOL Validation Loss = 0.7131580710411072
29-01-2023 23:23:09 INFO Epoch 1: [2432/10940] ---- BYOL Training Loss = 0.4880805015563965
29-01-2023 23:23:26 INFO Epoch 1: [2443/10940] ---- BYOL Training Loss = 0.5907588005065918
29-01-2023 23:23:44 INFO Epoch 1: [2454/10940] ---- BYOL Training Loss = 0.5504454374313354
29-01-2023 23:24:02 INFO Epoch 1: [2465/10940] ---- BYOL Training Loss = 0.5213165879249573
29-01-2023 23:24:54 INFO Epoch 1: [2465/10940] ---- BYOL Validation Loss = 0.5171816945075989
29-01-2023 23:25:12 INFO Epoch 1: [2476/10940] ---- BYOL Training Loss = 0.4920137822628021
29-01-2023 23:25:29 INFO Epoch 1: [2487/10940] ---- BYOL Training Loss = 0.5464238524436951
29-01-2023 23:25:47 INFO Epoch 1: [2498/10940] ---- BYOL Training Loss = 0.5427899956703186
29-01-2023 23:26:05 INFO Epoch 1: [2509/10940] ---- BYOL Training Loss = 0.460681289434433
29-01-2023 23:26:57 INFO Epoch 1: [2509/10940] ---- BYOL Validation Loss = 0.49369746446609497
29-01-2023 23:27:14 INFO Epoch 1: [2520/10940] ---- BYOL Training Loss = 0.43389207124710083
29-01-2023 23:27:32 INFO Epoch 1: [2531/10940] ---- BYOL Training Loss = 0.41447681188583374
29-01-2023 23:27:50 INFO Epoch 1: [2542/10940] ---- BYOL Training Loss = 0.5424588322639465
29-01-2023 23:28:07 INFO Epoch 1: [2553/10940] ---- BYOL Training Loss = 0.5631344318389893
29-01-2023 23:28:59 INFO Epoch 1: [2553/10940] ---- BYOL Validation Loss = 0.48691630363464355
29-01-2023 23:29:17 INFO Epoch 1: [2564/10940] ---- BYOL Training Loss = 0.5382476449012756
29-01-2023 23:29:34 INFO Epoch 1: [2575/10940] ---- BYOL Training Loss = 0.5293325185775757
29-01-2023 23:29:53 INFO Epoch 1: [2586/10940] ---- BYOL Training Loss = 0.4773755967617035
29-01-2023 23:30:10 INFO Epoch 1: [2597/10940] ---- BYOL Training Loss = 0.5321946144104004
29-01-2023 23:31:02 INFO Epoch 1: [2597/10940] ---- BYOL Validation Loss = 0.5369937419891357
29-01-2023 23:31:20 INFO Epoch 1: [2608/10940] ---- BYOL Training Loss = 0.544908881187439
29-01-2023 23:31:37 INFO Epoch 1: [2619/10940] ---- BYOL Training Loss = 0.4530150890350342
29-01-2023 23:31:55 INFO Epoch 1: [2630/10940] ---- BYOL Training Loss = 0.4002918601036072
29-01-2023 23:32:13 INFO Epoch 1: [2641/10940] ---- BYOL Training Loss = 0.5087289214134216
29-01-2023 23:33:05 INFO Epoch 1: [2641/10940] ---- BYOL Validation Loss = 0.5083419680595398
29-01-2023 23:33:22 INFO Epoch 1: [2652/10940] ---- BYOL Training Loss = 0.5799673795700073
29-01-2023 23:33:40 INFO Epoch 1: [2663/10940] ---- BYOL Training Loss = 0.5632954239845276
29-01-2023 23:33:58 INFO Epoch 1: [2674/10940] ---- BYOL Training Loss = 0.5527245998382568
29-01-2023 23:34:15 INFO Epoch 1: [2685/10940] ---- BYOL Training Loss = 0.5039618611335754
29-01-2023 23:35:08 INFO Epoch 1: [2685/10940] ---- BYOL Validation Loss = 0.492400586605072
29-01-2023 23:35:25 INFO Epoch 1: [2696/10940] ---- BYOL Training Loss = 0.47034555673599243
29-01-2023 23:35:43 INFO Epoch 1: [2707/10940] ---- BYOL Training Loss = 0.45218029618263245
29-01-2023 23:36:01 INFO Epoch 1: [2718/10940] ---- BYOL Training Loss = 0.48862919211387634
29-01-2023 23:36:19 INFO Epoch 1: [2729/10940] ---- BYOL Training Loss = 0.4971230924129486
29-01-2023 23:37:11 INFO Epoch 1: [2729/10940] ---- BYOL Validation Loss = 0.5300586819648743
29-01-2023 23:37:28 INFO Epoch 1: [2740/10940] ---- BYOL Training Loss = 0.47010716795921326
29-01-2023 23:37:46 INFO Epoch 1: [2751/10940] ---- BYOL Training Loss = 0.49127474427223206
29-01-2023 23:38:04 INFO Epoch 1: [2762/10940] ---- BYOL Training Loss = 0.47578081488609314
29-01-2023 23:38:21 INFO Epoch 1: [2773/10940] ---- BYOL Training Loss = 0.5331047773361206
29-01-2023 23:39:14 INFO Epoch 1: [2773/10940] ---- BYOL Validation Loss = 0.5131716728210449
29-01-2023 23:39:31 INFO Epoch 1: [2784/10940] ---- BYOL Training Loss = 0.4459684491157532
29-01-2023 23:39:49 INFO Epoch 1: [2795/10940] ---- BYOL Training Loss = 0.4678000807762146
29-01-2023 23:40:07 INFO Epoch 1: [2806/10940] ---- BYOL Training Loss = 0.5117091536521912
29-01-2023 23:40:25 INFO Epoch 1: [2817/10940] ---- BYOL Training Loss = 0.5047480463981628
29-01-2023 23:41:17 INFO Epoch 1: [2817/10940] ---- BYOL Validation Loss = 0.4920671880245209
29-01-2023 23:41:34 INFO Epoch 1: [2828/10940] ---- BYOL Training Loss = 0.6176409125328064
29-01-2023 23:41:52 INFO Epoch 1: [2839/10940] ---- BYOL Training Loss = 0.5401657819747925
29-01-2023 23:42:10 INFO Epoch 1: [2850/10940] ---- BYOL Training Loss = 0.5300150513648987
29-01-2023 23:42:27 INFO Epoch 1: [2861/10940] ---- BYOL Training Loss = 0.5502497553825378
29-01-2023 23:43:20 INFO Epoch 1: [2861/10940] ---- BYOL Validation Loss = 0.6982024312019348
29-01-2023 23:43:37 INFO Epoch 1: [2872/10940] ---- BYOL Training Loss = 0.5048516392707825
29-01-2023 23:43:55 INFO Epoch 1: [2883/10940] ---- BYOL Training Loss = 0.5054312348365784
29-01-2023 23:44:13 INFO Epoch 1: [2894/10940] ---- BYOL Training Loss = 0.4553011953830719
29-01-2023 23:44:31 INFO Epoch 1: [2905/10940] ---- BYOL Training Loss = 0.4293832778930664
29-01-2023 23:45:23 INFO Epoch 1: [2905/10940] ---- BYOL Validation Loss = 0.5023387670516968
29-01-2023 23:45:40 INFO Epoch 1: [2916/10940] ---- BYOL Training Loss = 0.4820345342159271
29-01-2023 23:45:58 INFO Epoch 1: [2927/10940] ---- BYOL Training Loss = 0.49778780341148376
29-01-2023 23:46:16 INFO Epoch 1: [2938/10940] ---- BYOL Training Loss = 0.45772814750671387
29-01-2023 23:46:34 INFO Epoch 1: [2949/10940] ---- BYOL Training Loss = 0.47082382440567017
29-01-2023 23:47:26 INFO Epoch 1: [2949/10940] ---- BYOL Validation Loss = 0.5359088182449341
29-01-2023 23:47:43 INFO Epoch 1: [2960/10940] ---- BYOL Training Loss = 0.5341933965682983
29-01-2023 23:48:01 INFO Epoch 1: [2971/10940] ---- BYOL Training Loss = 0.5933769941329956
29-01-2023 23:48:19 INFO Epoch 1: [2982/10940] ---- BYOL Training Loss = 0.5445102453231812
29-01-2023 23:48:37 INFO Epoch 1: [2993/10940] ---- BYOL Training Loss = 0.488886296749115
29-01-2023 23:49:29 INFO Epoch 1: [2993/10940] ---- BYOL Validation Loss = 0.5113676190376282
29-01-2023 23:49:46 INFO Epoch 1: [3004/10940] ---- BYOL Training Loss = 0.4588063657283783
29-01-2023 23:50:04 INFO Epoch 1: [3015/10940] ---- BYOL Training Loss = 0.47393250465393066
29-01-2023 23:50:22 INFO Epoch 1: [3026/10940] ---- BYOL Training Loss = 0.5513067245483398
29-01-2023 23:50:40 INFO Epoch 1: [3037/10940] ---- BYOL Training Loss = 0.5728867053985596
29-01-2023 23:51:32 INFO Epoch 1: [3037/10940] ---- BYOL Validation Loss = 0.4867953658103943
29-01-2023 23:51:50 INFO Epoch 1: [3048/10940] ---- BYOL Training Loss = 0.6359583139419556
29-01-2023 23:52:08 INFO Epoch 1: [3059/10940] ---- BYOL Training Loss = 0.5624147057533264
29-01-2023 23:52:26 INFO Epoch 1: [3070/10940] ---- BYOL Training Loss = 0.4829701781272888
29-01-2023 23:52:43 INFO Epoch 1: [3081/10940] ---- BYOL Training Loss = 0.46182146668434143
29-01-2023 23:53:36 INFO Epoch 1: [3081/10940] ---- BYOL Validation Loss = 0.506950318813324
29-01-2023 23:53:53 INFO Epoch 1: [3092/10940] ---- BYOL Training Loss = 0.4947195053100586
29-01-2023 23:54:11 INFO Epoch 1: [3103/10940] ---- BYOL Training Loss = 0.46577247977256775
29-01-2023 23:54:29 INFO Epoch 1: [3114/10940] ---- BYOL Training Loss = 0.4992777705192566
29-01-2023 23:54:46 INFO Epoch 1: [3125/10940] ---- BYOL Training Loss = 0.6025437116622925
29-01-2023 23:55:39 INFO Epoch 1: [3125/10940] ---- BYOL Validation Loss = 0.47364649176597595
29-01-2023 23:55:56 INFO Epoch 1: [3136/10940] ---- BYOL Training Loss = 0.5818313360214233
29-01-2023 23:56:14 INFO Epoch 1: [3147/10940] ---- BYOL Training Loss = 0.5169556736946106
29-01-2023 23:56:32 INFO Epoch 1: [3158/10940] ---- BYOL Training Loss = 0.4547560214996338
29-01-2023 23:56:50 INFO Epoch 1: [3169/10940] ---- BYOL Training Loss = 0.4449705481529236
29-01-2023 23:57:42 INFO Epoch 1: [3169/10940] ---- BYOL Validation Loss = 0.4741075932979584
29-01-2023 23:57:59 INFO Epoch 1: [3180/10940] ---- BYOL Training Loss = 0.5088288187980652
29-01-2023 23:58:17 INFO Epoch 1: [3191/10940] ---- BYOL Training Loss = 0.5844799280166626
29-01-2023 23:58:35 INFO Epoch 1: [3202/10940] ---- BYOL Training Loss = 0.4818558096885681
29-01-2023 23:58:53 INFO Epoch 1: [3213/10940] ---- BYOL Training Loss = 0.41371122002601624
29-01-2023 23:59:45 INFO Epoch 1: [3213/10940] ---- BYOL Validation Loss = 1.60426926612854
30-01-2023 00:00:02 INFO Epoch 1: [3224/10940] ---- BYOL Training Loss = 0.4780261516571045
30-01-2023 00:00:20 INFO Epoch 1: [3235/10940] ---- BYOL Training Loss = 0.4063758850097656
30-01-2023 00:00:38 INFO Epoch 1: [3246/10940] ---- BYOL Training Loss = 0.36078041791915894
30-01-2023 00:00:56 INFO Epoch 1: [3257/10940] ---- BYOL Training Loss = 0.40612301230430603
30-01-2023 00:01:48 INFO Epoch 1: [3257/10940] ---- BYOL Validation Loss = 0.5151053071022034
30-01-2023 00:02:05 INFO Epoch 1: [3268/10940] ---- BYOL Training Loss = 0.4923578202724457
30-01-2023 00:02:23 INFO Epoch 1: [3279/10940] ---- BYOL Training Loss = 0.4905870854854584
30-01-2023 00:02:41 INFO Epoch 1: [3290/10940] ---- BYOL Training Loss = 0.511327862739563
30-01-2023 00:02:59 INFO Epoch 1: [3301/10940] ---- BYOL Training Loss = 0.5416794419288635
30-01-2023 00:03:51 INFO Epoch 1: [3301/10940] ---- BYOL Validation Loss = 0.4728500545024872
30-01-2023 00:04:09 INFO Epoch 1: [3312/10940] ---- BYOL Training Loss = 0.47206640243530273
30-01-2023 00:04:27 INFO Epoch 1: [3323/10940] ---- BYOL Training Loss = 0.5462751984596252
30-01-2023 00:04:44 INFO Epoch 1: [3334/10940] ---- BYOL Training Loss = 0.5592750906944275
30-01-2023 00:05:02 INFO Epoch 1: [3345/10940] ---- BYOL Training Loss = 0.5131959319114685
30-01-2023 00:05:54 INFO Epoch 1: [3345/10940] ---- BYOL Validation Loss = 0.5023383498191833
30-01-2023 00:06:12 INFO Epoch 1: [3356/10940] ---- BYOL Training Loss = 0.4593069553375244
30-01-2023 00:06:30 INFO Epoch 1: [3367/10940] ---- BYOL Training Loss = 0.43746405839920044
30-01-2023 00:06:48 INFO Epoch 1: [3378/10940] ---- BYOL Training Loss = 0.5065120458602905
30-01-2023 00:07:05 INFO Epoch 1: [3389/10940] ---- BYOL Training Loss = 0.5438064336776733
30-01-2023 00:07:58 INFO Epoch 1: [3389/10940] ---- BYOL Validation Loss = 0.492988646030426
30-01-2023 00:08:15 INFO Epoch 1: [3400/10940] ---- BYOL Training Loss = 0.5007600784301758
30-01-2023 00:08:33 INFO Epoch 1: [3411/10940] ---- BYOL Training Loss = 0.46805763244628906
30-01-2023 00:08:51 INFO Epoch 1: [3422/10940] ---- BYOL Training Loss = 0.48806601762771606
30-01-2023 00:09:08 INFO Epoch 1: [3433/10940] ---- BYOL Training Loss = 0.46348515152931213
30-01-2023 00:10:00 INFO Epoch 1: [3433/10940] ---- BYOL Validation Loss = 0.49656325578689575
30-01-2023 00:10:18 INFO Epoch 1: [3444/10940] ---- BYOL Training Loss = 0.426947683095932
30-01-2023 00:10:36 INFO Epoch 1: [3455/10940] ---- BYOL Training Loss = 0.5003079175949097
30-01-2023 00:10:54 INFO Epoch 1: [3466/10940] ---- BYOL Training Loss = 0.5471398234367371
30-01-2023 00:11:12 INFO Epoch 1: [3477/10940] ---- BYOL Training Loss = 0.565696656703949
30-01-2023 00:12:04 INFO Epoch 1: [3477/10940] ---- BYOL Validation Loss = 0.6517845988273621
30-01-2023 00:12:21 INFO Epoch 1: [3488/10940] ---- BYOL Training Loss = 0.46530452370643616
30-01-2023 00:12:39 INFO Epoch 1: [3499/10940] ---- BYOL Training Loss = 0.5153310894966125
30-01-2023 00:12:57 INFO Epoch 1: [3510/10940] ---- BYOL Training Loss = 0.4333247244358063
30-01-2023 00:13:15 INFO Epoch 1: [3521/10940] ---- BYOL Training Loss = 0.46000272035598755
30-01-2023 00:14:07 INFO Epoch 1: [3521/10940] ---- BYOL Validation Loss = 0.48857685923576355
30-01-2023 00:14:25 INFO Epoch 1: [3532/10940] ---- BYOL Training Loss = 0.4287760257720947
30-01-2023 00:14:42 INFO Epoch 1: [3543/10940] ---- BYOL Training Loss = 0.4668489396572113
30-01-2023 00:15:00 INFO Epoch 1: [3554/10940] ---- BYOL Training Loss = 0.4802333414554596
30-01-2023 00:15:18 INFO Epoch 1: [3565/10940] ---- BYOL Training Loss = 0.4084717333316803
30-01-2023 00:16:10 INFO Epoch 1: [3565/10940] ---- BYOL Validation Loss = 0.48768192529678345
30-01-2023 00:16:28 INFO Epoch 1: [3576/10940] ---- BYOL Training Loss = 0.42926445603370667
30-01-2023 00:16:45 INFO Epoch 1: [3587/10940] ---- BYOL Training Loss = 0.46652284264564514
30-01-2023 00:17:04 INFO Epoch 1: [3598/10940] ---- BYOL Training Loss = 0.4893915057182312
30-01-2023 00:17:21 INFO Epoch 1: [3609/10940] ---- BYOL Training Loss = 0.40922513604164124
30-01-2023 00:18:13 INFO Epoch 1: [3609/10940] ---- BYOL Validation Loss = 0.4871313273906708
30-01-2023 00:18:31 INFO Epoch 1: [3620/10940] ---- BYOL Training Loss = 0.4403713643550873
30-01-2023 00:18:49 INFO Epoch 1: [3631/10940] ---- BYOL Training Loss = 0.4333142340183258
30-01-2023 00:19:07 INFO Epoch 1: [3642/10940] ---- BYOL Training Loss = 0.4475997984409332
30-01-2023 00:19:24 INFO Epoch 1: [3653/10940] ---- BYOL Training Loss = 0.5092281699180603
30-01-2023 00:20:16 INFO Epoch 1: [3653/10940] ---- BYOL Validation Loss = 0.9728058576583862
30-01-2023 00:20:34 INFO Epoch 1: [3664/10940] ---- BYOL Training Loss = 0.47730404138565063
30-01-2023 00:20:52 INFO Epoch 1: [3675/10940] ---- BYOL Training Loss = 0.46421828866004944
30-01-2023 00:21:10 INFO Epoch 1: [3686/10940] ---- BYOL Training Loss = 0.46651020646095276
30-01-2023 00:21:28 INFO Epoch 1: [3697/10940] ---- BYOL Training Loss = 0.43576574325561523
30-01-2023 00:22:20 INFO Epoch 1: [3697/10940] ---- BYOL Validation Loss = 0.4576326906681061
30-01-2023 00:22:37 INFO Epoch 1: [3708/10940] ---- BYOL Training Loss = 0.4420739710330963
30-01-2023 00:22:55 INFO Epoch 1: [3719/10940] ---- BYOL Training Loss = 0.4095366895198822
30-01-2023 00:23:13 INFO Epoch 1: [3730/10940] ---- BYOL Training Loss = 0.41131630539894104
30-01-2023 00:23:31 INFO Epoch 1: [3741/10940] ---- BYOL Training Loss = 0.4753212332725525
30-01-2023 00:24:23 INFO Epoch 1: [3741/10940] ---- BYOL Validation Loss = 0.49622076749801636
30-01-2023 00:24:41 INFO Epoch 1: [3752/10940] ---- BYOL Training Loss = 0.513251543045044
30-01-2023 00:24:59 INFO Epoch 1: [3763/10940] ---- BYOL Training Loss = 0.4268766939640045
30-01-2023 00:25:16 INFO Epoch 1: [3774/10940] ---- BYOL Training Loss = 0.46696925163269043
30-01-2023 00:25:34 INFO Epoch 1: [3785/10940] ---- BYOL Training Loss = 0.5024523735046387
30-01-2023 00:26:26 INFO Epoch 1: [3785/10940] ---- BYOL Validation Loss = 0.5119028091430664
30-01-2023 00:26:44 INFO Epoch 1: [3796/10940] ---- BYOL Training Loss = 0.5162526965141296
30-01-2023 00:27:02 INFO Epoch 1: [3807/10940] ---- BYOL Training Loss = 0.48761051893234253
30-01-2023 00:27:20 INFO Epoch 1: [3818/10940] ---- BYOL Training Loss = 0.5264948010444641
30-01-2023 00:27:38 INFO Epoch 1: [3829/10940] ---- BYOL Training Loss = 0.5007849335670471
30-01-2023 00:28:30 INFO Epoch 1: [3829/10940] ---- BYOL Validation Loss = 0.5240152478218079
30-01-2023 00:28:47 INFO Epoch 1: [3840/10940] ---- BYOL Training Loss = 0.4926166534423828
30-01-2023 00:29:05 INFO Epoch 1: [3851/10940] ---- BYOL Training Loss = 0.49370160698890686
30-01-2023 00:29:23 INFO Epoch 1: [3862/10940] ---- BYOL Training Loss = 0.49897879362106323
30-01-2023 00:29:41 INFO Epoch 1: [3873/10940] ---- BYOL Training Loss = 0.5096505880355835
30-01-2023 00:30:33 INFO Epoch 1: [3873/10940] ---- BYOL Validation Loss = 0.46776384115219116
30-01-2023 00:30:51 INFO Epoch 1: [3884/10940] ---- BYOL Training Loss = 0.46725398302078247
30-01-2023 00:31:09 INFO Epoch 1: [3895/10940] ---- BYOL Training Loss = 0.4544338285923004
30-01-2023 00:31:26 INFO Epoch 1: [3906/10940] ---- BYOL Training Loss = 0.4811064600944519
30-01-2023 00:31:44 INFO Epoch 1: [3917/10940] ---- BYOL Training Loss = 0.5783511400222778
30-01-2023 00:32:36 INFO Epoch 1: [3917/10940] ---- BYOL Validation Loss = 1.0353156328201294
30-01-2023 00:32:54 INFO Epoch 1: [3928/10940] ---- BYOL Training Loss = 0.5420483350753784
30-01-2023 00:33:12 INFO Epoch 1: [3939/10940] ---- BYOL Training Loss = 0.44493961334228516
30-01-2023 00:33:30 INFO Epoch 1: [3950/10940] ---- BYOL Training Loss = 0.5057972073554993
30-01-2023 00:33:48 INFO Epoch 1: [3961/10940] ---- BYOL Training Loss = 0.5832491517066956
30-01-2023 00:34:40 INFO Epoch 1: [3961/10940] ---- BYOL Validation Loss = 0.4838578402996063
30-01-2023 00:34:58 INFO Epoch 1: [3972/10940] ---- BYOL Training Loss = 0.5283790826797485
30-01-2023 00:35:15 INFO Epoch 1: [3983/10940] ---- BYOL Training Loss = 0.5225658416748047
30-01-2023 00:35:33 INFO Epoch 1: [3994/10940] ---- BYOL Training Loss = 0.5247125625610352
30-01-2023 00:35:52 INFO Epoch 1: [4005/10940] ---- BYOL Training Loss = 0.5336116552352905
30-01-2023 00:36:43 INFO Epoch 1: [4005/10940] ---- BYOL Validation Loss = 0.4507386088371277
30-01-2023 00:37:01 INFO Epoch 1: [4016/10940] ---- BYOL Training Loss = 0.5178037881851196
30-01-2023 00:37:19 INFO Epoch 1: [4027/10940] ---- BYOL Training Loss = 0.48758381605148315
30-01-2023 00:37:37 INFO Epoch 1: [4038/10940] ---- BYOL Training Loss = 0.525798499584198
30-01-2023 00:37:55 INFO Epoch 1: [4049/10940] ---- BYOL Training Loss = 0.45226097106933594
30-01-2023 00:38:47 INFO Epoch 1: [4049/10940] ---- BYOL Validation Loss = 0.4587501585483551
30-01-2023 00:39:04 INFO Epoch 1: [4060/10940] ---- BYOL Training Loss = 0.39332517981529236
30-01-2023 00:39:23 INFO Epoch 1: [4071/10940] ---- BYOL Training Loss = 0.4658324718475342
30-01-2023 00:39:40 INFO Epoch 1: [4082/10940] ---- BYOL Training Loss = 0.4818851351737976
30-01-2023 00:39:58 INFO Epoch 1: [4093/10940] ---- BYOL Training Loss = 0.44923657178878784
30-01-2023 00:40:50 INFO Epoch 1: [4093/10940] ---- BYOL Validation Loss = 0.46943792700767517
30-01-2023 00:41:08 INFO Epoch 1: [4104/10940] ---- BYOL Training Loss = 0.40450558066368103
30-01-2023 00:41:26 INFO Epoch 1: [4115/10940] ---- BYOL Training Loss = 0.4581753611564636
30-01-2023 00:41:44 INFO Epoch 1: [4126/10940] ---- BYOL Training Loss = 0.47159361839294434
30-01-2023 00:42:02 INFO Epoch 1: [4137/10940] ---- BYOL Training Loss = 0.456763356924057
30-01-2023 00:42:54 INFO Epoch 1: [4137/10940] ---- BYOL Validation Loss = 0.5061322450637817
30-01-2023 00:43:12 INFO Epoch 1: [4148/10940] ---- BYOL Training Loss = 0.5218914151191711
30-01-2023 00:43:29 INFO Epoch 1: [4159/10940] ---- BYOL Training Loss = 0.46464118361473083
30-01-2023 00:43:47 INFO Epoch 1: [4170/10940] ---- BYOL Training Loss = 0.45001649856567383
30-01-2023 00:44:05 INFO Epoch 1: [4181/10940] ---- BYOL Training Loss = 0.4594520032405853
30-01-2023 00:44:57 INFO Epoch 1: [4181/10940] ---- BYOL Validation Loss = 0.4586992561817169
30-01-2023 00:45:15 INFO Epoch 1: [4192/10940] ---- BYOL Training Loss = 0.43682408332824707
30-01-2023 00:45:33 INFO Epoch 1: [4203/10940] ---- BYOL Training Loss = 0.39428475499153137
30-01-2023 00:45:51 INFO Epoch 1: [4214/10940] ---- BYOL Training Loss = 0.421452134847641
30-01-2023 00:46:09 INFO Epoch 1: [4225/10940] ---- BYOL Training Loss = 0.5328716039657593
30-01-2023 00:47:01 INFO Epoch 1: [4225/10940] ---- BYOL Validation Loss = 0.5880169868469238
30-01-2023 00:47:18 INFO Epoch 1: [4236/10940] ---- BYOL Training Loss = 0.5447041988372803
30-01-2023 00:47:37 INFO Epoch 1: [4247/10940] ---- BYOL Training Loss = 0.5294903516769409
30-01-2023 00:47:55 INFO Epoch 1: [4258/10940] ---- BYOL Training Loss = 0.523088812828064
30-01-2023 00:48:13 INFO Epoch 1: [4269/10940] ---- BYOL Training Loss = 0.5952624082565308
30-01-2023 00:49:05 INFO Epoch 1: [4269/10940] ---- BYOL Validation Loss = 0.5012081861495972
30-01-2023 00:49:22 INFO Epoch 1: [4280/10940] ---- BYOL Training Loss = 0.5887676477432251
30-01-2023 00:49:40 INFO Epoch 1: [4291/10940] ---- BYOL Training Loss = 0.5074893236160278
30-01-2023 00:49:58 INFO Epoch 1: [4302/10940] ---- BYOL Training Loss = 0.6289218664169312
30-01-2023 00:50:17 INFO Epoch 1: [4313/10940] ---- BYOL Training Loss = 0.5649363994598389
30-01-2023 00:51:09 INFO Epoch 1: [4313/10940] ---- BYOL Validation Loss = 0.495516836643219
30-01-2023 00:51:26 INFO Epoch 1: [4324/10940] ---- BYOL Training Loss = 0.5309165716171265
30-01-2023 00:51:44 INFO Epoch 1: [4335/10940] ---- BYOL Training Loss = 0.539576530456543
30-01-2023 00:52:02 INFO Epoch 1: [4346/10940] ---- BYOL Training Loss = 0.4647967219352722
30-01-2023 00:52:20 INFO Epoch 1: [4357/10940] ---- BYOL Training Loss = 0.5118449926376343
30-01-2023 00:53:12 INFO Epoch 1: [4357/10940] ---- BYOL Validation Loss = 0.45738524198532104
30-01-2023 00:53:29 INFO Epoch 1: [4368/10940] ---- BYOL Training Loss = 0.49150997400283813
30-01-2023 00:53:48 INFO Epoch 1: [4379/10940] ---- BYOL Training Loss = 0.36631065607070923
30-01-2023 00:54:06 INFO Epoch 1: [4390/10940] ---- BYOL Training Loss = 0.46930837631225586
30-01-2023 00:54:23 INFO Epoch 1: [4401/10940] ---- BYOL Training Loss = 0.5617876052856445
30-01-2023 00:55:15 INFO Epoch 1: [4401/10940] ---- BYOL Validation Loss = 0.49707889556884766
30-01-2023 00:55:33 INFO Epoch 1: [4412/10940] ---- BYOL Training Loss = 0.5303349494934082
30-01-2023 00:55:51 INFO Epoch 1: [4423/10940] ---- BYOL Training Loss = 0.4352395534515381
30-01-2023 00:56:09 INFO Epoch 1: [4434/10940] ---- BYOL Training Loss = 0.4795113503932953
30-01-2023 00:56:27 INFO Epoch 1: [4445/10940] ---- BYOL Training Loss = 0.5282244086265564
30-01-2023 00:57:19 INFO Epoch 1: [4445/10940] ---- BYOL Validation Loss = 0.5089709162712097
30-01-2023 00:57:37 INFO Epoch 1: [4456/10940] ---- BYOL Training Loss = 0.5178331136703491
30-01-2023 00:57:54 INFO Epoch 1: [4467/10940] ---- BYOL Training Loss = 0.5298093557357788
30-01-2023 00:58:12 INFO Epoch 1: [4478/10940] ---- BYOL Training Loss = 0.498466432094574
30-01-2023 00:58:30 INFO Epoch 1: [4489/10940] ---- BYOL Training Loss = 0.451516717672348
30-01-2023 00:59:22 INFO Epoch 1: [4489/10940] ---- BYOL Validation Loss = 0.5190987586975098
30-01-2023 00:59:40 INFO Epoch 1: [4500/10940] ---- BYOL Training Loss = 0.4643474519252777
30-01-2023 00:59:58 INFO Epoch 1: [4511/10940] ---- BYOL Training Loss = 0.43918538093566895
30-01-2023 01:00:16 INFO Epoch 1: [4522/10940] ---- BYOL Training Loss = 0.473395973443985
30-01-2023 01:00:33 INFO Epoch 1: [4533/10940] ---- BYOL Training Loss = 0.5116816759109497
30-01-2023 01:01:26 INFO Epoch 1: [4533/10940] ---- BYOL Validation Loss = 0.5299896001815796
30-01-2023 01:01:43 INFO Epoch 1: [4544/10940] ---- BYOL Training Loss = 0.476889431476593
30-01-2023 01:02:02 INFO Epoch 1: [4555/10940] ---- BYOL Training Loss = 0.4856554865837097
30-01-2023 01:02:20 INFO Epoch 1: [4566/10940] ---- BYOL Training Loss = 0.522246778011322
30-01-2023 01:02:37 INFO Epoch 1: [4577/10940] ---- BYOL Training Loss = 0.5105120539665222
30-01-2023 01:03:29 INFO Epoch 1: [4577/10940] ---- BYOL Validation Loss = 0.49955272674560547
30-01-2023 01:03:47 INFO Epoch 1: [4588/10940] ---- BYOL Training Loss = 0.5285159349441528
30-01-2023 01:04:05 INFO Epoch 1: [4599/10940] ---- BYOL Training Loss = 0.5653773546218872
30-01-2023 01:04:23 INFO Epoch 1: [4610/10940] ---- BYOL Training Loss = 0.574889063835144
30-01-2023 01:04:41 INFO Epoch 1: [4621/10940] ---- BYOL Training Loss = 0.533969521522522
30-01-2023 01:05:33 INFO Epoch 1: [4621/10940] ---- BYOL Validation Loss = 0.5046200156211853
30-01-2023 01:05:51 INFO Epoch 1: [4632/10940] ---- BYOL Training Loss = 0.5576995015144348
30-01-2023 01:06:09 INFO Epoch 1: [4643/10940] ---- BYOL Training Loss = 0.4723614752292633
30-01-2023 01:06:27 INFO Epoch 1: [4654/10940] ---- BYOL Training Loss = 0.48598790168762207
30-01-2023 01:06:45 INFO Epoch 1: [4665/10940] ---- BYOL Training Loss = 0.5098152756690979
30-01-2023 01:07:37 INFO Epoch 1: [4665/10940] ---- BYOL Validation Loss = 0.4765850603580475
30-01-2023 01:07:55 INFO Epoch 1: [4676/10940] ---- BYOL Training Loss = 0.549643337726593
30-01-2023 01:08:13 INFO Epoch 1: [4687/10940] ---- BYOL Training Loss = 0.5207492709159851
30-01-2023 01:08:30 INFO Epoch 1: [4698/10940] ---- BYOL Training Loss = 0.45959171652793884
30-01-2023 01:08:49 INFO Epoch 1: [4709/10940] ---- BYOL Training Loss = 0.48348790407180786
30-01-2023 01:09:41 INFO Epoch 1: [4709/10940] ---- BYOL Validation Loss = 0.4552135467529297
30-01-2023 01:09:58 INFO Epoch 1: [4720/10940] ---- BYOL Training Loss = 0.49174395203590393
30-01-2023 01:10:17 INFO Epoch 1: [4731/10940] ---- BYOL Training Loss = 0.45760050415992737
30-01-2023 01:10:35 INFO Epoch 1: [4742/10940] ---- BYOL Training Loss = 0.42180633544921875
30-01-2023 01:10:53 INFO Epoch 1: [4753/10940] ---- BYOL Training Loss = 0.48952144384384155
30-01-2023 01:11:45 INFO Epoch 1: [4753/10940] ---- BYOL Validation Loss = 0.4754669964313507
30-01-2023 01:12:03 INFO Epoch 1: [4764/10940] ---- BYOL Training Loss = 0.5745729207992554
30-01-2023 01:12:21 INFO Epoch 1: [4775/10940] ---- BYOL Training Loss = 0.5542839169502258
30-01-2023 01:12:39 INFO Epoch 1: [4786/10940] ---- BYOL Training Loss = 0.4938928186893463
30-01-2023 01:12:56 INFO Epoch 1: [4797/10940] ---- BYOL Training Loss = 0.5026308298110962
30-01-2023 01:13:48 INFO Epoch 1: [4797/10940] ---- BYOL Validation Loss = 0.4865330755710602
30-01-2023 01:14:06 INFO Epoch 1: [4808/10940] ---- BYOL Training Loss = 0.5811115503311157
30-01-2023 01:14:24 INFO Epoch 1: [4819/10940] ---- BYOL Training Loss = 0.508702278137207
30-01-2023 01:14:42 INFO Epoch 1: [4830/10940] ---- BYOL Training Loss = 0.47257480025291443
30-01-2023 01:15:00 INFO Epoch 1: [4841/10940] ---- BYOL Training Loss = 0.4701244831085205
30-01-2023 01:15:52 INFO Epoch 1: [4841/10940] ---- BYOL Validation Loss = 0.4706748425960541
30-01-2023 01:16:10 INFO Epoch 1: [4852/10940] ---- BYOL Training Loss = 0.4549083709716797
30-01-2023 01:16:28 INFO Epoch 1: [4863/10940] ---- BYOL Training Loss = 0.5625731348991394
30-01-2023 01:16:46 INFO Epoch 1: [4874/10940] ---- BYOL Training Loss = 0.6436134576797485
30-01-2023 01:17:04 INFO Epoch 1: [4885/10940] ---- BYOL Training Loss = 0.5229299664497375
30-01-2023 01:17:56 INFO Epoch 1: [4885/10940] ---- BYOL Validation Loss = 0.5036635994911194
30-01-2023 01:18:14 INFO Epoch 1: [4896/10940] ---- BYOL Training Loss = 0.4831327795982361
30-01-2023 01:18:31 INFO Epoch 1: [4907/10940] ---- BYOL Training Loss = 0.5785776376724243
30-01-2023 01:18:50 INFO Epoch 1: [4918/10940] ---- BYOL Training Loss = 0.47213298082351685
30-01-2023 01:19:08 INFO Epoch 1: [4929/10940] ---- BYOL Training Loss = 0.393671452999115
30-01-2023 01:20:00 INFO Epoch 1: [4929/10940] ---- BYOL Validation Loss = 0.46606874465942383
30-01-2023 01:20:17 INFO Epoch 1: [4940/10940] ---- BYOL Training Loss = 0.38491398096084595
30-01-2023 01:20:35 INFO Epoch 1: [4951/10940] ---- BYOL Training Loss = 0.4241887629032135
30-01-2023 01:20:53 INFO Epoch 1: [4962/10940] ---- BYOL Training Loss = 0.45067039132118225
30-01-2023 01:21:12 INFO Epoch 1: [4973/10940] ---- BYOL Training Loss = 0.46949777007102966
30-01-2023 01:22:04 INFO Epoch 1: [4973/10940] ---- BYOL Validation Loss = 0.4825977683067322
30-01-2023 01:22:21 INFO Epoch 1: [4984/10940] ---- BYOL Training Loss = 0.5067870020866394
30-01-2023 01:22:39 INFO Epoch 1: [4995/10940] ---- BYOL Training Loss = 0.4274621903896332
30-01-2023 01:22:57 INFO Epoch 1: [5006/10940] ---- BYOL Training Loss = 0.43818607926368713
30-01-2023 01:23:15 INFO Epoch 1: [5017/10940] ---- BYOL Training Loss = 0.3882901668548584
30-01-2023 01:24:07 INFO Epoch 1: [5017/10940] ---- BYOL Validation Loss = 0.4619864523410797
30-01-2023 01:24:25 INFO Epoch 1: [5028/10940] ---- BYOL Training Loss = 0.4068746566772461
30-01-2023 01:24:43 INFO Epoch 1: [5039/10940] ---- BYOL Training Loss = 0.4904327988624573
30-01-2023 01:25:01 INFO Epoch 1: [5050/10940] ---- BYOL Training Loss = 0.4496634006500244
30-01-2023 01:25:19 INFO Epoch 1: [5061/10940] ---- BYOL Training Loss = 0.47657299041748047
30-01-2023 01:26:11 INFO Epoch 1: [5061/10940] ---- BYOL Validation Loss = 0.5270681977272034
30-01-2023 01:26:29 INFO Epoch 1: [5072/10940] ---- BYOL Training Loss = 0.4377654492855072
30-01-2023 01:26:47 INFO Epoch 1: [5083/10940] ---- BYOL Training Loss = 0.43150144815444946
30-01-2023 01:27:05 INFO Epoch 1: [5094/10940] ---- BYOL Training Loss = 0.48450642824172974
30-01-2023 01:27:23 INFO Epoch 1: [5105/10940] ---- BYOL Training Loss = 0.47141894698143005
30-01-2023 01:28:15 INFO Epoch 1: [5105/10940] ---- BYOL Validation Loss = 0.4674319326877594
30-01-2023 01:28:32 INFO Epoch 1: [5116/10940] ---- BYOL Training Loss = 0.4581317901611328
30-01-2023 01:28:51 INFO Epoch 1: [5127/10940] ---- BYOL Training Loss = 0.4202060103416443
30-01-2023 01:29:09 INFO Epoch 1: [5138/10940] ---- BYOL Training Loss = 0.4672318994998932
30-01-2023 01:29:26 INFO Epoch 1: [5149/10940] ---- BYOL Training Loss = 0.4371558725833893
30-01-2023 01:30:18 INFO Epoch 1: [5149/10940] ---- BYOL Validation Loss = 0.4613535702228546
30-01-2023 01:30:36 INFO Epoch 1: [5160/10940] ---- BYOL Training Loss = 0.4636947214603424
30-01-2023 01:30:54 INFO Epoch 1: [5171/10940] ---- BYOL Training Loss = 0.4795393943786621
30-01-2023 01:31:12 INFO Epoch 1: [5182/10940] ---- BYOL Training Loss = 0.5113497972488403
30-01-2023 01:31:30 INFO Epoch 1: [5193/10940] ---- BYOL Training Loss = 0.4947679936885834
30-01-2023 01:32:22 INFO Epoch 1: [5193/10940] ---- BYOL Validation Loss = 0.4766246974468231
30-01-2023 01:32:40 INFO Epoch 1: [5204/10940] ---- BYOL Training Loss = 0.4948963522911072
30-01-2023 01:32:58 INFO Epoch 1: [5215/10940] ---- BYOL Training Loss = 0.44230979681015015
30-01-2023 01:33:16 INFO Epoch 1: [5226/10940] ---- BYOL Training Loss = 0.4595550000667572
30-01-2023 01:33:34 INFO Epoch 1: [5237/10940] ---- BYOL Training Loss = 0.5264012217521667
30-01-2023 01:34:26 INFO Epoch 1: [5237/10940] ---- BYOL Validation Loss = 0.48216861486434937
30-01-2023 01:34:43 INFO Epoch 1: [5248/10940] ---- BYOL Training Loss = 0.5165079832077026
30-01-2023 01:35:01 INFO Epoch 1: [5259/10940] ---- BYOL Training Loss = 0.5128319263458252
30-01-2023 01:35:20 INFO Epoch 1: [5270/10940] ---- BYOL Training Loss = 0.4872247278690338
30-01-2023 01:35:38 INFO Epoch 1: [5281/10940] ---- BYOL Training Loss = 0.4725817143917084
30-01-2023 01:36:30 INFO Epoch 1: [5281/10940] ---- BYOL Validation Loss = 0.5114379525184631
30-01-2023 01:36:47 INFO Epoch 1: [5292/10940] ---- BYOL Training Loss = 0.5435578227043152
30-01-2023 01:37:05 INFO Epoch 1: [5303/10940] ---- BYOL Training Loss = 0.49563685059547424
30-01-2023 01:37:23 INFO Epoch 1: [5314/10940] ---- BYOL Training Loss = 0.47503143548965454
30-01-2023 01:37:42 INFO Epoch 1: [5325/10940] ---- BYOL Training Loss = 0.477120965719223
30-01-2023 01:38:34 INFO Epoch 1: [5325/10940] ---- BYOL Validation Loss = 0.47774115204811096
30-01-2023 01:38:51 INFO Epoch 1: [5336/10940] ---- BYOL Training Loss = 0.42632389068603516
30-01-2023 01:39:09 INFO Epoch 1: [5347/10940] ---- BYOL Training Loss = 0.5000120401382446
30-01-2023 01:39:27 INFO Epoch 1: [5358/10940] ---- BYOL Training Loss = 0.5666331052780151
30-01-2023 01:39:46 INFO Epoch 1: [5369/10940] ---- BYOL Training Loss = 0.49926456809043884
30-01-2023 01:40:38 INFO Epoch 1: [5369/10940] ---- BYOL Validation Loss = 2.7627007961273193
30-01-2023 01:40:55 INFO Epoch 1: [5380/10940] ---- BYOL Training Loss = 0.45742344856262207
30-01-2023 01:41:13 INFO Epoch 1: [5391/10940] ---- BYOL Training Loss = 0.5270304083824158
30-01-2023 01:41:31 INFO Epoch 1: [5402/10940] ---- BYOL Training Loss = 0.5120986104011536
30-01-2023 01:41:49 INFO Epoch 1: [5413/10940] ---- BYOL Training Loss = 0.45863255858421326
30-01-2023 01:42:41 INFO Epoch 1: [5413/10940] ---- BYOL Validation Loss = 0.48895183205604553
30-01-2023 01:42:59 INFO Epoch 1: [5424/10940] ---- BYOL Training Loss = 0.44959768652915955
30-01-2023 01:43:17 INFO Epoch 1: [5435/10940] ---- BYOL Training Loss = 0.4683608114719391
30-01-2023 01:43:35 INFO Epoch 1: [5446/10940] ---- BYOL Training Loss = 0.4464360177516937
30-01-2023 01:43:53 INFO Epoch 1: [5457/10940] ---- BYOL Training Loss = 0.4587791860103607
30-01-2023 01:44:45 INFO Epoch 1: [5457/10940] ---- BYOL Validation Loss = 0.4919182360172272
30-01-2023 01:45:04 INFO Epoch 1: [5468/10940] ---- BYOL Training Loss = 0.5209365487098694
30-01-2023 01:45:22 INFO Epoch 1: [5479/10940] ---- BYOL Training Loss = 0.4932820200920105
30-01-2023 01:45:40 INFO Epoch 1: [5490/10940] ---- BYOL Training Loss = 0.47862714529037476
30-01-2023 01:45:58 INFO Epoch 1: [5501/10940] ---- BYOL Training Loss = 0.48676690459251404
30-01-2023 01:46:50 INFO Epoch 1: [5501/10940] ---- BYOL Validation Loss = 0.578842043876648
30-01-2023 01:47:08 INFO Epoch 1: [5512/10940] ---- BYOL Training Loss = 0.5018932223320007
30-01-2023 01:47:26 INFO Epoch 1: [5523/10940] ---- BYOL Training Loss = 0.44246959686279297
30-01-2023 01:47:44 INFO Epoch 1: [5534/10940] ---- BYOL Training Loss = 0.4465307593345642
30-01-2023 01:48:02 INFO Epoch 1: [5545/10940] ---- BYOL Training Loss = 0.4691999554634094
30-01-2023 01:48:54 INFO Epoch 1: [5545/10940] ---- BYOL Validation Loss = 2.283722400665283
30-01-2023 01:49:12 INFO Epoch 1: [5556/10940] ---- BYOL Training Loss = 0.44808855652809143
30-01-2023 01:49:30 INFO Epoch 1: [5567/10940] ---- BYOL Training Loss = 0.4785687327384949
30-01-2023 01:49:48 INFO Epoch 1: [5578/10940] ---- BYOL Training Loss = 0.5111449956893921
30-01-2023 01:50:06 INFO Epoch 1: [5589/10940] ---- BYOL Training Loss = 0.4943333566188812
30-01-2023 01:50:58 INFO Epoch 1: [5589/10940] ---- BYOL Validation Loss = 0.504970908164978
30-01-2023 01:51:16 INFO Epoch 1: [5600/10940] ---- BYOL Training Loss = 0.4478529095649719
30-01-2023 01:51:34 INFO Epoch 1: [5611/10940] ---- BYOL Training Loss = 0.43566712737083435
30-01-2023 01:51:52 INFO Epoch 1: [5622/10940] ---- BYOL Training Loss = 0.4394001066684723
30-01-2023 01:52:10 INFO Epoch 1: [5633/10940] ---- BYOL Training Loss = 0.4691935181617737
30-01-2023 01:53:02 INFO Epoch 1: [5633/10940] ---- BYOL Validation Loss = 0.47914573550224304
30-01-2023 01:53:21 INFO Epoch 1: [5644/10940] ---- BYOL Training Loss = 0.4458295702934265
30-01-2023 01:53:39 INFO Epoch 1: [5655/10940] ---- BYOL Training Loss = 0.48734965920448303
30-01-2023 01:53:57 INFO Epoch 1: [5666/10940] ---- BYOL Training Loss = 0.47713932394981384
30-01-2023 01:54:15 INFO Epoch 1: [5677/10940] ---- BYOL Training Loss = 0.3907071352005005
30-01-2023 01:55:07 INFO Epoch 1: [5677/10940] ---- BYOL Validation Loss = 0.48151591420173645
30-01-2023 01:55:24 INFO Epoch 1: [5688/10940] ---- BYOL Training Loss = 0.41552042961120605
30-01-2023 01:55:43 INFO Epoch 1: [5699/10940] ---- BYOL Training Loss = 0.45426639914512634
30-01-2023 01:56:01 INFO Epoch 1: [5710/10940] ---- BYOL Training Loss = 0.5158010721206665
30-01-2023 01:56:19 INFO Epoch 1: [5721/10940] ---- BYOL Training Loss = 0.4664003849029541
30-01-2023 01:57:11 INFO Epoch 1: [5721/10940] ---- BYOL Validation Loss = 0.48700472712516785
30-01-2023 01:57:29 INFO Epoch 1: [5732/10940] ---- BYOL Training Loss = 0.40439271926879883
30-01-2023 01:57:47 INFO Epoch 1: [5743/10940] ---- BYOL Training Loss = 0.4627034664154053
30-01-2023 01:58:05 INFO Epoch 1: [5754/10940] ---- BYOL Training Loss = 0.44286876916885376
30-01-2023 01:58:23 INFO Epoch 1: [5765/10940] ---- BYOL Training Loss = 0.44123610854148865
30-01-2023 01:59:15 INFO Epoch 1: [5765/10940] ---- BYOL Validation Loss = 0.47370490431785583
30-01-2023 01:59:33 INFO Epoch 1: [5776/10940] ---- BYOL Training Loss = 0.45776915550231934
30-01-2023 01:59:51 INFO Epoch 1: [5787/10940] ---- BYOL Training Loss = 0.5607252717018127
30-01-2023 02:00:09 INFO Epoch 1: [5798/10940] ---- BYOL Training Loss = 0.5885727405548096
30-01-2023 02:00:27 INFO Epoch 1: [5809/10940] ---- BYOL Training Loss = 0.5601575374603271
30-01-2023 02:01:19 INFO Epoch 1: [5809/10940] ---- BYOL Validation Loss = 0.4607608914375305
30-01-2023 02:01:38 INFO Epoch 1: [5820/10940] ---- BYOL Training Loss = 0.4518446922302246
30-01-2023 02:01:56 INFO Epoch 1: [5831/10940] ---- BYOL Training Loss = 0.39172595739364624
30-01-2023 02:02:14 INFO Epoch 1: [5842/10940] ---- BYOL Training Loss = 0.4308171272277832
30-01-2023 02:02:32 INFO Epoch 1: [5853/10940] ---- BYOL Training Loss = 0.4768330156803131
30-01-2023 02:03:24 INFO Epoch 1: [5853/10940] ---- BYOL Validation Loss = 0.4696179926395416
30-01-2023 02:03:42 INFO Epoch 1: [5864/10940] ---- BYOL Training Loss = 0.5481155514717102
30-01-2023 02:04:00 INFO Epoch 1: [5875/10940] ---- BYOL Training Loss = 0.44275957345962524
30-01-2023 02:04:18 INFO Epoch 1: [5886/10940] ---- BYOL Training Loss = 0.44117599725723267
30-01-2023 02:04:36 INFO Epoch 1: [5897/10940] ---- BYOL Training Loss = 0.4921938478946686
30-01-2023 02:05:28 INFO Epoch 1: [5897/10940] ---- BYOL Validation Loss = 0.4754551351070404
30-01-2023 02:05:46 INFO Epoch 1: [5908/10940] ---- BYOL Training Loss = 0.441852867603302
30-01-2023 02:06:04 INFO Epoch 1: [5919/10940] ---- BYOL Training Loss = 0.48138564825057983
30-01-2023 02:06:22 INFO Epoch 1: [5930/10940] ---- BYOL Training Loss = 0.5157583355903625
30-01-2023 02:06:40 INFO Epoch 1: [5941/10940] ---- BYOL Training Loss = 0.5091618299484253
30-01-2023 02:07:32 INFO Epoch 1: [5941/10940] ---- BYOL Validation Loss = 2.533714532852173
30-01-2023 02:07:51 INFO Epoch 1: [5952/10940] ---- BYOL Training Loss = 0.43500274419784546
30-01-2023 02:08:09 INFO Epoch 1: [5963/10940] ---- BYOL Training Loss = 0.4974967837333679
30-01-2023 02:08:27 INFO Epoch 1: [5974/10940] ---- BYOL Training Loss = 0.5017245411872864
30-01-2023 02:08:45 INFO Epoch 1: [5985/10940] ---- BYOL Training Loss = 0.4676741063594818
30-01-2023 02:09:37 INFO Epoch 1: [5985/10940] ---- BYOL Validation Loss = 0.43308529257774353
30-01-2023 02:09:55 INFO Epoch 1: [5996/10940] ---- BYOL Training Loss = 0.47677096724510193
30-01-2023 02:10:13 INFO Epoch 1: [6007/10940] ---- BYOL Training Loss = 0.46020907163619995
30-01-2023 02:10:31 INFO Epoch 1: [6018/10940] ---- BYOL Training Loss = 0.47056928277015686
30-01-2023 02:10:49 INFO Epoch 1: [6029/10940] ---- BYOL Training Loss = 0.5119268298149109
30-01-2023 02:11:41 INFO Epoch 1: [6029/10940] ---- BYOL Validation Loss = 0.48219966888427734
30-01-2023 02:12:00 INFO Epoch 1: [6040/10940] ---- BYOL Training Loss = 0.44845905900001526
30-01-2023 02:12:18 INFO Epoch 1: [6051/10940] ---- BYOL Training Loss = 0.41501712799072266
30-01-2023 02:12:36 INFO Epoch 1: [6062/10940] ---- BYOL Training Loss = 0.5138587355613708
30-01-2023 02:12:54 INFO Epoch 1: [6073/10940] ---- BYOL Training Loss = 0.4530399739742279
30-01-2023 02:13:46 INFO Epoch 1: [6073/10940] ---- BYOL Validation Loss = 0.44716718792915344
30-01-2023 02:14:04 INFO Epoch 1: [6084/10940] ---- BYOL Training Loss = 0.4907302260398865
30-01-2023 02:14:22 INFO Epoch 1: [6095/10940] ---- BYOL Training Loss = 0.513067364692688
30-01-2023 02:14:40 INFO Epoch 1: [6106/10940] ---- BYOL Training Loss = 0.4827604293823242
30-01-2023 02:14:58 INFO Epoch 1: [6117/10940] ---- BYOL Training Loss = 0.5127223134040833
30-01-2023 02:15:50 INFO Epoch 1: [6117/10940] ---- BYOL Validation Loss = 0.4654730260372162
30-01-2023 02:16:08 INFO Epoch 1: [6128/10940] ---- BYOL Training Loss = 0.484480082988739
30-01-2023 02:16:26 INFO Epoch 1: [6139/10940] ---- BYOL Training Loss = 0.3981708884239197
30-01-2023 02:16:44 INFO Epoch 1: [6150/10940] ---- BYOL Training Loss = 0.44743967056274414
30-01-2023 02:17:03 INFO Epoch 1: [6161/10940] ---- BYOL Training Loss = 0.4384686052799225
30-01-2023 02:17:55 INFO Epoch 1: [6161/10940] ---- BYOL Validation Loss = 0.436673641204834
30-01-2023 02:18:12 INFO Epoch 1: [6172/10940] ---- BYOL Training Loss = 0.4302283227443695
30-01-2023 02:18:30 INFO Epoch 1: [6183/10940] ---- BYOL Training Loss = 0.4055109918117523
30-01-2023 02:18:48 INFO Epoch 1: [6194/10940] ---- BYOL Training Loss = 0.4140070974826813
30-01-2023 02:19:07 INFO Epoch 1: [6205/10940] ---- BYOL Training Loss = 0.4512365758419037
30-01-2023 02:19:59 INFO Epoch 1: [6205/10940] ---- BYOL Validation Loss = 2.5665359497070312
30-01-2023 02:20:17 INFO Epoch 1: [6216/10940] ---- BYOL Training Loss = 0.4337539076805115
30-01-2023 02:20:35 INFO Epoch 1: [6227/10940] ---- BYOL Training Loss = 0.4281589388847351
30-01-2023 02:20:53 INFO Epoch 1: [6238/10940] ---- BYOL Training Loss = 0.42951464653015137
30-01-2023 02:21:11 INFO Epoch 1: [6249/10940] ---- BYOL Training Loss = 0.4038362503051758
30-01-2023 02:22:03 INFO Epoch 1: [6249/10940] ---- BYOL Validation Loss = 0.44899699091911316
30-01-2023 02:22:21 INFO Epoch 1: [6260/10940] ---- BYOL Training Loss = 0.47362685203552246
30-01-2023 02:22:39 INFO Epoch 1: [6271/10940] ---- BYOL Training Loss = 0.5203779935836792
30-01-2023 02:22:58 INFO Epoch 1: [6282/10940] ---- BYOL Training Loss = 0.4602450430393219
30-01-2023 02:23:16 INFO Epoch 1: [6293/10940] ---- BYOL Training Loss = 0.43163204193115234
30-01-2023 02:24:08 INFO Epoch 1: [6293/10940] ---- BYOL Validation Loss = 0.4533407986164093
30-01-2023 02:24:25 INFO Epoch 1: [6304/10940] ---- BYOL Training Loss = 0.4603385329246521
30-01-2023 02:24:44 INFO Epoch 1: [6315/10940] ---- BYOL Training Loss = 0.4791085124015808
30-01-2023 02:25:02 INFO Epoch 1: [6326/10940] ---- BYOL Training Loss = 0.5076021552085876
30-01-2023 02:25:20 INFO Epoch 1: [6337/10940] ---- BYOL Training Loss = 0.48874178528785706
30-01-2023 02:26:12 INFO Epoch 1: [6337/10940] ---- BYOL Validation Loss = 0.46971574425697327
30-01-2023 02:26:30 INFO Epoch 1: [6348/10940] ---- BYOL Training Loss = 0.4662321209907532
30-01-2023 02:26:48 INFO Epoch 1: [6359/10940] ---- BYOL Training Loss = 0.43226251006126404
30-01-2023 02:27:06 INFO Epoch 1: [6370/10940] ---- BYOL Training Loss = 0.5100577473640442
30-01-2023 02:27:25 INFO Epoch 1: [6381/10940] ---- BYOL Training Loss = 0.4905715584754944
30-01-2023 02:28:17 INFO Epoch 1: [6381/10940] ---- BYOL Validation Loss = 0.46332699060440063
30-01-2023 02:28:34 INFO Epoch 1: [6392/10940] ---- BYOL Training Loss = 0.5169868469238281
30-01-2023 02:28:53 INFO Epoch 1: [6403/10940] ---- BYOL Training Loss = 0.4648244380950928
30-01-2023 02:29:11 INFO Epoch 1: [6414/10940] ---- BYOL Training Loss = 0.5023092031478882
30-01-2023 02:29:29 INFO Epoch 1: [6425/10940] ---- BYOL Training Loss = 0.5233479142189026
30-01-2023 02:30:21 INFO Epoch 1: [6425/10940] ---- BYOL Validation Loss = 0.46119794249534607
30-01-2023 02:30:38 INFO Epoch 1: [6436/10940] ---- BYOL Training Loss = 0.4227150082588196
30-01-2023 02:30:57 INFO Epoch 1: [6447/10940] ---- BYOL Training Loss = 0.43794840574264526
30-01-2023 02:31:15 INFO Epoch 1: [6458/10940] ---- BYOL Training Loss = 0.4685456156730652
30-01-2023 02:31:33 INFO Epoch 1: [6469/10940] ---- BYOL Training Loss = 0.4699023365974426
30-01-2023 02:32:25 INFO Epoch 1: [6469/10940] ---- BYOL Validation Loss = 0.45885542035102844
30-01-2023 02:32:43 INFO Epoch 1: [6480/10940] ---- BYOL Training Loss = 0.5490837693214417
30-01-2023 02:33:01 INFO Epoch 1: [6491/10940] ---- BYOL Training Loss = 0.5039286613464355
30-01-2023 02:33:20 INFO Epoch 1: [6502/10940] ---- BYOL Training Loss = 0.5175287127494812
30-01-2023 02:33:38 INFO Epoch 1: [6513/10940] ---- BYOL Training Loss = 0.5613078474998474
30-01-2023 02:34:30 INFO Epoch 1: [6513/10940] ---- BYOL Validation Loss = 0.46346235275268555
30-01-2023 02:34:48 INFO Epoch 1: [6524/10940] ---- BYOL Training Loss = 0.5062405467033386
30-01-2023 02:35:06 INFO Epoch 1: [6535/10940] ---- BYOL Training Loss = 0.4086252748966217
30-01-2023 02:35:24 INFO Epoch 1: [6546/10940] ---- BYOL Training Loss = 0.38638612627983093
30-01-2023 02:35:42 INFO Epoch 1: [6557/10940] ---- BYOL Training Loss = 0.42652344703674316
30-01-2023 02:36:34 INFO Epoch 1: [6557/10940] ---- BYOL Validation Loss = 0.4421789348125458
30-01-2023 02:36:52 INFO Epoch 1: [6568/10940] ---- BYOL Training Loss = 0.40914759039878845
30-01-2023 02:37:10 INFO Epoch 1: [6579/10940] ---- BYOL Training Loss = 0.40170615911483765
30-01-2023 02:37:29 INFO Epoch 1: [6590/10940] ---- BYOL Training Loss = 0.4894014000892639
30-01-2023 02:37:47 INFO Epoch 1: [6601/10940] ---- BYOL Training Loss = 0.5437451004981995
30-01-2023 02:38:39 INFO Epoch 1: [6601/10940] ---- BYOL Validation Loss = 0.45094799995422363
30-01-2023 02:38:56 INFO Epoch 1: [6612/10940] ---- BYOL Training Loss = 0.5388816595077515
30-01-2023 02:39:14 INFO Epoch 1: [6623/10940] ---- BYOL Training Loss = 0.5462481379508972
30-01-2023 02:39:33 INFO Epoch 1: [6634/10940] ---- BYOL Training Loss = 0.5321171283721924
30-01-2023 02:39:51 INFO Epoch 1: [6645/10940] ---- BYOL Training Loss = 0.5027718544006348
30-01-2023 02:40:43 INFO Epoch 1: [6645/10940] ---- BYOL Validation Loss = 0.49725469946861267
30-01-2023 02:41:01 INFO Epoch 1: [6656/10940] ---- BYOL Training Loss = 0.49690118432044983
30-01-2023 02:41:19 INFO Epoch 1: [6667/10940] ---- BYOL Training Loss = 0.43051663041114807
30-01-2023 02:41:37 INFO Epoch 1: [6678/10940] ---- BYOL Training Loss = 0.418637216091156
30-01-2023 02:41:55 INFO Epoch 1: [6689/10940] ---- BYOL Training Loss = 0.4159802496433258
30-01-2023 02:42:47 INFO Epoch 1: [6689/10940] ---- BYOL Validation Loss = 0.4911865293979645
30-01-2023 02:43:05 INFO Epoch 1: [6700/10940] ---- BYOL Training Loss = 0.46920639276504517
30-01-2023 02:43:24 INFO Epoch 1: [6711/10940] ---- BYOL Training Loss = 0.4094396233558655
30-01-2023 02:43:42 INFO Epoch 1: [6722/10940] ---- BYOL Training Loss = 0.4061072766780853
30-01-2023 02:44:00 INFO Epoch 1: [6733/10940] ---- BYOL Training Loss = 0.4157645106315613
30-01-2023 02:44:52 INFO Epoch 1: [6733/10940] ---- BYOL Validation Loss = 0.4617934823036194
30-01-2023 02:45:10 INFO Epoch 1: [6744/10940] ---- BYOL Training Loss = 0.4389071464538574
30-01-2023 02:45:28 INFO Epoch 1: [6755/10940] ---- BYOL Training Loss = 0.46424636244773865
30-01-2023 02:45:46 INFO Epoch 1: [6766/10940] ---- BYOL Training Loss = 0.4449191987514496
30-01-2023 02:46:04 INFO Epoch 1: [6777/10940] ---- BYOL Training Loss = 0.3696429133415222
30-01-2023 02:46:56 INFO Epoch 1: [6777/10940] ---- BYOL Validation Loss = 0.45730501413345337
30-01-2023 02:47:14 INFO Epoch 1: [6788/10940] ---- BYOL Training Loss = 0.43081584572792053
30-01-2023 02:47:33 INFO Epoch 1: [6799/10940] ---- BYOL Training Loss = 0.45578187704086304
30-01-2023 02:47:51 INFO Epoch 1: [6810/10940] ---- BYOL Training Loss = 0.43835368752479553
30-01-2023 02:48:09 INFO Epoch 1: [6821/10940] ---- BYOL Training Loss = 0.44797760248184204
30-01-2023 02:49:01 INFO Epoch 1: [6821/10940] ---- BYOL Validation Loss = 0.45325788855552673
30-01-2023 02:49:19 INFO Epoch 1: [6832/10940] ---- BYOL Training Loss = 0.46411871910095215
30-01-2023 02:49:37 INFO Epoch 1: [6843/10940] ---- BYOL Training Loss = 0.47851771116256714
30-01-2023 02:49:55 INFO Epoch 1: [6854/10940] ---- BYOL Training Loss = 0.47541871666908264
30-01-2023 02:50:14 INFO Epoch 1: [6865/10940] ---- BYOL Training Loss = 0.48006701469421387
30-01-2023 02:51:06 INFO Epoch 1: [6865/10940] ---- BYOL Validation Loss = 0.4663778245449066
30-01-2023 02:51:23 INFO Epoch 1: [6876/10940] ---- BYOL Training Loss = 0.45769381523132324
30-01-2023 02:51:41 INFO Epoch 1: [6887/10940] ---- BYOL Training Loss = 0.40080976486206055
30-01-2023 02:52:00 INFO Epoch 1: [6898/10940] ---- BYOL Training Loss = 0.44971442222595215
30-01-2023 02:52:18 INFO Epoch 1: [6909/10940] ---- BYOL Training Loss = 0.553963303565979
30-01-2023 02:53:10 INFO Epoch 1: [6909/10940] ---- BYOL Validation Loss = 0.4255584180355072
30-01-2023 02:53:28 INFO Epoch 1: [6920/10940] ---- BYOL Training Loss = 0.41292276978492737
30-01-2023 02:53:46 INFO Epoch 1: [6931/10940] ---- BYOL Training Loss = 0.4009283185005188
30-01-2023 02:54:05 INFO Epoch 1: [6942/10940] ---- BYOL Training Loss = 0.4726641774177551
30-01-2023 02:54:23 INFO Epoch 1: [6953/10940] ---- BYOL Training Loss = 0.5055269002914429
30-01-2023 02:55:15 INFO Epoch 1: [6953/10940] ---- BYOL Validation Loss = 0.46190446615219116
30-01-2023 02:55:33 INFO Epoch 1: [6964/10940] ---- BYOL Training Loss = 0.5443503260612488
30-01-2023 02:55:51 INFO Epoch 1: [6975/10940] ---- BYOL Training Loss = 0.5128189325332642
30-01-2023 02:56:09 INFO Epoch 1: [6986/10940] ---- BYOL Training Loss = 0.5558243989944458
30-01-2023 02:56:27 INFO Epoch 1: [6997/10940] ---- BYOL Training Loss = 0.4807402491569519
30-01-2023 02:57:19 INFO Epoch 1: [6997/10940] ---- BYOL Validation Loss = 0.4797741770744324
30-01-2023 02:57:38 INFO Epoch 1: [7008/10940] ---- BYOL Training Loss = 0.44113215804100037
30-01-2023 02:57:56 INFO Epoch 1: [7019/10940] ---- BYOL Training Loss = 0.44063568115234375
30-01-2023 02:58:14 INFO Epoch 1: [7030/10940] ---- BYOL Training Loss = 0.4172999858856201
30-01-2023 02:58:32 INFO Epoch 1: [7041/10940] ---- BYOL Training Loss = 0.4391604959964752
30-01-2023 02:59:24 INFO Epoch 1: [7041/10940] ---- BYOL Validation Loss = 0.43999120593070984
30-01-2023 02:59:42 INFO Epoch 1: [7052/10940] ---- BYOL Training Loss = 0.511093258857727
30-01-2023 03:00:00 INFO Epoch 1: [7063/10940] ---- BYOL Training Loss = 0.47942209243774414
30-01-2023 03:00:19 INFO Epoch 1: [7074/10940] ---- BYOL Training Loss = 0.5104323625564575
30-01-2023 03:00:37 INFO Epoch 1: [7085/10940] ---- BYOL Training Loss = 0.47946587204933167
30-01-2023 03:01:29 INFO Epoch 1: [7085/10940] ---- BYOL Validation Loss = 0.4749729037284851
30-01-2023 03:01:47 INFO Epoch 1: [7096/10940] ---- BYOL Training Loss = 0.4236311912536621
30-01-2023 03:02:05 INFO Epoch 1: [7107/10940] ---- BYOL Training Loss = 0.41245007514953613
30-01-2023 03:02:23 INFO Epoch 1: [7118/10940] ---- BYOL Training Loss = 0.39388296008110046
30-01-2023 03:02:41 INFO Epoch 1: [7129/10940] ---- BYOL Training Loss = 0.47309404611587524
30-01-2023 03:03:33 INFO Epoch 1: [7129/10940] ---- BYOL Validation Loss = 0.4336404502391815
30-01-2023 03:03:51 INFO Epoch 1: [7140/10940] ---- BYOL Training Loss = 0.5048763751983643
30-01-2023 03:04:09 INFO Epoch 1: [7151/10940] ---- BYOL Training Loss = 0.44347357749938965
30-01-2023 03:04:28 INFO Epoch 1: [7162/10940] ---- BYOL Training Loss = 0.4611244201660156
30-01-2023 03:04:46 INFO Epoch 1: [7173/10940] ---- BYOL Training Loss = 0.4345793128013611
30-01-2023 03:05:38 INFO Epoch 1: [7173/10940] ---- BYOL Validation Loss = 0.4505365788936615
30-01-2023 03:05:56 INFO Epoch 1: [7184/10940] ---- BYOL Training Loss = 0.4727000296115875
30-01-2023 03:06:14 INFO Epoch 1: [7195/10940] ---- BYOL Training Loss = 0.5095184445381165
30-01-2023 03:06:32 INFO Epoch 1: [7206/10940] ---- BYOL Training Loss = 0.4623103141784668
30-01-2023 03:06:51 INFO Epoch 1: [7217/10940] ---- BYOL Training Loss = 0.416645348072052
30-01-2023 03:07:43 INFO Epoch 1: [7217/10940] ---- BYOL Validation Loss = 0.4223438799381256
30-01-2023 03:08:01 INFO Epoch 1: [7228/10940] ---- BYOL Training Loss = 0.43500199913978577
30-01-2023 03:08:19 INFO Epoch 1: [7239/10940] ---- BYOL Training Loss = 0.4295675754547119
30-01-2023 03:08:37 INFO Epoch 1: [7250/10940] ---- BYOL Training Loss = 0.3987192213535309
30-01-2023 03:08:56 INFO Epoch 1: [7261/10940] ---- BYOL Training Loss = 0.4369204640388489
30-01-2023 03:09:48 INFO Epoch 1: [7261/10940] ---- BYOL Validation Loss = 0.43866729736328125
30-01-2023 03:10:06 INFO Epoch 1: [7272/10940] ---- BYOL Training Loss = 0.4664984345436096
30-01-2023 03:10:24 INFO Epoch 1: [7283/10940] ---- BYOL Training Loss = 0.4482029974460602
30-01-2023 03:10:42 INFO Epoch 1: [7294/10940] ---- BYOL Training Loss = 0.42848557233810425
30-01-2023 03:11:01 INFO Epoch 1: [7305/10940] ---- BYOL Training Loss = 0.3895045816898346
30-01-2023 03:11:52 INFO Epoch 1: [7305/10940] ---- BYOL Validation Loss = 0.42556166648864746
30-01-2023 03:12:10 INFO Epoch 1: [7316/10940] ---- BYOL Training Loss = 0.3457478880882263
30-01-2023 03:12:28 INFO Epoch 1: [7327/10940] ---- BYOL Training Loss = 0.4075348377227783
30-01-2023 03:12:47 INFO Epoch 1: [7338/10940] ---- BYOL Training Loss = 0.5546130537986755
30-01-2023 03:13:05 INFO Epoch 1: [7349/10940] ---- BYOL Training Loss = 0.5361982583999634
30-01-2023 03:13:57 INFO Epoch 1: [7349/10940] ---- BYOL Validation Loss = 0.5795049667358398
30-01-2023 03:14:15 INFO Epoch 1: [7360/10940] ---- BYOL Training Loss = 0.4642797112464905
30-01-2023 03:14:33 INFO Epoch 1: [7371/10940] ---- BYOL Training Loss = 0.4768128991127014
30-01-2023 03:14:52 INFO Epoch 1: [7382/10940] ---- BYOL Training Loss = 0.4783228933811188
30-01-2023 03:15:10 INFO Epoch 1: [7393/10940] ---- BYOL Training Loss = 0.496316522359848
30-01-2023 03:16:02 INFO Epoch 1: [7393/10940] ---- BYOL Validation Loss = 0.44619032740592957
30-01-2023 03:16:20 INFO Epoch 1: [7404/10940] ---- BYOL Training Loss = 0.5041977167129517
30-01-2023 03:16:38 INFO Epoch 1: [7415/10940] ---- BYOL Training Loss = 0.5464156270027161
30-01-2023 03:16:56 INFO Epoch 1: [7426/10940] ---- BYOL Training Loss = 0.5325502157211304
30-01-2023 03:17:15 INFO Epoch 1: [7437/10940] ---- BYOL Training Loss = 0.48853760957717896
30-01-2023 03:18:07 INFO Epoch 1: [7437/10940] ---- BYOL Validation Loss = 0.4896954894065857
30-01-2023 03:18:24 INFO Epoch 1: [7448/10940] ---- BYOL Training Loss = 0.4628933370113373
30-01-2023 03:18:43 INFO Epoch 1: [7459/10940] ---- BYOL Training Loss = 0.36967015266418457
30-01-2023 03:19:01 INFO Epoch 1: [7470/10940] ---- BYOL Training Loss = 0.45700615644454956
30-01-2023 03:19:19 INFO Epoch 1: [7481/10940] ---- BYOL Training Loss = 0.49314752221107483
30-01-2023 03:20:11 INFO Epoch 1: [7481/10940] ---- BYOL Validation Loss = 0.4488532841205597
30-01-2023 03:20:29 INFO Epoch 1: [7492/10940] ---- BYOL Training Loss = 0.5506114959716797
30-01-2023 03:20:48 INFO Epoch 1: [7503/10940] ---- BYOL Training Loss = 0.5503398180007935
30-01-2023 03:21:06 INFO Epoch 1: [7514/10940] ---- BYOL Training Loss = 0.43997377157211304
30-01-2023 03:21:24 INFO Epoch 1: [7525/10940] ---- BYOL Training Loss = 0.4357462525367737
30-01-2023 03:22:16 INFO Epoch 1: [7525/10940] ---- BYOL Validation Loss = 0.45659583806991577
30-01-2023 03:22:34 INFO Epoch 1: [7536/10940] ---- BYOL Training Loss = 0.4173412322998047
30-01-2023 03:22:52 INFO Epoch 1: [7547/10940] ---- BYOL Training Loss = 0.41686463356018066
30-01-2023 03:23:10 INFO Epoch 1: [7558/10940] ---- BYOL Training Loss = 0.49562138319015503
30-01-2023 03:23:29 INFO Epoch 1: [7569/10940] ---- BYOL Training Loss = 0.5110560655593872
30-01-2023 03:24:21 INFO Epoch 1: [7569/10940] ---- BYOL Validation Loss = 0.435104638338089
30-01-2023 03:24:39 INFO Epoch 1: [7580/10940] ---- BYOL Training Loss = 0.4417904019355774
30-01-2023 03:24:57 INFO Epoch 1: [7591/10940] ---- BYOL Training Loss = 0.49290236830711365
30-01-2023 03:25:15 INFO Epoch 1: [7602/10940] ---- BYOL Training Loss = 0.4573936462402344
30-01-2023 03:25:34 INFO Epoch 1: [7613/10940] ---- BYOL Training Loss = 0.4039273262023926
30-01-2023 03:26:25 INFO Epoch 1: [7613/10940] ---- BYOL Validation Loss = 0.45966529846191406
30-01-2023 03:26:43 INFO Epoch 1: [7624/10940] ---- BYOL Training Loss = 0.38531678915023804
30-01-2023 03:27:02 INFO Epoch 1: [7635/10940] ---- BYOL Training Loss = 0.4485477805137634
30-01-2023 03:27:20 INFO Epoch 1: [7646/10940] ---- BYOL Training Loss = 0.3884158730506897
30-01-2023 03:27:38 INFO Epoch 1: [7657/10940] ---- BYOL Training Loss = 0.3719049096107483
30-01-2023 03:28:30 INFO Epoch 1: [7657/10940] ---- BYOL Validation Loss = 0.4374634921550751
30-01-2023 03:28:48 INFO Epoch 1: [7668/10940] ---- BYOL Training Loss = 0.3484871983528137
30-01-2023 03:29:07 INFO Epoch 1: [7679/10940] ---- BYOL Training Loss = 0.37543782591819763
30-01-2023 03:29:25 INFO Epoch 1: [7690/10940] ---- BYOL Training Loss = 0.4376738667488098
30-01-2023 03:29:43 INFO Epoch 1: [7701/10940] ---- BYOL Training Loss = 0.4051252007484436
30-01-2023 03:30:35 INFO Epoch 1: [7701/10940] ---- BYOL Validation Loss = 0.4259189963340759
30-01-2023 03:30:53 INFO Epoch 1: [7712/10940] ---- BYOL Training Loss = 0.5171946287155151
30-01-2023 03:31:11 INFO Epoch 1: [7723/10940] ---- BYOL Training Loss = 0.5493627190589905
30-01-2023 03:31:30 INFO Epoch 1: [7734/10940] ---- BYOL Training Loss = 0.4322572648525238
30-01-2023 03:31:48 INFO Epoch 1: [7745/10940] ---- BYOL Training Loss = 0.3621904253959656
30-01-2023 03:32:40 INFO Epoch 1: [7745/10940] ---- BYOL Validation Loss = 0.4504629969596863
30-01-2023 03:32:58 INFO Epoch 1: [7756/10940] ---- BYOL Training Loss = 0.416120707988739
30-01-2023 03:33:16 INFO Epoch 1: [7767/10940] ---- BYOL Training Loss = 0.4585960805416107
30-01-2023 03:33:35 INFO Epoch 1: [7778/10940] ---- BYOL Training Loss = 0.4275434911251068
30-01-2023 03:33:53 INFO Epoch 1: [7789/10940] ---- BYOL Training Loss = 0.4299277663230896
30-01-2023 03:34:45 INFO Epoch 1: [7789/10940] ---- BYOL Validation Loss = 0.4343952238559723
30-01-2023 03:35:03 INFO Epoch 1: [7800/10940] ---- BYOL Training Loss = 0.4675818383693695
30-01-2023 03:35:22 INFO Epoch 1: [7811/10940] ---- BYOL Training Loss = 0.46490341424942017
30-01-2023 03:35:40 INFO Epoch 1: [7822/10940] ---- BYOL Training Loss = 0.46198588609695435
30-01-2023 03:35:58 INFO Epoch 1: [7833/10940] ---- BYOL Training Loss = 0.5187464952468872
30-01-2023 03:36:50 INFO Epoch 1: [7833/10940] ---- BYOL Validation Loss = 0.4691424071788788
30-01-2023 03:37:09 INFO Epoch 1: [7844/10940] ---- BYOL Training Loss = 0.43802469968795776
30-01-2023 03:37:27 INFO Epoch 1: [7855/10940] ---- BYOL Training Loss = 0.4388040006160736
30-01-2023 03:37:45 INFO Epoch 1: [7866/10940] ---- BYOL Training Loss = 0.4594499468803406
30-01-2023 03:38:03 INFO Epoch 1: [7877/10940] ---- BYOL Training Loss = 0.4284834861755371
30-01-2023 03:38:55 INFO Epoch 1: [7877/10940] ---- BYOL Validation Loss = 0.45232030749320984
30-01-2023 03:39:13 INFO Epoch 1: [7888/10940] ---- BYOL Training Loss = 0.546055793762207
30-01-2023 03:39:32 INFO Epoch 1: [7899/10940] ---- BYOL Training Loss = 0.5228441953659058
30-01-2023 03:39:50 INFO Epoch 1: [7910/10940] ---- BYOL Training Loss = 0.463644802570343
30-01-2023 03:40:08 INFO Epoch 1: [7921/10940] ---- BYOL Training Loss = 0.4955154061317444
30-01-2023 03:41:00 INFO Epoch 1: [7921/10940] ---- BYOL Validation Loss = 0.43053722381591797
30-01-2023 03:41:19 INFO Epoch 1: [7932/10940] ---- BYOL Training Loss = 0.4323582053184509
30-01-2023 03:41:37 INFO Epoch 1: [7943/10940] ---- BYOL Training Loss = 0.40649348497390747
30-01-2023 03:41:55 INFO Epoch 1: [7954/10940] ---- BYOL Training Loss = 0.44812169671058655
30-01-2023 03:42:14 INFO Epoch 1: [7965/10940] ---- BYOL Training Loss = 0.5209619998931885
30-01-2023 03:43:06 INFO Epoch 1: [7965/10940] ---- BYOL Validation Loss = 0.45204442739486694
30-01-2023 03:43:24 INFO Epoch 1: [7976/10940] ---- BYOL Training Loss = 0.5011690855026245
30-01-2023 03:43:42 INFO Epoch 1: [7987/10940] ---- BYOL Training Loss = 0.4357801377773285
30-01-2023 03:44:00 INFO Epoch 1: [7998/10940] ---- BYOL Training Loss = 0.5352849364280701
30-01-2023 03:44:19 INFO Epoch 1: [8009/10940] ---- BYOL Training Loss = 0.4921632707118988
30-01-2023 03:45:11 INFO Epoch 1: [8009/10940] ---- BYOL Validation Loss = 0.44656482338905334
30-01-2023 03:45:28 INFO Epoch 1: [8020/10940] ---- BYOL Training Loss = 0.44543132185935974
30-01-2023 03:45:47 INFO Epoch 1: [8031/10940] ---- BYOL Training Loss = 0.4375395178794861
30-01-2023 03:46:05 INFO Epoch 1: [8042/10940] ---- BYOL Training Loss = 0.4397430419921875
30-01-2023 03:46:23 INFO Epoch 1: [8053/10940] ---- BYOL Training Loss = 0.40297579765319824
30-01-2023 03:47:16 INFO Epoch 1: [8053/10940] ---- BYOL Validation Loss = 0.4208289682865143
30-01-2023 03:47:34 INFO Epoch 1: [8064/10940] ---- BYOL Training Loss = 0.3737652599811554
30-01-2023 03:47:52 INFO Epoch 1: [8075/10940] ---- BYOL Training Loss = 0.3735129237174988
30-01-2023 03:48:10 INFO Epoch 1: [8086/10940] ---- BYOL Training Loss = 0.43344005942344666
30-01-2023 03:48:29 INFO Epoch 1: [8097/10940] ---- BYOL Training Loss = 0.439375638961792
30-01-2023 03:49:21 INFO Epoch 1: [8097/10940] ---- BYOL Validation Loss = 0.41627708077430725
30-01-2023 03:49:39 INFO Epoch 1: [8108/10940] ---- BYOL Training Loss = 0.4440402090549469
30-01-2023 03:49:57 INFO Epoch 1: [8119/10940] ---- BYOL Training Loss = 0.45419472455978394
30-01-2023 03:50:16 INFO Epoch 1: [8130/10940] ---- BYOL Training Loss = 0.40663862228393555
30-01-2023 03:50:34 INFO Epoch 1: [8141/10940] ---- BYOL Training Loss = 0.48977869749069214
30-01-2023 03:51:26 INFO Epoch 1: [8141/10940] ---- BYOL Validation Loss = 0.4440435469150543
30-01-2023 03:51:44 INFO Epoch 1: [8152/10940] ---- BYOL Training Loss = 0.5024586319923401
30-01-2023 03:52:02 INFO Epoch 1: [8163/10940] ---- BYOL Training Loss = 0.4706014096736908
30-01-2023 03:52:21 INFO Epoch 1: [8174/10940] ---- BYOL Training Loss = 0.4606870710849762
30-01-2023 03:52:39 INFO Epoch 1: [8185/10940] ---- BYOL Training Loss = 0.43888726830482483
30-01-2023 03:53:31 INFO Epoch 1: [8185/10940] ---- BYOL Validation Loss = 0.4490165710449219
30-01-2023 03:53:49 INFO Epoch 1: [8196/10940] ---- BYOL Training Loss = 0.4615221917629242
30-01-2023 03:54:07 INFO Epoch 1: [8207/10940] ---- BYOL Training Loss = 0.4307224750518799
30-01-2023 03:54:26 INFO Epoch 1: [8218/10940] ---- BYOL Training Loss = 0.46006202697753906
30-01-2023 03:54:44 INFO Epoch 1: [8229/10940] ---- BYOL Training Loss = 0.46111664175987244
30-01-2023 03:55:36 INFO Epoch 1: [8229/10940] ---- BYOL Validation Loss = 0.44735807180404663
30-01-2023 03:55:54 INFO Epoch 1: [8240/10940] ---- BYOL Training Loss = 0.4816884994506836
30-01-2023 03:56:13 INFO Epoch 1: [8251/10940] ---- BYOL Training Loss = 0.5401347279548645
30-01-2023 03:56:31 INFO Epoch 1: [8262/10940] ---- BYOL Training Loss = 0.46711450815200806
30-01-2023 03:56:49 INFO Epoch 1: [8273/10940] ---- BYOL Training Loss = 0.39501339197158813
30-01-2023 03:57:42 INFO Epoch 1: [8273/10940] ---- BYOL Validation Loss = 0.4428475797176361
30-01-2023 03:58:00 INFO Epoch 1: [8284/10940] ---- BYOL Training Loss = 0.3652753233909607
30-01-2023 03:58:18 INFO Epoch 1: [8295/10940] ---- BYOL Training Loss = 0.3817737400531769
30-01-2023 03:58:37 INFO Epoch 1: [8306/10940] ---- BYOL Training Loss = 0.3705767095088959
30-01-2023 03:58:55 INFO Epoch 1: [8317/10940] ---- BYOL Training Loss = 0.44232186675071716
30-01-2023 03:59:47 INFO Epoch 1: [8317/10940] ---- BYOL Validation Loss = 0.44231271743774414
30-01-2023 04:00:05 INFO Epoch 1: [8328/10940] ---- BYOL Training Loss = 0.3904477655887604
30-01-2023 04:00:24 INFO Epoch 1: [8339/10940] ---- BYOL Training Loss = 0.3648757338523865
30-01-2023 04:00:42 INFO Epoch 1: [8350/10940] ---- BYOL Training Loss = 0.4136500358581543
30-01-2023 04:01:00 INFO Epoch 1: [8361/10940] ---- BYOL Training Loss = 0.4530794620513916
30-01-2023 04:01:52 INFO Epoch 1: [8361/10940] ---- BYOL Validation Loss = 0.47619837522506714
30-01-2023 04:02:11 INFO Epoch 1: [8372/10940] ---- BYOL Training Loss = 0.5256352424621582
30-01-2023 04:02:29 INFO Epoch 1: [8383/10940] ---- BYOL Training Loss = 0.505011260509491
30-01-2023 04:02:48 INFO Epoch 1: [8394/10940] ---- BYOL Training Loss = 0.48326215147972107
30-01-2023 04:03:06 INFO Epoch 1: [8405/10940] ---- BYOL Training Loss = 0.5246933698654175
30-01-2023 04:03:58 INFO Epoch 1: [8405/10940] ---- BYOL Validation Loss = 0.44843462109565735
30-01-2023 04:04:16 INFO Epoch 1: [8416/10940] ---- BYOL Training Loss = 0.4910164475440979
30-01-2023 04:04:35 INFO Epoch 1: [8427/10940] ---- BYOL Training Loss = 0.4293701648712158
30-01-2023 04:04:53 INFO Epoch 1: [8438/10940] ---- BYOL Training Loss = 0.4829978346824646
30-01-2023 04:05:11 INFO Epoch 1: [8449/10940] ---- BYOL Training Loss = 0.5317699909210205
30-01-2023 04:06:03 INFO Epoch 1: [8449/10940] ---- BYOL Validation Loss = 0.45123720169067383
30-01-2023 04:06:21 INFO Epoch 1: [8460/10940] ---- BYOL Training Loss = 0.5068387389183044
30-01-2023 04:06:40 INFO Epoch 1: [8471/10940] ---- BYOL Training Loss = 0.4356107711791992
30-01-2023 04:06:58 INFO Epoch 1: [8482/10940] ---- BYOL Training Loss = 0.5126739740371704
30-01-2023 04:07:17 INFO Epoch 1: [8493/10940] ---- BYOL Training Loss = 0.4335024356842041
30-01-2023 04:08:09 INFO Epoch 1: [8493/10940] ---- BYOL Validation Loss = 0.4316817820072174
30-01-2023 04:08:26 INFO Epoch 1: [8504/10940] ---- BYOL Training Loss = 0.4651153087615967
30-01-2023 04:08:45 INFO Epoch 1: [8515/10940] ---- BYOL Training Loss = 0.4880545139312744
30-01-2023 04:09:03 INFO Epoch 1: [8526/10940] ---- BYOL Training Loss = 0.4793721139431
30-01-2023 04:09:22 INFO Epoch 1: [8537/10940] ---- BYOL Training Loss = 0.42184409499168396
30-01-2023 04:10:14 INFO Epoch 1: [8537/10940] ---- BYOL Validation Loss = 0.44815564155578613
30-01-2023 04:10:32 INFO Epoch 1: [8548/10940] ---- BYOL Training Loss = 0.4712620675563812
30-01-2023 04:10:50 INFO Epoch 1: [8559/10940] ---- BYOL Training Loss = 0.43388980627059937
30-01-2023 04:11:09 INFO Epoch 1: [8570/10940] ---- BYOL Training Loss = 0.47962459921836853
30-01-2023 04:11:27 INFO Epoch 1: [8581/10940] ---- BYOL Training Loss = 0.40272074937820435
30-01-2023 04:12:19 INFO Epoch 1: [8581/10940] ---- BYOL Validation Loss = 0.45516708493232727
30-01-2023 04:12:37 INFO Epoch 1: [8592/10940] ---- BYOL Training Loss = 0.4190048277378082
30-01-2023 04:12:56 INFO Epoch 1: [8603/10940] ---- BYOL Training Loss = 0.4797598719596863
30-01-2023 04:13:14 INFO Epoch 1: [8614/10940] ---- BYOL Training Loss = 0.46075791120529175
30-01-2023 04:13:32 INFO Epoch 1: [8625/10940] ---- BYOL Training Loss = 0.4337010383605957
30-01-2023 04:14:24 INFO Epoch 1: [8625/10940] ---- BYOL Validation Loss = 0.44447317719459534
30-01-2023 04:14:43 INFO Epoch 1: [8636/10940] ---- BYOL Training Loss = 0.3864126205444336
30-01-2023 04:15:01 INFO Epoch 1: [8647/10940] ---- BYOL Training Loss = 0.42144760489463806
30-01-2023 04:15:19 INFO Epoch 1: [8658/10940] ---- BYOL Training Loss = 0.4224674105644226
30-01-2023 04:15:38 INFO Epoch 1: [8669/10940] ---- BYOL Training Loss = 0.40046119689941406
30-01-2023 04:16:30 INFO Epoch 1: [8669/10940] ---- BYOL Validation Loss = 0.45897477865219116
30-01-2023 04:16:48 INFO Epoch 1: [8680/10940] ---- BYOL Training Loss = 0.36560410261154175
30-01-2023 04:17:06 INFO Epoch 1: [8691/10940] ---- BYOL Training Loss = 0.36366623640060425
30-01-2023 04:17:25 INFO Epoch 1: [8702/10940] ---- BYOL Training Loss = 0.3959653079509735
30-01-2023 04:17:43 INFO Epoch 1: [8713/10940] ---- BYOL Training Loss = 0.39670535922050476
30-01-2023 04:18:35 INFO Epoch 1: [8713/10940] ---- BYOL Validation Loss = 0.473345011472702
30-01-2023 04:18:54 INFO Epoch 1: [8724/10940] ---- BYOL Training Loss = 0.34906309843063354
30-01-2023 04:19:12 INFO Epoch 1: [8735/10940] ---- BYOL Training Loss = 0.4225119650363922
30-01-2023 04:19:30 INFO Epoch 1: [8746/10940] ---- BYOL Training Loss = 0.41812318563461304
30-01-2023 04:19:49 INFO Epoch 1: [8757/10940] ---- BYOL Training Loss = 0.47229185700416565
30-01-2023 04:20:41 INFO Epoch 1: [8757/10940] ---- BYOL Validation Loss = 0.45113682746887207
30-01-2023 04:20:59 INFO Epoch 1: [8768/10940] ---- BYOL Training Loss = 0.4252508282661438
30-01-2023 04:21:18 INFO Epoch 1: [8779/10940] ---- BYOL Training Loss = 0.3403584957122803
30-01-2023 04:21:36 INFO Epoch 1: [8790/10940] ---- BYOL Training Loss = 0.3632326126098633
30-01-2023 04:21:54 INFO Epoch 1: [8801/10940] ---- BYOL Training Loss = 0.45727354288101196
30-01-2023 04:22:46 INFO Epoch 1: [8801/10940] ---- BYOL Validation Loss = 0.4557547867298126
30-01-2023 04:23:05 INFO Epoch 1: [8812/10940] ---- BYOL Training Loss = 0.46872344613075256
30-01-2023 04:23:23 INFO Epoch 1: [8823/10940] ---- BYOL Training Loss = 0.4960060119628906
30-01-2023 04:23:41 INFO Epoch 1: [8834/10940] ---- BYOL Training Loss = 0.5220924019813538
30-01-2023 04:24:00 INFO Epoch 1: [8845/10940] ---- BYOL Training Loss = 0.493051141500473
30-01-2023 04:24:52 INFO Epoch 1: [8845/10940] ---- BYOL Validation Loss = 0.4221600890159607
30-01-2023 04:25:10 INFO Epoch 1: [8856/10940] ---- BYOL Training Loss = 0.4398156702518463
30-01-2023 04:25:28 INFO Epoch 1: [8867/10940] ---- BYOL Training Loss = 0.3689214289188385
30-01-2023 04:25:47 INFO Epoch 1: [8878/10940] ---- BYOL Training Loss = 0.38928547501564026
30-01-2023 04:26:05 INFO Epoch 1: [8889/10940] ---- BYOL Training Loss = 0.41831713914871216
30-01-2023 04:26:57 INFO Epoch 1: [8889/10940] ---- BYOL Validation Loss = 0.43617263436317444
30-01-2023 04:27:16 INFO Epoch 1: [8900/10940] ---- BYOL Training Loss = 0.4595818519592285
30-01-2023 04:27:34 INFO Epoch 1: [8911/10940] ---- BYOL Training Loss = 0.4788653254508972
30-01-2023 04:27:52 INFO Epoch 1: [8922/10940] ---- BYOL Training Loss = 0.5458344221115112
30-01-2023 04:28:11 INFO Epoch 1: [8933/10940] ---- BYOL Training Loss = 0.5294947028160095
30-01-2023 04:29:03 INFO Epoch 1: [8933/10940] ---- BYOL Validation Loss = 0.45176205039024353
30-01-2023 04:29:21 INFO Epoch 1: [8944/10940] ---- BYOL Training Loss = 0.45104217529296875
30-01-2023 04:29:39 INFO Epoch 1: [8955/10940] ---- BYOL Training Loss = 0.4812028408050537
30-01-2023 04:29:58 INFO Epoch 1: [8966/10940] ---- BYOL Training Loss = 0.48944592475891113
30-01-2023 04:30:16 INFO Epoch 1: [8977/10940] ---- BYOL Training Loss = 0.3748216927051544
30-01-2023 04:31:08 INFO Epoch 1: [8977/10940] ---- BYOL Validation Loss = 0.42709872126579285
30-01-2023 04:31:26 INFO Epoch 1: [8988/10940] ---- BYOL Training Loss = 0.3738436996936798
30-01-2023 04:31:45 INFO Epoch 1: [8999/10940] ---- BYOL Training Loss = 0.3800228536128998
30-01-2023 04:32:03 INFO Epoch 1: [9010/10940] ---- BYOL Training Loss = 0.4201330244541168
30-01-2023 04:32:22 INFO Epoch 1: [9021/10940] ---- BYOL Training Loss = 0.4332502782344818
30-01-2023 04:33:14 INFO Epoch 1: [9021/10940] ---- BYOL Validation Loss = 0.44804781675338745
30-01-2023 04:33:32 INFO Epoch 1: [9032/10940] ---- BYOL Training Loss = 0.382171094417572
30-01-2023 04:33:50 INFO Epoch 1: [9043/10940] ---- BYOL Training Loss = 0.35948580503463745
30-01-2023 04:34:09 INFO Epoch 1: [9054/10940] ---- BYOL Training Loss = 0.37030622363090515
30-01-2023 04:34:27 INFO Epoch 1: [9065/10940] ---- BYOL Training Loss = 0.3998247981071472
30-01-2023 04:35:19 INFO Epoch 1: [9065/10940] ---- BYOL Validation Loss = 0.43384772539138794
30-01-2023 04:35:37 INFO Epoch 1: [9076/10940] ---- BYOL Training Loss = 0.4066828191280365
30-01-2023 04:35:55 INFO Epoch 1: [9087/10940] ---- BYOL Training Loss = 0.36885789036750793
30-01-2023 04:36:14 INFO Epoch 1: [9098/10940] ---- BYOL Training Loss = 0.4026990532875061
30-01-2023 04:36:33 INFO Epoch 1: [9109/10940] ---- BYOL Training Loss = 0.4666820168495178
30-01-2023 04:37:24 INFO Epoch 1: [9109/10940] ---- BYOL Validation Loss = 0.42154017090797424
30-01-2023 04:37:43 INFO Epoch 1: [9120/10940] ---- BYOL Training Loss = 0.377164751291275
30-01-2023 04:38:01 INFO Epoch 1: [9131/10940] ---- BYOL Training Loss = 0.4240991175174713
30-01-2023 04:38:20 INFO Epoch 1: [9142/10940] ---- BYOL Training Loss = 0.4569777548313141
30-01-2023 04:38:38 INFO Epoch 1: [9153/10940] ---- BYOL Training Loss = 0.3974876403808594
30-01-2023 04:39:30 INFO Epoch 1: [9153/10940] ---- BYOL Validation Loss = 0.4441409707069397
30-01-2023 04:39:48 INFO Epoch 1: [9164/10940] ---- BYOL Training Loss = 0.43794184923171997
30-01-2023 04:40:07 INFO Epoch 1: [9175/10940] ---- BYOL Training Loss = 0.39789777994155884
30-01-2023 04:40:25 INFO Epoch 1: [9186/10940] ---- BYOL Training Loss = 0.3323970139026642
30-01-2023 04:40:44 INFO Epoch 1: [9197/10940] ---- BYOL Training Loss = 0.40926164388656616
30-01-2023 04:41:36 INFO Epoch 1: [9197/10940] ---- BYOL Validation Loss = 0.4289439618587494
30-01-2023 04:41:54 INFO Epoch 1: [9208/10940] ---- BYOL Training Loss = 0.49274125695228577
30-01-2023 04:42:12 INFO Epoch 1: [9219/10940] ---- BYOL Training Loss = 0.4490639567375183
30-01-2023 04:42:31 INFO Epoch 1: [9230/10940] ---- BYOL Training Loss = 0.4675091803073883
30-01-2023 04:42:49 INFO Epoch 1: [9241/10940] ---- BYOL Training Loss = 0.48108071088790894
30-01-2023 04:43:42 INFO Epoch 1: [9241/10940] ---- BYOL Validation Loss = 0.4163232147693634
30-01-2023 04:43:59 INFO Epoch 1: [9252/10940] ---- BYOL Training Loss = 0.38458940386772156
30-01-2023 04:44:18 INFO Epoch 1: [9263/10940] ---- BYOL Training Loss = 0.4776061177253723
30-01-2023 04:44:37 INFO Epoch 1: [9274/10940] ---- BYOL Training Loss = 0.45483168959617615
30-01-2023 04:44:55 INFO Epoch 1: [9285/10940] ---- BYOL Training Loss = 0.42547911405563354
30-01-2023 04:45:47 INFO Epoch 1: [9285/10940] ---- BYOL Validation Loss = 0.41313448548316956
30-01-2023 04:46:05 INFO Epoch 1: [9296/10940] ---- BYOL Training Loss = 0.43272584676742554
30-01-2023 04:46:24 INFO Epoch 1: [9307/10940] ---- BYOL Training Loss = 0.4007909297943115
30-01-2023 04:46:42 INFO Epoch 1: [9318/10940] ---- BYOL Training Loss = 0.4105660915374756
30-01-2023 04:47:01 INFO Epoch 1: [9329/10940] ---- BYOL Training Loss = 0.4982732832431793
30-01-2023 04:47:53 INFO Epoch 1: [9329/10940] ---- BYOL Validation Loss = 0.9034350514411926
30-01-2023 04:48:11 INFO Epoch 1: [9340/10940] ---- BYOL Training Loss = 0.43311262130737305
30-01-2023 04:48:29 INFO Epoch 1: [9351/10940] ---- BYOL Training Loss = 0.39621520042419434
30-01-2023 04:48:48 INFO Epoch 1: [9362/10940] ---- BYOL Training Loss = 0.4421689510345459
30-01-2023 04:49:06 INFO Epoch 1: [9373/10940] ---- BYOL Training Loss = 0.4565398097038269
30-01-2023 04:49:58 INFO Epoch 1: [9373/10940] ---- BYOL Validation Loss = 0.43869447708129883
30-01-2023 04:50:16 INFO Epoch 1: [9384/10940] ---- BYOL Training Loss = 0.4358406662940979
30-01-2023 04:50:35 INFO Epoch 1: [9395/10940] ---- BYOL Training Loss = 0.3505212068557739
30-01-2023 04:50:53 INFO Epoch 1: [9406/10940] ---- BYOL Training Loss = 0.39498770236968994
30-01-2023 04:51:12 INFO Epoch 1: [9417/10940] ---- BYOL Training Loss = 0.43728122115135193
30-01-2023 04:52:04 INFO Epoch 1: [9417/10940] ---- BYOL Validation Loss = 0.4161422848701477
30-01-2023 04:52:22 INFO Epoch 1: [9428/10940] ---- BYOL Training Loss = 0.4538974165916443
30-01-2023 04:52:40 INFO Epoch 1: [9439/10940] ---- BYOL Training Loss = 0.480485200881958
30-01-2023 04:52:59 INFO Epoch 1: [9450/10940] ---- BYOL Training Loss = 0.4531538486480713
30-01-2023 04:53:18 INFO Epoch 1: [9461/10940] ---- BYOL Training Loss = 0.40727710723876953
30-01-2023 04:54:10 INFO Epoch 1: [9461/10940] ---- BYOL Validation Loss = 0.41228586435317993
30-01-2023 04:54:28 INFO Epoch 1: [9472/10940] ---- BYOL Training Loss = 0.38754716515541077
30-01-2023 04:54:46 INFO Epoch 1: [9483/10940] ---- BYOL Training Loss = 0.3685283064842224
30-01-2023 04:55:05 INFO Epoch 1: [9494/10940] ---- BYOL Training Loss = 0.3483870029449463
30-01-2023 04:55:24 INFO Epoch 1: [9505/10940] ---- BYOL Training Loss = 0.3572641611099243
30-01-2023 04:56:16 INFO Epoch 1: [9505/10940] ---- BYOL Validation Loss = 0.4413459599018097
30-01-2023 04:56:33 INFO Epoch 1: [9516/10940] ---- BYOL Training Loss = 0.4318722188472748
30-01-2023 04:56:52 INFO Epoch 1: [9527/10940] ---- BYOL Training Loss = 0.3783646821975708
30-01-2023 04:57:11 INFO Epoch 1: [9538/10940] ---- BYOL Training Loss = 0.34917038679122925
30-01-2023 04:57:29 INFO Epoch 1: [9549/10940] ---- BYOL Training Loss = 0.3389768600463867
30-01-2023 04:58:21 INFO Epoch 1: [9549/10940] ---- BYOL Validation Loss = 0.4129396975040436
30-01-2023 04:58:39 INFO Epoch 1: [9560/10940] ---- BYOL Training Loss = 0.3923419117927551
30-01-2023 04:58:58 INFO Epoch 1: [9571/10940] ---- BYOL Training Loss = 0.43044987320899963
30-01-2023 04:59:16 INFO Epoch 1: [9582/10940] ---- BYOL Training Loss = 0.438502699136734
30-01-2023 04:59:35 INFO Epoch 1: [9593/10940] ---- BYOL Training Loss = 0.3845748007297516
30-01-2023 05:00:27 INFO Epoch 1: [9593/10940] ---- BYOL Validation Loss = 0.4075617790222168
30-01-2023 05:00:45 INFO Epoch 1: [9604/10940] ---- BYOL Training Loss = 0.422781378030777
30-01-2023 05:01:04 INFO Epoch 1: [9615/10940] ---- BYOL Training Loss = 0.45016971230506897
30-01-2023 05:01:22 INFO Epoch 1: [9626/10940] ---- BYOL Training Loss = 0.4745069444179535
30-01-2023 05:01:41 INFO Epoch 1: [9637/10940] ---- BYOL Training Loss = 0.43303021788597107
30-01-2023 05:02:33 INFO Epoch 1: [9637/10940] ---- BYOL Validation Loss = 0.43631511926651
30-01-2023 05:02:51 INFO Epoch 1: [9648/10940] ---- BYOL Training Loss = 0.4754633903503418
30-01-2023 05:03:09 INFO Epoch 1: [9659/10940] ---- BYOL Training Loss = 0.46216922998428345
30-01-2023 05:03:28 INFO Epoch 1: [9670/10940] ---- BYOL Training Loss = 0.3813651502132416
30-01-2023 05:03:46 INFO Epoch 1: [9681/10940] ---- BYOL Training Loss = 0.37092700600624084
30-01-2023 05:04:38 INFO Epoch 1: [9681/10940] ---- BYOL Validation Loss = 0.42065200209617615
30-01-2023 05:04:57 INFO Epoch 1: [9692/10940] ---- BYOL Training Loss = 0.4058077931404114
30-01-2023 05:05:15 INFO Epoch 1: [9703/10940] ---- BYOL Training Loss = 0.4570106565952301
30-01-2023 05:05:33 INFO Epoch 1: [9714/10940] ---- BYOL Training Loss = 0.4035472869873047
30-01-2023 05:05:52 INFO Epoch 1: [9725/10940] ---- BYOL Training Loss = 0.41943424940109253
30-01-2023 05:06:44 INFO Epoch 1: [9725/10940] ---- BYOL Validation Loss = 0.41430336236953735
30-01-2023 05:07:02 INFO Epoch 1: [9736/10940] ---- BYOL Training Loss = 0.45138850808143616
30-01-2023 05:07:21 INFO Epoch 1: [9747/10940] ---- BYOL Training Loss = 0.45991531014442444
30-01-2023 05:07:39 INFO Epoch 1: [9758/10940] ---- BYOL Training Loss = 0.4527185559272766
30-01-2023 05:07:58 INFO Epoch 1: [9769/10940] ---- BYOL Training Loss = 0.4212944507598877
30-01-2023 05:08:50 INFO Epoch 1: [9769/10940] ---- BYOL Validation Loss = 0.4204745292663574
30-01-2023 05:09:08 INFO Epoch 1: [9780/10940] ---- BYOL Training Loss = 0.40085476636886597
30-01-2023 05:09:26 INFO Epoch 1: [9791/10940] ---- BYOL Training Loss = 0.4169073700904846
30-01-2023 05:09:45 INFO Epoch 1: [9802/10940] ---- BYOL Training Loss = 0.38603901863098145
30-01-2023 05:10:03 INFO Epoch 1: [9813/10940] ---- BYOL Training Loss = 0.35278570652008057
30-01-2023 05:10:55 INFO Epoch 1: [9813/10940] ---- BYOL Validation Loss = 0.43954870104789734
30-01-2023 05:11:14 INFO Epoch 1: [9824/10940] ---- BYOL Training Loss = 0.42168015241622925
30-01-2023 05:11:32 INFO Epoch 1: [9835/10940] ---- BYOL Training Loss = 0.47637003660202026
30-01-2023 05:11:51 INFO Epoch 1: [9846/10940] ---- BYOL Training Loss = 0.5525521636009216
30-01-2023 05:12:09 INFO Epoch 1: [9857/10940] ---- BYOL Training Loss = 0.4577024579048157
30-01-2023 05:13:01 INFO Epoch 1: [9857/10940] ---- BYOL Validation Loss = 0.4214985966682434
30-01-2023 05:13:19 INFO Epoch 1: [9868/10940] ---- BYOL Training Loss = 0.3222384452819824
30-01-2023 05:13:38 INFO Epoch 1: [9879/10940] ---- BYOL Training Loss = 0.37331634759902954
30-01-2023 05:13:57 INFO Epoch 1: [9890/10940] ---- BYOL Training Loss = 0.37069565057754517
30-01-2023 05:14:15 INFO Epoch 1: [9901/10940] ---- BYOL Training Loss = 0.39117711782455444
30-01-2023 05:15:08 INFO Epoch 1: [9901/10940] ---- BYOL Validation Loss = 0.42494091391563416
30-01-2023 05:15:26 INFO Epoch 1: [9912/10940] ---- BYOL Training Loss = 0.4277331233024597
30-01-2023 05:15:44 INFO Epoch 1: [9923/10940] ---- BYOL Training Loss = 0.34896594285964966
30-01-2023 05:16:03 INFO Epoch 1: [9934/10940] ---- BYOL Training Loss = 0.3871786296367645
30-01-2023 05:16:21 INFO Epoch 1: [9945/10940] ---- BYOL Training Loss = 0.4011905789375305
30-01-2023 05:17:13 INFO Epoch 1: [9945/10940] ---- BYOL Validation Loss = 0.41409990191459656
30-01-2023 05:17:32 INFO Epoch 1: [9956/10940] ---- BYOL Training Loss = 0.41412678360939026
30-01-2023 05:17:50 INFO Epoch 1: [9967/10940] ---- BYOL Training Loss = 0.461012065410614
30-01-2023 05:18:09 INFO Epoch 1: [9978/10940] ---- BYOL Training Loss = 0.39197978377342224
30-01-2023 05:18:27 INFO Epoch 1: [9989/10940] ---- BYOL Training Loss = 0.39263495802879333
30-01-2023 05:19:19 INFO Epoch 1: [9989/10940] ---- BYOL Validation Loss = 0.412971556186676
30-01-2023 05:19:38 INFO Epoch 1: [10000/10940] ---- BYOL Training Loss = 0.3276076912879944
30-01-2023 05:19:56 INFO Epoch 1: [10011/10940] ---- BYOL Training Loss = 0.36989346146583557
30-01-2023 05:20:15 INFO Epoch 1: [10022/10940] ---- BYOL Training Loss = 0.3805619478225708
30-01-2023 05:20:34 INFO Epoch 1: [10033/10940] ---- BYOL Training Loss = 0.3743928372859955
30-01-2023 05:21:26 INFO Epoch 1: [10033/10940] ---- BYOL Validation Loss = 0.3997977077960968
30-01-2023 05:21:44 INFO Epoch 1: [10044/10940] ---- BYOL Training Loss = 0.33644554018974304
30-01-2023 05:22:03 INFO Epoch 1: [10055/10940] ---- BYOL Training Loss = 0.3789134621620178
30-01-2023 05:22:21 INFO Epoch 1: [10066/10940] ---- BYOL Training Loss = 0.3610624670982361
30-01-2023 05:22:40 INFO Epoch 1: [10077/10940] ---- BYOL Training Loss = 0.3895736038684845
30-01-2023 05:23:32 INFO Epoch 1: [10077/10940] ---- BYOL Validation Loss = 0.4337039589881897
30-01-2023 05:23:50 INFO Epoch 1: [10088/10940] ---- BYOL Training Loss = 0.41217389702796936
30-01-2023 05:24:09 INFO Epoch 1: [10099/10940] ---- BYOL Training Loss = 0.4102729856967926
30-01-2023 05:24:28 INFO Epoch 1: [10110/10940] ---- BYOL Training Loss = 0.4191431999206543
30-01-2023 05:24:46 INFO Epoch 1: [10121/10940] ---- BYOL Training Loss = 0.4337101876735687
30-01-2023 05:25:38 INFO Epoch 1: [10121/10940] ---- BYOL Validation Loss = 0.4132257401943207
30-01-2023 05:25:56 INFO Epoch 1: [10132/10940] ---- BYOL Training Loss = 0.5438169240951538
30-01-2023 05:26:15 INFO Epoch 1: [10143/10940] ---- BYOL Training Loss = 0.47269243001937866
30-01-2023 05:26:33 INFO Epoch 1: [10154/10940] ---- BYOL Training Loss = 0.39142322540283203
30-01-2023 05:26:52 INFO Epoch 1: [10165/10940] ---- BYOL Training Loss = 0.37929031252861023
30-01-2023 05:27:44 INFO Epoch 1: [10165/10940] ---- BYOL Validation Loss = 0.41977986693382263
30-01-2023 05:28:02 INFO Epoch 1: [10176/10940] ---- BYOL Training Loss = 0.34613534808158875
30-01-2023 05:28:21 INFO Epoch 1: [10187/10940] ---- BYOL Training Loss = 0.33567380905151367
30-01-2023 05:28:39 INFO Epoch 1: [10198/10940] ---- BYOL Training Loss = 0.3184003531932831
30-01-2023 05:28:58 INFO Epoch 1: [10209/10940] ---- BYOL Training Loss = 0.3501732051372528
30-01-2023 05:29:50 INFO Epoch 1: [10209/10940] ---- BYOL Validation Loss = 0.39773908257484436
30-01-2023 05:30:08 INFO Epoch 1: [10220/10940] ---- BYOL Training Loss = 0.39696913957595825
30-01-2023 05:30:26 INFO Epoch 1: [10231/10940] ---- BYOL Training Loss = 0.4375455975532532
30-01-2023 05:30:46 INFO Epoch 1: [10242/10940] ---- BYOL Training Loss = 0.4698333740234375
30-01-2023 05:31:04 INFO Epoch 1: [10253/10940] ---- BYOL Training Loss = 0.4385948181152344
30-01-2023 05:31:56 INFO Epoch 1: [10253/10940] ---- BYOL Validation Loss = 0.40622732043266296
30-01-2023 05:32:14 INFO Epoch 1: [10264/10940] ---- BYOL Training Loss = 0.4101718068122864
30-01-2023 05:32:33 INFO Epoch 1: [10275/10940] ---- BYOL Training Loss = 0.384367972612381
30-01-2023 05:32:52 INFO Epoch 1: [10286/10940] ---- BYOL Training Loss = 0.4204947352409363
30-01-2023 05:33:10 INFO Epoch 1: [10297/10940] ---- BYOL Training Loss = 0.39790797233581543
30-01-2023 05:34:02 INFO Epoch 1: [10297/10940] ---- BYOL Validation Loss = 0.4004652798175812
30-01-2023 05:34:20 INFO Epoch 1: [10308/10940] ---- BYOL Training Loss = 0.4270506799221039
30-01-2023 05:34:39 INFO Epoch 1: [10319/10940] ---- BYOL Training Loss = 0.5043472051620483
30-01-2023 05:34:58 INFO Epoch 1: [10330/10940] ---- BYOL Training Loss = 0.4666239619255066
30-01-2023 05:35:17 INFO Epoch 1: [10341/10940] ---- BYOL Training Loss = 0.4335612654685974
30-01-2023 05:36:09 INFO Epoch 1: [10341/10940] ---- BYOL Validation Loss = 0.4011261761188507
30-01-2023 05:36:27 INFO Epoch 1: [10352/10940] ---- BYOL Training Loss = 0.42274150252342224
30-01-2023 05:36:45 INFO Epoch 1: [10363/10940] ---- BYOL Training Loss = 0.4272347092628479
30-01-2023 05:37:04 INFO Epoch 1: [10374/10940] ---- BYOL Training Loss = 0.45703062415122986
30-01-2023 05:37:23 INFO Epoch 1: [10385/10940] ---- BYOL Training Loss = 0.3661510646343231
30-01-2023 05:38:15 INFO Epoch 1: [10385/10940] ---- BYOL Validation Loss = 0.3994843065738678
30-01-2023 05:38:33 INFO Epoch 1: [10396/10940] ---- BYOL Training Loss = 0.3082132935523987
30-01-2023 05:38:51 INFO Epoch 1: [10407/10940] ---- BYOL Training Loss = 0.36498546600341797
30-01-2023 05:39:10 INFO Epoch 1: [10418/10940] ---- BYOL Training Loss = 0.41382092237472534
30-01-2023 05:39:28 INFO Epoch 1: [10429/10940] ---- BYOL Training Loss = 0.35751214623451233
30-01-2023 05:40:21 INFO Epoch 1: [10429/10940] ---- BYOL Validation Loss = 0.40813547372817993
30-01-2023 05:40:39 INFO Epoch 1: [10440/10940] ---- BYOL Training Loss = 0.34315457940101624
30-01-2023 05:40:58 INFO Epoch 1: [10451/10940] ---- BYOL Training Loss = 0.3454764783382416
30-01-2023 05:41:17 INFO Epoch 1: [10462/10940] ---- BYOL Training Loss = 0.3381223678588867
30-01-2023 05:41:35 INFO Epoch 1: [10473/10940] ---- BYOL Training Loss = 0.3492029905319214
30-01-2023 05:42:27 INFO Epoch 1: [10473/10940] ---- BYOL Validation Loss = 0.38018089532852173
30-01-2023 05:42:46 INFO Epoch 1: [10484/10940] ---- BYOL Training Loss = 0.3744595944881439
30-01-2023 05:43:04 INFO Epoch 1: [10495/10940] ---- BYOL Training Loss = 0.4160735607147217
30-01-2023 05:43:22 INFO Epoch 1: [10506/10940] ---- BYOL Training Loss = 0.4486604332923889
30-01-2023 05:43:41 INFO Epoch 1: [10517/10940] ---- BYOL Training Loss = 0.3964386582374573
30-01-2023 05:44:33 INFO Epoch 1: [10517/10940] ---- BYOL Validation Loss = 0.4022500813007355
30-01-2023 05:44:51 INFO Epoch 1: [10528/10940] ---- BYOL Training Loss = 0.30746689438819885
30-01-2023 05:45:10 INFO Epoch 1: [10539/10940] ---- BYOL Training Loss = 0.41127878427505493
30-01-2023 05:45:29 INFO Epoch 1: [10550/10940] ---- BYOL Training Loss = 0.47648268938064575
30-01-2023 05:45:48 INFO Epoch 1: [10561/10940] ---- BYOL Training Loss = 0.38602134585380554
30-01-2023 05:46:40 INFO Epoch 1: [10561/10940] ---- BYOL Validation Loss = 0.39484935998916626
30-01-2023 05:46:58 INFO Epoch 1: [10572/10940] ---- BYOL Training Loss = 0.3843146562576294
30-01-2023 05:47:17 INFO Epoch 1: [10583/10940] ---- BYOL Training Loss = 0.385571151971817
30-01-2023 05:47:35 INFO Epoch 1: [10594/10940] ---- BYOL Training Loss = 0.35953083634376526
30-01-2023 05:47:54 INFO Epoch 1: [10605/10940] ---- BYOL Training Loss = 0.3698301613330841
30-01-2023 05:48:46 INFO Epoch 1: [10605/10940] ---- BYOL Validation Loss = 0.39107200503349304
30-01-2023 05:49:04 INFO Epoch 1: [10616/10940] ---- BYOL Training Loss = 0.37627261877059937
30-01-2023 05:49:23 INFO Epoch 1: [10627/10940] ---- BYOL Training Loss = 0.3234628736972809
30-01-2023 05:49:41 INFO Epoch 1: [10638/10940] ---- BYOL Training Loss = 0.3460600972175598
30-01-2023 05:50:00 INFO Epoch 1: [10649/10940] ---- BYOL Training Loss = 0.32380059361457825
30-01-2023 05:50:52 INFO Epoch 1: [10649/10940] ---- BYOL Validation Loss = 0.3850826621055603
30-01-2023 05:51:10 INFO Epoch 1: [10660/10940] ---- BYOL Training Loss = 0.3316650986671448
30-01-2023 05:51:29 INFO Epoch 1: [10671/10940] ---- BYOL Training Loss = 0.37436845898628235
30-01-2023 05:51:48 INFO Epoch 1: [10682/10940] ---- BYOL Training Loss = 0.37020614743232727
30-01-2023 05:52:06 INFO Epoch 1: [10693/10940] ---- BYOL Training Loss = 0.3124452233314514
30-01-2023 05:52:58 INFO Epoch 1: [10693/10940] ---- BYOL Validation Loss = 0.3927050232887268
30-01-2023 05:53:17 INFO Epoch 1: [10704/10940] ---- BYOL Training Loss = 0.3548489809036255
30-01-2023 05:53:35 INFO Epoch 1: [10715/10940] ---- BYOL Training Loss = 0.37220102548599243
30-01-2023 05:53:53 INFO Epoch 1: [10726/10940] ---- BYOL Training Loss = 0.3793336749076843
30-01-2023 05:54:12 INFO Epoch 1: [10737/10940] ---- BYOL Training Loss = 0.4565567374229431
30-01-2023 05:55:04 INFO Epoch 1: [10737/10940] ---- BYOL Validation Loss = 0.4155265986919403
30-01-2023 05:55:22 INFO Epoch 1: [10748/10940] ---- BYOL Training Loss = 0.4390296936035156
30-01-2023 05:55:41 INFO Epoch 1: [10759/10940] ---- BYOL Training Loss = 0.40808406472206116
30-01-2023 05:56:00 INFO Epoch 1: [10770/10940] ---- BYOL Training Loss = 0.38414880633354187
30-01-2023 05:56:19 INFO Epoch 1: [10781/10940] ---- BYOL Training Loss = 0.37342575192451477
30-01-2023 05:57:11 INFO Epoch 1: [10781/10940] ---- BYOL Validation Loss = 0.40446481108665466
30-01-2023 05:57:29 INFO Epoch 1: [10792/10940] ---- BYOL Training Loss = 0.40068769454956055
30-01-2023 05:57:48 INFO Epoch 1: [10803/10940] ---- BYOL Training Loss = 0.397514671087265
30-01-2023 05:58:06 INFO Epoch 1: [10814/10940] ---- BYOL Training Loss = 0.4249058663845062
30-01-2023 05:58:25 INFO Epoch 1: [10825/10940] ---- BYOL Training Loss = 0.4416901171207428
30-01-2023 05:59:17 INFO Epoch 1: [10825/10940] ---- BYOL Validation Loss = 0.39702653884887695
30-01-2023 05:59:35 INFO Epoch 1: [10836/10940] ---- BYOL Training Loss = 0.37672728300094604
30-01-2023 05:59:54 INFO Epoch 1: [10847/10940] ---- BYOL Training Loss = 0.38354676961898804
30-01-2023 06:00:13 INFO Epoch 1: [10858/10940] ---- BYOL Training Loss = 0.41891083121299744
30-01-2023 06:00:31 INFO Epoch 1: [10869/10940] ---- BYOL Training Loss = 0.4436335563659668
30-01-2023 06:01:23 INFO Epoch 1: [10869/10940] ---- BYOL Validation Loss = 0.39821523427963257
30-01-2023 06:01:41 INFO Epoch 1: [10880/10940] ---- BYOL Training Loss = 0.4792858958244324
30-01-2023 06:02:00 INFO Epoch 1: [10891/10940] ---- BYOL Training Loss = 0.5073760747909546
30-01-2023 06:02:19 INFO Epoch 1: [10902/10940] ---- BYOL Training Loss = 0.4803878664970398
30-01-2023 06:02:37 INFO Epoch 1: [10913/10940] ---- BYOL Training Loss = 0.43827611207962036
30-01-2023 06:03:29 INFO Epoch 1: [10913/10940] ---- BYOL Validation Loss = 0.40550631284713745
30-01-2023 06:03:48 INFO Epoch 1: [10924/10940] ---- BYOL Training Loss = 0.4085625112056732
30-01-2023 06:04:06 INFO Epoch 1: [10935/10940] ---- BYOL Training Loss = 0.33150023221969604
30-01-2023 06:04:16 INFO Starting Epoch: 2
30-01-2023 06:04:34 INFO Epoch 2: [12/10940] ---- BYOL Training Loss = 0.5054260492324829
30-01-2023 06:04:51 INFO Epoch 2: [23/10940] ---- BYOL Training Loss = 0.4496184289455414
30-01-2023 06:05:09 INFO Epoch 2: [34/10940] ---- BYOL Training Loss = 0.36671414971351624
30-01-2023 06:05:26 INFO Epoch 2: [45/10940] ---- BYOL Training Loss = 0.33830463886260986
30-01-2023 06:06:18 INFO Epoch 2: [45/10940] ---- BYOL Validation Loss = 0.39189305901527405
30-01-2023 06:06:35 INFO Epoch 2: [56/10940] ---- BYOL Training Loss = 0.3732432723045349
30-01-2023 06:06:53 INFO Epoch 2: [67/10940] ---- BYOL Training Loss = 0.41649699211120605
30-01-2023 06:07:10 INFO Epoch 2: [78/10940] ---- BYOL Training Loss = 0.38813045620918274
30-01-2023 06:07:28 INFO Epoch 2: [89/10940] ---- BYOL Training Loss = 0.3793260157108307
30-01-2023 06:08:20 INFO Epoch 2: [89/10940] ---- BYOL Validation Loss = 0.4015674591064453
30-01-2023 06:08:37 INFO Epoch 2: [100/10940] ---- BYOL Training Loss = 0.37200117111206055
30-01-2023 06:08:55 INFO Epoch 2: [111/10940] ---- BYOL Training Loss = 0.37910932302474976
30-01-2023 06:09:12 INFO Epoch 2: [122/10940] ---- BYOL Training Loss = 0.39956000447273254
30-01-2023 06:09:30 INFO Epoch 2: [133/10940] ---- BYOL Training Loss = 0.45954638719558716
30-01-2023 06:10:22 INFO Epoch 2: [133/10940] ---- BYOL Validation Loss = 0.37295395135879517
30-01-2023 06:10:39 INFO Epoch 2: [144/10940] ---- BYOL Training Loss = 0.4366896152496338
30-01-2023 06:10:56 INFO Epoch 2: [155/10940] ---- BYOL Training Loss = 0.39488181471824646
30-01-2023 06:11:14 INFO Epoch 2: [166/10940] ---- BYOL Training Loss = 0.3099452257156372
30-01-2023 06:11:32 INFO Epoch 2: [177/10940] ---- BYOL Training Loss = 0.2740251421928406
30-01-2023 06:12:24 INFO Epoch 2: [177/10940] ---- BYOL Validation Loss = 0.3669469952583313
30-01-2023 06:12:41 INFO Epoch 2: [188/10940] ---- BYOL Training Loss = 0.36988207697868347
30-01-2023 06:12:58 INFO Epoch 2: [199/10940] ---- BYOL Training Loss = 0.44515371322631836
30-01-2023 06:13:16 INFO Epoch 2: [210/10940] ---- BYOL Training Loss = 0.39373552799224854
30-01-2023 06:13:33 INFO Epoch 2: [221/10940] ---- BYOL Training Loss = 0.35078054666519165
30-01-2023 06:14:25 INFO Epoch 2: [221/10940] ---- BYOL Validation Loss = 0.37835508584976196
30-01-2023 06:14:43 INFO Epoch 2: [232/10940] ---- BYOL Training Loss = 0.31094154715538025
30-01-2023 06:15:00 INFO Epoch 2: [243/10940] ---- BYOL Training Loss = 0.3284662365913391
30-01-2023 06:15:18 INFO Epoch 2: [254/10940] ---- BYOL Training Loss = 0.33643320202827454
30-01-2023 06:15:35 INFO Epoch 2: [265/10940] ---- BYOL Training Loss = 0.3112640380859375
30-01-2023 06:16:27 INFO Epoch 2: [265/10940] ---- BYOL Validation Loss = 0.34108883142471313
30-01-2023 06:16:44 INFO Epoch 2: [276/10940] ---- BYOL Training Loss = 0.3630836308002472
30-01-2023 06:17:02 INFO Epoch 2: [287/10940] ---- BYOL Training Loss = 0.4292619824409485
30-01-2023 06:17:19 INFO Epoch 2: [298/10940] ---- BYOL Training Loss = 0.42663732171058655
30-01-2023 06:17:37 INFO Epoch 2: [309/10940] ---- BYOL Training Loss = 0.33986786007881165
30-01-2023 06:18:29 INFO Epoch 2: [309/10940] ---- BYOL Validation Loss = 0.38005441427230835
30-01-2023 06:18:46 INFO Epoch 2: [320/10940] ---- BYOL Training Loss = 0.3700718283653259
30-01-2023 06:19:04 INFO Epoch 2: [331/10940] ---- BYOL Training Loss = 0.36959534883499146
30-01-2023 06:19:21 INFO Epoch 2: [342/10940] ---- BYOL Training Loss = 0.3478052020072937
30-01-2023 06:19:39 INFO Epoch 2: [353/10940] ---- BYOL Training Loss = 0.3927936255931854
30-01-2023 06:20:31 INFO Epoch 2: [353/10940] ---- BYOL Validation Loss = 0.38482213020324707
30-01-2023 06:20:48 INFO Epoch 2: [364/10940] ---- BYOL Training Loss = 0.39375072717666626
30-01-2023 06:21:06 INFO Epoch 2: [375/10940] ---- BYOL Training Loss = 0.33686771988868713
30-01-2023 06:21:23 INFO Epoch 2: [386/10940] ---- BYOL Training Loss = 0.37514638900756836
30-01-2023 06:21:41 INFO Epoch 2: [397/10940] ---- BYOL Training Loss = 0.3672703504562378
30-01-2023 06:22:33 INFO Epoch 2: [397/10940] ---- BYOL Validation Loss = 0.38012784719467163
30-01-2023 06:22:50 INFO Epoch 2: [408/10940] ---- BYOL Training Loss = 0.34267106652259827
30-01-2023 06:23:08 INFO Epoch 2: [419/10940] ---- BYOL Training Loss = 0.38292157649993896
30-01-2023 06:23:25 INFO Epoch 2: [430/10940] ---- BYOL Training Loss = 0.3600415289402008
30-01-2023 06:23:43 INFO Epoch 2: [441/10940] ---- BYOL Training Loss = 0.32008033990859985
30-01-2023 06:24:35 INFO Epoch 2: [441/10940] ---- BYOL Validation Loss = 0.3530557453632355
30-01-2023 06:24:52 INFO Epoch 2: [452/10940] ---- BYOL Training Loss = 0.37297168374061584
30-01-2023 06:25:10 INFO Epoch 2: [463/10940] ---- BYOL Training Loss = 0.3885303735733032
30-01-2023 06:25:28 INFO Epoch 2: [474/10940] ---- BYOL Training Loss = 0.43203407526016235
30-01-2023 06:25:45 INFO Epoch 2: [485/10940] ---- BYOL Training Loss = 0.4726587235927582
30-01-2023 06:26:37 INFO Epoch 2: [485/10940] ---- BYOL Validation Loss = 0.37008336186408997
30-01-2023 06:26:54 INFO Epoch 2: [496/10940] ---- BYOL Training Loss = 0.35630133748054504
30-01-2023 06:27:12 INFO Epoch 2: [507/10940] ---- BYOL Training Loss = 0.29027310013771057
30-01-2023 06:27:30 INFO Epoch 2: [518/10940] ---- BYOL Training Loss = 0.30741769075393677
30-01-2023 06:27:47 INFO Epoch 2: [529/10940] ---- BYOL Training Loss = 0.3538413345813751
30-01-2023 06:28:39 INFO Epoch 2: [529/10940] ---- BYOL Validation Loss = 0.38858604431152344
30-01-2023 06:28:57 INFO Epoch 2: [540/10940] ---- BYOL Training Loss = 0.3645625412464142
30-01-2023 06:29:14 INFO Epoch 2: [551/10940] ---- BYOL Training Loss = 0.37819623947143555
30-01-2023 06:29:32 INFO Epoch 2: [562/10940] ---- BYOL Training Loss = 0.38939937949180603
30-01-2023 06:29:50 INFO Epoch 2: [573/10940] ---- BYOL Training Loss = 0.3476146161556244
30-01-2023 06:30:42 INFO Epoch 2: [573/10940] ---- BYOL Validation Loss = 0.3806041181087494
30-01-2023 06:30:59 INFO Epoch 2: [584/10940] ---- BYOL Training Loss = 0.33233779668807983
30-01-2023 06:31:16 INFO Epoch 2: [595/10940] ---- BYOL Training Loss = 0.34363189339637756
30-01-2023 06:31:34 INFO Epoch 2: [606/10940] ---- BYOL Training Loss = 0.3503018319606781
30-01-2023 06:31:52 INFO Epoch 2: [617/10940] ---- BYOL Training Loss = 0.3742862343788147
30-01-2023 06:32:44 INFO Epoch 2: [617/10940] ---- BYOL Validation Loss = 0.3716560900211334
30-01-2023 06:33:01 INFO Epoch 2: [628/10940] ---- BYOL Training Loss = 0.4289173483848572
30-01-2023 06:33:18 INFO Epoch 2: [639/10940] ---- BYOL Training Loss = 0.44796115159988403
30-01-2023 06:33:36 INFO Epoch 2: [650/10940] ---- BYOL Training Loss = 0.3290639817714691
30-01-2023 06:33:53 INFO Epoch 2: [661/10940] ---- BYOL Training Loss = 0.3170340657234192
30-01-2023 06:34:45 INFO Epoch 2: [661/10940] ---- BYOL Validation Loss = 0.3962690532207489
30-01-2023 06:35:03 INFO Epoch 2: [672/10940] ---- BYOL Training Loss = 0.4352055490016937
30-01-2023 06:35:20 INFO Epoch 2: [683/10940] ---- BYOL Training Loss = 0.4589361548423767
30-01-2023 06:35:38 INFO Epoch 2: [694/10940] ---- BYOL Training Loss = 0.4369041323661804
30-01-2023 06:35:56 INFO Epoch 2: [705/10940] ---- BYOL Training Loss = 0.4146953225135803
30-01-2023 06:36:48 INFO Epoch 2: [705/10940] ---- BYOL Validation Loss = 0.38940927386283875
30-01-2023 06:37:05 INFO Epoch 2: [716/10940] ---- BYOL Training Loss = 0.40191420912742615
30-01-2023 06:37:22 INFO Epoch 2: [727/10940] ---- BYOL Training Loss = 0.4201844334602356
30-01-2023 06:37:40 INFO Epoch 2: [738/10940] ---- BYOL Training Loss = 0.39948880672454834
30-01-2023 06:37:58 INFO Epoch 2: [749/10940] ---- BYOL Training Loss = 0.34900373220443726
30-01-2023 06:38:50 INFO Epoch 2: [749/10940] ---- BYOL Validation Loss = 0.3724648654460907
30-01-2023 06:39:07 INFO Epoch 2: [760/10940] ---- BYOL Training Loss = 0.38092365860939026
30-01-2023 06:39:24 INFO Epoch 2: [771/10940] ---- BYOL Training Loss = 0.40735501050949097
30-01-2023 06:39:42 INFO Epoch 2: [782/10940] ---- BYOL Training Loss = 0.3523080348968506
30-01-2023 06:40:00 INFO Epoch 2: [793/10940] ---- BYOL Training Loss = 0.3596380352973938
30-01-2023 06:40:52 INFO Epoch 2: [793/10940] ---- BYOL Validation Loss = 0.3841218948364258
30-01-2023 06:41:09 INFO Epoch 2: [804/10940] ---- BYOL Training Loss = 0.4296961724758148
30-01-2023 06:41:26 INFO Epoch 2: [815/10940] ---- BYOL Training Loss = 0.42854195833206177
30-01-2023 06:41:44 INFO Epoch 2: [826/10940] ---- BYOL Training Loss = 0.3780871331691742
30-01-2023 06:42:01 INFO Epoch 2: [837/10940] ---- BYOL Training Loss = 0.41865330934524536
30-01-2023 06:42:54 INFO Epoch 2: [837/10940] ---- BYOL Validation Loss = 0.3614388406276703
30-01-2023 06:43:11 INFO Epoch 2: [848/10940] ---- BYOL Training Loss = 0.4264112412929535
30-01-2023 06:43:28 INFO Epoch 2: [859/10940] ---- BYOL Training Loss = 0.3537258207798004
30-01-2023 06:43:46 INFO Epoch 2: [870/10940] ---- BYOL Training Loss = 0.3491935133934021
30-01-2023 06:44:04 INFO Epoch 2: [881/10940] ---- BYOL Training Loss = 0.4026961326599121
30-01-2023 06:44:56 INFO Epoch 2: [881/10940] ---- BYOL Validation Loss = 0.38164982199668884
30-01-2023 06:45:13 INFO Epoch 2: [892/10940] ---- BYOL Training Loss = 0.38225218653678894
30-01-2023 06:45:31 INFO Epoch 2: [903/10940] ---- BYOL Training Loss = 0.32420581579208374
30-01-2023 06:45:48 INFO Epoch 2: [914/10940] ---- BYOL Training Loss = 0.3234058618545532
30-01-2023 06:46:06 INFO Epoch 2: [925/10940] ---- BYOL Training Loss = 0.28231120109558105
30-01-2023 06:46:58 INFO Epoch 2: [925/10940] ---- BYOL Validation Loss = 0.35662129521369934
30-01-2023 06:47:15 INFO Epoch 2: [936/10940] ---- BYOL Training Loss = 0.3611501455307007
30-01-2023 06:47:33 INFO Epoch 2: [947/10940] ---- BYOL Training Loss = 0.3961799442768097
30-01-2023 06:47:50 INFO Epoch 2: [958/10940] ---- BYOL Training Loss = 0.3946565091609955
30-01-2023 06:48:08 INFO Epoch 2: [969/10940] ---- BYOL Training Loss = 0.3926299214363098
30-01-2023 06:49:00 INFO Epoch 2: [969/10940] ---- BYOL Validation Loss = 0.3578396439552307
30-01-2023 06:49:17 INFO Epoch 2: [980/10940] ---- BYOL Training Loss = 0.3377350866794586
30-01-2023 06:49:35 INFO Epoch 2: [991/10940] ---- BYOL Training Loss = 0.35352623462677
30-01-2023 06:49:53 INFO Epoch 2: [1002/10940] ---- BYOL Training Loss = 0.3584158420562744
30-01-2023 06:50:10 INFO Epoch 2: [1013/10940] ---- BYOL Training Loss = 0.3249672055244446
30-01-2023 06:51:02 INFO Epoch 2: [1013/10940] ---- BYOL Validation Loss = 0.3516574501991272
30-01-2023 06:51:20 INFO Epoch 2: [1024/10940] ---- BYOL Training Loss = 0.36306291818618774
30-01-2023 06:51:37 INFO Epoch 2: [1035/10940] ---- BYOL Training Loss = 0.33905309438705444
30-01-2023 06:51:55 INFO Epoch 2: [1046/10940] ---- BYOL Training Loss = 0.33951038122177124
30-01-2023 06:52:13 INFO Epoch 2: [1057/10940] ---- BYOL Training Loss = 0.3361821472644806
30-01-2023 06:53:05 INFO Epoch 2: [1057/10940] ---- BYOL Validation Loss = 0.3782595992088318
30-01-2023 06:53:22 INFO Epoch 2: [1068/10940] ---- BYOL Training Loss = 0.3849024772644043
30-01-2023 06:53:40 INFO Epoch 2: [1079/10940] ---- BYOL Training Loss = 0.38563016057014465
30-01-2023 06:53:58 INFO Epoch 2: [1090/10940] ---- BYOL Training Loss = 0.42535704374313354
30-01-2023 06:54:15 INFO Epoch 2: [1101/10940] ---- BYOL Training Loss = 0.4254959225654602
30-01-2023 06:55:07 INFO Epoch 2: [1101/10940] ---- BYOL Validation Loss = 0.39040136337280273
30-01-2023 06:55:25 INFO Epoch 2: [1112/10940] ---- BYOL Training Loss = 0.4021197259426117
30-01-2023 06:55:42 INFO Epoch 2: [1123/10940] ---- BYOL Training Loss = 0.3860691785812378
30-01-2023 06:56:00 INFO Epoch 2: [1134/10940] ---- BYOL Training Loss = 0.31810611486434937
30-01-2023 06:56:17 INFO Epoch 2: [1145/10940] ---- BYOL Training Loss = 0.34922558069229126
30-01-2023 06:57:10 INFO Epoch 2: [1145/10940] ---- BYOL Validation Loss = 0.3998548090457916
30-01-2023 06:57:27 INFO Epoch 2: [1156/10940] ---- BYOL Training Loss = 0.3462584614753723
30-01-2023 06:57:44 INFO Epoch 2: [1167/10940] ---- BYOL Training Loss = 0.37308621406555176
30-01-2023 06:58:02 INFO Epoch 2: [1178/10940] ---- BYOL Training Loss = 0.4069923460483551
30-01-2023 06:58:20 INFO Epoch 2: [1189/10940] ---- BYOL Training Loss = 0.39732277393341064
30-01-2023 06:59:12 INFO Epoch 2: [1189/10940] ---- BYOL Validation Loss = 0.3718675971031189
30-01-2023 06:59:29 INFO Epoch 2: [1200/10940] ---- BYOL Training Loss = 0.4430866241455078
30-01-2023 06:59:46 INFO Epoch 2: [1211/10940] ---- BYOL Training Loss = 0.42406970262527466
30-01-2023 07:00:04 INFO Epoch 2: [1222/10940] ---- BYOL Training Loss = 0.41298922896385193
30-01-2023 07:00:22 INFO Epoch 2: [1233/10940] ---- BYOL Training Loss = 0.4239944517612457
30-01-2023 07:01:14 INFO Epoch 2: [1233/10940] ---- BYOL Validation Loss = 0.3681577146053314
30-01-2023 07:01:31 INFO Epoch 2: [1244/10940] ---- BYOL Training Loss = 0.3382341265678406
30-01-2023 07:01:49 INFO Epoch 2: [1255/10940] ---- BYOL Training Loss = 0.29574161767959595
30-01-2023 07:02:06 INFO Epoch 2: [1266/10940] ---- BYOL Training Loss = 0.3009604811668396
30-01-2023 07:02:24 INFO Epoch 2: [1277/10940] ---- BYOL Training Loss = 0.32613471150398254
30-01-2023 07:03:16 INFO Epoch 2: [1277/10940] ---- BYOL Validation Loss = 0.36513158679008484
30-01-2023 07:03:33 INFO Epoch 2: [1288/10940] ---- BYOL Training Loss = 0.32527950406074524
30-01-2023 07:03:51 INFO Epoch 2: [1299/10940] ---- BYOL Training Loss = 0.34421297907829285
30-01-2023 07:04:09 INFO Epoch 2: [1310/10940] ---- BYOL Training Loss = 0.34666261076927185
30-01-2023 07:04:26 INFO Epoch 2: [1321/10940] ---- BYOL Training Loss = 0.3824247419834137
30-01-2023 07:05:18 INFO Epoch 2: [1321/10940] ---- BYOL Validation Loss = 0.3632824122905731
30-01-2023 07:05:35 INFO Epoch 2: [1332/10940] ---- BYOL Training Loss = 0.3396371304988861
30-01-2023 07:05:53 INFO Epoch 2: [1343/10940] ---- BYOL Training Loss = 0.2793962359428406
30-01-2023 07:06:11 INFO Epoch 2: [1354/10940] ---- BYOL Training Loss = 0.28730061650276184
30-01-2023 07:06:29 INFO Epoch 2: [1365/10940] ---- BYOL Training Loss = 0.3208487629890442
30-01-2023 07:07:21 INFO Epoch 2: [1365/10940] ---- BYOL Validation Loss = 3.037285327911377
30-01-2023 07:07:38 INFO Epoch 2: [1376/10940] ---- BYOL Training Loss = 0.3883920907974243
30-01-2023 07:07:56 INFO Epoch 2: [1387/10940] ---- BYOL Training Loss = 0.32504016160964966
30-01-2023 07:08:13 INFO Epoch 2: [1398/10940] ---- BYOL Training Loss = 0.3913467228412628
30-01-2023 07:08:31 INFO Epoch 2: [1409/10940] ---- BYOL Training Loss = 0.40869489312171936
30-01-2023 07:09:23 INFO Epoch 2: [1409/10940] ---- BYOL Validation Loss = 0.37565064430236816
30-01-2023 07:09:41 INFO Epoch 2: [1420/10940] ---- BYOL Training Loss = 0.3396729528903961
30-01-2023 07:09:58 INFO Epoch 2: [1431/10940] ---- BYOL Training Loss = 0.37541475892066956
30-01-2023 07:10:16 INFO Epoch 2: [1442/10940] ---- BYOL Training Loss = 0.3654482960700989
30-01-2023 07:10:33 INFO Epoch 2: [1453/10940] ---- BYOL Training Loss = 0.3671770393848419
30-01-2023 07:11:26 INFO Epoch 2: [1453/10940] ---- BYOL Validation Loss = 0.38603299856185913
30-01-2023 07:11:43 INFO Epoch 2: [1464/10940] ---- BYOL Training Loss = 0.4082701802253723
30-01-2023 07:12:01 INFO Epoch 2: [1475/10940] ---- BYOL Training Loss = 0.5007675886154175
30-01-2023 07:12:18 INFO Epoch 2: [1486/10940] ---- BYOL Training Loss = 0.5211683511734009
30-01-2023 07:12:36 INFO Epoch 2: [1497/10940] ---- BYOL Training Loss = 0.40135669708251953
30-01-2023 07:13:28 INFO Epoch 2: [1497/10940] ---- BYOL Validation Loss = 0.35740646719932556
30-01-2023 07:13:45 INFO Epoch 2: [1508/10940] ---- BYOL Training Loss = 0.35207676887512207
30-01-2023 07:14:03 INFO Epoch 2: [1519/10940] ---- BYOL Training Loss = 0.38249918818473816
30-01-2023 07:14:21 INFO Epoch 2: [1530/10940] ---- BYOL Training Loss = 0.3475834131240845
30-01-2023 07:14:39 INFO Epoch 2: [1541/10940] ---- BYOL Training Loss = 0.36878663301467896
30-01-2023 07:15:31 INFO Epoch 2: [1541/10940] ---- BYOL Validation Loss = 0.33875200152397156
30-01-2023 07:15:48 INFO Epoch 2: [1552/10940] ---- BYOL Training Loss = 0.3476785123348236
30-01-2023 07:16:06 INFO Epoch 2: [1563/10940] ---- BYOL Training Loss = 0.33688992261886597
30-01-2023 07:16:23 INFO Epoch 2: [1574/10940] ---- BYOL Training Loss = 0.33999696373939514
30-01-2023 07:16:42 INFO Epoch 2: [1585/10940] ---- BYOL Training Loss = 0.3361944556236267
30-01-2023 07:17:34 INFO Epoch 2: [1585/10940] ---- BYOL Validation Loss = 0.35020971298217773
30-01-2023 07:17:51 INFO Epoch 2: [1596/10940] ---- BYOL Training Loss = 0.33031967282295227
30-01-2023 07:18:08 INFO Epoch 2: [1607/10940] ---- BYOL Training Loss = 0.38103052973747253
30-01-2023 07:18:26 INFO Epoch 2: [1618/10940] ---- BYOL Training Loss = 0.3395250141620636
30-01-2023 07:18:44 INFO Epoch 2: [1629/10940] ---- BYOL Training Loss = 0.36507341265678406
30-01-2023 07:19:36 INFO Epoch 2: [1629/10940] ---- BYOL Validation Loss = 0.35402217507362366
30-01-2023 07:19:53 INFO Epoch 2: [1640/10940] ---- BYOL Training Loss = 0.38544484972953796
30-01-2023 07:20:11 INFO Epoch 2: [1651/10940] ---- BYOL Training Loss = 0.39186108112335205
30-01-2023 07:20:29 INFO Epoch 2: [1662/10940] ---- BYOL Training Loss = 0.45561742782592773
30-01-2023 07:20:46 INFO Epoch 2: [1673/10940] ---- BYOL Training Loss = 0.45231375098228455
30-01-2023 07:21:38 INFO Epoch 2: [1673/10940] ---- BYOL Validation Loss = 0.3785400390625
30-01-2023 07:21:56 INFO Epoch 2: [1684/10940] ---- BYOL Training Loss = 0.33092132210731506
30-01-2023 07:22:13 INFO Epoch 2: [1695/10940] ---- BYOL Training Loss = 0.320793092250824
30-01-2023 07:22:31 INFO Epoch 2: [1706/10940] ---- BYOL Training Loss = 0.34821540117263794
30-01-2023 07:22:49 INFO Epoch 2: [1717/10940] ---- BYOL Training Loss = 0.37387946248054504
30-01-2023 07:23:41 INFO Epoch 2: [1717/10940] ---- BYOL Validation Loss = 0.3721470236778259
30-01-2023 07:23:58 INFO Epoch 2: [1728/10940] ---- BYOL Training Loss = 0.4012293219566345
30-01-2023 07:24:16 INFO Epoch 2: [1739/10940] ---- BYOL Training Loss = 0.43019047379493713
30-01-2023 07:24:33 INFO Epoch 2: [1750/10940] ---- BYOL Training Loss = 0.319667786359787
30-01-2023 07:24:51 INFO Epoch 2: [1761/10940] ---- BYOL Training Loss = 0.294717937707901
30-01-2023 07:25:43 INFO Epoch 2: [1761/10940] ---- BYOL Validation Loss = 0.3658657670021057
30-01-2023 07:26:00 INFO Epoch 2: [1772/10940] ---- BYOL Training Loss = 0.32213184237480164
30-01-2023 07:26:18 INFO Epoch 2: [1783/10940] ---- BYOL Training Loss = 0.38519009947776794
30-01-2023 07:26:36 INFO Epoch 2: [1794/10940] ---- BYOL Training Loss = 0.3939036726951599
30-01-2023 07:26:54 INFO Epoch 2: [1805/10940] ---- BYOL Training Loss = 0.3728569447994232
30-01-2023 07:27:46 INFO Epoch 2: [1805/10940] ---- BYOL Validation Loss = 0.34094932675361633
30-01-2023 07:28:03 INFO Epoch 2: [1816/10940] ---- BYOL Training Loss = 0.4148934781551361
30-01-2023 07:28:21 INFO Epoch 2: [1827/10940] ---- BYOL Training Loss = 0.3648552894592285
30-01-2023 07:28:38 INFO Epoch 2: [1838/10940] ---- BYOL Training Loss = 0.31865695118904114
30-01-2023 07:28:56 INFO Epoch 2: [1849/10940] ---- BYOL Training Loss = 0.3629087507724762
30-01-2023 07:29:48 INFO Epoch 2: [1849/10940] ---- BYOL Validation Loss = 0.3443275988101959
30-01-2023 07:30:05 INFO Epoch 2: [1860/10940] ---- BYOL Training Loss = 0.4095175266265869
30-01-2023 07:30:23 INFO Epoch 2: [1871/10940] ---- BYOL Training Loss = 0.41212987899780273
30-01-2023 07:30:41 INFO Epoch 2: [1882/10940] ---- BYOL Training Loss = 0.38662564754486084
30-01-2023 07:30:58 INFO Epoch 2: [1893/10940] ---- BYOL Training Loss = 0.4167686998844147
30-01-2023 07:31:51 INFO Epoch 2: [1893/10940] ---- BYOL Validation Loss = 0.35109707713127136
30-01-2023 07:32:08 INFO Epoch 2: [1904/10940] ---- BYOL Training Loss = 0.43209266662597656
30-01-2023 07:32:26 INFO Epoch 2: [1915/10940] ---- BYOL Training Loss = 0.4282976984977722
30-01-2023 07:32:43 INFO Epoch 2: [1926/10940] ---- BYOL Training Loss = 0.40988507866859436
30-01-2023 07:33:01 INFO Epoch 2: [1937/10940] ---- BYOL Training Loss = 0.34143146872520447
30-01-2023 07:33:53 INFO Epoch 2: [1937/10940] ---- BYOL Validation Loss = 0.36490029096603394
30-01-2023 07:34:11 INFO Epoch 2: [1948/10940] ---- BYOL Training Loss = 0.2976537048816681
30-01-2023 07:34:28 INFO Epoch 2: [1959/10940] ---- BYOL Training Loss = 0.30726081132888794
30-01-2023 07:34:46 INFO Epoch 2: [1970/10940] ---- BYOL Training Loss = 0.26437515020370483
30-01-2023 07:35:04 INFO Epoch 2: [1981/10940] ---- BYOL Training Loss = 0.2954058051109314
30-01-2023 07:35:56 INFO Epoch 2: [1981/10940] ---- BYOL Validation Loss = 0.3636797368526459
30-01-2023 07:36:13 INFO Epoch 2: [1992/10940] ---- BYOL Training Loss = 0.3698155879974365
30-01-2023 07:36:31 INFO Epoch 2: [2003/10940] ---- BYOL Training Loss = 0.3606288731098175
30-01-2023 07:36:48 INFO Epoch 2: [2014/10940] ---- BYOL Training Loss = 0.31624969840049744
30-01-2023 07:37:06 INFO Epoch 2: [2025/10940] ---- BYOL Training Loss = 0.353983610868454
30-01-2023 07:37:58 INFO Epoch 2: [2025/10940] ---- BYOL Validation Loss = 0.38061952590942383
30-01-2023 07:38:16 INFO Epoch 2: [2036/10940] ---- BYOL Training Loss = 0.4888014793395996
30-01-2023 07:38:33 INFO Epoch 2: [2047/10940] ---- BYOL Training Loss = 0.38988468050956726
30-01-2023 07:38:51 INFO Epoch 2: [2058/10940] ---- BYOL Training Loss = 0.3950541019439697
30-01-2023 07:39:09 INFO Epoch 2: [2069/10940] ---- BYOL Training Loss = 0.41835564374923706
30-01-2023 07:40:01 INFO Epoch 2: [2069/10940] ---- BYOL Validation Loss = 0.3920246958732605
30-01-2023 07:40:19 INFO Epoch 2: [2080/10940] ---- BYOL Training Loss = 0.4439786970615387
30-01-2023 07:40:36 INFO Epoch 2: [2091/10940] ---- BYOL Training Loss = 0.44872742891311646
30-01-2023 07:40:54 INFO Epoch 2: [2102/10940] ---- BYOL Training Loss = 0.4265729784965515
30-01-2023 07:41:12 INFO Epoch 2: [2113/10940] ---- BYOL Training Loss = 0.4492444097995758
30-01-2023 07:42:04 INFO Epoch 2: [2113/10940] ---- BYOL Validation Loss = 0.3673754632472992
30-01-2023 07:42:21 INFO Epoch 2: [2124/10940] ---- BYOL Training Loss = 0.3823762536048889
30-01-2023 07:42:39 INFO Epoch 2: [2135/10940] ---- BYOL Training Loss = 0.32635465264320374
30-01-2023 07:42:56 INFO Epoch 2: [2146/10940] ---- BYOL Training Loss = 0.34274277091026306
30-01-2023 07:43:14 INFO Epoch 2: [2157/10940] ---- BYOL Training Loss = 0.3400436043739319
30-01-2023 07:44:06 INFO Epoch 2: [2157/10940] ---- BYOL Validation Loss = 0.36424630880355835
30-01-2023 07:44:24 INFO Epoch 2: [2168/10940] ---- BYOL Training Loss = 0.3309054374694824
30-01-2023 07:44:42 INFO Epoch 2: [2179/10940] ---- BYOL Training Loss = 0.33839353919029236
30-01-2023 07:44:59 INFO Epoch 2: [2190/10940] ---- BYOL Training Loss = 0.3162136375904083
30-01-2023 07:45:17 INFO Epoch 2: [2201/10940] ---- BYOL Training Loss = 0.2642362415790558
30-01-2023 07:46:09 INFO Epoch 2: [2201/10940] ---- BYOL Validation Loss = 0.3572551906108856
30-01-2023 07:46:27 INFO Epoch 2: [2212/10940] ---- BYOL Training Loss = 0.3748568892478943
30-01-2023 07:46:45 INFO Epoch 2: [2223/10940] ---- BYOL Training Loss = 0.4077301025390625
30-01-2023 07:47:03 INFO Epoch 2: [2234/10940] ---- BYOL Training Loss = 0.3341367840766907
30-01-2023 07:47:20 INFO Epoch 2: [2245/10940] ---- BYOL Training Loss = 0.3328871726989746
30-01-2023 07:48:12 INFO Epoch 2: [2245/10940] ---- BYOL Validation Loss = 0.3606070578098297
30-01-2023 07:48:30 INFO Epoch 2: [2256/10940] ---- BYOL Training Loss = 0.4140647053718567
30-01-2023 07:48:47 INFO Epoch 2: [2267/10940] ---- BYOL Training Loss = 0.44395703077316284
30-01-2023 07:49:05 INFO Epoch 2: [2278/10940] ---- BYOL Training Loss = 0.4038066864013672
30-01-2023 07:49:23 INFO Epoch 2: [2289/10940] ---- BYOL Training Loss = 0.35846784710884094
30-01-2023 07:50:15 INFO Epoch 2: [2289/10940] ---- BYOL Validation Loss = 0.3705756366252899
30-01-2023 07:50:32 INFO Epoch 2: [2300/10940] ---- BYOL Training Loss = 0.3860166668891907
30-01-2023 07:50:50 INFO Epoch 2: [2311/10940] ---- BYOL Training Loss = 0.37006261944770813
30-01-2023 07:51:07 INFO Epoch 2: [2322/10940] ---- BYOL Training Loss = 0.3779200613498688
30-01-2023 07:51:25 INFO Epoch 2: [2333/10940] ---- BYOL Training Loss = 0.37955617904663086
30-01-2023 07:52:17 INFO Epoch 2: [2333/10940] ---- BYOL Validation Loss = 0.37963730096817017
30-01-2023 07:52:35 INFO Epoch 2: [2344/10940] ---- BYOL Training Loss = 0.3553066849708557
30-01-2023 07:52:53 INFO Epoch 2: [2355/10940] ---- BYOL Training Loss = 0.3515969514846802
30-01-2023 07:53:10 INFO Epoch 2: [2366/10940] ---- BYOL Training Loss = 0.4014318585395813
30-01-2023 07:53:28 INFO Epoch 2: [2377/10940] ---- BYOL Training Loss = 0.40050849318504333
30-01-2023 07:54:20 INFO Epoch 2: [2377/10940] ---- BYOL Validation Loss = 0.3561767637729645
30-01-2023 07:54:37 INFO Epoch 2: [2388/10940] ---- BYOL Training Loss = 0.4399377405643463
30-01-2023 07:54:55 INFO Epoch 2: [2399/10940] ---- BYOL Training Loss = 0.42000117897987366
30-01-2023 07:55:13 INFO Epoch 2: [2410/10940] ---- BYOL Training Loss = 0.4087716042995453
30-01-2023 07:55:31 INFO Epoch 2: [2421/10940] ---- BYOL Training Loss = 0.39739933609962463
30-01-2023 07:56:23 INFO Epoch 2: [2421/10940] ---- BYOL Validation Loss = 0.36889439821243286
30-01-2023 07:56:40 INFO Epoch 2: [2432/10940] ---- BYOL Training Loss = 0.3353883624076843
30-01-2023 07:56:58 INFO Epoch 2: [2443/10940] ---- BYOL Training Loss = 0.3048689365386963
30-01-2023 07:57:16 INFO Epoch 2: [2454/10940] ---- BYOL Training Loss = 0.34834861755371094
30-01-2023 07:57:34 INFO Epoch 2: [2465/10940] ---- BYOL Training Loss = 0.35732585191726685
30-01-2023 07:58:26 INFO Epoch 2: [2465/10940] ---- BYOL Validation Loss = 0.363506555557251
30-01-2023 07:58:43 INFO Epoch 2: [2476/10940] ---- BYOL Training Loss = 0.3950803279876709
30-01-2023 07:59:01 INFO Epoch 2: [2487/10940] ---- BYOL Training Loss = 0.40886029601097107
30-01-2023 07:59:18 INFO Epoch 2: [2498/10940] ---- BYOL Training Loss = 0.4010304808616638
30-01-2023 07:59:36 INFO Epoch 2: [2509/10940] ---- BYOL Training Loss = 0.417769193649292
30-01-2023 08:00:28 INFO Epoch 2: [2509/10940] ---- BYOL Validation Loss = 0.3885190188884735
30-01-2023 08:00:45 INFO Epoch 2: [2520/10940] ---- BYOL Training Loss = 0.431939035654068
30-01-2023 08:01:03 INFO Epoch 2: [2531/10940] ---- BYOL Training Loss = 0.35357585549354553
30-01-2023 08:01:21 INFO Epoch 2: [2542/10940] ---- BYOL Training Loss = 0.3199024200439453
30-01-2023 08:01:39 INFO Epoch 2: [2553/10940] ---- BYOL Training Loss = 0.26849907636642456
30-01-2023 08:02:31 INFO Epoch 2: [2553/10940] ---- BYOL Validation Loss = 0.35839638113975525
30-01-2023 08:02:49 INFO Epoch 2: [2564/10940] ---- BYOL Training Loss = 0.3010019063949585
30-01-2023 08:03:06 INFO Epoch 2: [2575/10940] ---- BYOL Training Loss = 0.39958417415618896
30-01-2023 08:03:24 INFO Epoch 2: [2586/10940] ---- BYOL Training Loss = 0.3509350121021271
30-01-2023 08:03:42 INFO Epoch 2: [2597/10940] ---- BYOL Training Loss = 0.3216199576854706
30-01-2023 08:04:34 INFO Epoch 2: [2597/10940] ---- BYOL Validation Loss = 0.34617695212364197
30-01-2023 08:04:51 INFO Epoch 2: [2608/10940] ---- BYOL Training Loss = 0.3935546278953552
30-01-2023 08:05:09 INFO Epoch 2: [2619/10940] ---- BYOL Training Loss = 0.3943137526512146
30-01-2023 08:05:27 INFO Epoch 2: [2630/10940] ---- BYOL Training Loss = 0.3986664414405823
30-01-2023 08:05:44 INFO Epoch 2: [2641/10940] ---- BYOL Training Loss = 0.40259629487991333
30-01-2023 08:06:36 INFO Epoch 2: [2641/10940] ---- BYOL Validation Loss = 0.33728504180908203
30-01-2023 08:06:54 INFO Epoch 2: [2652/10940] ---- BYOL Training Loss = 0.42280465364456177
30-01-2023 08:07:12 INFO Epoch 2: [2663/10940] ---- BYOL Training Loss = 0.3340723514556885
30-01-2023 08:07:30 INFO Epoch 2: [2674/10940] ---- BYOL Training Loss = 0.4032811224460602
30-01-2023 08:07:48 INFO Epoch 2: [2685/10940] ---- BYOL Training Loss = 0.41311803460121155
30-01-2023 08:08:40 INFO Epoch 2: [2685/10940] ---- BYOL Validation Loss = 0.4299817681312561
30-01-2023 08:08:57 INFO Epoch 2: [2696/10940] ---- BYOL Training Loss = 0.27660149335861206
30-01-2023 08:09:15 INFO Epoch 2: [2707/10940] ---- BYOL Training Loss = 0.2873363196849823
30-01-2023 08:09:33 INFO Epoch 2: [2718/10940] ---- BYOL Training Loss = 0.3628102242946625
30-01-2023 08:09:50 INFO Epoch 2: [2729/10940] ---- BYOL Training Loss = 0.3864537179470062
30-01-2023 08:10:43 INFO Epoch 2: [2729/10940] ---- BYOL Validation Loss = 0.35281530022621155
30-01-2023 08:11:00 INFO Epoch 2: [2740/10940] ---- BYOL Training Loss = 0.3573870062828064
30-01-2023 08:11:18 INFO Epoch 2: [2751/10940] ---- BYOL Training Loss = 0.36310070753097534
30-01-2023 08:11:36 INFO Epoch 2: [2762/10940] ---- BYOL Training Loss = 0.32735589146614075
30-01-2023 08:11:54 INFO Epoch 2: [2773/10940] ---- BYOL Training Loss = 0.3567766547203064
30-01-2023 08:12:46 INFO Epoch 2: [2773/10940] ---- BYOL Validation Loss = 0.35033199191093445
30-01-2023 08:13:03 INFO Epoch 2: [2784/10940] ---- BYOL Training Loss = 0.3450285494327545
30-01-2023 08:13:21 INFO Epoch 2: [2795/10940] ---- BYOL Training Loss = 0.31436586380004883
30-01-2023 08:13:39 INFO Epoch 2: [2806/10940] ---- BYOL Training Loss = 0.3203636407852173
30-01-2023 08:13:56 INFO Epoch 2: [2817/10940] ---- BYOL Training Loss = 0.32664212584495544
30-01-2023 08:14:48 INFO Epoch 2: [2817/10940] ---- BYOL Validation Loss = 0.3331332206726074
30-01-2023 08:15:06 INFO Epoch 2: [2828/10940] ---- BYOL Training Loss = 0.37407639622688293
30-01-2023 08:15:24 INFO Epoch 2: [2839/10940] ---- BYOL Training Loss = 0.3622300624847412
30-01-2023 08:15:41 INFO Epoch 2: [2850/10940] ---- BYOL Training Loss = 0.3281002938747406
30-01-2023 08:16:00 INFO Epoch 2: [2861/10940] ---- BYOL Training Loss = 0.335869163274765
30-01-2023 08:16:52 INFO Epoch 2: [2861/10940] ---- BYOL Validation Loss = 0.3487437665462494
30-01-2023 08:17:09 INFO Epoch 2: [2872/10940] ---- BYOL Training Loss = 0.3795088231563568
30-01-2023 08:17:27 INFO Epoch 2: [2883/10940] ---- BYOL Training Loss = 0.40907520055770874
30-01-2023 08:17:45 INFO Epoch 2: [2894/10940] ---- BYOL Training Loss = 0.3351748585700989
30-01-2023 08:18:03 INFO Epoch 2: [2905/10940] ---- BYOL Training Loss = 0.33344948291778564
30-01-2023 08:18:55 INFO Epoch 2: [2905/10940] ---- BYOL Validation Loss = 0.34896209836006165
30-01-2023 08:19:12 INFO Epoch 2: [2916/10940] ---- BYOL Training Loss = 0.38396167755126953
30-01-2023 08:19:30 INFO Epoch 2: [2927/10940] ---- BYOL Training Loss = 0.35710665583610535
30-01-2023 08:19:48 INFO Epoch 2: [2938/10940] ---- BYOL Training Loss = 0.35144346952438354
30-01-2023 08:20:06 INFO Epoch 2: [2949/10940] ---- BYOL Training Loss = 0.37522056698799133
30-01-2023 08:20:58 INFO Epoch 2: [2949/10940] ---- BYOL Validation Loss = 0.36270734667778015
30-01-2023 08:21:15 INFO Epoch 2: [2960/10940] ---- BYOL Training Loss = 0.41060012578964233
30-01-2023 08:21:33 INFO Epoch 2: [2971/10940] ---- BYOL Training Loss = 0.41476887464523315
30-01-2023 08:21:51 INFO Epoch 2: [2982/10940] ---- BYOL Training Loss = 0.3916209638118744
30-01-2023 08:22:09 INFO Epoch 2: [2993/10940] ---- BYOL Training Loss = 0.3633121848106384
30-01-2023 08:23:01 INFO Epoch 2: [2993/10940] ---- BYOL Validation Loss = 0.3428880572319031
30-01-2023 08:23:18 INFO Epoch 2: [3004/10940] ---- BYOL Training Loss = 0.3681345582008362
30-01-2023 08:23:36 INFO Epoch 2: [3015/10940] ---- BYOL Training Loss = 0.4431692063808441
30-01-2023 08:23:54 INFO Epoch 2: [3026/10940] ---- BYOL Training Loss = 0.4169960618019104
30-01-2023 08:24:12 INFO Epoch 2: [3037/10940] ---- BYOL Training Loss = 0.33141055703163147
30-01-2023 08:25:04 INFO Epoch 2: [3037/10940] ---- BYOL Validation Loss = 0.8433048129081726
30-01-2023 08:25:22 INFO Epoch 2: [3048/10940] ---- BYOL Training Loss = 0.3451818823814392
30-01-2023 08:25:40 INFO Epoch 2: [3059/10940] ---- BYOL Training Loss = 0.31432265043258667
30-01-2023 08:25:57 INFO Epoch 2: [3070/10940] ---- BYOL Training Loss = 0.37847036123275757
30-01-2023 08:26:15 INFO Epoch 2: [3081/10940] ---- BYOL Training Loss = 0.37595003843307495
30-01-2023 08:27:07 INFO Epoch 2: [3081/10940] ---- BYOL Validation Loss = 0.33271870017051697
30-01-2023 08:27:25 INFO Epoch 2: [3092/10940] ---- BYOL Training Loss = 0.3469693958759308
30-01-2023 08:27:43 INFO Epoch 2: [3103/10940] ---- BYOL Training Loss = 0.3563356399536133
30-01-2023 08:28:01 INFO Epoch 2: [3114/10940] ---- BYOL Training Loss = 0.35106465220451355
30-01-2023 08:28:19 INFO Epoch 2: [3125/10940] ---- BYOL Training Loss = 0.38094449043273926
30-01-2023 08:29:11 INFO Epoch 2: [3125/10940] ---- BYOL Validation Loss = 0.34639403223991394
30-01-2023 08:29:28 INFO Epoch 2: [3136/10940] ---- BYOL Training Loss = 0.3490774929523468
30-01-2023 08:29:46 INFO Epoch 2: [3147/10940] ---- BYOL Training Loss = 0.3232346177101135
30-01-2023 08:30:04 INFO Epoch 2: [3158/10940] ---- BYOL Training Loss = 0.318156898021698
30-01-2023 08:30:21 INFO Epoch 2: [3169/10940] ---- BYOL Training Loss = 0.33741143345832825
30-01-2023 08:31:14 INFO Epoch 2: [3169/10940] ---- BYOL Validation Loss = 0.33960431814193726
30-01-2023 08:31:31 INFO Epoch 2: [3180/10940] ---- BYOL Training Loss = 0.3577563464641571
30-01-2023 08:31:49 INFO Epoch 2: [3191/10940] ---- BYOL Training Loss = 0.3781312108039856
30-01-2023 08:32:07 INFO Epoch 2: [3202/10940] ---- BYOL Training Loss = 0.35341885685920715
30-01-2023 08:32:25 INFO Epoch 2: [3213/10940] ---- BYOL Training Loss = 0.32955366373062134
30-01-2023 08:33:17 INFO Epoch 2: [3213/10940] ---- BYOL Validation Loss = 0.37761572003364563
30-01-2023 08:33:34 INFO Epoch 2: [3224/10940] ---- BYOL Training Loss = 0.3826003670692444
30-01-2023 08:33:52 INFO Epoch 2: [3235/10940] ---- BYOL Training Loss = 0.31271564960479736
30-01-2023 08:34:10 INFO Epoch 2: [3246/10940] ---- BYOL Training Loss = 0.31074631214141846
30-01-2023 08:34:28 INFO Epoch 2: [3257/10940] ---- BYOL Training Loss = 0.36605969071388245
30-01-2023 08:35:20 INFO Epoch 2: [3257/10940] ---- BYOL Validation Loss = 0.3407513201236725
30-01-2023 08:35:37 INFO Epoch 2: [3268/10940] ---- BYOL Training Loss = 0.36344435811042786
30-01-2023 08:35:56 INFO Epoch 2: [3279/10940] ---- BYOL Training Loss = 0.39725735783576965
30-01-2023 08:36:13 INFO Epoch 2: [3290/10940] ---- BYOL Training Loss = 0.40764790773391724
30-01-2023 08:36:31 INFO Epoch 2: [3301/10940] ---- BYOL Training Loss = 0.3288764953613281
30-01-2023 08:37:23 INFO Epoch 2: [3301/10940] ---- BYOL Validation Loss = 0.3386920392513275
30-01-2023 08:37:41 INFO Epoch 2: [3312/10940] ---- BYOL Training Loss = 0.3142551779747009
30-01-2023 08:37:58 INFO Epoch 2: [3323/10940] ---- BYOL Training Loss = 0.3392375111579895
30-01-2023 08:38:16 INFO Epoch 2: [3334/10940] ---- BYOL Training Loss = 0.37903809547424316
30-01-2023 08:38:34 INFO Epoch 2: [3345/10940] ---- BYOL Training Loss = 0.3423425555229187
30-01-2023 08:39:26 INFO Epoch 2: [3345/10940] ---- BYOL Validation Loss = 0.5072368383407593
30-01-2023 08:39:44 INFO Epoch 2: [3356/10940] ---- BYOL Training Loss = 0.35936596989631653
30-01-2023 08:40:02 INFO Epoch 2: [3367/10940] ---- BYOL Training Loss = 0.44813627004623413
30-01-2023 08:40:19 INFO Epoch 2: [3378/10940] ---- BYOL Training Loss = 0.35466334223747253
30-01-2023 08:40:37 INFO Epoch 2: [3389/10940] ---- BYOL Training Loss = 0.3850030303001404
30-01-2023 08:41:29 INFO Epoch 2: [3389/10940] ---- BYOL Validation Loss = 0.3701196312904358
30-01-2023 08:41:47 INFO Epoch 2: [3400/10940] ---- BYOL Training Loss = 0.4209466576576233
30-01-2023 08:42:04 INFO Epoch 2: [3411/10940] ---- BYOL Training Loss = 0.3614666163921356
30-01-2023 08:42:22 INFO Epoch 2: [3422/10940] ---- BYOL Training Loss = 0.43870821595191956
30-01-2023 08:42:41 INFO Epoch 2: [3433/10940] ---- BYOL Training Loss = 0.3887559473514557
30-01-2023 08:43:33 INFO Epoch 2: [3433/10940] ---- BYOL Validation Loss = 0.33251094818115234
30-01-2023 08:43:51 INFO Epoch 2: [3444/10940] ---- BYOL Training Loss = 0.35661953687667847
30-01-2023 08:44:08 INFO Epoch 2: [3455/10940] ---- BYOL Training Loss = 0.3920048773288727
30-01-2023 08:44:26 INFO Epoch 2: [3466/10940] ---- BYOL Training Loss = 0.3945828080177307
30-01-2023 08:44:44 INFO Epoch 2: [3477/10940] ---- BYOL Training Loss = 0.3756009638309479
30-01-2023 08:45:36 INFO Epoch 2: [3477/10940] ---- BYOL Validation Loss = 0.33209535479545593
30-01-2023 08:45:54 INFO Epoch 2: [3488/10940] ---- BYOL Training Loss = 0.4059486389160156
30-01-2023 08:46:11 INFO Epoch 2: [3499/10940] ---- BYOL Training Loss = 0.45355838537216187
30-01-2023 08:46:30 INFO Epoch 2: [3510/10940] ---- BYOL Training Loss = 0.40531808137893677
30-01-2023 08:46:48 INFO Epoch 2: [3521/10940] ---- BYOL Training Loss = 0.4019324779510498
30-01-2023 08:47:40 INFO Epoch 2: [3521/10940] ---- BYOL Validation Loss = 0.3425697982311249
30-01-2023 08:47:57 INFO Epoch 2: [3532/10940] ---- BYOL Training Loss = 0.3332388997077942
30-01-2023 08:48:15 INFO Epoch 2: [3543/10940] ---- BYOL Training Loss = 0.362472802400589
30-01-2023 08:48:33 INFO Epoch 2: [3554/10940] ---- BYOL Training Loss = 0.34636473655700684
30-01-2023 08:48:51 INFO Epoch 2: [3565/10940] ---- BYOL Training Loss = 0.346832811832428
30-01-2023 08:49:43 INFO Epoch 2: [3565/10940] ---- BYOL Validation Loss = 0.3462628722190857
30-01-2023 08:50:01 INFO Epoch 2: [3576/10940] ---- BYOL Training Loss = 0.40427494049072266
30-01-2023 08:50:19 INFO Epoch 2: [3587/10940] ---- BYOL Training Loss = 0.3617308735847473
30-01-2023 08:50:37 INFO Epoch 2: [3598/10940] ---- BYOL Training Loss = 0.3137814402580261
30-01-2023 08:50:54 INFO Epoch 2: [3609/10940] ---- BYOL Training Loss = 0.37952497601509094
30-01-2023 08:51:46 INFO Epoch 2: [3609/10940] ---- BYOL Validation Loss = 0.32869431376457214
30-01-2023 08:52:04 INFO Epoch 2: [3620/10940] ---- BYOL Training Loss = 0.37620872259140015
30-01-2023 08:52:22 INFO Epoch 2: [3631/10940] ---- BYOL Training Loss = 0.4062691628932953
30-01-2023 08:52:40 INFO Epoch 2: [3642/10940] ---- BYOL Training Loss = 0.4097764492034912
30-01-2023 08:52:58 INFO Epoch 2: [3653/10940] ---- BYOL Training Loss = 0.3914141058921814
30-01-2023 08:53:50 INFO Epoch 2: [3653/10940] ---- BYOL Validation Loss = 0.34842225909233093
30-01-2023 08:54:08 INFO Epoch 2: [3664/10940] ---- BYOL Training Loss = 0.3561425805091858
30-01-2023 08:54:25 INFO Epoch 2: [3675/10940] ---- BYOL Training Loss = 0.35403650999069214
30-01-2023 08:54:43 INFO Epoch 2: [3686/10940] ---- BYOL Training Loss = 0.3376699984073639
30-01-2023 08:55:01 INFO Epoch 2: [3697/10940] ---- BYOL Training Loss = 0.2824177145957947
30-01-2023 08:55:53 INFO Epoch 2: [3697/10940] ---- BYOL Validation Loss = 0.3259505331516266
30-01-2023 08:56:11 INFO Epoch 2: [3708/10940] ---- BYOL Training Loss = 0.3368901312351227
30-01-2023 08:56:29 INFO Epoch 2: [3719/10940] ---- BYOL Training Loss = 0.39271876215934753
30-01-2023 08:56:47 INFO Epoch 2: [3730/10940] ---- BYOL Training Loss = 0.4153878092765808
30-01-2023 08:57:05 INFO Epoch 2: [3741/10940] ---- BYOL Training Loss = 0.4021013677120209
30-01-2023 08:57:57 INFO Epoch 2: [3741/10940] ---- BYOL Validation Loss = 0.3611687123775482
30-01-2023 08:58:14 INFO Epoch 2: [3752/10940] ---- BYOL Training Loss = 0.3680875301361084
30-01-2023 08:58:32 INFO Epoch 2: [3763/10940] ---- BYOL Training Loss = 0.37392204999923706
30-01-2023 08:58:50 INFO Epoch 2: [3774/10940] ---- BYOL Training Loss = 0.33147698640823364
30-01-2023 08:59:08 INFO Epoch 2: [3785/10940] ---- BYOL Training Loss = 0.28518471121788025
30-01-2023 09:00:00 INFO Epoch 2: [3785/10940] ---- BYOL Validation Loss = 0.34194475412368774
30-01-2023 09:00:18 INFO Epoch 2: [3796/10940] ---- BYOL Training Loss = 0.4057159423828125
30-01-2023 09:00:36 INFO Epoch 2: [3807/10940] ---- BYOL Training Loss = 0.39938464760780334
30-01-2023 09:00:54 INFO Epoch 2: [3818/10940] ---- BYOL Training Loss = 0.2906269431114197
30-01-2023 09:01:11 INFO Epoch 2: [3829/10940] ---- BYOL Training Loss = 0.3010104298591614
30-01-2023 09:02:03 INFO Epoch 2: [3829/10940] ---- BYOL Validation Loss = 0.32854732871055603
30-01-2023 09:02:21 INFO Epoch 2: [3840/10940] ---- BYOL Training Loss = 0.28086990118026733
30-01-2023 09:02:39 INFO Epoch 2: [3851/10940] ---- BYOL Training Loss = 0.2975786328315735
30-01-2023 09:02:57 INFO Epoch 2: [3862/10940] ---- BYOL Training Loss = 0.320701539516449
30-01-2023 09:03:15 INFO Epoch 2: [3873/10940] ---- BYOL Training Loss = 0.39622607827186584
30-01-2023 09:04:07 INFO Epoch 2: [3873/10940] ---- BYOL Validation Loss = 0.32050201296806335
30-01-2023 09:04:24 INFO Epoch 2: [3884/10940] ---- BYOL Training Loss = 0.33037298917770386
30-01-2023 09:04:42 INFO Epoch 2: [3895/10940] ---- BYOL Training Loss = 0.3534618020057678
30-01-2023 09:05:00 INFO Epoch 2: [3906/10940] ---- BYOL Training Loss = 0.3707510828971863
30-01-2023 09:05:18 INFO Epoch 2: [3917/10940] ---- BYOL Training Loss = 0.34435731172561646
30-01-2023 09:06:10 INFO Epoch 2: [3917/10940] ---- BYOL Validation Loss = 0.36091136932373047
30-01-2023 09:06:28 INFO Epoch 2: [3928/10940] ---- BYOL Training Loss = 0.3214135766029358
30-01-2023 09:06:46 INFO Epoch 2: [3939/10940] ---- BYOL Training Loss = 0.32614171504974365
30-01-2023 09:07:03 INFO Epoch 2: [3950/10940] ---- BYOL Training Loss = 0.37001535296440125
30-01-2023 09:07:21 INFO Epoch 2: [3961/10940] ---- BYOL Training Loss = 0.3791625201702118
30-01-2023 09:08:13 INFO Epoch 2: [3961/10940] ---- BYOL Validation Loss = 0.3527408242225647
30-01-2023 09:08:31 INFO Epoch 2: [3972/10940] ---- BYOL Training Loss = 0.3448924124240875
30-01-2023 09:08:49 INFO Epoch 2: [3983/10940] ---- BYOL Training Loss = 0.3269214928150177
30-01-2023 09:09:07 INFO Epoch 2: [3994/10940] ---- BYOL Training Loss = 0.3490127921104431
30-01-2023 09:09:25 INFO Epoch 2: [4005/10940] ---- BYOL Training Loss = 0.3524157404899597
30-01-2023 09:10:17 INFO Epoch 2: [4005/10940] ---- BYOL Validation Loss = 0.32737746834754944
30-01-2023 09:10:34 INFO Epoch 2: [4016/10940] ---- BYOL Training Loss = 0.3517918586730957
30-01-2023 09:10:52 INFO Epoch 2: [4027/10940] ---- BYOL Training Loss = 0.3253762125968933
30-01-2023 09:11:10 INFO Epoch 2: [4038/10940] ---- BYOL Training Loss = 0.32344236969947815
30-01-2023 09:11:28 INFO Epoch 2: [4049/10940] ---- BYOL Training Loss = 0.3577444851398468
30-01-2023 09:12:21 INFO Epoch 2: [4049/10940] ---- BYOL Validation Loss = 0.3561771810054779
30-01-2023 09:12:38 INFO Epoch 2: [4060/10940] ---- BYOL Training Loss = 0.34690266847610474
30-01-2023 09:12:56 INFO Epoch 2: [4071/10940] ---- BYOL Training Loss = 0.32941964268684387
30-01-2023 09:13:14 INFO Epoch 2: [4082/10940] ---- BYOL Training Loss = 0.32719647884368896
30-01-2023 09:13:32 INFO Epoch 2: [4093/10940] ---- BYOL Training Loss = 0.33960258960723877
30-01-2023 09:14:24 INFO Epoch 2: [4093/10940] ---- BYOL Validation Loss = 2.889646530151367
30-01-2023 09:14:41 INFO Epoch 2: [4104/10940] ---- BYOL Training Loss = 0.3621175289154053
30-01-2023 09:15:00 INFO Epoch 2: [4115/10940] ---- BYOL Training Loss = 0.32872873544692993
30-01-2023 09:15:17 INFO Epoch 2: [4126/10940] ---- BYOL Training Loss = 0.3942820429801941
30-01-2023 09:15:35 INFO Epoch 2: [4137/10940] ---- BYOL Training Loss = 0.406674861907959
30-01-2023 09:16:27 INFO Epoch 2: [4137/10940] ---- BYOL Validation Loss = 0.34150609374046326
30-01-2023 09:16:45 INFO Epoch 2: [4148/10940] ---- BYOL Training Loss = 0.36946043372154236
30-01-2023 09:17:03 INFO Epoch 2: [4159/10940] ---- BYOL Training Loss = 0.3551417291164398
30-01-2023 09:17:21 INFO Epoch 2: [4170/10940] ---- BYOL Training Loss = 0.3777436316013336
30-01-2023 09:17:39 INFO Epoch 2: [4181/10940] ---- BYOL Training Loss = 0.3375118672847748
30-01-2023 09:18:31 INFO Epoch 2: [4181/10940] ---- BYOL Validation Loss = 0.34055089950561523
30-01-2023 09:18:48 INFO Epoch 2: [4192/10940] ---- BYOL Training Loss = 0.3608535826206207
30-01-2023 09:19:06 INFO Epoch 2: [4203/10940] ---- BYOL Training Loss = 0.3741053640842438
30-01-2023 09:19:24 INFO Epoch 2: [4214/10940] ---- BYOL Training Loss = 0.38272836804389954
30-01-2023 09:19:43 INFO Epoch 2: [4225/10940] ---- BYOL Training Loss = 0.3710041344165802
30-01-2023 09:20:35 INFO Epoch 2: [4225/10940] ---- BYOL Validation Loss = 0.3590671718120575
30-01-2023 09:20:52 INFO Epoch 2: [4236/10940] ---- BYOL Training Loss = 0.36253905296325684
30-01-2023 09:21:10 INFO Epoch 2: [4247/10940] ---- BYOL Training Loss = 0.3749581277370453
30-01-2023 09:21:28 INFO Epoch 2: [4258/10940] ---- BYOL Training Loss = 0.3647514581680298
30-01-2023 09:21:46 INFO Epoch 2: [4269/10940] ---- BYOL Training Loss = 0.4663573205471039
30-01-2023 09:22:38 INFO Epoch 2: [4269/10940] ---- BYOL Validation Loss = 0.34870609641075134
30-01-2023 09:22:56 INFO Epoch 2: [4280/10940] ---- BYOL Training Loss = 0.4358769357204437
30-01-2023 09:23:14 INFO Epoch 2: [4291/10940] ---- BYOL Training Loss = 0.408902108669281
30-01-2023 09:23:32 INFO Epoch 2: [4302/10940] ---- BYOL Training Loss = 0.3496360778808594
30-01-2023 09:23:50 INFO Epoch 2: [4313/10940] ---- BYOL Training Loss = 0.3793758749961853
30-01-2023 09:24:42 INFO Epoch 2: [4313/10940] ---- BYOL Validation Loss = 0.34573009610176086
30-01-2023 09:25:00 INFO Epoch 2: [4324/10940] ---- BYOL Training Loss = 0.3939658999443054
30-01-2023 09:25:18 INFO Epoch 2: [4335/10940] ---- BYOL Training Loss = 0.3498907685279846
30-01-2023 09:25:36 INFO Epoch 2: [4346/10940] ---- BYOL Training Loss = 0.43213874101638794
30-01-2023 09:25:54 INFO Epoch 2: [4357/10940] ---- BYOL Training Loss = 0.3679654896259308
30-01-2023 09:26:46 INFO Epoch 2: [4357/10940] ---- BYOL Validation Loss = 0.3525116741657257
30-01-2023 09:27:03 INFO Epoch 2: [4368/10940] ---- BYOL Training Loss = 0.35254642367362976
30-01-2023 09:27:21 INFO Epoch 2: [4379/10940] ---- BYOL Training Loss = 0.39808201789855957
30-01-2023 09:27:39 INFO Epoch 2: [4390/10940] ---- BYOL Training Loss = 0.3597903847694397
30-01-2023 09:27:57 INFO Epoch 2: [4401/10940] ---- BYOL Training Loss = 0.3394611179828644
30-01-2023 09:28:49 INFO Epoch 2: [4401/10940] ---- BYOL Validation Loss = 0.3394092917442322
30-01-2023 09:29:07 INFO Epoch 2: [4412/10940] ---- BYOL Training Loss = 0.3723317086696625
30-01-2023 09:29:25 INFO Epoch 2: [4423/10940] ---- BYOL Training Loss = 0.3724478483200073
30-01-2023 09:29:43 INFO Epoch 2: [4434/10940] ---- BYOL Training Loss = 0.31476491689682007
30-01-2023 09:30:01 INFO Epoch 2: [4445/10940] ---- BYOL Training Loss = 0.3035559058189392
30-01-2023 09:30:53 INFO Epoch 2: [4445/10940] ---- BYOL Validation Loss = 0.33488914370536804
30-01-2023 09:31:11 INFO Epoch 2: [4456/10940] ---- BYOL Training Loss = 0.32768505811691284
30-01-2023 09:31:29 INFO Epoch 2: [4467/10940] ---- BYOL Training Loss = 0.34344616532325745
30-01-2023 09:31:47 INFO Epoch 2: [4478/10940] ---- BYOL Training Loss = 0.3901485800743103
30-01-2023 09:32:04 INFO Epoch 2: [4489/10940] ---- BYOL Training Loss = 0.35211506485939026
30-01-2023 09:32:56 INFO Epoch 2: [4489/10940] ---- BYOL Validation Loss = 0.34328779578208923
30-01-2023 09:33:14 INFO Epoch 2: [4500/10940] ---- BYOL Training Loss = 0.2972685694694519
30-01-2023 09:33:32 INFO Epoch 2: [4511/10940] ---- BYOL Training Loss = 0.305423766374588
30-01-2023 09:33:50 INFO Epoch 2: [4522/10940] ---- BYOL Training Loss = 0.3063827157020569
30-01-2023 09:34:08 INFO Epoch 2: [4533/10940] ---- BYOL Training Loss = 0.34173423051834106
30-01-2023 09:35:00 INFO Epoch 2: [4533/10940] ---- BYOL Validation Loss = 0.3316461145877838
30-01-2023 09:35:18 INFO Epoch 2: [4544/10940] ---- BYOL Training Loss = 0.3424440920352936
30-01-2023 09:35:36 INFO Epoch 2: [4555/10940] ---- BYOL Training Loss = 0.38835227489471436
30-01-2023 09:35:54 INFO Epoch 2: [4566/10940] ---- BYOL Training Loss = 0.3877304494380951
30-01-2023 09:36:12 INFO Epoch 2: [4577/10940] ---- BYOL Training Loss = 0.32416778802871704
30-01-2023 09:37:04 INFO Epoch 2: [4577/10940] ---- BYOL Validation Loss = 0.33578380942344666
30-01-2023 09:37:22 INFO Epoch 2: [4588/10940] ---- BYOL Training Loss = 0.36244508624076843
30-01-2023 09:37:40 INFO Epoch 2: [4599/10940] ---- BYOL Training Loss = 0.3447074294090271
30-01-2023 09:37:58 INFO Epoch 2: [4610/10940] ---- BYOL Training Loss = 0.3643949031829834
30-01-2023 09:38:16 INFO Epoch 2: [4621/10940] ---- BYOL Training Loss = 0.386496365070343
30-01-2023 09:39:08 INFO Epoch 2: [4621/10940] ---- BYOL Validation Loss = 0.33790722489356995
30-01-2023 09:39:26 INFO Epoch 2: [4632/10940] ---- BYOL Training Loss = 0.4386366903781891
30-01-2023 09:39:44 INFO Epoch 2: [4643/10940] ---- BYOL Training Loss = 0.3994627594947815
30-01-2023 09:40:01 INFO Epoch 2: [4654/10940] ---- BYOL Training Loss = 0.357106477022171
30-01-2023 09:40:19 INFO Epoch 2: [4665/10940] ---- BYOL Training Loss = 0.3551403880119324
30-01-2023 09:41:11 INFO Epoch 2: [4665/10940] ---- BYOL Validation Loss = 0.3348090946674347
30-01-2023 09:41:30 INFO Epoch 2: [4676/10940] ---- BYOL Training Loss = 0.3189484179019928
30-01-2023 09:41:48 INFO Epoch 2: [4687/10940] ---- BYOL Training Loss = 0.35820192098617554
30-01-2023 09:42:06 INFO Epoch 2: [4698/10940] ---- BYOL Training Loss = 0.43462643027305603
30-01-2023 09:42:23 INFO Epoch 2: [4709/10940] ---- BYOL Training Loss = 0.4013395309448242
30-01-2023 09:43:15 INFO Epoch 2: [4709/10940] ---- BYOL Validation Loss = 0.3352043926715851
30-01-2023 09:43:33 INFO Epoch 2: [4720/10940] ---- BYOL Training Loss = 0.34905368089675903
30-01-2023 09:43:51 INFO Epoch 2: [4731/10940] ---- BYOL Training Loss = 0.34689921140670776
30-01-2023 09:44:10 INFO Epoch 2: [4742/10940] ---- BYOL Training Loss = 0.29926061630249023
30-01-2023 09:44:27 INFO Epoch 2: [4753/10940] ---- BYOL Training Loss = 0.28747087717056274
30-01-2023 09:45:19 INFO Epoch 2: [4753/10940] ---- BYOL Validation Loss = 0.3270416855812073
30-01-2023 09:45:37 INFO Epoch 2: [4764/10940] ---- BYOL Training Loss = 0.27359825372695923
30-01-2023 09:45:55 INFO Epoch 2: [4775/10940] ---- BYOL Training Loss = 0.33871063590049744
30-01-2023 09:46:13 INFO Epoch 2: [4786/10940] ---- BYOL Training Loss = 0.3371449410915375
30-01-2023 09:46:31 INFO Epoch 2: [4797/10940] ---- BYOL Training Loss = 0.3189237713813782
30-01-2023 09:47:23 INFO Epoch 2: [4797/10940] ---- BYOL Validation Loss = 0.33948782086372375
30-01-2023 09:47:41 INFO Epoch 2: [4808/10940] ---- BYOL Training Loss = 0.35249844193458557
30-01-2023 09:47:59 INFO Epoch 2: [4819/10940] ---- BYOL Training Loss = 0.36532557010650635
30-01-2023 09:48:17 INFO Epoch 2: [4830/10940] ---- BYOL Training Loss = 0.33288824558258057
30-01-2023 09:48:35 INFO Epoch 2: [4841/10940] ---- BYOL Training Loss = 0.334063321352005
30-01-2023 09:49:27 INFO Epoch 2: [4841/10940] ---- BYOL Validation Loss = 0.32352176308631897
30-01-2023 09:49:45 INFO Epoch 2: [4852/10940] ---- BYOL Training Loss = 0.35075491666793823
30-01-2023 09:50:03 INFO Epoch 2: [4863/10940] ---- BYOL Training Loss = 0.37795567512512207
30-01-2023 09:50:21 INFO Epoch 2: [4874/10940] ---- BYOL Training Loss = 0.3859357535839081
30-01-2023 09:50:39 INFO Epoch 2: [4885/10940] ---- BYOL Training Loss = 0.3297756314277649
30-01-2023 09:51:31 INFO Epoch 2: [4885/10940] ---- BYOL Validation Loss = 0.31888917088508606
30-01-2023 09:51:49 INFO Epoch 2: [4896/10940] ---- BYOL Training Loss = 0.35307741165161133
30-01-2023 09:52:07 INFO Epoch 2: [4907/10940] ---- BYOL Training Loss = 0.35478881001472473
30-01-2023 09:52:25 INFO Epoch 2: [4918/10940] ---- BYOL Training Loss = 0.3610156774520874
30-01-2023 09:52:43 INFO Epoch 2: [4929/10940] ---- BYOL Training Loss = 0.32699018716812134
30-01-2023 09:53:35 INFO Epoch 2: [4929/10940] ---- BYOL Validation Loss = 0.31317397952079773
30-01-2023 09:53:53 INFO Epoch 2: [4940/10940] ---- BYOL Training Loss = 0.29632821679115295
30-01-2023 09:54:11 INFO Epoch 2: [4951/10940] ---- BYOL Training Loss = 0.349494606256485
30-01-2023 09:54:29 INFO Epoch 2: [4962/10940] ---- BYOL Training Loss = 0.3403220772743225
30-01-2023 09:54:47 INFO Epoch 2: [4973/10940] ---- BYOL Training Loss = 0.42681288719177246
30-01-2023 09:55:39 INFO Epoch 2: [4973/10940] ---- BYOL Validation Loss = 0.3360321819782257
30-01-2023 09:55:57 INFO Epoch 2: [4984/10940] ---- BYOL Training Loss = 0.42154890298843384
30-01-2023 09:56:15 INFO Epoch 2: [4995/10940] ---- BYOL Training Loss = 0.33567434549331665
30-01-2023 09:56:33 INFO Epoch 2: [5006/10940] ---- BYOL Training Loss = 0.31370028853416443
30-01-2023 09:56:51 INFO Epoch 2: [5017/10940] ---- BYOL Training Loss = 0.3710736334323883
30-01-2023 09:57:43 INFO Epoch 2: [5017/10940] ---- BYOL Validation Loss = 0.3336632251739502
30-01-2023 09:58:00 INFO Epoch 2: [5028/10940] ---- BYOL Training Loss = 0.385871946811676
30-01-2023 09:58:19 INFO Epoch 2: [5039/10940] ---- BYOL Training Loss = 0.3391425609588623
30-01-2023 09:58:37 INFO Epoch 2: [5050/10940] ---- BYOL Training Loss = 0.31226032972335815
30-01-2023 09:58:55 INFO Epoch 2: [5061/10940] ---- BYOL Training Loss = 0.3051598072052002
30-01-2023 09:59:47 INFO Epoch 2: [5061/10940] ---- BYOL Validation Loss = 0.3226962089538574
30-01-2023 10:00:04 INFO Epoch 2: [5072/10940] ---- BYOL Training Loss = 0.321807324886322
30-01-2023 10:00:22 INFO Epoch 2: [5083/10940] ---- BYOL Training Loss = 0.34617406129837036
30-01-2023 10:00:41 INFO Epoch 2: [5094/10940] ---- BYOL Training Loss = 0.38539522886276245
30-01-2023 10:00:59 INFO Epoch 2: [5105/10940] ---- BYOL Training Loss = 0.39507490396499634
30-01-2023 10:01:51 INFO Epoch 2: [5105/10940] ---- BYOL Validation Loss = 0.3372180759906769
30-01-2023 10:02:08 INFO Epoch 2: [5116/10940] ---- BYOL Training Loss = 0.3059626519680023
30-01-2023 10:02:26 INFO Epoch 2: [5127/10940] ---- BYOL Training Loss = 0.26827743649482727
30-01-2023 10:02:45 INFO Epoch 2: [5138/10940] ---- BYOL Training Loss = 0.3560448884963989
30-01-2023 10:03:03 INFO Epoch 2: [5149/10940] ---- BYOL Training Loss = 0.38819417357444763
30-01-2023 10:03:55 INFO Epoch 2: [5149/10940] ---- BYOL Validation Loss = 0.32550033926963806
30-01-2023 10:04:13 INFO Epoch 2: [5160/10940] ---- BYOL Training Loss = 0.367614209651947
30-01-2023 10:04:31 INFO Epoch 2: [5171/10940] ---- BYOL Training Loss = 0.3620489239692688
30-01-2023 10:04:49 INFO Epoch 2: [5182/10940] ---- BYOL Training Loss = 0.3826284110546112
30-01-2023 10:05:07 INFO Epoch 2: [5193/10940] ---- BYOL Training Loss = 0.4272032678127289
30-01-2023 10:05:59 INFO Epoch 2: [5193/10940] ---- BYOL Validation Loss = 0.3452100455760956
30-01-2023 10:06:17 INFO Epoch 2: [5204/10940] ---- BYOL Training Loss = 0.41484102606773376
30-01-2023 10:06:35 INFO Epoch 2: [5215/10940] ---- BYOL Training Loss = 0.33444052934646606
30-01-2023 10:06:53 INFO Epoch 2: [5226/10940] ---- BYOL Training Loss = 0.2961522340774536
30-01-2023 10:07:11 INFO Epoch 2: [5237/10940] ---- BYOL Training Loss = 0.2960492968559265
30-01-2023 10:08:03 INFO Epoch 2: [5237/10940] ---- BYOL Validation Loss = 0.3368212878704071
30-01-2023 10:08:21 INFO Epoch 2: [5248/10940] ---- BYOL Training Loss = 0.31955140829086304
30-01-2023 10:08:39 INFO Epoch 2: [5259/10940] ---- BYOL Training Loss = 0.33994022011756897
30-01-2023 10:08:57 INFO Epoch 2: [5270/10940] ---- BYOL Training Loss = 0.3465941548347473
30-01-2023 10:09:15 INFO Epoch 2: [5281/10940] ---- BYOL Training Loss = 0.3693859875202179
30-01-2023 10:10:07 INFO Epoch 2: [5281/10940] ---- BYOL Validation Loss = 0.33861494064331055
30-01-2023 10:10:25 INFO Epoch 2: [5292/10940] ---- BYOL Training Loss = 0.3727755546569824
30-01-2023 10:10:43 INFO Epoch 2: [5303/10940] ---- BYOL Training Loss = 0.33977457880973816
30-01-2023 10:11:01 INFO Epoch 2: [5314/10940] ---- BYOL Training Loss = 0.384238600730896
30-01-2023 10:11:19 INFO Epoch 2: [5325/10940] ---- BYOL Training Loss = 0.3515918552875519
30-01-2023 10:12:11 INFO Epoch 2: [5325/10940] ---- BYOL Validation Loss = 0.3252737820148468
30-01-2023 10:12:29 INFO Epoch 2: [5336/10940] ---- BYOL Training Loss = 0.3191226124763489
30-01-2023 10:12:47 INFO Epoch 2: [5347/10940] ---- BYOL Training Loss = 0.3704482913017273
30-01-2023 10:13:05 INFO Epoch 2: [5358/10940] ---- BYOL Training Loss = 0.3687186539173126
30-01-2023 10:13:23 INFO Epoch 2: [5369/10940] ---- BYOL Training Loss = 0.35513877868652344
30-01-2023 10:14:15 INFO Epoch 2: [5369/10940] ---- BYOL Validation Loss = 0.33515146374702454
30-01-2023 10:14:33 INFO Epoch 2: [5380/10940] ---- BYOL Training Loss = 0.3464922606945038
30-01-2023 10:14:51 INFO Epoch 2: [5391/10940] ---- BYOL Training Loss = 0.3134375214576721
30-01-2023 10:15:09 INFO Epoch 2: [5402/10940] ---- BYOL Training Loss = 0.32112112641334534
30-01-2023 10:15:27 INFO Epoch 2: [5413/10940] ---- BYOL Training Loss = 0.33334648609161377
30-01-2023 10:16:19 INFO Epoch 2: [5413/10940] ---- BYOL Validation Loss = 0.34254342317581177
30-01-2023 10:16:36 INFO Epoch 2: [5424/10940] ---- BYOL Training Loss = 0.3484899401664734
30-01-2023 10:16:55 INFO Epoch 2: [5435/10940] ---- BYOL Training Loss = 0.387439101934433
30-01-2023 10:17:13 INFO Epoch 2: [5446/10940] ---- BYOL Training Loss = 0.37397658824920654
30-01-2023 10:17:31 INFO Epoch 2: [5457/10940] ---- BYOL Training Loss = 0.3623608350753784
30-01-2023 10:18:23 INFO Epoch 2: [5457/10940] ---- BYOL Validation Loss = 0.34186607599258423
30-01-2023 10:18:40 INFO Epoch 2: [5468/10940] ---- BYOL Training Loss = 0.33306026458740234
30-01-2023 10:18:59 INFO Epoch 2: [5479/10940] ---- BYOL Training Loss = 0.27479156851768494
30-01-2023 10:19:17 INFO Epoch 2: [5490/10940] ---- BYOL Training Loss = 0.30396077036857605
30-01-2023 10:19:35 INFO Epoch 2: [5501/10940] ---- BYOL Training Loss = 0.30515724420547485
30-01-2023 10:20:27 INFO Epoch 2: [5501/10940] ---- BYOL Validation Loss = 0.3354337513446808
30-01-2023 10:20:45 INFO Epoch 2: [5512/10940] ---- BYOL Training Loss = 0.3174568712711334
30-01-2023 10:21:03 INFO Epoch 2: [5523/10940] ---- BYOL Training Loss = 0.331394761800766
30-01-2023 10:21:21 INFO Epoch 2: [5534/10940] ---- BYOL Training Loss = 0.33558565378189087
30-01-2023 10:21:39 INFO Epoch 2: [5545/10940] ---- BYOL Training Loss = 0.29294636845588684
30-01-2023 10:22:31 INFO Epoch 2: [5545/10940] ---- BYOL Validation Loss = 0.33353424072265625
30-01-2023 10:22:49 INFO Epoch 2: [5556/10940] ---- BYOL Training Loss = 0.29162997007369995
30-01-2023 10:23:07 INFO Epoch 2: [5567/10940] ---- BYOL Training Loss = 0.319945752620697
30-01-2023 10:23:25 INFO Epoch 2: [5578/10940] ---- BYOL Training Loss = 0.31741857528686523
30-01-2023 10:23:43 INFO Epoch 2: [5589/10940] ---- BYOL Training Loss = 0.2879701256752014
30-01-2023 10:24:35 INFO Epoch 2: [5589/10940] ---- BYOL Validation Loss = 0.3251884877681732
30-01-2023 10:24:53 INFO Epoch 2: [5600/10940] ---- BYOL Training Loss = 0.32378697395324707
30-01-2023 10:25:11 INFO Epoch 2: [5611/10940] ---- BYOL Training Loss = 0.29938316345214844
30-01-2023 10:25:29 INFO Epoch 2: [5622/10940] ---- BYOL Training Loss = 0.25666752457618713
30-01-2023 10:25:47 INFO Epoch 2: [5633/10940] ---- BYOL Training Loss = 0.25363627076148987
30-01-2023 10:26:39 INFO Epoch 2: [5633/10940] ---- BYOL Validation Loss = 0.3265211284160614
30-01-2023 10:26:56 INFO Epoch 2: [5644/10940] ---- BYOL Training Loss = 0.3255021572113037
30-01-2023 10:27:15 INFO Epoch 2: [5655/10940] ---- BYOL Training Loss = 0.37488311529159546
30-01-2023 10:27:33 INFO Epoch 2: [5666/10940] ---- BYOL Training Loss = 0.317886084318161
30-01-2023 10:27:51 INFO Epoch 2: [5677/10940] ---- BYOL Training Loss = 0.3156120181083679
30-01-2023 10:28:42 INFO Epoch 2: [5677/10940] ---- BYOL Validation Loss = 0.326097697019577
30-01-2023 10:29:00 INFO Epoch 2: [5688/10940] ---- BYOL Training Loss = 0.3328533470630646
30-01-2023 10:29:19 INFO Epoch 2: [5699/10940] ---- BYOL Training Loss = 0.37604784965515137
30-01-2023 10:29:36 INFO Epoch 2: [5710/10940] ---- BYOL Training Loss = 0.3772050142288208
30-01-2023 10:29:54 INFO Epoch 2: [5721/10940] ---- BYOL Training Loss = 0.4016689360141754
30-01-2023 10:30:46 INFO Epoch 2: [5721/10940] ---- BYOL Validation Loss = 0.34580332040786743
30-01-2023 10:31:04 INFO Epoch 2: [5732/10940] ---- BYOL Training Loss = 0.40920862555503845
30-01-2023 10:31:22 INFO Epoch 2: [5743/10940] ---- BYOL Training Loss = 0.34900107979774475
30-01-2023 10:31:40 INFO Epoch 2: [5754/10940] ---- BYOL Training Loss = 0.3692604899406433
30-01-2023 10:31:58 INFO Epoch 2: [5765/10940] ---- BYOL Training Loss = 0.33683639764785767
30-01-2023 10:32:50 INFO Epoch 2: [5765/10940] ---- BYOL Validation Loss = 0.33887413144111633
30-01-2023 10:33:08 INFO Epoch 2: [5776/10940] ---- BYOL Training Loss = 0.31166189908981323
30-01-2023 10:33:26 INFO Epoch 2: [5787/10940] ---- BYOL Training Loss = 0.3286387026309967
30-01-2023 10:33:44 INFO Epoch 2: [5798/10940] ---- BYOL Training Loss = 0.3931686282157898
30-01-2023 10:34:02 INFO Epoch 2: [5809/10940] ---- BYOL Training Loss = 0.4014803469181061
30-01-2023 10:34:54 INFO Epoch 2: [5809/10940] ---- BYOL Validation Loss = 0.33920812606811523
30-01-2023 10:35:12 INFO Epoch 2: [5820/10940] ---- BYOL Training Loss = 0.3202240765094757
30-01-2023 10:35:30 INFO Epoch 2: [5831/10940] ---- BYOL Training Loss = 0.37544959783554077
30-01-2023 10:35:48 INFO Epoch 2: [5842/10940] ---- BYOL Training Loss = 0.3996106684207916
30-01-2023 10:36:06 INFO Epoch 2: [5853/10940] ---- BYOL Training Loss = 0.3236650824546814
30-01-2023 10:36:58 INFO Epoch 2: [5853/10940] ---- BYOL Validation Loss = 0.3285442888736725
30-01-2023 10:37:16 INFO Epoch 2: [5864/10940] ---- BYOL Training Loss = 0.29664871096611023
30-01-2023 10:37:34 INFO Epoch 2: [5875/10940] ---- BYOL Training Loss = 0.251078724861145
30-01-2023 10:37:52 INFO Epoch 2: [5886/10940] ---- BYOL Training Loss = 0.3051021099090576
30-01-2023 10:38:10 INFO Epoch 2: [5897/10940] ---- BYOL Training Loss = 0.3510516881942749
30-01-2023 10:39:02 INFO Epoch 2: [5897/10940] ---- BYOL Validation Loss = 0.35629934072494507
30-01-2023 10:39:20 INFO Epoch 2: [5908/10940] ---- BYOL Training Loss = 0.3345377445220947
30-01-2023 10:39:38 INFO Epoch 2: [5919/10940] ---- BYOL Training Loss = 0.35644859075546265
30-01-2023 10:39:56 INFO Epoch 2: [5930/10940] ---- BYOL Training Loss = 0.3931625485420227
30-01-2023 10:40:14 INFO Epoch 2: [5941/10940] ---- BYOL Training Loss = 0.3465602993965149
30-01-2023 10:41:06 INFO Epoch 2: [5941/10940] ---- BYOL Validation Loss = 0.3411148488521576
30-01-2023 10:41:24 INFO Epoch 2: [5952/10940] ---- BYOL Training Loss = 0.3041209876537323
30-01-2023 10:41:42 INFO Epoch 2: [5963/10940] ---- BYOL Training Loss = 0.3241053521633148
30-01-2023 10:42:00 INFO Epoch 2: [5974/10940] ---- BYOL Training Loss = 0.31433790922164917
30-01-2023 10:42:18 INFO Epoch 2: [5985/10940] ---- BYOL Training Loss = 0.29624781012535095
30-01-2023 10:43:10 INFO Epoch 2: [5985/10940] ---- BYOL Validation Loss = 0.33805570006370544
30-01-2023 10:43:28 INFO Epoch 2: [5996/10940] ---- BYOL Training Loss = 0.31293848156929016
30-01-2023 10:43:46 INFO Epoch 2: [6007/10940] ---- BYOL Training Loss = 0.325145423412323
30-01-2023 10:44:04 INFO Epoch 2: [6018/10940] ---- BYOL Training Loss = 0.3229585289955139
30-01-2023 10:44:22 INFO Epoch 2: [6029/10940] ---- BYOL Training Loss = 0.40503066778182983
30-01-2023 10:45:14 INFO Epoch 2: [6029/10940] ---- BYOL Validation Loss = 0.3238050639629364
30-01-2023 10:45:32 INFO Epoch 2: [6040/10940] ---- BYOL Training Loss = 0.39783984422683716
30-01-2023 10:45:51 INFO Epoch 2: [6051/10940] ---- BYOL Training Loss = 0.3400944471359253
30-01-2023 10:46:09 INFO Epoch 2: [6062/10940] ---- BYOL Training Loss = 0.3744692802429199
30-01-2023 10:46:27 INFO Epoch 2: [6073/10940] ---- BYOL Training Loss = 0.37802064418792725
30-01-2023 10:47:19 INFO Epoch 2: [6073/10940] ---- BYOL Validation Loss = 0.32087966799736023
30-01-2023 10:47:36 INFO Epoch 2: [6084/10940] ---- BYOL Training Loss = 0.2809600234031677
30-01-2023 10:47:55 INFO Epoch 2: [6095/10940] ---- BYOL Training Loss = 0.33184951543807983
30-01-2023 10:48:13 INFO Epoch 2: [6106/10940] ---- BYOL Training Loss = 0.33891719579696655
30-01-2023 10:48:31 INFO Epoch 2: [6117/10940] ---- BYOL Training Loss = 0.35931113362312317
30-01-2023 10:49:23 INFO Epoch 2: [6117/10940] ---- BYOL Validation Loss = 0.3395083248615265
30-01-2023 10:49:41 INFO Epoch 2: [6128/10940] ---- BYOL Training Loss = 0.33558326959609985
30-01-2023 10:49:59 INFO Epoch 2: [6139/10940] ---- BYOL Training Loss = 0.32642048597335815
30-01-2023 10:50:17 INFO Epoch 2: [6150/10940] ---- BYOL Training Loss = 0.4019502103328705
30-01-2023 10:50:35 INFO Epoch 2: [6161/10940] ---- BYOL Training Loss = 0.3785102367401123
30-01-2023 10:51:27 INFO Epoch 2: [6161/10940] ---- BYOL Validation Loss = 0.3247268497943878
30-01-2023 10:51:46 INFO Epoch 2: [6172/10940] ---- BYOL Training Loss = 0.3125855028629303
30-01-2023 10:52:04 INFO Epoch 2: [6183/10940] ---- BYOL Training Loss = 0.3085567355155945
30-01-2023 10:52:22 INFO Epoch 2: [6194/10940] ---- BYOL Training Loss = 0.3018585741519928
30-01-2023 10:52:40 INFO Epoch 2: [6205/10940] ---- BYOL Training Loss = 0.338529109954834
30-01-2023 10:53:32 INFO Epoch 2: [6205/10940] ---- BYOL Validation Loss = 0.3291988968849182
30-01-2023 10:53:50 INFO Epoch 2: [6216/10940] ---- BYOL Training Loss = 0.36514219641685486
30-01-2023 10:54:08 INFO Epoch 2: [6227/10940] ---- BYOL Training Loss = 0.3548419177532196
30-01-2023 10:54:26 INFO Epoch 2: [6238/10940] ---- BYOL Training Loss = 0.3767636716365814
30-01-2023 10:54:45 INFO Epoch 2: [6249/10940] ---- BYOL Training Loss = 0.34781888127326965
30-01-2023 10:55:37 INFO Epoch 2: [6249/10940] ---- BYOL Validation Loss = 0.330068439245224
30-01-2023 10:55:55 INFO Epoch 2: [6260/10940] ---- BYOL Training Loss = 0.34220561385154724
30-01-2023 10:56:13 INFO Epoch 2: [6271/10940] ---- BYOL Training Loss = 0.3653998076915741
30-01-2023 10:56:31 INFO Epoch 2: [6282/10940] ---- BYOL Training Loss = 0.34179097414016724
30-01-2023 10:56:49 INFO Epoch 2: [6293/10940] ---- BYOL Training Loss = 0.30556195974349976
30-01-2023 10:57:41 INFO Epoch 2: [6293/10940] ---- BYOL Validation Loss = 0.3322382867336273
30-01-2023 10:57:59 INFO Epoch 2: [6304/10940] ---- BYOL Training Loss = 0.3103594183921814
30-01-2023 10:58:17 INFO Epoch 2: [6315/10940] ---- BYOL Training Loss = 0.3372023403644562
30-01-2023 10:58:36 INFO Epoch 2: [6326/10940] ---- BYOL Training Loss = 0.4403437674045563
30-01-2023 10:58:54 INFO Epoch 2: [6337/10940] ---- BYOL Training Loss = 0.43730124831199646
30-01-2023 10:59:46 INFO Epoch 2: [6337/10940] ---- BYOL Validation Loss = 0.3328954875469208
30-01-2023 11:00:04 INFO Epoch 2: [6348/10940] ---- BYOL Training Loss = 0.3032817244529724
30-01-2023 11:00:22 INFO Epoch 2: [6359/10940] ---- BYOL Training Loss = 0.32631006836891174
30-01-2023 11:00:40 INFO Epoch 2: [6370/10940] ---- BYOL Training Loss = 0.29763004183769226
30-01-2023 11:00:58 INFO Epoch 2: [6381/10940] ---- BYOL Training Loss = 0.3213415741920471
30-01-2023 11:01:50 INFO Epoch 2: [6381/10940] ---- BYOL Validation Loss = 0.3348050117492676
30-01-2023 11:02:08 INFO Epoch 2: [6392/10940] ---- BYOL Training Loss = 0.348812460899353
30-01-2023 11:02:26 INFO Epoch 2: [6403/10940] ---- BYOL Training Loss = 0.319947212934494
30-01-2023 11:02:44 INFO Epoch 2: [6414/10940] ---- BYOL Training Loss = 0.3474368751049042
30-01-2023 11:03:02 INFO Epoch 2: [6425/10940] ---- BYOL Training Loss = 0.3683200180530548
30-01-2023 11:03:54 INFO Epoch 2: [6425/10940] ---- BYOL Validation Loss = 0.34144729375839233
30-01-2023 11:04:12 INFO Epoch 2: [6436/10940] ---- BYOL Training Loss = 0.32432395219802856
30-01-2023 11:04:31 INFO Epoch 2: [6447/10940] ---- BYOL Training Loss = 0.33510822057724
30-01-2023 11:04:49 INFO Epoch 2: [6458/10940] ---- BYOL Training Loss = 0.3422608971595764
30-01-2023 11:05:07 INFO Epoch 2: [6469/10940] ---- BYOL Training Loss = 0.37589216232299805
30-01-2023 11:05:59 INFO Epoch 2: [6469/10940] ---- BYOL Validation Loss = 0.38544735312461853
30-01-2023 11:06:17 INFO Epoch 2: [6480/10940] ---- BYOL Training Loss = 0.36058464646339417
30-01-2023 11:06:35 INFO Epoch 2: [6491/10940] ---- BYOL Training Loss = 0.2993427813053131
30-01-2023 11:06:53 INFO Epoch 2: [6502/10940] ---- BYOL Training Loss = 0.29348406195640564
30-01-2023 11:07:11 INFO Epoch 2: [6513/10940] ---- BYOL Training Loss = 0.3255905508995056
30-01-2023 11:08:03 INFO Epoch 2: [6513/10940] ---- BYOL Validation Loss = 0.3204744756221771
30-01-2023 11:08:21 INFO Epoch 2: [6524/10940] ---- BYOL Training Loss = 0.3086179196834564
30-01-2023 11:08:40 INFO Epoch 2: [6535/10940] ---- BYOL Training Loss = 0.3348901867866516
30-01-2023 11:08:58 INFO Epoch 2: [6546/10940] ---- BYOL Training Loss = 0.3975071609020233
30-01-2023 11:09:16 INFO Epoch 2: [6557/10940] ---- BYOL Training Loss = 0.34660467505455017
30-01-2023 11:10:08 INFO Epoch 2: [6557/10940] ---- BYOL Validation Loss = 0.31508827209472656
30-01-2023 11:10:26 INFO Epoch 2: [6568/10940] ---- BYOL Training Loss = 0.34941425919532776
30-01-2023 11:10:44 INFO Epoch 2: [6579/10940] ---- BYOL Training Loss = 0.35543856024742126
30-01-2023 11:11:02 INFO Epoch 2: [6590/10940] ---- BYOL Training Loss = 0.3564019799232483
30-01-2023 11:11:20 INFO Epoch 2: [6601/10940] ---- BYOL Training Loss = 0.37362655997276306
30-01-2023 11:12:12 INFO Epoch 2: [6601/10940] ---- BYOL Validation Loss = 0.31849074363708496
30-01-2023 11:12:30 INFO Epoch 2: [6612/10940] ---- BYOL Training Loss = 0.38110142946243286
30-01-2023 11:12:48 INFO Epoch 2: [6623/10940] ---- BYOL Training Loss = 0.33848509192466736
30-01-2023 11:13:06 INFO Epoch 2: [6634/10940] ---- BYOL Training Loss = 0.2811070680618286
30-01-2023 11:13:25 INFO Epoch 2: [6645/10940] ---- BYOL Training Loss = 0.27653664350509644
30-01-2023 11:14:17 INFO Epoch 2: [6645/10940] ---- BYOL Validation Loss = 0.31576308608055115
30-01-2023 11:14:34 INFO Epoch 2: [6656/10940] ---- BYOL Training Loss = 0.3097563683986664
30-01-2023 11:14:52 INFO Epoch 2: [6667/10940] ---- BYOL Training Loss = 0.31494444608688354
30-01-2023 11:15:11 INFO Epoch 2: [6678/10940] ---- BYOL Training Loss = 0.30499759316444397
30-01-2023 11:15:29 INFO Epoch 2: [6689/10940] ---- BYOL Training Loss = 0.3147083520889282
30-01-2023 11:16:21 INFO Epoch 2: [6689/10940] ---- BYOL Validation Loss = 0.3208165764808655
30-01-2023 11:16:39 INFO Epoch 2: [6700/10940] ---- BYOL Training Loss = 0.3619830906391144
30-01-2023 11:16:57 INFO Epoch 2: [6711/10940] ---- BYOL Training Loss = 0.305890828371048
30-01-2023 11:17:16 INFO Epoch 2: [6722/10940] ---- BYOL Training Loss = 0.2834710478782654
30-01-2023 11:17:34 INFO Epoch 2: [6733/10940] ---- BYOL Training Loss = 0.32923513650894165
30-01-2023 11:18:26 INFO Epoch 2: [6733/10940] ---- BYOL Validation Loss = 0.3347744047641754
30-01-2023 11:18:43 INFO Epoch 2: [6744/10940] ---- BYOL Training Loss = 0.301958292722702
30-01-2023 11:19:01 INFO Epoch 2: [6755/10940] ---- BYOL Training Loss = 0.3176804184913635
30-01-2023 11:19:20 INFO Epoch 2: [6766/10940] ---- BYOL Training Loss = 0.2788306176662445
30-01-2023 11:19:38 INFO Epoch 2: [6777/10940] ---- BYOL Training Loss = 0.2948521077632904
30-01-2023 11:20:30 INFO Epoch 2: [6777/10940] ---- BYOL Validation Loss = 0.3379015028476715
30-01-2023 11:20:48 INFO Epoch 2: [6788/10940] ---- BYOL Training Loss = 0.35884544253349304
30-01-2023 11:21:06 INFO Epoch 2: [6799/10940] ---- BYOL Training Loss = 0.4098030626773834
30-01-2023 11:21:24 INFO Epoch 2: [6810/10940] ---- BYOL Training Loss = 0.36359748244285583
30-01-2023 11:21:42 INFO Epoch 2: [6821/10940] ---- BYOL Training Loss = 0.3449931740760803
30-01-2023 11:22:34 INFO Epoch 2: [6821/10940] ---- BYOL Validation Loss = 0.33258873224258423
30-01-2023 11:22:52 INFO Epoch 2: [6832/10940] ---- BYOL Training Loss = 0.32149991393089294
30-01-2023 11:23:11 INFO Epoch 2: [6843/10940] ---- BYOL Training Loss = 0.35878241062164307
30-01-2023 11:23:29 INFO Epoch 2: [6854/10940] ---- BYOL Training Loss = 0.3325363099575043
30-01-2023 11:23:47 INFO Epoch 2: [6865/10940] ---- BYOL Training Loss = 0.31921783089637756
30-01-2023 11:24:39 INFO Epoch 2: [6865/10940] ---- BYOL Validation Loss = 0.33403557538986206
30-01-2023 11:24:57 INFO Epoch 2: [6876/10940] ---- BYOL Training Loss = 0.34291893243789673
30-01-2023 11:25:16 INFO Epoch 2: [6887/10940] ---- BYOL Training Loss = 0.2895602583885193
30-01-2023 11:25:34 INFO Epoch 2: [6898/10940] ---- BYOL Training Loss = 0.3137792944908142
30-01-2023 11:25:52 INFO Epoch 2: [6909/10940] ---- BYOL Training Loss = 0.34197309613227844
30-01-2023 11:26:44 INFO Epoch 2: [6909/10940] ---- BYOL Validation Loss = 0.32047250866889954
30-01-2023 11:27:02 INFO Epoch 2: [6920/10940] ---- BYOL Training Loss = 0.3519725799560547
30-01-2023 11:27:20 INFO Epoch 2: [6931/10940] ---- BYOL Training Loss = 0.32830289006233215
30-01-2023 11:27:39 INFO Epoch 2: [6942/10940] ---- BYOL Training Loss = 0.2864239811897278
30-01-2023 11:27:57 INFO Epoch 2: [6953/10940] ---- BYOL Training Loss = 0.3490709066390991
30-01-2023 11:28:49 INFO Epoch 2: [6953/10940] ---- BYOL Validation Loss = 0.32400041818618774
30-01-2023 11:29:07 INFO Epoch 2: [6964/10940] ---- BYOL Training Loss = 0.3203781545162201
30-01-2023 11:29:25 INFO Epoch 2: [6975/10940] ---- BYOL Training Loss = 0.3221514821052551
30-01-2023 11:29:44 INFO Epoch 2: [6986/10940] ---- BYOL Training Loss = 0.31976553797721863
30-01-2023 11:30:02 INFO Epoch 2: [6997/10940] ---- BYOL Training Loss = 0.3106490671634674
30-01-2023 11:30:54 INFO Epoch 2: [6997/10940] ---- BYOL Validation Loss = 0.31752094626426697
30-01-2023 11:31:11 INFO Epoch 2: [7008/10940] ---- BYOL Training Loss = 0.3100143074989319
30-01-2023 11:31:30 INFO Epoch 2: [7019/10940] ---- BYOL Training Loss = 0.33016258478164673
30-01-2023 11:31:48 INFO Epoch 2: [7030/10940] ---- BYOL Training Loss = 0.3128150701522827
30-01-2023 11:32:06 INFO Epoch 2: [7041/10940] ---- BYOL Training Loss = 0.38955944776535034
30-01-2023 11:32:58 INFO Epoch 2: [7041/10940] ---- BYOL Validation Loss = 0.32496505975723267
30-01-2023 11:33:17 INFO Epoch 2: [7052/10940] ---- BYOL Training Loss = 0.35561320185661316
30-01-2023 11:33:35 INFO Epoch 2: [7063/10940] ---- BYOL Training Loss = 0.3148176968097687
30-01-2023 11:33:53 INFO Epoch 2: [7074/10940] ---- BYOL Training Loss = 0.3249150812625885
30-01-2023 11:34:11 INFO Epoch 2: [7085/10940] ---- BYOL Training Loss = 0.34557071328163147
30-01-2023 11:35:03 INFO Epoch 2: [7085/10940] ---- BYOL Validation Loss = 0.32920876145362854
30-01-2023 11:35:21 INFO Epoch 2: [7096/10940] ---- BYOL Training Loss = 0.30922868847846985
30-01-2023 11:35:39 INFO Epoch 2: [7107/10940] ---- BYOL Training Loss = 0.30755671858787537
30-01-2023 11:35:57 INFO Epoch 2: [7118/10940] ---- BYOL Training Loss = 0.3547520041465759
30-01-2023 11:36:16 INFO Epoch 2: [7129/10940] ---- BYOL Training Loss = 0.3765697479248047
30-01-2023 11:37:08 INFO Epoch 2: [7129/10940] ---- BYOL Validation Loss = 0.3307263255119324
30-01-2023 11:37:26 INFO Epoch 2: [7140/10940] ---- BYOL Training Loss = 0.39331963658332825
30-01-2023 11:37:44 INFO Epoch 2: [7151/10940] ---- BYOL Training Loss = 0.3537082076072693
30-01-2023 11:38:03 INFO Epoch 2: [7162/10940] ---- BYOL Training Loss = 0.3454253077507019
30-01-2023 11:38:21 INFO Epoch 2: [7173/10940] ---- BYOL Training Loss = 0.3331556022167206
30-01-2023 11:39:13 INFO Epoch 2: [7173/10940] ---- BYOL Validation Loss = 0.3358519971370697
30-01-2023 11:39:31 INFO Epoch 2: [7184/10940] ---- BYOL Training Loss = 0.344887912273407
30-01-2023 11:39:49 INFO Epoch 2: [7195/10940] ---- BYOL Training Loss = 0.3259728252887726
30-01-2023 11:40:07 INFO Epoch 2: [7206/10940] ---- BYOL Training Loss = 0.33295178413391113
30-01-2023 11:40:25 INFO Epoch 2: [7217/10940] ---- BYOL Training Loss = 0.3857041895389557
30-01-2023 11:41:17 INFO Epoch 2: [7217/10940] ---- BYOL Validation Loss = 0.34964075684547424
30-01-2023 11:41:35 INFO Epoch 2: [7228/10940] ---- BYOL Training Loss = 0.3558747172355652
30-01-2023 11:41:54 INFO Epoch 2: [7239/10940] ---- BYOL Training Loss = 0.32876014709472656
30-01-2023 11:42:12 INFO Epoch 2: [7250/10940] ---- BYOL Training Loss = 0.3312903046607971
30-01-2023 11:42:30 INFO Epoch 2: [7261/10940] ---- BYOL Training Loss = 0.3375633955001831
30-01-2023 11:43:22 INFO Epoch 2: [7261/10940] ---- BYOL Validation Loss = 0.32853052020072937
30-01-2023 11:43:40 INFO Epoch 2: [7272/10940] ---- BYOL Training Loss = 0.3620140850543976
30-01-2023 11:43:58 INFO Epoch 2: [7283/10940] ---- BYOL Training Loss = 0.393172025680542
30-01-2023 11:44:17 INFO Epoch 2: [7294/10940] ---- BYOL Training Loss = 0.39410561323165894
30-01-2023 11:44:35 INFO Epoch 2: [7305/10940] ---- BYOL Training Loss = 0.3596757650375366
30-01-2023 11:45:27 INFO Epoch 2: [7305/10940] ---- BYOL Validation Loss = 0.3297794461250305
30-01-2023 11:45:45 INFO Epoch 2: [7316/10940] ---- BYOL Training Loss = 0.3319910764694214
30-01-2023 11:46:03 INFO Epoch 2: [7327/10940] ---- BYOL Training Loss = 0.34267979860305786
30-01-2023 11:46:22 INFO Epoch 2: [7338/10940] ---- BYOL Training Loss = 0.36256489157676697
30-01-2023 11:46:40 INFO Epoch 2: [7349/10940] ---- BYOL Training Loss = 0.3715500235557556
30-01-2023 11:47:32 INFO Epoch 2: [7349/10940] ---- BYOL Validation Loss = 0.33081912994384766
30-01-2023 11:47:50 INFO Epoch 2: [7360/10940] ---- BYOL Training Loss = 0.329574316740036
30-01-2023 11:48:08 INFO Epoch 2: [7371/10940] ---- BYOL Training Loss = 0.32682329416275024
30-01-2023 11:48:26 INFO Epoch 2: [7382/10940] ---- BYOL Training Loss = 0.3207036256790161
30-01-2023 11:48:44 INFO Epoch 2: [7393/10940] ---- BYOL Training Loss = 0.3173474967479706
30-01-2023 11:49:36 INFO Epoch 2: [7393/10940] ---- BYOL Validation Loss = 0.33054110407829285
30-01-2023 11:49:54 INFO Epoch 2: [7404/10940] ---- BYOL Training Loss = 0.38865453004837036
30-01-2023 11:50:13 INFO Epoch 2: [7415/10940] ---- BYOL Training Loss = 0.3419150114059448
30-01-2023 11:50:31 INFO Epoch 2: [7426/10940] ---- BYOL Training Loss = 0.29219499230384827
30-01-2023 11:50:49 INFO Epoch 2: [7437/10940] ---- BYOL Training Loss = 0.2770156264305115
30-01-2023 11:51:41 INFO Epoch 2: [7437/10940] ---- BYOL Validation Loss = 0.3268502354621887
30-01-2023 11:52:00 INFO Epoch 2: [7448/10940] ---- BYOL Training Loss = 0.31197866797447205
30-01-2023 11:52:18 INFO Epoch 2: [7459/10940] ---- BYOL Training Loss = 0.33098748326301575
30-01-2023 11:52:36 INFO Epoch 2: [7470/10940] ---- BYOL Training Loss = 0.31309837102890015
30-01-2023 11:52:54 INFO Epoch 2: [7481/10940] ---- BYOL Training Loss = 0.30699869990348816
30-01-2023 11:53:46 INFO Epoch 2: [7481/10940] ---- BYOL Validation Loss = 0.32703015208244324
30-01-2023 11:54:04 INFO Epoch 2: [7492/10940] ---- BYOL Training Loss = 0.3769298791885376
30-01-2023 11:54:23 INFO Epoch 2: [7503/10940] ---- BYOL Training Loss = 0.39933091402053833
30-01-2023 11:54:41 INFO Epoch 2: [7514/10940] ---- BYOL Training Loss = 0.3196800947189331
30-01-2023 11:54:59 INFO Epoch 2: [7525/10940] ---- BYOL Training Loss = 0.35328155755996704
30-01-2023 11:55:51 INFO Epoch 2: [7525/10940] ---- BYOL Validation Loss = 0.31461000442504883
30-01-2023 11:56:09 INFO Epoch 2: [7536/10940] ---- BYOL Training Loss = 0.40211454033851624
30-01-2023 11:56:28 INFO Epoch 2: [7547/10940] ---- BYOL Training Loss = 0.3213033080101013
30-01-2023 11:56:46 INFO Epoch 2: [7558/10940] ---- BYOL Training Loss = 0.27328255772590637
30-01-2023 11:57:04 INFO Epoch 2: [7569/10940] ---- BYOL Training Loss = 0.2764781713485718
30-01-2023 11:57:56 INFO Epoch 2: [7569/10940] ---- BYOL Validation Loss = 0.34051522612571716
30-01-2023 11:58:15 INFO Epoch 2: [7580/10940] ---- BYOL Training Loss = 0.3280549645423889
30-01-2023 11:58:33 INFO Epoch 2: [7591/10940] ---- BYOL Training Loss = 0.40120357275009155
30-01-2023 11:58:51 INFO Epoch 2: [7602/10940] ---- BYOL Training Loss = 0.35650408267974854
30-01-2023 11:59:10 INFO Epoch 2: [7613/10940] ---- BYOL Training Loss = 0.38260048627853394
30-01-2023 12:00:02 INFO Epoch 2: [7613/10940] ---- BYOL Validation Loss = 0.32895946502685547
30-01-2023 12:00:19 INFO Epoch 2: [7624/10940] ---- BYOL Training Loss = 0.4281386435031891
30-01-2023 12:00:38 INFO Epoch 2: [7635/10940] ---- BYOL Training Loss = 0.4017360210418701
30-01-2023 12:00:56 INFO Epoch 2: [7646/10940] ---- BYOL Training Loss = 0.3717135787010193
30-01-2023 12:01:14 INFO Epoch 2: [7657/10940] ---- BYOL Training Loss = 0.2966083288192749
30-01-2023 12:02:06 INFO Epoch 2: [7657/10940] ---- BYOL Validation Loss = 0.34675487875938416
30-01-2023 12:02:24 INFO Epoch 2: [7668/10940] ---- BYOL Training Loss = 0.2599145770072937
30-01-2023 12:02:43 INFO Epoch 2: [7679/10940] ---- BYOL Training Loss = 0.2930826246738434
30-01-2023 12:03:01 INFO Epoch 2: [7690/10940] ---- BYOL Training Loss = 0.2938995659351349
30-01-2023 12:03:19 INFO Epoch 2: [7701/10940] ---- BYOL Training Loss = 0.33443683385849
30-01-2023 12:04:11 INFO Epoch 2: [7701/10940] ---- BYOL Validation Loss = 0.32637909054756165
30-01-2023 12:04:29 INFO Epoch 2: [7712/10940] ---- BYOL Training Loss = 0.36797577142715454
30-01-2023 12:04:48 INFO Epoch 2: [7723/10940] ---- BYOL Training Loss = 0.35208243131637573
30-01-2023 12:05:06 INFO Epoch 2: [7734/10940] ---- BYOL Training Loss = 0.3436662554740906
30-01-2023 12:05:24 INFO Epoch 2: [7745/10940] ---- BYOL Training Loss = 0.33446183800697327
30-01-2023 12:06:17 INFO Epoch 2: [7745/10940] ---- BYOL Validation Loss = 0.32420045137405396
30-01-2023 12:06:35 INFO Epoch 2: [7756/10940] ---- BYOL Training Loss = 0.33413612842559814
30-01-2023 12:06:53 INFO Epoch 2: [7767/10940] ---- BYOL Training Loss = 0.28389066457748413
30-01-2023 12:07:12 INFO Epoch 2: [7778/10940] ---- BYOL Training Loss = 0.3195458650588989
30-01-2023 12:07:30 INFO Epoch 2: [7789/10940] ---- BYOL Training Loss = 0.3129924237728119
30-01-2023 12:08:22 INFO Epoch 2: [7789/10940] ---- BYOL Validation Loss = 0.33697476983070374
30-01-2023 12:08:40 INFO Epoch 2: [7800/10940] ---- BYOL Training Loss = 0.30731773376464844
30-01-2023 12:08:58 INFO Epoch 2: [7811/10940] ---- BYOL Training Loss = 0.24424166977405548
30-01-2023 12:09:16 INFO Epoch 2: [7822/10940] ---- BYOL Training Loss = 0.2575305998325348
30-01-2023 12:09:35 INFO Epoch 2: [7833/10940] ---- BYOL Training Loss = 0.31863242387771606
30-01-2023 12:10:27 INFO Epoch 2: [7833/10940] ---- BYOL Validation Loss = 0.32226434350013733
30-01-2023 12:10:45 INFO Epoch 2: [7844/10940] ---- BYOL Training Loss = 0.34677836298942566
30-01-2023 12:11:03 INFO Epoch 2: [7855/10940] ---- BYOL Training Loss = 0.28079885244369507
30-01-2023 12:11:21 INFO Epoch 2: [7866/10940] ---- BYOL Training Loss = 0.306801974773407
30-01-2023 12:11:39 INFO Epoch 2: [7877/10940] ---- BYOL Training Loss = 0.30440622568130493
30-01-2023 12:12:31 INFO Epoch 2: [7877/10940] ---- BYOL Validation Loss = 0.3408300578594208
30-01-2023 12:12:50 INFO Epoch 2: [7888/10940] ---- BYOL Training Loss = 0.3228129744529724
30-01-2023 12:13:08 INFO Epoch 2: [7899/10940] ---- BYOL Training Loss = 0.3592774271965027
30-01-2023 12:13:26 INFO Epoch 2: [7910/10940] ---- BYOL Training Loss = 0.2941826581954956
30-01-2023 12:13:45 INFO Epoch 2: [7921/10940] ---- BYOL Training Loss = 0.2665300965309143
30-01-2023 12:14:37 INFO Epoch 2: [7921/10940] ---- BYOL Validation Loss = 0.3208496868610382
30-01-2023 12:14:55 INFO Epoch 2: [7932/10940] ---- BYOL Training Loss = 0.2683061957359314
30-01-2023 12:15:13 INFO Epoch 2: [7943/10940] ---- BYOL Training Loss = 0.2649613916873932
30-01-2023 12:15:32 INFO Epoch 2: [7954/10940] ---- BYOL Training Loss = 0.3246300220489502
30-01-2023 12:15:50 INFO Epoch 2: [7965/10940] ---- BYOL Training Loss = 0.34188535809516907
30-01-2023 12:16:42 INFO Epoch 2: [7965/10940] ---- BYOL Validation Loss = 0.3129750192165375
30-01-2023 12:17:00 INFO Epoch 2: [7976/10940] ---- BYOL Training Loss = 0.3196406662464142
30-01-2023 12:17:18 INFO Epoch 2: [7987/10940] ---- BYOL Training Loss = 0.31693872809410095
30-01-2023 12:17:36 INFO Epoch 2: [7998/10940] ---- BYOL Training Loss = 0.35714250802993774
30-01-2023 12:17:55 INFO Epoch 2: [8009/10940] ---- BYOL Training Loss = 0.3437870144844055
30-01-2023 12:18:47 INFO Epoch 2: [8009/10940] ---- BYOL Validation Loss = 0.31417110562324524
30-01-2023 12:19:05 INFO Epoch 2: [8020/10940] ---- BYOL Training Loss = 0.3176538348197937
30-01-2023 12:19:23 INFO Epoch 2: [8031/10940] ---- BYOL Training Loss = 0.306068480014801
30-01-2023 12:19:42 INFO Epoch 2: [8042/10940] ---- BYOL Training Loss = 0.2801467478275299
30-01-2023 12:20:00 INFO Epoch 2: [8053/10940] ---- BYOL Training Loss = 0.29233652353286743
30-01-2023 12:20:52 INFO Epoch 2: [8053/10940] ---- BYOL Validation Loss = 0.31197020411491394
30-01-2023 12:21:10 INFO Epoch 2: [8064/10940] ---- BYOL Training Loss = 0.31758299469947815
30-01-2023 12:21:28 INFO Epoch 2: [8075/10940] ---- BYOL Training Loss = 0.30596211552619934
30-01-2023 12:21:47 INFO Epoch 2: [8086/10940] ---- BYOL Training Loss = 0.30477139353752136
30-01-2023 12:22:05 INFO Epoch 2: [8097/10940] ---- BYOL Training Loss = 0.3556939661502838
30-01-2023 12:22:57 INFO Epoch 2: [8097/10940] ---- BYOL Validation Loss = 0.3126445412635803
30-01-2023 12:23:15 INFO Epoch 2: [8108/10940] ---- BYOL Training Loss = 0.34492605924606323
30-01-2023 12:23:33 INFO Epoch 2: [8119/10940] ---- BYOL Training Loss = 0.36944371461868286
30-01-2023 12:23:52 INFO Epoch 2: [8130/10940] ---- BYOL Training Loss = 0.3792099356651306
30-01-2023 12:24:10 INFO Epoch 2: [8141/10940] ---- BYOL Training Loss = 0.32297995686531067
30-01-2023 12:25:02 INFO Epoch 2: [8141/10940] ---- BYOL Validation Loss = 0.30546966195106506
30-01-2023 12:25:20 INFO Epoch 2: [8152/10940] ---- BYOL Training Loss = 0.38945767283439636
30-01-2023 12:25:38 INFO Epoch 2: [8163/10940] ---- BYOL Training Loss = 0.36613839864730835
30-01-2023 12:25:57 INFO Epoch 2: [8174/10940] ---- BYOL Training Loss = 0.3303987383842468
30-01-2023 12:26:15 INFO Epoch 2: [8185/10940] ---- BYOL Training Loss = 0.31394267082214355
30-01-2023 12:27:07 INFO Epoch 2: [8185/10940] ---- BYOL Validation Loss = 0.3072243332862854
30-01-2023 12:27:25 INFO Epoch 2: [8196/10940] ---- BYOL Training Loss = 0.2566123902797699
30-01-2023 12:27:44 INFO Epoch 2: [8207/10940] ---- BYOL Training Loss = 0.27150025963783264
30-01-2023 12:28:02 INFO Epoch 2: [8218/10940] ---- BYOL Training Loss = 0.2857096195220947
30-01-2023 12:28:20 INFO Epoch 2: [8229/10940] ---- BYOL Training Loss = 0.31200331449508667
30-01-2023 12:29:13 INFO Epoch 2: [8229/10940] ---- BYOL Validation Loss = 0.3312600553035736
30-01-2023 12:29:31 INFO Epoch 2: [8240/10940] ---- BYOL Training Loss = 0.2740274667739868
30-01-2023 12:29:49 INFO Epoch 2: [8251/10940] ---- BYOL Training Loss = 0.3191789984703064
30-01-2023 12:30:07 INFO Epoch 2: [8262/10940] ---- BYOL Training Loss = 0.3487442135810852
30-01-2023 12:30:26 INFO Epoch 2: [8273/10940] ---- BYOL Training Loss = 0.3297968804836273
30-01-2023 12:31:18 INFO Epoch 2: [8273/10940] ---- BYOL Validation Loss = 0.3148832321166992
30-01-2023 12:31:36 INFO Epoch 2: [8284/10940] ---- BYOL Training Loss = 0.34456107020378113
30-01-2023 12:31:54 INFO Epoch 2: [8295/10940] ---- BYOL Training Loss = 0.32370367646217346
30-01-2023 12:32:12 INFO Epoch 2: [8306/10940] ---- BYOL Training Loss = 0.3459605574607849
30-01-2023 12:32:31 INFO Epoch 2: [8317/10940] ---- BYOL Training Loss = 0.29237982630729675
30-01-2023 12:33:23 INFO Epoch 2: [8317/10940] ---- BYOL Validation Loss = 0.32677632570266724
30-01-2023 12:33:41 INFO Epoch 2: [8328/10940] ---- BYOL Training Loss = 0.2745450437068939
30-01-2023 12:33:59 INFO Epoch 2: [8339/10940] ---- BYOL Training Loss = 0.33164092898368835
30-01-2023 12:34:17 INFO Epoch 2: [8350/10940] ---- BYOL Training Loss = 0.3602401316165924
30-01-2023 12:34:36 INFO Epoch 2: [8361/10940] ---- BYOL Training Loss = 0.3684818148612976
30-01-2023 12:35:28 INFO Epoch 2: [8361/10940] ---- BYOL Validation Loss = 0.32428354024887085
30-01-2023 12:35:46 INFO Epoch 2: [8372/10940] ---- BYOL Training Loss = 0.41474318504333496
30-01-2023 12:36:04 INFO Epoch 2: [8383/10940] ---- BYOL Training Loss = 0.3801567554473877
30-01-2023 12:36:23 INFO Epoch 2: [8394/10940] ---- BYOL Training Loss = 0.37199899554252625
30-01-2023 12:36:41 INFO Epoch 2: [8405/10940] ---- BYOL Training Loss = 0.3872075080871582
30-01-2023 12:37:33 INFO Epoch 2: [8405/10940] ---- BYOL Validation Loss = 0.3220481872558594
30-01-2023 12:37:51 INFO Epoch 2: [8416/10940] ---- BYOL Training Loss = 0.38664162158966064
30-01-2023 12:38:09 INFO Epoch 2: [8427/10940] ---- BYOL Training Loss = 0.37301182746887207
30-01-2023 12:38:28 INFO Epoch 2: [8438/10940] ---- BYOL Training Loss = 0.3266553282737732
30-01-2023 12:38:46 INFO Epoch 2: [8449/10940] ---- BYOL Training Loss = 0.3074689507484436
30-01-2023 12:39:38 INFO Epoch 2: [8449/10940] ---- BYOL Validation Loss = 0.3060579299926758
30-01-2023 12:39:56 INFO Epoch 2: [8460/10940] ---- BYOL Training Loss = 0.3046301007270813
30-01-2023 12:40:15 INFO Epoch 2: [8471/10940] ---- BYOL Training Loss = 0.2851818799972534
30-01-2023 12:40:33 INFO Epoch 2: [8482/10940] ---- BYOL Training Loss = 0.3137323260307312
30-01-2023 12:40:52 INFO Epoch 2: [8493/10940] ---- BYOL Training Loss = 0.40503907203674316
30-01-2023 12:41:44 INFO Epoch 2: [8493/10940] ---- BYOL Validation Loss = 0.5566554665565491
30-01-2023 12:42:02 INFO Epoch 2: [8504/10940] ---- BYOL Training Loss = 0.3068310618400574
30-01-2023 12:42:21 INFO Epoch 2: [8515/10940] ---- BYOL Training Loss = 0.2958638668060303
30-01-2023 12:42:39 INFO Epoch 2: [8526/10940] ---- BYOL Training Loss = 0.32204604148864746
30-01-2023 12:42:58 INFO Epoch 2: [8537/10940] ---- BYOL Training Loss = 0.2738563120365143
30-01-2023 12:43:49 INFO Epoch 2: [8537/10940] ---- BYOL Validation Loss = 0.317182719707489
30-01-2023 12:44:07 INFO Epoch 2: [8548/10940] ---- BYOL Training Loss = 0.30913445353507996
30-01-2023 12:44:26 INFO Epoch 2: [8559/10940] ---- BYOL Training Loss = 0.3453370928764343
30-01-2023 12:44:44 INFO Epoch 2: [8570/10940] ---- BYOL Training Loss = 0.3031410574913025
30-01-2023 12:45:02 INFO Epoch 2: [8581/10940] ---- BYOL Training Loss = 0.3114900290966034
30-01-2023 12:45:54 INFO Epoch 2: [8581/10940] ---- BYOL Validation Loss = 0.32406923174858093
30-01-2023 12:46:12 INFO Epoch 2: [8592/10940] ---- BYOL Training Loss = 0.35082486271858215
30-01-2023 12:46:31 INFO Epoch 2: [8603/10940] ---- BYOL Training Loss = 0.31908994913101196
30-01-2023 12:46:49 INFO Epoch 2: [8614/10940] ---- BYOL Training Loss = 0.2896648347377777
30-01-2023 12:47:08 INFO Epoch 2: [8625/10940] ---- BYOL Training Loss = 0.35898900032043457
30-01-2023 12:48:00 INFO Epoch 2: [8625/10940] ---- BYOL Validation Loss = 0.3334888517856598
30-01-2023 12:48:18 INFO Epoch 2: [8636/10940] ---- BYOL Training Loss = 0.34682798385620117
30-01-2023 12:48:36 INFO Epoch 2: [8647/10940] ---- BYOL Training Loss = 0.35524511337280273
30-01-2023 12:48:55 INFO Epoch 2: [8658/10940] ---- BYOL Training Loss = 0.3217700123786926
30-01-2023 12:49:13 INFO Epoch 2: [8669/10940] ---- BYOL Training Loss = 0.31890058517456055
30-01-2023 12:50:05 INFO Epoch 2: [8669/10940] ---- BYOL Validation Loss = 0.32144245505332947
30-01-2023 12:50:23 INFO Epoch 2: [8680/10940] ---- BYOL Training Loss = 0.383876234292984
30-01-2023 12:50:42 INFO Epoch 2: [8691/10940] ---- BYOL Training Loss = 0.3207263946533203
30-01-2023 12:51:00 INFO Epoch 2: [8702/10940] ---- BYOL Training Loss = 0.297250360250473
30-01-2023 12:51:19 INFO Epoch 2: [8713/10940] ---- BYOL Training Loss = 0.3295948803424835
30-01-2023 12:52:11 INFO Epoch 2: [8713/10940] ---- BYOL Validation Loss = 0.3323834538459778
30-01-2023 12:52:28 INFO Epoch 2: [8724/10940] ---- BYOL Training Loss = 0.3209763169288635
30-01-2023 12:52:47 INFO Epoch 2: [8735/10940] ---- BYOL Training Loss = 0.30792349576950073
30-01-2023 12:53:05 INFO Epoch 2: [8746/10940] ---- BYOL Training Loss = 0.32044902443885803
30-01-2023 12:53:24 INFO Epoch 2: [8757/10940] ---- BYOL Training Loss = 0.285160630941391
30-01-2023 12:54:16 INFO Epoch 2: [8757/10940] ---- BYOL Validation Loss = 0.3186678886413574
30-01-2023 12:54:34 INFO Epoch 2: [8768/10940] ---- BYOL Training Loss = 0.24427711963653564
30-01-2023 12:54:52 INFO Epoch 2: [8779/10940] ---- BYOL Training Loss = 0.29603511095046997
30-01-2023 12:55:11 INFO Epoch 2: [8790/10940] ---- BYOL Training Loss = 0.30998504161834717
30-01-2023 12:55:29 INFO Epoch 2: [8801/10940] ---- BYOL Training Loss = 0.32852768898010254
30-01-2023 12:56:21 INFO Epoch 2: [8801/10940] ---- BYOL Validation Loss = 0.33123379945755005
30-01-2023 12:56:39 INFO Epoch 2: [8812/10940] ---- BYOL Training Loss = 0.34179791808128357
30-01-2023 12:56:58 INFO Epoch 2: [8823/10940] ---- BYOL Training Loss = 0.3220551013946533
30-01-2023 12:57:16 INFO Epoch 2: [8834/10940] ---- BYOL Training Loss = 0.338107705116272
30-01-2023 12:57:35 INFO Epoch 2: [8845/10940] ---- BYOL Training Loss = 0.3100028932094574
30-01-2023 12:58:26 INFO Epoch 2: [8845/10940] ---- BYOL Validation Loss = 0.3320215046405792
30-01-2023 12:58:44 INFO Epoch 2: [8856/10940] ---- BYOL Training Loss = 0.35609227418899536
30-01-2023 12:59:03 INFO Epoch 2: [8867/10940] ---- BYOL Training Loss = 0.38678881525993347
30-01-2023 12:59:21 INFO Epoch 2: [8878/10940] ---- BYOL Training Loss = 0.34709444642066956
30-01-2023 12:59:40 INFO Epoch 2: [8889/10940] ---- BYOL Training Loss = 0.4175681173801422
30-01-2023 13:00:33 INFO Epoch 2: [8889/10940] ---- BYOL Validation Loss = 0.3351925015449524
30-01-2023 13:00:50 INFO Epoch 2: [8900/10940] ---- BYOL Training Loss = 0.38402169942855835
30-01-2023 13:01:09 INFO Epoch 2: [8911/10940] ---- BYOL Training Loss = 0.32485026121139526
30-01-2023 13:01:27 INFO Epoch 2: [8922/10940] ---- BYOL Training Loss = 0.33104124665260315
30-01-2023 13:01:46 INFO Epoch 2: [8933/10940] ---- BYOL Training Loss = 0.34943026304244995
30-01-2023 13:02:38 INFO Epoch 2: [8933/10940] ---- BYOL Validation Loss = 0.3268532156944275
30-01-2023 13:02:56 INFO Epoch 2: [8944/10940] ---- BYOL Training Loss = 0.3863388001918793
30-01-2023 13:03:14 INFO Epoch 2: [8955/10940] ---- BYOL Training Loss = 0.35244444012641907
30-01-2023 13:03:33 INFO Epoch 2: [8966/10940] ---- BYOL Training Loss = 0.3272365927696228
30-01-2023 13:03:51 INFO Epoch 2: [8977/10940] ---- BYOL Training Loss = 0.31183159351348877
30-01-2023 13:04:43 INFO Epoch 2: [8977/10940] ---- BYOL Validation Loss = 0.33070626854896545
30-01-2023 13:05:01 INFO Epoch 2: [8988/10940] ---- BYOL Training Loss = 0.28975340723991394
30-01-2023 13:05:20 INFO Epoch 2: [8999/10940] ---- BYOL Training Loss = 0.27137863636016846
30-01-2023 13:05:38 INFO Epoch 2: [9010/10940] ---- BYOL Training Loss = 0.3297610878944397
30-01-2023 13:05:57 INFO Epoch 2: [9021/10940] ---- BYOL Training Loss = 0.3930602967739105
30-01-2023 13:06:49 INFO Epoch 2: [9021/10940] ---- BYOL Validation Loss = 0.3297875225543976
30-01-2023 13:07:07 INFO Epoch 2: [9032/10940] ---- BYOL Training Loss = 0.34580954909324646
30-01-2023 13:07:25 INFO Epoch 2: [9043/10940] ---- BYOL Training Loss = 0.37063318490982056
30-01-2023 13:07:44 INFO Epoch 2: [9054/10940] ---- BYOL Training Loss = 0.3808117210865021
30-01-2023 13:08:02 INFO Epoch 2: [9065/10940] ---- BYOL Training Loss = 0.3526126742362976
30-01-2023 13:08:54 INFO Epoch 2: [9065/10940] ---- BYOL Validation Loss = 0.3340635895729065
30-01-2023 13:09:12 INFO Epoch 2: [9076/10940] ---- BYOL Training Loss = 0.3561754524707794
30-01-2023 13:09:31 INFO Epoch 2: [9087/10940] ---- BYOL Training Loss = 0.360763818025589
30-01-2023 13:09:49 INFO Epoch 2: [9098/10940] ---- BYOL Training Loss = 0.37243813276290894
30-01-2023 13:10:08 INFO Epoch 2: [9109/10940] ---- BYOL Training Loss = 0.3177306354045868
30-01-2023 13:11:00 INFO Epoch 2: [9109/10940] ---- BYOL Validation Loss = 0.32839521765708923
30-01-2023 13:11:18 INFO Epoch 2: [9120/10940] ---- BYOL Training Loss = 0.34355345368385315
30-01-2023 13:11:36 INFO Epoch 2: [9131/10940] ---- BYOL Training Loss = 0.35026460886001587
30-01-2023 13:11:55 INFO Epoch 2: [9142/10940] ---- BYOL Training Loss = 0.3400157392024994
30-01-2023 13:12:13 INFO Epoch 2: [9153/10940] ---- BYOL Training Loss = 0.32400357723236084
30-01-2023 13:13:05 INFO Epoch 2: [9153/10940] ---- BYOL Validation Loss = 0.3313067555427551
30-01-2023 13:13:23 INFO Epoch 2: [9164/10940] ---- BYOL Training Loss = 0.38245445489883423
30-01-2023 13:13:41 INFO Epoch 2: [9175/10940] ---- BYOL Training Loss = 0.37671250104904175
30-01-2023 13:14:00 INFO Epoch 2: [9186/10940] ---- BYOL Training Loss = 0.3423435091972351
30-01-2023 13:14:19 INFO Epoch 2: [9197/10940] ---- BYOL Training Loss = 0.3246571123600006
30-01-2023 13:15:11 INFO Epoch 2: [9197/10940] ---- BYOL Validation Loss = 0.31973281502723694
30-01-2023 13:15:29 INFO Epoch 2: [9208/10940] ---- BYOL Training Loss = 0.32318973541259766
30-01-2023 13:15:47 INFO Epoch 2: [9219/10940] ---- BYOL Training Loss = 0.31402716040611267
30-01-2023 13:16:06 INFO Epoch 2: [9230/10940] ---- BYOL Training Loss = 0.3635062873363495
30-01-2023 13:16:24 INFO Epoch 2: [9241/10940] ---- BYOL Training Loss = 0.34744954109191895
30-01-2023 13:17:16 INFO Epoch 2: [9241/10940] ---- BYOL Validation Loss = 0.3335075378417969
30-01-2023 13:17:34 INFO Epoch 2: [9252/10940] ---- BYOL Training Loss = 0.2977214455604553
30-01-2023 13:17:53 INFO Epoch 2: [9263/10940] ---- BYOL Training Loss = 0.32769039273262024
30-01-2023 13:18:11 INFO Epoch 2: [9274/10940] ---- BYOL Training Loss = 0.3585209250450134
30-01-2023 13:18:30 INFO Epoch 2: [9285/10940] ---- BYOL Training Loss = 0.33500418066978455
30-01-2023 13:19:22 INFO Epoch 2: [9285/10940] ---- BYOL Validation Loss = 0.3161485493183136
30-01-2023 13:19:40 INFO Epoch 2: [9296/10940] ---- BYOL Training Loss = 0.3327287435531616
30-01-2023 13:19:58 INFO Epoch 2: [9307/10940] ---- BYOL Training Loss = 0.38433948159217834
30-01-2023 13:20:17 INFO Epoch 2: [9318/10940] ---- BYOL Training Loss = 0.3197077214717865
30-01-2023 13:20:35 INFO Epoch 2: [9329/10940] ---- BYOL Training Loss = 0.32023462653160095
30-01-2023 13:21:27 INFO Epoch 2: [9329/10940] ---- BYOL Validation Loss = 0.33188125491142273
30-01-2023 13:21:46 INFO Epoch 2: [9340/10940] ---- BYOL Training Loss = 0.3277476727962494
30-01-2023 13:22:04 INFO Epoch 2: [9351/10940] ---- BYOL Training Loss = 0.3317614793777466
30-01-2023 13:22:22 INFO Epoch 2: [9362/10940] ---- BYOL Training Loss = 0.37415820360183716
30-01-2023 13:22:41 INFO Epoch 2: [9373/10940] ---- BYOL Training Loss = 0.3540450930595398
30-01-2023 13:23:33 INFO Epoch 2: [9373/10940] ---- BYOL Validation Loss = 0.3223985731601715
30-01-2023 13:23:51 INFO Epoch 2: [9384/10940] ---- BYOL Training Loss = 0.3301343619823456
30-01-2023 13:24:10 INFO Epoch 2: [9395/10940] ---- BYOL Training Loss = 0.31314271688461304
30-01-2023 13:24:28 INFO Epoch 2: [9406/10940] ---- BYOL Training Loss = 0.3058411180973053
30-01-2023 13:24:46 INFO Epoch 2: [9417/10940] ---- BYOL Training Loss = 0.34738263487815857
30-01-2023 13:25:38 INFO Epoch 2: [9417/10940] ---- BYOL Validation Loss = 0.34138885140419006
30-01-2023 13:25:57 INFO Epoch 2: [9428/10940] ---- BYOL Training Loss = 0.45666375756263733
30-01-2023 13:26:15 INFO Epoch 2: [9439/10940] ---- BYOL Training Loss = 0.41375431418418884
30-01-2023 13:26:34 INFO Epoch 2: [9450/10940] ---- BYOL Training Loss = 0.36037713289260864
30-01-2023 13:26:52 INFO Epoch 2: [9461/10940] ---- BYOL Training Loss = 0.3279074728488922
30-01-2023 13:27:44 INFO Epoch 2: [9461/10940] ---- BYOL Validation Loss = 0.3248976171016693
30-01-2023 13:28:02 INFO Epoch 2: [9472/10940] ---- BYOL Training Loss = 0.30421334505081177
30-01-2023 13:28:21 INFO Epoch 2: [9483/10940] ---- BYOL Training Loss = 0.35262730717658997
30-01-2023 13:28:39 INFO Epoch 2: [9494/10940] ---- BYOL Training Loss = 0.35932210087776184
30-01-2023 13:28:58 INFO Epoch 2: [9505/10940] ---- BYOL Training Loss = 0.31474941968917847
30-01-2023 13:29:50 INFO Epoch 2: [9505/10940] ---- BYOL Validation Loss = 0.323896199464798
30-01-2023 13:30:08 INFO Epoch 2: [9516/10940] ---- BYOL Training Loss = 0.31387200951576233
30-01-2023 13:30:26 INFO Epoch 2: [9527/10940] ---- BYOL Training Loss = 0.29967358708381653
30-01-2023 13:30:45 INFO Epoch 2: [9538/10940] ---- BYOL Training Loss = 0.28546732664108276
30-01-2023 13:31:03 INFO Epoch 2: [9549/10940] ---- BYOL Training Loss = 0.30573904514312744
30-01-2023 13:31:55 INFO Epoch 2: [9549/10940] ---- BYOL Validation Loss = 0.33679717779159546
30-01-2023 13:32:14 INFO Epoch 2: [9560/10940] ---- BYOL Training Loss = 0.3491893708705902
30-01-2023 13:32:32 INFO Epoch 2: [9571/10940] ---- BYOL Training Loss = 0.35544511675834656
30-01-2023 13:32:51 INFO Epoch 2: [9582/10940] ---- BYOL Training Loss = 0.3342045843601227
30-01-2023 13:33:09 INFO Epoch 2: [9593/10940] ---- BYOL Training Loss = 0.3731614947319031
30-01-2023 13:34:01 INFO Epoch 2: [9593/10940] ---- BYOL Validation Loss = 0.33678027987480164
30-01-2023 13:34:19 INFO Epoch 2: [9604/10940] ---- BYOL Training Loss = 0.3570766746997833
30-01-2023 13:34:38 INFO Epoch 2: [9615/10940] ---- BYOL Training Loss = 0.35156694054603577
30-01-2023 13:34:57 INFO Epoch 2: [9626/10940] ---- BYOL Training Loss = 0.34800177812576294
30-01-2023 13:35:15 INFO Epoch 2: [9637/10940] ---- BYOL Training Loss = 0.3997921049594879
30-01-2023 13:36:07 INFO Epoch 2: [9637/10940] ---- BYOL Validation Loss = 0.3356669247150421
30-01-2023 13:36:25 INFO Epoch 2: [9648/10940] ---- BYOL Training Loss = 0.3846195340156555
30-01-2023 13:36:44 INFO Epoch 2: [9659/10940] ---- BYOL Training Loss = 0.3858880400657654
30-01-2023 13:37:02 INFO Epoch 2: [9670/10940] ---- BYOL Training Loss = 0.34359413385391235
30-01-2023 13:37:21 INFO Epoch 2: [9681/10940] ---- BYOL Training Loss = 0.3425365686416626
30-01-2023 13:38:13 INFO Epoch 2: [9681/10940] ---- BYOL Validation Loss = 0.3305438160896301
30-01-2023 13:38:31 INFO Epoch 2: [9692/10940] ---- BYOL Training Loss = 0.2944461703300476
30-01-2023 13:38:49 INFO Epoch 2: [9703/10940] ---- BYOL Training Loss = 0.2896999716758728
30-01-2023 13:39:08 INFO Epoch 2: [9714/10940] ---- BYOL Training Loss = 0.36602750420570374
30-01-2023 13:39:27 INFO Epoch 2: [9725/10940] ---- BYOL Training Loss = 0.36529114842414856
30-01-2023 13:40:19 INFO Epoch 2: [9725/10940] ---- BYOL Validation Loss = 0.33022767305374146
30-01-2023 13:40:37 INFO Epoch 2: [9736/10940] ---- BYOL Training Loss = 0.308596670627594
30-01-2023 13:40:55 INFO Epoch 2: [9747/10940] ---- BYOL Training Loss = 0.3014339506626129
30-01-2023 13:41:14 INFO Epoch 2: [9758/10940] ---- BYOL Training Loss = 0.30030155181884766
30-01-2023 13:41:32 INFO Epoch 2: [9769/10940] ---- BYOL Training Loss = 0.2832857370376587
30-01-2023 13:42:24 INFO Epoch 2: [9769/10940] ---- BYOL Validation Loss = 0.3405286967754364
30-01-2023 13:42:42 INFO Epoch 2: [9780/10940] ---- BYOL Training Loss = 0.3175317645072937
30-01-2023 13:43:01 INFO Epoch 2: [9791/10940] ---- BYOL Training Loss = 0.3119545578956604
30-01-2023 13:43:20 INFO Epoch 2: [9802/10940] ---- BYOL Training Loss = 0.35273492336273193
30-01-2023 13:43:38 INFO Epoch 2: [9813/10940] ---- BYOL Training Loss = 0.3388552963733673
30-01-2023 13:44:30 INFO Epoch 2: [9813/10940] ---- BYOL Validation Loss = 0.3431189954280853
30-01-2023 13:44:48 INFO Epoch 2: [9824/10940] ---- BYOL Training Loss = 0.35261204838752747
30-01-2023 13:45:07 INFO Epoch 2: [9835/10940] ---- BYOL Training Loss = 0.34715548157691956
30-01-2023 13:45:25 INFO Epoch 2: [9846/10940] ---- BYOL Training Loss = 0.3541905879974365
30-01-2023 13:45:44 INFO Epoch 2: [9857/10940] ---- BYOL Training Loss = 0.36595505475997925
30-01-2023 13:46:36 INFO Epoch 2: [9857/10940] ---- BYOL Validation Loss = 0.33799031376838684
30-01-2023 13:46:54 INFO Epoch 2: [9868/10940] ---- BYOL Training Loss = 0.350342720746994
30-01-2023 13:47:13 INFO Epoch 2: [9879/10940] ---- BYOL Training Loss = 0.34719687700271606
30-01-2023 13:47:31 INFO Epoch 2: [9890/10940] ---- BYOL Training Loss = 0.30749624967575073
30-01-2023 13:47:50 INFO Epoch 2: [9901/10940] ---- BYOL Training Loss = 0.32184046506881714
30-01-2023 13:48:42 INFO Epoch 2: [9901/10940] ---- BYOL Validation Loss = 0.32966476678848267
30-01-2023 13:49:00 INFO Epoch 2: [9912/10940] ---- BYOL Training Loss = 0.4150053858757019
30-01-2023 13:49:19 INFO Epoch 2: [9923/10940] ---- BYOL Training Loss = 0.4074400067329407
30-01-2023 13:49:37 INFO Epoch 2: [9934/10940] ---- BYOL Training Loss = 0.3581448197364807
30-01-2023 13:49:56 INFO Epoch 2: [9945/10940] ---- BYOL Training Loss = 0.3736738860607147
30-01-2023 13:50:48 INFO Epoch 2: [9945/10940] ---- BYOL Validation Loss = 0.33891814947128296
30-01-2023 13:51:06 INFO Epoch 2: [9956/10940] ---- BYOL Training Loss = 0.4019569456577301
30-01-2023 13:51:24 INFO Epoch 2: [9967/10940] ---- BYOL Training Loss = 0.37090715765953064
30-01-2023 13:51:43 INFO Epoch 2: [9978/10940] ---- BYOL Training Loss = 0.2951849699020386
30-01-2023 13:52:02 INFO Epoch 2: [9989/10940] ---- BYOL Training Loss = 0.2884213924407959
30-01-2023 13:52:54 INFO Epoch 2: [9989/10940] ---- BYOL Validation Loss = 0.3349494934082031
30-01-2023 13:53:12 INFO Epoch 2: [10000/10940] ---- BYOL Training Loss = 0.344420850276947
30-01-2023 13:53:31 INFO Epoch 2: [10011/10940] ---- BYOL Training Loss = 0.37243568897247314
30-01-2023 13:53:49 INFO Epoch 2: [10022/10940] ---- BYOL Training Loss = 0.3730774521827698
30-01-2023 13:54:08 INFO Epoch 2: [10033/10940] ---- BYOL Training Loss = 0.3549507260322571
30-01-2023 13:55:00 INFO Epoch 2: [10033/10940] ---- BYOL Validation Loss = 0.33985933661460876
30-01-2023 13:55:18 INFO Epoch 2: [10044/10940] ---- BYOL Training Loss = 0.4574217200279236
30-01-2023 13:55:37 INFO Epoch 2: [10055/10940] ---- BYOL Training Loss = 0.4366498589515686
30-01-2023 13:55:55 INFO Epoch 2: [10066/10940] ---- BYOL Training Loss = 0.3469591438770294
30-01-2023 13:56:14 INFO Epoch 2: [10077/10940] ---- BYOL Training Loss = 0.33053499460220337
30-01-2023 13:57:06 INFO Epoch 2: [10077/10940] ---- BYOL Validation Loss = 0.34246954321861267
30-01-2023 13:57:24 INFO Epoch 2: [10088/10940] ---- BYOL Training Loss = 0.3735683262348175
30-01-2023 13:57:43 INFO Epoch 2: [10099/10940] ---- BYOL Training Loss = 0.4093066155910492
30-01-2023 13:58:01 INFO Epoch 2: [10110/10940] ---- BYOL Training Loss = 0.37203454971313477
30-01-2023 13:58:20 INFO Epoch 2: [10121/10940] ---- BYOL Training Loss = 0.30253836512565613
30-01-2023 13:59:12 INFO Epoch 2: [10121/10940] ---- BYOL Validation Loss = 0.3290192782878876
30-01-2023 13:59:30 INFO Epoch 2: [10132/10940] ---- BYOL Training Loss = 0.34501296281814575
30-01-2023 13:59:48 INFO Epoch 2: [10143/10940] ---- BYOL Training Loss = 0.3401457667350769
30-01-2023 14:00:07 INFO Epoch 2: [10154/10940] ---- BYOL Training Loss = 0.32181569933891296
30-01-2023 14:00:25 INFO Epoch 2: [10165/10940] ---- BYOL Training Loss = 0.3502846360206604
30-01-2023 14:01:18 INFO Epoch 2: [10165/10940] ---- BYOL Validation Loss = 0.32686468958854675
30-01-2023 14:01:36 INFO Epoch 2: [10176/10940] ---- BYOL Training Loss = 0.39162084460258484
30-01-2023 14:01:55 INFO Epoch 2: [10187/10940] ---- BYOL Training Loss = 0.3495754599571228
30-01-2023 14:02:13 INFO Epoch 2: [10198/10940] ---- BYOL Training Loss = 0.28454476594924927
30-01-2023 14:02:32 INFO Epoch 2: [10209/10940] ---- BYOL Training Loss = 0.2717805504798889
30-01-2023 14:03:24 INFO Epoch 2: [10209/10940] ---- BYOL Validation Loss = 0.33941665291786194
30-01-2023 14:03:42 INFO Epoch 2: [10220/10940] ---- BYOL Training Loss = 0.3161119818687439
30-01-2023 14:04:00 INFO Epoch 2: [10231/10940] ---- BYOL Training Loss = 0.37961143255233765
30-01-2023 14:04:19 INFO Epoch 2: [10242/10940] ---- BYOL Training Loss = 0.37835463881492615
30-01-2023 14:04:38 INFO Epoch 2: [10253/10940] ---- BYOL Training Loss = 0.39732587337493896
30-01-2023 14:05:30 INFO Epoch 2: [10253/10940] ---- BYOL Validation Loss = 0.3283279240131378
30-01-2023 14:05:48 INFO Epoch 2: [10264/10940] ---- BYOL Training Loss = 0.3876170217990875
30-01-2023 14:06:07 INFO Epoch 2: [10275/10940] ---- BYOL Training Loss = 0.36775630712509155
30-01-2023 14:06:25 INFO Epoch 2: [10286/10940] ---- BYOL Training Loss = 0.3356330990791321
30-01-2023 14:06:44 INFO Epoch 2: [10297/10940] ---- BYOL Training Loss = 0.29723745584487915
30-01-2023 14:07:36 INFO Epoch 2: [10297/10940] ---- BYOL Validation Loss = 0.32902151346206665
30-01-2023 14:07:54 INFO Epoch 2: [10308/10940] ---- BYOL Training Loss = 0.35008370876312256
30-01-2023 14:08:12 INFO Epoch 2: [10319/10940] ---- BYOL Training Loss = 0.362810879945755
30-01-2023 14:08:31 INFO Epoch 2: [10330/10940] ---- BYOL Training Loss = 0.3587673008441925
30-01-2023 14:08:50 INFO Epoch 2: [10341/10940] ---- BYOL Training Loss = 0.3855442404747009
30-01-2023 14:09:42 INFO Epoch 2: [10341/10940] ---- BYOL Validation Loss = 0.3292054235935211
30-01-2023 14:10:00 INFO Epoch 2: [10352/10940] ---- BYOL Training Loss = 0.3071257770061493
30-01-2023 14:10:18 INFO Epoch 2: [10363/10940] ---- BYOL Training Loss = 0.3089776635169983
30-01-2023 14:10:37 INFO Epoch 2: [10374/10940] ---- BYOL Training Loss = 0.3967530131340027
30-01-2023 14:10:56 INFO Epoch 2: [10385/10940] ---- BYOL Training Loss = 0.34438082575798035
30-01-2023 14:11:48 INFO Epoch 2: [10385/10940] ---- BYOL Validation Loss = 0.34400439262390137
30-01-2023 14:12:06 INFO Epoch 2: [10396/10940] ---- BYOL Training Loss = 0.28676632046699524
30-01-2023 14:12:25 INFO Epoch 2: [10407/10940] ---- BYOL Training Loss = 0.3449082374572754
30-01-2023 14:12:43 INFO Epoch 2: [10418/10940] ---- BYOL Training Loss = 0.37783485651016235
30-01-2023 14:13:02 INFO Epoch 2: [10429/10940] ---- BYOL Training Loss = 0.330575168132782
30-01-2023 14:13:54 INFO Epoch 2: [10429/10940] ---- BYOL Validation Loss = 0.33341169357299805
30-01-2023 14:14:12 INFO Epoch 2: [10440/10940] ---- BYOL Training Loss = 0.29933419823646545
30-01-2023 14:14:31 INFO Epoch 2: [10451/10940] ---- BYOL Training Loss = 0.3379485011100769
30-01-2023 14:14:49 INFO Epoch 2: [10462/10940] ---- BYOL Training Loss = 0.36346545815467834
30-01-2023 14:15:08 INFO Epoch 2: [10473/10940] ---- BYOL Training Loss = 0.2963450849056244
30-01-2023 14:16:00 INFO Epoch 2: [10473/10940] ---- BYOL Validation Loss = 0.3362368047237396
30-01-2023 14:16:18 INFO Epoch 2: [10484/10940] ---- BYOL Training Loss = 0.34557703137397766
30-01-2023 14:16:37 INFO Epoch 2: [10495/10940] ---- BYOL Training Loss = 0.37894299626350403
30-01-2023 14:16:56 INFO Epoch 2: [10506/10940] ---- BYOL Training Loss = 0.37806111574172974
30-01-2023 14:17:14 INFO Epoch 2: [10517/10940] ---- BYOL Training Loss = 0.3548438251018524
30-01-2023 14:18:06 INFO Epoch 2: [10517/10940] ---- BYOL Validation Loss = 0.32758277654647827
30-01-2023 14:18:25 INFO Epoch 2: [10528/10940] ---- BYOL Training Loss = 0.3885117173194885
30-01-2023 14:18:43 INFO Epoch 2: [10539/10940] ---- BYOL Training Loss = 0.4183286130428314
30-01-2023 14:19:02 INFO Epoch 2: [10550/10940] ---- BYOL Training Loss = 0.35245847702026367
30-01-2023 14:19:20 INFO Epoch 2: [10561/10940] ---- BYOL Training Loss = 0.2906726896762848
30-01-2023 14:20:13 INFO Epoch 2: [10561/10940] ---- BYOL Validation Loss = 0.3350926339626312
30-01-2023 14:20:31 INFO Epoch 2: [10572/10940] ---- BYOL Training Loss = 0.33111679553985596
30-01-2023 14:20:49 INFO Epoch 2: [10583/10940] ---- BYOL Training Loss = 0.3612828254699707
30-01-2023 14:21:08 INFO Epoch 2: [10594/10940] ---- BYOL Training Loss = 0.3768916726112366
30-01-2023 14:21:26 INFO Epoch 2: [10605/10940] ---- BYOL Training Loss = 0.3795161843299866
30-01-2023 14:22:18 INFO Epoch 2: [10605/10940] ---- BYOL Validation Loss = 0.33944350481033325
30-01-2023 14:22:37 INFO Epoch 2: [10616/10940] ---- BYOL Training Loss = 0.3162730634212494
30-01-2023 14:22:55 INFO Epoch 2: [10627/10940] ---- BYOL Training Loss = 0.339193731546402
30-01-2023 14:23:14 INFO Epoch 2: [10638/10940] ---- BYOL Training Loss = 0.3259187936782837
30-01-2023 14:23:33 INFO Epoch 2: [10649/10940] ---- BYOL Training Loss = 0.33467715978622437
30-01-2023 14:24:25 INFO Epoch 2: [10649/10940] ---- BYOL Validation Loss = 0.31488528847694397
30-01-2023 14:24:43 INFO Epoch 2: [10660/10940] ---- BYOL Training Loss = 0.3582035303115845
30-01-2023 14:25:01 INFO Epoch 2: [10671/10940] ---- BYOL Training Loss = 0.3105560839176178
30-01-2023 14:25:20 INFO Epoch 2: [10682/10940] ---- BYOL Training Loss = 0.3324529826641083
30-01-2023 14:25:39 INFO Epoch 2: [10693/10940] ---- BYOL Training Loss = 0.33247607946395874
30-01-2023 14:26:31 INFO Epoch 2: [10693/10940] ---- BYOL Validation Loss = 0.32830461859703064
30-01-2023 14:26:49 INFO Epoch 2: [10704/10940] ---- BYOL Training Loss = 0.3155238926410675
30-01-2023 14:27:07 INFO Epoch 2: [10715/10940] ---- BYOL Training Loss = 0.34931880235671997
30-01-2023 14:27:26 INFO Epoch 2: [10726/10940] ---- BYOL Training Loss = 0.3623548150062561
30-01-2023 14:27:44 INFO Epoch 2: [10737/10940] ---- BYOL Training Loss = 0.42285624146461487
30-01-2023 14:28:36 INFO Epoch 2: [10737/10940] ---- BYOL Validation Loss = 0.36338165402412415
30-01-2023 14:28:55 INFO Epoch 2: [10748/10940] ---- BYOL Training Loss = 0.3799823820590973
30-01-2023 14:29:13 INFO Epoch 2: [10759/10940] ---- BYOL Training Loss = 0.3049152195453644
30-01-2023 14:29:32 INFO Epoch 2: [10770/10940] ---- BYOL Training Loss = 0.30720821022987366
30-01-2023 14:29:51 INFO Epoch 2: [10781/10940] ---- BYOL Training Loss = 0.3555981516838074
30-01-2023 14:30:43 INFO Epoch 2: [10781/10940] ---- BYOL Validation Loss = 0.33902329206466675
30-01-2023 14:31:01 INFO Epoch 2: [10792/10940] ---- BYOL Training Loss = 0.3320987820625305
30-01-2023 14:31:20 INFO Epoch 2: [10803/10940] ---- BYOL Training Loss = 0.3364000916481018
30-01-2023 14:31:38 INFO Epoch 2: [10814/10940] ---- BYOL Training Loss = 0.3791247606277466
30-01-2023 14:31:57 INFO Epoch 2: [10825/10940] ---- BYOL Training Loss = 0.3613778054714203
30-01-2023 14:32:49 INFO Epoch 2: [10825/10940] ---- BYOL Validation Loss = 0.3245117962360382
30-01-2023 14:33:07 INFO Epoch 2: [10836/10940] ---- BYOL Training Loss = 0.37527185678482056
30-01-2023 14:33:26 INFO Epoch 2: [10847/10940] ---- BYOL Training Loss = 0.4021407961845398
30-01-2023 14:33:45 INFO Epoch 2: [10858/10940] ---- BYOL Training Loss = 0.3779164254665375
30-01-2023 14:34:03 INFO Epoch 2: [10869/10940] ---- BYOL Training Loss = 0.3918991684913635
30-01-2023 14:34:55 INFO Epoch 2: [10869/10940] ---- BYOL Validation Loss = 0.31951481103897095
30-01-2023 14:35:13 INFO Epoch 2: [10880/10940] ---- BYOL Training Loss = 0.42346400022506714
30-01-2023 14:35:32 INFO Epoch 2: [10891/10940] ---- BYOL Training Loss = 0.39550796151161194
30-01-2023 14:35:51 INFO Epoch 2: [10902/10940] ---- BYOL Training Loss = 0.32833343744277954
30-01-2023 14:36:10 INFO Epoch 2: [10913/10940] ---- BYOL Training Loss = 0.3476981520652771
30-01-2023 14:37:02 INFO Epoch 2: [10913/10940] ---- BYOL Validation Loss = 0.33004599809646606
30-01-2023 14:37:20 INFO Epoch 2: [10924/10940] ---- BYOL Training Loss = 0.3260278105735779
30-01-2023 14:37:39 INFO Epoch 2: [10935/10940] ---- BYOL Training Loss = 0.3521610200405121
30-01-2023 14:37:48 INFO Starting Epoch: 3
30-01-2023 14:38:06 INFO Epoch 3: [12/10940] ---- BYOL Training Loss = 0.3569529056549072
30-01-2023 14:38:23 INFO Epoch 3: [23/10940] ---- BYOL Training Loss = 0.3701987564563751
30-01-2023 14:38:41 INFO Epoch 3: [34/10940] ---- BYOL Training Loss = 0.3687918782234192
30-01-2023 14:38:58 INFO Epoch 3: [45/10940] ---- BYOL Training Loss = 0.35662662982940674
30-01-2023 14:39:50 INFO Epoch 3: [45/10940] ---- BYOL Validation Loss = 0.33915236592292786
30-01-2023 14:40:07 INFO Epoch 3: [56/10940] ---- BYOL Training Loss = 0.3445626497268677
30-01-2023 14:40:25 INFO Epoch 3: [67/10940] ---- BYOL Training Loss = 0.4029921591281891
30-01-2023 14:40:42 INFO Epoch 3: [78/10940] ---- BYOL Training Loss = 0.36610862612724304
30-01-2023 14:41:00 INFO Epoch 3: [89/10940] ---- BYOL Training Loss = 0.3373323976993561
30-01-2023 14:41:52 INFO Epoch 3: [89/10940] ---- BYOL Validation Loss = 0.3383673131465912
30-01-2023 14:42:09 INFO Epoch 3: [100/10940] ---- BYOL Training Loss = 0.39192068576812744
30-01-2023 14:42:27 INFO Epoch 3: [111/10940] ---- BYOL Training Loss = 0.35255736112594604
30-01-2023 14:42:44 INFO Epoch 3: [122/10940] ---- BYOL Training Loss = 0.32749831676483154
30-01-2023 14:43:02 INFO Epoch 3: [133/10940] ---- BYOL Training Loss = 0.32311657071113586
30-01-2023 14:43:54 INFO Epoch 3: [133/10940] ---- BYOL Validation Loss = 0.3326026499271393
30-01-2023 14:44:11 INFO Epoch 3: [144/10940] ---- BYOL Training Loss = 0.3724232017993927
30-01-2023 14:44:29 INFO Epoch 3: [155/10940] ---- BYOL Training Loss = 0.32950490713119507
30-01-2023 14:44:46 INFO Epoch 3: [166/10940] ---- BYOL Training Loss = 0.28391891717910767
30-01-2023 14:45:04 INFO Epoch 3: [177/10940] ---- BYOL Training Loss = 0.3275372385978699
30-01-2023 14:45:56 INFO Epoch 3: [177/10940] ---- BYOL Validation Loss = 0.3372354507446289
30-01-2023 14:46:13 INFO Epoch 3: [188/10940] ---- BYOL Training Loss = 0.3025948405265808
30-01-2023 14:46:31 INFO Epoch 3: [199/10940] ---- BYOL Training Loss = 0.37347671389579773
30-01-2023 14:46:48 INFO Epoch 3: [210/10940] ---- BYOL Training Loss = 0.35395652055740356
30-01-2023 14:47:06 INFO Epoch 3: [221/10940] ---- BYOL Training Loss = 0.3297882080078125
30-01-2023 14:47:58 INFO Epoch 3: [221/10940] ---- BYOL Validation Loss = 0.33042973279953003
30-01-2023 14:48:15 INFO Epoch 3: [232/10940] ---- BYOL Training Loss = 0.3416018784046173
30-01-2023 14:48:32 INFO Epoch 3: [243/10940] ---- BYOL Training Loss = 0.2919279932975769
30-01-2023 14:48:50 INFO Epoch 3: [254/10940] ---- BYOL Training Loss = 0.330144464969635
30-01-2023 14:49:07 INFO Epoch 3: [265/10940] ---- BYOL Training Loss = 0.3438505530357361
30-01-2023 14:49:59 INFO Epoch 3: [265/10940] ---- BYOL Validation Loss = 0.3275257647037506
30-01-2023 14:50:17 INFO Epoch 3: [276/10940] ---- BYOL Training Loss = 0.333987295627594
30-01-2023 14:50:34 INFO Epoch 3: [287/10940] ---- BYOL Training Loss = 0.3296504616737366
30-01-2023 14:50:52 INFO Epoch 3: [298/10940] ---- BYOL Training Loss = 0.3101549446582794
30-01-2023 14:51:09 INFO Epoch 3: [309/10940] ---- BYOL Training Loss = 0.3206683099269867
30-01-2023 14:52:01 INFO Epoch 3: [309/10940] ---- BYOL Validation Loss = 0.33224502205848694
30-01-2023 14:52:18 INFO Epoch 3: [320/10940] ---- BYOL Training Loss = 0.33182042837142944
30-01-2023 14:52:36 INFO Epoch 3: [331/10940] ---- BYOL Training Loss = 0.3589029312133789
30-01-2023 14:52:53 INFO Epoch 3: [342/10940] ---- BYOL Training Loss = 0.36241045594215393
30-01-2023 14:53:11 INFO Epoch 3: [353/10940] ---- BYOL Training Loss = 0.40166759490966797
30-01-2023 14:54:03 INFO Epoch 3: [353/10940] ---- BYOL Validation Loss = 0.3284478187561035
30-01-2023 14:54:20 INFO Epoch 3: [364/10940] ---- BYOL Training Loss = 0.39363378286361694
30-01-2023 14:54:38 INFO Epoch 3: [375/10940] ---- BYOL Training Loss = 0.34629005193710327
30-01-2023 14:54:55 INFO Epoch 3: [386/10940] ---- BYOL Training Loss = 0.29840266704559326
30-01-2023 14:55:13 INFO Epoch 3: [397/10940] ---- BYOL Training Loss = 0.3022124767303467
30-01-2023 14:56:05 INFO Epoch 3: [397/10940] ---- BYOL Validation Loss = 0.3249921500682831
30-01-2023 14:56:23 INFO Epoch 3: [408/10940] ---- BYOL Training Loss = 0.31067705154418945
30-01-2023 14:56:40 INFO Epoch 3: [419/10940] ---- BYOL Training Loss = 0.31132856011390686
30-01-2023 14:56:58 INFO Epoch 3: [430/10940] ---- BYOL Training Loss = 0.3271690011024475
30-01-2023 14:57:16 INFO Epoch 3: [441/10940] ---- BYOL Training Loss = 0.3437557816505432
30-01-2023 14:58:08 INFO Epoch 3: [441/10940] ---- BYOL Validation Loss = 0.33996835350990295
30-01-2023 14:58:25 INFO Epoch 3: [452/10940] ---- BYOL Training Loss = 0.3476422429084778
30-01-2023 14:58:42 INFO Epoch 3: [463/10940] ---- BYOL Training Loss = 0.38578906655311584
30-01-2023 14:59:00 INFO Epoch 3: [474/10940] ---- BYOL Training Loss = 0.3749158978462219
30-01-2023 14:59:18 INFO Epoch 3: [485/10940] ---- BYOL Training Loss = 0.36749619245529175
30-01-2023 15:00:10 INFO Epoch 3: [485/10940] ---- BYOL Validation Loss = 0.33342447876930237
30-01-2023 15:00:27 INFO Epoch 3: [496/10940] ---- BYOL Training Loss = 0.3697529137134552
30-01-2023 15:00:44 INFO Epoch 3: [507/10940] ---- BYOL Training Loss = 0.3301301598548889
30-01-2023 15:01:02 INFO Epoch 3: [518/10940] ---- BYOL Training Loss = 0.383094847202301
30-01-2023 15:01:19 INFO Epoch 3: [529/10940] ---- BYOL Training Loss = 0.35441216826438904
30-01-2023 15:02:11 INFO Epoch 3: [529/10940] ---- BYOL Validation Loss = 0.3312458395957947
30-01-2023 15:02:29 INFO Epoch 3: [540/10940] ---- BYOL Training Loss = 0.3188536763191223
30-01-2023 15:02:46 INFO Epoch 3: [551/10940] ---- BYOL Training Loss = 0.3188778758049011
30-01-2023 15:03:04 INFO Epoch 3: [562/10940] ---- BYOL Training Loss = 0.3505241274833679
30-01-2023 15:03:21 INFO Epoch 3: [573/10940] ---- BYOL Training Loss = 0.33773770928382874
30-01-2023 15:04:13 INFO Epoch 3: [573/10940] ---- BYOL Validation Loss = 0.33098429441452026
30-01-2023 15:04:30 INFO Epoch 3: [584/10940] ---- BYOL Training Loss = 0.2984890043735504
30-01-2023 15:04:48 INFO Epoch 3: [595/10940] ---- BYOL Training Loss = 0.30608484148979187
30-01-2023 15:05:05 INFO Epoch 3: [606/10940] ---- BYOL Training Loss = 0.29302337765693665
30-01-2023 15:05:23 INFO Epoch 3: [617/10940] ---- BYOL Training Loss = 0.3402663767337799
30-01-2023 15:06:15 INFO Epoch 3: [617/10940] ---- BYOL Validation Loss = 0.3291875422000885
30-01-2023 15:06:32 INFO Epoch 3: [628/10940] ---- BYOL Training Loss = 0.3301106095314026
30-01-2023 15:06:50 INFO Epoch 3: [639/10940] ---- BYOL Training Loss = 0.2638484537601471
30-01-2023 15:07:07 INFO Epoch 3: [650/10940] ---- BYOL Training Loss = 0.3250691890716553
30-01-2023 15:07:25 INFO Epoch 3: [661/10940] ---- BYOL Training Loss = 0.3668990731239319
30-01-2023 15:08:17 INFO Epoch 3: [661/10940] ---- BYOL Validation Loss = 0.32752323150634766
30-01-2023 15:08:34 INFO Epoch 3: [672/10940] ---- BYOL Training Loss = 0.31565946340560913
30-01-2023 15:08:52 INFO Epoch 3: [683/10940] ---- BYOL Training Loss = 0.30512362718582153
30-01-2023 15:09:09 INFO Epoch 3: [694/10940] ---- BYOL Training Loss = 0.3574095666408539
30-01-2023 15:09:27 INFO Epoch 3: [705/10940] ---- BYOL Training Loss = 0.3269672691822052
30-01-2023 15:10:19 INFO Epoch 3: [705/10940] ---- BYOL Validation Loss = 0.31998246908187866
30-01-2023 15:10:36 INFO Epoch 3: [716/10940] ---- BYOL Training Loss = 0.2910156846046448
30-01-2023 15:10:54 INFO Epoch 3: [727/10940] ---- BYOL Training Loss = 0.32680004835128784
30-01-2023 15:11:11 INFO Epoch 3: [738/10940] ---- BYOL Training Loss = 0.3543104827404022
30-01-2023 15:11:29 INFO Epoch 3: [749/10940] ---- BYOL Training Loss = 0.3352441191673279
30-01-2023 15:12:21 INFO Epoch 3: [749/10940] ---- BYOL Validation Loss = 0.33123329281806946
30-01-2023 15:12:38 INFO Epoch 3: [760/10940] ---- BYOL Training Loss = 0.30416610836982727
30-01-2023 15:12:56 INFO Epoch 3: [771/10940] ---- BYOL Training Loss = 0.31863072514533997
30-01-2023 15:13:13 INFO Epoch 3: [782/10940] ---- BYOL Training Loss = 0.325070858001709
30-01-2023 15:13:31 INFO Epoch 3: [793/10940] ---- BYOL Training Loss = 0.3444128632545471
30-01-2023 15:14:23 INFO Epoch 3: [793/10940] ---- BYOL Validation Loss = 0.3357069790363312
30-01-2023 15:14:40 INFO Epoch 3: [804/10940] ---- BYOL Training Loss = 0.35247737169265747
30-01-2023 15:14:57 INFO Epoch 3: [815/10940] ---- BYOL Training Loss = 0.34779149293899536
30-01-2023 15:15:15 INFO Epoch 3: [826/10940] ---- BYOL Training Loss = 0.34087425470352173
30-01-2023 15:15:33 INFO Epoch 3: [837/10940] ---- BYOL Training Loss = 0.355142742395401
30-01-2023 15:16:25 INFO Epoch 3: [837/10940] ---- BYOL Validation Loss = 0.33120250701904297
30-01-2023 15:16:42 INFO Epoch 3: [848/10940] ---- BYOL Training Loss = 0.34048131108283997
30-01-2023 15:17:00 INFO Epoch 3: [859/10940] ---- BYOL Training Loss = 0.36189544200897217
30-01-2023 15:17:17 INFO Epoch 3: [870/10940] ---- BYOL Training Loss = 0.34701213240623474
30-01-2023 15:17:35 INFO Epoch 3: [881/10940] ---- BYOL Training Loss = 0.3646695613861084
30-01-2023 15:18:27 INFO Epoch 3: [881/10940] ---- BYOL Validation Loss = 0.3436945080757141
30-01-2023 15:18:44 INFO Epoch 3: [892/10940] ---- BYOL Training Loss = 0.4030075967311859
30-01-2023 15:19:02 INFO Epoch 3: [903/10940] ---- BYOL Training Loss = 0.3692709505558014
30-01-2023 15:19:19 INFO Epoch 3: [914/10940] ---- BYOL Training Loss = 0.27364420890808105
30-01-2023 15:19:37 INFO Epoch 3: [925/10940] ---- BYOL Training Loss = 0.32384222745895386
30-01-2023 15:20:29 INFO Epoch 3: [925/10940] ---- BYOL Validation Loss = 0.32689931988716125
30-01-2023 15:20:46 INFO Epoch 3: [936/10940] ---- BYOL Training Loss = 0.31396496295928955
30-01-2023 15:21:04 INFO Epoch 3: [947/10940] ---- BYOL Training Loss = 0.2959121763706207
30-01-2023 15:21:22 INFO Epoch 3: [958/10940] ---- BYOL Training Loss = 0.28311267495155334
30-01-2023 15:21:40 INFO Epoch 3: [969/10940] ---- BYOL Training Loss = 0.3067353367805481
30-01-2023 15:22:32 INFO Epoch 3: [969/10940] ---- BYOL Validation Loss = 0.34226182103157043
30-01-2023 15:22:49 INFO Epoch 3: [980/10940] ---- BYOL Training Loss = 0.3319647014141083
30-01-2023 15:23:06 INFO Epoch 3: [991/10940] ---- BYOL Training Loss = 0.28513652086257935
30-01-2023 15:23:24 INFO Epoch 3: [1002/10940] ---- BYOL Training Loss = 0.3070903718471527
30-01-2023 15:23:42 INFO Epoch 3: [1013/10940] ---- BYOL Training Loss = 0.3014596998691559
30-01-2023 15:24:34 INFO Epoch 3: [1013/10940] ---- BYOL Validation Loss = 0.31739258766174316
30-01-2023 15:24:51 INFO Epoch 3: [1024/10940] ---- BYOL Training Loss = 0.2854696810245514
30-01-2023 15:25:09 INFO Epoch 3: [1035/10940] ---- BYOL Training Loss = 0.3187099099159241
30-01-2023 15:25:27 INFO Epoch 3: [1046/10940] ---- BYOL Training Loss = 0.32288533449172974
30-01-2023 15:25:44 INFO Epoch 3: [1057/10940] ---- BYOL Training Loss = 0.32606953382492065
30-01-2023 15:26:37 INFO Epoch 3: [1057/10940] ---- BYOL Validation Loss = 0.32517051696777344
30-01-2023 15:26:54 INFO Epoch 3: [1068/10940] ---- BYOL Training Loss = 0.3216727375984192
30-01-2023 15:27:11 INFO Epoch 3: [1079/10940] ---- BYOL Training Loss = 0.3282833397388458
30-01-2023 15:27:29 INFO Epoch 3: [1090/10940] ---- BYOL Training Loss = 0.30797070264816284
30-01-2023 15:27:47 INFO Epoch 3: [1101/10940] ---- BYOL Training Loss = 0.33447206020355225
30-01-2023 15:28:39 INFO Epoch 3: [1101/10940] ---- BYOL Validation Loss = 0.3202407658100128
30-01-2023 15:28:56 INFO Epoch 3: [1112/10940] ---- BYOL Training Loss = 0.37235361337661743
30-01-2023 15:29:14 INFO Epoch 3: [1123/10940] ---- BYOL Training Loss = 0.2997923493385315
30-01-2023 15:29:32 INFO Epoch 3: [1134/10940] ---- BYOL Training Loss = 0.26648473739624023
30-01-2023 15:29:49 INFO Epoch 3: [1145/10940] ---- BYOL Training Loss = 0.3486981987953186
30-01-2023 15:30:41 INFO Epoch 3: [1145/10940] ---- BYOL Validation Loss = 0.33385521173477173
30-01-2023 15:30:58 INFO Epoch 3: [1156/10940] ---- BYOL Training Loss = 0.35941892862319946
30-01-2023 15:31:16 INFO Epoch 3: [1167/10940] ---- BYOL Training Loss = 0.34119167923927307
30-01-2023 15:31:34 INFO Epoch 3: [1178/10940] ---- BYOL Training Loss = 0.32486453652381897
30-01-2023 15:31:51 INFO Epoch 3: [1189/10940] ---- BYOL Training Loss = 0.3022098243236542
30-01-2023 15:32:43 INFO Epoch 3: [1189/10940] ---- BYOL Validation Loss = 0.32840824127197266
30-01-2023 15:33:01 INFO Epoch 3: [1200/10940] ---- BYOL Training Loss = 0.30841097235679626
30-01-2023 15:33:18 INFO Epoch 3: [1211/10940] ---- BYOL Training Loss = 0.30511584877967834
30-01-2023 15:33:36 INFO Epoch 3: [1222/10940] ---- BYOL Training Loss = 0.2536022365093231
30-01-2023 15:33:54 INFO Epoch 3: [1233/10940] ---- BYOL Training Loss = 0.3196437656879425
30-01-2023 15:34:46 INFO Epoch 3: [1233/10940] ---- BYOL Validation Loss = 0.3315317928791046
30-01-2023 15:35:03 INFO Epoch 3: [1244/10940] ---- BYOL Training Loss = 0.34981706738471985
30-01-2023 15:35:21 INFO Epoch 3: [1255/10940] ---- BYOL Training Loss = 0.3316716253757477
30-01-2023 15:35:38 INFO Epoch 3: [1266/10940] ---- BYOL Training Loss = 0.3294888138771057
30-01-2023 15:35:56 INFO Epoch 3: [1277/10940] ---- BYOL Training Loss = 0.3663174510002136
30-01-2023 15:36:48 INFO Epoch 3: [1277/10940] ---- BYOL Validation Loss = 0.320831298828125
30-01-2023 15:37:05 INFO Epoch 3: [1288/10940] ---- BYOL Training Loss = 0.3275948762893677
30-01-2023 15:37:23 INFO Epoch 3: [1299/10940] ---- BYOL Training Loss = 0.3580351769924164
30-01-2023 15:37:40 INFO Epoch 3: [1310/10940] ---- BYOL Training Loss = 0.3464946150779724
30-01-2023 15:37:58 INFO Epoch 3: [1321/10940] ---- BYOL Training Loss = 0.3275824785232544
30-01-2023 15:38:50 INFO Epoch 3: [1321/10940] ---- BYOL Validation Loss = 0.34346550703048706
30-01-2023 15:39:08 INFO Epoch 3: [1332/10940] ---- BYOL Training Loss = 0.29866427183151245
30-01-2023 15:39:25 INFO Epoch 3: [1343/10940] ---- BYOL Training Loss = 0.2846671938896179
30-01-2023 15:39:43 INFO Epoch 3: [1354/10940] ---- BYOL Training Loss = 0.2838124632835388
30-01-2023 15:40:01 INFO Epoch 3: [1365/10940] ---- BYOL Training Loss = 0.32513320446014404
30-01-2023 15:40:53 INFO Epoch 3: [1365/10940] ---- BYOL Validation Loss = 0.33537811040878296
30-01-2023 15:41:10 INFO Epoch 3: [1376/10940] ---- BYOL Training Loss = 0.35863807797431946
30-01-2023 15:41:27 INFO Epoch 3: [1387/10940] ---- BYOL Training Loss = 0.3338724374771118
30-01-2023 15:41:45 INFO Epoch 3: [1398/10940] ---- BYOL Training Loss = 0.3219474256038666
30-01-2023 15:42:03 INFO Epoch 3: [1409/10940] ---- BYOL Training Loss = 0.3334735035896301
30-01-2023 15:42:55 INFO Epoch 3: [1409/10940] ---- BYOL Validation Loss = 0.3211807608604431
30-01-2023 15:43:12 INFO Epoch 3: [1420/10940] ---- BYOL Training Loss = 0.3365600109100342
30-01-2023 15:43:30 INFO Epoch 3: [1431/10940] ---- BYOL Training Loss = 0.3452848792076111
30-01-2023 15:43:47 INFO Epoch 3: [1442/10940] ---- BYOL Training Loss = 0.3681906759738922
30-01-2023 15:44:05 INFO Epoch 3: [1453/10940] ---- BYOL Training Loss = 0.2867268919944763
30-01-2023 15:44:57 INFO Epoch 3: [1453/10940] ---- BYOL Validation Loss = 0.3381500542163849
30-01-2023 15:45:14 INFO Epoch 3: [1464/10940] ---- BYOL Training Loss = 0.2527112364768982
30-01-2023 15:45:32 INFO Epoch 3: [1475/10940] ---- BYOL Training Loss = 0.2917858958244324
30-01-2023 15:45:49 INFO Epoch 3: [1486/10940] ---- BYOL Training Loss = 0.3513437509536743
30-01-2023 15:46:07 INFO Epoch 3: [1497/10940] ---- BYOL Training Loss = 0.3293626606464386
30-01-2023 15:46:59 INFO Epoch 3: [1497/10940] ---- BYOL Validation Loss = 0.32592734694480896
30-01-2023 15:47:16 INFO Epoch 3: [1508/10940] ---- BYOL Training Loss = 0.337650328874588
30-01-2023 15:47:34 INFO Epoch 3: [1519/10940] ---- BYOL Training Loss = 0.3196609616279602
30-01-2023 15:47:52 INFO Epoch 3: [1530/10940] ---- BYOL Training Loss = 0.31835493445396423
30-01-2023 15:48:09 INFO Epoch 3: [1541/10940] ---- BYOL Training Loss = 0.3677888810634613
30-01-2023 15:49:01 INFO Epoch 3: [1541/10940] ---- BYOL Validation Loss = 0.3164924085140228
30-01-2023 15:49:19 INFO Epoch 3: [1552/10940] ---- BYOL Training Loss = 0.38863998651504517
30-01-2023 15:49:36 INFO Epoch 3: [1563/10940] ---- BYOL Training Loss = 0.34637385606765747
30-01-2023 15:49:54 INFO Epoch 3: [1574/10940] ---- BYOL Training Loss = 0.38992220163345337
30-01-2023 15:50:12 INFO Epoch 3: [1585/10940] ---- BYOL Training Loss = 0.35286790132522583
30-01-2023 15:51:04 INFO Epoch 3: [1585/10940] ---- BYOL Validation Loss = 0.329765260219574
30-01-2023 15:51:21 INFO Epoch 3: [1596/10940] ---- BYOL Training Loss = 0.3353148400783539
30-01-2023 15:51:39 INFO Epoch 3: [1607/10940] ---- BYOL Training Loss = 0.27112486958503723
30-01-2023 15:51:57 INFO Epoch 3: [1618/10940] ---- BYOL Training Loss = 0.3277045786380768
30-01-2023 15:52:14 INFO Epoch 3: [1629/10940] ---- BYOL Training Loss = 0.3421582877635956
30-01-2023 15:53:06 INFO Epoch 3: [1629/10940] ---- BYOL Validation Loss = 0.324562132358551
30-01-2023 15:53:24 INFO Epoch 3: [1640/10940] ---- BYOL Training Loss = 0.33070042729377747
30-01-2023 15:53:41 INFO Epoch 3: [1651/10940] ---- BYOL Training Loss = 0.33026400208473206
30-01-2023 15:53:59 INFO Epoch 3: [1662/10940] ---- BYOL Training Loss = 0.3377017378807068
30-01-2023 15:54:17 INFO Epoch 3: [1673/10940] ---- BYOL Training Loss = 0.35145002603530884
30-01-2023 15:55:09 INFO Epoch 3: [1673/10940] ---- BYOL Validation Loss = 0.3206159472465515
30-01-2023 15:55:26 INFO Epoch 3: [1684/10940] ---- BYOL Training Loss = 0.34832924604415894
30-01-2023 15:55:44 INFO Epoch 3: [1695/10940] ---- BYOL Training Loss = 0.29253992438316345
30-01-2023 15:56:01 INFO Epoch 3: [1706/10940] ---- BYOL Training Loss = 0.27128371596336365
30-01-2023 15:56:19 INFO Epoch 3: [1717/10940] ---- BYOL Training Loss = 0.3138129711151123
30-01-2023 15:57:11 INFO Epoch 3: [1717/10940] ---- BYOL Validation Loss = 0.32472625374794006
30-01-2023 15:57:28 INFO Epoch 3: [1728/10940] ---- BYOL Training Loss = 0.3507992625236511
30-01-2023 15:57:46 INFO Epoch 3: [1739/10940] ---- BYOL Training Loss = 0.3196820318698883
30-01-2023 15:58:04 INFO Epoch 3: [1750/10940] ---- BYOL Training Loss = 0.33083420991897583
30-01-2023 15:58:21 INFO Epoch 3: [1761/10940] ---- BYOL Training Loss = 0.3712652623653412
30-01-2023 15:59:13 INFO Epoch 3: [1761/10940] ---- BYOL Validation Loss = 0.3266465961933136
30-01-2023 15:59:31 INFO Epoch 3: [1772/10940] ---- BYOL Training Loss = 0.3610461354255676
30-01-2023 15:59:48 INFO Epoch 3: [1783/10940] ---- BYOL Training Loss = 0.3216875195503235
30-01-2023 16:00:06 INFO Epoch 3: [1794/10940] ---- BYOL Training Loss = 0.3249552845954895
30-01-2023 16:00:24 INFO Epoch 3: [1805/10940] ---- BYOL Training Loss = 0.34417957067489624
30-01-2023 16:01:17 INFO Epoch 3: [1805/10940] ---- BYOL Validation Loss = 0.33044371008872986
30-01-2023 16:01:34 INFO Epoch 3: [1816/10940] ---- BYOL Training Loss = 0.3482939898967743
30-01-2023 16:01:52 INFO Epoch 3: [1827/10940] ---- BYOL Training Loss = 0.3950028419494629
30-01-2023 16:02:09 INFO Epoch 3: [1838/10940] ---- BYOL Training Loss = 0.40841737389564514
30-01-2023 16:02:27 INFO Epoch 3: [1849/10940] ---- BYOL Training Loss = 0.35053786635398865
30-01-2023 16:03:19 INFO Epoch 3: [1849/10940] ---- BYOL Validation Loss = 0.3223210871219635
30-01-2023 16:03:36 INFO Epoch 3: [1860/10940] ---- BYOL Training Loss = 0.3447956442832947
30-01-2023 16:03:54 INFO Epoch 3: [1871/10940] ---- BYOL Training Loss = 0.39755937457084656
30-01-2023 16:04:11 INFO Epoch 3: [1882/10940] ---- BYOL Training Loss = 0.35064882040023804
30-01-2023 16:04:29 INFO Epoch 3: [1893/10940] ---- BYOL Training Loss = 0.34471186995506287
30-01-2023 16:05:21 INFO Epoch 3: [1893/10940] ---- BYOL Validation Loss = 0.32701465487480164
30-01-2023 16:05:39 INFO Epoch 3: [1904/10940] ---- BYOL Training Loss = 0.4251876473426819
30-01-2023 16:05:56 INFO Epoch 3: [1915/10940] ---- BYOL Training Loss = 0.39270275831222534
30-01-2023 16:06:14 INFO Epoch 3: [1926/10940] ---- BYOL Training Loss = 0.36817312240600586
30-01-2023 16:06:32 INFO Epoch 3: [1937/10940] ---- BYOL Training Loss = 0.3661658763885498
30-01-2023 16:07:24 INFO Epoch 3: [1937/10940] ---- BYOL Validation Loss = 0.33259889483451843
30-01-2023 16:07:41 INFO Epoch 3: [1948/10940] ---- BYOL Training Loss = 0.4039553701877594
30-01-2023 16:07:59 INFO Epoch 3: [1959/10940] ---- BYOL Training Loss = 0.408446729183197
30-01-2023 16:08:16 INFO Epoch 3: [1970/10940] ---- BYOL Training Loss = 0.32631784677505493
30-01-2023 16:08:34 INFO Epoch 3: [1981/10940] ---- BYOL Training Loss = 0.2624557614326477
30-01-2023 16:09:26 INFO Epoch 3: [1981/10940] ---- BYOL Validation Loss = 0.3218022882938385
30-01-2023 16:09:43 INFO Epoch 3: [1992/10940] ---- BYOL Training Loss = 0.29626283049583435
30-01-2023 16:10:01 INFO Epoch 3: [2003/10940] ---- BYOL Training Loss = 0.3136933445930481
30-01-2023 16:10:19 INFO Epoch 3: [2014/10940] ---- BYOL Training Loss = 0.31468552350997925
30-01-2023 16:10:37 INFO Epoch 3: [2025/10940] ---- BYOL Training Loss = 0.32279521226882935
30-01-2023 16:11:29 INFO Epoch 3: [2025/10940] ---- BYOL Validation Loss = 0.322557657957077
30-01-2023 16:11:46 INFO Epoch 3: [2036/10940] ---- BYOL Training Loss = 0.33123716711997986
30-01-2023 16:12:04 INFO Epoch 3: [2047/10940] ---- BYOL Training Loss = 0.30303412675857544
30-01-2023 16:12:21 INFO Epoch 3: [2058/10940] ---- BYOL Training Loss = 0.3358255624771118
30-01-2023 16:12:39 INFO Epoch 3: [2069/10940] ---- BYOL Training Loss = 0.30950579047203064
30-01-2023 16:13:31 INFO Epoch 3: [2069/10940] ---- BYOL Validation Loss = 0.3150487542152405
30-01-2023 16:13:49 INFO Epoch 3: [2080/10940] ---- BYOL Training Loss = 0.24091915786266327
30-01-2023 16:14:06 INFO Epoch 3: [2091/10940] ---- BYOL Training Loss = 0.2174825668334961
30-01-2023 16:14:24 INFO Epoch 3: [2102/10940] ---- BYOL Training Loss = 0.28716206550598145
30-01-2023 16:14:42 INFO Epoch 3: [2113/10940] ---- BYOL Training Loss = 0.29743584990501404
30-01-2023 16:15:34 INFO Epoch 3: [2113/10940] ---- BYOL Validation Loss = 0.3057436943054199
30-01-2023 16:15:51 INFO Epoch 3: [2124/10940] ---- BYOL Training Loss = 0.29730942845344543
30-01-2023 16:16:09 INFO Epoch 3: [2135/10940] ---- BYOL Training Loss = 0.2808580696582794
30-01-2023 16:16:26 INFO Epoch 3: [2146/10940] ---- BYOL Training Loss = 0.3040781617164612
30-01-2023 16:16:44 INFO Epoch 3: [2157/10940] ---- BYOL Training Loss = 0.3101702034473419
30-01-2023 16:17:36 INFO Epoch 3: [2157/10940] ---- BYOL Validation Loss = 0.31113913655281067
30-01-2023 16:17:53 INFO Epoch 3: [2168/10940] ---- BYOL Training Loss = 0.31172433495521545
30-01-2023 16:18:11 INFO Epoch 3: [2179/10940] ---- BYOL Training Loss = 0.27212947607040405
30-01-2023 16:18:29 INFO Epoch 3: [2190/10940] ---- BYOL Training Loss = 0.2848846912384033
30-01-2023 16:18:47 INFO Epoch 3: [2201/10940] ---- BYOL Training Loss = 0.32143908739089966
30-01-2023 16:19:39 INFO Epoch 3: [2201/10940] ---- BYOL Validation Loss = 0.31753021478652954
30-01-2023 16:19:56 INFO Epoch 3: [2212/10940] ---- BYOL Training Loss = 0.3161589503288269
30-01-2023 16:20:14 INFO Epoch 3: [2223/10940] ---- BYOL Training Loss = 0.3519352078437805
30-01-2023 16:20:32 INFO Epoch 3: [2234/10940] ---- BYOL Training Loss = 0.3048579692840576
30-01-2023 16:20:49 INFO Epoch 3: [2245/10940] ---- BYOL Training Loss = 0.2983022928237915
30-01-2023 16:21:41 INFO Epoch 3: [2245/10940] ---- BYOL Validation Loss = 0.31026872992515564
30-01-2023 16:21:59 INFO Epoch 3: [2256/10940] ---- BYOL Training Loss = 0.30366969108581543
30-01-2023 16:22:16 INFO Epoch 3: [2267/10940] ---- BYOL Training Loss = 0.31900691986083984
30-01-2023 16:22:34 INFO Epoch 3: [2278/10940] ---- BYOL Training Loss = 0.3379337191581726
30-01-2023 16:22:52 INFO Epoch 3: [2289/10940] ---- BYOL Training Loss = 0.3351014256477356
30-01-2023 16:23:44 INFO Epoch 3: [2289/10940] ---- BYOL Validation Loss = 0.32174310088157654
30-01-2023 16:24:01 INFO Epoch 3: [2300/10940] ---- BYOL Training Loss = 0.30478808283805847
30-01-2023 16:24:19 INFO Epoch 3: [2311/10940] ---- BYOL Training Loss = 0.26584070920944214
30-01-2023 16:24:37 INFO Epoch 3: [2322/10940] ---- BYOL Training Loss = 0.37598544359207153
30-01-2023 16:24:55 INFO Epoch 3: [2333/10940] ---- BYOL Training Loss = 0.3714125156402588
30-01-2023 16:25:47 INFO Epoch 3: [2333/10940] ---- BYOL Validation Loss = 0.3332149088382721
30-01-2023 16:26:04 INFO Epoch 3: [2344/10940] ---- BYOL Training Loss = 0.3234776258468628
30-01-2023 16:26:22 INFO Epoch 3: [2355/10940] ---- BYOL Training Loss = 0.32719358801841736
30-01-2023 16:26:40 INFO Epoch 3: [2366/10940] ---- BYOL Training Loss = 0.35730963945388794
30-01-2023 16:26:57 INFO Epoch 3: [2377/10940] ---- BYOL Training Loss = 0.3884059488773346
30-01-2023 16:27:49 INFO Epoch 3: [2377/10940] ---- BYOL Validation Loss = 0.31307345628738403
30-01-2023 16:28:07 INFO Epoch 3: [2388/10940] ---- BYOL Training Loss = 0.3107618987560272
30-01-2023 16:28:24 INFO Epoch 3: [2399/10940] ---- BYOL Training Loss = 0.32318487763404846
30-01-2023 16:28:42 INFO Epoch 3: [2410/10940] ---- BYOL Training Loss = 0.3192445635795593
30-01-2023 16:29:00 INFO Epoch 3: [2421/10940] ---- BYOL Training Loss = 0.27851444482803345
30-01-2023 16:29:52 INFO Epoch 3: [2421/10940] ---- BYOL Validation Loss = 0.31482043862342834
30-01-2023 16:30:10 INFO Epoch 3: [2432/10940] ---- BYOL Training Loss = 0.2652590870857239
30-01-2023 16:30:28 INFO Epoch 3: [2443/10940] ---- BYOL Training Loss = 0.29267048835754395
30-01-2023 16:30:46 INFO Epoch 3: [2454/10940] ---- BYOL Training Loss = 0.3229065239429474
30-01-2023 16:31:03 INFO Epoch 3: [2465/10940] ---- BYOL Training Loss = 0.3344746232032776
30-01-2023 16:31:56 INFO Epoch 3: [2465/10940] ---- BYOL Validation Loss = 0.3183675706386566
30-01-2023 16:32:13 INFO Epoch 3: [2476/10940] ---- BYOL Training Loss = 0.3088124990463257
30-01-2023 16:32:31 INFO Epoch 3: [2487/10940] ---- BYOL Training Loss = 0.334297239780426
30-01-2023 16:32:48 INFO Epoch 3: [2498/10940] ---- BYOL Training Loss = 0.37673160433769226
30-01-2023 16:33:06 INFO Epoch 3: [2509/10940] ---- BYOL Training Loss = 0.35698050260543823
30-01-2023 16:33:58 INFO Epoch 3: [2509/10940] ---- BYOL Validation Loss = 0.3264169692993164
30-01-2023 16:34:15 INFO Epoch 3: [2520/10940] ---- BYOL Training Loss = 0.3100760281085968
30-01-2023 16:34:33 INFO Epoch 3: [2531/10940] ---- BYOL Training Loss = 0.315854549407959
30-01-2023 16:34:51 INFO Epoch 3: [2542/10940] ---- BYOL Training Loss = 0.2835220694541931
30-01-2023 16:35:09 INFO Epoch 3: [2553/10940] ---- BYOL Training Loss = 0.31882667541503906
30-01-2023 16:36:01 INFO Epoch 3: [2553/10940] ---- BYOL Validation Loss = 0.33304792642593384
30-01-2023 16:36:18 INFO Epoch 3: [2564/10940] ---- BYOL Training Loss = 0.39006927609443665
30-01-2023 16:36:36 INFO Epoch 3: [2575/10940] ---- BYOL Training Loss = 0.335480272769928
30-01-2023 16:36:54 INFO Epoch 3: [2586/10940] ---- BYOL Training Loss = 0.3102136552333832
30-01-2023 16:37:12 INFO Epoch 3: [2597/10940] ---- BYOL Training Loss = 0.317931205034256
30-01-2023 16:38:04 INFO Epoch 3: [2597/10940] ---- BYOL Validation Loss = 0.3154314160346985
30-01-2023 16:38:21 INFO Epoch 3: [2608/10940] ---- BYOL Training Loss = 0.3197483420372009
30-01-2023 16:38:39 INFO Epoch 3: [2619/10940] ---- BYOL Training Loss = 0.3341027498245239
30-01-2023 16:38:56 INFO Epoch 3: [2630/10940] ---- BYOL Training Loss = 0.3986591100692749
30-01-2023 16:39:14 INFO Epoch 3: [2641/10940] ---- BYOL Training Loss = 0.39797136187553406
30-01-2023 16:40:06 INFO Epoch 3: [2641/10940] ---- BYOL Validation Loss = 0.32635143399238586
30-01-2023 16:40:24 INFO Epoch 3: [2652/10940] ---- BYOL Training Loss = 0.33946508169174194
30-01-2023 16:40:42 INFO Epoch 3: [2663/10940] ---- BYOL Training Loss = 0.30896976590156555
30-01-2023 16:40:59 INFO Epoch 3: [2674/10940] ---- BYOL Training Loss = 0.2870238721370697
30-01-2023 16:41:17 INFO Epoch 3: [2685/10940] ---- BYOL Training Loss = 0.3221209943294525
30-01-2023 16:42:09 INFO Epoch 3: [2685/10940] ---- BYOL Validation Loss = 0.3125137686729431
30-01-2023 16:42:27 INFO Epoch 3: [2696/10940] ---- BYOL Training Loss = 0.3747560381889343
30-01-2023 16:42:44 INFO Epoch 3: [2707/10940] ---- BYOL Training Loss = 0.4053584039211273
30-01-2023 16:43:02 INFO Epoch 3: [2718/10940] ---- BYOL Training Loss = 0.37601709365844727
30-01-2023 16:43:20 INFO Epoch 3: [2729/10940] ---- BYOL Training Loss = 0.3832798898220062
30-01-2023 16:44:12 INFO Epoch 3: [2729/10940] ---- BYOL Validation Loss = 0.3247275650501251
30-01-2023 16:44:29 INFO Epoch 3: [2740/10940] ---- BYOL Training Loss = 0.40892189741134644
30-01-2023 16:44:47 INFO Epoch 3: [2751/10940] ---- BYOL Training Loss = 0.30631792545318604
30-01-2023 16:45:05 INFO Epoch 3: [2762/10940] ---- BYOL Training Loss = 0.31410327553749084
30-01-2023 16:45:23 INFO Epoch 3: [2773/10940] ---- BYOL Training Loss = 0.34003394842147827
30-01-2023 16:46:15 INFO Epoch 3: [2773/10940] ---- BYOL Validation Loss = 0.314773827791214
30-01-2023 16:46:32 INFO Epoch 3: [2784/10940] ---- BYOL Training Loss = 0.4089764654636383
30-01-2023 16:46:50 INFO Epoch 3: [2795/10940] ---- BYOL Training Loss = 0.3932947814464569
30-01-2023 16:47:08 INFO Epoch 3: [2806/10940] ---- BYOL Training Loss = 0.3480274975299835
30-01-2023 16:47:26 INFO Epoch 3: [2817/10940] ---- BYOL Training Loss = 0.37202194333076477
30-01-2023 16:48:18 INFO Epoch 3: [2817/10940] ---- BYOL Validation Loss = 0.3261117935180664
30-01-2023 16:48:35 INFO Epoch 3: [2828/10940] ---- BYOL Training Loss = 0.3501143157482147
30-01-2023 16:48:53 INFO Epoch 3: [2839/10940] ---- BYOL Training Loss = 0.32112404704093933
30-01-2023 16:49:11 INFO Epoch 3: [2850/10940] ---- BYOL Training Loss = 0.3628842830657959
30-01-2023 16:49:29 INFO Epoch 3: [2861/10940] ---- BYOL Training Loss = 0.34378498792648315
30-01-2023 16:50:21 INFO Epoch 3: [2861/10940] ---- BYOL Validation Loss = 0.315094530582428
30-01-2023 16:50:38 INFO Epoch 3: [2872/10940] ---- BYOL Training Loss = 0.3120940029621124
30-01-2023 16:50:56 INFO Epoch 3: [2883/10940] ---- BYOL Training Loss = 0.3210920989513397
30-01-2023 16:51:14 INFO Epoch 3: [2894/10940] ---- BYOL Training Loss = 0.2915442883968353
30-01-2023 16:51:31 INFO Epoch 3: [2905/10940] ---- BYOL Training Loss = 0.35027116537094116
30-01-2023 16:52:24 INFO Epoch 3: [2905/10940] ---- BYOL Validation Loss = 0.3150223195552826
30-01-2023 16:52:41 INFO Epoch 3: [2916/10940] ---- BYOL Training Loss = 0.41534385085105896
30-01-2023 16:52:59 INFO Epoch 3: [2927/10940] ---- BYOL Training Loss = 0.3613065183162689
30-01-2023 16:53:17 INFO Epoch 3: [2938/10940] ---- BYOL Training Loss = 0.3230583369731903
30-01-2023 16:53:34 INFO Epoch 3: [2949/10940] ---- BYOL Training Loss = 0.3246667981147766
30-01-2023 16:54:26 INFO Epoch 3: [2949/10940] ---- BYOL Validation Loss = 0.3127356469631195
30-01-2023 16:54:44 INFO Epoch 3: [2960/10940] ---- BYOL Training Loss = 0.2862589657306671
30-01-2023 16:55:02 INFO Epoch 3: [2971/10940] ---- BYOL Training Loss = 0.26895955204963684
30-01-2023 16:55:19 INFO Epoch 3: [2982/10940] ---- BYOL Training Loss = 0.2840483784675598
30-01-2023 16:55:37 INFO Epoch 3: [2993/10940] ---- BYOL Training Loss = 0.34648627042770386
30-01-2023 16:56:29 INFO Epoch 3: [2993/10940] ---- BYOL Validation Loss = 0.31676623225212097
30-01-2023 16:56:47 INFO Epoch 3: [3004/10940] ---- BYOL Training Loss = 0.37699639797210693
30-01-2023 16:57:05 INFO Epoch 3: [3015/10940] ---- BYOL Training Loss = 0.36632102727890015
30-01-2023 16:57:23 INFO Epoch 3: [3026/10940] ---- BYOL Training Loss = 0.2813270390033722
30-01-2023 16:57:40 INFO Epoch 3: [3037/10940] ---- BYOL Training Loss = 0.3430989384651184
30-01-2023 16:58:33 INFO Epoch 3: [3037/10940] ---- BYOL Validation Loss = 0.3224215507507324
30-01-2023 16:58:51 INFO Epoch 3: [3048/10940] ---- BYOL Training Loss = 0.29268908500671387
30-01-2023 16:59:08 INFO Epoch 3: [3059/10940] ---- BYOL Training Loss = 0.291689395904541
30-01-2023 16:59:26 INFO Epoch 3: [3070/10940] ---- BYOL Training Loss = 0.32239165902137756
30-01-2023 16:59:44 INFO Epoch 3: [3081/10940] ---- BYOL Training Loss = 0.31666338443756104
30-01-2023 17:00:36 INFO Epoch 3: [3081/10940] ---- BYOL Validation Loss = 0.31796714663505554
30-01-2023 17:00:53 INFO Epoch 3: [3092/10940] ---- BYOL Training Loss = 0.3293960690498352
30-01-2023 17:01:11 INFO Epoch 3: [3103/10940] ---- BYOL Training Loss = 0.31574517488479614
30-01-2023 17:01:29 INFO Epoch 3: [3114/10940] ---- BYOL Training Loss = 0.3358211815357208
30-01-2023 17:01:47 INFO Epoch 3: [3125/10940] ---- BYOL Training Loss = 0.3249996304512024
30-01-2023 17:02:39 INFO Epoch 3: [3125/10940] ---- BYOL Validation Loss = 0.3085932731628418
30-01-2023 17:02:57 INFO Epoch 3: [3136/10940] ---- BYOL Training Loss = 0.30616462230682373
30-01-2023 17:03:15 INFO Epoch 3: [3147/10940] ---- BYOL Training Loss = 0.33559316396713257
30-01-2023 17:03:33 INFO Epoch 3: [3158/10940] ---- BYOL Training Loss = 0.336617648601532
30-01-2023 17:03:50 INFO Epoch 3: [3169/10940] ---- BYOL Training Loss = 0.2918350398540497
30-01-2023 17:04:43 INFO Epoch 3: [3169/10940] ---- BYOL Validation Loss = 0.3149375915527344
30-01-2023 17:05:00 INFO Epoch 3: [3180/10940] ---- BYOL Training Loss = 0.24753829836845398
30-01-2023 17:05:18 INFO Epoch 3: [3191/10940] ---- BYOL Training Loss = 0.32812732458114624
30-01-2023 17:05:36 INFO Epoch 3: [3202/10940] ---- BYOL Training Loss = 0.3127797842025757
30-01-2023 17:05:54 INFO Epoch 3: [3213/10940] ---- BYOL Training Loss = 0.3138323724269867
30-01-2023 17:06:46 INFO Epoch 3: [3213/10940] ---- BYOL Validation Loss = 0.31990846991539
30-01-2023 17:07:04 INFO Epoch 3: [3224/10940] ---- BYOL Training Loss = 0.2982347905635834
30-01-2023 17:07:21 INFO Epoch 3: [3235/10940] ---- BYOL Training Loss = 0.28393039107322693
30-01-2023 17:07:39 INFO Epoch 3: [3246/10940] ---- BYOL Training Loss = 0.26148027181625366
30-01-2023 17:07:57 INFO Epoch 3: [3257/10940] ---- BYOL Training Loss = 0.2818092107772827
30-01-2023 17:08:49 INFO Epoch 3: [3257/10940] ---- BYOL Validation Loss = 0.31268128752708435
30-01-2023 17:09:06 INFO Epoch 3: [3268/10940] ---- BYOL Training Loss = 0.333816260099411
30-01-2023 17:09:25 INFO Epoch 3: [3279/10940] ---- BYOL Training Loss = 0.34952855110168457
30-01-2023 17:09:42 INFO Epoch 3: [3290/10940] ---- BYOL Training Loss = 0.3402343690395355
30-01-2023 17:10:00 INFO Epoch 3: [3301/10940] ---- BYOL Training Loss = 0.3151010572910309
30-01-2023 17:10:52 INFO Epoch 3: [3301/10940] ---- BYOL Validation Loss = 0.3155671954154968
30-01-2023 17:11:10 INFO Epoch 3: [3312/10940] ---- BYOL Training Loss = 0.31445202231407166
30-01-2023 17:11:27 INFO Epoch 3: [3323/10940] ---- BYOL Training Loss = 0.2992944121360779
30-01-2023 17:11:45 INFO Epoch 3: [3334/10940] ---- BYOL Training Loss = 0.3125845789909363
30-01-2023 17:12:03 INFO Epoch 3: [3345/10940] ---- BYOL Training Loss = 0.31940826773643494
30-01-2023 17:12:55 INFO Epoch 3: [3345/10940] ---- BYOL Validation Loss = 0.3101344108581543
30-01-2023 17:13:13 INFO Epoch 3: [3356/10940] ---- BYOL Training Loss = 0.3339338004589081
30-01-2023 17:13:30 INFO Epoch 3: [3367/10940] ---- BYOL Training Loss = 0.37006884813308716
30-01-2023 17:13:48 INFO Epoch 3: [3378/10940] ---- BYOL Training Loss = 0.2781893312931061
30-01-2023 17:14:06 INFO Epoch 3: [3389/10940] ---- BYOL Training Loss = 0.24854616820812225
30-01-2023 17:14:58 INFO Epoch 3: [3389/10940] ---- BYOL Validation Loss = 0.313721626996994
30-01-2023 17:15:16 INFO Epoch 3: [3400/10940] ---- BYOL Training Loss = 0.2663900852203369
30-01-2023 17:15:34 INFO Epoch 3: [3411/10940] ---- BYOL Training Loss = 0.3417884409427643
30-01-2023 17:15:51 INFO Epoch 3: [3422/10940] ---- BYOL Training Loss = 0.33697816729545593
30-01-2023 17:16:10 INFO Epoch 3: [3433/10940] ---- BYOL Training Loss = 0.30729788541793823
30-01-2023 17:17:02 INFO Epoch 3: [3433/10940] ---- BYOL Validation Loss = 0.3240218758583069
30-01-2023 17:17:19 INFO Epoch 3: [3444/10940] ---- BYOL Training Loss = 0.29150718450546265
30-01-2023 17:17:37 INFO Epoch 3: [3455/10940] ---- BYOL Training Loss = 0.2692612111568451
30-01-2023 17:17:55 INFO Epoch 3: [3466/10940] ---- BYOL Training Loss = 0.26413050293922424
30-01-2023 17:18:12 INFO Epoch 3: [3477/10940] ---- BYOL Training Loss = 0.29360485076904297
30-01-2023 17:19:04 INFO Epoch 3: [3477/10940] ---- BYOL Validation Loss = 0.31261298060417175
30-01-2023 17:19:22 INFO Epoch 3: [3488/10940] ---- BYOL Training Loss = 0.3399941325187683
30-01-2023 17:19:40 INFO Epoch 3: [3499/10940] ---- BYOL Training Loss = 0.32363298535346985
30-01-2023 17:19:58 INFO Epoch 3: [3510/10940] ---- BYOL Training Loss = 0.275359570980072
30-01-2023 17:20:16 INFO Epoch 3: [3521/10940] ---- BYOL Training Loss = 0.31364738941192627
30-01-2023 17:21:08 INFO Epoch 3: [3521/10940] ---- BYOL Validation Loss = 0.311678409576416
30-01-2023 17:21:26 INFO Epoch 3: [3532/10940] ---- BYOL Training Loss = 0.30228421092033386
30-01-2023 17:21:44 INFO Epoch 3: [3543/10940] ---- BYOL Training Loss = 0.29142096638679504
30-01-2023 17:22:02 INFO Epoch 3: [3554/10940] ---- BYOL Training Loss = 0.2897040843963623
30-01-2023 17:22:19 INFO Epoch 3: [3565/10940] ---- BYOL Training Loss = 0.3725302815437317
30-01-2023 17:23:11 INFO Epoch 3: [3565/10940] ---- BYOL Validation Loss = 0.3059331476688385
30-01-2023 17:23:29 INFO Epoch 3: [3576/10940] ---- BYOL Training Loss = 0.3807663321495056
30-01-2023 17:23:47 INFO Epoch 3: [3587/10940] ---- BYOL Training Loss = 0.32037830352783203
30-01-2023 17:24:05 INFO Epoch 3: [3598/10940] ---- BYOL Training Loss = 0.32373881340026855
30-01-2023 17:24:23 INFO Epoch 3: [3609/10940] ---- BYOL Training Loss = 0.3410446345806122
30-01-2023 17:25:15 INFO Epoch 3: [3609/10940] ---- BYOL Validation Loss = 0.31270259618759155
30-01-2023 17:25:32 INFO Epoch 3: [3620/10940] ---- BYOL Training Loss = 0.30944064259529114
30-01-2023 17:25:50 INFO Epoch 3: [3631/10940] ---- BYOL Training Loss = 0.3073177933692932
30-01-2023 17:26:08 INFO Epoch 3: [3642/10940] ---- BYOL Training Loss = 0.31821948289871216
30-01-2023 17:26:26 INFO Epoch 3: [3653/10940] ---- BYOL Training Loss = 0.31344032287597656
30-01-2023 17:27:18 INFO Epoch 3: [3653/10940] ---- BYOL Validation Loss = 0.3132548928260803
30-01-2023 17:27:36 INFO Epoch 3: [3664/10940] ---- BYOL Training Loss = 0.31100815534591675
30-01-2023 17:27:54 INFO Epoch 3: [3675/10940] ---- BYOL Training Loss = 0.318461149930954
30-01-2023 17:28:12 INFO Epoch 3: [3686/10940] ---- BYOL Training Loss = 0.3287411630153656
30-01-2023 17:28:30 INFO Epoch 3: [3697/10940] ---- BYOL Training Loss = 0.33637097477912903
30-01-2023 17:29:22 INFO Epoch 3: [3697/10940] ---- BYOL Validation Loss = 0.30222028493881226
30-01-2023 17:29:39 INFO Epoch 3: [3708/10940] ---- BYOL Training Loss = 0.32489413022994995
30-01-2023 17:29:57 INFO Epoch 3: [3719/10940] ---- BYOL Training Loss = 0.33740168809890747
30-01-2023 17:30:15 INFO Epoch 3: [3730/10940] ---- BYOL Training Loss = 0.35681238770484924
30-01-2023 17:30:33 INFO Epoch 3: [3741/10940] ---- BYOL Training Loss = 0.2968561053276062
30-01-2023 17:31:25 INFO Epoch 3: [3741/10940] ---- BYOL Validation Loss = 0.30728650093078613
30-01-2023 17:31:43 INFO Epoch 3: [3752/10940] ---- BYOL Training Loss = 0.3516193628311157
30-01-2023 17:32:00 INFO Epoch 3: [3763/10940] ---- BYOL Training Loss = 0.36614692211151123
30-01-2023 17:32:18 INFO Epoch 3: [3774/10940] ---- BYOL Training Loss = 0.3195249140262604
30-01-2023 17:32:36 INFO Epoch 3: [3785/10940] ---- BYOL Training Loss = 0.33359193801879883
30-01-2023 17:33:28 INFO Epoch 3: [3785/10940] ---- BYOL Validation Loss = 0.3076004087924957
30-01-2023 17:33:46 INFO Epoch 3: [3796/10940] ---- BYOL Training Loss = 0.294754296541214
30-01-2023 17:34:04 INFO Epoch 3: [3807/10940] ---- BYOL Training Loss = 0.31576597690582275
30-01-2023 17:34:22 INFO Epoch 3: [3818/10940] ---- BYOL Training Loss = 0.3311682939529419
30-01-2023 17:34:40 INFO Epoch 3: [3829/10940] ---- BYOL Training Loss = 0.2694445550441742
30-01-2023 17:35:32 INFO Epoch 3: [3829/10940] ---- BYOL Validation Loss = 0.30578184127807617
30-01-2023 17:35:49 INFO Epoch 3: [3840/10940] ---- BYOL Training Loss = 0.24941258132457733
30-01-2023 17:36:07 INFO Epoch 3: [3851/10940] ---- BYOL Training Loss = 0.28111693263053894
30-01-2023 17:36:25 INFO Epoch 3: [3862/10940] ---- BYOL Training Loss = 0.29105955362319946
30-01-2023 17:36:43 INFO Epoch 3: [3873/10940] ---- BYOL Training Loss = 0.3063790798187256
30-01-2023 17:37:35 INFO Epoch 3: [3873/10940] ---- BYOL Validation Loss = 0.300353080034256
30-01-2023 17:37:53 INFO Epoch 3: [3884/10940] ---- BYOL Training Loss = 0.3025628328323364
30-01-2023 17:38:11 INFO Epoch 3: [3895/10940] ---- BYOL Training Loss = 0.27584484219551086
30-01-2023 17:38:28 INFO Epoch 3: [3906/10940] ---- BYOL Training Loss = 0.2986026704311371
30-01-2023 17:38:46 INFO Epoch 3: [3917/10940] ---- BYOL Training Loss = 0.355087548494339
30-01-2023 17:39:39 INFO Epoch 3: [3917/10940] ---- BYOL Validation Loss = 0.30086687207221985
30-01-2023 17:39:56 INFO Epoch 3: [3928/10940] ---- BYOL Training Loss = 0.3549707531929016
30-01-2023 17:40:14 INFO Epoch 3: [3939/10940] ---- BYOL Training Loss = 0.31159788370132446
30-01-2023 17:40:32 INFO Epoch 3: [3950/10940] ---- BYOL Training Loss = 0.28300416469573975
30-01-2023 17:40:50 INFO Epoch 3: [3961/10940] ---- BYOL Training Loss = 0.31233999133110046
30-01-2023 17:41:42 INFO Epoch 3: [3961/10940] ---- BYOL Validation Loss = 0.2992180287837982
30-01-2023 17:42:00 INFO Epoch 3: [3972/10940] ---- BYOL Training Loss = 0.32436954975128174
30-01-2023 17:42:17 INFO Epoch 3: [3983/10940] ---- BYOL Training Loss = 0.3644085228443146
30-01-2023 17:42:36 INFO Epoch 3: [3994/10940] ---- BYOL Training Loss = 0.2924550175666809
30-01-2023 17:42:54 INFO Epoch 3: [4005/10940] ---- BYOL Training Loss = 0.3053285479545593
30-01-2023 17:43:46 INFO Epoch 3: [4005/10940] ---- BYOL Validation Loss = 0.3100021779537201
30-01-2023 17:44:03 INFO Epoch 3: [4016/10940] ---- BYOL Training Loss = 0.3350191116333008
30-01-2023 17:44:21 INFO Epoch 3: [4027/10940] ---- BYOL Training Loss = 0.35291439294815063
30-01-2023 17:44:39 INFO Epoch 3: [4038/10940] ---- BYOL Training Loss = 0.3335292637348175
30-01-2023 17:44:57 INFO Epoch 3: [4049/10940] ---- BYOL Training Loss = 0.2876013219356537
30-01-2023 17:45:49 INFO Epoch 3: [4049/10940] ---- BYOL Validation Loss = 0.30801814794540405
30-01-2023 17:46:07 INFO Epoch 3: [4060/10940] ---- BYOL Training Loss = 0.2716776132583618
30-01-2023 17:46:25 INFO Epoch 3: [4071/10940] ---- BYOL Training Loss = 0.3048208951950073
30-01-2023 17:46:43 INFO Epoch 3: [4082/10940] ---- BYOL Training Loss = 0.29049691557884216
30-01-2023 17:47:01 INFO Epoch 3: [4093/10940] ---- BYOL Training Loss = 0.23884287476539612
30-01-2023 17:47:53 INFO Epoch 3: [4093/10940] ---- BYOL Validation Loss = 0.2983074188232422
30-01-2023 17:48:11 INFO Epoch 3: [4104/10940] ---- BYOL Training Loss = 0.26727113127708435
30-01-2023 17:48:28 INFO Epoch 3: [4115/10940] ---- BYOL Training Loss = 0.2763614356517792
30-01-2023 17:48:47 INFO Epoch 3: [4126/10940] ---- BYOL Training Loss = 0.26089659333229065
30-01-2023 17:49:05 INFO Epoch 3: [4137/10940] ---- BYOL Training Loss = 0.2754487097263336
30-01-2023 17:49:57 INFO Epoch 3: [4137/10940] ---- BYOL Validation Loss = 0.30658620595932007
30-01-2023 17:50:14 INFO Epoch 3: [4148/10940] ---- BYOL Training Loss = 0.3069390058517456
30-01-2023 17:50:32 INFO Epoch 3: [4159/10940] ---- BYOL Training Loss = 0.35519400238990784
30-01-2023 17:50:50 INFO Epoch 3: [4170/10940] ---- BYOL Training Loss = 0.35244742035865784
30-01-2023 17:51:08 INFO Epoch 3: [4181/10940] ---- BYOL Training Loss = 0.3663840889930725
30-01-2023 17:52:00 INFO Epoch 3: [4181/10940] ---- BYOL Validation Loss = 0.3165915608406067
30-01-2023 17:52:18 INFO Epoch 3: [4192/10940] ---- BYOL Training Loss = 0.30306941270828247
30-01-2023 17:52:36 INFO Epoch 3: [4203/10940] ---- BYOL Training Loss = 0.2897239625453949
30-01-2023 17:52:54 INFO Epoch 3: [4214/10940] ---- BYOL Training Loss = 0.32075342535972595
30-01-2023 17:53:11 INFO Epoch 3: [4225/10940] ---- BYOL Training Loss = 0.3282340168952942
30-01-2023 17:54:03 INFO Epoch 3: [4225/10940] ---- BYOL Validation Loss = 0.3068820834159851
30-01-2023 17:54:21 INFO Epoch 3: [4236/10940] ---- BYOL Training Loss = 0.33762362599372864
30-01-2023 17:54:39 INFO Epoch 3: [4247/10940] ---- BYOL Training Loss = 0.2951655685901642
30-01-2023 17:54:57 INFO Epoch 3: [4258/10940] ---- BYOL Training Loss = 0.2714230716228485
30-01-2023 17:55:15 INFO Epoch 3: [4269/10940] ---- BYOL Training Loss = 0.3051588833332062
30-01-2023 17:56:07 INFO Epoch 3: [4269/10940] ---- BYOL Validation Loss = 0.3073957860469818
30-01-2023 17:56:25 INFO Epoch 3: [4280/10940] ---- BYOL Training Loss = 0.34421318769454956
30-01-2023 17:56:43 INFO Epoch 3: [4291/10940] ---- BYOL Training Loss = 0.35402923822402954
30-01-2023 17:57:01 INFO Epoch 3: [4302/10940] ---- BYOL Training Loss = 0.3337939381599426
30-01-2023 17:57:19 INFO Epoch 3: [4313/10940] ---- BYOL Training Loss = 0.3115595281124115
30-01-2023 17:58:11 INFO Epoch 3: [4313/10940] ---- BYOL Validation Loss = 0.31264033913612366
30-01-2023 17:58:29 INFO Epoch 3: [4324/10940] ---- BYOL Training Loss = 0.2847653925418854
30-01-2023 17:58:47 INFO Epoch 3: [4335/10940] ---- BYOL Training Loss = 0.27825605869293213
30-01-2023 17:59:04 INFO Epoch 3: [4346/10940] ---- BYOL Training Loss = 0.2898018956184387
30-01-2023 17:59:22 INFO Epoch 3: [4357/10940] ---- BYOL Training Loss = 0.27835211157798767
30-01-2023 18:00:14 INFO Epoch 3: [4357/10940] ---- BYOL Validation Loss = 0.30777233839035034
30-01-2023 18:00:32 INFO Epoch 3: [4368/10940] ---- BYOL Training Loss = 0.25047120451927185
30-01-2023 18:00:50 INFO Epoch 3: [4379/10940] ---- BYOL Training Loss = 0.26409590244293213
30-01-2023 18:01:08 INFO Epoch 3: [4390/10940] ---- BYOL Training Loss = 0.25693875551223755
30-01-2023 18:01:26 INFO Epoch 3: [4401/10940] ---- BYOL Training Loss = 0.27277281880378723
30-01-2023 18:02:18 INFO Epoch 3: [4401/10940] ---- BYOL Validation Loss = 0.3010757863521576
30-01-2023 18:02:36 INFO Epoch 3: [4412/10940] ---- BYOL Training Loss = 0.312282919883728
30-01-2023 18:02:53 INFO Epoch 3: [4423/10940] ---- BYOL Training Loss = 0.25928452610969543
30-01-2023 18:03:12 INFO Epoch 3: [4434/10940] ---- BYOL Training Loss = 0.29415565729141235
30-01-2023 18:03:30 INFO Epoch 3: [4445/10940] ---- BYOL Training Loss = 0.32488328218460083
30-01-2023 18:04:22 INFO Epoch 3: [4445/10940] ---- BYOL Validation Loss = 0.30257755517959595
30-01-2023 18:04:39 INFO Epoch 3: [4456/10940] ---- BYOL Training Loss = 0.2786831259727478
30-01-2023 18:04:57 INFO Epoch 3: [4467/10940] ---- BYOL Training Loss = 0.31147488951683044
30-01-2023 18:05:15 INFO Epoch 3: [4478/10940] ---- BYOL Training Loss = 0.31984320282936096
30-01-2023 18:05:33 INFO Epoch 3: [4489/10940] ---- BYOL Training Loss = 0.26101744174957275
30-01-2023 18:06:26 INFO Epoch 3: [4489/10940] ---- BYOL Validation Loss = 0.3072943091392517
30-01-2023 18:06:43 INFO Epoch 3: [4500/10940] ---- BYOL Training Loss = 0.27896803617477417
30-01-2023 18:07:01 INFO Epoch 3: [4511/10940] ---- BYOL Training Loss = 0.3315933346748352
30-01-2023 18:07:19 INFO Epoch 3: [4522/10940] ---- BYOL Training Loss = 0.3640590310096741
30-01-2023 18:07:37 INFO Epoch 3: [4533/10940] ---- BYOL Training Loss = 0.3026323914527893
30-01-2023 18:08:29 INFO Epoch 3: [4533/10940] ---- BYOL Validation Loss = 0.30129629373550415
30-01-2023 18:08:46 INFO Epoch 3: [4544/10940] ---- BYOL Training Loss = 0.2892386317253113
30-01-2023 18:09:05 INFO Epoch 3: [4555/10940] ---- BYOL Training Loss = 0.2974850535392761
30-01-2023 18:09:23 INFO Epoch 3: [4566/10940] ---- BYOL Training Loss = 0.2856576144695282
30-01-2023 18:09:41 INFO Epoch 3: [4577/10940] ---- BYOL Training Loss = 0.29545658826828003
30-01-2023 18:10:33 INFO Epoch 3: [4577/10940] ---- BYOL Validation Loss = 0.300313264131546
30-01-2023 18:10:50 INFO Epoch 3: [4588/10940] ---- BYOL Training Loss = 0.3028791844844818
30-01-2023 18:11:08 INFO Epoch 3: [4599/10940] ---- BYOL Training Loss = 0.2797936499118805
30-01-2023 18:11:26 INFO Epoch 3: [4610/10940] ---- BYOL Training Loss = 0.2704847455024719
30-01-2023 18:11:44 INFO Epoch 3: [4621/10940] ---- BYOL Training Loss = 0.3349081873893738
30-01-2023 18:12:36 INFO Epoch 3: [4621/10940] ---- BYOL Validation Loss = 0.3032851219177246
30-01-2023 18:12:54 INFO Epoch 3: [4632/10940] ---- BYOL Training Loss = 0.36686351895332336
30-01-2023 18:13:12 INFO Epoch 3: [4643/10940] ---- BYOL Training Loss = 0.33060362935066223
30-01-2023 18:13:31 INFO Epoch 3: [4654/10940] ---- BYOL Training Loss = 0.2727205157279968
30-01-2023 18:13:48 INFO Epoch 3: [4665/10940] ---- BYOL Training Loss = 0.288322389125824
30-01-2023 18:14:41 INFO Epoch 3: [4665/10940] ---- BYOL Validation Loss = 0.3019353747367859
30-01-2023 18:14:58 INFO Epoch 3: [4676/10940] ---- BYOL Training Loss = 0.2981022298336029
30-01-2023 18:15:16 INFO Epoch 3: [4687/10940] ---- BYOL Training Loss = 0.2923014163970947
30-01-2023 18:15:34 INFO Epoch 3: [4698/10940] ---- BYOL Training Loss = 0.33098357915878296
30-01-2023 18:15:52 INFO Epoch 3: [4709/10940] ---- BYOL Training Loss = 0.35095176100730896
30-01-2023 18:16:44 INFO Epoch 3: [4709/10940] ---- BYOL Validation Loss = 0.299314945936203
30-01-2023 18:17:02 INFO Epoch 3: [4720/10940] ---- BYOL Training Loss = 0.35408592224121094
30-01-2023 18:17:20 INFO Epoch 3: [4731/10940] ---- BYOL Training Loss = 0.35169774293899536
30-01-2023 18:17:38 INFO Epoch 3: [4742/10940] ---- BYOL Training Loss = 0.33528321981430054
30-01-2023 18:17:56 INFO Epoch 3: [4753/10940] ---- BYOL Training Loss = 0.34551531076431274
30-01-2023 18:18:48 INFO Epoch 3: [4753/10940] ---- BYOL Validation Loss = 0.310858815908432
30-01-2023 18:19:06 INFO Epoch 3: [4764/10940] ---- BYOL Training Loss = 0.31223630905151367
30-01-2023 18:19:24 INFO Epoch 3: [4775/10940] ---- BYOL Training Loss = 0.3488788902759552
30-01-2023 18:19:42 INFO Epoch 3: [4786/10940] ---- BYOL Training Loss = 0.3419701159000397
30-01-2023 18:20:00 INFO Epoch 3: [4797/10940] ---- BYOL Training Loss = 0.32061249017715454
30-01-2023 18:20:52 INFO Epoch 3: [4797/10940] ---- BYOL Validation Loss = 0.30010515451431274
30-01-2023 18:21:10 INFO Epoch 3: [4808/10940] ---- BYOL Training Loss = 0.35697054862976074
30-01-2023 18:21:28 INFO Epoch 3: [4819/10940] ---- BYOL Training Loss = 0.32537245750427246
30-01-2023 18:21:46 INFO Epoch 3: [4830/10940] ---- BYOL Training Loss = 0.3068212866783142
30-01-2023 18:22:04 INFO Epoch 3: [4841/10940] ---- BYOL Training Loss = 0.3185799717903137
30-01-2023 18:22:56 INFO Epoch 3: [4841/10940] ---- BYOL Validation Loss = 0.29259008169174194
30-01-2023 18:23:14 INFO Epoch 3: [4852/10940] ---- BYOL Training Loss = 0.29144471883773804
30-01-2023 18:23:32 INFO Epoch 3: [4863/10940] ---- BYOL Training Loss = 0.36162450909614563
30-01-2023 18:23:50 INFO Epoch 3: [4874/10940] ---- BYOL Training Loss = 0.28063398599624634
30-01-2023 18:24:08 INFO Epoch 3: [4885/10940] ---- BYOL Training Loss = 0.28029999136924744
30-01-2023 18:25:00 INFO Epoch 3: [4885/10940] ---- BYOL Validation Loss = 0.29516032338142395
30-01-2023 18:25:18 INFO Epoch 3: [4896/10940] ---- BYOL Training Loss = 0.32477039098739624
30-01-2023 18:25:36 INFO Epoch 3: [4907/10940] ---- BYOL Training Loss = 0.29026341438293457
30-01-2023 18:25:54 INFO Epoch 3: [4918/10940] ---- BYOL Training Loss = 0.3829319179058075
30-01-2023 18:26:12 INFO Epoch 3: [4929/10940] ---- BYOL Training Loss = 0.3815374970436096
30-01-2023 18:27:04 INFO Epoch 3: [4929/10940] ---- BYOL Validation Loss = 0.2989102005958557
30-01-2023 18:27:22 INFO Epoch 3: [4940/10940] ---- BYOL Training Loss = 0.297677218914032
30-01-2023 18:27:40 INFO Epoch 3: [4951/10940] ---- BYOL Training Loss = 0.27853477001190186
30-01-2023 18:27:58 INFO Epoch 3: [4962/10940] ---- BYOL Training Loss = 0.2689844071865082
30-01-2023 18:28:15 INFO Epoch 3: [4973/10940] ---- BYOL Training Loss = 0.2501826882362366
30-01-2023 18:29:08 INFO Epoch 3: [4973/10940] ---- BYOL Validation Loss = 0.29973268508911133
30-01-2023 18:29:26 INFO Epoch 3: [4984/10940] ---- BYOL Training Loss = 0.2885662913322449
30-01-2023 18:29:44 INFO Epoch 3: [4995/10940] ---- BYOL Training Loss = 0.2731989622116089
30-01-2023 18:30:02 INFO Epoch 3: [5006/10940] ---- BYOL Training Loss = 0.30302783846855164
30-01-2023 18:30:19 INFO Epoch 3: [5017/10940] ---- BYOL Training Loss = 0.32442834973335266
30-01-2023 18:31:11 INFO Epoch 3: [5017/10940] ---- BYOL Validation Loss = 0.3027850091457367
30-01-2023 18:31:30 INFO Epoch 3: [5028/10940] ---- BYOL Training Loss = 0.3164827227592468
30-01-2023 18:31:48 INFO Epoch 3: [5039/10940] ---- BYOL Training Loss = 0.3401032090187073
30-01-2023 18:32:06 INFO Epoch 3: [5050/10940] ---- BYOL Training Loss = 0.2893070578575134
30-01-2023 18:32:23 INFO Epoch 3: [5061/10940] ---- BYOL Training Loss = 0.3069709539413452
30-01-2023 18:33:15 INFO Epoch 3: [5061/10940] ---- BYOL Validation Loss = 0.29508528113365173
30-01-2023 18:33:33 INFO Epoch 3: [5072/10940] ---- BYOL Training Loss = 0.3089481294155121
30-01-2023 18:33:51 INFO Epoch 3: [5083/10940] ---- BYOL Training Loss = 0.3177506625652313
30-01-2023 18:34:09 INFO Epoch 3: [5094/10940] ---- BYOL Training Loss = 0.3248319625854492
30-01-2023 18:34:27 INFO Epoch 3: [5105/10940] ---- BYOL Training Loss = 0.31763026118278503
30-01-2023 18:35:19 INFO Epoch 3: [5105/10940] ---- BYOL Validation Loss = 0.2983335554599762
30-01-2023 18:35:37 INFO Epoch 3: [5116/10940] ---- BYOL Training Loss = 0.2860262989997864
30-01-2023 18:35:55 INFO Epoch 3: [5127/10940] ---- BYOL Training Loss = 0.32714852690696716
30-01-2023 18:36:13 INFO Epoch 3: [5138/10940] ---- BYOL Training Loss = 0.3815799653530121
30-01-2023 18:36:31 INFO Epoch 3: [5149/10940] ---- BYOL Training Loss = 0.3108564019203186
30-01-2023 18:37:23 INFO Epoch 3: [5149/10940] ---- BYOL Validation Loss = 0.29338693618774414
30-01-2023 18:37:41 INFO Epoch 3: [5160/10940] ---- BYOL Training Loss = 0.25184646248817444
30-01-2023 18:37:59 INFO Epoch 3: [5171/10940] ---- BYOL Training Loss = 0.2645876705646515
30-01-2023 18:38:17 INFO Epoch 3: [5182/10940] ---- BYOL Training Loss = 0.3346302807331085
30-01-2023 18:38:35 INFO Epoch 3: [5193/10940] ---- BYOL Training Loss = 0.3226936161518097
30-01-2023 18:39:27 INFO Epoch 3: [5193/10940] ---- BYOL Validation Loss = 0.3066246807575226
30-01-2023 18:39:45 INFO Epoch 3: [5204/10940] ---- BYOL Training Loss = 0.3055141568183899
30-01-2023 18:40:03 INFO Epoch 3: [5215/10940] ---- BYOL Training Loss = 0.28880682587623596
30-01-2023 18:40:21 INFO Epoch 3: [5226/10940] ---- BYOL Training Loss = 0.2722545266151428
30-01-2023 18:40:39 INFO Epoch 3: [5237/10940] ---- BYOL Training Loss = 0.2404593527317047
30-01-2023 18:41:31 INFO Epoch 3: [5237/10940] ---- BYOL Validation Loss = 0.29848697781562805
30-01-2023 18:41:49 INFO Epoch 3: [5248/10940] ---- BYOL Training Loss = 0.30365878343582153
30-01-2023 18:42:06 INFO Epoch 3: [5259/10940] ---- BYOL Training Loss = 0.3296126425266266
30-01-2023 18:42:24 INFO Epoch 3: [5270/10940] ---- BYOL Training Loss = 0.33103084564208984
30-01-2023 18:42:43 INFO Epoch 3: [5281/10940] ---- BYOL Training Loss = 0.35628563165664673
30-01-2023 18:43:35 INFO Epoch 3: [5281/10940] ---- BYOL Validation Loss = 0.3002431094646454
30-01-2023 18:43:52 INFO Epoch 3: [5292/10940] ---- BYOL Training Loss = 0.34109610319137573
30-01-2023 18:44:11 INFO Epoch 3: [5303/10940] ---- BYOL Training Loss = 0.29296597838401794
30-01-2023 18:44:28 INFO Epoch 3: [5314/10940] ---- BYOL Training Loss = 0.30273622274398804
30-01-2023 18:44:47 INFO Epoch 3: [5325/10940] ---- BYOL Training Loss = 0.35151228308677673
30-01-2023 18:45:39 INFO Epoch 3: [5325/10940] ---- BYOL Validation Loss = 0.32110661268234253
30-01-2023 18:45:57 INFO Epoch 3: [5336/10940] ---- BYOL Training Loss = 0.30512478947639465
30-01-2023 18:46:15 INFO Epoch 3: [5347/10940] ---- BYOL Training Loss = 0.29330164194107056
30-01-2023 18:46:33 INFO Epoch 3: [5358/10940] ---- BYOL Training Loss = 0.31060001254081726
30-01-2023 18:46:50 INFO Epoch 3: [5369/10940] ---- BYOL Training Loss = 0.3416060507297516
30-01-2023 18:47:42 INFO Epoch 3: [5369/10940] ---- BYOL Validation Loss = 0.3001645505428314
30-01-2023 18:48:01 INFO Epoch 3: [5380/10940] ---- BYOL Training Loss = 0.3129635453224182
30-01-2023 18:48:18 INFO Epoch 3: [5391/10940] ---- BYOL Training Loss = 0.3053966760635376
30-01-2023 18:48:37 INFO Epoch 3: [5402/10940] ---- BYOL Training Loss = 0.32819873094558716
30-01-2023 18:48:55 INFO Epoch 3: [5413/10940] ---- BYOL Training Loss = 0.330566942691803
30-01-2023 18:49:47 INFO Epoch 3: [5413/10940] ---- BYOL Validation Loss = 0.31416893005371094
30-01-2023 18:50:05 INFO Epoch 3: [5424/10940] ---- BYOL Training Loss = 0.32641899585723877
30-01-2023 18:50:23 INFO Epoch 3: [5435/10940] ---- BYOL Training Loss = 0.3119645118713379
30-01-2023 18:50:41 INFO Epoch 3: [5446/10940] ---- BYOL Training Loss = 0.28265440464019775
30-01-2023 18:50:59 INFO Epoch 3: [5457/10940] ---- BYOL Training Loss = 0.2972675561904907
30-01-2023 18:51:51 INFO Epoch 3: [5457/10940] ---- BYOL Validation Loss = 0.3006613552570343
30-01-2023 18:52:09 INFO Epoch 3: [5468/10940] ---- BYOL Training Loss = 0.29418864846229553
30-01-2023 18:52:27 INFO Epoch 3: [5479/10940] ---- BYOL Training Loss = 0.3521954417228699
30-01-2023 18:52:45 INFO Epoch 3: [5490/10940] ---- BYOL Training Loss = 0.3409327566623688
30-01-2023 18:53:03 INFO Epoch 3: [5501/10940] ---- BYOL Training Loss = 0.3217747211456299
30-01-2023 18:53:55 INFO Epoch 3: [5501/10940] ---- BYOL Validation Loss = 0.2973747253417969
30-01-2023 18:54:13 INFO Epoch 3: [5512/10940] ---- BYOL Training Loss = 0.25919681787490845
30-01-2023 18:54:31 INFO Epoch 3: [5523/10940] ---- BYOL Training Loss = 0.3145471513271332
30-01-2023 18:54:49 INFO Epoch 3: [5534/10940] ---- BYOL Training Loss = 0.303625226020813
30-01-2023 18:55:07 INFO Epoch 3: [5545/10940] ---- BYOL Training Loss = 0.2805764675140381
30-01-2023 18:55:59 INFO Epoch 3: [5545/10940] ---- BYOL Validation Loss = 0.2906489968299866
30-01-2023 18:56:17 INFO Epoch 3: [5556/10940] ---- BYOL Training Loss = 0.2778280973434448
30-01-2023 18:56:35 INFO Epoch 3: [5567/10940] ---- BYOL Training Loss = 0.28950434923171997
30-01-2023 18:56:53 INFO Epoch 3: [5578/10940] ---- BYOL Training Loss = 0.3048824667930603
30-01-2023 18:57:11 INFO Epoch 3: [5589/10940] ---- BYOL Training Loss = 0.2975218594074249
30-01-2023 18:58:03 INFO Epoch 3: [5589/10940] ---- BYOL Validation Loss = 0.30070704221725464
30-01-2023 18:58:20 INFO Epoch 3: [5600/10940] ---- BYOL Training Loss = 0.24785974621772766
30-01-2023 18:58:39 INFO Epoch 3: [5611/10940] ---- BYOL Training Loss = 0.2889169752597809
30-01-2023 18:58:57 INFO Epoch 3: [5622/10940] ---- BYOL Training Loss = 0.33585208654403687
30-01-2023 18:59:15 INFO Epoch 3: [5633/10940] ---- BYOL Training Loss = 0.31443026661872864
30-01-2023 19:00:07 INFO Epoch 3: [5633/10940] ---- BYOL Validation Loss = 0.30092233419418335
30-01-2023 19:00:25 INFO Epoch 3: [5644/10940] ---- BYOL Training Loss = 0.2874774932861328
30-01-2023 19:00:43 INFO Epoch 3: [5655/10940] ---- BYOL Training Loss = 0.3054583668708801
30-01-2023 19:01:01 INFO Epoch 3: [5666/10940] ---- BYOL Training Loss = 0.2814905047416687
30-01-2023 19:01:19 INFO Epoch 3: [5677/10940] ---- BYOL Training Loss = 0.30028122663497925
30-01-2023 19:02:11 INFO Epoch 3: [5677/10940] ---- BYOL Validation Loss = 0.30435413122177124
30-01-2023 19:02:29 INFO Epoch 3: [5688/10940] ---- BYOL Training Loss = 0.3141452670097351
30-01-2023 19:02:47 INFO Epoch 3: [5699/10940] ---- BYOL Training Loss = 0.31051281094551086
30-01-2023 19:03:05 INFO Epoch 3: [5710/10940] ---- BYOL Training Loss = 0.33237773180007935
30-01-2023 19:03:23 INFO Epoch 3: [5721/10940] ---- BYOL Training Loss = 0.3258570432662964
30-01-2023 19:04:15 INFO Epoch 3: [5721/10940] ---- BYOL Validation Loss = 0.30361631512641907
30-01-2023 19:04:33 INFO Epoch 3: [5732/10940] ---- BYOL Training Loss = 0.30440405011177063
30-01-2023 19:04:51 INFO Epoch 3: [5743/10940] ---- BYOL Training Loss = 0.29597607254981995
30-01-2023 19:05:09 INFO Epoch 3: [5754/10940] ---- BYOL Training Loss = 0.27890172600746155
30-01-2023 19:05:27 INFO Epoch 3: [5765/10940] ---- BYOL Training Loss = 0.2682211697101593
30-01-2023 19:06:19 INFO Epoch 3: [5765/10940] ---- BYOL Validation Loss = 0.301065593957901
30-01-2023 19:06:37 INFO Epoch 3: [5776/10940] ---- BYOL Training Loss = 0.3668515384197235
30-01-2023 19:06:55 INFO Epoch 3: [5787/10940] ---- BYOL Training Loss = 0.38073208928108215
30-01-2023 19:07:13 INFO Epoch 3: [5798/10940] ---- BYOL Training Loss = 0.32010987401008606
30-01-2023 19:07:31 INFO Epoch 3: [5809/10940] ---- BYOL Training Loss = 0.2811291217803955
30-01-2023 19:08:23 INFO Epoch 3: [5809/10940] ---- BYOL Validation Loss = 0.2957881987094879
30-01-2023 19:08:41 INFO Epoch 3: [5820/10940] ---- BYOL Training Loss = 0.2927696108818054
30-01-2023 19:08:59 INFO Epoch 3: [5831/10940] ---- BYOL Training Loss = 0.3272259831428528
30-01-2023 19:09:17 INFO Epoch 3: [5842/10940] ---- BYOL Training Loss = 0.2876712679862976
30-01-2023 19:09:35 INFO Epoch 3: [5853/10940] ---- BYOL Training Loss = 0.3154050409793854
30-01-2023 19:10:27 INFO Epoch 3: [5853/10940] ---- BYOL Validation Loss = 0.3046853840351105
30-01-2023 19:10:45 INFO Epoch 3: [5864/10940] ---- BYOL Training Loss = 0.3042844235897064
30-01-2023 19:11:03 INFO Epoch 3: [5875/10940] ---- BYOL Training Loss = 0.2801629900932312
30-01-2023 19:11:21 INFO Epoch 3: [5886/10940] ---- BYOL Training Loss = 0.30728620290756226
30-01-2023 19:11:39 INFO Epoch 3: [5897/10940] ---- BYOL Training Loss = 0.342956006526947
30-01-2023 19:12:31 INFO Epoch 3: [5897/10940] ---- BYOL Validation Loss = 0.30327919125556946
30-01-2023 19:12:49 INFO Epoch 3: [5908/10940] ---- BYOL Training Loss = 0.31942984461784363
30-01-2023 19:13:08 INFO Epoch 3: [5919/10940] ---- BYOL Training Loss = 0.2940189242362976
30-01-2023 19:13:26 INFO Epoch 3: [5930/10940] ---- BYOL Training Loss = 0.27213892340660095
30-01-2023 19:13:44 INFO Epoch 3: [5941/10940] ---- BYOL Training Loss = 0.29489758610725403
30-01-2023 19:14:36 INFO Epoch 3: [5941/10940] ---- BYOL Validation Loss = 0.3013210594654083
30-01-2023 19:14:53 INFO Epoch 3: [5952/10940] ---- BYOL Training Loss = 0.3390507400035858
30-01-2023 19:15:12 INFO Epoch 3: [5963/10940] ---- BYOL Training Loss = 0.31208857893943787
30-01-2023 19:15:30 INFO Epoch 3: [5974/10940] ---- BYOL Training Loss = 0.2843564450740814
30-01-2023 19:15:48 INFO Epoch 3: [5985/10940] ---- BYOL Training Loss = 0.298544317483902
30-01-2023 19:16:40 INFO Epoch 3: [5985/10940] ---- BYOL Validation Loss = 0.3067161440849304
30-01-2023 19:16:57 INFO Epoch 3: [5996/10940] ---- BYOL Training Loss = 0.2843037545681
30-01-2023 19:17:16 INFO Epoch 3: [6007/10940] ---- BYOL Training Loss = 0.27552691102027893
30-01-2023 19:17:34 INFO Epoch 3: [6018/10940] ---- BYOL Training Loss = 0.2770313620567322
30-01-2023 19:17:52 INFO Epoch 3: [6029/10940] ---- BYOL Training Loss = 0.30558767914772034
30-01-2023 19:18:44 INFO Epoch 3: [6029/10940] ---- BYOL Validation Loss = 0.30128735303878784
30-01-2023 19:19:02 INFO Epoch 3: [6040/10940] ---- BYOL Training Loss = 0.28499674797058105
30-01-2023 19:19:20 INFO Epoch 3: [6051/10940] ---- BYOL Training Loss = 0.3592110276222229
30-01-2023 19:19:38 INFO Epoch 3: [6062/10940] ---- BYOL Training Loss = 0.3616231381893158
30-01-2023 19:19:56 INFO Epoch 3: [6073/10940] ---- BYOL Training Loss = 0.26499873399734497
30-01-2023 19:20:48 INFO Epoch 3: [6073/10940] ---- BYOL Validation Loss = 0.30801695585250854
30-01-2023 19:21:06 INFO Epoch 3: [6084/10940] ---- BYOL Training Loss = 0.3300766944885254
30-01-2023 19:21:24 INFO Epoch 3: [6095/10940] ---- BYOL Training Loss = 0.29544180631637573
30-01-2023 19:21:42 INFO Epoch 3: [6106/10940] ---- BYOL Training Loss = 0.23778016865253448
30-01-2023 19:22:00 INFO Epoch 3: [6117/10940] ---- BYOL Training Loss = 0.3080207407474518
30-01-2023 19:22:52 INFO Epoch 3: [6117/10940] ---- BYOL Validation Loss = 0.30307266116142273
30-01-2023 19:23:10 INFO Epoch 3: [6128/10940] ---- BYOL Training Loss = 0.3659669756889343
30-01-2023 19:23:28 INFO Epoch 3: [6139/10940] ---- BYOL Training Loss = 0.3343971073627472
30-01-2023 19:23:46 INFO Epoch 3: [6150/10940] ---- BYOL Training Loss = 0.2664721608161926
30-01-2023 19:24:04 INFO Epoch 3: [6161/10940] ---- BYOL Training Loss = 0.2741488218307495
30-01-2023 19:24:56 INFO Epoch 3: [6161/10940] ---- BYOL Validation Loss = 0.2983589172363281
30-01-2023 19:25:15 INFO Epoch 3: [6172/10940] ---- BYOL Training Loss = 0.30967381596565247
30-01-2023 19:25:33 INFO Epoch 3: [6183/10940] ---- BYOL Training Loss = 0.3091358542442322
30-01-2023 19:25:51 INFO Epoch 3: [6194/10940] ---- BYOL Training Loss = 0.29625585675239563
30-01-2023 19:26:09 INFO Epoch 3: [6205/10940] ---- BYOL Training Loss = 0.29633015394210815
30-01-2023 19:27:01 INFO Epoch 3: [6205/10940] ---- BYOL Validation Loss = 0.2937299311161041
30-01-2023 19:27:19 INFO Epoch 3: [6216/10940] ---- BYOL Training Loss = 0.30163922905921936
30-01-2023 19:27:37 INFO Epoch 3: [6227/10940] ---- BYOL Training Loss = 0.2799903154373169
30-01-2023 19:27:55 INFO Epoch 3: [6238/10940] ---- BYOL Training Loss = 0.27278584241867065
30-01-2023 19:28:14 INFO Epoch 3: [6249/10940] ---- BYOL Training Loss = 0.2752937972545624
30-01-2023 19:29:06 INFO Epoch 3: [6249/10940] ---- BYOL Validation Loss = 0.2975727617740631
30-01-2023 19:29:23 INFO Epoch 3: [6260/10940] ---- BYOL Training Loss = 0.26958948373794556
30-01-2023 19:29:42 INFO Epoch 3: [6271/10940] ---- BYOL Training Loss = 0.29543036222457886
30-01-2023 19:30:00 INFO Epoch 3: [6282/10940] ---- BYOL Training Loss = 0.2888406813144684
30-01-2023 19:30:18 INFO Epoch 3: [6293/10940] ---- BYOL Training Loss = 0.3039199709892273
30-01-2023 19:31:10 INFO Epoch 3: [6293/10940] ---- BYOL Validation Loss = 0.30253860354423523
30-01-2023 19:31:28 INFO Epoch 3: [6304/10940] ---- BYOL Training Loss = 0.27557554841041565
30-01-2023 19:31:47 INFO Epoch 3: [6315/10940] ---- BYOL Training Loss = 0.3067927360534668
30-01-2023 19:32:05 INFO Epoch 3: [6326/10940] ---- BYOL Training Loss = 0.3173482120037079
30-01-2023 19:32:23 INFO Epoch 3: [6337/10940] ---- BYOL Training Loss = 0.2907445430755615
30-01-2023 19:33:15 INFO Epoch 3: [6337/10940] ---- BYOL Validation Loss = 0.2930769920349121
30-01-2023 19:33:33 INFO Epoch 3: [6348/10940] ---- BYOL Training Loss = 0.29750198125839233
30-01-2023 19:33:51 INFO Epoch 3: [6359/10940] ---- BYOL Training Loss = 0.2873907685279846
30-01-2023 19:34:09 INFO Epoch 3: [6370/10940] ---- BYOL Training Loss = 0.28545963764190674
30-01-2023 19:34:27 INFO Epoch 3: [6381/10940] ---- BYOL Training Loss = 0.28815993666648865
30-01-2023 19:35:20 INFO Epoch 3: [6381/10940] ---- BYOL Validation Loss = 0.29662492871284485
30-01-2023 19:35:37 INFO Epoch 3: [6392/10940] ---- BYOL Training Loss = 0.26803362369537354
30-01-2023 19:35:55 INFO Epoch 3: [6403/10940] ---- BYOL Training Loss = 0.3044458031654358
30-01-2023 19:36:13 INFO Epoch 3: [6414/10940] ---- BYOL Training Loss = 0.29941999912261963
30-01-2023 19:36:32 INFO Epoch 3: [6425/10940] ---- BYOL Training Loss = 0.3324567377567291
30-01-2023 19:37:24 INFO Epoch 3: [6425/10940] ---- BYOL Validation Loss = 0.29457515478134155
30-01-2023 19:37:42 INFO Epoch 3: [6436/10940] ---- BYOL Training Loss = 0.349104106426239
30-01-2023 19:38:00 INFO Epoch 3: [6447/10940] ---- BYOL Training Loss = 0.3447529971599579
30-01-2023 19:38:19 INFO Epoch 3: [6458/10940] ---- BYOL Training Loss = 0.28355473279953003
30-01-2023 19:38:37 INFO Epoch 3: [6469/10940] ---- BYOL Training Loss = 0.27023953199386597
30-01-2023 19:39:29 INFO Epoch 3: [6469/10940] ---- BYOL Validation Loss = 0.30024904012680054
30-01-2023 19:39:47 INFO Epoch 3: [6480/10940] ---- BYOL Training Loss = 0.30721086263656616
30-01-2023 19:40:05 INFO Epoch 3: [6491/10940] ---- BYOL Training Loss = 0.3173232972621918
30-01-2023 19:40:23 INFO Epoch 3: [6502/10940] ---- BYOL Training Loss = 0.3262145519256592
30-01-2023 19:40:41 INFO Epoch 3: [6513/10940] ---- BYOL Training Loss = 0.2877783477306366
30-01-2023 19:41:33 INFO Epoch 3: [6513/10940] ---- BYOL Validation Loss = 0.3089335858821869
30-01-2023 19:41:51 INFO Epoch 3: [6524/10940] ---- BYOL Training Loss = 0.29247915744781494
30-01-2023 19:42:10 INFO Epoch 3: [6535/10940] ---- BYOL Training Loss = 0.279062956571579
30-01-2023 19:42:28 INFO Epoch 3: [6546/10940] ---- BYOL Training Loss = 0.2700170874595642
30-01-2023 19:42:46 INFO Epoch 3: [6557/10940] ---- BYOL Training Loss = 0.2549593448638916
30-01-2023 19:43:38 INFO Epoch 3: [6557/10940] ---- BYOL Validation Loss = 0.2969609797000885
30-01-2023 19:43:55 INFO Epoch 3: [6568/10940] ---- BYOL Training Loss = 0.2540581226348877
30-01-2023 19:44:14 INFO Epoch 3: [6579/10940] ---- BYOL Training Loss = 0.30745428800582886
30-01-2023 19:44:32 INFO Epoch 3: [6590/10940] ---- BYOL Training Loss = 0.3205869495868683
30-01-2023 19:44:50 INFO Epoch 3: [6601/10940] ---- BYOL Training Loss = 0.27201300859451294
30-01-2023 19:45:42 INFO Epoch 3: [6601/10940] ---- BYOL Validation Loss = 0.3007548749446869
30-01-2023 19:46:01 INFO Epoch 3: [6612/10940] ---- BYOL Training Loss = 0.28964459896087646
30-01-2023 19:46:19 INFO Epoch 3: [6623/10940] ---- BYOL Training Loss = 0.2996671199798584
30-01-2023 19:46:37 INFO Epoch 3: [6634/10940] ---- BYOL Training Loss = 0.2763369679450989
30-01-2023 19:46:55 INFO Epoch 3: [6645/10940] ---- BYOL Training Loss = 0.266021192073822
30-01-2023 19:47:48 INFO Epoch 3: [6645/10940] ---- BYOL Validation Loss = 0.2947736382484436
30-01-2023 19:48:05 INFO Epoch 3: [6656/10940] ---- BYOL Training Loss = 0.2738388776779175
30-01-2023 19:48:24 INFO Epoch 3: [6667/10940] ---- BYOL Training Loss = 0.31135445833206177
30-01-2023 19:48:42 INFO Epoch 3: [6678/10940] ---- BYOL Training Loss = 0.31870460510253906
30-01-2023 19:49:00 INFO Epoch 3: [6689/10940] ---- BYOL Training Loss = 0.2962504029273987
30-01-2023 19:49:52 INFO Epoch 3: [6689/10940] ---- BYOL Validation Loss = 0.29763397574424744
30-01-2023 19:50:10 INFO Epoch 3: [6700/10940] ---- BYOL Training Loss = 0.26432451605796814
30-01-2023 19:50:28 INFO Epoch 3: [6711/10940] ---- BYOL Training Loss = 0.3248683214187622
30-01-2023 19:50:47 INFO Epoch 3: [6722/10940] ---- BYOL Training Loss = 0.30555564165115356
30-01-2023 19:51:05 INFO Epoch 3: [6733/10940] ---- BYOL Training Loss = 0.2804298996925354
30-01-2023 19:51:57 INFO Epoch 3: [6733/10940] ---- BYOL Validation Loss = 0.2913784384727478
30-01-2023 19:52:15 INFO Epoch 3: [6744/10940] ---- BYOL Training Loss = 0.2549259066581726
30-01-2023 19:52:33 INFO Epoch 3: [6755/10940] ---- BYOL Training Loss = 0.28847748041152954
30-01-2023 19:52:51 INFO Epoch 3: [6766/10940] ---- BYOL Training Loss = 0.3289842903614044
30-01-2023 19:53:09 INFO Epoch 3: [6777/10940] ---- BYOL Training Loss = 0.3325933814048767
30-01-2023 19:54:01 INFO Epoch 3: [6777/10940] ---- BYOL Validation Loss = 0.2915414869785309
30-01-2023 19:54:19 INFO Epoch 3: [6788/10940] ---- BYOL Training Loss = 0.3123166263103485
30-01-2023 19:54:38 INFO Epoch 3: [6799/10940] ---- BYOL Training Loss = 0.3454435467720032
30-01-2023 19:54:56 INFO Epoch 3: [6810/10940] ---- BYOL Training Loss = 0.32495033740997314
30-01-2023 19:55:14 INFO Epoch 3: [6821/10940] ---- BYOL Training Loss = 0.2710188925266266
30-01-2023 19:56:06 INFO Epoch 3: [6821/10940] ---- BYOL Validation Loss = 0.2985478341579437
30-01-2023 19:56:24 INFO Epoch 3: [6832/10940] ---- BYOL Training Loss = 0.2710495591163635
30-01-2023 19:56:42 INFO Epoch 3: [6843/10940] ---- BYOL Training Loss = 0.30673107504844666
30-01-2023 19:57:00 INFO Epoch 3: [6854/10940] ---- BYOL Training Loss = 0.24900221824645996
30-01-2023 19:57:18 INFO Epoch 3: [6865/10940] ---- BYOL Training Loss = 0.24146930873394012
30-01-2023 19:58:11 INFO Epoch 3: [6865/10940] ---- BYOL Validation Loss = 0.2910344898700714
30-01-2023 19:58:29 INFO Epoch 3: [6876/10940] ---- BYOL Training Loss = 0.20737656950950623
30-01-2023 19:58:47 INFO Epoch 3: [6887/10940] ---- BYOL Training Loss = 0.2915927767753601
30-01-2023 19:59:05 INFO Epoch 3: [6898/10940] ---- BYOL Training Loss = 0.28711432218551636
30-01-2023 19:59:24 INFO Epoch 3: [6909/10940] ---- BYOL Training Loss = 0.26208096742630005
30-01-2023 20:00:16 INFO Epoch 3: [6909/10940] ---- BYOL Validation Loss = 0.286520391702652
30-01-2023 20:00:33 INFO Epoch 3: [6920/10940] ---- BYOL Training Loss = 0.28788214921951294
30-01-2023 20:00:51 INFO Epoch 3: [6931/10940] ---- BYOL Training Loss = 0.3347926735877991
30-01-2023 20:01:10 INFO Epoch 3: [6942/10940] ---- BYOL Training Loss = 0.3808539807796478
30-01-2023 20:01:28 INFO Epoch 3: [6953/10940] ---- BYOL Training Loss = 0.3320448398590088
30-01-2023 20:02:20 INFO Epoch 3: [6953/10940] ---- BYOL Validation Loss = 0.2917839586734772
30-01-2023 20:02:38 INFO Epoch 3: [6964/10940] ---- BYOL Training Loss = 0.3016362190246582
30-01-2023 20:02:56 INFO Epoch 3: [6975/10940] ---- BYOL Training Loss = 0.29219764471054077
30-01-2023 20:03:15 INFO Epoch 3: [6986/10940] ---- BYOL Training Loss = 0.2853718400001526
30-01-2023 20:03:33 INFO Epoch 3: [6997/10940] ---- BYOL Training Loss = 0.2997480630874634
30-01-2023 20:04:25 INFO Epoch 3: [6997/10940] ---- BYOL Validation Loss = 0.29718664288520813
30-01-2023 20:04:43 INFO Epoch 3: [7008/10940] ---- BYOL Training Loss = 0.2584673762321472
30-01-2023 20:05:01 INFO Epoch 3: [7019/10940] ---- BYOL Training Loss = 0.22689679265022278
30-01-2023 20:05:19 INFO Epoch 3: [7030/10940] ---- BYOL Training Loss = 0.3229121267795563
30-01-2023 20:05:38 INFO Epoch 3: [7041/10940] ---- BYOL Training Loss = 0.3349847197532654
30-01-2023 20:06:30 INFO Epoch 3: [7041/10940] ---- BYOL Validation Loss = 0.2933540940284729
30-01-2023 20:06:48 INFO Epoch 3: [7052/10940] ---- BYOL Training Loss = 0.2691674530506134
30-01-2023 20:07:06 INFO Epoch 3: [7063/10940] ---- BYOL Training Loss = 0.2710067927837372
30-01-2023 20:07:24 INFO Epoch 3: [7074/10940] ---- BYOL Training Loss = 0.27961817383766174
30-01-2023 20:07:42 INFO Epoch 3: [7085/10940] ---- BYOL Training Loss = 0.2781884968280792
30-01-2023 20:08:34 INFO Epoch 3: [7085/10940] ---- BYOL Validation Loss = 0.2953948378562927
30-01-2023 20:08:53 INFO Epoch 3: [7096/10940] ---- BYOL Training Loss = 0.2472858726978302
30-01-2023 20:09:11 INFO Epoch 3: [7107/10940] ---- BYOL Training Loss = 0.2415146827697754
30-01-2023 20:09:29 INFO Epoch 3: [7118/10940] ---- BYOL Training Loss = 0.25911280512809753
30-01-2023 20:09:47 INFO Epoch 3: [7129/10940] ---- BYOL Training Loss = 0.3166448771953583
30-01-2023 20:10:39 INFO Epoch 3: [7129/10940] ---- BYOL Validation Loss = 0.289318710565567
30-01-2023 20:10:57 INFO Epoch 3: [7140/10940] ---- BYOL Training Loss = 0.3091890513896942
30-01-2023 20:11:15 INFO Epoch 3: [7151/10940] ---- BYOL Training Loss = 0.27663454413414
30-01-2023 20:11:34 INFO Epoch 3: [7162/10940] ---- BYOL Training Loss = 0.28148260712623596
30-01-2023 20:11:52 INFO Epoch 3: [7173/10940] ---- BYOL Training Loss = 0.3325268626213074
30-01-2023 20:12:44 INFO Epoch 3: [7173/10940] ---- BYOL Validation Loss = 0.2931027114391327
30-01-2023 20:13:02 INFO Epoch 3: [7184/10940] ---- BYOL Training Loss = 0.37929078936576843
30-01-2023 20:13:20 INFO Epoch 3: [7195/10940] ---- BYOL Training Loss = 0.34821853041648865
30-01-2023 20:13:38 INFO Epoch 3: [7206/10940] ---- BYOL Training Loss = 0.2952192723751068
30-01-2023 20:13:57 INFO Epoch 3: [7217/10940] ---- BYOL Training Loss = 0.263559490442276
30-01-2023 20:14:49 INFO Epoch 3: [7217/10940] ---- BYOL Validation Loss = 0.2879123091697693
30-01-2023 20:15:07 INFO Epoch 3: [7228/10940] ---- BYOL Training Loss = 0.2885933220386505
30-01-2023 20:15:25 INFO Epoch 3: [7239/10940] ---- BYOL Training Loss = 0.2805666923522949
30-01-2023 20:15:43 INFO Epoch 3: [7250/10940] ---- BYOL Training Loss = 0.26828494668006897
30-01-2023 20:16:02 INFO Epoch 3: [7261/10940] ---- BYOL Training Loss = 0.32567906379699707
30-01-2023 20:16:54 INFO Epoch 3: [7261/10940] ---- BYOL Validation Loss = 0.29312896728515625
30-01-2023 20:17:12 INFO Epoch 3: [7272/10940] ---- BYOL Training Loss = 0.36523470282554626
30-01-2023 20:17:30 INFO Epoch 3: [7283/10940] ---- BYOL Training Loss = 0.31616443395614624
30-01-2023 20:17:48 INFO Epoch 3: [7294/10940] ---- BYOL Training Loss = 0.31892257928848267
30-01-2023 20:18:07 INFO Epoch 3: [7305/10940] ---- BYOL Training Loss = 0.30128806829452515
30-01-2023 20:18:59 INFO Epoch 3: [7305/10940] ---- BYOL Validation Loss = 0.28694894909858704
30-01-2023 20:19:17 INFO Epoch 3: [7316/10940] ---- BYOL Training Loss = 0.28781652450561523
30-01-2023 20:19:35 INFO Epoch 3: [7327/10940] ---- BYOL Training Loss = 0.30339285731315613
30-01-2023 20:19:54 INFO Epoch 3: [7338/10940] ---- BYOL Training Loss = 0.300790011882782
30-01-2023 20:20:12 INFO Epoch 3: [7349/10940] ---- BYOL Training Loss = 0.2768721282482147
30-01-2023 20:21:04 INFO Epoch 3: [7349/10940] ---- BYOL Validation Loss = 0.28875574469566345
30-01-2023 20:21:21 INFO Epoch 3: [7360/10940] ---- BYOL Training Loss = 0.3245200514793396
30-01-2023 20:21:40 INFO Epoch 3: [7371/10940] ---- BYOL Training Loss = 0.34988337755203247
30-01-2023 20:21:58 INFO Epoch 3: [7382/10940] ---- BYOL Training Loss = 0.3324623107910156
30-01-2023 20:22:17 INFO Epoch 3: [7393/10940] ---- BYOL Training Loss = 0.3552441895008087
30-01-2023 20:23:09 INFO Epoch 3: [7393/10940] ---- BYOL Validation Loss = 0.2992599904537201
30-01-2023 20:23:27 INFO Epoch 3: [7404/10940] ---- BYOL Training Loss = 0.300720751285553
30-01-2023 20:23:45 INFO Epoch 3: [7415/10940] ---- BYOL Training Loss = 0.23314432799816132
30-01-2023 20:24:03 INFO Epoch 3: [7426/10940] ---- BYOL Training Loss = 0.2694663405418396
30-01-2023 20:24:22 INFO Epoch 3: [7437/10940] ---- BYOL Training Loss = 0.3085176944732666
30-01-2023 20:25:14 INFO Epoch 3: [7437/10940] ---- BYOL Validation Loss = 0.2953244745731354
30-01-2023 20:25:32 INFO Epoch 3: [7448/10940] ---- BYOL Training Loss = 0.26395827531814575
30-01-2023 20:25:50 INFO Epoch 3: [7459/10940] ---- BYOL Training Loss = 0.2940213084220886
30-01-2023 20:26:08 INFO Epoch 3: [7470/10940] ---- BYOL Training Loss = 0.31046921014785767
30-01-2023 20:26:26 INFO Epoch 3: [7481/10940] ---- BYOL Training Loss = 0.2801143229007721
30-01-2023 20:27:18 INFO Epoch 3: [7481/10940] ---- BYOL Validation Loss = 0.2898678183555603
30-01-2023 20:27:36 INFO Epoch 3: [7492/10940] ---- BYOL Training Loss = 0.26289016008377075
30-01-2023 20:27:55 INFO Epoch 3: [7503/10940] ---- BYOL Training Loss = 0.3200034499168396
30-01-2023 20:28:13 INFO Epoch 3: [7514/10940] ---- BYOL Training Loss = 0.2900853753089905
30-01-2023 20:28:31 INFO Epoch 3: [7525/10940] ---- BYOL Training Loss = 0.3069499433040619
30-01-2023 20:29:23 INFO Epoch 3: [7525/10940] ---- BYOL Validation Loss = 0.2912347614765167
30-01-2023 20:29:41 INFO Epoch 3: [7536/10940] ---- BYOL Training Loss = 0.31112703680992126
30-01-2023 20:30:00 INFO Epoch 3: [7547/10940] ---- BYOL Training Loss = 0.275238573551178
30-01-2023 20:30:18 INFO Epoch 3: [7558/10940] ---- BYOL Training Loss = 0.27745354175567627
30-01-2023 20:30:37 INFO Epoch 3: [7569/10940] ---- BYOL Training Loss = 0.2805858254432678
30-01-2023 20:31:29 INFO Epoch 3: [7569/10940] ---- BYOL Validation Loss = 0.2981559932231903
30-01-2023 20:31:47 INFO Epoch 3: [7580/10940] ---- BYOL Training Loss = 0.2929913103580475
30-01-2023 20:32:05 INFO Epoch 3: [7591/10940] ---- BYOL Training Loss = 0.2757861316204071
30-01-2023 20:32:23 INFO Epoch 3: [7602/10940] ---- BYOL Training Loss = 0.2929128110408783
30-01-2023 20:32:41 INFO Epoch 3: [7613/10940] ---- BYOL Training Loss = 0.29497864842414856
30-01-2023 20:33:33 INFO Epoch 3: [7613/10940] ---- BYOL Validation Loss = 0.28990858793258667
30-01-2023 20:33:51 INFO Epoch 3: [7624/10940] ---- BYOL Training Loss = 0.2748226523399353
30-01-2023 20:34:09 INFO Epoch 3: [7635/10940] ---- BYOL Training Loss = 0.24836984276771545
30-01-2023 20:34:28 INFO Epoch 3: [7646/10940] ---- BYOL Training Loss = 0.32419243454933167
30-01-2023 20:34:46 INFO Epoch 3: [7657/10940] ---- BYOL Training Loss = 0.3410384953022003
30-01-2023 20:35:38 INFO Epoch 3: [7657/10940] ---- BYOL Validation Loss = 0.2949705719947815
30-01-2023 20:35:56 INFO Epoch 3: [7668/10940] ---- BYOL Training Loss = 0.30238381028175354
30-01-2023 20:36:15 INFO Epoch 3: [7679/10940] ---- BYOL Training Loss = 0.28343284130096436
30-01-2023 20:36:33 INFO Epoch 3: [7690/10940] ---- BYOL Training Loss = 0.2629314363002777
30-01-2023 20:36:51 INFO Epoch 3: [7701/10940] ---- BYOL Training Loss = 0.30825358629226685
30-01-2023 20:37:43 INFO Epoch 3: [7701/10940] ---- BYOL Validation Loss = 0.2920125126838684
30-01-2023 20:38:02 INFO Epoch 3: [7712/10940] ---- BYOL Training Loss = 0.3080584406852722
30-01-2023 20:38:20 INFO Epoch 3: [7723/10940] ---- BYOL Training Loss = 0.3208925426006317
30-01-2023 20:38:38 INFO Epoch 3: [7734/10940] ---- BYOL Training Loss = 0.34438130259513855
30-01-2023 20:38:57 INFO Epoch 3: [7745/10940] ---- BYOL Training Loss = 0.29143887758255005
30-01-2023 20:39:49 INFO Epoch 3: [7745/10940] ---- BYOL Validation Loss = 0.29328253865242004
30-01-2023 20:40:06 INFO Epoch 3: [7756/10940] ---- BYOL Training Loss = 0.27987372875213623
30-01-2023 20:40:25 INFO Epoch 3: [7767/10940] ---- BYOL Training Loss = 0.2779340445995331
30-01-2023 20:40:43 INFO Epoch 3: [7778/10940] ---- BYOL Training Loss = 0.2848474383354187
30-01-2023 20:41:01 INFO Epoch 3: [7789/10940] ---- BYOL Training Loss = 0.3877115845680237
30-01-2023 20:41:53 INFO Epoch 3: [7789/10940] ---- BYOL Validation Loss = 0.2968849539756775
30-01-2023 20:42:12 INFO Epoch 3: [7800/10940] ---- BYOL Training Loss = 0.39342302083969116
30-01-2023 20:42:30 INFO Epoch 3: [7811/10940] ---- BYOL Training Loss = 0.3140257000923157
30-01-2023 20:42:48 INFO Epoch 3: [7822/10940] ---- BYOL Training Loss = 0.2811267077922821
30-01-2023 20:43:07 INFO Epoch 3: [7833/10940] ---- BYOL Training Loss = 0.2859756648540497
30-01-2023 20:43:59 INFO Epoch 3: [7833/10940] ---- BYOL Validation Loss = 0.29456302523612976
30-01-2023 20:44:17 INFO Epoch 3: [7844/10940] ---- BYOL Training Loss = 0.3155490458011627
30-01-2023 20:44:35 INFO Epoch 3: [7855/10940] ---- BYOL Training Loss = 0.27819833159446716
30-01-2023 20:44:54 INFO Epoch 3: [7866/10940] ---- BYOL Training Loss = 0.3210619390010834
30-01-2023 20:45:12 INFO Epoch 3: [7877/10940] ---- BYOL Training Loss = 0.2746198773384094
30-01-2023 20:46:04 INFO Epoch 3: [7877/10940] ---- BYOL Validation Loss = 0.2791425585746765
30-01-2023 20:46:22 INFO Epoch 3: [7888/10940] ---- BYOL Training Loss = 0.24506697058677673
30-01-2023 20:46:41 INFO Epoch 3: [7899/10940] ---- BYOL Training Loss = 0.2963173985481262
30-01-2023 20:46:59 INFO Epoch 3: [7910/10940] ---- BYOL Training Loss = 0.27335765957832336
30-01-2023 20:47:17 INFO Epoch 3: [7921/10940] ---- BYOL Training Loss = 0.26687943935394287
30-01-2023 20:48:09 INFO Epoch 3: [7921/10940] ---- BYOL Validation Loss = 0.27997446060180664
30-01-2023 20:48:27 INFO Epoch 3: [7932/10940] ---- BYOL Training Loss = 0.30047741532325745
30-01-2023 20:48:46 INFO Epoch 3: [7943/10940] ---- BYOL Training Loss = 0.3499266505241394
30-01-2023 20:49:04 INFO Epoch 3: [7954/10940] ---- BYOL Training Loss = 0.3007100820541382
30-01-2023 20:49:23 INFO Epoch 3: [7965/10940] ---- BYOL Training Loss = 0.26096734404563904
30-01-2023 20:50:15 INFO Epoch 3: [7965/10940] ---- BYOL Validation Loss = 0.28271082043647766
30-01-2023 20:50:33 INFO Epoch 3: [7976/10940] ---- BYOL Training Loss = 0.2865518629550934
30-01-2023 20:50:51 INFO Epoch 3: [7987/10940] ---- BYOL Training Loss = 0.34015223383903503
30-01-2023 20:51:09 INFO Epoch 3: [7998/10940] ---- BYOL Training Loss = 0.35891085863113403
30-01-2023 20:51:28 INFO Epoch 3: [8009/10940] ---- BYOL Training Loss = 0.33759385347366333
30-01-2023 20:52:19 INFO Epoch 3: [8009/10940] ---- BYOL Validation Loss = 0.28902286291122437
30-01-2023 20:52:37 INFO Epoch 3: [8020/10940] ---- BYOL Training Loss = 0.2781088650226593
30-01-2023 20:52:56 INFO Epoch 3: [8031/10940] ---- BYOL Training Loss = 0.2989475429058075
30-01-2023 20:53:14 INFO Epoch 3: [8042/10940] ---- BYOL Training Loss = 0.2921563982963562
30-01-2023 20:53:32 INFO Epoch 3: [8053/10940] ---- BYOL Training Loss = 0.26799342036247253
30-01-2023 20:54:24 INFO Epoch 3: [8053/10940] ---- BYOL Validation Loss = 0.28874191641807556
30-01-2023 20:54:43 INFO Epoch 3: [8064/10940] ---- BYOL Training Loss = 0.2639661431312561
30-01-2023 20:55:01 INFO Epoch 3: [8075/10940] ---- BYOL Training Loss = 0.29527637362480164
30-01-2023 20:55:19 INFO Epoch 3: [8086/10940] ---- BYOL Training Loss = 0.3011649250984192
30-01-2023 20:55:38 INFO Epoch 3: [8097/10940] ---- BYOL Training Loss = 0.29057762026786804
30-01-2023 20:56:30 INFO Epoch 3: [8097/10940] ---- BYOL Validation Loss = 0.2910481095314026
30-01-2023 20:56:47 INFO Epoch 3: [8108/10940] ---- BYOL Training Loss = 0.30360180139541626
30-01-2023 20:57:06 INFO Epoch 3: [8119/10940] ---- BYOL Training Loss = 0.3336126208305359
30-01-2023 20:57:24 INFO Epoch 3: [8130/10940] ---- BYOL Training Loss = 0.3329750597476959
30-01-2023 20:57:43 INFO Epoch 3: [8141/10940] ---- BYOL Training Loss = 0.28239279985427856
30-01-2023 20:58:35 INFO Epoch 3: [8141/10940] ---- BYOL Validation Loss = 0.28719350695610046
30-01-2023 20:58:52 INFO Epoch 3: [8152/10940] ---- BYOL Training Loss = 0.27269962430000305
30-01-2023 20:59:11 INFO Epoch 3: [8163/10940] ---- BYOL Training Loss = 0.2899631857872009
30-01-2023 20:59:29 INFO Epoch 3: [8174/10940] ---- BYOL Training Loss = 0.24107758700847626
30-01-2023 20:59:48 INFO Epoch 3: [8185/10940] ---- BYOL Training Loss = 0.24932308495044708
30-01-2023 21:00:40 INFO Epoch 3: [8185/10940] ---- BYOL Validation Loss = 0.29906851053237915
30-01-2023 21:00:58 INFO Epoch 3: [8196/10940] ---- BYOL Training Loss = 0.2748713493347168
30-01-2023 21:01:16 INFO Epoch 3: [8207/10940] ---- BYOL Training Loss = 0.2976991534233093
30-01-2023 21:01:35 INFO Epoch 3: [8218/10940] ---- BYOL Training Loss = 0.29457828402519226
30-01-2023 21:01:53 INFO Epoch 3: [8229/10940] ---- BYOL Training Loss = 0.2521716356277466
30-01-2023 21:02:45 INFO Epoch 3: [8229/10940] ---- BYOL Validation Loss = 0.2982551157474518
30-01-2023 21:03:03 INFO Epoch 3: [8240/10940] ---- BYOL Training Loss = 0.26712125539779663
30-01-2023 21:03:21 INFO Epoch 3: [8251/10940] ---- BYOL Training Loss = 0.31109458208084106
30-01-2023 21:03:40 INFO Epoch 3: [8262/10940] ---- BYOL Training Loss = 0.295599102973938
30-01-2023 21:03:58 INFO Epoch 3: [8273/10940] ---- BYOL Training Loss = 0.23312798142433167
30-01-2023 21:04:50 INFO Epoch 3: [8273/10940] ---- BYOL Validation Loss = 0.27601999044418335
30-01-2023 21:05:08 INFO Epoch 3: [8284/10940] ---- BYOL Training Loss = 0.25289711356163025
30-01-2023 21:05:26 INFO Epoch 3: [8295/10940] ---- BYOL Training Loss = 0.3001938462257385
30-01-2023 21:05:44 INFO Epoch 3: [8306/10940] ---- BYOL Training Loss = 0.3121536374092102
30-01-2023 21:06:03 INFO Epoch 3: [8317/10940] ---- BYOL Training Loss = 0.30992352962493896
30-01-2023 21:06:55 INFO Epoch 3: [8317/10940] ---- BYOL Validation Loss = 0.28178849816322327
30-01-2023 21:07:13 INFO Epoch 3: [8328/10940] ---- BYOL Training Loss = 0.2663596272468567
30-01-2023 21:07:31 INFO Epoch 3: [8339/10940] ---- BYOL Training Loss = 0.252919465303421
30-01-2023 21:07:50 INFO Epoch 3: [8350/10940] ---- BYOL Training Loss = 0.2519572377204895
30-01-2023 21:08:08 INFO Epoch 3: [8361/10940] ---- BYOL Training Loss = 0.2543744444847107
30-01-2023 21:09:00 INFO Epoch 3: [8361/10940] ---- BYOL Validation Loss = 0.2806907296180725
30-01-2023 21:09:18 INFO Epoch 3: [8372/10940] ---- BYOL Training Loss = 0.27317044138908386
30-01-2023 21:09:36 INFO Epoch 3: [8383/10940] ---- BYOL Training Loss = 0.2421727180480957
30-01-2023 21:09:54 INFO Epoch 3: [8394/10940] ---- BYOL Training Loss = 0.2836708426475525
30-01-2023 21:10:13 INFO Epoch 3: [8405/10940] ---- BYOL Training Loss = 0.3052963316440582
30-01-2023 21:11:05 INFO Epoch 3: [8405/10940] ---- BYOL Validation Loss = 0.28656893968582153
30-01-2023 21:11:23 INFO Epoch 3: [8416/10940] ---- BYOL Training Loss = 0.3035462200641632
30-01-2023 21:11:41 INFO Epoch 3: [8427/10940] ---- BYOL Training Loss = 0.34025925397872925
30-01-2023 21:12:00 INFO Epoch 3: [8438/10940] ---- BYOL Training Loss = 0.29765450954437256
30-01-2023 21:12:18 INFO Epoch 3: [8449/10940] ---- BYOL Training Loss = 0.2090744972229004
30-01-2023 21:13:10 INFO Epoch 3: [8449/10940] ---- BYOL Validation Loss = 0.279428631067276
30-01-2023 21:13:27 INFO Epoch 3: [8460/10940] ---- BYOL Training Loss = 0.2405165731906891
30-01-2023 21:13:46 INFO Epoch 3: [8471/10940] ---- BYOL Training Loss = 0.293032705783844
30-01-2023 21:14:04 INFO Epoch 3: [8482/10940] ---- BYOL Training Loss = 0.30170702934265137
30-01-2023 21:14:22 INFO Epoch 3: [8493/10940] ---- BYOL Training Loss = 0.3021330237388611
30-01-2023 21:15:14 INFO Epoch 3: [8493/10940] ---- BYOL Validation Loss = 0.28435757756233215
30-01-2023 21:15:33 INFO Epoch 3: [8504/10940] ---- BYOL Training Loss = 0.29486408829689026
30-01-2023 21:15:51 INFO Epoch 3: [8515/10940] ---- BYOL Training Loss = 0.3211210370063782
30-01-2023 21:16:09 INFO Epoch 3: [8526/10940] ---- BYOL Training Loss = 0.29147735238075256
30-01-2023 21:16:28 INFO Epoch 3: [8537/10940] ---- BYOL Training Loss = 0.26592588424682617
30-01-2023 21:17:19 INFO Epoch 3: [8537/10940] ---- BYOL Validation Loss = 0.28909334540367126
30-01-2023 21:17:37 INFO Epoch 3: [8548/10940] ---- BYOL Training Loss = 0.2948768436908722
30-01-2023 21:17:56 INFO Epoch 3: [8559/10940] ---- BYOL Training Loss = 0.30210188031196594
30-01-2023 21:18:14 INFO Epoch 3: [8570/10940] ---- BYOL Training Loss = 0.27957597374916077
30-01-2023 21:18:32 INFO Epoch 3: [8581/10940] ---- BYOL Training Loss = 0.26442933082580566
30-01-2023 21:19:24 INFO Epoch 3: [8581/10940] ---- BYOL Validation Loss = 0.287626713514328
30-01-2023 21:19:42 INFO Epoch 3: [8592/10940] ---- BYOL Training Loss = 0.31716078519821167
30-01-2023 21:20:01 INFO Epoch 3: [8603/10940] ---- BYOL Training Loss = 0.3380260467529297
30-01-2023 21:20:19 INFO Epoch 3: [8614/10940] ---- BYOL Training Loss = 0.31502100825309753
30-01-2023 21:20:37 INFO Epoch 3: [8625/10940] ---- BYOL Training Loss = 0.26251593232154846
30-01-2023 21:21:29 INFO Epoch 3: [8625/10940] ---- BYOL Validation Loss = 0.28939002752304077
30-01-2023 21:21:47 INFO Epoch 3: [8636/10940] ---- BYOL Training Loss = 0.3201367259025574
30-01-2023 21:22:06 INFO Epoch 3: [8647/10940] ---- BYOL Training Loss = 0.32835519313812256
30-01-2023 21:22:24 INFO Epoch 3: [8658/10940] ---- BYOL Training Loss = 0.3146528899669647
30-01-2023 21:22:42 INFO Epoch 3: [8669/10940] ---- BYOL Training Loss = 0.2958967685699463
30-01-2023 21:23:34 INFO Epoch 3: [8669/10940] ---- BYOL Validation Loss = 0.2883482575416565
30-01-2023 21:23:52 INFO Epoch 3: [8680/10940] ---- BYOL Training Loss = 0.2763632833957672
30-01-2023 21:24:10 INFO Epoch 3: [8691/10940] ---- BYOL Training Loss = 0.30243000388145447
30-01-2023 21:24:29 INFO Epoch 3: [8702/10940] ---- BYOL Training Loss = 0.308395117521286
30-01-2023 21:24:47 INFO Epoch 3: [8713/10940] ---- BYOL Training Loss = 0.29779136180877686
30-01-2023 21:25:39 INFO Epoch 3: [8713/10940] ---- BYOL Validation Loss = 0.2815067768096924
30-01-2023 21:25:57 INFO Epoch 3: [8724/10940] ---- BYOL Training Loss = 0.3149735927581787
30-01-2023 21:26:15 INFO Epoch 3: [8735/10940] ---- BYOL Training Loss = 0.3251248598098755
30-01-2023 21:26:34 INFO Epoch 3: [8746/10940] ---- BYOL Training Loss = 0.313973605632782
30-01-2023 21:26:52 INFO Epoch 3: [8757/10940] ---- BYOL Training Loss = 0.32956117391586304
30-01-2023 21:27:44 INFO Epoch 3: [8757/10940] ---- BYOL Validation Loss = 0.2791360914707184
30-01-2023 21:28:02 INFO Epoch 3: [8768/10940] ---- BYOL Training Loss = 0.3007705807685852
30-01-2023 21:28:21 INFO Epoch 3: [8779/10940] ---- BYOL Training Loss = 0.2611459493637085
30-01-2023 21:28:39 INFO Epoch 3: [8790/10940] ---- BYOL Training Loss = 0.2783888876438141
30-01-2023 21:28:57 INFO Epoch 3: [8801/10940] ---- BYOL Training Loss = 0.270678848028183
30-01-2023 21:29:49 INFO Epoch 3: [8801/10940] ---- BYOL Validation Loss = 0.2911156713962555
30-01-2023 21:30:07 INFO Epoch 3: [8812/10940] ---- BYOL Training Loss = 0.2932920753955841
30-01-2023 21:30:25 INFO Epoch 3: [8823/10940] ---- BYOL Training Loss = 0.2901139557361603
30-01-2023 21:30:44 INFO Epoch 3: [8834/10940] ---- BYOL Training Loss = 0.2981296181678772
30-01-2023 21:31:02 INFO Epoch 3: [8845/10940] ---- BYOL Training Loss = 0.3130454421043396
30-01-2023 21:31:54 INFO Epoch 3: [8845/10940] ---- BYOL Validation Loss = 0.28709104657173157
30-01-2023 21:32:12 INFO Epoch 3: [8856/10940] ---- BYOL Training Loss = 0.279960960149765
30-01-2023 21:32:31 INFO Epoch 3: [8867/10940] ---- BYOL Training Loss = 0.2681480646133423
30-01-2023 21:32:49 INFO Epoch 3: [8878/10940] ---- BYOL Training Loss = 0.2973773777484894
30-01-2023 21:33:08 INFO Epoch 3: [8889/10940] ---- BYOL Training Loss = 0.2906559705734253
30-01-2023 21:34:00 INFO Epoch 3: [8889/10940] ---- BYOL Validation Loss = 0.28122273087501526
30-01-2023 21:34:18 INFO Epoch 3: [8900/10940] ---- BYOL Training Loss = 0.2594833970069885
30-01-2023 21:34:36 INFO Epoch 3: [8911/10940] ---- BYOL Training Loss = 0.2912557125091553
30-01-2023 21:34:54 INFO Epoch 3: [8922/10940] ---- BYOL Training Loss = 0.3050888776779175
30-01-2023 21:35:13 INFO Epoch 3: [8933/10940] ---- BYOL Training Loss = 0.3006945252418518
30-01-2023 21:36:04 INFO Epoch 3: [8933/10940] ---- BYOL Validation Loss = 0.28380683064460754
30-01-2023 21:36:23 INFO Epoch 3: [8944/10940] ---- BYOL Training Loss = 0.27482229471206665
30-01-2023 21:36:41 INFO Epoch 3: [8955/10940] ---- BYOL Training Loss = 0.28196531534194946
30-01-2023 21:36:59 INFO Epoch 3: [8966/10940] ---- BYOL Training Loss = 0.2841140925884247
30-01-2023 21:37:18 INFO Epoch 3: [8977/10940] ---- BYOL Training Loss = 0.30727943778038025
30-01-2023 21:38:10 INFO Epoch 3: [8977/10940] ---- BYOL Validation Loss = 0.28151431679725647
30-01-2023 21:38:28 INFO Epoch 3: [8988/10940] ---- BYOL Training Loss = 0.3101176917552948
30-01-2023 21:38:46 INFO Epoch 3: [8999/10940] ---- BYOL Training Loss = 0.2905328869819641
30-01-2023 21:39:05 INFO Epoch 3: [9010/10940] ---- BYOL Training Loss = 0.2831256091594696
30-01-2023 21:39:23 INFO Epoch 3: [9021/10940] ---- BYOL Training Loss = 0.25638866424560547
30-01-2023 21:40:15 INFO Epoch 3: [9021/10940] ---- BYOL Validation Loss = 0.27808454632759094
30-01-2023 21:40:33 INFO Epoch 3: [9032/10940] ---- BYOL Training Loss = 0.2677108943462372
30-01-2023 21:40:51 INFO Epoch 3: [9043/10940] ---- BYOL Training Loss = 0.23625466227531433
30-01-2023 21:41:10 INFO Epoch 3: [9054/10940] ---- BYOL Training Loss = 0.2648952603340149
30-01-2023 21:41:28 INFO Epoch 3: [9065/10940] ---- BYOL Training Loss = 0.26498305797576904
30-01-2023 21:42:20 INFO Epoch 3: [9065/10940] ---- BYOL Validation Loss = 0.2817174792289734
30-01-2023 21:42:38 INFO Epoch 3: [9076/10940] ---- BYOL Training Loss = 0.2877752482891083
30-01-2023 21:42:57 INFO Epoch 3: [9087/10940] ---- BYOL Training Loss = 0.3597277104854584
30-01-2023 21:43:15 INFO Epoch 3: [9098/10940] ---- BYOL Training Loss = 0.32296493649482727
30-01-2023 21:43:34 INFO Epoch 3: [9109/10940] ---- BYOL Training Loss = 0.30874985456466675
30-01-2023 21:44:25 INFO Epoch 3: [9109/10940] ---- BYOL Validation Loss = 0.2896752655506134
30-01-2023 21:44:43 INFO Epoch 3: [9120/10940] ---- BYOL Training Loss = 0.3288589119911194
30-01-2023 21:45:01 INFO Epoch 3: [9131/10940] ---- BYOL Training Loss = 0.32828372716903687
30-01-2023 21:45:20 INFO Epoch 3: [9142/10940] ---- BYOL Training Loss = 0.33370241522789
30-01-2023 21:45:39 INFO Epoch 3: [9153/10940] ---- BYOL Training Loss = 0.29399099946022034
30-01-2023 21:46:30 INFO Epoch 3: [9153/10940] ---- BYOL Validation Loss = 0.2840721011161804
30-01-2023 21:46:48 INFO Epoch 3: [9164/10940] ---- BYOL Training Loss = 0.27103641629219055
30-01-2023 21:47:07 INFO Epoch 3: [9175/10940] ---- BYOL Training Loss = 0.23042985796928406
30-01-2023 21:47:25 INFO Epoch 3: [9186/10940] ---- BYOL Training Loss = 0.2526249587535858
30-01-2023 21:47:44 INFO Epoch 3: [9197/10940] ---- BYOL Training Loss = 0.2838061451911926
30-01-2023 21:48:36 INFO Epoch 3: [9197/10940] ---- BYOL Validation Loss = 0.29259467124938965
30-01-2023 21:48:53 INFO Epoch 3: [9208/10940] ---- BYOL Training Loss = 0.2898187041282654
30-01-2023 21:49:12 INFO Epoch 3: [9219/10940] ---- BYOL Training Loss = 0.3278929591178894
30-01-2023 21:49:30 INFO Epoch 3: [9230/10940] ---- BYOL Training Loss = 0.2995683252811432
30-01-2023 21:49:49 INFO Epoch 3: [9241/10940] ---- BYOL Training Loss = 0.24474993348121643
30-01-2023 21:50:40 INFO Epoch 3: [9241/10940] ---- BYOL Validation Loss = 0.28305941820144653
30-01-2023 21:50:59 INFO Epoch 3: [9252/10940] ---- BYOL Training Loss = 0.27842190861701965
30-01-2023 21:51:17 INFO Epoch 3: [9263/10940] ---- BYOL Training Loss = 0.30655235052108765
30-01-2023 21:51:35 INFO Epoch 3: [9274/10940] ---- BYOL Training Loss = 0.2791290879249573
30-01-2023 21:51:54 INFO Epoch 3: [9285/10940] ---- BYOL Training Loss = 0.2767563760280609
30-01-2023 21:52:46 INFO Epoch 3: [9285/10940] ---- BYOL Validation Loss = 0.277226984500885
30-01-2023 21:53:04 INFO Epoch 3: [9296/10940] ---- BYOL Training Loss = 0.2784040570259094
30-01-2023 21:53:23 INFO Epoch 3: [9307/10940] ---- BYOL Training Loss = 0.24302184581756592
30-01-2023 21:53:41 INFO Epoch 3: [9318/10940] ---- BYOL Training Loss = 0.22598202526569366
30-01-2023 21:53:59 INFO Epoch 3: [9329/10940] ---- BYOL Training Loss = 0.2854190468788147
30-01-2023 21:54:51 INFO Epoch 3: [9329/10940] ---- BYOL Validation Loss = 0.2806311249732971
30-01-2023 21:55:09 INFO Epoch 3: [9340/10940] ---- BYOL Training Loss = 0.3192957043647766
30-01-2023 21:55:27 INFO Epoch 3: [9351/10940] ---- BYOL Training Loss = 0.3078375458717346
30-01-2023 21:55:46 INFO Epoch 3: [9362/10940] ---- BYOL Training Loss = 0.3110102713108063
30-01-2023 21:56:04 INFO Epoch 3: [9373/10940] ---- BYOL Training Loss = 0.27923157811164856
30-01-2023 21:56:56 INFO Epoch 3: [9373/10940] ---- BYOL Validation Loss = 0.2755896747112274
30-01-2023 21:57:15 INFO Epoch 3: [9384/10940] ---- BYOL Training Loss = 0.2605088949203491
30-01-2023 21:57:33 INFO Epoch 3: [9395/10940] ---- BYOL Training Loss = 0.2947883903980255
30-01-2023 21:57:51 INFO Epoch 3: [9406/10940] ---- BYOL Training Loss = 0.27725186944007874
30-01-2023 21:58:10 INFO Epoch 3: [9417/10940] ---- BYOL Training Loss = 0.27741825580596924
30-01-2023 21:59:02 INFO Epoch 3: [9417/10940] ---- BYOL Validation Loss = 0.27482089400291443
30-01-2023 21:59:20 INFO Epoch 3: [9428/10940] ---- BYOL Training Loss = 0.2928338944911957
30-01-2023 21:59:38 INFO Epoch 3: [9439/10940] ---- BYOL Training Loss = 0.2962815761566162
30-01-2023 21:59:57 INFO Epoch 3: [9450/10940] ---- BYOL Training Loss = 0.32160621881484985
30-01-2023 22:00:15 INFO Epoch 3: [9461/10940] ---- BYOL Training Loss = 0.2527490556240082
30-01-2023 22:01:07 INFO Epoch 3: [9461/10940] ---- BYOL Validation Loss = 0.27014589309692383
30-01-2023 22:01:25 INFO Epoch 3: [9472/10940] ---- BYOL Training Loss = 0.25217992067337036
30-01-2023 22:01:44 INFO Epoch 3: [9483/10940] ---- BYOL Training Loss = 0.27887290716171265
30-01-2023 22:02:02 INFO Epoch 3: [9494/10940] ---- BYOL Training Loss = 0.3188342750072479
30-01-2023 22:02:20 INFO Epoch 3: [9505/10940] ---- BYOL Training Loss = 0.329499214887619
30-01-2023 22:03:12 INFO Epoch 3: [9505/10940] ---- BYOL Validation Loss = 0.2715975046157837
30-01-2023 22:03:30 INFO Epoch 3: [9516/10940] ---- BYOL Training Loss = 0.34095126390457153
30-01-2023 22:03:49 INFO Epoch 3: [9527/10940] ---- BYOL Training Loss = 0.29843461513519287
30-01-2023 22:04:07 INFO Epoch 3: [9538/10940] ---- BYOL Training Loss = 0.21898476779460907
30-01-2023 22:04:26 INFO Epoch 3: [9549/10940] ---- BYOL Training Loss = 0.23453502357006073
30-01-2023 22:05:18 INFO Epoch 3: [9549/10940] ---- BYOL Validation Loss = 0.2811308801174164
30-01-2023 22:05:36 INFO Epoch 3: [9560/10940] ---- BYOL Training Loss = 0.2555539309978485
30-01-2023 22:05:55 INFO Epoch 3: [9571/10940] ---- BYOL Training Loss = 0.2644670009613037
30-01-2023 22:06:13 INFO Epoch 3: [9582/10940] ---- BYOL Training Loss = 0.26334068179130554
30-01-2023 22:06:31 INFO Epoch 3: [9593/10940] ---- BYOL Training Loss = 0.25208571553230286
30-01-2023 22:07:23 INFO Epoch 3: [9593/10940] ---- BYOL Validation Loss = 0.27268463373184204
30-01-2023 22:07:41 INFO Epoch 3: [9604/10940] ---- BYOL Training Loss = 0.2963482737541199
30-01-2023 22:08:00 INFO Epoch 3: [9615/10940] ---- BYOL Training Loss = 0.2884179949760437
30-01-2023 22:08:18 INFO Epoch 3: [9626/10940] ---- BYOL Training Loss = 0.2985365092754364
30-01-2023 22:08:37 INFO Epoch 3: [9637/10940] ---- BYOL Training Loss = 0.2991200089454651
30-01-2023 22:09:29 INFO Epoch 3: [9637/10940] ---- BYOL Validation Loss = 0.2740815281867981
30-01-2023 22:09:47 INFO Epoch 3: [9648/10940] ---- BYOL Training Loss = 0.2482360303401947
30-01-2023 22:10:05 INFO Epoch 3: [9659/10940] ---- BYOL Training Loss = 0.257303386926651
30-01-2023 22:10:24 INFO Epoch 3: [9670/10940] ---- BYOL Training Loss = 0.22839736938476562
30-01-2023 22:10:42 INFO Epoch 3: [9681/10940] ---- BYOL Training Loss = 0.2558836340904236
30-01-2023 22:11:34 INFO Epoch 3: [9681/10940] ---- BYOL Validation Loss = 0.2770986258983612
30-01-2023 22:11:52 INFO Epoch 3: [9692/10940] ---- BYOL Training Loss = 0.26891323924064636
30-01-2023 22:12:11 INFO Epoch 3: [9703/10940] ---- BYOL Training Loss = 0.2831741273403168
30-01-2023 22:12:29 INFO Epoch 3: [9714/10940] ---- BYOL Training Loss = 0.25964048504829407
30-01-2023 22:12:48 INFO Epoch 3: [9725/10940] ---- BYOL Training Loss = 0.24851056933403015
30-01-2023 22:13:39 INFO Epoch 3: [9725/10940] ---- BYOL Validation Loss = 0.28646087646484375
30-01-2023 22:13:58 INFO Epoch 3: [9736/10940] ---- BYOL Training Loss = 0.28688448667526245
30-01-2023 22:14:16 INFO Epoch 3: [9747/10940] ---- BYOL Training Loss = 0.29810479283332825
30-01-2023 22:14:35 INFO Epoch 3: [9758/10940] ---- BYOL Training Loss = 0.31876689195632935
30-01-2023 22:14:53 INFO Epoch 3: [9769/10940] ---- BYOL Training Loss = 0.29233554005622864
30-01-2023 22:15:45 INFO Epoch 3: [9769/10940] ---- BYOL Validation Loss = 0.27647241950035095
30-01-2023 22:16:03 INFO Epoch 3: [9780/10940] ---- BYOL Training Loss = 0.28359323740005493
30-01-2023 22:16:22 INFO Epoch 3: [9791/10940] ---- BYOL Training Loss = 0.26987725496292114
30-01-2023 22:16:41 INFO Epoch 3: [9802/10940] ---- BYOL Training Loss = 0.27512291073799133
30-01-2023 22:16:59 INFO Epoch 3: [9813/10940] ---- BYOL Training Loss = 0.28316599130630493
30-01-2023 22:17:51 INFO Epoch 3: [9813/10940] ---- BYOL Validation Loss = 0.28353551030158997
30-01-2023 22:18:09 INFO Epoch 3: [9824/10940] ---- BYOL Training Loss = 0.30021652579307556
30-01-2023 22:18:28 INFO Epoch 3: [9835/10940] ---- BYOL Training Loss = 0.27803394198417664
30-01-2023 22:18:46 INFO Epoch 3: [9846/10940] ---- BYOL Training Loss = 0.2718788981437683
30-01-2023 22:19:05 INFO Epoch 3: [9857/10940] ---- BYOL Training Loss = 0.2987692058086395
30-01-2023 22:19:57 INFO Epoch 3: [9857/10940] ---- BYOL Validation Loss = 0.2814823091030121
30-01-2023 22:20:15 INFO Epoch 3: [9868/10940] ---- BYOL Training Loss = 0.3332131505012512
30-01-2023 22:20:33 INFO Epoch 3: [9879/10940] ---- BYOL Training Loss = 0.32410457730293274
30-01-2023 22:20:52 INFO Epoch 3: [9890/10940] ---- BYOL Training Loss = 0.2776177227497101
30-01-2023 22:21:10 INFO Epoch 3: [9901/10940] ---- BYOL Training Loss = 0.2891993224620819
30-01-2023 22:22:02 INFO Epoch 3: [9901/10940] ---- BYOL Validation Loss = 0.27685004472732544
30-01-2023 22:22:20 INFO Epoch 3: [9912/10940] ---- BYOL Training Loss = 0.28244608640670776
30-01-2023 22:22:39 INFO Epoch 3: [9923/10940] ---- BYOL Training Loss = 0.29607847332954407
30-01-2023 22:22:57 INFO Epoch 3: [9934/10940] ---- BYOL Training Loss = 0.2897174060344696
30-01-2023 22:23:16 INFO Epoch 3: [9945/10940] ---- BYOL Training Loss = 0.29666632413864136
30-01-2023 22:24:08 INFO Epoch 3: [9945/10940] ---- BYOL Validation Loss = 0.2717631161212921
30-01-2023 22:24:26 INFO Epoch 3: [9956/10940] ---- BYOL Training Loss = 0.34446364641189575
30-01-2023 22:24:44 INFO Epoch 3: [9967/10940] ---- BYOL Training Loss = 0.3213636577129364
30-01-2023 22:25:03 INFO Epoch 3: [9978/10940] ---- BYOL Training Loss = 0.305297315120697
30-01-2023 22:25:21 INFO Epoch 3: [9989/10940] ---- BYOL Training Loss = 0.30867794156074524
30-01-2023 22:26:13 INFO Epoch 3: [9989/10940] ---- BYOL Validation Loss = 0.27355656027793884
30-01-2023 22:26:32 INFO Epoch 3: [10000/10940] ---- BYOL Training Loss = 0.28350314497947693
30-01-2023 22:26:50 INFO Epoch 3: [10011/10940] ---- BYOL Training Loss = 0.28591638803482056
30-01-2023 22:27:09 INFO Epoch 3: [10022/10940] ---- BYOL Training Loss = 0.3196784257888794
30-01-2023 22:27:27 INFO Epoch 3: [10033/10940] ---- BYOL Training Loss = 0.31512343883514404
30-01-2023 22:28:19 INFO Epoch 3: [10033/10940] ---- BYOL Validation Loss = 0.2773325443267822
30-01-2023 22:28:37 INFO Epoch 3: [10044/10940] ---- BYOL Training Loss = 0.2964382767677307
30-01-2023 22:28:56 INFO Epoch 3: [10055/10940] ---- BYOL Training Loss = 0.2847479581832886
30-01-2023 22:29:14 INFO Epoch 3: [10066/10940] ---- BYOL Training Loss = 0.2591158449649811
30-01-2023 22:29:33 INFO Epoch 3: [10077/10940] ---- BYOL Training Loss = 0.3173871338367462
30-01-2023 22:30:25 INFO Epoch 3: [10077/10940] ---- BYOL Validation Loss = 0.28180617094039917
30-01-2023 22:30:43 INFO Epoch 3: [10088/10940] ---- BYOL Training Loss = 0.32261523604393005
30-01-2023 22:31:01 INFO Epoch 3: [10099/10940] ---- BYOL Training Loss = 0.33615589141845703
30-01-2023 22:31:20 INFO Epoch 3: [10110/10940] ---- BYOL Training Loss = 0.31874048709869385
30-01-2023 22:31:38 INFO Epoch 3: [10121/10940] ---- BYOL Training Loss = 0.30741262435913086
30-01-2023 22:32:30 INFO Epoch 3: [10121/10940] ---- BYOL Validation Loss = 0.2821981608867645
30-01-2023 22:32:49 INFO Epoch 3: [10132/10940] ---- BYOL Training Loss = 0.31389421224594116
30-01-2023 22:33:07 INFO Epoch 3: [10143/10940] ---- BYOL Training Loss = 0.2715684771537781
30-01-2023 22:33:26 INFO Epoch 3: [10154/10940] ---- BYOL Training Loss = 0.21874037384986877
30-01-2023 22:33:44 INFO Epoch 3: [10165/10940] ---- BYOL Training Loss = 0.23666389286518097
30-01-2023 22:34:36 INFO Epoch 3: [10165/10940] ---- BYOL Validation Loss = 0.2696303427219391
30-01-2023 22:34:54 INFO Epoch 3: [10176/10940] ---- BYOL Training Loss = 0.2521865665912628
30-01-2023 22:35:13 INFO Epoch 3: [10187/10940] ---- BYOL Training Loss = 0.25797420740127563
30-01-2023 22:35:31 INFO Epoch 3: [10198/10940] ---- BYOL Training Loss = 0.2837046980857849
30-01-2023 22:35:50 INFO Epoch 3: [10209/10940] ---- BYOL Training Loss = 0.2990669012069702
30-01-2023 22:36:42 INFO Epoch 3: [10209/10940] ---- BYOL Validation Loss = 0.2738102078437805
30-01-2023 22:37:00 INFO Epoch 3: [10220/10940] ---- BYOL Training Loss = 0.2795533239841461
30-01-2023 22:37:19 INFO Epoch 3: [10231/10940] ---- BYOL Training Loss = 0.2614946961402893
30-01-2023 22:37:37 INFO Epoch 3: [10242/10940] ---- BYOL Training Loss = 0.2869158983230591
30-01-2023 22:37:56 INFO Epoch 3: [10253/10940] ---- BYOL Training Loss = 0.3059355914592743
30-01-2023 22:38:48 INFO Epoch 3: [10253/10940] ---- BYOL Validation Loss = 0.2773227393627167
30-01-2023 22:39:06 INFO Epoch 3: [10264/10940] ---- BYOL Training Loss = 0.30230915546417236
30-01-2023 22:39:25 INFO Epoch 3: [10275/10940] ---- BYOL Training Loss = 0.25219956040382385
30-01-2023 22:39:43 INFO Epoch 3: [10286/10940] ---- BYOL Training Loss = 0.27976399660110474
30-01-2023 22:40:01 INFO Epoch 3: [10297/10940] ---- BYOL Training Loss = 0.2963508665561676
30-01-2023 22:40:53 INFO Epoch 3: [10297/10940] ---- BYOL Validation Loss = 0.28058192133903503
30-01-2023 22:41:11 INFO Epoch 3: [10308/10940] ---- BYOL Training Loss = 0.2770244777202606
30-01-2023 22:41:30 INFO Epoch 3: [10319/10940] ---- BYOL Training Loss = 0.2603611350059509
30-01-2023 22:41:49 INFO Epoch 3: [10330/10940] ---- BYOL Training Loss = 0.2689506709575653
30-01-2023 22:42:07 INFO Epoch 3: [10341/10940] ---- BYOL Training Loss = 0.28686997294425964
30-01-2023 22:42:59 INFO Epoch 3: [10341/10940] ---- BYOL Validation Loss = 0.2879033088684082
30-01-2023 22:43:17 INFO Epoch 3: [10352/10940] ---- BYOL Training Loss = 0.3069201111793518
30-01-2023 22:43:36 INFO Epoch 3: [10363/10940] ---- BYOL Training Loss = 0.34400564432144165
30-01-2023 22:43:55 INFO Epoch 3: [10374/10940] ---- BYOL Training Loss = 0.323245644569397
30-01-2023 22:44:13 INFO Epoch 3: [10385/10940] ---- BYOL Training Loss = 0.25894373655319214
30-01-2023 22:45:05 INFO Epoch 3: [10385/10940] ---- BYOL Validation Loss = 0.27660927176475525
30-01-2023 22:45:23 INFO Epoch 3: [10396/10940] ---- BYOL Training Loss = 0.3043205142021179
30-01-2023 22:45:42 INFO Epoch 3: [10407/10940] ---- BYOL Training Loss = 0.33367016911506653
30-01-2023 22:46:00 INFO Epoch 3: [10418/10940] ---- BYOL Training Loss = 0.2794049382209778
30-01-2023 22:46:19 INFO Epoch 3: [10429/10940] ---- BYOL Training Loss = 0.2584958076477051
30-01-2023 22:47:11 INFO Epoch 3: [10429/10940] ---- BYOL Validation Loss = 0.27954837679862976
30-01-2023 22:47:29 INFO Epoch 3: [10440/10940] ---- BYOL Training Loss = 0.2817072570323944
30-01-2023 22:47:47 INFO Epoch 3: [10451/10940] ---- BYOL Training Loss = 0.2774195075035095
30-01-2023 22:48:06 INFO Epoch 3: [10462/10940] ---- BYOL Training Loss = 0.28568387031555176
30-01-2023 22:48:25 INFO Epoch 3: [10473/10940] ---- BYOL Training Loss = 0.26840659976005554
30-01-2023 22:49:16 INFO Epoch 3: [10473/10940] ---- BYOL Validation Loss = 0.2770819664001465
30-01-2023 22:49:34 INFO Epoch 3: [10484/10940] ---- BYOL Training Loss = 0.24031749367713928
30-01-2023 22:49:53 INFO Epoch 3: [10495/10940] ---- BYOL Training Loss = 0.322961688041687
30-01-2023 22:50:12 INFO Epoch 3: [10506/10940] ---- BYOL Training Loss = 0.27322059869766235
30-01-2023 22:50:30 INFO Epoch 3: [10517/10940] ---- BYOL Training Loss = 0.26732581853866577
30-01-2023 22:51:22 INFO Epoch 3: [10517/10940] ---- BYOL Validation Loss = 0.27445104718208313
30-01-2023 22:51:40 INFO Epoch 3: [10528/10940] ---- BYOL Training Loss = 0.28541749715805054
30-01-2023 22:51:59 INFO Epoch 3: [10539/10940] ---- BYOL Training Loss = 0.27832743525505066
30-01-2023 22:52:18 INFO Epoch 3: [10550/10940] ---- BYOL Training Loss = 0.29149752855300903
30-01-2023 22:52:36 INFO Epoch 3: [10561/10940] ---- BYOL Training Loss = 0.29396218061447144
30-01-2023 22:53:28 INFO Epoch 3: [10561/10940] ---- BYOL Validation Loss = 0.27671903371810913
30-01-2023 22:53:46 INFO Epoch 3: [10572/10940] ---- BYOL Training Loss = 0.29297736287117004
30-01-2023 22:54:05 INFO Epoch 3: [10583/10940] ---- BYOL Training Loss = 0.2940727770328522
30-01-2023 22:54:23 INFO Epoch 3: [10594/10940] ---- BYOL Training Loss = 0.2392244040966034
30-01-2023 22:54:42 INFO Epoch 3: [10605/10940] ---- BYOL Training Loss = 0.24637119472026825
30-01-2023 22:55:33 INFO Epoch 3: [10605/10940] ---- BYOL Validation Loss = 0.28178757429122925
30-01-2023 22:55:52 INFO Epoch 3: [10616/10940] ---- BYOL Training Loss = 0.2756233215332031
30-01-2023 22:56:10 INFO Epoch 3: [10627/10940] ---- BYOL Training Loss = 0.2756320536136627
30-01-2023 22:56:29 INFO Epoch 3: [10638/10940] ---- BYOL Training Loss = 0.2839003801345825
30-01-2023 22:56:48 INFO Epoch 3: [10649/10940] ---- BYOL Training Loss = 0.3086921274662018
30-01-2023 22:57:39 INFO Epoch 3: [10649/10940] ---- BYOL Validation Loss = 0.28495463728904724
30-01-2023 22:57:57 INFO Epoch 3: [10660/10940] ---- BYOL Training Loss = 0.27466654777526855
30-01-2023 22:58:16 INFO Epoch 3: [10671/10940] ---- BYOL Training Loss = 0.25563323497772217
30-01-2023 22:58:35 INFO Epoch 3: [10682/10940] ---- BYOL Training Loss = 0.3053832948207855
30-01-2023 22:58:53 INFO Epoch 3: [10693/10940] ---- BYOL Training Loss = 0.3448367118835449
30-01-2023 22:59:45 INFO Epoch 3: [10693/10940] ---- BYOL Validation Loss = 0.2750217318534851
30-01-2023 23:00:03 INFO Epoch 3: [10704/10940] ---- BYOL Training Loss = 0.3768533766269684
30-01-2023 23:00:22 INFO Epoch 3: [10715/10940] ---- BYOL Training Loss = 0.3375101685523987
30-01-2023 23:00:41 INFO Epoch 3: [10726/10940] ---- BYOL Training Loss = 0.27657458186149597
30-01-2023 23:00:59 INFO Epoch 3: [10737/10940] ---- BYOL Training Loss = 0.2573300004005432
30-01-2023 23:01:51 INFO Epoch 3: [10737/10940] ---- BYOL Validation Loss = 0.27647900581359863
30-01-2023 23:02:09 INFO Epoch 3: [10748/10940] ---- BYOL Training Loss = 0.26990851759910583
30-01-2023 23:02:28 INFO Epoch 3: [10759/10940] ---- BYOL Training Loss = 0.2966788709163666
30-01-2023 23:02:47 INFO Epoch 3: [10770/10940] ---- BYOL Training Loss = 0.2845625877380371
30-01-2023 23:03:05 INFO Epoch 3: [10781/10940] ---- BYOL Training Loss = 0.2572339177131653
30-01-2023 23:03:57 INFO Epoch 3: [10781/10940] ---- BYOL Validation Loss = 0.2723962664604187
30-01-2023 23:04:15 INFO Epoch 3: [10792/10940] ---- BYOL Training Loss = 0.23885111510753632
30-01-2023 23:04:34 INFO Epoch 3: [10803/10940] ---- BYOL Training Loss = 0.26671504974365234
30-01-2023 23:04:52 INFO Epoch 3: [10814/10940] ---- BYOL Training Loss = 0.33556821942329407
30-01-2023 23:05:11 INFO Epoch 3: [10825/10940] ---- BYOL Training Loss = 0.24515502154827118
30-01-2023 23:06:03 INFO Epoch 3: [10825/10940] ---- BYOL Validation Loss = 0.26786455512046814
30-01-2023 23:06:21 INFO Epoch 3: [10836/10940] ---- BYOL Training Loss = 0.19492748379707336
30-01-2023 23:06:40 INFO Epoch 3: [10847/10940] ---- BYOL Training Loss = 0.25777119398117065
30-01-2023 23:06:58 INFO Epoch 3: [10858/10940] ---- BYOL Training Loss = 0.2762652039527893
30-01-2023 23:07:17 INFO Epoch 3: [10869/10940] ---- BYOL Training Loss = 0.2591071128845215
30-01-2023 23:08:09 INFO Epoch 3: [10869/10940] ---- BYOL Validation Loss = 0.2818578779697418
30-01-2023 23:08:27 INFO Epoch 3: [10880/10940] ---- BYOL Training Loss = 0.22917938232421875
30-01-2023 23:08:46 INFO Epoch 3: [10891/10940] ---- BYOL Training Loss = 0.26376447081565857
30-01-2023 23:09:04 INFO Epoch 3: [10902/10940] ---- BYOL Training Loss = 0.27347350120544434
30-01-2023 23:09:23 INFO Epoch 3: [10913/10940] ---- BYOL Training Loss = 0.27851420640945435
30-01-2023 23:10:15 INFO Epoch 3: [10913/10940] ---- BYOL Validation Loss = 0.28070273995399475
30-01-2023 23:10:33 INFO Epoch 3: [10924/10940] ---- BYOL Training Loss = 0.33904457092285156
30-01-2023 23:10:52 INFO Epoch 3: [10935/10940] ---- BYOL Training Loss = 0.2744585871696472
30-01-2023 23:11:01 INFO Starting Epoch: 4
30-01-2023 23:11:19 INFO Epoch 4: [12/10940] ---- BYOL Training Loss = 0.31404909491539
30-01-2023 23:11:36 INFO Epoch 4: [23/10940] ---- BYOL Training Loss = 0.2807946801185608
30-01-2023 23:11:54 INFO Epoch 4: [34/10940] ---- BYOL Training Loss = 0.28498026728630066
30-01-2023 23:12:11 INFO Epoch 4: [45/10940] ---- BYOL Training Loss = 0.3126603960990906
30-01-2023 23:13:03 INFO Epoch 4: [45/10940] ---- BYOL Validation Loss = 0.28379976749420166
30-01-2023 23:13:20 INFO Epoch 4: [56/10940] ---- BYOL Training Loss = 0.32193052768707275
30-01-2023 23:13:38 INFO Epoch 4: [67/10940] ---- BYOL Training Loss = 0.29775649309158325
30-01-2023 23:13:55 INFO Epoch 4: [78/10940] ---- BYOL Training Loss = 0.24531826376914978
30-01-2023 23:14:13 INFO Epoch 4: [89/10940] ---- BYOL Training Loss = 0.22123345732688904
30-01-2023 23:15:04 INFO Epoch 4: [89/10940] ---- BYOL Validation Loss = 0.2789306342601776
30-01-2023 23:15:21 INFO Epoch 4: [100/10940] ---- BYOL Training Loss = 0.271361768245697
30-01-2023 23:15:39 INFO Epoch 4: [111/10940] ---- BYOL Training Loss = 0.27063149213790894
30-01-2023 23:15:57 INFO Epoch 4: [122/10940] ---- BYOL Training Loss = 0.29990309476852417
30-01-2023 23:16:14 INFO Epoch 4: [133/10940] ---- BYOL Training Loss = 0.3171578049659729
30-01-2023 23:17:06 INFO Epoch 4: [133/10940] ---- BYOL Validation Loss = 0.30010318756103516
30-01-2023 23:17:23 INFO Epoch 4: [144/10940] ---- BYOL Training Loss = 0.3250052034854889
30-01-2023 23:17:41 INFO Epoch 4: [155/10940] ---- BYOL Training Loss = 0.29094988107681274
30-01-2023 23:17:58 INFO Epoch 4: [166/10940] ---- BYOL Training Loss = 0.24570021033287048
30-01-2023 23:18:15 INFO Epoch 4: [177/10940] ---- BYOL Training Loss = 0.2626939117908478
30-01-2023 23:19:07 INFO Epoch 4: [177/10940] ---- BYOL Validation Loss = 0.2773496210575104
30-01-2023 23:19:24 INFO Epoch 4: [188/10940] ---- BYOL Training Loss = 0.2750810980796814
30-01-2023 23:19:42 INFO Epoch 4: [199/10940] ---- BYOL Training Loss = 0.29384201765060425
30-01-2023 23:20:00 INFO Epoch 4: [210/10940] ---- BYOL Training Loss = 0.3005542755126953
30-01-2023 23:20:17 INFO Epoch 4: [221/10940] ---- BYOL Training Loss = 0.30819171667099
30-01-2023 23:21:09 INFO Epoch 4: [221/10940] ---- BYOL Validation Loss = 0.2761171758174896
30-01-2023 23:21:26 INFO Epoch 4: [232/10940] ---- BYOL Training Loss = 0.2952831983566284
30-01-2023 23:21:44 INFO Epoch 4: [243/10940] ---- BYOL Training Loss = 0.2795705497264862
30-01-2023 23:22:01 INFO Epoch 4: [254/10940] ---- BYOL Training Loss = 0.28969427943229675
30-01-2023 23:22:19 INFO Epoch 4: [265/10940] ---- BYOL Training Loss = 0.32078519463539124
30-01-2023 23:23:11 INFO Epoch 4: [265/10940] ---- BYOL Validation Loss = 0.27751442790031433
30-01-2023 23:23:28 INFO Epoch 4: [276/10940] ---- BYOL Training Loss = 0.290424644947052
30-01-2023 23:23:46 INFO Epoch 4: [287/10940] ---- BYOL Training Loss = 0.24729058146476746
30-01-2023 23:24:03 INFO Epoch 4: [298/10940] ---- BYOL Training Loss = 0.2198352813720703
30-01-2023 23:24:21 INFO Epoch 4: [309/10940] ---- BYOL Training Loss = 0.2796010375022888
30-01-2023 23:25:13 INFO Epoch 4: [309/10940] ---- BYOL Validation Loss = 0.2749660611152649
30-01-2023 23:25:30 INFO Epoch 4: [320/10940] ---- BYOL Training Loss = 0.311065137386322
30-01-2023 23:25:47 INFO Epoch 4: [331/10940] ---- BYOL Training Loss = 0.29533541202545166
30-01-2023 23:26:05 INFO Epoch 4: [342/10940] ---- BYOL Training Loss = 0.2570430636405945
30-01-2023 23:26:22 INFO Epoch 4: [353/10940] ---- BYOL Training Loss = 0.27247610688209534
30-01-2023 23:27:14 INFO Epoch 4: [353/10940] ---- BYOL Validation Loss = 0.2648475468158722
30-01-2023 23:27:32 INFO Epoch 4: [364/10940] ---- BYOL Training Loss = 0.2864307463169098
30-01-2023 23:27:49 INFO Epoch 4: [375/10940] ---- BYOL Training Loss = 0.2767539620399475
30-01-2023 23:28:07 INFO Epoch 4: [386/10940] ---- BYOL Training Loss = 0.273480623960495
30-01-2023 23:28:24 INFO Epoch 4: [397/10940] ---- BYOL Training Loss = 0.2706682085990906
30-01-2023 23:29:16 INFO Epoch 4: [397/10940] ---- BYOL Validation Loss = 0.2824762761592865
30-01-2023 23:29:33 INFO Epoch 4: [408/10940] ---- BYOL Training Loss = 0.3146856427192688
30-01-2023 23:29:51 INFO Epoch 4: [419/10940] ---- BYOL Training Loss = 0.304891437292099
30-01-2023 23:30:08 INFO Epoch 4: [430/10940] ---- BYOL Training Loss = 0.29695743322372437
30-01-2023 23:30:26 INFO Epoch 4: [441/10940] ---- BYOL Training Loss = 0.29137036204338074
30-01-2023 23:31:18 INFO Epoch 4: [441/10940] ---- BYOL Validation Loss = 0.2654087245464325
30-01-2023 23:31:35 INFO Epoch 4: [452/10940] ---- BYOL Training Loss = 0.2404009848833084
30-01-2023 23:31:52 INFO Epoch 4: [463/10940] ---- BYOL Training Loss = 0.24470055103302002
30-01-2023 23:32:10 INFO Epoch 4: [474/10940] ---- BYOL Training Loss = 0.2792055010795593
30-01-2023 23:32:28 INFO Epoch 4: [485/10940] ---- BYOL Training Loss = 0.2868555188179016
30-01-2023 23:33:19 INFO Epoch 4: [485/10940] ---- BYOL Validation Loss = 0.2757067382335663
30-01-2023 23:33:37 INFO Epoch 4: [496/10940] ---- BYOL Training Loss = 0.23934321105480194
30-01-2023 23:33:54 INFO Epoch 4: [507/10940] ---- BYOL Training Loss = 0.2461298257112503
30-01-2023 23:34:12 INFO Epoch 4: [518/10940] ---- BYOL Training Loss = 0.21900925040245056
30-01-2023 23:34:29 INFO Epoch 4: [529/10940] ---- BYOL Training Loss = 0.2777255177497864
30-01-2023 23:35:21 INFO Epoch 4: [529/10940] ---- BYOL Validation Loss = 0.2868647873401642
30-01-2023 23:35:38 INFO Epoch 4: [540/10940] ---- BYOL Training Loss = 0.2883921265602112
30-01-2023 23:35:56 INFO Epoch 4: [551/10940] ---- BYOL Training Loss = 0.273251473903656
30-01-2023 23:36:14 INFO Epoch 4: [562/10940] ---- BYOL Training Loss = 0.24825184047222137
30-01-2023 23:36:31 INFO Epoch 4: [573/10940] ---- BYOL Training Loss = 0.2779324948787689
30-01-2023 23:37:23 INFO Epoch 4: [573/10940] ---- BYOL Validation Loss = 0.2765021026134491
30-01-2023 23:37:40 INFO Epoch 4: [584/10940] ---- BYOL Training Loss = 0.30029669404029846
30-01-2023 23:37:58 INFO Epoch 4: [595/10940] ---- BYOL Training Loss = 0.30696621537208557
30-01-2023 23:38:16 INFO Epoch 4: [606/10940] ---- BYOL Training Loss = 0.27666717767715454
30-01-2023 23:38:33 INFO Epoch 4: [617/10940] ---- BYOL Training Loss = 0.2829020321369171
30-01-2023 23:39:25 INFO Epoch 4: [617/10940] ---- BYOL Validation Loss = 0.27162912487983704
30-01-2023 23:39:42 INFO Epoch 4: [628/10940] ---- BYOL Training Loss = 0.3355332016944885
30-01-2023 23:40:00 INFO Epoch 4: [639/10940] ---- BYOL Training Loss = 0.2874661386013031
30-01-2023 23:40:18 INFO Epoch 4: [650/10940] ---- BYOL Training Loss = 0.25904062390327454
30-01-2023 23:40:35 INFO Epoch 4: [661/10940] ---- BYOL Training Loss = 0.23213282227516174
30-01-2023 23:41:27 INFO Epoch 4: [661/10940] ---- BYOL Validation Loss = 0.2703251540660858
30-01-2023 23:41:44 INFO Epoch 4: [672/10940] ---- BYOL Training Loss = 0.19651511311531067
30-01-2023 23:42:02 INFO Epoch 4: [683/10940] ---- BYOL Training Loss = 0.2273201048374176
30-01-2023 23:42:19 INFO Epoch 4: [694/10940] ---- BYOL Training Loss = 0.27808114886283875
30-01-2023 23:42:37 INFO Epoch 4: [705/10940] ---- BYOL Training Loss = 0.2579132616519928
30-01-2023 23:43:29 INFO Epoch 4: [705/10940] ---- BYOL Validation Loss = 0.2603045701980591
30-01-2023 23:43:46 INFO Epoch 4: [716/10940] ---- BYOL Training Loss = 0.27621978521347046
30-01-2023 23:44:04 INFO Epoch 4: [727/10940] ---- BYOL Training Loss = 0.2783663868904114
30-01-2023 23:44:21 INFO Epoch 4: [738/10940] ---- BYOL Training Loss = 0.2159842699766159
30-01-2023 23:44:39 INFO Epoch 4: [749/10940] ---- BYOL Training Loss = 0.2201964408159256
30-01-2023 23:45:31 INFO Epoch 4: [749/10940] ---- BYOL Validation Loss = 0.27493348717689514
30-01-2023 23:45:48 INFO Epoch 4: [760/10940] ---- BYOL Training Loss = 0.2451084405183792
30-01-2023 23:46:05 INFO Epoch 4: [771/10940] ---- BYOL Training Loss = 0.2773723006248474
30-01-2023 23:46:23 INFO Epoch 4: [782/10940] ---- BYOL Training Loss = 0.25219598412513733
30-01-2023 23:46:41 INFO Epoch 4: [793/10940] ---- BYOL Training Loss = 0.25248098373413086
30-01-2023 23:47:32 INFO Epoch 4: [793/10940] ---- BYOL Validation Loss = 0.2622382640838623
30-01-2023 23:47:49 INFO Epoch 4: [804/10940] ---- BYOL Training Loss = 0.2812080979347229
30-01-2023 23:48:07 INFO Epoch 4: [815/10940] ---- BYOL Training Loss = 0.2891600728034973
30-01-2023 23:48:25 INFO Epoch 4: [826/10940] ---- BYOL Training Loss = 0.29287558794021606
30-01-2023 23:48:43 INFO Epoch 4: [837/10940] ---- BYOL Training Loss = 0.26005688309669495
30-01-2023 23:49:34 INFO Epoch 4: [837/10940] ---- BYOL Validation Loss = 0.27335119247436523
30-01-2023 23:49:52 INFO Epoch 4: [848/10940] ---- BYOL Training Loss = 0.26549845933914185
30-01-2023 23:50:09 INFO Epoch 4: [859/10940] ---- BYOL Training Loss = 0.31856444478034973
30-01-2023 23:50:27 INFO Epoch 4: [870/10940] ---- BYOL Training Loss = 0.330620676279068
30-01-2023 23:50:44 INFO Epoch 4: [881/10940] ---- BYOL Training Loss = 0.33569997549057007
30-01-2023 23:51:36 INFO Epoch 4: [881/10940] ---- BYOL Validation Loss = 0.2834504544734955
30-01-2023 23:51:53 INFO Epoch 4: [892/10940] ---- BYOL Training Loss = 0.34112125635147095
30-01-2023 23:52:11 INFO Epoch 4: [903/10940] ---- BYOL Training Loss = 0.2981463670730591
30-01-2023 23:52:29 INFO Epoch 4: [914/10940] ---- BYOL Training Loss = 0.2548942565917969
30-01-2023 23:52:46 INFO Epoch 4: [925/10940] ---- BYOL Training Loss = 0.27205803990364075
30-01-2023 23:53:38 INFO Epoch 4: [925/10940] ---- BYOL Validation Loss = 0.26863953471183777
30-01-2023 23:53:55 INFO Epoch 4: [936/10940] ---- BYOL Training Loss = 0.2702636122703552
30-01-2023 23:54:13 INFO Epoch 4: [947/10940] ---- BYOL Training Loss = 0.2731156051158905
30-01-2023 23:54:30 INFO Epoch 4: [958/10940] ---- BYOL Training Loss = 0.2774440050125122
30-01-2023 23:54:48 INFO Epoch 4: [969/10940] ---- BYOL Training Loss = 0.2685612440109253
30-01-2023 23:55:40 INFO Epoch 4: [969/10940] ---- BYOL Validation Loss = 0.27162978053092957
30-01-2023 23:55:57 INFO Epoch 4: [980/10940] ---- BYOL Training Loss = 0.2349621057510376
30-01-2023 23:56:14 INFO Epoch 4: [991/10940] ---- BYOL Training Loss = 0.24817657470703125
30-01-2023 23:56:32 INFO Epoch 4: [1002/10940] ---- BYOL Training Loss = 0.25041648745536804
30-01-2023 23:56:49 INFO Epoch 4: [1013/10940] ---- BYOL Training Loss = 0.2223936766386032
30-01-2023 23:57:41 INFO Epoch 4: [1013/10940] ---- BYOL Validation Loss = 0.26570776104927063
30-01-2023 23:57:58 INFO Epoch 4: [1024/10940] ---- BYOL Training Loss = 0.23434562981128693
30-01-2023 23:58:16 INFO Epoch 4: [1035/10940] ---- BYOL Training Loss = 0.2577926516532898
30-01-2023 23:58:34 INFO Epoch 4: [1046/10940] ---- BYOL Training Loss = 0.27195918560028076
30-01-2023 23:58:51 INFO Epoch 4: [1057/10940] ---- BYOL Training Loss = 0.2566909193992615
30-01-2023 23:59:43 INFO Epoch 4: [1057/10940] ---- BYOL Validation Loss = 0.270519495010376
31-01-2023 00:00:00 INFO Epoch 4: [1068/10940] ---- BYOL Training Loss = 0.21007469296455383
31-01-2023 00:00:18 INFO Epoch 4: [1079/10940] ---- BYOL Training Loss = 0.2063116580247879
31-01-2023 00:00:36 INFO Epoch 4: [1090/10940] ---- BYOL Training Loss = 0.2557557225227356
31-01-2023 00:00:53 INFO Epoch 4: [1101/10940] ---- BYOL Training Loss = 0.26835688948631287
31-01-2023 00:01:45 INFO Epoch 4: [1101/10940] ---- BYOL Validation Loss = 0.2655625641345978
31-01-2023 00:02:02 INFO Epoch 4: [1112/10940] ---- BYOL Training Loss = 0.22751715779304504
31-01-2023 00:02:20 INFO Epoch 4: [1123/10940] ---- BYOL Training Loss = 0.23352965712547302
31-01-2023 00:02:38 INFO Epoch 4: [1134/10940] ---- BYOL Training Loss = 0.23833270370960236
31-01-2023 00:02:55 INFO Epoch 4: [1145/10940] ---- BYOL Training Loss = 0.2629120349884033
31-01-2023 00:03:47 INFO Epoch 4: [1145/10940] ---- BYOL Validation Loss = 0.2660549581050873
31-01-2023 00:04:04 INFO Epoch 4: [1156/10940] ---- BYOL Training Loss = 0.2508407235145569
31-01-2023 00:04:22 INFO Epoch 4: [1167/10940] ---- BYOL Training Loss = 0.2874528467655182
31-01-2023 00:04:40 INFO Epoch 4: [1178/10940] ---- BYOL Training Loss = 0.31830400228500366
31-01-2023 00:04:57 INFO Epoch 4: [1189/10940] ---- BYOL Training Loss = 0.2895919680595398
31-01-2023 00:05:49 INFO Epoch 4: [1189/10940] ---- BYOL Validation Loss = 0.262308269739151
31-01-2023 00:06:06 INFO Epoch 4: [1200/10940] ---- BYOL Training Loss = 0.3034115135669708
31-01-2023 00:06:24 INFO Epoch 4: [1211/10940] ---- BYOL Training Loss = 0.3435043692588806
31-01-2023 00:06:42 INFO Epoch 4: [1222/10940] ---- BYOL Training Loss = 0.3102959990501404
31-01-2023 00:07:00 INFO Epoch 4: [1233/10940] ---- BYOL Training Loss = 0.2742713987827301
31-01-2023 00:07:52 INFO Epoch 4: [1233/10940] ---- BYOL Validation Loss = 0.2715238332748413
31-01-2023 00:08:09 INFO Epoch 4: [1244/10940] ---- BYOL Training Loss = 0.252397745847702
31-01-2023 00:08:26 INFO Epoch 4: [1255/10940] ---- BYOL Training Loss = 0.2629840672016144
31-01-2023 00:08:44 INFO Epoch 4: [1266/10940] ---- BYOL Training Loss = 0.29761308431625366
31-01-2023 00:09:02 INFO Epoch 4: [1277/10940] ---- BYOL Training Loss = 0.26066258549690247
31-01-2023 00:09:53 INFO Epoch 4: [1277/10940] ---- BYOL Validation Loss = 0.2658984065055847
31-01-2023 00:10:11 INFO Epoch 4: [1288/10940] ---- BYOL Training Loss = 0.28193649649620056
31-01-2023 00:10:28 INFO Epoch 4: [1299/10940] ---- BYOL Training Loss = 0.28286370635032654
31-01-2023 00:10:46 INFO Epoch 4: [1310/10940] ---- BYOL Training Loss = 0.25867387652397156
31-01-2023 00:11:04 INFO Epoch 4: [1321/10940] ---- BYOL Training Loss = 0.23837420344352722
31-01-2023 00:11:55 INFO Epoch 4: [1321/10940] ---- BYOL Validation Loss = 0.2657613158226013
31-01-2023 00:12:13 INFO Epoch 4: [1332/10940] ---- BYOL Training Loss = 0.2331557720899582
31-01-2023 00:12:30 INFO Epoch 4: [1343/10940] ---- BYOL Training Loss = 0.2957521080970764
31-01-2023 00:12:48 INFO Epoch 4: [1354/10940] ---- BYOL Training Loss = 0.2838229537010193
31-01-2023 00:13:06 INFO Epoch 4: [1365/10940] ---- BYOL Training Loss = 0.28597432374954224
31-01-2023 00:13:58 INFO Epoch 4: [1365/10940] ---- BYOL Validation Loss = 0.2700316607952118
31-01-2023 00:14:15 INFO Epoch 4: [1376/10940] ---- BYOL Training Loss = 0.29728028178215027
31-01-2023 00:14:32 INFO Epoch 4: [1387/10940] ---- BYOL Training Loss = 0.29402849078178406
31-01-2023 00:14:50 INFO Epoch 4: [1398/10940] ---- BYOL Training Loss = 0.30529171228408813
31-01-2023 00:15:08 INFO Epoch 4: [1409/10940] ---- BYOL Training Loss = 0.30106693506240845
31-01-2023 00:16:00 INFO Epoch 4: [1409/10940] ---- BYOL Validation Loss = 0.25920259952545166
31-01-2023 00:16:17 INFO Epoch 4: [1420/10940] ---- BYOL Training Loss = 0.2582438290119171
31-01-2023 00:16:35 INFO Epoch 4: [1431/10940] ---- BYOL Training Loss = 0.2483046054840088
31-01-2023 00:16:52 INFO Epoch 4: [1442/10940] ---- BYOL Training Loss = 0.24314984679222107
31-01-2023 00:17:10 INFO Epoch 4: [1453/10940] ---- BYOL Training Loss = 0.24723616242408752
31-01-2023 00:18:02 INFO Epoch 4: [1453/10940] ---- BYOL Validation Loss = 0.26078957319259644
31-01-2023 00:18:19 INFO Epoch 4: [1464/10940] ---- BYOL Training Loss = 0.28637391328811646
31-01-2023 00:18:37 INFO Epoch 4: [1475/10940] ---- BYOL Training Loss = 0.2785211503505707
31-01-2023 00:18:54 INFO Epoch 4: [1486/10940] ---- BYOL Training Loss = 0.27399566769599915
31-01-2023 00:19:12 INFO Epoch 4: [1497/10940] ---- BYOL Training Loss = 0.2799034118652344
31-01-2023 00:20:04 INFO Epoch 4: [1497/10940] ---- BYOL Validation Loss = 0.27431079745292664
31-01-2023 00:20:22 INFO Epoch 4: [1508/10940] ---- BYOL Training Loss = 0.3124743402004242
31-01-2023 00:20:39 INFO Epoch 4: [1519/10940] ---- BYOL Training Loss = 0.2768654227256775
31-01-2023 00:20:57 INFO Epoch 4: [1530/10940] ---- BYOL Training Loss = 0.29051271080970764
31-01-2023 00:21:15 INFO Epoch 4: [1541/10940] ---- BYOL Training Loss = 0.31963640451431274
31-01-2023 00:22:07 INFO Epoch 4: [1541/10940] ---- BYOL Validation Loss = 0.269408255815506
31-01-2023 00:22:24 INFO Epoch 4: [1552/10940] ---- BYOL Training Loss = 0.2654253840446472
31-01-2023 00:22:42 INFO Epoch 4: [1563/10940] ---- BYOL Training Loss = 0.278847873210907
31-01-2023 00:22:59 INFO Epoch 4: [1574/10940] ---- BYOL Training Loss = 0.2519371509552002
31-01-2023 00:23:17 INFO Epoch 4: [1585/10940] ---- BYOL Training Loss = 0.22269053757190704
31-01-2023 00:24:09 INFO Epoch 4: [1585/10940] ---- BYOL Validation Loss = 0.2664918899536133
31-01-2023 00:24:26 INFO Epoch 4: [1596/10940] ---- BYOL Training Loss = 0.21555820107460022
31-01-2023 00:24:44 INFO Epoch 4: [1607/10940] ---- BYOL Training Loss = 0.2622047960758209
31-01-2023 00:25:02 INFO Epoch 4: [1618/10940] ---- BYOL Training Loss = 0.28978684544563293
31-01-2023 00:25:19 INFO Epoch 4: [1629/10940] ---- BYOL Training Loss = 0.29307058453559875
31-01-2023 00:26:11 INFO Epoch 4: [1629/10940] ---- BYOL Validation Loss = 0.26651155948638916
31-01-2023 00:26:28 INFO Epoch 4: [1640/10940] ---- BYOL Training Loss = 0.2833004593849182
31-01-2023 00:26:46 INFO Epoch 4: [1651/10940] ---- BYOL Training Loss = 0.26532191038131714
31-01-2023 00:27:04 INFO Epoch 4: [1662/10940] ---- BYOL Training Loss = 0.24131569266319275
31-01-2023 00:27:21 INFO Epoch 4: [1673/10940] ---- BYOL Training Loss = 0.2531081438064575
31-01-2023 00:28:13 INFO Epoch 4: [1673/10940] ---- BYOL Validation Loss = 0.2584182918071747
31-01-2023 00:28:30 INFO Epoch 4: [1684/10940] ---- BYOL Training Loss = 0.2111816108226776
31-01-2023 00:28:49 INFO Epoch 4: [1695/10940] ---- BYOL Training Loss = 0.22434315085411072
31-01-2023 00:29:06 INFO Epoch 4: [1706/10940] ---- BYOL Training Loss = 0.2817900478839874
31-01-2023 00:29:24 INFO Epoch 4: [1717/10940] ---- BYOL Training Loss = 0.2693210244178772
31-01-2023 00:30:16 INFO Epoch 4: [1717/10940] ---- BYOL Validation Loss = 0.25597459077835083
31-01-2023 00:30:33 INFO Epoch 4: [1728/10940] ---- BYOL Training Loss = 0.261994332075119
31-01-2023 00:30:51 INFO Epoch 4: [1739/10940] ---- BYOL Training Loss = 0.2553747296333313
31-01-2023 00:31:08 INFO Epoch 4: [1750/10940] ---- BYOL Training Loss = 0.23058085143566132
31-01-2023 00:31:26 INFO Epoch 4: [1761/10940] ---- BYOL Training Loss = 0.23467978835105896
31-01-2023 00:32:18 INFO Epoch 4: [1761/10940] ---- BYOL Validation Loss = 0.26355448365211487
31-01-2023 00:32:35 INFO Epoch 4: [1772/10940] ---- BYOL Training Loss = 0.2460820972919464
31-01-2023 00:32:53 INFO Epoch 4: [1783/10940] ---- BYOL Training Loss = 0.2539155185222626
31-01-2023 00:33:10 INFO Epoch 4: [1794/10940] ---- BYOL Training Loss = 0.2676757276058197
31-01-2023 00:33:28 INFO Epoch 4: [1805/10940] ---- BYOL Training Loss = 0.2997061014175415
31-01-2023 00:34:20 INFO Epoch 4: [1805/10940] ---- BYOL Validation Loss = 0.2649165093898773
31-01-2023 00:34:37 INFO Epoch 4: [1816/10940] ---- BYOL Training Loss = 0.29350146651268005
31-01-2023 00:34:55 INFO Epoch 4: [1827/10940] ---- BYOL Training Loss = 0.2631371319293976
31-01-2023 00:35:13 INFO Epoch 4: [1838/10940] ---- BYOL Training Loss = 0.2666616439819336
31-01-2023 00:35:30 INFO Epoch 4: [1849/10940] ---- BYOL Training Loss = 0.2892574369907379
31-01-2023 00:36:22 INFO Epoch 4: [1849/10940] ---- BYOL Validation Loss = 0.26962360739707947
31-01-2023 00:36:39 INFO Epoch 4: [1860/10940] ---- BYOL Training Loss = 0.3177851140499115
31-01-2023 00:36:57 INFO Epoch 4: [1871/10940] ---- BYOL Training Loss = 0.295998215675354
31-01-2023 00:37:15 INFO Epoch 4: [1882/10940] ---- BYOL Training Loss = 0.26653915643692017
31-01-2023 00:37:33 INFO Epoch 4: [1893/10940] ---- BYOL Training Loss = 0.2809576094150543
31-01-2023 00:38:24 INFO Epoch 4: [1893/10940] ---- BYOL Validation Loss = 0.26558205485343933
31-01-2023 00:38:42 INFO Epoch 4: [1904/10940] ---- BYOL Training Loss = 0.30064857006073
31-01-2023 00:39:00 INFO Epoch 4: [1915/10940] ---- BYOL Training Loss = 0.253711462020874
31-01-2023 00:39:18 INFO Epoch 4: [1926/10940] ---- BYOL Training Loss = 0.28150349855422974
31-01-2023 00:39:35 INFO Epoch 4: [1937/10940] ---- BYOL Training Loss = 0.3130621910095215
31-01-2023 00:40:27 INFO Epoch 4: [1937/10940] ---- BYOL Validation Loss = 0.26125138998031616
31-01-2023 00:40:45 INFO Epoch 4: [1948/10940] ---- BYOL Training Loss = 0.26321959495544434
31-01-2023 00:41:02 INFO Epoch 4: [1959/10940] ---- BYOL Training Loss = 0.24140505492687225
31-01-2023 00:41:20 INFO Epoch 4: [1970/10940] ---- BYOL Training Loss = 0.23418526351451874
31-01-2023 00:41:38 INFO Epoch 4: [1981/10940] ---- BYOL Training Loss = 0.25435513257980347
31-01-2023 00:42:30 INFO Epoch 4: [1981/10940] ---- BYOL Validation Loss = 0.2636924088001251
31-01-2023 00:42:47 INFO Epoch 4: [1992/10940] ---- BYOL Training Loss = 0.22586758434772491
31-01-2023 00:43:04 INFO Epoch 4: [2003/10940] ---- BYOL Training Loss = 0.22776249051094055
31-01-2023 00:43:22 INFO Epoch 4: [2014/10940] ---- BYOL Training Loss = 0.2771553099155426
31-01-2023 00:43:40 INFO Epoch 4: [2025/10940] ---- BYOL Training Loss = 0.27902060747146606
31-01-2023 00:44:32 INFO Epoch 4: [2025/10940] ---- BYOL Validation Loss = 0.26304760575294495
31-01-2023 00:44:49 INFO Epoch 4: [2036/10940] ---- BYOL Training Loss = 0.2727523446083069
31-01-2023 00:45:07 INFO Epoch 4: [2047/10940] ---- BYOL Training Loss = 0.29481154680252075
31-01-2023 00:45:25 INFO Epoch 4: [2058/10940] ---- BYOL Training Loss = 0.29059743881225586
31-01-2023 00:45:42 INFO Epoch 4: [2069/10940] ---- BYOL Training Loss = 0.2638089954853058
31-01-2023 00:46:34 INFO Epoch 4: [2069/10940] ---- BYOL Validation Loss = 0.25968897342681885
31-01-2023 00:46:52 INFO Epoch 4: [2080/10940] ---- BYOL Training Loss = 0.2612308859825134
31-01-2023 00:47:10 INFO Epoch 4: [2091/10940] ---- BYOL Training Loss = 0.2544134855270386
31-01-2023 00:47:27 INFO Epoch 4: [2102/10940] ---- BYOL Training Loss = 0.25591737031936646
31-01-2023 00:47:45 INFO Epoch 4: [2113/10940] ---- BYOL Training Loss = 0.25064048171043396
31-01-2023 00:48:37 INFO Epoch 4: [2113/10940] ---- BYOL Validation Loss = 0.2592926621437073
31-01-2023 00:48:54 INFO Epoch 4: [2124/10940] ---- BYOL Training Loss = 0.24550819396972656
31-01-2023 00:49:12 INFO Epoch 4: [2135/10940] ---- BYOL Training Loss = 0.2801937758922577
31-01-2023 00:49:30 INFO Epoch 4: [2146/10940] ---- BYOL Training Loss = 0.2552814781665802
31-01-2023 00:49:47 INFO Epoch 4: [2157/10940] ---- BYOL Training Loss = 0.3054650127887726
31-01-2023 00:50:39 INFO Epoch 4: [2157/10940] ---- BYOL Validation Loss = 0.2623882591724396
31-01-2023 00:50:56 INFO Epoch 4: [2168/10940] ---- BYOL Training Loss = 0.3372747302055359
31-01-2023 00:51:14 INFO Epoch 4: [2179/10940] ---- BYOL Training Loss = 0.27895587682724
31-01-2023 00:51:32 INFO Epoch 4: [2190/10940] ---- BYOL Training Loss = 0.23209300637245178
31-01-2023 00:51:50 INFO Epoch 4: [2201/10940] ---- BYOL Training Loss = 0.22874565422534943
31-01-2023 00:52:42 INFO Epoch 4: [2201/10940] ---- BYOL Validation Loss = 0.25410521030426025
31-01-2023 00:52:59 INFO Epoch 4: [2212/10940] ---- BYOL Training Loss = 0.27747002243995667
31-01-2023 00:53:17 INFO Epoch 4: [2223/10940] ---- BYOL Training Loss = 0.3166246712207794
31-01-2023 00:53:34 INFO Epoch 4: [2234/10940] ---- BYOL Training Loss = 0.271393358707428
31-01-2023 00:53:52 INFO Epoch 4: [2245/10940] ---- BYOL Training Loss = 0.24728648364543915
31-01-2023 00:54:44 INFO Epoch 4: [2245/10940] ---- BYOL Validation Loss = 0.2732084393501282
31-01-2023 00:55:01 INFO Epoch 4: [2256/10940] ---- BYOL Training Loss = 0.3166441321372986
31-01-2023 00:55:19 INFO Epoch 4: [2267/10940] ---- BYOL Training Loss = 0.3112345337867737
31-01-2023 00:55:37 INFO Epoch 4: [2278/10940] ---- BYOL Training Loss = 0.23981615900993347
31-01-2023 00:55:54 INFO Epoch 4: [2289/10940] ---- BYOL Training Loss = 0.23992416262626648
31-01-2023 00:56:46 INFO Epoch 4: [2289/10940] ---- BYOL Validation Loss = 0.29235154390335083
31-01-2023 00:57:03 INFO Epoch 4: [2300/10940] ---- BYOL Training Loss = 0.28091442584991455
31-01-2023 00:57:21 INFO Epoch 4: [2311/10940] ---- BYOL Training Loss = 0.22436866164207458
31-01-2023 00:57:39 INFO Epoch 4: [2322/10940] ---- BYOL Training Loss = 0.2518511712551117
31-01-2023 00:57:57 INFO Epoch 4: [2333/10940] ---- BYOL Training Loss = 0.29575562477111816
31-01-2023 00:58:49 INFO Epoch 4: [2333/10940] ---- BYOL Validation Loss = 0.27200016379356384
31-01-2023 00:59:06 INFO Epoch 4: [2344/10940] ---- BYOL Training Loss = 0.2765443027019501
31-01-2023 00:59:24 INFO Epoch 4: [2355/10940] ---- BYOL Training Loss = 0.27515482902526855
31-01-2023 00:59:41 INFO Epoch 4: [2366/10940] ---- BYOL Training Loss = 0.25935977697372437
31-01-2023 00:59:59 INFO Epoch 4: [2377/10940] ---- BYOL Training Loss = 0.23971529304981232
31-01-2023 01:00:51 INFO Epoch 4: [2377/10940] ---- BYOL Validation Loss = 0.2653962969779968
31-01-2023 01:01:08 INFO Epoch 4: [2388/10940] ---- BYOL Training Loss = 0.21011169254779816
31-01-2023 01:01:26 INFO Epoch 4: [2399/10940] ---- BYOL Training Loss = 0.23295485973358154
31-01-2023 01:01:44 INFO Epoch 4: [2410/10940] ---- BYOL Training Loss = 0.21325775980949402
31-01-2023 01:02:01 INFO Epoch 4: [2421/10940] ---- BYOL Training Loss = 0.20763225853443146
31-01-2023 01:02:53 INFO Epoch 4: [2421/10940] ---- BYOL Validation Loss = 0.2652793228626251
31-01-2023 01:03:11 INFO Epoch 4: [2432/10940] ---- BYOL Training Loss = 0.2184261530637741
31-01-2023 01:03:29 INFO Epoch 4: [2443/10940] ---- BYOL Training Loss = 0.2909921407699585
31-01-2023 01:03:46 INFO Epoch 4: [2454/10940] ---- BYOL Training Loss = 0.2994442582130432
31-01-2023 01:04:04 INFO Epoch 4: [2465/10940] ---- BYOL Training Loss = 0.2648225724697113
31-01-2023 01:04:56 INFO Epoch 4: [2465/10940] ---- BYOL Validation Loss = 0.2680993676185608
31-01-2023 01:05:13 INFO Epoch 4: [2476/10940] ---- BYOL Training Loss = 0.25599661469459534
31-01-2023 01:05:31 INFO Epoch 4: [2487/10940] ---- BYOL Training Loss = 0.24162444472312927
31-01-2023 01:05:49 INFO Epoch 4: [2498/10940] ---- BYOL Training Loss = 0.3089216351509094
31-01-2023 01:06:06 INFO Epoch 4: [2509/10940] ---- BYOL Training Loss = 0.33436089754104614
31-01-2023 01:06:58 INFO Epoch 4: [2509/10940] ---- BYOL Validation Loss = 0.27287212014198303
31-01-2023 01:07:15 INFO Epoch 4: [2520/10940] ---- BYOL Training Loss = 0.2916456162929535
31-01-2023 01:07:33 INFO Epoch 4: [2531/10940] ---- BYOL Training Loss = 0.24155668914318085
31-01-2023 01:07:51 INFO Epoch 4: [2542/10940] ---- BYOL Training Loss = 0.24234695732593536
31-01-2023 01:08:09 INFO Epoch 4: [2553/10940] ---- BYOL Training Loss = 0.27124208211898804
31-01-2023 01:09:01 INFO Epoch 4: [2553/10940] ---- BYOL Validation Loss = 0.25905534625053406
31-01-2023 01:09:18 INFO Epoch 4: [2564/10940] ---- BYOL Training Loss = 0.24461600184440613
31-01-2023 01:09:36 INFO Epoch 4: [2575/10940] ---- BYOL Training Loss = 0.23838374018669128
31-01-2023 01:09:54 INFO Epoch 4: [2586/10940] ---- BYOL Training Loss = 0.2600421905517578
31-01-2023 01:10:11 INFO Epoch 4: [2597/10940] ---- BYOL Training Loss = 0.23060445487499237
31-01-2023 01:11:03 INFO Epoch 4: [2597/10940] ---- BYOL Validation Loss = 0.2626383602619171
31-01-2023 01:11:20 INFO Epoch 4: [2608/10940] ---- BYOL Training Loss = 0.27277013659477234
31-01-2023 01:11:38 INFO Epoch 4: [2619/10940] ---- BYOL Training Loss = 0.2720981240272522
31-01-2023 01:11:56 INFO Epoch 4: [2630/10940] ---- BYOL Training Loss = 0.23523405194282532
31-01-2023 01:12:13 INFO Epoch 4: [2641/10940] ---- BYOL Training Loss = 0.26698651909828186
31-01-2023 01:13:05 INFO Epoch 4: [2641/10940] ---- BYOL Validation Loss = 0.2698821723461151
31-01-2023 01:13:23 INFO Epoch 4: [2652/10940] ---- BYOL Training Loss = 0.2652828097343445
31-01-2023 01:13:41 INFO Epoch 4: [2663/10940] ---- BYOL Training Loss = 0.27610623836517334
31-01-2023 01:13:58 INFO Epoch 4: [2674/10940] ---- BYOL Training Loss = 0.2528131604194641
31-01-2023 01:14:16 INFO Epoch 4: [2685/10940] ---- BYOL Training Loss = 0.2427235096693039
31-01-2023 01:15:08 INFO Epoch 4: [2685/10940] ---- BYOL Validation Loss = 0.266946017742157
31-01-2023 01:15:25 INFO Epoch 4: [2696/10940] ---- BYOL Training Loss = 0.2527463436126709
31-01-2023 01:15:43 INFO Epoch 4: [2707/10940] ---- BYOL Training Loss = 0.2561939060688019
31-01-2023 01:16:01 INFO Epoch 4: [2718/10940] ---- BYOL Training Loss = 0.25430402159690857
31-01-2023 01:16:18 INFO Epoch 4: [2729/10940] ---- BYOL Training Loss = 0.2854744791984558
31-01-2023 01:17:10 INFO Epoch 4: [2729/10940] ---- BYOL Validation Loss = 0.26494836807250977
31-01-2023 01:17:27 INFO Epoch 4: [2740/10940] ---- BYOL Training Loss = 0.26344382762908936
31-01-2023 01:17:45 INFO Epoch 4: [2751/10940] ---- BYOL Training Loss = 0.26886844635009766
31-01-2023 01:18:03 INFO Epoch 4: [2762/10940] ---- BYOL Training Loss = 0.24456147849559784
31-01-2023 01:18:21 INFO Epoch 4: [2773/10940] ---- BYOL Training Loss = 0.23448166251182556
31-01-2023 01:19:13 INFO Epoch 4: [2773/10940] ---- BYOL Validation Loss = 0.25595590472221375
31-01-2023 01:19:30 INFO Epoch 4: [2784/10940] ---- BYOL Training Loss = 0.2629968523979187
31-01-2023 01:19:48 INFO Epoch 4: [2795/10940] ---- BYOL Training Loss = 0.2560123801231384
31-01-2023 01:20:06 INFO Epoch 4: [2806/10940] ---- BYOL Training Loss = 0.26468876004219055
31-01-2023 01:20:24 INFO Epoch 4: [2817/10940] ---- BYOL Training Loss = 0.26963967084884644
31-01-2023 01:21:15 INFO Epoch 4: [2817/10940] ---- BYOL Validation Loss = 0.265582799911499
31-01-2023 01:21:33 INFO Epoch 4: [2828/10940] ---- BYOL Training Loss = 0.24656781554222107
31-01-2023 01:21:50 INFO Epoch 4: [2839/10940] ---- BYOL Training Loss = 0.2779293656349182
31-01-2023 01:22:09 INFO Epoch 4: [2850/10940] ---- BYOL Training Loss = 0.2969270944595337
31-01-2023 01:22:26 INFO Epoch 4: [2861/10940] ---- BYOL Training Loss = 0.284832239151001
31-01-2023 01:23:18 INFO Epoch 4: [2861/10940] ---- BYOL Validation Loss = 0.26270052790641785
31-01-2023 01:23:36 INFO Epoch 4: [2872/10940] ---- BYOL Training Loss = 0.2870406210422516
31-01-2023 01:23:53 INFO Epoch 4: [2883/10940] ---- BYOL Training Loss = 0.2748512625694275
31-01-2023 01:24:11 INFO Epoch 4: [2894/10940] ---- BYOL Training Loss = 0.24076172709465027
31-01-2023 01:24:29 INFO Epoch 4: [2905/10940] ---- BYOL Training Loss = 0.2758488953113556
31-01-2023 01:25:21 INFO Epoch 4: [2905/10940] ---- BYOL Validation Loss = 0.255682110786438
31-01-2023 01:25:38 INFO Epoch 4: [2916/10940] ---- BYOL Training Loss = 0.29978442192077637
31-01-2023 01:25:56 INFO Epoch 4: [2927/10940] ---- BYOL Training Loss = 0.2920542359352112
31-01-2023 01:26:14 INFO Epoch 4: [2938/10940] ---- BYOL Training Loss = 0.23521801829338074
31-01-2023 01:26:32 INFO Epoch 4: [2949/10940] ---- BYOL Training Loss = 0.21682770550251007
31-01-2023 01:27:24 INFO Epoch 4: [2949/10940] ---- BYOL Validation Loss = 0.2525116205215454
31-01-2023 01:27:41 INFO Epoch 4: [2960/10940] ---- BYOL Training Loss = 0.22881802916526794
31-01-2023 01:27:59 INFO Epoch 4: [2971/10940] ---- BYOL Training Loss = 0.2742545008659363
31-01-2023 01:28:17 INFO Epoch 4: [2982/10940] ---- BYOL Training Loss = 0.2784714102745056
31-01-2023 01:28:35 INFO Epoch 4: [2993/10940] ---- BYOL Training Loss = 0.27728623151779175
31-01-2023 01:29:27 INFO Epoch 4: [2993/10940] ---- BYOL Validation Loss = 0.2599411904811859
31-01-2023 01:29:44 INFO Epoch 4: [3004/10940] ---- BYOL Training Loss = 0.26413530111312866
31-01-2023 01:30:02 INFO Epoch 4: [3015/10940] ---- BYOL Training Loss = 0.2478388100862503
31-01-2023 01:30:20 INFO Epoch 4: [3026/10940] ---- BYOL Training Loss = 0.25898322463035583
31-01-2023 01:30:38 INFO Epoch 4: [3037/10940] ---- BYOL Training Loss = 0.264944851398468
31-01-2023 01:31:30 INFO Epoch 4: [3037/10940] ---- BYOL Validation Loss = 0.2655838429927826
31-01-2023 01:31:47 INFO Epoch 4: [3048/10940] ---- BYOL Training Loss = 0.2839812934398651
31-01-2023 01:32:05 INFO Epoch 4: [3059/10940] ---- BYOL Training Loss = 0.2807186245918274
31-01-2023 01:32:23 INFO Epoch 4: [3070/10940] ---- BYOL Training Loss = 0.2871995270252228
31-01-2023 01:32:40 INFO Epoch 4: [3081/10940] ---- BYOL Training Loss = 0.3121665120124817
31-01-2023 01:33:32 INFO Epoch 4: [3081/10940] ---- BYOL Validation Loss = 0.26498880982398987
31-01-2023 01:33:50 INFO Epoch 4: [3092/10940] ---- BYOL Training Loss = 0.2729170322418213
31-01-2023 01:34:08 INFO Epoch 4: [3103/10940] ---- BYOL Training Loss = 0.23265588283538818
31-01-2023 01:34:26 INFO Epoch 4: [3114/10940] ---- BYOL Training Loss = 0.2372349202632904
31-01-2023 01:34:44 INFO Epoch 4: [3125/10940] ---- BYOL Training Loss = 0.2776709198951721
31-01-2023 01:35:35 INFO Epoch 4: [3125/10940] ---- BYOL Validation Loss = 0.2566472887992859
31-01-2023 01:35:53 INFO Epoch 4: [3136/10940] ---- BYOL Training Loss = 0.25798165798187256
31-01-2023 01:36:11 INFO Epoch 4: [3147/10940] ---- BYOL Training Loss = 0.22931091487407684
31-01-2023 01:36:28 INFO Epoch 4: [3158/10940] ---- BYOL Training Loss = 0.23363594710826874
31-01-2023 01:36:46 INFO Epoch 4: [3169/10940] ---- BYOL Training Loss = 0.21219651401042938
31-01-2023 01:37:38 INFO Epoch 4: [3169/10940] ---- BYOL Validation Loss = 0.2524280548095703
31-01-2023 01:37:55 INFO Epoch 4: [3180/10940] ---- BYOL Training Loss = 0.20506298542022705
31-01-2023 01:38:14 INFO Epoch 4: [3191/10940] ---- BYOL Training Loss = 0.2666841149330139
31-01-2023 01:38:31 INFO Epoch 4: [3202/10940] ---- BYOL Training Loss = 0.2895054221153259
31-01-2023 01:38:49 INFO Epoch 4: [3213/10940] ---- BYOL Training Loss = 0.2584450840950012
31-01-2023 01:39:41 INFO Epoch 4: [3213/10940] ---- BYOL Validation Loss = 0.24825944006443024
31-01-2023 01:39:58 INFO Epoch 4: [3224/10940] ---- BYOL Training Loss = 0.26015886664390564
31-01-2023 01:40:16 INFO Epoch 4: [3235/10940] ---- BYOL Training Loss = 0.22042123973369598
31-01-2023 01:40:34 INFO Epoch 4: [3246/10940] ---- BYOL Training Loss = 0.2204168140888214
31-01-2023 01:40:52 INFO Epoch 4: [3257/10940] ---- BYOL Training Loss = 0.22263792157173157
31-01-2023 01:41:44 INFO Epoch 4: [3257/10940] ---- BYOL Validation Loss = 0.25892382860183716
31-01-2023 01:42:01 INFO Epoch 4: [3268/10940] ---- BYOL Training Loss = 0.2336335927248001
31-01-2023 01:42:19 INFO Epoch 4: [3279/10940] ---- BYOL Training Loss = 0.24144694209098816
31-01-2023 01:42:37 INFO Epoch 4: [3290/10940] ---- BYOL Training Loss = 0.249689981341362
31-01-2023 01:42:55 INFO Epoch 4: [3301/10940] ---- BYOL Training Loss = 0.25077781081199646
31-01-2023 01:43:47 INFO Epoch 4: [3301/10940] ---- BYOL Validation Loss = 0.2693730294704437
31-01-2023 01:44:04 INFO Epoch 4: [3312/10940] ---- BYOL Training Loss = 0.26567763090133667
31-01-2023 01:44:22 INFO Epoch 4: [3323/10940] ---- BYOL Training Loss = 0.29432475566864014
31-01-2023 01:44:40 INFO Epoch 4: [3334/10940] ---- BYOL Training Loss = 0.2786439061164856
31-01-2023 01:44:58 INFO Epoch 4: [3345/10940] ---- BYOL Training Loss = 0.25303828716278076
31-01-2023 01:45:50 INFO Epoch 4: [3345/10940] ---- BYOL Validation Loss = 0.2544432282447815
31-01-2023 01:46:08 INFO Epoch 4: [3356/10940] ---- BYOL Training Loss = 0.21185970306396484
31-01-2023 01:46:25 INFO Epoch 4: [3367/10940] ---- BYOL Training Loss = 0.24178585410118103
31-01-2023 01:46:43 INFO Epoch 4: [3378/10940] ---- BYOL Training Loss = 0.2888575494289398
31-01-2023 01:47:01 INFO Epoch 4: [3389/10940] ---- BYOL Training Loss = 0.26367393136024475
31-01-2023 01:47:53 INFO Epoch 4: [3389/10940] ---- BYOL Validation Loss = 0.25867849588394165
31-01-2023 01:48:10 INFO Epoch 4: [3400/10940] ---- BYOL Training Loss = 0.31258273124694824
31-01-2023 01:48:28 INFO Epoch 4: [3411/10940] ---- BYOL Training Loss = 0.29562363028526306
31-01-2023 01:48:46 INFO Epoch 4: [3422/10940] ---- BYOL Training Loss = 0.21433743834495544
31-01-2023 01:49:04 INFO Epoch 4: [3433/10940] ---- BYOL Training Loss = 0.25330880284309387
31-01-2023 01:49:56 INFO Epoch 4: [3433/10940] ---- BYOL Validation Loss = 0.2549728453159332
31-01-2023 01:50:13 INFO Epoch 4: [3444/10940] ---- BYOL Training Loss = 0.2758903503417969
31-01-2023 01:50:31 INFO Epoch 4: [3455/10940] ---- BYOL Training Loss = 0.21588699519634247
31-01-2023 01:50:49 INFO Epoch 4: [3466/10940] ---- BYOL Training Loss = 0.19161517918109894
31-01-2023 01:51:07 INFO Epoch 4: [3477/10940] ---- BYOL Training Loss = 0.2341165989637375
31-01-2023 01:51:59 INFO Epoch 4: [3477/10940] ---- BYOL Validation Loss = 0.2561394274234772
31-01-2023 01:52:16 INFO Epoch 4: [3488/10940] ---- BYOL Training Loss = 0.22734364867210388
31-01-2023 01:52:34 INFO Epoch 4: [3499/10940] ---- BYOL Training Loss = 0.2603505253791809
31-01-2023 01:52:52 INFO Epoch 4: [3510/10940] ---- BYOL Training Loss = 0.24832478165626526
31-01-2023 01:53:10 INFO Epoch 4: [3521/10940] ---- BYOL Training Loss = 0.24558866024017334
31-01-2023 01:54:02 INFO Epoch 4: [3521/10940] ---- BYOL Validation Loss = 0.25735563039779663
31-01-2023 01:54:19 INFO Epoch 4: [3532/10940] ---- BYOL Training Loss = 0.22352823615074158
31-01-2023 01:54:37 INFO Epoch 4: [3543/10940] ---- BYOL Training Loss = 0.21486349403858185
31-01-2023 01:54:55 INFO Epoch 4: [3554/10940] ---- BYOL Training Loss = 0.25739148259162903
31-01-2023 01:55:13 INFO Epoch 4: [3565/10940] ---- BYOL Training Loss = 0.23955126106739044
31-01-2023 01:56:05 INFO Epoch 4: [3565/10940] ---- BYOL Validation Loss = 0.24889801442623138
31-01-2023 01:56:23 INFO Epoch 4: [3576/10940] ---- BYOL Training Loss = 0.22988295555114746
31-01-2023 01:56:40 INFO Epoch 4: [3587/10940] ---- BYOL Training Loss = 0.2582702040672302
31-01-2023 01:56:58 INFO Epoch 4: [3598/10940] ---- BYOL Training Loss = 0.27265363931655884
31-01-2023 01:57:16 INFO Epoch 4: [3609/10940] ---- BYOL Training Loss = 0.23958143591880798
31-01-2023 01:58:08 INFO Epoch 4: [3609/10940] ---- BYOL Validation Loss = 0.2585192024707794
31-01-2023 01:58:26 INFO Epoch 4: [3620/10940] ---- BYOL Training Loss = 0.23238889873027802
31-01-2023 01:58:43 INFO Epoch 4: [3631/10940] ---- BYOL Training Loss = 0.2569322884082794
31-01-2023 01:59:02 INFO Epoch 4: [3642/10940] ---- BYOL Training Loss = 0.2476222813129425
31-01-2023 01:59:19 INFO Epoch 4: [3653/10940] ---- BYOL Training Loss = 0.20371396839618683
31-01-2023 02:00:11 INFO Epoch 4: [3653/10940] ---- BYOL Validation Loss = 0.25106459856033325
31-01-2023 02:00:29 INFO Epoch 4: [3664/10940] ---- BYOL Training Loss = 0.1878078132867813
31-01-2023 02:00:46 INFO Epoch 4: [3675/10940] ---- BYOL Training Loss = 0.24421298503875732
31-01-2023 02:01:04 INFO Epoch 4: [3686/10940] ---- BYOL Training Loss = 0.2708568274974823
31-01-2023 02:01:22 INFO Epoch 4: [3697/10940] ---- BYOL Training Loss = 0.2675808072090149
31-01-2023 02:02:14 INFO Epoch 4: [3697/10940] ---- BYOL Validation Loss = 0.2464437186717987
31-01-2023 02:02:32 INFO Epoch 4: [3708/10940] ---- BYOL Training Loss = 0.2963387370109558
31-01-2023 02:02:50 INFO Epoch 4: [3719/10940] ---- BYOL Training Loss = 0.23851510882377625
31-01-2023 02:03:08 INFO Epoch 4: [3730/10940] ---- BYOL Training Loss = 0.21771450340747833
31-01-2023 02:03:25 INFO Epoch 4: [3741/10940] ---- BYOL Training Loss = 0.23571792244911194
31-01-2023 02:04:17 INFO Epoch 4: [3741/10940] ---- BYOL Validation Loss = 0.2555020749568939
31-01-2023 02:04:35 INFO Epoch 4: [3752/10940] ---- BYOL Training Loss = 0.2608491778373718
31-01-2023 02:04:53 INFO Epoch 4: [3763/10940] ---- BYOL Training Loss = 0.298178106546402
31-01-2023 02:05:11 INFO Epoch 4: [3774/10940] ---- BYOL Training Loss = 0.2533615827560425
31-01-2023 02:05:29 INFO Epoch 4: [3785/10940] ---- BYOL Training Loss = 0.269481360912323
31-01-2023 02:06:21 INFO Epoch 4: [3785/10940] ---- BYOL Validation Loss = 0.2547977566719055
31-01-2023 02:06:38 INFO Epoch 4: [3796/10940] ---- BYOL Training Loss = 0.29578453302383423
31-01-2023 02:06:56 INFO Epoch 4: [3807/10940] ---- BYOL Training Loss = 0.31742650270462036
31-01-2023 02:07:14 INFO Epoch 4: [3818/10940] ---- BYOL Training Loss = 0.2542242109775543
31-01-2023 02:07:32 INFO Epoch 4: [3829/10940] ---- BYOL Training Loss = 0.23638732731342316
31-01-2023 02:08:24 INFO Epoch 4: [3829/10940] ---- BYOL Validation Loss = 0.25608664751052856
31-01-2023 02:08:41 INFO Epoch 4: [3840/10940] ---- BYOL Training Loss = 0.25796249508857727
31-01-2023 02:08:59 INFO Epoch 4: [3851/10940] ---- BYOL Training Loss = 0.2622073292732239
31-01-2023 02:09:17 INFO Epoch 4: [3862/10940] ---- BYOL Training Loss = 0.29412949085235596
31-01-2023 02:09:35 INFO Epoch 4: [3873/10940] ---- BYOL Training Loss = 0.272030234336853
31-01-2023 02:10:27 INFO Epoch 4: [3873/10940] ---- BYOL Validation Loss = 0.2572214901447296
31-01-2023 02:10:44 INFO Epoch 4: [3884/10940] ---- BYOL Training Loss = 0.2646560072898865
31-01-2023 02:11:03 INFO Epoch 4: [3895/10940] ---- BYOL Training Loss = 0.30600273609161377
31-01-2023 02:11:20 INFO Epoch 4: [3906/10940] ---- BYOL Training Loss = 0.3061782121658325
31-01-2023 02:11:39 INFO Epoch 4: [3917/10940] ---- BYOL Training Loss = 0.2619483172893524
31-01-2023 02:12:31 INFO Epoch 4: [3917/10940] ---- BYOL Validation Loss = 0.24935655295848846
31-01-2023 02:12:48 INFO Epoch 4: [3928/10940] ---- BYOL Training Loss = 0.27545493841171265
31-01-2023 02:13:06 INFO Epoch 4: [3939/10940] ---- BYOL Training Loss = 0.2909042537212372
31-01-2023 02:13:24 INFO Epoch 4: [3950/10940] ---- BYOL Training Loss = 0.23169314861297607
31-01-2023 02:13:42 INFO Epoch 4: [3961/10940] ---- BYOL Training Loss = 0.22909800708293915
31-01-2023 02:14:34 INFO Epoch 4: [3961/10940] ---- BYOL Validation Loss = 0.256754994392395
31-01-2023 02:14:52 INFO Epoch 4: [3972/10940] ---- BYOL Training Loss = 0.29594188928604126
31-01-2023 02:15:09 INFO Epoch 4: [3983/10940] ---- BYOL Training Loss = 0.2714104652404785
31-01-2023 02:15:27 INFO Epoch 4: [3994/10940] ---- BYOL Training Loss = 0.23109447956085205
31-01-2023 02:15:45 INFO Epoch 4: [4005/10940] ---- BYOL Training Loss = 0.28165900707244873
31-01-2023 02:16:37 INFO Epoch 4: [4005/10940] ---- BYOL Validation Loss = 0.2558673918247223
31-01-2023 02:16:55 INFO Epoch 4: [4016/10940] ---- BYOL Training Loss = 0.286751389503479
31-01-2023 02:17:13 INFO Epoch 4: [4027/10940] ---- BYOL Training Loss = 0.23172929883003235
31-01-2023 02:17:31 INFO Epoch 4: [4038/10940] ---- BYOL Training Loss = 0.24812564253807068
31-01-2023 02:17:49 INFO Epoch 4: [4049/10940] ---- BYOL Training Loss = 0.28995394706726074
31-01-2023 02:18:41 INFO Epoch 4: [4049/10940] ---- BYOL Validation Loss = 0.2505519986152649
31-01-2023 02:18:58 INFO Epoch 4: [4060/10940] ---- BYOL Training Loss = 0.2586396038532257
31-01-2023 02:19:16 INFO Epoch 4: [4071/10940] ---- BYOL Training Loss = 0.26694023609161377
31-01-2023 02:19:34 INFO Epoch 4: [4082/10940] ---- BYOL Training Loss = 0.27493542432785034
31-01-2023 02:19:52 INFO Epoch 4: [4093/10940] ---- BYOL Training Loss = 0.26532191038131714
31-01-2023 02:20:44 INFO Epoch 4: [4093/10940] ---- BYOL Validation Loss = 0.2516033947467804
31-01-2023 02:21:01 INFO Epoch 4: [4104/10940] ---- BYOL Training Loss = 0.2638865113258362
31-01-2023 02:21:19 INFO Epoch 4: [4115/10940] ---- BYOL Training Loss = 0.2697603702545166
31-01-2023 02:21:37 INFO Epoch 4: [4126/10940] ---- BYOL Training Loss = 0.2603183686733246
31-01-2023 02:21:55 INFO Epoch 4: [4137/10940] ---- BYOL Training Loss = 0.25077033042907715
31-01-2023 02:22:47 INFO Epoch 4: [4137/10940] ---- BYOL Validation Loss = 0.26228779554367065
31-01-2023 02:23:04 INFO Epoch 4: [4148/10940] ---- BYOL Training Loss = 0.22724278271198273
31-01-2023 02:23:22 INFO Epoch 4: [4159/10940] ---- BYOL Training Loss = 0.19722986221313477
31-01-2023 02:23:40 INFO Epoch 4: [4170/10940] ---- BYOL Training Loss = 0.2167809009552002
31-01-2023 02:23:58 INFO Epoch 4: [4181/10940] ---- BYOL Training Loss = 0.2389891892671585
31-01-2023 02:24:50 INFO Epoch 4: [4181/10940] ---- BYOL Validation Loss = 0.2523881196975708
31-01-2023 02:25:08 INFO Epoch 4: [4192/10940] ---- BYOL Training Loss = 0.2310047447681427
31-01-2023 02:25:26 INFO Epoch 4: [4203/10940] ---- BYOL Training Loss = 0.22340083122253418
31-01-2023 02:25:43 INFO Epoch 4: [4214/10940] ---- BYOL Training Loss = 0.2910415232181549
31-01-2023 02:26:02 INFO Epoch 4: [4225/10940] ---- BYOL Training Loss = 0.29929670691490173
31-01-2023 02:26:54 INFO Epoch 4: [4225/10940] ---- BYOL Validation Loss = 0.2582031190395355
31-01-2023 02:27:11 INFO Epoch 4: [4236/10940] ---- BYOL Training Loss = 0.2638050615787506
31-01-2023 02:27:29 INFO Epoch 4: [4247/10940] ---- BYOL Training Loss = 0.2378300130367279
31-01-2023 02:27:47 INFO Epoch 4: [4258/10940] ---- BYOL Training Loss = 0.2813563942909241
31-01-2023 02:28:05 INFO Epoch 4: [4269/10940] ---- BYOL Training Loss = 0.2902524471282959
31-01-2023 02:28:57 INFO Epoch 4: [4269/10940] ---- BYOL Validation Loss = 0.2645869851112366
31-01-2023 02:29:15 INFO Epoch 4: [4280/10940] ---- BYOL Training Loss = 0.23713001608848572
31-01-2023 02:29:33 INFO Epoch 4: [4291/10940] ---- BYOL Training Loss = 0.2246485948562622
31-01-2023 02:29:50 INFO Epoch 4: [4302/10940] ---- BYOL Training Loss = 0.25131359696388245
31-01-2023 02:30:08 INFO Epoch 4: [4313/10940] ---- BYOL Training Loss = 0.27531105279922485
31-01-2023 02:31:00 INFO Epoch 4: [4313/10940] ---- BYOL Validation Loss = 0.2511442005634308
31-01-2023 02:31:18 INFO Epoch 4: [4324/10940] ---- BYOL Training Loss = 0.25356024503707886
31-01-2023 02:31:36 INFO Epoch 4: [4335/10940] ---- BYOL Training Loss = 0.26851409673690796
31-01-2023 02:31:54 INFO Epoch 4: [4346/10940] ---- BYOL Training Loss = 0.2963714003562927
31-01-2023 02:32:12 INFO Epoch 4: [4357/10940] ---- BYOL Training Loss = 0.26382631063461304
31-01-2023 02:33:04 INFO Epoch 4: [4357/10940] ---- BYOL Validation Loss = 0.261718213558197
31-01-2023 02:33:21 INFO Epoch 4: [4368/10940] ---- BYOL Training Loss = 0.2558540999889374
31-01-2023 02:33:39 INFO Epoch 4: [4379/10940] ---- BYOL Training Loss = 0.21825775504112244
31-01-2023 02:33:57 INFO Epoch 4: [4390/10940] ---- BYOL Training Loss = 0.21364597976207733
31-01-2023 02:34:15 INFO Epoch 4: [4401/10940] ---- BYOL Training Loss = 0.2355598509311676
31-01-2023 02:35:07 INFO Epoch 4: [4401/10940] ---- BYOL Validation Loss = 0.2592751979827881
31-01-2023 02:35:25 INFO Epoch 4: [4412/10940] ---- BYOL Training Loss = 0.2524583339691162
31-01-2023 02:35:42 INFO Epoch 4: [4423/10940] ---- BYOL Training Loss = 0.25248557329177856
31-01-2023 02:36:00 INFO Epoch 4: [4434/10940] ---- BYOL Training Loss = 0.24389179050922394
31-01-2023 02:36:18 INFO Epoch 4: [4445/10940] ---- BYOL Training Loss = 0.2315537929534912
31-01-2023 02:37:10 INFO Epoch 4: [4445/10940] ---- BYOL Validation Loss = 0.2572285830974579
31-01-2023 02:37:28 INFO Epoch 4: [4456/10940] ---- BYOL Training Loss = 0.28242743015289307
31-01-2023 02:37:46 INFO Epoch 4: [4467/10940] ---- BYOL Training Loss = 0.3120144307613373
31-01-2023 02:38:04 INFO Epoch 4: [4478/10940] ---- BYOL Training Loss = 0.2638016939163208
31-01-2023 02:38:22 INFO Epoch 4: [4489/10940] ---- BYOL Training Loss = 0.24478760361671448
31-01-2023 02:39:14 INFO Epoch 4: [4489/10940] ---- BYOL Validation Loss = 0.25246500968933105
31-01-2023 02:39:32 INFO Epoch 4: [4500/10940] ---- BYOL Training Loss = 0.2527778148651123
31-01-2023 02:39:50 INFO Epoch 4: [4511/10940] ---- BYOL Training Loss = 0.24938678741455078
31-01-2023 02:40:08 INFO Epoch 4: [4522/10940] ---- BYOL Training Loss = 0.28021684288978577
31-01-2023 02:40:26 INFO Epoch 4: [4533/10940] ---- BYOL Training Loss = 0.3124130964279175
31-01-2023 02:41:18 INFO Epoch 4: [4533/10940] ---- BYOL Validation Loss = 0.26887086033821106
31-01-2023 02:41:35 INFO Epoch 4: [4544/10940] ---- BYOL Training Loss = 0.2821263372898102
31-01-2023 02:41:53 INFO Epoch 4: [4555/10940] ---- BYOL Training Loss = 0.28163787722587585
31-01-2023 02:42:12 INFO Epoch 4: [4566/10940] ---- BYOL Training Loss = 0.2500320374965668
31-01-2023 02:42:30 INFO Epoch 4: [4577/10940] ---- BYOL Training Loss = 0.25001147389411926
31-01-2023 02:43:22 INFO Epoch 4: [4577/10940] ---- BYOL Validation Loss = 0.26393428444862366
31-01-2023 02:43:39 INFO Epoch 4: [4588/10940] ---- BYOL Training Loss = 0.26286354660987854
31-01-2023 02:43:57 INFO Epoch 4: [4599/10940] ---- BYOL Training Loss = 0.22614121437072754
31-01-2023 02:44:15 INFO Epoch 4: [4610/10940] ---- BYOL Training Loss = 0.25256943702697754
31-01-2023 02:44:33 INFO Epoch 4: [4621/10940] ---- BYOL Training Loss = 0.2931538224220276
31-01-2023 02:45:25 INFO Epoch 4: [4621/10940] ---- BYOL Validation Loss = 0.2609620690345764
31-01-2023 02:45:43 INFO Epoch 4: [4632/10940] ---- BYOL Training Loss = 0.31831616163253784
31-01-2023 02:46:01 INFO Epoch 4: [4643/10940] ---- BYOL Training Loss = 0.2796790301799774
31-01-2023 02:46:19 INFO Epoch 4: [4654/10940] ---- BYOL Training Loss = 0.2418333739042282
31-01-2023 02:46:36 INFO Epoch 4: [4665/10940] ---- BYOL Training Loss = 0.2789849042892456
31-01-2023 02:47:28 INFO Epoch 4: [4665/10940] ---- BYOL Validation Loss = 0.2684752643108368
31-01-2023 02:47:46 INFO Epoch 4: [4676/10940] ---- BYOL Training Loss = 0.24744673073291779
31-01-2023 02:48:04 INFO Epoch 4: [4687/10940] ---- BYOL Training Loss = 0.2781676650047302
31-01-2023 02:48:22 INFO Epoch 4: [4698/10940] ---- BYOL Training Loss = 0.2793886363506317
31-01-2023 02:48:40 INFO Epoch 4: [4709/10940] ---- BYOL Training Loss = 0.2560752332210541
31-01-2023 02:49:32 INFO Epoch 4: [4709/10940] ---- BYOL Validation Loss = 0.2618371546268463
31-01-2023 02:49:49 INFO Epoch 4: [4720/10940] ---- BYOL Training Loss = 0.2987802028656006
31-01-2023 02:50:07 INFO Epoch 4: [4731/10940] ---- BYOL Training Loss = 0.3067034184932709
31-01-2023 02:50:26 INFO Epoch 4: [4742/10940] ---- BYOL Training Loss = 0.2908785939216614
31-01-2023 02:50:44 INFO Epoch 4: [4753/10940] ---- BYOL Training Loss = 0.2699577212333679
31-01-2023 02:51:36 INFO Epoch 4: [4753/10940] ---- BYOL Validation Loss = 0.2676016688346863
31-01-2023 02:51:53 INFO Epoch 4: [4764/10940] ---- BYOL Training Loss = 0.26165881752967834
31-01-2023 02:52:11 INFO Epoch 4: [4775/10940] ---- BYOL Training Loss = 0.2242383509874344
31-01-2023 02:52:29 INFO Epoch 4: [4786/10940] ---- BYOL Training Loss = 0.205606147646904
31-01-2023 02:52:47 INFO Epoch 4: [4797/10940] ---- BYOL Training Loss = 0.27762332558631897
31-01-2023 02:53:39 INFO Epoch 4: [4797/10940] ---- BYOL Validation Loss = 0.269856333732605
31-01-2023 02:53:57 INFO Epoch 4: [4808/10940] ---- BYOL Training Loss = 0.26772838830947876
31-01-2023 02:54:15 INFO Epoch 4: [4819/10940] ---- BYOL Training Loss = 0.26042085886001587
31-01-2023 02:54:33 INFO Epoch 4: [4830/10940] ---- BYOL Training Loss = 0.2809680700302124
31-01-2023 02:54:51 INFO Epoch 4: [4841/10940] ---- BYOL Training Loss = 0.2360786497592926
31-01-2023 02:55:42 INFO Epoch 4: [4841/10940] ---- BYOL Validation Loss = 0.2598986029624939
31-01-2023 02:56:00 INFO Epoch 4: [4852/10940] ---- BYOL Training Loss = 0.2501278817653656
31-01-2023 02:56:18 INFO Epoch 4: [4863/10940] ---- BYOL Training Loss = 0.2999466061592102
31-01-2023 02:56:36 INFO Epoch 4: [4874/10940] ---- BYOL Training Loss = 0.2669902741909027
31-01-2023 02:56:54 INFO Epoch 4: [4885/10940] ---- BYOL Training Loss = 0.2537403404712677
31-01-2023 02:57:46 INFO Epoch 4: [4885/10940] ---- BYOL Validation Loss = 0.25315093994140625
31-01-2023 02:58:04 INFO Epoch 4: [4896/10940] ---- BYOL Training Loss = 0.29900622367858887
31-01-2023 02:58:22 INFO Epoch 4: [4907/10940] ---- BYOL Training Loss = 0.2836816608905792
31-01-2023 02:58:40 INFO Epoch 4: [4918/10940] ---- BYOL Training Loss = 0.26578396558761597
31-01-2023 02:58:58 INFO Epoch 4: [4929/10940] ---- BYOL Training Loss = 0.2523316442966461
31-01-2023 02:59:49 INFO Epoch 4: [4929/10940] ---- BYOL Validation Loss = 0.25330400466918945
31-01-2023 03:00:07 INFO Epoch 4: [4940/10940] ---- BYOL Training Loss = 0.23753710091114044
31-01-2023 03:00:25 INFO Epoch 4: [4951/10940] ---- BYOL Training Loss = 0.23310574889183044
31-01-2023 03:00:43 INFO Epoch 4: [4962/10940] ---- BYOL Training Loss = 0.2539902925491333
31-01-2023 03:01:01 INFO Epoch 4: [4973/10940] ---- BYOL Training Loss = 0.2539598345756531
31-01-2023 03:01:53 INFO Epoch 4: [4973/10940] ---- BYOL Validation Loss = 0.26377198100090027
31-01-2023 03:02:10 INFO Epoch 4: [4984/10940] ---- BYOL Training Loss = 0.28192633390426636
31-01-2023 03:02:29 INFO Epoch 4: [4995/10940] ---- BYOL Training Loss = 0.32353299856185913
31-01-2023 03:02:47 INFO Epoch 4: [5006/10940] ---- BYOL Training Loss = 0.2742884159088135
31-01-2023 03:03:05 INFO Epoch 4: [5017/10940] ---- BYOL Training Loss = 0.21204116940498352
31-01-2023 03:03:56 INFO Epoch 4: [5017/10940] ---- BYOL Validation Loss = 0.25682511925697327
31-01-2023 03:04:14 INFO Epoch 4: [5028/10940] ---- BYOL Training Loss = 0.22788551449775696
31-01-2023 03:04:32 INFO Epoch 4: [5039/10940] ---- BYOL Training Loss = 0.25631478428840637
31-01-2023 03:04:50 INFO Epoch 4: [5050/10940] ---- BYOL Training Loss = 0.2837247848510742
31-01-2023 03:05:08 INFO Epoch 4: [5061/10940] ---- BYOL Training Loss = 0.3042444884777069
31-01-2023 03:06:00 INFO Epoch 4: [5061/10940] ---- BYOL Validation Loss = 0.25724074244499207
31-01-2023 03:06:17 INFO Epoch 4: [5072/10940] ---- BYOL Training Loss = 0.2666223645210266
31-01-2023 03:06:35 INFO Epoch 4: [5083/10940] ---- BYOL Training Loss = 0.27145394682884216
31-01-2023 03:06:54 INFO Epoch 4: [5094/10940] ---- BYOL Training Loss = 0.2690579891204834
31-01-2023 03:07:12 INFO Epoch 4: [5105/10940] ---- BYOL Training Loss = 0.2509477734565735
31-01-2023 03:08:03 INFO Epoch 4: [5105/10940] ---- BYOL Validation Loss = 0.2568824589252472
31-01-2023 03:08:21 INFO Epoch 4: [5116/10940] ---- BYOL Training Loss = 0.24193081259727478
31-01-2023 03:08:39 INFO Epoch 4: [5127/10940] ---- BYOL Training Loss = 0.2593298852443695
31-01-2023 03:08:57 INFO Epoch 4: [5138/10940] ---- BYOL Training Loss = 0.2538054585456848
31-01-2023 03:09:15 INFO Epoch 4: [5149/10940] ---- BYOL Training Loss = 0.22679845988750458
31-01-2023 03:10:07 INFO Epoch 4: [5149/10940] ---- BYOL Validation Loss = 0.24793699383735657
31-01-2023 03:10:24 INFO Epoch 4: [5160/10940] ---- BYOL Training Loss = 0.24010474979877472
31-01-2023 03:10:42 INFO Epoch 4: [5171/10940] ---- BYOL Training Loss = 0.24074597656726837
31-01-2023 03:11:00 INFO Epoch 4: [5182/10940] ---- BYOL Training Loss = 0.22885651886463165
31-01-2023 03:11:18 INFO Epoch 4: [5193/10940] ---- BYOL Training Loss = 0.22650115191936493
31-01-2023 03:12:10 INFO Epoch 4: [5193/10940] ---- BYOL Validation Loss = 0.2598037123680115
31-01-2023 03:12:28 INFO Epoch 4: [5204/10940] ---- BYOL Training Loss = 0.24628396332263947
31-01-2023 03:12:46 INFO Epoch 4: [5215/10940] ---- BYOL Training Loss = 0.24007463455200195
31-01-2023 03:13:04 INFO Epoch 4: [5226/10940] ---- BYOL Training Loss = 0.22071783244609833
31-01-2023 03:13:22 INFO Epoch 4: [5237/10940] ---- BYOL Training Loss = 0.2123563289642334
31-01-2023 03:14:14 INFO Epoch 4: [5237/10940] ---- BYOL Validation Loss = 0.24634729325771332
31-01-2023 03:14:31 INFO Epoch 4: [5248/10940] ---- BYOL Training Loss = 0.2596104145050049
31-01-2023 03:14:49 INFO Epoch 4: [5259/10940] ---- BYOL Training Loss = 0.30016249418258667
31-01-2023 03:15:07 INFO Epoch 4: [5270/10940] ---- BYOL Training Loss = 0.26842498779296875
31-01-2023 03:15:25 INFO Epoch 4: [5281/10940] ---- BYOL Training Loss = 0.27758121490478516
31-01-2023 03:16:17 INFO Epoch 4: [5281/10940] ---- BYOL Validation Loss = 0.25557029247283936
31-01-2023 03:16:35 INFO Epoch 4: [5292/10940] ---- BYOL Training Loss = 0.26050740480422974
31-01-2023 03:16:53 INFO Epoch 4: [5303/10940] ---- BYOL Training Loss = 0.24702179431915283
31-01-2023 03:17:11 INFO Epoch 4: [5314/10940] ---- BYOL Training Loss = 0.24225802719593048
31-01-2023 03:17:29 INFO Epoch 4: [5325/10940] ---- BYOL Training Loss = 0.24205753207206726
31-01-2023 03:18:21 INFO Epoch 4: [5325/10940] ---- BYOL Validation Loss = 0.2569538652896881
31-01-2023 03:18:38 INFO Epoch 4: [5336/10940] ---- BYOL Training Loss = 0.26418229937553406
31-01-2023 03:18:56 INFO Epoch 4: [5347/10940] ---- BYOL Training Loss = 0.2790241837501526
31-01-2023 03:19:14 INFO Epoch 4: [5358/10940] ---- BYOL Training Loss = 0.2582307755947113
31-01-2023 03:19:32 INFO Epoch 4: [5369/10940] ---- BYOL Training Loss = 0.23053105175495148
31-01-2023 03:20:24 INFO Epoch 4: [5369/10940] ---- BYOL Validation Loss = 0.2537895739078522
31-01-2023 03:20:42 INFO Epoch 4: [5380/10940] ---- BYOL Training Loss = 0.3055265545845032
31-01-2023 03:21:00 INFO Epoch 4: [5391/10940] ---- BYOL Training Loss = 0.33814483880996704
31-01-2023 03:21:18 INFO Epoch 4: [5402/10940] ---- BYOL Training Loss = 0.27605992555618286
31-01-2023 03:21:36 INFO Epoch 4: [5413/10940] ---- BYOL Training Loss = 0.21712923049926758
31-01-2023 03:22:28 INFO Epoch 4: [5413/10940] ---- BYOL Validation Loss = 0.24340228736400604
31-01-2023 03:22:45 INFO Epoch 4: [5424/10940] ---- BYOL Training Loss = 0.24961300194263458
31-01-2023 03:23:04 INFO Epoch 4: [5435/10940] ---- BYOL Training Loss = 0.2978375554084778
31-01-2023 03:23:22 INFO Epoch 4: [5446/10940] ---- BYOL Training Loss = 0.29108139872550964
31-01-2023 03:23:40 INFO Epoch 4: [5457/10940] ---- BYOL Training Loss = 0.25971823930740356
31-01-2023 03:24:32 INFO Epoch 4: [5457/10940] ---- BYOL Validation Loss = 0.2509785592556
31-01-2023 03:24:49 INFO Epoch 4: [5468/10940] ---- BYOL Training Loss = 0.2797805666923523
31-01-2023 03:25:07 INFO Epoch 4: [5479/10940] ---- BYOL Training Loss = 0.2613983452320099
31-01-2023 03:25:25 INFO Epoch 4: [5490/10940] ---- BYOL Training Loss = 0.22874729335308075
31-01-2023 03:25:43 INFO Epoch 4: [5501/10940] ---- BYOL Training Loss = 0.23024752736091614
31-01-2023 03:26:35 INFO Epoch 4: [5501/10940] ---- BYOL Validation Loss = 0.2606092393398285
31-01-2023 03:26:53 INFO Epoch 4: [5512/10940] ---- BYOL Training Loss = 0.21695196628570557
31-01-2023 03:27:11 INFO Epoch 4: [5523/10940] ---- BYOL Training Loss = 0.2204107940196991
31-01-2023 03:27:29 INFO Epoch 4: [5534/10940] ---- BYOL Training Loss = 0.23464135825634003
31-01-2023 03:27:47 INFO Epoch 4: [5545/10940] ---- BYOL Training Loss = 0.247775599360466
31-01-2023 03:28:39 INFO Epoch 4: [5545/10940] ---- BYOL Validation Loss = 0.2561003267765045
31-01-2023 03:28:56 INFO Epoch 4: [5556/10940] ---- BYOL Training Loss = 0.2772355377674103
31-01-2023 03:29:14 INFO Epoch 4: [5567/10940] ---- BYOL Training Loss = 0.2521754503250122
31-01-2023 03:29:33 INFO Epoch 4: [5578/10940] ---- BYOL Training Loss = 0.2573728561401367
31-01-2023 03:29:51 INFO Epoch 4: [5589/10940] ---- BYOL Training Loss = 0.24938137829303741
31-01-2023 03:30:42 INFO Epoch 4: [5589/10940] ---- BYOL Validation Loss = 0.2521565556526184
31-01-2023 03:31:00 INFO Epoch 4: [5600/10940] ---- BYOL Training Loss = 0.26522549986839294
31-01-2023 03:31:18 INFO Epoch 4: [5611/10940] ---- BYOL Training Loss = 0.28674545884132385
31-01-2023 03:31:36 INFO Epoch 4: [5622/10940] ---- BYOL Training Loss = 0.24813544750213623
31-01-2023 03:31:54 INFO Epoch 4: [5633/10940] ---- BYOL Training Loss = 0.21823544800281525
31-01-2023 03:32:46 INFO Epoch 4: [5633/10940] ---- BYOL Validation Loss = 0.25313615798950195
31-01-2023 03:33:04 INFO Epoch 4: [5644/10940] ---- BYOL Training Loss = 0.24138888716697693
31-01-2023 03:33:22 INFO Epoch 4: [5655/10940] ---- BYOL Training Loss = 0.25957611203193665
31-01-2023 03:33:40 INFO Epoch 4: [5666/10940] ---- BYOL Training Loss = 0.26917535066604614
31-01-2023 03:33:58 INFO Epoch 4: [5677/10940] ---- BYOL Training Loss = 0.27426356077194214
31-01-2023 03:34:50 INFO Epoch 4: [5677/10940] ---- BYOL Validation Loss = 0.25274139642715454
31-01-2023 03:35:07 INFO Epoch 4: [5688/10940] ---- BYOL Training Loss = 0.23052401840686798
31-01-2023 03:35:25 INFO Epoch 4: [5699/10940] ---- BYOL Training Loss = 0.2268531769514084
31-01-2023 03:35:44 INFO Epoch 4: [5710/10940] ---- BYOL Training Loss = 0.2739434242248535
31-01-2023 03:36:02 INFO Epoch 4: [5721/10940] ---- BYOL Training Loss = 0.23224258422851562
31-01-2023 03:36:54 INFO Epoch 4: [5721/10940] ---- BYOL Validation Loss = 0.2570383846759796
31-01-2023 03:37:11 INFO Epoch 4: [5732/10940] ---- BYOL Training Loss = 0.19218894839286804
31-01-2023 03:37:29 INFO Epoch 4: [5743/10940] ---- BYOL Training Loss = 0.2040390968322754
31-01-2023 03:37:48 INFO Epoch 4: [5754/10940] ---- BYOL Training Loss = 0.20939388871192932
31-01-2023 03:38:06 INFO Epoch 4: [5765/10940] ---- BYOL Training Loss = 0.28154247999191284
31-01-2023 03:38:57 INFO Epoch 4: [5765/10940] ---- BYOL Validation Loss = 0.24527156352996826
31-01-2023 03:39:15 INFO Epoch 4: [5776/10940] ---- BYOL Training Loss = 0.28244075179100037
31-01-2023 03:39:33 INFO Epoch 4: [5787/10940] ---- BYOL Training Loss = 0.3055574297904968
31-01-2023 03:39:51 INFO Epoch 4: [5798/10940] ---- BYOL Training Loss = 0.2748410999774933
31-01-2023 03:40:09 INFO Epoch 4: [5809/10940] ---- BYOL Training Loss = 0.2328251153230667
31-01-2023 03:41:01 INFO Epoch 4: [5809/10940] ---- BYOL Validation Loss = 0.25569289922714233
31-01-2023 03:41:19 INFO Epoch 4: [5820/10940] ---- BYOL Training Loss = 0.2354816198348999
31-01-2023 03:41:37 INFO Epoch 4: [5831/10940] ---- BYOL Training Loss = 0.26541367173194885
31-01-2023 03:41:55 INFO Epoch 4: [5842/10940] ---- BYOL Training Loss = 0.2704920172691345
31-01-2023 03:42:13 INFO Epoch 4: [5853/10940] ---- BYOL Training Loss = 0.24672476947307587
31-01-2023 03:43:05 INFO Epoch 4: [5853/10940] ---- BYOL Validation Loss = 0.2465246468782425
31-01-2023 03:43:23 INFO Epoch 4: [5864/10940] ---- BYOL Training Loss = 0.2465776950120926
31-01-2023 03:43:41 INFO Epoch 4: [5875/10940] ---- BYOL Training Loss = 0.24498657882213593
31-01-2023 03:43:59 INFO Epoch 4: [5886/10940] ---- BYOL Training Loss = 0.20526418089866638
31-01-2023 03:44:17 INFO Epoch 4: [5897/10940] ---- BYOL Training Loss = 0.23047354817390442
31-01-2023 03:45:09 INFO Epoch 4: [5897/10940] ---- BYOL Validation Loss = 0.2541513741016388
31-01-2023 03:45:27 INFO Epoch 4: [5908/10940] ---- BYOL Training Loss = 0.26772135496139526
31-01-2023 03:45:45 INFO Epoch 4: [5919/10940] ---- BYOL Training Loss = 0.211211159825325
31-01-2023 03:46:03 INFO Epoch 4: [5930/10940] ---- BYOL Training Loss = 0.21091680228710175
31-01-2023 03:46:21 INFO Epoch 4: [5941/10940] ---- BYOL Training Loss = 0.2530158460140228
31-01-2023 03:47:13 INFO Epoch 4: [5941/10940] ---- BYOL Validation Loss = 0.260843425989151
31-01-2023 03:47:31 INFO Epoch 4: [5952/10940] ---- BYOL Training Loss = 0.3127050995826721
31-01-2023 03:47:49 INFO Epoch 4: [5963/10940] ---- BYOL Training Loss = 0.26093789935112
31-01-2023 03:48:07 INFO Epoch 4: [5974/10940] ---- BYOL Training Loss = 0.22759756445884705
31-01-2023 03:48:25 INFO Epoch 4: [5985/10940] ---- BYOL Training Loss = 0.2591966986656189
31-01-2023 03:49:17 INFO Epoch 4: [5985/10940] ---- BYOL Validation Loss = 0.2538619041442871
31-01-2023 03:49:34 INFO Epoch 4: [5996/10940] ---- BYOL Training Loss = 0.26456978917121887
31-01-2023 03:49:53 INFO Epoch 4: [6007/10940] ---- BYOL Training Loss = 0.2530955672264099
31-01-2023 03:50:11 INFO Epoch 4: [6018/10940] ---- BYOL Training Loss = 0.2567457854747772
31-01-2023 03:50:29 INFO Epoch 4: [6029/10940] ---- BYOL Training Loss = 0.2911907434463501
31-01-2023 03:51:21 INFO Epoch 4: [6029/10940] ---- BYOL Validation Loss = 0.2555830180644989
31-01-2023 03:51:38 INFO Epoch 4: [6040/10940] ---- BYOL Training Loss = 0.2935958504676819
31-01-2023 03:51:56 INFO Epoch 4: [6051/10940] ---- BYOL Training Loss = 0.2611522376537323
31-01-2023 03:52:15 INFO Epoch 4: [6062/10940] ---- BYOL Training Loss = 0.273901104927063
31-01-2023 03:52:33 INFO Epoch 4: [6073/10940] ---- BYOL Training Loss = 0.24853169918060303
31-01-2023 03:53:25 INFO Epoch 4: [6073/10940] ---- BYOL Validation Loss = 0.25403937697410583
31-01-2023 03:53:42 INFO Epoch 4: [6084/10940] ---- BYOL Training Loss = 0.2339392453432083
31-01-2023 03:54:00 INFO Epoch 4: [6095/10940] ---- BYOL Training Loss = 0.2627885043621063
31-01-2023 03:54:19 INFO Epoch 4: [6106/10940] ---- BYOL Training Loss = 0.25309792160987854
31-01-2023 03:54:37 INFO Epoch 4: [6117/10940] ---- BYOL Training Loss = 0.25596120953559875
31-01-2023 03:55:28 INFO Epoch 4: [6117/10940] ---- BYOL Validation Loss = 0.2479054182767868
31-01-2023 03:55:46 INFO Epoch 4: [6128/10940] ---- BYOL Training Loss = 0.2420116364955902
31-01-2023 03:56:04 INFO Epoch 4: [6139/10940] ---- BYOL Training Loss = 0.23486927151679993
31-01-2023 03:56:23 INFO Epoch 4: [6150/10940] ---- BYOL Training Loss = 0.27074259519577026
31-01-2023 03:56:40 INFO Epoch 4: [6161/10940] ---- BYOL Training Loss = 0.24450841546058655
31-01-2023 03:57:32 INFO Epoch 4: [6161/10940] ---- BYOL Validation Loss = 0.2543226480484009
31-01-2023 03:57:50 INFO Epoch 4: [6172/10940] ---- BYOL Training Loss = 0.21472057700157166
31-01-2023 03:58:08 INFO Epoch 4: [6183/10940] ---- BYOL Training Loss = 0.263740211725235
31-01-2023 03:58:26 INFO Epoch 4: [6194/10940] ---- BYOL Training Loss = 0.2587084174156189
31-01-2023 03:58:44 INFO Epoch 4: [6205/10940] ---- BYOL Training Loss = 0.22452834248542786
31-01-2023 03:59:36 INFO Epoch 4: [6205/10940] ---- BYOL Validation Loss = 0.25099828839302063
31-01-2023 03:59:54 INFO Epoch 4: [6216/10940] ---- BYOL Training Loss = 0.2578975558280945
31-01-2023 04:00:12 INFO Epoch 4: [6227/10940] ---- BYOL Training Loss = 0.23773784935474396
31-01-2023 04:00:30 INFO Epoch 4: [6238/10940] ---- BYOL Training Loss = 0.22939518094062805
31-01-2023 04:00:48 INFO Epoch 4: [6249/10940] ---- BYOL Training Loss = 0.287341833114624
31-01-2023 04:01:40 INFO Epoch 4: [6249/10940] ---- BYOL Validation Loss = 0.2548198699951172
31-01-2023 04:01:58 INFO Epoch 4: [6260/10940] ---- BYOL Training Loss = 0.2696012258529663
31-01-2023 04:02:16 INFO Epoch 4: [6271/10940] ---- BYOL Training Loss = 0.22413578629493713
31-01-2023 04:02:34 INFO Epoch 4: [6282/10940] ---- BYOL Training Loss = 0.27705541253089905
31-01-2023 04:02:52 INFO Epoch 4: [6293/10940] ---- BYOL Training Loss = 0.32820719480514526
31-01-2023 04:03:44 INFO Epoch 4: [6293/10940] ---- BYOL Validation Loss = 0.2480548769235611
31-01-2023 04:04:02 INFO Epoch 4: [6304/10940] ---- BYOL Training Loss = 0.2947787940502167
31-01-2023 04:04:20 INFO Epoch 4: [6315/10940] ---- BYOL Training Loss = 0.21746893227100372
31-01-2023 04:04:38 INFO Epoch 4: [6326/10940] ---- BYOL Training Loss = 0.27149567008018494
31-01-2023 04:04:56 INFO Epoch 4: [6337/10940] ---- BYOL Training Loss = 0.28755292296409607
31-01-2023 04:05:48 INFO Epoch 4: [6337/10940] ---- BYOL Validation Loss = 0.2494451254606247
31-01-2023 04:06:06 INFO Epoch 4: [6348/10940] ---- BYOL Training Loss = 0.25660112500190735
31-01-2023 04:06:24 INFO Epoch 4: [6359/10940] ---- BYOL Training Loss = 0.27438634634017944
31-01-2023 04:06:42 INFO Epoch 4: [6370/10940] ---- BYOL Training Loss = 0.2683737874031067
31-01-2023 04:07:00 INFO Epoch 4: [6381/10940] ---- BYOL Training Loss = 0.229183167219162
31-01-2023 04:07:52 INFO Epoch 4: [6381/10940] ---- BYOL Validation Loss = 0.25158172845840454
31-01-2023 04:08:10 INFO Epoch 4: [6392/10940] ---- BYOL Training Loss = 0.20477397739887238
31-01-2023 04:08:28 INFO Epoch 4: [6403/10940] ---- BYOL Training Loss = 0.23176173865795135
31-01-2023 04:08:46 INFO Epoch 4: [6414/10940] ---- BYOL Training Loss = 0.26289668679237366
31-01-2023 04:09:04 INFO Epoch 4: [6425/10940] ---- BYOL Training Loss = 0.2789611220359802
31-01-2023 04:09:56 INFO Epoch 4: [6425/10940] ---- BYOL Validation Loss = 0.25002795457839966
31-01-2023 04:10:14 INFO Epoch 4: [6436/10940] ---- BYOL Training Loss = 0.2806982398033142
31-01-2023 04:10:32 INFO Epoch 4: [6447/10940] ---- BYOL Training Loss = 0.24669146537780762
31-01-2023 04:10:50 INFO Epoch 4: [6458/10940] ---- BYOL Training Loss = 0.30221861600875854
31-01-2023 04:11:08 INFO Epoch 4: [6469/10940] ---- BYOL Training Loss = 0.31576043367385864
31-01-2023 04:12:00 INFO Epoch 4: [6469/10940] ---- BYOL Validation Loss = 0.2539733052253723
31-01-2023 04:12:18 INFO Epoch 4: [6480/10940] ---- BYOL Training Loss = 0.30176880955696106
31-01-2023 04:12:36 INFO Epoch 4: [6491/10940] ---- BYOL Training Loss = 0.31760191917419434
31-01-2023 04:12:54 INFO Epoch 4: [6502/10940] ---- BYOL Training Loss = 0.26634106040000916
31-01-2023 04:13:13 INFO Epoch 4: [6513/10940] ---- BYOL Training Loss = 0.25505587458610535
31-01-2023 04:14:04 INFO Epoch 4: [6513/10940] ---- BYOL Validation Loss = 0.2445497214794159
31-01-2023 04:14:22 INFO Epoch 4: [6524/10940] ---- BYOL Training Loss = 0.2808665633201599
31-01-2023 04:14:40 INFO Epoch 4: [6535/10940] ---- BYOL Training Loss = 0.28248539566993713
31-01-2023 04:14:59 INFO Epoch 4: [6546/10940] ---- BYOL Training Loss = 0.22761356830596924
31-01-2023 04:15:17 INFO Epoch 4: [6557/10940] ---- BYOL Training Loss = 0.2415657490491867
31-01-2023 04:16:08 INFO Epoch 4: [6557/10940] ---- BYOL Validation Loss = 0.24403230845928192
31-01-2023 04:16:26 INFO Epoch 4: [6568/10940] ---- BYOL Training Loss = 0.24802139401435852
31-01-2023 04:16:44 INFO Epoch 4: [6579/10940] ---- BYOL Training Loss = 0.2435113936662674
31-01-2023 04:17:03 INFO Epoch 4: [6590/10940] ---- BYOL Training Loss = 0.23093156516551971
31-01-2023 04:17:21 INFO Epoch 4: [6601/10940] ---- BYOL Training Loss = 0.2459971010684967
31-01-2023 04:18:12 INFO Epoch 4: [6601/10940] ---- BYOL Validation Loss = 0.2486894428730011
31-01-2023 04:18:30 INFO Epoch 4: [6612/10940] ---- BYOL Training Loss = 0.2623867988586426
31-01-2023 04:18:48 INFO Epoch 4: [6623/10940] ---- BYOL Training Loss = 0.2733863890171051
31-01-2023 04:19:07 INFO Epoch 4: [6634/10940] ---- BYOL Training Loss = 0.2739083170890808
31-01-2023 04:19:25 INFO Epoch 4: [6645/10940] ---- BYOL Training Loss = 0.2610671818256378
31-01-2023 04:20:16 INFO Epoch 4: [6645/10940] ---- BYOL Validation Loss = 0.25146812200546265
31-01-2023 04:20:34 INFO Epoch 4: [6656/10940] ---- BYOL Training Loss = 0.25717848539352417
31-01-2023 04:20:53 INFO Epoch 4: [6667/10940] ---- BYOL Training Loss = 0.2651144862174988
31-01-2023 04:21:11 INFO Epoch 4: [6678/10940] ---- BYOL Training Loss = 0.2734318673610687
31-01-2023 04:21:29 INFO Epoch 4: [6689/10940] ---- BYOL Training Loss = 0.2833860516548157
31-01-2023 04:22:21 INFO Epoch 4: [6689/10940] ---- BYOL Validation Loss = 0.24108685553073883
31-01-2023 04:22:38 INFO Epoch 4: [6700/10940] ---- BYOL Training Loss = 0.2529471814632416
31-01-2023 04:22:57 INFO Epoch 4: [6711/10940] ---- BYOL Training Loss = 0.2469506561756134
31-01-2023 04:23:15 INFO Epoch 4: [6722/10940] ---- BYOL Training Loss = 0.2733292281627655
31-01-2023 04:23:33 INFO Epoch 4: [6733/10940] ---- BYOL Training Loss = 0.2874019742012024
31-01-2023 04:24:25 INFO Epoch 4: [6733/10940] ---- BYOL Validation Loss = 0.2592794895172119
31-01-2023 04:24:43 INFO Epoch 4: [6744/10940] ---- BYOL Training Loss = 0.2593289315700531
31-01-2023 04:25:01 INFO Epoch 4: [6755/10940] ---- BYOL Training Loss = 0.2521534562110901
31-01-2023 04:25:19 INFO Epoch 4: [6766/10940] ---- BYOL Training Loss = 0.27431029081344604
31-01-2023 04:25:38 INFO Epoch 4: [6777/10940] ---- BYOL Training Loss = 0.26079797744750977
31-01-2023 04:26:29 INFO Epoch 4: [6777/10940] ---- BYOL Validation Loss = 0.24694392085075378
31-01-2023 04:26:47 INFO Epoch 4: [6788/10940] ---- BYOL Training Loss = 0.24472124874591827
31-01-2023 04:27:05 INFO Epoch 4: [6799/10940] ---- BYOL Training Loss = 0.2630311846733093
31-01-2023 04:27:24 INFO Epoch 4: [6810/10940] ---- BYOL Training Loss = 0.295929491519928
31-01-2023 04:27:42 INFO Epoch 4: [6821/10940] ---- BYOL Training Loss = 0.2781595289707184
31-01-2023 04:28:33 INFO Epoch 4: [6821/10940] ---- BYOL Validation Loss = 0.2456207573413849
31-01-2023 04:28:51 INFO Epoch 4: [6832/10940] ---- BYOL Training Loss = 0.2554354667663574
31-01-2023 04:29:09 INFO Epoch 4: [6843/10940] ---- BYOL Training Loss = 0.26976197957992554
31-01-2023 04:29:28 INFO Epoch 4: [6854/10940] ---- BYOL Training Loss = 0.2630949318408966
31-01-2023 04:29:46 INFO Epoch 4: [6865/10940] ---- BYOL Training Loss = 0.2789393961429596
31-01-2023 04:30:38 INFO Epoch 4: [6865/10940] ---- BYOL Validation Loss = 0.2604908347129822
31-01-2023 04:30:55 INFO Epoch 4: [6876/10940] ---- BYOL Training Loss = 0.28379592299461365
31-01-2023 04:31:14 INFO Epoch 4: [6887/10940] ---- BYOL Training Loss = 0.2611362338066101
31-01-2023 04:31:32 INFO Epoch 4: [6898/10940] ---- BYOL Training Loss = 0.2495805323123932
31-01-2023 04:31:50 INFO Epoch 4: [6909/10940] ---- BYOL Training Loss = 0.2504236400127411
31-01-2023 04:32:42 INFO Epoch 4: [6909/10940] ---- BYOL Validation Loss = 0.24217304587364197
31-01-2023 04:33:00 INFO Epoch 4: [6920/10940] ---- BYOL Training Loss = 0.2752082347869873
31-01-2023 04:33:18 INFO Epoch 4: [6931/10940] ---- BYOL Training Loss = 0.2812598943710327
31-01-2023 04:33:36 INFO Epoch 4: [6942/10940] ---- BYOL Training Loss = 0.27305519580841064
31-01-2023 04:33:54 INFO Epoch 4: [6953/10940] ---- BYOL Training Loss = 0.25154149532318115
31-01-2023 04:34:46 INFO Epoch 4: [6953/10940] ---- BYOL Validation Loss = 0.24729600548744202
31-01-2023 04:35:04 INFO Epoch 4: [6964/10940] ---- BYOL Training Loss = 0.2111741304397583
31-01-2023 04:35:22 INFO Epoch 4: [6975/10940] ---- BYOL Training Loss = 0.2745538353919983
31-01-2023 04:35:40 INFO Epoch 4: [6986/10940] ---- BYOL Training Loss = 0.3012629449367523
31-01-2023 04:35:59 INFO Epoch 4: [6997/10940] ---- BYOL Training Loss = 0.30485159158706665
31-01-2023 04:36:51 INFO Epoch 4: [6997/10940] ---- BYOL Validation Loss = 0.25192180275917053
31-01-2023 04:37:08 INFO Epoch 4: [7008/10940] ---- BYOL Training Loss = 0.28984734416007996
31-01-2023 04:37:27 INFO Epoch 4: [7019/10940] ---- BYOL Training Loss = 0.2502654492855072
31-01-2023 04:37:45 INFO Epoch 4: [7030/10940] ---- BYOL Training Loss = 0.23250512778759003
31-01-2023 04:38:03 INFO Epoch 4: [7041/10940] ---- BYOL Training Loss = 0.22825057804584503
31-01-2023 04:38:55 INFO Epoch 4: [7041/10940] ---- BYOL Validation Loss = 0.24797379970550537
31-01-2023 04:39:13 INFO Epoch 4: [7052/10940] ---- BYOL Training Loss = 0.2775479555130005
31-01-2023 04:39:31 INFO Epoch 4: [7063/10940] ---- BYOL Training Loss = 0.25060319900512695
31-01-2023 04:39:50 INFO Epoch 4: [7074/10940] ---- BYOL Training Loss = 0.23600471019744873
31-01-2023 04:40:08 INFO Epoch 4: [7085/10940] ---- BYOL Training Loss = 0.2646346390247345
31-01-2023 04:40:59 INFO Epoch 4: [7085/10940] ---- BYOL Validation Loss = 0.2480965107679367
31-01-2023 04:41:17 INFO Epoch 4: [7096/10940] ---- BYOL Training Loss = 0.2829902768135071
31-01-2023 04:41:36 INFO Epoch 4: [7107/10940] ---- BYOL Training Loss = 0.23967942595481873
31-01-2023 04:41:54 INFO Epoch 4: [7118/10940] ---- BYOL Training Loss = 0.24947324395179749
31-01-2023 04:42:12 INFO Epoch 4: [7129/10940] ---- BYOL Training Loss = 0.2590924799442291
31-01-2023 04:43:04 INFO Epoch 4: [7129/10940] ---- BYOL Validation Loss = 0.25046229362487793
31-01-2023 04:43:22 INFO Epoch 4: [7140/10940] ---- BYOL Training Loss = 0.28088077902793884
31-01-2023 04:43:40 INFO Epoch 4: [7151/10940] ---- BYOL Training Loss = 0.2649744153022766
31-01-2023 04:43:58 INFO Epoch 4: [7162/10940] ---- BYOL Training Loss = 0.2457747757434845
31-01-2023 04:44:17 INFO Epoch 4: [7173/10940] ---- BYOL Training Loss = 0.2634446918964386
31-01-2023 04:45:08 INFO Epoch 4: [7173/10940] ---- BYOL Validation Loss = 0.2542656660079956
31-01-2023 04:45:26 INFO Epoch 4: [7184/10940] ---- BYOL Training Loss = 0.26722559332847595
31-01-2023 04:45:44 INFO Epoch 4: [7195/10940] ---- BYOL Training Loss = 0.25646334886550903
31-01-2023 04:46:02 INFO Epoch 4: [7206/10940] ---- BYOL Training Loss = 0.285118043422699
31-01-2023 04:46:21 INFO Epoch 4: [7217/10940] ---- BYOL Training Loss = 0.2864024043083191
31-01-2023 04:47:13 INFO Epoch 4: [7217/10940] ---- BYOL Validation Loss = 0.247848778963089
31-01-2023 04:47:30 INFO Epoch 4: [7228/10940] ---- BYOL Training Loss = 0.25035983324050903
31-01-2023 04:47:48 INFO Epoch 4: [7239/10940] ---- BYOL Training Loss = 0.25534990429878235
31-01-2023 04:48:07 INFO Epoch 4: [7250/10940] ---- BYOL Training Loss = 0.31602799892425537
31-01-2023 04:48:25 INFO Epoch 4: [7261/10940] ---- BYOL Training Loss = 0.26735177636146545
31-01-2023 04:49:17 INFO Epoch 4: [7261/10940] ---- BYOL Validation Loss = 0.2474968433380127
31-01-2023 04:49:35 INFO Epoch 4: [7272/10940] ---- BYOL Training Loss = 0.2535874843597412
31-01-2023 04:49:53 INFO Epoch 4: [7283/10940] ---- BYOL Training Loss = 0.25184565782546997
31-01-2023 04:50:11 INFO Epoch 4: [7294/10940] ---- BYOL Training Loss = 0.20578666031360626
31-01-2023 04:50:29 INFO Epoch 4: [7305/10940] ---- BYOL Training Loss = 0.26515957713127136
31-01-2023 04:51:21 INFO Epoch 4: [7305/10940] ---- BYOL Validation Loss = 0.2493172436952591
31-01-2023 04:51:39 INFO Epoch 4: [7316/10940] ---- BYOL Training Loss = 0.31896576285362244
31-01-2023 04:51:57 INFO Epoch 4: [7327/10940] ---- BYOL Training Loss = 0.2526790201663971
31-01-2023 04:52:16 INFO Epoch 4: [7338/10940] ---- BYOL Training Loss = 0.25024545192718506
31-01-2023 04:52:34 INFO Epoch 4: [7349/10940] ---- BYOL Training Loss = 0.2818228006362915
31-01-2023 04:53:25 INFO Epoch 4: [7349/10940] ---- BYOL Validation Loss = 0.24582111835479736
31-01-2023 04:53:44 INFO Epoch 4: [7360/10940] ---- BYOL Training Loss = 0.28873273730278015
31-01-2023 04:54:02 INFO Epoch 4: [7371/10940] ---- BYOL Training Loss = 0.28554436564445496
31-01-2023 04:54:20 INFO Epoch 4: [7382/10940] ---- BYOL Training Loss = 0.2608375549316406
31-01-2023 04:54:39 INFO Epoch 4: [7393/10940] ---- BYOL Training Loss = 0.2346329391002655
31-01-2023 04:55:30 INFO Epoch 4: [7393/10940] ---- BYOL Validation Loss = 0.2498284876346588
31-01-2023 04:55:48 INFO Epoch 4: [7404/10940] ---- BYOL Training Loss = 0.22103524208068848
31-01-2023 04:56:06 INFO Epoch 4: [7415/10940] ---- BYOL Training Loss = 0.24331052601337433
31-01-2023 04:56:25 INFO Epoch 4: [7426/10940] ---- BYOL Training Loss = 0.2610601782798767
31-01-2023 04:56:43 INFO Epoch 4: [7437/10940] ---- BYOL Training Loss = 0.28471270203590393
31-01-2023 04:57:34 INFO Epoch 4: [7437/10940] ---- BYOL Validation Loss = 0.2506488859653473
31-01-2023 04:57:52 INFO Epoch 4: [7448/10940] ---- BYOL Training Loss = 0.2747144103050232
31-01-2023 04:58:11 INFO Epoch 4: [7459/10940] ---- BYOL Training Loss = 0.24837195873260498
31-01-2023 04:58:29 INFO Epoch 4: [7470/10940] ---- BYOL Training Loss = 0.2655002176761627
31-01-2023 04:58:47 INFO Epoch 4: [7481/10940] ---- BYOL Training Loss = 0.23974637687206268
31-01-2023 04:59:39 INFO Epoch 4: [7481/10940] ---- BYOL Validation Loss = 0.24396464228630066
31-01-2023 04:59:57 INFO Epoch 4: [7492/10940] ---- BYOL Training Loss = 0.25845271348953247
31-01-2023 05:00:15 INFO Epoch 4: [7503/10940] ---- BYOL Training Loss = 0.24749024212360382
31-01-2023 05:00:33 INFO Epoch 4: [7514/10940] ---- BYOL Training Loss = 0.25380295515060425
31-01-2023 05:00:52 INFO Epoch 4: [7525/10940] ---- BYOL Training Loss = 0.24836616218090057
31-01-2023 05:01:44 INFO Epoch 4: [7525/10940] ---- BYOL Validation Loss = 0.24475206434726715
31-01-2023 05:02:01 INFO Epoch 4: [7536/10940] ---- BYOL Training Loss = 0.27224618196487427
31-01-2023 05:02:20 INFO Epoch 4: [7547/10940] ---- BYOL Training Loss = 0.27323275804519653
31-01-2023 05:02:38 INFO Epoch 4: [7558/10940] ---- BYOL Training Loss = 0.2627066671848297
31-01-2023 05:02:56 INFO Epoch 4: [7569/10940] ---- BYOL Training Loss = 0.29691383242607117
31-01-2023 05:03:48 INFO Epoch 4: [7569/10940] ---- BYOL Validation Loss = 0.25171518325805664
31-01-2023 05:04:06 INFO Epoch 4: [7580/10940] ---- BYOL Training Loss = 0.32130739092826843
31-01-2023 05:04:24 INFO Epoch 4: [7591/10940] ---- BYOL Training Loss = 0.2896643280982971
31-01-2023 05:04:43 INFO Epoch 4: [7602/10940] ---- BYOL Training Loss = 0.2942315936088562
31-01-2023 05:05:01 INFO Epoch 4: [7613/10940] ---- BYOL Training Loss = 0.2592199146747589
31-01-2023 05:05:52 INFO Epoch 4: [7613/10940] ---- BYOL Validation Loss = 0.2472650110721588
31-01-2023 05:06:11 INFO Epoch 4: [7624/10940] ---- BYOL Training Loss = 0.21249432861804962
31-01-2023 05:06:29 INFO Epoch 4: [7635/10940] ---- BYOL Training Loss = 0.21867792308330536
31-01-2023 05:06:47 INFO Epoch 4: [7646/10940] ---- BYOL Training Loss = 0.24469491839408875
31-01-2023 05:07:05 INFO Epoch 4: [7657/10940] ---- BYOL Training Loss = 0.26705601811408997
31-01-2023 05:07:57 INFO Epoch 4: [7657/10940] ---- BYOL Validation Loss = 0.24459831416606903
31-01-2023 05:08:15 INFO Epoch 4: [7668/10940] ---- BYOL Training Loss = 0.2692902982234955
31-01-2023 05:08:33 INFO Epoch 4: [7679/10940] ---- BYOL Training Loss = 0.26678675413131714
31-01-2023 05:08:51 INFO Epoch 4: [7690/10940] ---- BYOL Training Loss = 0.2406541109085083
31-01-2023 05:09:10 INFO Epoch 4: [7701/10940] ---- BYOL Training Loss = 0.23312914371490479
31-01-2023 05:10:01 INFO Epoch 4: [7701/10940] ---- BYOL Validation Loss = 0.2397874891757965
31-01-2023 05:10:19 INFO Epoch 4: [7712/10940] ---- BYOL Training Loss = 0.25793376564979553
31-01-2023 05:10:37 INFO Epoch 4: [7723/10940] ---- BYOL Training Loss = 0.24875696003437042
31-01-2023 05:10:56 INFO Epoch 4: [7734/10940] ---- BYOL Training Loss = 0.24356424808502197
31-01-2023 05:11:14 INFO Epoch 4: [7745/10940] ---- BYOL Training Loss = 0.24612006545066833
31-01-2023 05:12:06 INFO Epoch 4: [7745/10940] ---- BYOL Validation Loss = 0.2404225617647171
31-01-2023 05:12:24 INFO Epoch 4: [7756/10940] ---- BYOL Training Loss = 0.22214190661907196
31-01-2023 05:12:42 INFO Epoch 4: [7767/10940] ---- BYOL Training Loss = 0.21900705993175507
31-01-2023 05:13:00 INFO Epoch 4: [7778/10940] ---- BYOL Training Loss = 0.3065793812274933
31-01-2023 05:13:19 INFO Epoch 4: [7789/10940] ---- BYOL Training Loss = 0.31444042921066284
31-01-2023 05:14:10 INFO Epoch 4: [7789/10940] ---- BYOL Validation Loss = 0.24899959564208984
31-01-2023 05:14:28 INFO Epoch 4: [7800/10940] ---- BYOL Training Loss = 0.2698950469493866
31-01-2023 05:14:47 INFO Epoch 4: [7811/10940] ---- BYOL Training Loss = 0.252268522977829
31-01-2023 05:15:05 INFO Epoch 4: [7822/10940] ---- BYOL Training Loss = 0.2312263697385788
31-01-2023 05:15:23 INFO Epoch 4: [7833/10940] ---- BYOL Training Loss = 0.2326972931623459
31-01-2023 05:16:15 INFO Epoch 4: [7833/10940] ---- BYOL Validation Loss = 0.24466052651405334
31-01-2023 05:16:33 INFO Epoch 4: [7844/10940] ---- BYOL Training Loss = 0.22600157558918
31-01-2023 05:16:52 INFO Epoch 4: [7855/10940] ---- BYOL Training Loss = 0.2521499693393707
31-01-2023 05:17:10 INFO Epoch 4: [7866/10940] ---- BYOL Training Loss = 0.2414354830980301
31-01-2023 05:17:28 INFO Epoch 4: [7877/10940] ---- BYOL Training Loss = 0.22970321774482727
31-01-2023 05:18:20 INFO Epoch 4: [7877/10940] ---- BYOL Validation Loss = 0.24978730082511902
31-01-2023 05:18:38 INFO Epoch 4: [7888/10940] ---- BYOL Training Loss = 0.25910571217536926
slurmstepd-landonia21: error: *** JOB 1507987 ON landonia21 CANCELLED AT 2023-01-31T05:18:44 DUE TO TIME LIMIT ***
